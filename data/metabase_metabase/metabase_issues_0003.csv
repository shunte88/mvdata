id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2673956862,issue,closed,completed,[Epic] Integrate new code editor lib,"### Links

- [product doc](https://www.notion.so/metabase/Native-editor-revamp-5a4b32bca82646fbb2d6ae455c674602)
- [tech doc](https://www.notion.so/metabase/Tech-doc-Native-editor-revamp-14569354c90180a0846cd5451992cc1c)
- [testing plan](https://www.notion.so/metabase/Testing-plan-Native-editor-revamp-14569354c901803bac92ecb07764e373)
- feature branch: `native-editor-revamp`
- issue links:
  - https://github.com/metabase/metabase/issues/45681
  - https://github.com/metabase/metabase/issues/12520
  - https://github.com/metabase/metabase/issues/16013
  - https://github.com/metabase/metabase/issues/3885
  - https://github.com/metabase/metabase/issues/13693
  - https://github.com/metabase/metabase/issues/48712
  - https://github.com/metabase/metabase/issues/4469
  - https://github.com/metabase/metabase/issues/4587
  - https://github.com/metabase/metabase/issues/26218

### Implementation Plan

```[tasklist]
#### Milestone 1: Research if replacing ACE with CodeMirror 6 is a good idea
- [ ] https://github.com/metabase/metabase/issues/50257
- [ ] https://github.com/metabase/metabase/issues/51090
- [ ] https://github.com/metabase/metabase/issues/51493
- [ ] https://github.com/metabase/metabase/issues/52585
```

```[tasklist]
#### Milestone 2: BE issues
- [ ] https://github.com/metabase/metabase/issues/26218
- [ ] https://github.com/metabase/metabase/issues/16013
- [ ] https://github.com/metabase/metabase/issues/45681
- [ ] https://github.com/metabase/metabase/issues/13693
```

```[tasklist]
#### Milestone 3: FE improvements
- [ ] Allow changing query text size
- [ ] Show database type so the user would know which syntax to use
- [ ] Add a user preference for autoformat settings (ie. tabs vs spaces, number of spaces)
- [ ] Add dark theme
- [ ] Add a user preference for uppercase vs lowercase keywords 
```

```[tasklist]
#### Milestone 4: Revamp data reference
- [ ] Implement preloading and pagination to make it loading faster 
- [ ] Allow to search for connected questions
- [ ] Show tables, columns, models, metrics, questions in tabs so they would be accessible without scrolling
- [ ] Implement click-to-insert button for data reference entries
- [ ] Show table and column descriptions on hover as in other places
- [ ] Update the UI to make it consistent with the new style of the data entry lists 
- [ ] Allow to search in the data reference
```",romeovs,2024-11-20 00:12:47+00:00,['romeovs'],2025-01-31 15:16:02+00:00,2025-01-29 17:39:24+00:00,https://github.com/metabase/metabase/issues/50249,"[('.Frontend', ''), ('.Epic', 'Feature Implementation or Project')]",[],
2673577108,issue,open,,[Epic] Migrate segments to MBQL lib,"Use MBQL lib and query components instead of legacy ones.

```[tasklist]
- [ ] Segment editor
- [ ] Segment revision history
```",ranquild,2024-11-19 21:26:26+00:00,['ranquild'],2024-11-19 21:26:33+00:00,,https://github.com/metabase/metabase/issues/50244,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2673568994,issue,open,,We should run the CI building/containerizing jobs on branches that touch those files,Right now they only run on `master` which means changes to the GH Actions workflows or actions can break the build and fixing it is a big PITA since you don't know if your fix actually worked until it hits `master`. We should run those jobs on PRs that touch those files ,camsaul,2024-11-19 21:21:10+00:00,[],2025-02-04 20:23:40+00:00,,https://github.com/metabase/metabase/issues/50243,"[('.Building & Releasing', ''), ('.CI & Tests', ''), ('.Team/DevEx', '')]","[{'comment_id': 2486783353, 'issue_id': 2673568994, 'author': 'camsaul', 'body': ""See https://metaboat.slack.com/archives/C5XHN8GLW/p1731949219128809 for more context about how we broke the build since we weren't running these tests"", 'created_at': datetime.datetime(2024, 11, 19, 21, 24, 49, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-11-19 21:24:49 UTC): See https://metaboat.slack.com/archives/C5XHN8GLW/p1731949219128809 for more context about how we broke the build since we weren't running these tests

"
2673540959,issue,open,,"After we finish modularizing the backend code, make CI smarter about which tests to run","Credit Sanya for suggesting this here https://metaboat.slack.com/archives/C5XHN8GLW/p1732048772680349

I could easily see us writing code where if we have module dependencies like

```
Module C --depends-on--> Module B --depends-on--> Module A
```

and a PR only touches Module C then we don't need to run the tests for B or A. It will definitely be doable at some point in the near future.

Once we finish the backend modularity project we should look into this",camsaul,2024-11-19 21:03:02+00:00,[],2025-02-04 20:23:38+00:00,,https://github.com/metabase/metabase/issues/50241,"[('.CI & Tests', ''), ('.Team/DevEx', '')]",[],
2673387117,issue,closed,completed,[Epic] Remove inline temporal bucketing from exclude date filter expressions,"There are 4 exclude date filters that use temporal buckets:
- `hour-of-day`: `[""!="", [""field"", 1, {""temporal-unit"": ""hour-of-day""}], 10]` // excludes 10AM
- `day-of-week`: `[""!="", [""field"", 1, {""temporal-unit"": ""day-of-week""}], ""2024-11-19""]` // excludes Tuesday because `2024-11-19` is Tuesday
- `month-of-year`: `[""!="", [""field"", 1, {""temporal-unit"": ""month-of-year""}], ""2024-11-19""]` // excludes November
- `quarter-of-year`: `[""!="", [""field"", 1, {""temporal-unit"": ""quarter-of-year""}], ""2024-11-19""]` // excludes Q4

We can achieve the same using expressions:
- `hour-of-day`: `[""!="", [""get-hour"", [""field"", 1, null]], 10]` // excludes 10AM
- `day-of-week`: `[""!="", [""get-iso-day-of-week"", [""field"", 1, null]], 2]` // excludes Tuesday
- `month-of-year`: `[""!="", [""get-month"", [""field"", 1, null]], 11]` // excludes November
- `quarter-of-year`: `[""!="", [""get-quarter"", [""field"", 1, null]], 3]` // excludes Q3

Note that I used a non-existing `get-iso-day-of-week` instead of `get-day-of-week` because I don't want these filters to break when someone changes the `start-of-week` setting. `get-iso-day-of-week`  should return 1-7, where 1 is Monday, 7 is Sunday.

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/50424
- [ ] https://github.com/metabase/metabase/issues/50574
- [ ] https://github.com/metabase/metabase/issues/50670
- [ ] https://github.com/metabase/metabase/pull/50752
- [ ] https://github.com/metabase/metabase/pull/50765
- [ ] https://github.com/metabase/metabase/pull/50888
- [ ] https://github.com/metabase/metabase/pull/50953
- [ ] https://github.com/metabase/metabase/pull/50957
- [ ] https://github.com/metabase/metabase/issues/50920
- [ ] https://github.com/metabase/metabase/issues/50958
```
",ranquild,2024-11-19 20:03:32+00:00,"['ranquild', 'metamben']",2024-12-12 23:58:20+00:00,2024-12-12 23:58:19+00:00,https://github.com/metabase/metabase/issues/50238,"[('Type:Tech Debt', 'or Refactoring'), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2673236110,issue,open,,"In Snowflake, use more specific filtering functions `Contains`, `Not contains`, `Start with`, and `End with` instead of `LIKE` to support Collations","Snowflake support [Collations](https://docs.snowflake.com/en/sql-reference/collation#label-collation-specification)

These are applied to string comparisons, but not all clauses support them. `LIKE` supports [only a few Collations](https://docs.snowflake.com/en/sql-reference/functions/like#collation-details).

If we use `CONTAINS`, `NOT CONTAINS`, `STARTWITH`, and `ENDWITH` instead of `LIKE`, we would support more Collation specifications.

https://docs.snowflake.com/en/sql-reference/functions/contains
https://docs.snowflake.com/en/sql-reference/functions/startswith
https://docs.snowflake.com/en/sql-reference/functions/endswith
",luizarakaki,2024-11-19 19:09:59+00:00,[],2025-02-04 20:30:36+00:00,,https://github.com/metabase/metabase/issues/50233,"[('Type:New Feature', ''), ('Database/Snowflake', ''), ('.Team/Drivers', '')]",[],
2673126574,issue,closed,not_planned,NLP2SQL in bigquery,is possible have question in NLP to SQL using bigquery connector?,johnfelipe,2024-11-19 18:38:55+00:00,[],2024-11-20 01:08:24+00:00,2024-11-20 00:14:40+00:00,https://github.com/metabase/metabase/issues/50231,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2487025589, 'issue_id': 2673126574, 'author': 'paoliniluis', 'body': 'What???', 'created_at': datetime.datetime(2024, 11, 20, 0, 14, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487055741, 'issue_id': 2673126574, 'author': 'johnfelipe', 'body': 'A chatbot like blazesql or abacus\r\nNatural language to SQL\r\nThat is not in roadmap?\r\n\r\nEl mar, 19 nov 2024, 7:15\u202fp. m., Luis Paolini ***@***.***>\r\nescribió:\r\n\r\n> What???\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/50231#issuecomment-2487025589>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AADIWFFP3ACVZZEWG6J7K332BPIAPAVCNFSM6AAAAABSCZI6SOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDIOBXGAZDKNJYHE>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 11, 20, 0, 41, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487093723, 'issue_id': 2673126574, 'author': 'paoliniluis', 'body': 'Please ask questions in the forums. All our roadmap is public', 'created_at': datetime.datetime(2024, 11, 20, 1, 8, 22, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-20 00:14:40 UTC): What???

johnfelipe (Issue Creator) on (2024-11-20 00:41:59 UTC): A chatbot like blazesql or abacus
Natural language to SQL
That is not in roadmap?

El mar, 19 nov 2024, 7:15 p. m., Luis Paolini ***@***.***>
escribió:

paoliniluis on (2024-11-20 01:08:22 UTC): Please ask questions in the forums. All our roadmap is public

"
2673051491,issue,closed,completed,Static Embedding - hide_download_button hash parameter doesn't work,"### Describe the bug

Setting the value of the hide_download_button hash parameter TRUE doesn't disable downloads for static embeds.

https://www.metabase.com/docs/v0.50/embedding/static-embedding-parameters#customizing-the-appearance-of-a-static-embed

### To Reproduce

1. Set up v50
2. Enable static embedding
3. For one of the dashboards add the hash parameter to hide download button like so:

MetabaseURL.com/JWTjwtJWT#hide_download_button=true

https://www.metabase.com/docs/v0.50/embedding/static-embedding-parameters#customizing-the-appearance-of-a-static-embed

### Expected behavior

The download button on the Questions should no longer be available when this has param is set to true.

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.30
```

### Severity

annoying

### Additional context

In version 51 the ""downloads"" has parameter works as expected.

https://www.metabase.com/docs/latest/embedding/static-embedding-parameters#customizing-the-appearance-of-a-static-embed",ixipixi,2024-11-19 17:58:00+00:00,[],2024-11-20 03:34:02+00:00,2024-11-20 03:32:21+00:00,https://github.com/metabase/metabase/issues/50227,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2487278708, 'issue_id': 2673051491, 'author': 'ixipixi', 'body': 'I misunderstood expected behavior here. This flag only removes the download options for embedded questions. Question on embedded dashboards will still have the download option. V51 does contain controls for removing download functionality from embedded dashboards.', 'created_at': datetime.datetime(2024, 11, 20, 3, 34, 1, tzinfo=datetime.timezone.utc)}]","ixipixi (Issue Creator) on (2024-11-20 03:34:01 UTC): I misunderstood expected behavior here. This flag only removes the download options for embedded questions. Question on embedded dashboards will still have the download option. V51 does contain controls for removing download functionality from embedded dashboards.

"
2672883017,issue,closed,completed,Sync views and materialized views,"We don't have good test coverage on view sync and we are not sure if we are syncing views on most databases.

- [x] Postgres: views
- [x] Postrgres: materialized views
- [x] MySQL: views
- [x] Redshift: views
- [x] Redshift: materialized views
- [x] BigQuery: views
- [x] BigQuery: materialized views
- [ ] Snowflake: views
- [x] SQL Server: views
- [x] Mongo: views
- [x] Athena: views
- [x] Databricks: views
- [x] Databricks: materialized views
- [x] Spark SQL: views
- [x] SQLite: views

to do later
- [x] Oracle: views
- [ ] H2: views
- [ ] H2: materialized views
- [ ] Snowflake: materialized views (enterprise feature)
- [ ] Oracle: materialized views
- [ ] Vertica: views",luizarakaki,2024-11-19 16:59:21+00:00,[],2024-12-10 19:52:54+00:00,2024-12-04 19:43:26+00:00,https://github.com/metabase/metabase/issues/50223,"[('Type:Bug', 'Product defects'), ('Database/', ''), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/Drivers', '')]",[],
2672555000,issue,open,,Dropdown Filter Displays Only the First Selected Item When Multiple Items Are Chosen,"### Describe the bug

After upgrading to v0.51, we encountered a regression affecting dropdown filters. 
When multiple items are selected, the filter only displays the first selected item instead of the expected label ‘X items.’ This behavior is confusing for users and impacts clarity in filter selection.![Image](https://github.com/user-attachments/assets/87a16df8-f34d-4f8e-a1de-c3b260317862)


### To Reproduce

1.	Navigate to a report with a dropdown filter.
2.	Select multiple items in the filter.
3.	Observe that only the first selected item is displayed instead of the expected label.

Note : This issue does not affect all dropdown filters; some are functioning as expected.

### Expected behavior

The filter should display “X items,” where X is the total number of selected items, to clearly indicate the number of selections.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""snowflake"",
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-12"",
      ""tag"": ""v0.51.3.2"",
      ""hash"": ""c6378ef""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Debian 16.2-1.pgdg110+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-36-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

blocking some users

### Additional context

_No response_",tcourtainsellsy,2024-11-19 15:24:44+00:00,[],2025-02-04 20:31:27+00:00,,https://github.com/metabase/metabase/issues/50217,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2672528090,issue,closed,not_planned,Question isn't showing join in notebook editor,"### Describe the bug

I have at least two older questions that start with a model that are joined to another model, and the joined model no longer appears in the notebook editor.  I have not made any changes to these questions in months.  I can see the join in the SQL editor, so the join is ""there"" - it's just not visible.

Example:  https://stats.metabase.com/question/13128-tickets-created-prior-month/notebook
Another example:  https://stats.metabase.com/question/19872-new-success-tickets-by-week-by-source

![Image](https://github.com/user-attachments/assets/979683a6-378c-4617-a2ff-dd7cc3ddabc2)

This makes editing the question almost impossible.  If I wanted to change this to a table and edit  the columns, I have to recreate the question from scratch.

### To Reproduce

I haven't been able to reproduce it 

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome
Built on 2024-11-19

Hash: 55ebe0b
```

### Severity

Very bad

### Additional context

_No response_",cbalusek,2024-11-19 15:14:37+00:00,['ranquild'],2024-11-22 20:54:28+00:00,2024-11-22 20:54:27+00:00,https://github.com/metabase/metabase/issues/50216,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2494783267, 'issue_id': 2672528090, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/45041', 'created_at': datetime.datetime(2024, 11, 22, 20, 54, 27, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-11-22 20:54:27 UTC): Duplicate of https://github.com/metabase/metabase/issues/45041

"
2672446612,issue,open,,I/O error during migration does not cleanly abort migration,"### Describe the bug

A fresh instance on v1.51.2-X01 encountered ""org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend."" on its first start. On subsequent starts it would fail with ""Database has migration lock; cannot run migrations.""

### To Reproduce

I did not reproduce it, but expect the following to show the issue:

1. Start Metabase v51.2
2. While it is running migrations, induce network errors, causing a migration to fail
3. Wait for Metabase to shut down
4. Start it again
5. Observe startup failure and ""Database has migration lock; cannot run migrations.""

### Expected behavior

Upon encountering I/O errors during migrations, either:
* Retry migration
* Release migration lock, so that the next start will be able to successfully apply them

### Logs

First exception:
```
liquibase.exception.DatabaseException: An I/O error occurred while sending to the backend. [Failed SQL: (0) ALTER TABLE query_action ADD CONSTRAINT pk_query_action PRIMARY KEY (action_id)]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__45488.invoke(liquibase.clj:371)
	at metabase.db.liquibase$run_in_scope_locked$reify__45484.run(liquibase.clj:336)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:329)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:312)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:360)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:353)
	at metabase.db.setup$migrate_BANG_55501__55502$fn__55503.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase45418__45419$f_STAR___45420.invoke(liquibase.clj:135)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invokeStatic(liquibase.clj:138)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invoke(liquibase.clj:126)
	at metabase.db.setup$migrate_BANG_55501__55502.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_55501__55502.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:428)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539$fn__55540.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:238)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:224)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_55535__55536.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_55535__55536.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__55564.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:424)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:121)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:102)
	at metabase.core$init_BANG_.invokeStatic(core.clj:181)
	at metabase.core$init_BANG_.invoke(core.clj:176)
	at metabase.core$start_normally.invokeStatic(core.clj:193)
	at metabase.core$start_normally.invoke(core.clj:187)
	at metabase.core$entrypoint.invokeStatic(core.clj:226)
	at metabase.core$entrypoint.doInvoke(core.clj:220)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at clojure.lang.Var.applyTo(Var.java:707)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend.
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:398)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
Caused by: java.io.EOFException
	at org.postgresql.core.PGStream.receiveChar(PGStream.java:469)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2166)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	... 94 more
```

Then, on the same run:
```
liquibase.exception.LockException: liquibase.exception.DatabaseException: org.postgresql.util.PSQLException: This connection has been closed.
	at liquibase.lockservice.StandardLockService.releaseLock(StandardLockService.java:407)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:139)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__45488.invoke(liquibase.clj:371)
	at metabase.db.liquibase$run_in_scope_locked$reify__45484.run(liquibase.clj:336)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:329)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:312)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:360)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:353)
	at metabase.db.setup$migrate_BANG_55501__55502$fn__55503.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase45418__45419$f_STAR___45420.invoke(liquibase.clj:135)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invokeStatic(liquibase.clj:138)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invoke(liquibase.clj:126)
	at metabase.db.setup$migrate_BANG_55501__55502.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_55501__55502.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:428)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539$fn__55540.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:238)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:224)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_55535__55536.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_55535__55536.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__55564.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:424)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:121)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:102)
	at metabase.core$init_BANG_.invokeStatic(core.clj:181)
	at metabase.core$init_BANG_.invoke(core.clj:176)
	at metabase.core$start_normally.invokeStatic(core.clj:193)
	at metabase.core$start_normally.invoke(core.clj:187)
	at metabase.core$entrypoint.invokeStatic(core.clj:226)
	at metabase.core$entrypoint.doInvoke(core.clj:220)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at clojure.lang.Var.applyTo(Var.java:707)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.DatabaseException: org.postgresql.util.PSQLException: This connection has been closed.
	at liquibase.database.jvm.JdbcConnection.rollback(JdbcConnection.java:464)
	at liquibase.database.AbstractJdbcDatabase.rollback(AbstractJdbcDatabase.java:1203)
	at liquibase.database.core.PostgresDatabase.rollback(PostgresDatabase.java:401)
	at liquibase.lockservice.StandardLockService.releaseLock(StandardLockService.java:370)
	... 61 more
Caused by: org.postgresql.util.PSQLException: This connection has been closed.
	at org.postgresql.jdbc.PgConnection.checkClosed(PgConnection.java:1009)
	at org.postgresql.jdbc.PgConnection.getAutoCommit(PgConnection.java:969)
	at com.mchange.v2.c3p0.impl.NewProxyConnection.getAutoCommit(NewProxyConnection.java:1227)
	at liquibase.database.jvm.JdbcConnection.rollback(JdbcConnection.java:460)
	... 64 more
```

On next start:
```
liquibase.exception.LockException: Database has migration lock; cannot run migrations. You can force-release these locks by running `java -jar metabase.jar migrate release-locks`.
	at metabase.db.liquibase$wait_for_migration_lock$fn__45449.invoke(liquibase.clj:233)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:174)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:181)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:181)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:181)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:181)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.util.jvm$do_with_auto_retries.invokeStatic(jvm.clj:181)
	at metabase.util.jvm$do_with_auto_retries.invoke(jvm.clj:164)
	at metabase.db.liquibase$wait_for_migration_lock.invokeStatic(liquibase.clj:227)
	at metabase.db.liquibase$wait_for_migration_lock.invoke(liquibase.clj:222)
	at metabase.db.liquibase$run_in_scope_locked$reify__45484.run(liquibase.clj:333)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:329)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:312)
	at metabase.db.liquibase$consolidate_liquibase_changesets_BANG_45562__45563.invokeStatic(liquibase.clj:464)
	at metabase.db.liquibase$consolidate_liquibase_changesets_BANG_45562__45563.invoke(liquibase.clj:443)
	at metabase.db.setup$migrate_BANG_55501__55502$fn__55503.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase45418__45419$f_STAR___45420.invoke(liquibase.clj:135)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invokeStatic(liquibase.clj:138)
	at metabase.db.liquibase$do_with_liquibase45418__45419.invoke(liquibase.clj:126)
	at metabase.db.setup$migrate_BANG_55501__55502.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_55501__55502.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:428)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_55528__55529.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539$fn__55540.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:238)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:224)
	at metabase.db.setup$setup_db_BANG_55535__55536$fn__55539.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_55535__55536.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_55535__55536.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__55564.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:424)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:121)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:102)
	at metabase.core$init_BANG_.invokeStatic(core.clj:181)
	at metabase.core$init_BANG_.invoke(core.clj:176)
	at metabase.core$start_normally.invokeStatic(core.clj:193)
	at metabase.core$start_normally.invoke(core.clj:187)
	at metabase.core$entrypoint.invokeStatic(core.clj:226)
	at metabase.core$entrypoint.doInvoke(core.clj:220)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at clojure.lang.Var.applyTo(Var.java:707)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:400)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:135)
	at metabase.bootstrap.main(Unknown Source)
```

### Information about your Metabase installation

```JSON
Metabase v1.51.2 on Linux
```

### Severity

can cause downtime, but easy workaround

### Additional context

https://metaboat.slack.com/archives/C013VC33N95/p1732025675282919

Similar to: https://github.com/metabase/metabase/issues/37866

Different issue, not the problem I ran into, but similar cause: https://github.com/metabase/metabase/issues/30360",devurandom,2024-11-19 14:45:11+00:00,['filipesilva'],2025-02-06 00:04:35+00:00,,https://github.com/metabase/metabase/issues/50212,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2485966930, 'issue_id': 2672446612, 'author': 'crisptrutski', 'body': ""I'm nervous about automatically releasing the locks - we don't know what's currently running on the database, and we don't want to risk corrupting it."", 'created_at': datetime.datetime(2024, 11, 19, 15, 4, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515533584, 'issue_id': 2672446612, 'author': 'nvoxland', 'body': ""Yes, just automatically releasing the lock can be dangerous -- there are migrations that sometimes just take a while and you don't want to assume that just because it's been locked for a while doesn't mean it's stuck. It can just be busy working.\n\nThe standard Liquibase lock manager is designed to work in the generic case in a consistent way across all database types, where the database is the only thing shared is the database and it has to work consistently across all the database types liquibase could possibly work with as well as try to work with update-sql mode. So it's purposefully simple, but also pluggable to allow replacements.\n\nFor us, we only have to find something that works well with our particular setup. If we had an existing inter-process communication system like zookeeper or raft or something we could rely on that instead of the database as the communication system that would help, but we don't have that.\n\nWith our more limited application-database supported databases, however, we could take advantage of built-in database support for better locks. Postgresql has `pg_advisory_lock` and Mysql/Mariadb has `GET_LOCK` which I think is what we'd be looking for to grab an exclusive lock and automatically release it if the connection is closed. That allows us to rely on the database to automatically clean-up the lock if something goes wrong and we'd never be in a stuck spot.\n\nH2 doesn't have a similar feature, but a custom lock service extension can just fall back to the standard version for h2."", 'created_at': datetime.datetime(2024, 12, 3, 20, 55, 45, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-11-19 15:04:11 UTC): I'm nervous about automatically releasing the locks - we don't know what's currently running on the database, and we don't want to risk corrupting it.

nvoxland on (2024-12-03 20:55:45 UTC): Yes, just automatically releasing the lock can be dangerous -- there are migrations that sometimes just take a while and you don't want to assume that just because it's been locked for a while doesn't mean it's stuck. It can just be busy working.

The standard Liquibase lock manager is designed to work in the generic case in a consistent way across all database types, where the database is the only thing shared is the database and it has to work consistently across all the database types liquibase could possibly work with as well as try to work with update-sql mode. So it's purposefully simple, but also pluggable to allow replacements.

For us, we only have to find something that works well with our particular setup. If we had an existing inter-process communication system like zookeeper or raft or something we could rely on that instead of the database as the communication system that would help, but we don't have that.

With our more limited application-database supported databases, however, we could take advantage of built-in database support for better locks. Postgresql has `pg_advisory_lock` and Mysql/Mariadb has `GET_LOCK` which I think is what we'd be looking for to grab an exclusive lock and automatically release it if the connection is closed. That allows us to rely on the database to automatically clean-up the lock if something goes wrong and we'd never be in a stuck spot.

H2 doesn't have a similar feature, but a custom lock service extension can just fall back to the standard version for h2.

"
2672315550,issue,open,,Column custom title,"**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
Once I rename a colum title I can't see the original name anymore. I need to delete my custom title so it's remplaced by the original name, but then I have to remember to put my custom title back on

**Describe the solution you'd like**
A clear and concise description of what you want to happen.
If I could in see the original fiel name like when I hover the colum title I'd be good enought for control purposes

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.
Removing the custom title to control what's under there then put it back on

**How important is this feature to you?**
When working on my own questions it's not usually needed but as we are using Metabase more and more the situation where one would use a question made by someone else happen more and more

**Additional context**
Add any other context or screenshots about the feature request here.
",Product-lita,2024-11-19 14:11:52+00:00,[],2025-02-04 20:30:54+00:00,,https://github.com/metabase/metabase/issues/50209,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2569149676, 'issue_id': 2672315550, 'author': 'brunobergher', 'body': '@Product-lita when you said ""original name"", do you mean the name in the database itself? And is your desire to be able to see it when in the visual query builder?', 'created_at': datetime.datetime(2025, 1, 3, 12, 27, 43, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 12:27:43 UTC): @Product-lita when you said ""original name"", do you mean the name in the database itself? And is your desire to be able to see it when in the visual query builder?

"
2672304164,issue,closed,completed,Re-ordering of Pivot Column Row section breaks download,"### Describe the bug

Not sure if it's even related to Re-ordering of Pivot Column Rows. But that's how i am able to hit this issue on downloads

### To Reproduce

1. Go to New Question ->  Orders -> Build this question:

![Image](https://github.com/user-attachments/assets/3551c900-94b0-4855-adcb-8d7b5d9e4cf2)

2. Set visualization as a Pivot -> with the following settings -> Try to download and it downloads without any issues

![Image](https://github.com/user-attachments/assets/1e7e4c51-0616-45ca-b8e7-2a4dbeaf50a5)

3. Now swap the Created At: Month with the User ID and try to Download

![Image](https://github.com/user-attachments/assets/a7ee47ad-9df9-44e3-99bd-9cec95509e3c)

4. It will fail for the Keep Data Pivoted Option 

![Image](https://github.com/user-attachments/assets/212e3fa3-ca63-4d56-a4bb-c20ccae50540)



### Expected behavior

The download works

### Logs

```
{:database_id 1,
 :started_at #t ""2024-11-19T15:01:05.577034+01:00[Europe/Malta]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error reducing result rows"",
   :stacktrace
   [""--> query_processor.pivot$append_queries_reduce_fn85538__85539$multiple_reducing__85541$respond__85543.invoke(pivot.clj:313)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__87276.invoke(execute.clj:725)""
    ""driver.h2$fn__90052$fn__90054.invoke(h2.clj:543)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection87050__87051.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection87050__87051.invoke(execute.clj:321)""
    ""driver.h2$fn__90052.invokeStatic(h2.clj:534)""
    ""driver.h2$fn__90052.invoke(h2.clj:530)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__113467.invokeStatic(sql_jdbc.clj:79)""
    ""driver.sql_jdbc$fn__113467.invoke(sql_jdbc.clj:77)""
    ""driver.h2$fn__89891.invokeStatic(h2.clj:271)""
    ""driver.h2$fn__89891.invoke(h2.clj:267)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:52)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:39)""
    ""query_processor.pivot$append_queries_reduce_fn85538__85539$multiple_reducing__85541$fn__85547.invoke(pivot.clj:324)""
    ""query_processor.pivot$append_queries_reduce_fn85538__85539$multiple_reducing__85541.invoke(pivot.clj:320)""
    ""query_processor.pipeline$_STAR_run_STAR_$respond__58968.invoke(pipeline.clj:100)""
    ""query_processor.pivot$append_queries_execute_fn85533__85534$multiple_execute__85535.invoke(pivot.clj:291)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:102)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:95)""
    ""query_processor.execute$run.invokeStatic(execute.clj:62)""
    ""query_processor.execute$run.invoke(execute.clj:56)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_76938__76939$fn__76940.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__76955.invoke(execute.clj:25)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__76961.invoke(execute.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___76911.invoke(cache.clj:241)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__73948.invoke(permissions.clj:148)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74659.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74669.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute76988__76989$fn__76990.invoke(execute.clj:94)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invoke(setup.clj:216)""
    ""query_processor.execute$execute76988__76989.invokeStatic(execute.clj:93)""
    ""query_processor.execute$execute76988__76989.invoke(execute.clj:89)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
    ""query_processor.middleware.enterprise$fn__74686$handle_audit_app_internal_queries__74687$fn__74689.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74697.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware77844__77845$fn__77846.invoke(process_userland_query.clj:204)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions77909__77910$fn__77911.invoke(catch_exceptions.clj:132)""
    ""query_processor$process_query77950__77951$fn__77952.invoke(query_processor.clj:80)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invoke(setup.clj:216)""
    ""query_processor$process_query77950__77951.invokeStatic(query_processor.clj:78)""
    ""query_processor$process_query77950__77951.invoke(query_processor.clj:71)""
    ""query_processor.pivot$process_multiple_queries85554__85556.invokeStatic(pivot.clj:350)""
    ""query_processor.pivot$process_multiple_queries85554__85556.invoke(pivot.clj:340)""
    ""query_processor.pivot$run_pivot_query85642__85643$fn__85644.invoke(pivot.clj:605)""
    ""query_processor.setup$do_with_canceled_chan75179__75180$fn__75181.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings75172__75173$fn__75174.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver75165__75166$fn__75167$fn__75168.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:106)""
    ""driver$do_with_driver.invoke(driver.clj:101)""
    ""query_processor.setup$do_with_driver75165__75166$fn__75167.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider75156__75157$fn__75158$fn__75161.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider58679__58680.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider58679__58680.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider58679__58680.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider58679__58680.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider75156__75157$fn__75158.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database75146__75147$fn__75148.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup75184__75185.invoke(setup.clj:216)""
    ""query_processor.pivot$run_pivot_query85642__85643.invokeStatic(pivot.clj:595)""
    ""query_processor.pivot$run_pivot_query85642__85643.invoke(pivot.clj:585)""
    ""query_processor.card$process_query_for_card_default_run_fn$fn__87527$fn__87528.invoke(card.clj:193)""
    ""query_processor.streaming$_streaming_response$fn__61522$fn__61523$fn__61524.invoke(streaming.clj:175)""
    ""query_processor.streaming$_streaming_response$fn__61522$fn__61523.invoke(streaming.clj:173)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:164)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:151)""
    ""query_processor.streaming$_streaming_response$fn__61522.invoke(streaming.clj:170)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__53163.invoke(streaming_response.clj:97)""],
   :error_type :qp,
   :ex-data {:type :qp}}],
 :action_id nil,
 :error_type :qp,
 :json_query
 {:lib/type :mbql/query,
  :qp.pivot/breakout-combination [0 1 2],
  :lib/metadata
  (metabase.lib.metadata.invocation-tracker/invocation-tracker-provider (metabase.lib.metadata.cached-provider/cached-metadata-provider (metabase.lib.metadata.jvm/->UncachedApplicationDatabaseMetadataProvider 1))),
  :stages
  [{:lib/type :mbql.stage/mbql,
    :source-table 5,
    :aggregation [[:count {:lib/uuid ""bdbf67a9-5bc3-42b4-86ba-dc44ab3eeadc""}]],
    :breakout
    [[:field
      {:base-type :type/DateTime,
       :temporal-unit :month,
       :lib/uuid ""182f9c30-61cb-4c66-b9ee-1629d3cdcb2f"",
       :effective-type :type/DateTime}
      41]
     [:field
      {:base-type :type/Integer, :lib/uuid ""fde57920-07a8-4379-a102-ff0f0e7f1b90"", :effective-type :type/Integer}
      43]
     [:field
      {:base-type :type/Integer, :lib/uuid ""44187507-3ea1-4d9c-adc1-aa7fc2e6706d"", :effective-type :type/Integer}
      40]
     [:expression
      {:lib/uuid ""45314b74-4cd2-41e7-afb6-f4f7910ea936"", :base-type :type/Integer, :effective-type :type/Integer}
      ""pivot-grouping""]],
    :expressions [[:abs {:lib/uuid ""3b0e2092-2600-474f-8711-e53f79bec43b"", :lib/expression-name ""pivot-grouping""} 0]]}],
  :middleware
  {:process-viz-settings? true,
   :userland-query? true,
   :format-rows? true,
   :ignore-cached-results? true,
   :pivot-options {:pivot-rows [0 1], :pivot-cols [2], :pivot-measures [3], :column-sort-order {}},
   :pivot? true,
   :js-int-to-string? false,
   :add-default-userland-constraints? true,
   :skip-results-metadata? true},
  :viz-settings
  {:pivot_table.column_split {:rows [""CREATED_AT"" ""USER_ID""], :columns [""PRODUCT_ID""], :values [""count""]},
   :pivot_table.column_widths {:leftHeaderWidths [141 81], :totalLeftHeaderWidths 222, :valueHeaderWidths {}}},
  :lib.convert/converted? true,
  :database 1},
 :status :failed,
 :class java.lang.ClassCastException,
 :stacktrace [nil],
 :card_id 112,
 :context :csv-download,
 :error nil,
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

```JSON
Running metabase 1.51.4
```

### Severity

Breaks downloads

### Additional context

_No response_",Tony-metabase,2024-11-19 14:07:12+00:00,['adam-james-v'],2024-11-26 22:18:18+00:00,2024-11-26 19:54:52+00:00,https://github.com/metabase/metabase/issues/50207,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2498019348, 'issue_id': 2672304164, 'author': 'Sidhantp12', 'body': '![Image](https://github.com/user-attachments/assets/7891af70-580e-4d89-8c7c-6e4c333ba997)\nWanted to add this topic here, or should i create a new issue?... \n\nThe issue seems to be related to the multiplication factor applied to the measure (e.g., kg multiplied by 1000) in Metabase. Here\'s a breakdown of the bug:\n\nBug Description:\nWhen the ""Multiply"" field is set to 1000 for a measure (e.g., kg), it adjusts the displayed values in the table correctly within Metabase.\nHowever, when exporting the data with the ""Keep data pivoted"" option enabled, the downloaded Excel file contains corrupted or incorrect data. This might happen due to the multiplication being applied inconsistently during the export process.\n\nLet me know, If I need to create a new ISSUE', 'created_at': datetime.datetime(2024, 11, 25, 13, 25, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498625105, 'issue_id': 2672304164, 'author': 'escherize', 'body': 'Hi, [Sidhantp12](https://github.com/Sidhantp12) I posted this as a new issue [here](https://github.com/metabase/metabase/issues/50462).', 'created_at': datetime.datetime(2024, 11, 25, 17, 29, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502045923, 'issue_id': 2672304164, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2024, 11, 26, 22, 18, 18, tzinfo=datetime.timezone.utc)}]","Sidhantp12 on (2024-11-25 13:25:46 UTC): ![Image](https://github.com/user-attachments/assets/7891af70-580e-4d89-8c7c-6e4c333ba997)
Wanted to add this topic here, or should i create a new issue?... 

The issue seems to be related to the multiplication factor applied to the measure (e.g., kg multiplied by 1000) in Metabase. Here's a breakdown of the bug:

Bug Description:
When the ""Multiply"" field is set to 1000 for a measure (e.g., kg), it adjusts the displayed values in the table correctly within Metabase.
However, when exporting the data with the ""Keep data pivoted"" option enabled, the downloaded Excel file contains corrupted or incorrect data. This might happen due to the multiplication being applied inconsistently during the export process.

Let me know, If I need to create a new ISSUE

escherize on (2024-11-25 17:29:01 UTC): Hi, [Sidhantp12](https://github.com/Sidhantp12) I posted this as a new issue [here](https://github.com/metabase/metabase/issues/50462).

github-actions[bot] on (2024-11-26 22:18:18 UTC): 🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)

"
2672262362,issue,open,,Search Index polish,"- [x] Fix up namespace hierarchy and remove ns-module-checker overrides
- [x] Remove test dependency on hybrid strategy, and delete it
- [x] Make personalized ranking configurable
- [ ] Namespace docs + better docstrings
- [ ] Clean up ranking config to live with the rest of the specifications
- [ ] Generalize primary versus secondary search terms
- [ ] Make :models and :personal-collection filters first class
- [ ] Make dictionary configurable
- [ ] Tests for queue thread safety",crisptrutski,2024-11-19 13:51:14+00:00,['crisptrutski'],2024-12-06 10:05:51+00:00,,https://github.com/metabase/metabase/issues/50206,[],[],
2672262031,issue,open,,Search Index optimizations,"Various ideas for speeding up the query performance

- [ ] Pre-calculate collection which (if any) personal collection each item is nested within.
- [ ] Pre-calculate collection display parameters, e.g. effective location
- [ ] Pre-render as much of the details as possible
- [ ] Remove unused cruft from JSON in the index
- [ ] Improve indexes on the table",crisptrutski,2024-11-19 13:51:07+00:00,[],2025-02-04 20:27:23+00:00,,https://github.com/metabase/metabase/issues/50205,"[('Organization/Search', '')]",[],
2672256144,issue,open,,Search Index kept up-to-date,"```[tasklist]
### Tasks
- [x] Fix tests in CI
- [x] Don't blow away the index for restarts (i.e. schema hasn't changed)
- [ ] Enable for indexed-entity (requires Toucan2 fix)
- [ ] Find another solution than using an after-update hook (e.g. decorating toucan2/update!)
- [ ] Test performance impact (not sure how best to do this, wide scope)
- [ ] Test capturing the cascading deletion flow
- [ ] Automatic data-flow for fields coming from sub-selects
- [ ] Backpressure so we can regulate the load we create on CPU/io
```
",crisptrutski,2024-11-19 13:48:59+00:00,['crisptrutski'],2024-12-05 15:02:33+00:00,,https://github.com/metabase/metabase/issues/50204,[],"[{'comment_id': 2485789567, 'issue_id': 2672256144, 'author': 'crisptrutski', 'body': 'Toucan2 related issues:\n\n1. Adding after-update hooks causes extra queries and updates to the database.\n  - Potentially work around is to use the before update instead, as we add a delay, and the update is idempotent.\n  - Discussed with @piranha and we think this is a good way to go, if we change the queue delay time to 2s.\n2. Adding after-update hooks can cause the return value of `update!` statements to change (from count to a vector)\n  - This one is a blocker for indexed-entity, and perhaps future search-models too.', 'created_at': datetime.datetime(2024, 11, 19, 13, 55, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487774215, 'issue_id': 2672256144, 'author': 'crisptrutski', 'body': 'Re: smarter bootstrapping\n\nIdea: have another metadata table with version number, schema checksum, last indexed.\n\nCan also make it point directly as `search_index_<uuid>` and use the metadata + atom to track it.', 'created_at': datetime.datetime(2024, 11, 20, 7, 48, 44, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-11-19 13:55:37 UTC): Toucan2 related issues:

1. Adding after-update hooks causes extra queries and updates to the database.
  - Potentially work around is to use the before update instead, as we add a delay, and the update is idempotent.
  - Discussed with @piranha and we think this is a good way to go, if we change the queue delay time to 2s.
2. Adding after-update hooks can cause the return value of `update!` statements to change (from count to a vector)
  - This one is a blocker for indexed-entity, and perhaps future search-models too.

crisptrutski (Issue Creator) on (2024-11-20 07:48:44 UTC): Re: smarter bootstrapping

Idea: have another metadata table with version number, schema checksum, last indexed.

Can also make it point directly as `search_index_<uuid>` and use the metadata + atom to track it.

"
2672246590,issue,open,,Ability to validate or modify questions via onBeforeSave in the sdk,"We have the `onBeforeSave` props in the SDK that is currently called right before a question is saved, mainly to show a loading indicator while the question is being saved.

We should extend on this API by allowing the user to provide custom validations, e.g. by returning `false` to prevent the question from being saved and showing a failed save state in the form.

```tsx
const shouldSave = await onBeforeSave(question, context)

if (!shouldSave) {
 // show a fail save state
}
```

We are currently exposing the Question object from metabase-lib to the public API though, so it might be good to wait until we get a simpler public-facing Question object, which would be more suitable for validation.

Alternatively, we could provide a way to modify the question itself, although this could be a little tricky if we are not using the MBQL object.",heypoom,2024-11-19 13:45:36+00:00,[],2025-02-04 20:25:57+00:00,,https://github.com/metabase/metabase/issues/50202,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2672022418,issue,closed,completed,Put `#locale` under `whitelabel` feature flag,Epic https://github.com/metabase/metabase/issues/50182,WiNloSt,2024-11-19 12:31:44+00:00,['WiNloSt'],2024-11-26 18:50:58+00:00,2024-11-21 08:52:12+00:00,https://github.com/metabase/metabase/issues/50199,[],[],
2672001531,issue,closed,not_planned,[Flaky Test] should resize iframe to dashboard content size (metabase#47061),"### Describe the bug

This [happened](https://app.trunk.io/metabase/flaky-tests/test/facb35f0-6d76-5e7d-b21c-40401bbc3ff6?repo=metabase%2Fmetabase) after we introduced the assertions for the P1 issue https://github.com/metabase/metabase/issues/49537.

It seems the hover state doesn't work reliably. And we should find a way to enable the assertion again.

### To Reproduce

Run the stress test

",WiNloSt,2024-11-19 12:22:44+00:00,[],2024-12-13 16:45:44+00:00,2024-12-13 16:45:44+00:00,https://github.com/metabase/metabase/issues/50197,"[('.Frontend', ''), ('flaky-test-fix', ''), ('.Team/Embedding', '')]",[],
2671984019,issue,closed,completed,Download Menu doesn't translate Formatting Options,"### Describe the bug

This is the menu in english:

![Image](https://github.com/user-attachments/assets/4ab5dafe-e6f1-4423-ac46-ffe2006ee607)

This is the menu in Japanese:

![Image](https://github.com/user-attachments/assets/31ad97ec-c2a4-416a-8ead-36e2a53bd52a)


### To Reproduce

Change the language to anything but English and go to the download section of the menu.

- ""formatted is not translated, while ""unformatted"" is translated
- ""Keep data pivoted"" is not translated

### Expected behavior

The Download Menu is properly Translated

### Logs

None that are relevant

### Information about your Metabase installation

```JSON
1.51.4
```

### Severity

This will make non english users confused

### Additional context

_No response_",Tony-metabase,2024-11-19 12:14:33+00:00,[],2025-01-13 14:20:55+00:00,2024-11-22 08:50:45+00:00,https://github.com/metabase/metabase/issues/50196,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2493217930, 'issue_id': 2671984019, 'author': 'Tony-metabase', 'body': 'Fixed with 1.51.4.3', 'created_at': datetime.datetime(2024, 11, 22, 8, 50, 45, tzinfo=datetime.timezone.utc)}]","Tony-metabase (Issue Creator) on (2024-11-22 08:50:45 UTC): Fixed with 1.51.4.3

"
2671920467,issue,open,,Model breaks after table modification and cannot be edited,"### Describe the bug

When a table used in a model is modified, the model breaks and becomes inaccessible for editing. The application only allows downloading a JSON file with the error, making it impossible to fix the model directly.

### To Reproduce

1. Enable model persistence.
2. Create a model using a table.
3. Modify the table (e.g., add/remove columns).
4. Try to edit the model.

### Expected behavior

Expected Behavior
The model should be editable to fix errors caused by table modifications.

Actual Behavior
The model becomes locked, and only a JSON error file can be downloaded.



### Logs

[metabase-diagnostic-info-2024-11-19T11_38_32.955Z.json](https://github.com/user-attachments/files/17814639/metabase-diagnostic-info-2024-11-19T11_38_32.955Z.json)


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.20""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-LTS"",
    ""java.vendor"": ""Red Hat, Inc."",
    ""java.vendor.url"": ""https://www.redhat.com/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""3.10.0-1160.114.2.el7.x86_64"",
    ""user.language"": ""es"",
    ""user.timezone"": ""Europe/Madrid""
  }
}
```

### Severity

High

### Additional context

_No response_",rodrigoGA,2024-11-19 11:48:41+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/50194,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2508293692, 'issue_id': 2671920467, 'author': 'metamben', 'body': ""@rodrigoGA, I couldn't reproduce the problem by adding a column to the table. Can you give more precise steps how to do that?\n\nRemoving a column breaks the model _if the field is used in the query_, but I don't think this is something new. Did that work for you in previous versions of Metabase?"", 'created_at': datetime.datetime(2024, 11, 29, 18, 33, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508619528, 'issue_id': 2671920467, 'author': 'rodrigoGA', 'body': '@metamben I’m new to working with models, so I’m not sure if this is a bug or the standard behavior of Metabase. Here’s the situation:\n\nI created a model based on tableX and set it as persistent (everything worked fine).\nA few days later, due to business needs, I modified tableX, adding some columns and removing others.\nI went into Metabase to add the new column required for the model referencing tableX. However, when I clicked on the model name, Metabase showed an error screen with the only option being to download the metabase-diagnostic-info-2024-11-19T11_38_32.955Z.json file, which I attached to the ticket.\n\nAll I wanted to do with the model was to delete a column and add another one, but it was impossible. There was no way to access the query that defines the model—it always showed the error screen. As a result, I lost the query. The only solution was to delete the model and recreate it.\n\nI’m not sure if this is the expected behavior, but I think it should allow you to access the editor to fix the model issue. In this case, it was a simple fix, but model queries can be complex, and losing them can be a big problem.', 'created_at': datetime.datetime(2024, 11, 29, 20, 30, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508690109, 'issue_id': 2671920467, 'author': 'metamben', 'body': ""@rodrigoGA, do I understand right that you don't have this problem unless model persistence is enabled?\n\nI cannot reproduce the issue: when I open the model, the query fails, but I can still edit the query definition.\n\n![Image](https://github.com/user-attachments/assets/bfd35ae9-1c7b-4060-abeb-e70437f7a072)"", 'created_at': datetime.datetime(2024, 11, 29, 21, 51, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514706515, 'issue_id': 2671920467, 'author': 'metamben', 'body': '@rodrigoGA, can you check if your problem is specific to persisted models? Can you give more information (logs, for example)? The expected behavior is (both for persisted and not persisted models) for the query to fail and produce the screen show in the screenshot above. There should be an option `Edit query definition` that lets you fix the query.', 'created_at': datetime.datetime(2024, 12, 3, 14, 22, 32, tzinfo=datetime.timezone.utc)}]","metamben on (2024-11-29 18:33:53 UTC): @rodrigoGA, I couldn't reproduce the problem by adding a column to the table. Can you give more precise steps how to do that?

Removing a column breaks the model _if the field is used in the query_, but I don't think this is something new. Did that work for you in previous versions of Metabase?

rodrigoGA (Issue Creator) on (2024-11-29 20:30:41 UTC): @metamben I’m new to working with models, so I’m not sure if this is a bug or the standard behavior of Metabase. Here’s the situation:

I created a model based on tableX and set it as persistent (everything worked fine).
A few days later, due to business needs, I modified tableX, adding some columns and removing others.
I went into Metabase to add the new column required for the model referencing tableX. However, when I clicked on the model name, Metabase showed an error screen with the only option being to download the metabase-diagnostic-info-2024-11-19T11_38_32.955Z.json file, which I attached to the ticket.

All I wanted to do with the model was to delete a column and add another one, but it was impossible. There was no way to access the query that defines the model—it always showed the error screen. As a result, I lost the query. The only solution was to delete the model and recreate it.

I’m not sure if this is the expected behavior, but I think it should allow you to access the editor to fix the model issue. In this case, it was a simple fix, but model queries can be complex, and losing them can be a big problem.

metamben on (2024-11-29 21:51:40 UTC): @rodrigoGA, do I understand right that you don't have this problem unless model persistence is enabled?

I cannot reproduce the issue: when I open the model, the query fails, but I can still edit the query definition.

![Image](https://github.com/user-attachments/assets/bfd35ae9-1c7b-4060-abeb-e70437f7a072)

metamben on (2024-12-03 14:22:32 UTC): @rodrigoGA, can you check if your problem is specific to persisted models? Can you give more information (logs, for example)? The expected behavior is (both for persisted and not persisted models) for the query to fail and produce the screen show in the screenshot above. There should be an option `Edit query definition` that lets you fix the query.

"
2671247734,issue,open,,Filter based on a data point in embedded dashboard,"**Is your feature request related to a problem? Please describe.**
I have to create a global filter in an embedded dashboard for every segmentation I want to do.

**Describe the solution you'd like**
Filter based on a data point in an embedded dashboard as well will allow me to don't create a lot of filters to analyze the data.

**Describe alternatives you've considered**

**How important is this feature to you?**
Good to have
",jatorna,2024-11-19 08:28:05+00:00,[],2025-02-04 20:31:04+00:00,,https://github.com/metabase/metabase/issues/50185,"[('Type:New Feature', '')]","[{'comment_id': 2569135879, 'issue_id': 2671247734, 'author': 'brunobergher', 'body': ""@jatorna I'm having some difficulty understanding your request. Mind expanding upon it or maybe sharing a couple examples?"", 'created_at': datetime.datetime(2025, 1, 3, 12, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571376256, 'issue_id': 2671247734, 'author': 'jatorna', 'body': '@brunobergher thanks for your answer.\n\nIt would be amazing if we could filter an embedded dashboard like the video attached.\n\nhttps://github.com/user-attachments/assets/f579f4f2-5986-461a-b814-c13cf348bf60', 'created_at': datetime.datetime(2025, 1, 4, 18, 27, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572891025, 'issue_id': 2671247734, 'author': 'brunobergher', 'body': ""I see. So to play it back: you'd like to be able to define the `filter by value` action in drill-down menus to map to a specific dashboard filter."", 'created_at': datetime.datetime(2025, 1, 6, 11, 11, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2579293083, 'issue_id': 2671247734, 'author': 'jatorna', 'body': ""Yes, basically.\nAnd what about a non-existent dashboard filter?\nFor example in qlik, you don't have to define all the global filters in your dashboard. They are there automatically and if you click in some column they create a new global filter applying it to all the data."", 'created_at': datetime.datetime(2025, 1, 9, 6, 49, 40, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 12:16:00 UTC): @jatorna I'm having some difficulty understanding your request. Mind expanding upon it or maybe sharing a couple examples?

jatorna (Issue Creator) on (2025-01-04 18:27:31 UTC): @brunobergher thanks for your answer.

It would be amazing if we could filter an embedded dashboard like the video attached.

https://github.com/user-attachments/assets/f579f4f2-5986-461a-b814-c13cf348bf60

brunobergher on (2025-01-06 11:11:21 UTC): I see. So to play it back: you'd like to be able to define the `filter by value` action in drill-down menus to map to a specific dashboard filter.

jatorna (Issue Creator) on (2025-01-09 06:49:40 UTC): Yes, basically.
And what about a non-existent dashboard filter?
For example in qlik, you don't have to define all the global filters in your dashboard. They are there automatically and if you click in some column they create a new global filter applying it to all the data.

"
2671243908,issue,closed,completed,Logarithmic scale fails to display negative numbers in Waterfall chart,"### Describe the bug

The logarithmic scale option in the waterfall chart no longer supports negative numbers. 
In older versions the chart handled negative values gracefully (mirroring the values of the positive value log).
This issue results in failure to render waterfall dynamics where negative values can be present.

### To Reproduce

1. Create a dataset containing both positive and negative numbers. [Imagine categorical cashflows]

> Category    Value  
> Income      1000  
> Expense     -500  
> Savings     300  
> Loss        -200  

2. Enable the logarithmic scale for the graph in Waterfall visualization settings.
3. Observe the error while rendering of the chart.


### Expected behavior

The chart should be capable of gracefully handling the negative values by mirroring the log if the value falls below zero. On the graph, the true data value is to be depicted when hovered over.

### Logs

Probably irrelevant


### Information about your Metabase installation

```JSON
- Metabase v0.51.2.3 (Docker)
- Safari Version 18.1 (20619.2.8.11.10), default configuration.
- macOS 15.1 (24B83)

The expected behavior can be experienced in Metabase v0.46.6.4 (Docker)
```

### Severity

blocking an upgrade

### Additional context

_No response_",rv-solomasov,2024-11-19 08:26:13+00:00,[],2025-01-30 22:14:08+00:00,2025-01-30 17:13:03+00:00,https://github.com/metabase/metabase/issues/50184,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2550888033, 'issue_id': 2671243908, 'author': 'pavelpolygalov', 'body': 'Please provide information about the plans to resolve this bug. We are unable to upgrade to the new version of Metabase because of it', 'created_at': datetime.datetime(2024, 12, 18, 9, 59, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625092035, 'issue_id': 2671243908, 'author': 'alxnddr', 'body': 'The bug appears to be fixed:\n<img width=""1914"" alt=""Image"" src=""https://github.com/user-attachments/assets/50ddfb20-7b49-4171-8102-0681e8c45ff4"" />\n\nPlease let us know if are you still experiencing the problem and we\'ll reopen the issue.', 'created_at': datetime.datetime(2025, 1, 30, 17, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625708598, 'issue_id': 2671243908, 'author': 'rv-solomasov', 'body': 'Thank you, will test in our environment asap!', 'created_at': datetime.datetime(2025, 1, 30, 22, 14, 7, tzinfo=datetime.timezone.utc)}]","pavelpolygalov on (2024-12-18 09:59:32 UTC): Please provide information about the plans to resolve this bug. We are unable to upgrade to the new version of Metabase because of it

alxnddr on (2025-01-30 17:13:03 UTC): The bug appears to be fixed:
<img width=""1914"" alt=""Image"" src=""https://github.com/user-attachments/assets/50ddfb20-7b49-4171-8102-0681e8c45ff4"" />

Please let us know if are you still experiencing the problem and we'll reopen the issue.

rv-solomasov (Issue Creator) on (2025-01-30 22:14:07 UTC): Thank you, will test in our environment asap!

"
2671159730,issue,closed,completed,[Epic] Support language localization in static embedding,"**Links**
- [product doc](https://www.notion.so/metabase/Support-language-localization-in-static-embedding-0307665e3008435d9bb2b3fff8148d7d)
- [Original issue](https://github.com/metabase/metabase/issues/8490)

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/49531
- [ ] https://github.com/metabase/metabase/issues/50199
- [ ] https://github.com/metabase/metabase/issues/50313
- [ ] Write E2E tests for result downloads using user date locale
- [ ] https://github.com/metabase/metabase/pull/51002
- [ ] https://github.com/metabase/metabase/pull/51456
```",WiNloSt,2024-11-19 07:49:34+00:00,[],2025-02-07 08:04:49+00:00,2025-02-07 08:04:49+00:00,https://github.com/metabase/metabase/issues/50182,"[('.Epic', 'Feature Implementation or Project')]",[],
2670481320,issue,open,,Custom columns in models will show in the column selector and the query,"### Describe the bug

There's some weird metadata problem on models that are inherited from models

### To Reproduce

1) create a model from the people table (model 1)
2) create a model based on model 1, removing 2 columns, e.g. email and latitude (model 2)
3) create a model based on model 2 (model 3)
4) now create 2 custom columns on model 1 (e.g. concat source and state and concat longitude and source)
5) go to model 2, see that the new custom columns are selected, but not shown
![Image](https://github.com/user-attachments/assets/30827990-77f7-4b4c-96f6-f1d275ca2d89)

### Expected behavior

We should reflect the columns that are selected in the editor

### Logs

NA

### Information about your Metabase installation

```JSON
-I could repro in v50.x, but might come from before
```

### Severity

P1ish

### Additional context

NA",paoliniluis,2024-11-19 01:56:48+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/50178,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2575401269, 'issue_id': 2670481320, 'author': 'thebiglabasky', 'body': ""Wouldn't the default behavior need to actually not show the new custom columns to downstream models?\nI agree that if selected these should be displayed, but I feel like the default behavior should be to hide new columns by default in model 2 and 3, no?"", 'created_at': datetime.datetime(2025, 1, 7, 14, 18, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577634026, 'issue_id': 2670481320, 'author': 'thebiglabasky', 'body': 'Also, highly related to #37314', 'created_at': datetime.datetime(2025, 1, 8, 13, 8, 51, tzinfo=datetime.timezone.utc)}]","thebiglabasky on (2025-01-07 14:18:05 UTC): Wouldn't the default behavior need to actually not show the new custom columns to downstream models?
I agree that if selected these should be displayed, but I feel like the default behavior should be to hide new columns by default in model 2 and 3, no?

thebiglabasky on (2025-01-08 13:08:51 UTC): Also, highly related to #37314

"
2670090823,issue,closed,completed,Questions in Dashboards - Milestone 3 - Polish - after the tool to bulk migrate questions into dashboards,"Follow-ups to be done after 52
```[tasklist]
### Milestone 3
- [ ] https://github.com/metabase/metabase/issues/51237
- [ ] [BE] Usage analytics should have all questions inside dashboards (Arakaki will work on this when the tool to migrate questions is done)
- [ ] [BE] Improve revision history copy, ""dashboard-internal"" in copy is weird (https://metaboat.slack.com/archives/C06RM2GEP5Z/p1736888437835159?thread_ts=1736888123.270439&cid=C06RM2GEP5Z
- [ ] [BE] X-raying a table should create dashboard questions instead of standalone questions
- [ ] [FE] Placeholder cards should allow creating a new question or selecting an existing question
- [ ] [FE] When creating a question in the dashboard edit mode, let the user pick the tab to save it
- [ ] [FE] Users should not be able to save to another dashboard when starting dashboard creation flow from a specific dashboard
- [ ] [FE] User analytics dashboard shouldn't show in the recents tab of collection picker (https://www.notion.so/metabase/It-might-be-unclear-to-the-user-why-Usage-analytics-dashboards-can-t-be-selected-15969354c9018091bc29c8ebb7286600?pvs=4)
- [x] [FE] Source breadcrumbs for dashboard questions based on modals looks bad (https://metaboat.slack.com/archives/C01LQQ2UW03/p1736883192626749
- [x] [FE] Notebook editor showing dashboard name should be a clickable link
- [x] [FE] Confirm move to new dashboard modal is missing `?` (https://metaboat.slack.com/archives/C06RM2GEP5Z/p1736885060785059)
- [x] [FE] Tentative: scroll to question position when adding it to the dashboard
- [x] [FE] Collection picker should allow creating a dashboard on the fly (https://www.figma.com/design/JIHSbaYBdXjkaNSivUG76T/Enable-saving-questions-directly-to-dashboards-and-make-this-the-default-path?node-id=1181-3599&node-type=frame&t=Ve7Mnl2UFiwn0LB4-11)
- [x] [FE] pressing escape twice does not close both the ""Select a collection or dashboard” and ""Save new question” modal (https://www.notion.so/metabase/P3-pressing-escape-twice-does-not-close-both-the-Select-a-collection-or-dashboard-and-Save-new-q-15969354c901807d8d3fe01274982bd3?pvs=4)
- [x] [FE] When duplicating a question, if the user edits the name, the name input field stays red although there isn't an error (https://www.loom.com/share/c589e607da574376b2230790fc376a21?sid=6da820d2-ea98-4cec-a818-6c388c9ef0de)
```",iethree,2024-11-18 22:22:36+00:00,['sloansparger'],2025-02-05 14:44:51+00:00,2025-02-05 14:44:51+00:00,https://github.com/metabase/metabase/issues/50176,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2670090451,issue,closed,not_planned,Questions in Dashboards - Milestone 3,"We are trying to get to milestone 3 for 52
```[tasklist]
### Milestone 3
- [ ] Migration tool (standalone questions to dashboards)
```",iethree,2024-11-18 22:22:20+00:00,[],2024-12-10 21:37:00+00:00,2024-12-10 21:36:02+00:00,https://github.com/metabase/metabase/issues/50175,[],"[{'comment_id': 2532940871, 'issue_id': 2670090451, 'author': 'iethree', 'body': 'this got reorged into another milestone', 'created_at': datetime.datetime(2024, 12, 10, 21, 36, 2, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-12-10 21:36:02 UTC): this got reorged into another milestone

"
2670089699,issue,closed,completed,Questions in Dashboards - Milestone 1.5,"```[tasklist]
### Milestone 2
- [x] Dashboard questions in search
- [x] Dashboard questions as source for QB questions
- [x] Moving dashboard questions
- [x] turn a standalone question into a DC
- [x] turn a DC into a standalone question
- [x] DCs findable in pickers
```",iethree,2024-11-18 22:22:03+00:00,['sloansparger'],2024-12-10 21:44:47+00:00,2024-12-10 21:34:08+00:00,https://github.com/metabase/metabase/issues/50174,[],"[{'comment_id': 2532937906, 'issue_id': 2670089699, 'author': 'iethree', 'body': 'hey cool we did this along with milestone 1!', 'created_at': datetime.datetime(2024, 12, 10, 21, 34, 8, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-12-10 21:34:08 UTC): hey cool we did this along with milestone 1!

"
2670089262,issue,closed,completed,Questions in Dashboards - Milestone 2 - Required,"note: milestone 2 is required for the minimum-shippable version of questions in dashobards

```[tasklist]
### Milestone 2
- [ ] https://github.com/metabase/metabase/issues/51169
- [x] Refine save-your-changes confirmation dialog (ask Maz) - Sloan working on this now...
- [x] FE: Try to de-duplicate dashboard GET requests (Sloan on it)
- [x] get rid of extra breadcrumb api requests now that dashboards are hydrated on cards (Sloan on it)
- [x] update restored card toast to link to containing dashboard instead of collection for dashboard cards
- [x] update legacy DataSelector to support questions saved in dashboards
- [x] Adjust initialDashboardId calculation
- [ ] https://github.com/metabase/metabase/issues/51346
- [x] ensure old-data picker can handle (embedding added it back) (Arakaki talk to Alberto) - nothing to resolve here
- [x] Update `useRootCollectionPickerItems` to account for passed in `models` (Nick on it)
```",iethree,2024-11-18 22:21:48+00:00,[],2025-01-15 19:26:07+00:00,2025-01-15 19:26:07+00:00,https://github.com/metabase/metabase/issues/50173,[],[],
2670088855,issue,closed,completed,Questions in Dashboards - Milestone 1,"```[tasklist]
### Milestone 1
- [x] Create dashboard questions
- [x] Update dashboard questions
- [x] Remove dashboard questions
- [x] Archiving dashboard / permanently deleting dashboards
- [x] Duplicating dashboards w/ dashboard questions
- [x] Dedicated dashboard question page
- [x] Exclude dashboard questions from stale items
- [x] Allow hiding OR showing dashboard questions in search
- [x] Update question picker to show dashboards + dashboard questions
- [x] Add e2e tests
- [x] BE - Integrate trash and revision history for dashboard questions
- [x] BE - autoplace cards on their dashboard when they're created, moved, etc.
- [x] BE: fix autoplace runtime error
- [x] BE: why are dashboard questions appearing in the trash while unarchived?
- [x] BE: duplicating a dashboard doubles its DQs
- [x] BE: autoplace cards on unarchive
- [x] BE: archived DQs still appear on their dashboards
- [x] BE: add context to ""invalid dashboard question"" errors
- [x] In the question sidesheet, Saved In should refer to the dashboard when it is saved there
- [x] Move standalone questions into dashboards
- [x] Bug: creating a new collection in the entity picker when a dashboard is selected looks like a collection in the dashboard
- [x] Resolve the ""add series"" feature - dont show series from cards in other dashboards
- [x] FE: fix e2e tests
- [x] FE: fix frontend type check
- [x] FE: fix frontend unit tests
- [x] Make sure the testing plan is satisfied
- [x] FE: fix state propagation in the query builder header
- [x] Add unit tests for collection breadcrumb changes
- [x] Save questions directly to a dashboard that is not in our analytics
- [x] have FE use the bulk cards in dashboard check
```
[Milestone 1 todo doc](https://www.notion.so/metabase/What-s-left-for-Cards-in-Dashboard-to-be-merge-ready-13469354c901801b8636dd466dff06e3) ",iethree,2024-11-18 22:21:32+00:00,"['johnswanson', 'iethree']",2025-01-27 22:13:45+00:00,2024-12-10 19:51:39+00:00,https://github.com/metabase/metabase/issues/50172,[],[],
2669163264,issue,open,,INVALID_ARGUMENT Name xx not found when chaining SQL questions,"**Describe the bug**
I think I am definitively missing something with the SQL Question Editor of Metabase.
I am always ending with errors like 
400 Bad Request POST https://bigquery.googleapis.com/bigquery/v2/projects/xxx-infra/queries { ""code"": 400, ""errors"": [ { ""domain"": ""global"", ""location"": ""q"", ""locationType"": ""parameter"", ""message"": ""Name XX not found inside source at [2:100]"", ""reason"": ""invalidQuery"" } ], ""message"": ""Name xxx not found inside source at [2:100]"", ""status"": ""INVALID_ARGUMENT"" }
when trying to set up ""simple"" use cases with the SQL Editor.

When trying to understand what does not work using the SQL Editor view, it seems that the issue relies in the Metabase engine that translates the Question into SQL, which seems quite strange 🤔 

Here is a ""simple"" example:
- I have a saved question named ""Customers using feedback v2 - trackers with feedback information"" that creates a custom column named has_feedback_received (based on an attribute named has_delivered_notification_opened)
- I am then trying to create a question from this saved question using a count_if(has_feedback_received)
- I get the error ""Name has_delivered_notification_opened not found inside source""

If I checked the SQL generated I realize that the issue is the SQL generated: instead of using count_if(has_feedback_received) it used count_if(has_delivered_notification_opened) which does not exists :thinking: 
![Image](https://github.com/user-attachments/assets/443ffd38-3729-4e49-96af-2429f4aaa365)

I think I am missing something ?
How can I fix this ?

**Logs**
No relevant logs in the console

**To Reproduce**
Steps to reproduce the behavior:
See the image

**Expected behavior**
I would expect to get my countif working without having an error.
To be more precise I would have expected the SQL to be translated as
SELECT
  DATETIME_TRUNC(`source`.`created_at`, week(monday)) AS `created_at`,
  SUM(
    CASE
      WHEN `source`.`**has_feedback_received**` = TRUE THEN 1
      ELSE 0.0
    END
  ) AS `trackers_with_feedback_received_count`
FROM
  (
    SELECT
      `intermediary.int_trackers_with_usage`.`tracker_id` AS `tracker_id`,
      `intermediary.int_trackers_with_usage`.`has_delivered_notification_opened` AS `has_feedback_received`,
....


**Severity**
How severe an issue is this bug to you? 
This is only an example out of many when trying to use the Metabase SQL Editor.
It is really annoying because I think there are a lot of benefits of using this Editor instead of Native SQL, but this issue is starting to make my users not want to use the Editor on Metabase and ask me to write everything in Native SQL, which is the opposite of Metabase philosophy

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-22"",
      ""tag"": ""v0.50.31.1"",
      ""hash"": ""d4b2302""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",Simonot,2024-11-18 16:46:33+00:00,[],2024-11-20 17:41:24+00:00,,https://github.com/metabase/metabase/issues/50160,[],"[{'comment_id': 2483835774, 'issue_id': 2669163264, 'author': 'paoliniluis', 'body': 'Can you move to 51.3 and test if this is there?', 'created_at': datetime.datetime(2024, 11, 18, 18, 41, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483837043, 'issue_id': 2669163264, 'author': 'paoliniluis', 'body': 'Or this is simply https://github.com/metabase/metabase/issues/37600', 'created_at': datetime.datetime(2024, 11, 18, 18, 41, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489046699, 'issue_id': 2669163264, 'author': 'Simonot', 'body': 'I will try updating to 51.4 and keep you posted.\nIt could be related to the issue mentioned indeed, because (even if for this one there are no spaces) I also have the issue with space ;)', 'created_at': datetime.datetime(2024, 11, 20, 16, 28, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489097772, 'issue_id': 2669163264, 'author': 'Simonot', 'body': 'Unfortunately, it does not fix the issue.\n\nI could build a more easy to reproduce set up but for me it is pretty clear that something is buggy in the Question to SQL (maybe only for BigQuery).\nHere is another example:\n![Image](https://github.com/user-attachments/assets/05063218-7da4-4c70-ab1d-5b37b6c02336)\n\nIt seems that the issue relies on the the aliasing. Indeed:\n- We have a first alias in our model ""Account using feedback v1"" to transform billing_orgnanization_id to cus_id\n- When trying to use this in my Question editor, for some reason:\n   - The table alias is correct (Accounts_using_feedback_v1___Company)\n   - BUT the attribute access is not the correct one (here we try to access billing_orgnanization_id that does not exist instead of cus_id)\n\nMaybe it is in the Custom Expression editor 🤔 (but from what I see it seems correct here (ie using cus_id)):\n![Image](https://github.com/user-attachments/assets/a3393f3f-164b-4fba-a378-ca5eafe390bb)\n\nDo you think I should create a more reproductible set up an open another issue ?', 'created_at': datetime.datetime(2024, 11, 20, 16, 50, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489142486, 'issue_id': 2669163264, 'author': 'Simonot', 'body': 'By digging a little bit, I feel the issue is related to the join and to chainning.\nIndeed ""Accounts using feedback v1"" is based on a Model that joins:\n- Accounts\n- Billing Organization\n(we can it in the image because you have `source.account_id` and `source.name` that belongs to Account and than `source.Billing_Organizations__xxx` that belongs to Billing Organizations)\n\nAnd the issue only occurs for attribute of Billing Organizations:\n![Image](https://github.com/user-attachments/assets/a787c993-5399-4a15-9211-9a086e5291cd)\n![Image](https://github.com/user-attachments/assets/e12dd38e-53fe-4573-87c6-cff0ceb4e97e)', 'created_at': datetime.datetime(2024, 11, 20, 17, 11, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489199645, 'issue_id': 2669163264, 'author': 'Simonot', 'body': 'Well well well,\n\nAfter some more digging (and a little bit of luck) I could nail down the issue (or maybe it is an expected behavior that I missed 🤔 ) to something that seems not related: metadata of Models 🙀 \n\nIt turns out that I had 2 models:\n- ""Accounts using feedback v1""\n- ""Accounts using feedback v2""\nwhich were almost the same (only a filter was different), and the issue of aliasing turns out to be present ONLY in ""Accounts using feedback v1"".\nAfter changing a the filter to be the same, and changing the name, I could not see any difference in the SQL generated except the wrong aliasing only for ""Accounts using feedback v1"" (that was renamed ""Accounts using feedback v0"") at some point.\nAnd after checking the metadata of the Models, I saw a difference !\n![Image](https://github.com/user-attachments/assets/2d68472b-a6f2-4181-a86f-77451e22628b)\n\nIt seems that the fact that  ""Accounts using feedback v0"" had a metadata ""Entity Name"" on the `cus_name` attribute, made it wrongly aliasing.\nIn the opposite, the ""Accounts using feedback v2"" had a metadata ""No special type"" on the `cus_name` attribute and worked correctly 🤔 \n\nI have changed the metadata of the Model, but I will probably open another issue specific to Model to understand what am I missing.\n\nAny comment is more than welcome if someone understand what happens', 'created_at': datetime.datetime(2024, 11, 20, 17, 41, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-18 18:41:01 UTC): Can you move to 51.3 and test if this is there?

paoliniluis on (2024-11-18 18:41:41 UTC): Or this is simply https://github.com/metabase/metabase/issues/37600

Simonot (Issue Creator) on (2024-11-20 16:28:19 UTC): I will try updating to 51.4 and keep you posted.
It could be related to the issue mentioned indeed, because (even if for this one there are no spaces) I also have the issue with space ;)

Simonot (Issue Creator) on (2024-11-20 16:50:14 UTC): Unfortunately, it does not fix the issue.

I could build a more easy to reproduce set up but for me it is pretty clear that something is buggy in the Question to SQL (maybe only for BigQuery).
Here is another example:
![Image](https://github.com/user-attachments/assets/05063218-7da4-4c70-ab1d-5b37b6c02336)

It seems that the issue relies on the the aliasing. Indeed:
- We have a first alias in our model ""Account using feedback v1"" to transform billing_orgnanization_id to cus_id
- When trying to use this in my Question editor, for some reason:
   - The table alias is correct (Accounts_using_feedback_v1___Company)
   - BUT the attribute access is not the correct one (here we try to access billing_orgnanization_id that does not exist instead of cus_id)

Maybe it is in the Custom Expression editor 🤔 (but from what I see it seems correct here (ie using cus_id)):
![Image](https://github.com/user-attachments/assets/a3393f3f-164b-4fba-a378-ca5eafe390bb)

Do you think I should create a more reproductible set up an open another issue ?

Simonot (Issue Creator) on (2024-11-20 17:11:05 UTC): By digging a little bit, I feel the issue is related to the join and to chainning.
Indeed ""Accounts using feedback v1"" is based on a Model that joins:
- Accounts
- Billing Organization
(we can it in the image because you have `source.account_id` and `source.name` that belongs to Account and than `source.Billing_Organizations__xxx` that belongs to Billing Organizations)

And the issue only occurs for attribute of Billing Organizations:
![Image](https://github.com/user-attachments/assets/a787c993-5399-4a15-9211-9a086e5291cd)
![Image](https://github.com/user-attachments/assets/e12dd38e-53fe-4573-87c6-cff0ceb4e97e)

Simonot (Issue Creator) on (2024-11-20 17:41:23 UTC): Well well well,

After some more digging (and a little bit of luck) I could nail down the issue (or maybe it is an expected behavior that I missed 🤔 ) to something that seems not related: metadata of Models 🙀 

It turns out that I had 2 models:
- ""Accounts using feedback v1""
- ""Accounts using feedback v2""
which were almost the same (only a filter was different), and the issue of aliasing turns out to be present ONLY in ""Accounts using feedback v1"".
After changing a the filter to be the same, and changing the name, I could not see any difference in the SQL generated except the wrong aliasing only for ""Accounts using feedback v1"" (that was renamed ""Accounts using feedback v0"") at some point.
And after checking the metadata of the Models, I saw a difference !
![Image](https://github.com/user-attachments/assets/2d68472b-a6f2-4181-a86f-77451e22628b)

It seems that the fact that  ""Accounts using feedback v0"" had a metadata ""Entity Name"" on the `cus_name` attribute, made it wrongly aliasing.
In the opposite, the ""Accounts using feedback v2"" had a metadata ""No special type"" on the `cus_name` attribute and worked correctly 🤔 

I have changed the metadata of the Model, but I will probably open another issue specific to Model to understand what am I missing.

Any comment is more than welcome if someone understand what happens

"
2669083035,issue,open,,Collapse / hide filters in dashboard,"**Is your feature request related to a problem? Please describe.**
I am starting to have a lot of filters in my dashboard and they use around 30% of the screen, especially now that they are locked in the top.

**Describe the solution you'd like**
It would be really nice to have a button or function to collapse the filters or move them in the layout of the dashboard. We can collapse them and show only the applied ones

**How important is this feature to you?**
I think it will improve a lot the visualization, especially in the embedded dashboards

",jatorna,2024-11-18 16:11:38+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/50157,"[('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2483605462, 'issue_id': 2669083035, 'author': 'paoliniluis', 'body': 'similar to https://github.com/metabase/metabase/issues/25249 and https://github.com/metabase/metabase/issues/33162 cc @ignacio-mb @jessicaul , I think we have this one created already but double checking', 'created_at': datetime.datetime(2024, 11, 18, 17, 0, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484757001, 'issue_id': 2669083035, 'author': 'jatorna', 'body': 'Thanks @paoliniluis . \nDo we plan to implement it soon?', 'created_at': datetime.datetime(2024, 11, 19, 5, 44, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569392294, 'issue_id': 2669083035, 'author': 'brunobergher', 'body': 'Related to, if not a duplicate of #12482', 'created_at': datetime.datetime(2025, 1, 3, 15, 22, 45, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-18 17:00:18 UTC): similar to https://github.com/metabase/metabase/issues/25249 and https://github.com/metabase/metabase/issues/33162 cc @ignacio-mb @jessicaul , I think we have this one created already but double checking

jatorna (Issue Creator) on (2024-11-19 05:44:28 UTC): Thanks @paoliniluis . 
Do we plan to implement it soon?

brunobergher on (2025-01-03 15:22:45 UTC): Related to, if not a duplicate of #12482

"
2669069481,issue,open,,List all questions created by a given user in one place,"**Is your feature request related to a problem? Please describe.**
It's not easy to view all questions you've ever created, in fact, I'm not sure this is possible. 

**Describe the solution you'd like**
![Image](https://github.com/user-attachments/assets/4e684e0b-2d7f-480b-87a4-227d71c0bc2f)
It would be very helpful to easily see a list of all questions you've ever created. It could live under the 'browse' section, beneath models and databases. 


**Describe alternatives you've considered**
I suppose I could write a query which pulls up all questions I've ever written, but I'm not very SQL literate, so this would be a heavy lift I think. I don't even know if this is possible. 

**How important is this feature to you?**
7/10
",kmanda95,2024-11-18 16:05:50+00:00,[],2025-02-04 20:30:53+00:00,,https://github.com/metabase/metabase/issues/50154,"[('Type:New Feature', ''), ('Organization/', '')]","[{'comment_id': 2565645131, 'issue_id': 2669069481, 'author': 'brunobergher', 'body': ""@kmanda95 I've heard requests for this before and have my own take, but I'm curious: how would you use this compared to, say, search?"", 'created_at': datetime.datetime(2024, 12, 30, 15, 47, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565804639, 'issue_id': 2669069481, 'author': 'kmanda95', 'body': ""@brunobergher So personally, I don't follow a great naming convention for how I title my questions, and I have a lot of them, so remembering the exact name or specific words used in the name would make it hard to search for (which is part of my current problem). Having a bucket/list/area with of all those questions, which I could then command F through, would be ideal."", 'created_at': datetime.datetime(2024, 12, 30, 18, 41, 11, tzinfo=datetime.timezone.utc)}]","brunobergher on (2024-12-30 15:47:07 UTC): @kmanda95 I've heard requests for this before and have my own take, but I'm curious: how would you use this compared to, say, search?

kmanda95 (Issue Creator) on (2024-12-30 18:41:11 UTC): @brunobergher So personally, I don't follow a great naming convention for how I title my questions, and I have a lot of them, so remembering the exact name or specific words used in the name would make it hard to search for (which is part of my current problem). Having a bucket/list/area with of all those questions, which I could then command F through, would be ideal.

"
2668587538,issue,open,,Default filter name does not respect `include-current` parameter,"### Describe the bug

![Image](https://github.com/user-attachments/assets/4d18d526-a5dc-4f09-b370-bd557365db6f)


### To Reproduce

1. New > Question > Orders
2. Add filter > Created At > Last week

✅ Filter name is ""Created At is **in the previous** week""

3. Edit filter and select ""Include this week""

❌ Filter name is ""Created At is **in the previous** week""

### Expected behavior

Filter name should be different when `include-current` is `true`.

TODO: confirm expected behavior with the product team.
Suggested name: ""Created At is in **this or previous** week"".

If input is ""0 weeks"" plus ""include this week"" then filter name should be ""Created At is this week""

### Information about your Metabase installation

master, 17887dcd2ceb5d638271b430f2b8522cdd9b6f1b

### Severity

P2
",kamilmielnik,2024-11-18 13:36:08+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/50139,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.Product Input Needed', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2668452944,issue,closed,not_planned,Table Fields Overlapping Across Databases with the Same Table Name,"### Describe the bug

When adding two MySQL databases (**test1** and **test2**) in Metabase, both containing a table named `customer` but with different schemas, the fields from the `customer` table in one database are incorrectly merged or displayed in the schema or query results of the other `customer` table. This results in schema confusion and incorrect query outputs.
![Image](https://github.com/user-attachments/assets/47841f5c-9c2a-423b-aa8c-2056fd42d92b)
![Image](https://github.com/user-attachments/assets/ccfe2c6d-723a-4967-a1d9-e0a6bd6ad8d3)


### To Reproduce

### Steps to Reproduce:

1. Go to Metabase and add two MySQL databases, let's call them **test1** and **test2**, both hosted on the same MySQL server (`localhost`).
2. Each database contains a table named `customer`, but their structures are different:
   - **test1.customer**:
     ```sql
     CREATE TABLE `customer` (
       `customer_id` int(11) NOT NULL AUTO_INCREMENT,
       `first_name` varchar(50) NOT NULL,
       `last_name` varchar(50) NOT NULL,
       `email` varchar(100) NOT NULL,
       `phone_number` varchar(15) DEFAULT NULL,
       `created_at` timestamp NULL DEFAULT current_timestamp(),
       PRIMARY KEY (`customer_id`),
       UNIQUE KEY `email` (`email`)
     ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
     ```
   - **test2.customer**:
     ```sql
     CREATE TABLE `customer` (
       `customer_id` int(11) NOT NULL AUTO_INCREMENT,
       `order_name` varchar(50) NOT NULL,
       `other_name` varchar(50) NOT NULL,
       `email2` varchar(100) NOT NULL,
       `phone2` varchar(15) DEFAULT NULL,
       `created_at` timestamp NULL DEFAULT current_timestamp(),
       PRIMARY KEY (`customer_id`),
       UNIQUE KEY `email2` (`email2`)
     ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
     ```
3. In Metabase, attempt to query one of the `customer` tables (e.g., from **test1**).
4. Observe the error: Fields from the other `customer` table (e.g., from **test2**) appear in the query interface or results, causing confusion.


### Expected behavior

**Expected behavior**

Each table in Metabase should only display fields that belong to its corresponding database and table schema. Fields from tables in other databases with the same name should not interfere.

**Actual Behavior:**
Fields from the customer table in test2 are included in the query or schema view of the customer table in test1, and vice versa. This leads to unexpected query results and incorrect schema representation.



### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase 0.51.3
Server version: 10.11.6-MariaDB-0+deb12u1 Debian 12
```

### Severity

High

### Additional context

Both databases are hosted on the same MySQL instance (localhost).
The issue seems to arise because the tables have the same name (customer) despite being in different databases. Metabase appears to conflate the schemas of tables with identical names across databases.",EndikaRamos,2024-11-18 12:55:53+00:00,[],2024-11-19 07:19:15+00:00,2024-11-18 13:51:57+00:00,https://github.com/metabase/metabase/issues/50138,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Team/Querying', '')]","[{'comment_id': 2483110645, 'issue_id': 2668452944, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/50072, fixed already', 'created_at': datetime.datetime(2024, 11, 18, 13, 51, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484874781, 'issue_id': 2668452944, 'author': 'crisptrutski', 'body': 'Unsure of whether this is sync or query builder issue, worth ruling out the former first I think.', 'created_at': datetime.datetime(2024, 11, 19, 7, 19, 14, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-18 13:51:57 UTC): duplicate of https://github.com/metabase/metabase/issues/50072, fixed already

crisptrutski on (2024-11-19 07:19:14 UTC): Unsure of whether this is sync or query builder issue, worth ruling out the former first I think.

"
2668093457,issue,closed,completed,GeoJSON asset file should follow the metabaseInstanceUrl when in embedding sdk,"When the frontend loads the world.json asset file (example: https://shoppy.hosted.staging.metabase.com/app/assets/geojson/world.json) when loading maps, it should use a prefix following `metabaseInstanceUrl` when in the context of the embedding sdk. This allows users to use reverse proxying with Metabase.

How to reproduce with Vite:

```tsx
export default defineConfig({
  plugins: [react()],
  resolve: {
    alias: {},
  },
  server: {
    proxy: {
      ""/metabase-proxy/"": {
        target: ""http://localhost:3000/"",
        changeOrigin: true,
        rewrite: (path) => path.replace(/^\/metabase-proxy/, """"),
      },
    },
  },
});
```",heypoom,2024-11-18 10:46:38+00:00,['npretto'],2024-11-19 11:44:31+00:00,2024-11-19 11:00:59+00:00,https://github.com/metabase/metabase/issues/50132,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2667653722,issue,closed,completed,Remove clause button shrinks in the notebook editor,"### Describe the bug

![Image](https://github.com/user-attachments/assets/2b9010f9-2520-41dc-b78f-aaab584bb706)


### To Reproduce

1. New > Question > Orders
2. Create a custom column `[Total]` with name `this-is-a-really-long-name-that-will-make-the-button-shrink`
3. Change viewport width to 375

""x"" button to remove the custom column is not 16x16px

### Expected behavior

""x"" button should always have the same size


### Information about your Metabase installation

master, 17887dcd2ceb5d638271b430f2b8522cdd9b6f1b

### Severity

P3
",kamilmielnik,2024-11-18 08:43:04+00:00,['kamilmielnik'],2024-11-19 12:04:21+00:00,2024-11-19 11:21:01+00:00,https://github.com/metabase/metabase/issues/50128,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2666682221,issue,open,,Error when viewing a dataset with a histogram at different time scales,"### Describe the bug

Hello,

I have an histogram.
X axis : number of lines
Y axis : date of arrival of tickets

It works well.

Request :
![Image](https://github.com/user-attachments/assets/1b6c22fb-38ad-4e84-a57a-d4a8722bc48e)

Result : 
![Image](https://github.com/user-attachments/assets/e8d7a3eb-6cde-41b0-838f-9384da883906)

If I add this filter for instance, it works well.
![Image](https://github.com/user-attachments/assets/cdfeb673-9117-4647-9920-b60090ab8173)
![Image](https://github.com/user-attachments/assets/ba91e5c0-9a88-45e4-acb0-65e856be1e51)

Nevertheless, if i add the filter ""Last month"", it does not work.
![Image](https://github.com/user-attachments/assets/eefb7f46-6d4e-4866-bcaa-622dfef214e7)
![Image](https://github.com/user-attachments/assets/cf363bd9-7fec-4c5e-b64e-6c5a5f11b0c5)

If I visualize the same graphic not by day but by ""Day of month"", it works.

PS : When I look at the result of the request, the dataset is right.

Moreover, the same dataset can be displayed as ""Curve"" and it works well whatever the chosen time scale.

Thus, It may be a little issue with histogram visualization.

Thank you for your answer


### To Reproduce

If I try to create an equivalent question with the metabase databases, it seems to work well.

![Image](https://github.com/user-attachments/assets/7b4740a0-04ad-492c-88c6-853844baf8cb)


### Expected behavior

I expected to see my dataset for last month by day but it does not work.

### Logs

No special log found.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""clickhouse"",
      ""h2"",
      ""mysql"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-08-21"",
      ""tag"": ""v1.50.21"",
      ""hash"": ""ec9f5d7""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Noumea""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.10 (Debian 13.10-1.pgdg100+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.19.0-23-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Minor

### Additional context

_No response_",Pierre-PSUD,2024-11-17 23:09:25+00:00,[],2025-02-04 20:31:20+00:00,,https://github.com/metabase/metabase/issues/50122,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2666180130,issue,closed,not_planned,Some filters are not working in latest build for column with name state,"### Describe the bug

```Hint: No operator matches the given name and argument types. You might need to add explicit type casts.
  Position: 2693```

I dug a bit more 
```""oban"".""oban_jobs"".""state"" = CAST('discarded' AS ""oban_job_state"")```
![Image](https://github.com/user-attachments/assets/f6c219cd-d4d2-4c69-b00a-1ca13be05838)


### To Reproduce

1. Go to a table that contains a column state
2. Click on filter by state
3. Scroll down to '....'
4. See error


### Expected behavior

It should generate query like ""oban"".""oban_jobs"".""state"" = 'discarded'

### Logs

_No response_

### Information about your Metabase installation

```JSON
Firefox,
Metabase metabase/metabase-enterprise:v1.51.3.5
```

### Severity

p1

### Additional context

_No response_",himangshuj,2024-11-17 17:23:05+00:00,['ranquild'],2024-12-03 16:18:44+00:00,2024-12-03 16:18:43+00:00,https://github.com/metabase/metabase/issues/50121,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2481399545, 'issue_id': 2666180130, 'author': 'himangshuj', 'body': 'The code is working in v1.50.31.4', 'created_at': datetime.datetime(2024, 11, 17, 17, 48, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493995270, 'issue_id': 2666180130, 'author': 'ranquild', 'body': ""@himangshuj is your column a native database enum? If yes, is `discarded` a valid enum value? Could you also share the actual query error? What's your DB - postgres or something else?"", 'created_at': datetime.datetime(2024, 11, 22, 15, 18, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515008359, 'issue_id': 2666180130, 'author': 'ranquild', 'body': ""Closing this as there is not enough info in the issue. Could be related to this https://github.com/metabase/metabase/issues/50771. Please open another issue with details and repro steps if that's a different problem."", 'created_at': datetime.datetime(2024, 12, 3, 16, 18, 43, tzinfo=datetime.timezone.utc)}]","himangshuj (Issue Creator) on (2024-11-17 17:48:42 UTC): The code is working in v1.50.31.4

ranquild (Assginee) on (2024-11-22 15:18:19 UTC): @himangshuj is your column a native database enum? If yes, is `discarded` a valid enum value? Could you also share the actual query error? What's your DB - postgres or something else?

ranquild (Assginee) on (2024-12-03 16:18:43 UTC): Closing this as there is not enough info in the issue. Could be related to this https://github.com/metabase/metabase/issues/50771. Please open another issue with details and repro steps if that's a different problem.

"
2663415549,issue,closed,completed,[Epic] Ensure SDK works with Metabase,"**Links**
- product doc: https://www.notion.so/metabase/Ensure-SDK-works-with-Metabase-5775e2b0f423483594c5a4881f688a84
- eng doc: https://www.notion.so/metabase/Tech-E2E-tests-for-SDK-cross-version-testing-12769354c90180af81c1c2bd7168b475
- feature branch: `sdk-e2e-tests-stable`

**Implementation Plan**


***Milestone 1***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/49196
- [ ] https://github.com/metabase/metabase/pull/50235
- [ ] https://github.com/metabase/metabase/pull/50423
```


",deniskaber,2024-11-15 22:55:42+00:00,['deniskaber'],2024-11-27 18:23:08+00:00,2024-11-27 18:23:08+00:00,https://github.com/metabase/metabase/issues/50113,"[('.CI & Tests', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2663194684,issue,open,,"You Can Turn Off CSV Uploads for ""Metabase Cloud Storage"" and Cannot Re-enable It","### Describe the bug

If you have the add on for ""Metabase Cloud Storage"" it allows you to disable CSV uploads to this database from the admin panel. If you accidentally do this you cannot correct it.



### To Reproduce

1. Set up a staging instance with a data warehouse add on
2. Log into the instance and disable CSV uploads
3. Try to re-enable it
4. See error:

![Image](https://github.com/user-attachments/assets/dfc5f4cd-65b5-4a6d-b07b-d75e331b2c51)

### Expected behavior

Users shouldn't be able to get into this state where they can't add data to the attached storage.

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50
```

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-11-15 21:29:17+00:00,[],2025-02-04 20:27:29+00:00,,https://github.com/metabase/metabase/issues/50109,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2480006208, 'issue_id': 2663194684, 'author': 'dpsutton', 'body': ""The attached datawarehouse is marked as not writable. We'll need some mechanism here:\n\nhttps://github.com/metabase/metabase/blob/master/src/metabase/models/database.clj#L105"", 'created_at': datetime.datetime(2024, 11, 15, 21, 59, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485956924, 'issue_id': 2663194684, 'author': 'crisptrutski', 'body': ""@devurandom I wasn't sure whether this was best for you or BEC to pick up, so thanks for answering that question 😄"", 'created_at': datetime.datetime(2024, 11, 19, 15, 0, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486514903, 'issue_id': 2663194684, 'author': 'devurandom', 'body': '> I wasn\'t sure whether this was best for you or BEC to pick up, so thanks for answering that question 😄\n\nI can create a stop-gap to prevent customers from getting into the ""cannot switch back to Metabase Cloud Storage"" situation, by preventing them from switching away from it in the first place (I would submit an improved version of https://github.com/metabase/metabase/pull/45842 -- it was reverted in https://github.com/metabase/metabase/pull/47611).\n\nHowever, ultimately we want to allow users to choose, but that will (to my understanding) require more fine-grained permissions. A side-effect of https://github.com/metabase/metabase/pull/42869 is that now the upload settings are governed by database config write permissions. We probably want to separate the write permission to database connection details from the permission to change upload settings. If BEC could take that on that would be great, since that\'s beyond what I can do soon.', 'created_at': datetime.datetime(2024, 11, 19, 19, 2, 26, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-11-15 21:59:32 UTC): The attached datawarehouse is marked as not writable. We'll need some mechanism here:

https://github.com/metabase/metabase/blob/master/src/metabase/models/database.clj#L105

crisptrutski on (2024-11-19 15:00:39 UTC): @devurandom I wasn't sure whether this was best for you or BEC to pick up, so thanks for answering that question 😄

devurandom on (2024-11-19 19:02:26 UTC): I can create a stop-gap to prevent customers from getting into the ""cannot switch back to Metabase Cloud Storage"" situation, by preventing them from switching away from it in the first place (I would submit an improved version of https://github.com/metabase/metabase/pull/45842 -- it was reverted in https://github.com/metabase/metabase/pull/47611).

However, ultimately we want to allow users to choose, but that will (to my understanding) require more fine-grained permissions. A side-effect of https://github.com/metabase/metabase/pull/42869 is that now the upload settings are governed by database config write permissions. We probably want to separate the write permission to database connection details from the permission to change upload settings. If BEC could take that on that would be great, since that's beyond what I can do soon.

"
2663132331,issue,closed,completed,Serialization: Importing Same YAML with NULL Entity ID Twice Later Breaks Export,"### Describe the bug

You can import a card via serialization that has with a NULL entity ID and Metabase generates the ID for you. You can import it again and it will also work.

On third import it fails with:

`Error during serialization: ERROR: duplicate key value violates unique constraint ""report_card_entity_id_key""`

If you attempt to export now you are also met with this error.



### To Reproduce

1. Set up a test instance and export a collection
2. Modify one of the cards to set a NULL entity ID and change the name
3. Import via serialization - it works!
4. Import it again - it works!
5. Import it again - constraint violation
6. Attempt to export - also constraint violation

### Expected behavior

We should be able to prevent users from creating this state, I would think.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Replicated in 50 and 51
```

### Severity

Blocking some users

### Additional context

A cloud customer broken the export functionality on their instance this way. Seems like the second imported card exists without an entityID. On export it attempts to generate an ID identical to one that already exists (which makes sense). So we can work around this by editing the card in the instance and exporting again. But it's a very frustrating experience.",ixipixi,2024-11-15 21:03:22+00:00,['wotbrew'],2025-01-27 19:29:28+00:00,2025-01-27 18:37:41+00:00,https://github.com/metabase/metabase/issues/50106,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2482465512, 'issue_id': 2663132331, 'author': 'crisptrutski', 'body': ""Lowering to P2 after seeing there's a (tedious) workaround."", 'created_at': datetime.datetime(2024, 11, 18, 9, 54, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498149201, 'issue_id': 2663132331, 'author': 'luizarakaki', 'body': ""How do they get a card without entity-id? This shouldn't be possible...\n\nThere is a limit on how much yaml wrangling we support, editing entity-id seems off-limits"", 'created_at': datetime.datetime(2024, 11, 25, 14, 20, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2499695234, 'issue_id': 2663132331, 'author': 'ixipixi', 'body': '@luizarakaki they erased the entity_id in an exported card in order to create a duplicate. I agree that there should be some limits here - but we actually tell them in the docs: [""If you import an item with blank entity_id (and blank serdes/meta → id), Metabase will create a new item.""](https://www.metabase.com/docs/latest/installation-and-operation/serialization#how-import-works) \n\nHowever, we don\'t indicate how the entity_id is generated or tell them how to guarantee it will be unique. Separately, we have many customers editing entity IDs to support serialization in a multi tenant instance because it\'s the only option they have for duplicating assets right now.', 'created_at': datetime.datetime(2024, 11, 26, 5, 30, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2550721016, 'issue_id': 2663132331, 'author': 'piranha', 'body': ""Our entity_id generation is based on the actual data in an entity (in a card in this case), so it makes sense why it fails the third time — it's the same as it was generated for the second time. I think this was done in hope to support some kind of serdes-v1-like functionality.\n\nI'm a bit surprised that it did not update card2 and tried to insert something. 🤣\n\nIf we want to keep this behavior I can think of a few ways to solve it:\n1) check if generated entity id already exists in db and should be regenerated with more random input\n2) or make entity_id generation random"", 'created_at': datetime.datetime(2024, 12, 18, 8, 51, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568928852, 'issue_id': 2663132331, 'author': 'piranha', 'body': 'Heads up: for this behavior to change we need to understand what\'s the behavior we want to have here. Do we want this (empty entity_id) to be a way to create ""duplicates"" in the db, or do we want to join them with existing data? Because right now behavior borders on being undefined.', 'created_at': datetime.datetime(2025, 1, 3, 9, 25, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575922479, 'issue_id': 2663132331, 'author': 'luizarakaki', 'body': '@piranha I think we should make entity_id generation random now.\n\nWhen we shipped this on 45, it made sense to use the identity function to generate a consistent entity-id on `import`.\nBut now, we generate the entity-id on `export` and the only use for NULL entity-id is to duplicate content. So randomizing the entity-id makes sense to enable this use case and fix the issue.', 'created_at': datetime.datetime(2025, 1, 7, 18, 3, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2583988177, 'issue_id': 2663132331, 'author': 'bshepherdson', 'body': 'I think that makes sense, but only in the case where we\'re importing something that has no `entity_id`. That can\'t happen by accident (since we\'d never export them like that), so it\'s safe.\n\nThe ""we previously used serdes v1 and now we\'re using v2"" workflow is still handled because we would backfill any missing `entity_id`s before both the export and import, and the exported entities would have their (possibly backfilled) `entity_id`s set.', 'created_at': datetime.datetime(2025, 1, 10, 20, 19, 53, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-11-18 09:54:04 UTC): Lowering to P2 after seeing there's a (tedious) workaround.

luizarakaki on (2024-11-25 14:20:20 UTC): How do they get a card without entity-id? This shouldn't be possible...

There is a limit on how much yaml wrangling we support, editing entity-id seems off-limits

ixipixi (Issue Creator) on (2024-11-26 05:30:17 UTC): @luizarakaki they erased the entity_id in an exported card in order to create a duplicate. I agree that there should be some limits here - but we actually tell them in the docs: [""If you import an item with blank entity_id (and blank serdes/meta → id), Metabase will create a new item.""](https://www.metabase.com/docs/latest/installation-and-operation/serialization#how-import-works) 

However, we don't indicate how the entity_id is generated or tell them how to guarantee it will be unique. Separately, we have many customers editing entity IDs to support serialization in a multi tenant instance because it's the only option they have for duplicating assets right now.

piranha on (2024-12-18 08:51:11 UTC): Our entity_id generation is based on the actual data in an entity (in a card in this case), so it makes sense why it fails the third time — it's the same as it was generated for the second time. I think this was done in hope to support some kind of serdes-v1-like functionality.

I'm a bit surprised that it did not update card2 and tried to insert something. 🤣

If we want to keep this behavior I can think of a few ways to solve it:
1) check if generated entity id already exists in db and should be regenerated with more random input
2) or make entity_id generation random

piranha on (2025-01-03 09:25:26 UTC): Heads up: for this behavior to change we need to understand what's the behavior we want to have here. Do we want this (empty entity_id) to be a way to create ""duplicates"" in the db, or do we want to join them with existing data? Because right now behavior borders on being undefined.

luizarakaki on (2025-01-07 18:03:49 UTC): @piranha I think we should make entity_id generation random now.

When we shipped this on 45, it made sense to use the identity function to generate a consistent entity-id on `import`.
But now, we generate the entity-id on `export` and the only use for NULL entity-id is to duplicate content. So randomizing the entity-id makes sense to enable this use case and fix the issue.

bshepherdson on (2025-01-10 20:19:53 UTC): I think that makes sense, but only in the case where we're importing something that has no `entity_id`. That can't happen by accident (since we'd never export them like that), so it's safe.

The ""we previously used serdes v1 and now we're using v2"" workflow is still handled because we would backfill any missing `entity_id`s before both the export and import, and the exported entities would have their (possibly backfilled) `entity_id`s set.

"
2663102346,issue,open,,Update sandboxing to fetch `result_metadata` of a native query without actually running the query,"The sandboxing enforcement code needs access to the `result_metadata` of a card, which might not be present if it's a card based on a query that hasn't been run since the last time it was saved. If it's a native query, currently we run the query with a `LIMIT 0` to fetch the metadata, but apparently there's a newer method that allows us to avoid running the query. 

Slack discussion: https://metaboat.slack.com/archives/C064EB1UE5P/p1731616267343049?thread_ts=1731532799.297809&cid=C064EB1UE5P",noahmoss,2024-11-15 20:44:36+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/50105,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2662710149,issue,open,,Use Next.js experimental compatibility layer and print a message in the embedding cli,"Using CLI in Next.js does not work today because of the dynamic import statements needed.

For Next.js specifically, we could update the import line to use the experimental compatibility layer that Nicolo built, and point them to the Next.js bit of the documentation in case it doesn't work for them.",heypoom,2024-11-15 17:46:22+00:00,['heypoom'],2025-02-05 15:26:27+00:00,,https://github.com/metabase/metabase/issues/50096,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2662710027,issue,open,,Apply container queries to make analytics component responsive and note in console in the embedding cli,"Most React projects or even default starter kits comes with CSS that applies `max-width` to the project. If someone is trying it out the SDK for the first time, and we don't tell them anything about CSS in the CLI, it looks bad because the component expects to be rendered in full-screen.

We can make the style a bit more responsive (container queries maybe), and maybe print a message that this is intended to be rendered as a full-width component.",heypoom,2024-11-15 17:46:18+00:00,[],2025-02-04 20:25:48+00:00,,https://github.com/metabase/metabase/issues/50095,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2662709885,issue,closed,completed,Detect and emit TypeScript component files for TS projects in the embedding cli,"We only emit `.jsx` components currently, and not every React project is configured with JavaScript interop. We should change the extension of the emitted components to `.tsx` once we are in a TypeScript project. We could detect for the `typescript` dependency or presence of `tsconfig.json` in the project root, and then emit `.tsx` by default instead if it is detected.

We should also use the `define` utilities from the SDK, so it produces the correct types.",heypoom,2024-11-15 17:46:13+00:00,['heypoom'],2024-11-21 09:04:57+00:00,2024-11-21 08:21:40+00:00,https://github.com/metabase/metabase/issues/50094,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2662708793,issue,closed,completed,Improve the import path suggestions printed into the console in the embedding cli,"We should improve the default import path suggestions printed in the console. Also, we should update the console message to tweak the import path to match where their component lives.

We can print this note in the end:

> Make sure the `from` path is valid (depending on your app, you may need to move the components to a new directory).
",heypoom,2024-11-15 17:45:38+00:00,['heypoom'],2024-11-20 20:45:10+00:00,2024-11-20 19:55:15+00:00,https://github.com/metabase/metabase/issues/50093,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]","[{'comment_id': 2482245859, 'issue_id': 2662708793, 'author': 'heypoom', 'body': 'Make sure the instructions align with the docs in https://github.com/metabase/metabase/pull/50098', 'created_at': datetime.datetime(2024, 11, 18, 8, 21, 48, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-18 08:21:48 UTC): Make sure the instructions align with the docs in https://github.com/metabase/metabase/pull/50098

"
2662694452,issue,open,,[Epic] Embedding CLI Improvements,"***Milestone 1***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/50093
- [ ] https://github.com/metabase/metabase/issues/50094
- [ ] https://github.com/metabase/metabase/issues/52796
- [ ] https://github.com/metabase/metabase/issues/50096
- [ ] https://github.com/metabase/metabase/issues/50095
```",heypoom,2024-11-15 17:38:02+00:00,['heypoom'],2025-02-05 11:49:05+00:00,,https://github.com/metabase/metabase/issues/50092,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]","[{'comment_id': 2498889374, 'issue_id': 2662694452, 'author': 'heypoom', 'body': 'Paused to focus on https://github.com/metabase/metabase/issues/50002', 'created_at': datetime.datetime(2024, 11, 25, 19, 44, 7, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-25 19:44:07 UTC): Paused to focus on https://github.com/metabase/metabase/issues/50002

"
2662620385,issue,closed,completed,Pie chart error: no row values found for key,"### Describe the bug

We sometimes run into an error when changing filters on a dashboard with pie charts; from what I can gather the error occurs when an inner ring value that was previously in the result set disappears to to narrowing the filter criteria. The chart will then report `No row values found for key x` and fails to load.

We have multiple pie charts on the same dashboard all plotting the same set of inner ring values, but occurs when one pie chart doesn't have an inner ring value in its result set that the others have. The error only ocurrs for statically embedded charts, I'm unable to reproduce it when viewing the dashboard in the Metabase GUI. See logs for full stack trace.

### To Reproduce

Create an embedded dashboard with multiple pie charts that plot the same inner ring values, find a filter value that ensures an inner ring value disappears from the result set of _one_ of the pie chart questions but not the others.

### Expected behavior

No errors.

### Logs

```
Error: No row values found for key 2: Fair
    d app-embed.742223b063e05082.js:453
    v app-embed.742223b063e05082.js:453
    v PieChart.tsx:63
    useMemo vendor.66cc5cf07b44f626.js:1
    useMemo vendor.66cc5cf07b44f626.js:1
    ke PieChart.tsx:61
    o_ vendor.66cc5cf07b44f626.js:1
    l vendor.66cc5cf07b44f626.js:1
    sN vendor.66cc5cf07b44f626.js:1
    sP vendor.66cc5cf07b44f626.js:1
    sP vendor.66cc5cf07b44f626.js:1
    sk vendor.66cc5cf07b44f626.js:1
    sR vendor.66cc5cf07b44f626.js:1
    r8 vendor.66cc5cf07b44f626.js:1
    sx vendor.66cc5cf07b44f626.js:1
    sx vendor.66cc5cf07b44f626.js:1
    sw vendor.66cc5cf07b44f626.js:1
    oD vendor.66cc5cf07b44f626.js:1
    oT vendor.66cc5cf07b44f626.js:1
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    t vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    41419 session-middleware.js:59
    default vendor.66cc5cf07b44f626.js:1
    <anonymous> vendor.66cc5cf07b44f626.js:8
    default vendor.66cc5cf07b44f626.js:1
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    h vendor.66cc5cf07b44f626.js:8
    D vendor.66cc5cf07b44f626.js:8
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    Y data-fetching.ts:389
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    f data-fetching.ts:452
    J data-fetching.ts:450
    a vendor.66cc5cf07b44f626.js:8
    K app-embed.742223b063e05082.js:209
    B app-embed.742223b063e05082.js:209
    aj vendor.66cc5cf07b44f626.js:1
    sH vendor.66cc5cf07b44f626.js:1
    sj vendor.66cc5cf07b44f626.js:1
    w vendor.66cc5cf07b44f626.js:1
    E vendor.66cc5cf07b44f626.js:1
    73717 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    89489 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    83975 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    12788 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66598 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66817 app-embed.742223b063e05082.js:159
    a runtime.223af989e21439f4.js:1
app-embed.742223b063e05082.js:194:28642
14:04:56.694
Error: No row values found for key 2: Fair
    d app-embed.742223b063e05082.js:453
    v app-embed.742223b063e05082.js:453
    v PieChart.tsx:63
    useMemo vendor.66cc5cf07b44f626.js:1
    useMemo vendor.66cc5cf07b44f626.js:1
    ke PieChart.tsx:61
    o_ vendor.66cc5cf07b44f626.js:1
    l vendor.66cc5cf07b44f626.js:1
    sN vendor.66cc5cf07b44f626.js:1
    sP vendor.66cc5cf07b44f626.js:1
    sP vendor.66cc5cf07b44f626.js:1
    sk vendor.66cc5cf07b44f626.js:1
    sR vendor.66cc5cf07b44f626.js:1
    r8 vendor.66cc5cf07b44f626.js:1
    sx vendor.66cc5cf07b44f626.js:1
    sx vendor.66cc5cf07b44f626.js:1
    sw vendor.66cc5cf07b44f626.js:1
    oD vendor.66cc5cf07b44f626.js:1
    oT vendor.66cc5cf07b44f626.js:1
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    t vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    41419 session-middleware.js:59
    default vendor.66cc5cf07b44f626.js:1
    <anonymous> vendor.66cc5cf07b44f626.js:8
    default vendor.66cc5cf07b44f626.js:1
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    h vendor.66cc5cf07b44f626.js:8
    D vendor.66cc5cf07b44f626.js:8
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    Y data-fetching.ts:389
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    f data-fetching.ts:452
    J data-fetching.ts:450
    a vendor.66cc5cf07b44f626.js:8
    K app-embed.742223b063e05082.js:209
    B app-embed.742223b063e05082.js:209
    aj vendor.66cc5cf07b44f626.js:1
    sH vendor.66cc5cf07b44f626.js:1
    sj vendor.66cc5cf07b44f626.js:1
    w vendor.66cc5cf07b44f626.js:1
    E vendor.66cc5cf07b44f626.js:1
    73717 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    89489 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    83975 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    12788 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66598 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66817 app-embed.742223b063e05082.js:159
    a runtime.223af989e21439f4.js:1
 
Object { componentStack: ""\nke@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:453:52899\ndiv\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\nu@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:1:1565194\neI@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:378:19570\nc@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:11:827096\nu@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:72:4383\nnH@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:186:9156\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\nu@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:1:1565194\n87378/nN<@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:186:11593\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\nt@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:4040110\nv@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:4021101\ny@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:3966360\ndiv\n_@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:3977344\ny@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:3991777\nnF@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:191:164\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\nnV@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:191:2388\nc@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:11:827096\nu@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:72:4383\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\ndiv\nh@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:81:31255\nmain\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\ndiv\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\nel@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:209:10373\nq@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:209:16901\n32095/B<@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:209:20259\nc@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:11:827096\n$@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:209:21376\n64803/v<@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:209:15420\nc@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:11:827096\nRouterContext\nRouter\nd@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:386351\nnb@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:344:27338\nA@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63644\nX@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:463170\n93889/u/<@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:63250\n7138/t.DragDropContextProvider@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:1:3695372\nlA@https://charts-staging.rombit.com/app/dist/app-embed.742223b063e05082.js:396:7352\nea@https://charts-staging.rombit.com/app/dist/vendor.66cc5cf07b44f626.js:15:442"" }
app-embed.742223b063e05082.js:194:28642
    error app-embed.742223b063e05082.js:194
    componentDidCatch ErrorBoundary.tsx:30
    callback vendor.66cc5cf07b44f626.js:1
    iV vendor.66cc5cf07b44f626.js:1
    a0 vendor.66cc5cf07b44f626.js:1
    e vendor.66cc5cf07b44f626.js:1
    sj vendor.66cc5cf07b44f626.js:1
    sj vendor.66cc5cf07b44f626.js:1
    sR vendor.66cc5cf07b44f626.js:1
    r8 vendor.66cc5cf07b44f626.js:1
    sx vendor.66cc5cf07b44f626.js:1
    (Async: VoidFunction)
    sx vendor.66cc5cf07b44f626.js:1
    sw vendor.66cc5cf07b44f626.js:1
    oD vendor.66cc5cf07b44f626.js:1
    oT vendor.66cc5cf07b44f626.js:1
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    f vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notify vendor.66cc5cf07b44f626.js:11
    notifyNestedSubs vendor.66cc5cf07b44f626.js:11
    a vendor.66cc5cf07b44f626.js:11
    t vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    g vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    41419 session-middleware.js:59
    default vendor.66cc5cf07b44f626.js:1
    <anonymous> vendor.66cc5cf07b44f626.js:8
    default vendor.66cc5cf07b44f626.js:1
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    h vendor.66cc5cf07b44f626.js:8
    D vendor.66cc5cf07b44f626.js:8
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    Y data-fetching.ts:389
    a vendor.66cc5cf07b44f626.js:8
    dispatch vendor.66cc5cf07b44f626.js:8
    f data-fetching.ts:452
    J data-fetching.ts:450
    a vendor.66cc5cf07b44f626.js:8
    K app-embed.742223b063e05082.js:209
    B app-embed.742223b063e05082.js:209
    aj vendor.66cc5cf07b44f626.js:1
    sH vendor.66cc5cf07b44f626.js:1
    sj vendor.66cc5cf07b44f626.js:1
    w vendor.66cc5cf07b44f626.js:1
    E vendor.66cc5cf07b44f626.js:1
    (Async: EventHandlerNonNull)
    73717 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    89489 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    83975 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    12788 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66598 vendor.66cc5cf07b44f626.js:1
    a runtime.223af989e21439f4.js:1
    66817 app-embed.742223b063e05082.js:159
    a runtime.223af989e21439f4.js:1
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v1.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```

### Severity

Medium

### Additional context

_No response_",YvesBos,2024-11-15 17:14:16+00:00,['alxnddr'],2024-12-14 02:04:12+00:00,2024-12-13 23:49:56+00:00,https://github.com/metabase/metabase/issues/50090,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2481722122, 'issue_id': 2662620385, 'author': 'abhinav8888', 'body': 'I am facing this issue as well. Occurs only for embedded charts, not in Metabas GUI', 'created_at': datetime.datetime(2024, 11, 18, 0, 54, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512724149, 'issue_id': 2662620385, 'author': 'lucashamaguchi', 'body': 'I am also facing this issue after upgrading from v0.46.6.2 to v0.51.6', 'created_at': datetime.datetime(2024, 12, 2, 20, 22, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521192925, 'issue_id': 2662620385, 'author': 'Willian-A', 'body': 'same problem', 'created_at': datetime.datetime(2024, 12, 5, 19, 6, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539178487, 'issue_id': 2662620385, 'author': 'theram', 'body': ""Same problem here on 0.51.4 & 0.52.2. Downgraded to 0.49.14 and issue didn't reappear."", 'created_at': datetime.datetime(2024, 12, 12, 14, 53, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539595486, 'issue_id': 2662620385, 'author': 'paoliniluis', 'body': 'Seems like a very recurrent issue: can someone help with the reproduction checking this comment?\nhttps://github.com/metabase/metabase/issues/50381#issuecomment-2524816827\n\n@Willian-A @theram @lucashamaguchi @abhinav8888 @YvesBos', 'created_at': datetime.datetime(2024, 12, 12, 17, 38, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2540889663, 'issue_id': 2662620385, 'author': 'theram', 'body': 'Hi @paoliniluis , \nI cant provide the info relating to alerts as my situation was related to using public dashboard links but sounded  similar (same ""No row values found for key...""). My set up is: postgres db holding metabase db, and my data db. 3 pies hooked up to 3 postgres views in the data db. These pies individually work - all the time - when viewed from their shared public link in browser. However when these same pies exist in a dashboard - and the dashboard is viewed via public link, one or more pies either dont provide all their data or provide no data at all with the ""Somethings gone wrong message"". \n\nRefreshing the page can make the failing pie(s) work, but others stop working, so the error(s) are inconsistent. From the embed preview tab the same behaviour can be seen. All pies/dashboards work fine in the metabase UI. \n\nWill attach the api calls made and the debug json that is downloadable when a chart fails to load.\n\n[api-calls-for-public-dashboard-issue-with-pies.txt](https://github.com/user-attachments/files/18123637/api-calls-for-public-dashboard-issue-with-pies.txt)\n[metabase-diagnostic-info-2024-12-13T08_20_06.700Z.json](https://github.com/user-attachments/files/18123635/metabase-diagnostic-info-2024-12-13T08_20_06.700Z.json)\n[metabase-diagnostic-info-2024-12-13T08_18_35.672Z.json](https://github.com/user-attachments/files/18123636/metabase-diagnostic-info-2024-12-13T08_18_35.672Z.json)', 'created_at': datetime.datetime(2024, 12, 13, 8, 43, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542661867, 'issue_id': 2662620385, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52.3](https://github.com/metabase/metabase/milestone/292)', 'created_at': datetime.datetime(2024, 12, 14, 2, 4, 11, tzinfo=datetime.timezone.utc)}]","abhinav8888 on (2024-11-18 00:54:33 UTC): I am facing this issue as well. Occurs only for embedded charts, not in Metabas GUI

lucashamaguchi on (2024-12-02 20:22:37 UTC): I am also facing this issue after upgrading from v0.46.6.2 to v0.51.6

Willian-A on (2024-12-05 19:06:33 UTC): same problem

theram on (2024-12-12 14:53:22 UTC): Same problem here on 0.51.4 & 0.52.2. Downgraded to 0.49.14 and issue didn't reappear.

paoliniluis on (2024-12-12 17:38:35 UTC): Seems like a very recurrent issue: can someone help with the reproduction checking this comment?
https://github.com/metabase/metabase/issues/50381#issuecomment-2524816827

@Willian-A @theram @lucashamaguchi @abhinav8888 @YvesBos

theram on (2024-12-13 08:43:51 UTC): Hi @paoliniluis , 
I cant provide the info relating to alerts as my situation was related to using public dashboard links but sounded  similar (same ""No row values found for key...""). My set up is: postgres db holding metabase db, and my data db. 3 pies hooked up to 3 postgres views in the data db. These pies individually work - all the time - when viewed from their shared public link in browser. However when these same pies exist in a dashboard - and the dashboard is viewed via public link, one or more pies either dont provide all their data or provide no data at all with the ""Somethings gone wrong message"". 

Refreshing the page can make the failing pie(s) work, but others stop working, so the error(s) are inconsistent. From the embed preview tab the same behaviour can be seen. All pies/dashboards work fine in the metabase UI. 

Will attach the api calls made and the debug json that is downloadable when a chart fails to load.

[api-calls-for-public-dashboard-issue-with-pies.txt](https://github.com/user-attachments/files/18123637/api-calls-for-public-dashboard-issue-with-pies.txt)
[metabase-diagnostic-info-2024-12-13T08_20_06.700Z.json](https://github.com/user-attachments/files/18123635/metabase-diagnostic-info-2024-12-13T08_20_06.700Z.json)
[metabase-diagnostic-info-2024-12-13T08_18_35.672Z.json](https://github.com/user-attachments/files/18123636/metabase-diagnostic-info-2024-12-13T08_18_35.672Z.json)

github-actions[bot] on (2024-12-14 02:04:11 UTC): 🚀 This should also be released by [v0.52.3](https://github.com/metabase/metabase/milestone/292)

"
2662475358,issue,closed,completed,Document MB_EMAIL_MAX_RECIPIENTS_PER_SECOND,"**Is your feature request related to a problem? Please describe.**
Admins can now slow down / throttle the sending rate of emails from their instance. It would be helpful to document this.
[See #49477](https://github.com/metabase/metabase/pull/49477)

",ixipixi,2024-11-15 16:23:26+00:00,[],2024-12-13 11:51:12+00:00,2024-12-13 11:51:11+00:00,https://github.com/metabase/metabase/issues/50087,"[('Type:Documentation', ''), ('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2541276555, 'issue_id': 2662475358, 'author': 'jeff-bruemmer', 'body': 'Documented here: https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_email_max_recipients_per_second', 'created_at': datetime.datetime(2024, 12, 13, 11, 51, 11, tzinfo=datetime.timezone.utc)}]","jeff-bruemmer on (2024-12-13 11:51:11 UTC): Documented here: https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_email_max_recipients_per_second

"
2662443236,issue,closed,completed,Custom destination click behavior broken for statically embedded trend charts,"### Describe the bug

Starting in v1.51.1, the custom click behavior on statically embedded trend charts is broken. Nothing happens, no errors logged in the console. 

Only trend seem to be affected, the click behavior for our other chart types still works. I've reproduced the issue using the sample database, see below. On version v1.50.27 it still works, I've verified using the same method.

### To Reproduce

1. Ensure static embedding is enabled
2. Create a new dashboard with the `Discount given per quarter` trend chart
3. Add custom destination click behavior to the trend chart: link to `https://google.com`
4. Save & publish the dashboard
5. Open the iframe URL that you get by running the suggested snippet
6. Click on the number in the trend chart

### Expected behavior

`https://google.com` should open in a new tab.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v1.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```

### Severity

High

### Additional context

_No response_",YvesBos,2024-11-15 16:05:53+00:00,['uladzimirdev'],2024-11-18 12:25:36+00:00,2024-11-18 11:21:44+00:00,https://github.com/metabase/metabase/issues/50086,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2479742957, 'issue_id': 2662443236, 'author': 'uladzimirdev', 'body': 'thanks for a nice bug report, we have a similar problem reported here https://github.com/metabase/metabase/issues/49776\n\ntable view is affected as well', 'created_at': datetime.datetime(2024, 11, 15, 19, 9, 17, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Assginee) on (2024-11-15 19:09:17 UTC): thanks for a nice bug report, we have a similar problem reported here https://github.com/metabase/metabase/issues/49776

table view is affected as well

"
2662267828,issue,closed,completed,"Change CreateQuestion's API, implementation and improve default behaviour on saving questions","We should replace the `<CreateQuestion />` component's API, underlying implementation and docs. It should now consume the `<InteractiveQuestion />` directly and expose the same props. We should also improve [the behaviour after the question is being saved](https://www.loom.com/share/aafc92798b814f56bd989765153920dc).",heypoom,2024-11-15 15:13:05+00:00,['heypoom'],2024-11-20 21:12:23+00:00,2024-11-20 18:11:58+00:00,https://github.com/metabase/metabase/issues/50082,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2662221209,issue,closed,not_planned,"When drilling in on a pie chart segment that is empty values, the filter filters on (empty) instead of using isempty and returns no results","### Describe the bug

When drilling in on a pie chart segment that is empty values, the filter filters on (empty) instead of using isempty and returns no results.  

![Image](https://github.com/user-attachments/assets/5eae25f8-4457-4c82-bcee-6569a92f60b1)

[loom](https://www.loom.com/share/a69e7e777b714c0e96dc42547640ce60?sid=44e56086-b816-4ba9-9512-72a400ecdfbf)

This problem doesn't exist on row charts.  No, I'm not turning all my pie charts to row charts to solve for this.

### To Reproduce

1.  Create a pie chart, grouping by a data set doesn't have values for all rows
2. Attempt to drill in
3. 


### Expected behavior

Should return rows with empty values

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome

Built on 2024-11-12

Hash: dc01cad
```

### Severity

frustrating

### Additional context

_No response_",cbalusek,2024-11-15 14:50:46+00:00,[],2024-11-26 17:35:21+00:00,2024-11-26 17:35:21+00:00,https://github.com/metabase/metabase/issues/50080,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2501533341, 'issue_id': 2662221209, 'author': 'mngr', 'body': 'Seems to be a duplicate of https://github.com/metabase/metabase/issues/49737', 'created_at': datetime.datetime(2024, 11, 26, 17, 24, 51, tzinfo=datetime.timezone.utc)}]","mngr on (2024-11-26 17:24:51 UTC): Seems to be a duplicate of https://github.com/metabase/metabase/issues/49737

"
2661841783,issue,closed,completed,"When editing a trend chart, it is no longer possible to add comparisons with previous years.","### Describe the bug

When editing a trend chart, it is no longer possible to add comparisons with previous years.

Previously, it was possible to indicate multiple years for comparison in a trend chart, but now that option has disappeared, allowing only the selection of ""previous year.""

![Image](https://github.com/user-attachments/assets/30a0877d-8e9e-4cdb-94f5-72aa32418ce3)


### To Reproduce

1. Go to **dashboard with trend chart and just 1 year in comparision**
2. Click on **edit visualization options trough dashboard**
4. See error


### Expected behavior

![Image](https://github.com/user-attachments/assets/460e27f9-d68e-442c-a112-f9abfe7a23b8)


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-PT"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-13"",
      ""tag"": ""v0.51.3.3"",
      ""hash"": ""cd3e26b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-91-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Lisbon""
  }
}
```

### Severity

high

### Additional context

_No response_",francisco-mooddie,2024-11-15 12:31:35+00:00,[],2025-01-30 17:08:10+00:00,2025-01-30 17:08:09+00:00,https://github.com/metabase/metabase/issues/50075,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2625081160, 'issue_id': 2661841783, 'author': 'alxnddr', 'body': 'Closed by https://github.com/metabase/metabase/pull/51960', 'created_at': datetime.datetime(2025, 1, 30, 17, 8, 9, tzinfo=datetime.timezone.utc)}]","alxnddr on (2025-01-30 17:08:09 UTC): Closed by https://github.com/metabase/metabase/pull/51960

"
2661833987,issue,closed,completed,Problem editing the view through the dashboard - transparent background,"### Describe the bug

When editing the visualization of a question through the dashboard, the settings background appears transparent, making it difficult to view the data.

![Image](https://github.com/user-attachments/assets/333d9071-5185-4b66-bdaa-a547441a9da6)


### To Reproduce

1. Go to **any dashboard**
2. Click on **edit dashboard and visualization options of any question**
4. See **error**


### Expected behavior

It should work like previous versions.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-PT"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-13"",
      ""tag"": ""v0.51.3.3"",
      ""hash"": ""cd3e26b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
```

### Severity

High

### Additional context

_No response_",francisco-mooddie,2024-11-15 12:27:08+00:00,['alxnddr'],2025-01-23 19:09:01+00:00,2025-01-23 19:08:59+00:00,https://github.com/metabase/metabase/issues/50074,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2478820204, 'issue_id': 2661833987, 'author': 'npfitz', 'body': ""Hi @francisco-mooddie , is this easily reproduceable for you? Are there any errors in the Javascript console? I'm not able to reproduce on a fresh instance of 51.3.3."", 'created_at': datetime.datetime(2024, 11, 15, 13, 30, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491341196, 'issue_id': 2661833987, 'author': 'paoliniluis', 'body': 'Closing, most probably someone tweaked the CSS of Metabase', 'created_at': datetime.datetime(2024, 11, 21, 14, 19, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515435692, 'issue_id': 2661833987, 'author': 'Akrista', 'body': 'Same issue here after updating to 51\n\n![Image](https://github.com/user-attachments/assets/d828853a-f7a4-47b9-864e-d5f96d4df18f)', 'created_at': datetime.datetime(2024, 12, 3, 20, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515547126, 'issue_id': 2661833987, 'author': 'paoliniluis', 'body': ""@Akrista have you done any CSS change to Metabase? what's your screen resolution?"", 'created_at': datetime.datetime(2024, 12, 3, 21, 3, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515626189, 'issue_id': 2661833987, 'author': 'Akrista', 'body': 'Hey @paoliniluis none that i remember tbh. Screen resolution is 1920x1080.\n\nJust in case that i did before, where would i insert additional or custom css to Metabase? so i can check, this metabase instance is in a docker container and so far neither my config or data folder of that container contain any custom css.', 'created_at': datetime.datetime(2024, 12, 3, 21, 53, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515800584, 'issue_id': 2661833987, 'author': 'Akrista', 'body': 'Hey, dunno if this helps somehow, made some tests with a new instance of metabase. Please let me know if i can be of help contributing to the project to check this issue, is not a deal breaker tbh i\'ve been using it like this for weeks and didn\'t even try to look for an issue previously reported hehe.\n\n## Firefox using Private Browsing:\n\n![Image](https://github.com/user-attachments/assets/eef2ffa0-430c-47d5-bc95-37c364524744)\n\n## Chrome using incognito:\n\n![Image](https://github.com/user-attachments/assets/45cad8d8-1118-497c-ba59-dc78507562d9)\n\n## Metabase JSON\n\n```json\n{\n  ""browser-info"": {\n    ""language"": ""en-US"",\n    ""platform"": ""Win32"",\n    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:135.0) Gecko/20100101 Firefox/135.0"",\n    ""vendor"": """"\n  },\n  ""metabase-info"": {\n    ""databases"": [\n      ""h2""\n    ],\n    ""run-mode"": ""prod"",\n    ""plan-alias"": """",\n    ""version"": {\n      ""date"": ""2024-11-28"",\n      ""tag"": ""v0.51.6"",\n      ""hash"": ""fc77ed4""\n    },\n    ""settings"": {\n      ""report-timezone"": null\n    },\n    ""hosting-env"": ""unknown"",\n    ""application-database"": ""postgres"",\n    ""application-database-details"": {\n      ""database"": {\n        ""name"": ""PostgreSQL"",\n        ""version"": ""15.6 (Debian 15.6-1.pgdg120+2)""\n      },\n      ""jdbc-driver"": {\n        ""name"": ""PostgreSQL JDBC Driver"",\n        ""version"": ""42.7.3""\n      }\n    }\n  },\n  ""system-info"": {\n    ""file.encoding"": ""UTF-8"",\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\n    ""java.runtime.version"": ""11.0.25+9"",\n    ""java.vendor"": ""Eclipse Adoptium"",\n    ""java.vendor.url"": ""https://adoptium.net/"",\n    ""java.version"": ""11.0.25"",\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\n    ""java.vm.version"": ""11.0.25+9"",\n    ""os.name"": ""Linux"",\n    ""os.version"": ""6.1.0-13-amd64"",\n    ""user.language"": ""en"",\n    ""user.timezone"": ""America/Caracas""\n  }\n}\n```', 'created_at': datetime.datetime(2024, 12, 3, 23, 30, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515801621, 'issue_id': 2661833987, 'author': 'Akrista', 'body': '## Browser Console Logs\n\n```console\nContent-Security-Policy: The page’s settings blocked an event handler (script-src-attr) from being executed because it violates the following directive: “script-src \'self\' https://maps.google.com/ https://accounts.google.com/ \'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=\' \'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=\' \'sha256-3N2Z+Nu++/yNMVHIl863JigVmt2Nr9gt2doEMJT2Wzk=\'”\nSource: Metabase.AssetErrorLoad(this) 5 [1-e-commerce-insights](https://mtb.aklab.duckdns.org/dashboard/1-e-commerce-insights?category=&date_range=&location=&tab=1-overview&vendor=)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.metadata.calculation] ""Don\'t know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\nThis site appears to use a scroll-linked positioning effect. This may not work well with asynchronous panning; see https://firefox-source-docs.mozilla.org/performance/scroll-linked_effects.html for further details and to join the discussion on related tools and features! [help](https://mtb.aklab.duckdns.org/admin/troubleshooting/help)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.metadata.calculation] ""Don\'t know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n[metabase.lib.metadata.calculation] ""Don\'t know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)\n```', 'created_at': datetime.datetime(2024, 12, 3, 23, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519223020, 'issue_id': 2661833987, 'author': 'Daniel270309', 'body': ""I'm also having the same issue after updating to 51 yesterday. I'm new to Metabase on a self-hosted install. In any case, the issue is happening regardless of what screen resolution I'm in or the size of the window or what type of visualization I'm editing. Using Google Chrome. Please see screenshot below.\nAlso, It's worth noting that I would have found this issue more easily if the title had been in English instead of in Portuguese. \n![Image](https://github.com/user-attachments/assets/4934f2ac-8e94-4c30-b3cf-717f05472a3c)"", 'created_at': datetime.datetime(2024, 12, 5, 5, 35, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520504932, 'issue_id': 2661833987, 'author': 'Daniel270309', 'body': '@francisco-mooddie Thank you!', 'created_at': datetime.datetime(2024, 12, 5, 14, 39, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530390303, 'issue_id': 2661833987, 'author': 'Daniel270309', 'body': 'Any idea if there is a workaround or solution to this? Or maybe an update on a fix?', 'created_at': datetime.datetime(2024, 12, 10, 4, 56, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610805075, 'issue_id': 2661833987, 'author': 'alxnddr', 'body': 'Closed by https://github.com/metabase/metabase/pull/51960', 'created_at': datetime.datetime(2025, 1, 23, 19, 8, 59, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-11-15 13:30:44 UTC): Hi @francisco-mooddie , is this easily reproduceable for you? Are there any errors in the Javascript console? I'm not able to reproduce on a fresh instance of 51.3.3.

paoliniluis on (2024-11-21 14:19:43 UTC): Closing, most probably someone tweaked the CSS of Metabase

Akrista on (2024-12-03 20:01:00 UTC): Same issue here after updating to 51

![Image](https://github.com/user-attachments/assets/d828853a-f7a4-47b9-864e-d5f96d4df18f)

paoliniluis on (2024-12-03 21:03:56 UTC): @Akrista have you done any CSS change to Metabase? what's your screen resolution?

Akrista on (2024-12-03 21:53:03 UTC): Hey @paoliniluis none that i remember tbh. Screen resolution is 1920x1080.

Just in case that i did before, where would i insert additional or custom css to Metabase? so i can check, this metabase instance is in a docker container and so far neither my config or data folder of that container contain any custom css.

Akrista on (2024-12-03 23:30:10 UTC): Hey, dunno if this helps somehow, made some tests with a new instance of metabase. Please let me know if i can be of help contributing to the project to check this issue, is not a deal breaker tbh i've been using it like this for weeks and didn't even try to look for an issue previously reported hehe.

## Firefox using Private Browsing:

![Image](https://github.com/user-attachments/assets/eef2ffa0-430c-47d5-bc95-37c364524744)

## Chrome using incognito:

![Image](https://github.com/user-attachments/assets/45cad8d8-1118-497c-ba59-dc78507562d9)

## Metabase JSON

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:135.0) Gecko/20100101 Firefox/135.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-28"",
      ""tag"": ""v0.51.6"",
      ""hash"": ""fc77ed4""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.6 (Debian 15.6-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-13-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Caracas""
  }
}
```

Akrista on (2024-12-03 23:31:07 UTC): ## Browser Console Logs

```console
Content-Security-Policy: The page’s settings blocked an event handler (script-src-attr) from being executed because it violates the following directive: “script-src 'self' https://maps.google.com/ https://accounts.google.com/ 'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=' 'sha256-3N2Z+Nu++/yNMVHIl863JigVmt2Nr9gt2doEMJT2Wzk='”
Source: Metabase.AssetErrorLoad(this) 5 [1-e-commerce-insights](https://mtb.aklab.duckdns.org/dashboard/1-e-commerce-insights?category=&date_range=&location=&tab=1-overview&vendor=)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.metadata.calculation] ""Don't know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
This site appears to use a scroll-linked positioning effect. This may not work well with asynchronous panning; see https://firefox-source-docs.mozilla.org/performance/scroll-linked_effects.html for further details and to join the discussion on related tools and features! [help](https://mtb.aklab.duckdns.org/admin/troubleshooting/help)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.metadata.calculation] ""Don't know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.metadata.calculation] ""Don't know how to calculate display name for nil. Add an impl for metabase.lib.metadata.calculation/display-name-method for :dispatch-type/nil"" 2 [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
```

Daniel270309 on (2024-12-05 05:35:27 UTC): I'm also having the same issue after updating to 51 yesterday. I'm new to Metabase on a self-hosted install. In any case, the issue is happening regardless of what screen resolution I'm in or the size of the window or what type of visualization I'm editing. Using Google Chrome. Please see screenshot below.
Also, It's worth noting that I would have found this issue more easily if the title had been in English instead of in Portuguese. 
![Image](https://github.com/user-attachments/assets/4934f2ac-8e94-4c30-b3cf-717f05472a3c)

Daniel270309 on (2024-12-05 14:39:25 UTC): @francisco-mooddie Thank you!

Daniel270309 on (2024-12-10 04:56:11 UTC): Any idea if there is a workaround or solution to this? Or maybe an update on a fix?

alxnddr (Assginee) on (2025-01-23 19:08:59 UTC): Closed by https://github.com/metabase/metabase/pull/51960

"
2661617020,issue,closed,completed,Sync of DB is merging fields from neighbor DB from table with same name,"### Describe the bug

![Image](https://github.com/user-attachments/assets/0fb7e6c4-5c52-43ea-b643-929f80ce95c3)
I have 5 differend DBs on same Mysql server. all 5 has tables with exact same name. tables has different fields. after scan DB table metadata of synced table contains merged list of fields from all 5 tables. it started after I upated to version 0.51.3 Fir 8 Nov 2024. look like sync method lost filter by table_schema.
I hav dig a little  and found  pull reuqest that could be possible cause of this issue https://github.com/metabase/metabase/pull/49011   - I  see that was something  changed rekated to shema

### To Reproduce

1. Go to 'database administration'  and select one of DB 
2. Click on 'Sync database schema now'
3.  got to 'Table Metadata'
4. see that metadata contains fieds from another DB


### Expected behavior

Metadata  must contains fildes fonly from synced Database

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version   0.51.3
Internal Database Postgre
Connected DB Mysql
```

### Severity

911

### Additional context

I need urgent fix becuase if cannot stop system from scanning  time to time. ",artem-levashov,2024-11-15 10:50:17+00:00,[],2024-11-15 18:56:42+00:00,2024-11-15 18:13:01+00:00,https://github.com/metabase/metabase/issues/50072,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('.Team/Drivers', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2661455205,issue,open,,Select none is shown and checked when all the found options are checked in the filter,"### Describe the bug

When I search for the value in the filter and select whatever is found, on top Select none is shown and checked, this looks strange, it should be unchecked.

### To Reproduce

1. Go to Accounts table from the Sample database
2. Start adding a filter, choose Last name
3. Search for Abb
4. Choose all 4 options available
5. See that Select none is shown and checked on top
![Image](https://github.com/user-attachments/assets/54ae1009-ad31-49af-99d2-ffe7b0c9467c)



### Expected behavior

Select none should be shown unchecked in this situation

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```

### Severity

Just confusing

### Additional context

_No response_",mngr,2024-11-15 09:50:47+00:00,[],2025-02-04 20:27:34+00:00,,https://github.com/metabase/metabase/issues/50070,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2569533422, 'issue_id': 2661455205, 'author': 'ranquild', 'body': 'This was the expected behavior when it was implemented. We need a spec for all possible states for the checkbox pattern with select all/none if we want to revise this.', 'created_at': datetime.datetime(2025, 1, 3, 16, 53, 10, tzinfo=datetime.timezone.utc)}]","ranquild on (2025-01-03 16:53:10 UTC): This was the expected behavior when it was implemented. We need a spec for all possible states for the checkbox pattern with select all/none if we want to revise this.

"
2661141485,issue,closed,completed,Update SDK docs on Next JS examples to make it clearer,"From this [discussion on Slack](https://metaboat.slack.com/archives/C063Q3F1HPF/p1731426932816459?thread_ts=1731424484.303689&cid=C063Q3F1HPF), it's seen that our documentation on how to use the SDK with Next JS for both App router and Pages router is a bit confusing because we just say to do the same thing as the for Pages router as we do with the App router.

",WiNloSt,2024-11-15 07:52:27+00:00,[],2024-11-18 06:04:34+00:00,2024-11-15 13:20:01+00:00,https://github.com/metabase/metabase/issues/50066,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2661126428,issue,closed,completed,Postgres XML Column is not visualized,"### Describe the bug

Currently Metabase does not display the contents of Postgres xml columns.
Instead we only see the object identifier:
![Image](https://github.com/user-attachments/assets/d954fb6b-33c8-4527-a868-675db2660811)




### To Reproduce

Create a Postgres Table with an xml column and view it inside Metabase

### Expected behavior

We should be able to see the contents of the xml column similarly as with JSON column

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version 0.49.0
- Postgres 15.6 (Debian)
```

### Severity

For us it is Blocking as we cannot see the contents of xml columns

### Additional context

_No response_",PixelBumper,2024-11-15 07:43:53+00:00,['rileythomp'],2025-01-22 16:05:01+00:00,2025-01-20 23:30:05+00:00,https://github.com/metabase/metabase/issues/50065,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Postgres', None), ('.Team/Drivers', '')]",[],
2660537572,issue,closed,completed,"0.51.x: ERROR metabase.task Error rescheduling job,org.quartz.ObjectAlreadyExistsException","### Describe the bug

We upgraded from 0.50.x to 0.51.x and these started occurring. It also seems that new alerts are not being sent, unclear if related.

### To Reproduce

1. Upgrade to 0.51.x


### Expected behavior

No error is reported.

### Logs


```
[fa705b8e-d7fb-4d33-b15b-74494d6383e9] 2024-11-15T13:17:37+11:00 ERROR metabase.task Error rescheduling job
org.quartz.ObjectAlreadyExistsException: Unable to store Trigger with name: 'metabase.task.backfill-query-fields.trigger' and group: 'DEFAULT', because one already exists with this identification.
at org.quartz.impl.jdbcjobstore.JobStoreSupport.storeTrigger(JobStoreSupport.java:1184)
at org.quartz.impl.jdbcjobstore.JobStoreSupport.replaceTrigger(JobStoreSupport.java:1503)
at org.quartz.impl.jdbcjobstore.JobStoreSupport$11.execute(JobStoreSupport.java:1478)
at org.quartz.impl.jdbcjobstore.JobStoreSupport.executeInNonManagedTXLock(JobStoreSupport.java:3864)
at org.quartz.impl.jdbcjobstore.JobStoreTX.executeInLock(JobStoreTX.java:93)
at org.quartz.impl.jdbcjobstore.JobStoreSupport.replaceTrigger(JobStoreSupport.java:1474)
at org.quartz.core.QuartzScheduler.rescheduleJob(QuartzScheduler.java:1121)
at org.quartz.impl.StdScheduler.rescheduleJob(StdScheduler.java:321)
at metabase.task$reschedule_task_BANG_93209__93210.invokeStatic(task.clj:201)
at metabase.task$reschedule_task_BANG_93209__93210.invoke(task.clj:192)
at metabase.task$schedule_task_BANG_93225__93226.invokeStatic(task.clj:221)
at metabase.task$schedule_task_BANG_93225__93226.invoke(task.clj:213)
at metabase.task.sweep_query_analysis$fn__108080.invokeStatic(sweep_query_analysis.clj:113)
at metabase.task.sweep_query_analysis$fn__108080.invoke(sweep_query_analysis.clj:96)
at metabase.task$init_tasks_BANG_$fn__93132.invoke(task.clj:79)
at metabase.task$init_tasks_BANG_.invokeStatic(task.clj:75)
at metabase.task$init_tasks_BANG_.invoke(task.clj:71)
at metabase.task$init_scheduler_BANG_.invokeStatic(task.clj:166)
at metabase.task$init_scheduler_BANG_.invoke(task.clj:153)
at metabase.task$start_scheduler_BANG_.invokeStatic(task.clj:177)
at metabase.task$start_scheduler_BANG_.invoke(task.clj:172)
at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:166)
at metabase.core$init_BANG__STAR_.invoke(core.clj:102)
at metabase.core$init_BANG_.invokeStatic(core.clj:181)
at metabase.core$init_BANG_.invoke(core.clj:176)
at metabase.core$start_normally.invokeStatic(core.clj:193)
at metabase.core$start_normally.invoke(core.clj:187)
at metabase.core$entrypoint.invokeStatic(core.clj:226)
at metabase.core$entrypoint.doInvoke(core.clj:220)
at clojure.lang.RestFn.invoke(RestFn.java:400)
at clojure.lang.AFn.applyToHelper(AFn.java:152)
at clojure.lang.RestFn.applyTo(RestFn.java:135)
at clojure.lang.Var.applyTo(Var.java:707)
at clojure.core$apply.invokeStatic(core.clj:667)
at clojure.core$apply.invoke(core.clj:662)
at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
at clojure.lang.RestFn.invoke(RestFn.java:400)
at clojure.lang.AFn.applyToHelper(AFn.java:152)
at clojure.lang.RestFn.applyTo(RestFn.java:135)
at metabase.bootstrap.main(Unknown Source)
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-AU"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""redshift""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": ""Australia/Sydney""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.226-214.880.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Australia/Sydney""
  }
}
```

### Severity

blocking some users

### Additional context

Deployment context is Docker using AWS ECS Fargate, 1-2 instances typically running concurrently.",michael-gratton,2024-11-15 02:36:19+00:00,['crisptrutski'],2024-12-04 08:12:29+00:00,2024-12-02 09:27:40+00:00,https://github.com/metabase/metabase/issues/50063,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Workflows', 'aka BEC'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2481980140, 'issue_id': 2660537572, 'author': 'qnkhuat', 'body': ""Could you give us the result of this query?\n```sql\nselect * from qrtz_triggers;\n```\n\n>  It also seems that new alerts are not being sent\n\nCould you try creating a new alert and then running this query\n```sql\nselect * from qrtz_triggers where trigger_name like 'metabase.task.send-pulse.trigger.{{YOUR_NEW_ALERT_ID}}%'\n```\nThere should be one record returning."", 'created_at': datetime.datetime(2024, 11, 18, 5, 20, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484306679, 'issue_id': 2660537572, 'author': 'michael-gratton', 'body': ""Sure thing:\n\n> select * from qrtz_triggers;\n\n| sched_name        | trigger_name                                        | trigger_group | job_name                                   | job_group | description                               | next_fire_time | prev_fire_time | priority | trigger_state | trigger_type | start_time    | end_time | calendar_name | misfire_instr | job_data  |\n|-------------------|-----------------------------------------------------|---------------|--------------------------------------------|-----------|-------------------------------------------|----------------|----------------|----------|---------------|--------------|---------------|----------|---------------|---------------|-----------|\n| MetabaseScheduler | metabase.task.anonymous-stats.trigger               | DEFAULT       | metabase.task.anonymous-stats.job          | DEFAULT   |                                           |  1731988140000 |  1731901740000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.111.0_0_0_*_*_?_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        6 | WAITING       | CRON         | 1721962889000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.follow-up-emails.trigger              | DEFAULT       | metabase.task.follow-up-emails.job         | DEFAULT   |                                           |  1731978000000 |  1731891600000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.58           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 58              |  1731972780000 |  1731969180000 |        5 | WAITING       | CRON         | 1683795973000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.creator-sentiment-emails.trigger      | DEFAULT       | metabase.task.creator-sentiment-emails.job | DEFAULT   |                                           |  1732287600000 |  1731682800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.8         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 8            |  1732042800000 |  1731956400000 |        5 | BLOCKED       | CRON         | 1659406805000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.75.0_0_9_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732053600000 |  1731967200000 |     3575 | WAITING       | CRON         | 1721862025000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.truncate-audit-tables.trigger         | DEFAULT       | metabase.task.truncate-audit-tables.job    | DEFAULT   |                                           |  1731978000000 |  1731934800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 0 bytes   |\n| MetabaseScheduler | metabase.task.refresh-channel-cache.trigger         | DEFAULT       | metabase.task.refresh-channel-cache.job    | DEFAULT   |                                           |  1731981120000 |  1731966720000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 0 bytes   |\n| MetabaseScheduler | metabase.task.upgrade-checks.trigger                | DEFAULT       | metabase.task.upgrade-checks.job           | DEFAULT   |                                           |  1732000500000 |  1731957300000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.PersistencePrune.scheduled.trigger    | DEFAULT       | metabase.task.PersistencePrune.job         | DEFAULT   | Prune deletable PersistInfo once per hour |  1731970800000 |  1731967200000 |        5 | WAITING       | CRON         | 1731655563000 |        0 |               |             2 | 0 bytes   |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.11        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 11           |  1731956400000 |  1731870000000 |        5 | BLOCKED       | CRON         | 1659406816000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.analyze-queries.trigger               | DEFAULT       | metabase.task.analyze-queries.job          | DEFAULT   |                                           |             -1 |  1731884183090 |        5 | COMPLETE      | SIMPLE       | 1731655582686 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.8            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 8               |  1731972300000 |  1731968700000 |        5 | WAITING       | CRON         | 1659320701000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.task-history-cleanup.trigger          | DEFAULT       | metabase.task.task-history-cleanup.job     | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.72.0_0_8_1_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1733000400000 |  1730408400000 |     3469 | WAITING       | CRON         | 1719784930000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.63.0_0_9_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732053600000 |  1731967200000 |     3597 | WAITING       | CRON         | 1721862002000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.50.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |     3596 | WAITING       | CRON         | 1721865604000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.3         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 3            |  1731967200000 |  1731880800000 |        5 | BLOCKED       | CRON         | 1659320693000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.backfill-query-fields.trigger         | DEFAULT       | metabase.task.backfill-query-fields.job    | DEFAULT   |                                           |  1731979140000 |  1731964740000 |        5 | WAITING       | CRON         | 1731633453000 |        0 |               |            -1 | 0 bytes   |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.11           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 11              |  1731972600000 |  1731969000000 |        5 | WAITING       | CRON         | 1659320705000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.60.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058711000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.74.0_0_8_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732050000000 |  1731963600000 |     3531 | WAITING       | CRON         | 1720389668000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.56           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 56              |  1731972000000 |  1731968400000 |        5 | WAITING       | CRON         | 1659320696000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.56        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 56           |  1732039200000 |  1731952800000 |        5 | BLOCKED       | CRON         | 1659406968000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.PersistenceRefresh.database.trigger.3 | DEFAULT       | metabase.task.PersistenceRefresh.job       | DEFAULT   | Refresh models for database 3             |  1731970800000 |  1731963600000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 376 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.67.0_0_8_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732050000000 |  1731963600000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.110.0_0_11_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731974400000 |  1731888000000 |     3558 | WAITING       | CRON         | 1721178042000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.71.0_0_9_1_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1733004000000 |  1730412000000 |     3548 | WAITING       | CRON         | 1719788452000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.55        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 55           |  1731960000000 |  1731873600000 |        5 | BLOCKED       | CRON         | 1659320690000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.59           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 59              |  1731970560000 |  1731966960000 |        5 | WAITING       | CRON         | 1695701116000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.176.0_0_*_*_*_?_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1731629454000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.61.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058711000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.109.0_0_11_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731974400000 |  1731888000000 |     3554 | WAITING       | CRON         | 1721523645000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.2            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 2               |  1732046400000 |  1731960000000 |        5 | WAITING       | CRON         | 1720681039000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.58        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 58           |  1732028400000 |  1731942000000 |        5 | BLOCKED       | CRON         | 1687076758000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.2         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 2            |  1731963600000 |  1731877200000 |        5 | BLOCKED       | CRON         | 1718930089000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.55           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 55              |  1731971100000 |  1731967500000 |        5 | WAITING       | CRON         | 1647867550000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.112.0_0_18_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731999600000 |  1731913200000 |        6 | WAITING       | CRON         | 1722071722000 |        0 |               |             1 | 996 bytes |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.66.0_0_0_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.142.0_0_9_?_*_5_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732140000000 |  1731535200000 |        6 | WAITING       | CRON         | 1725489688000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.send-pulse.trigger.64.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |\n| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.3            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 3               |  1731970500000 |  1731966900000 |        5 | WAITING       | CRON         | 1676941133000 |        0 |               |             2 | 358 bytes |\n| MetabaseScheduler | metabase.task.update-field-values.trigger.59        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 59           |  1732003200000 |  1731916800000 |        5 | BLOCKED       | CRON         | 1695701116000 |        0 |               |             2 | 358 bytes |\n\n\n> Could you try creating a new alert and then running this query\n> \n> select * from qrtz_triggers where trigger_name like 'metabase.task.send-pulse.trigger.{{YOUR_NEW_ALERT_ID}}%'\n> \n> There should be one record returning.\n\nThat is indeed what happened. I think the issue with the alerts is maybe unrelated, or at least perhaps worth resolving the first issue and I'll file another one if I think there is still an outstanding problem."", 'created_at': datetime.datetime(2024, 11, 18, 22, 56, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484563349, 'issue_id': 2660537572, 'author': 'qnkhuat', 'body': 'everything looks normal there, are you getting this error consistently on every deployment? if so, does it happen if you run Metabase on a single instance?', 'created_at': datetime.datetime(2024, 11, 19, 2, 15, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484564761, 'issue_id': 2660537572, 'author': 'qnkhuat', 'body': ""query analysis is unused for now, so it's just a P2. Alert not sending might be a separate one"", 'created_at': datetime.datetime(2024, 11, 19, 2, 16, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516498168, 'issue_id': 2660537572, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2024, 12, 4, 8, 12, 27, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-11-18 05:20:45 UTC): Could you give us the result of this query?
```sql
select * from qrtz_triggers;
```


Could you try creating a new alert and then running this query
```sql
select * from qrtz_triggers where trigger_name like 'metabase.task.send-pulse.trigger.{{YOUR_NEW_ALERT_ID}}%'
```
There should be one record returning.

michael-gratton (Issue Creator) on (2024-11-18 22:56:14 UTC): Sure thing:


| sched_name        | trigger_name                                        | trigger_group | job_name                                   | job_group | description                               | next_fire_time | prev_fire_time | priority | trigger_state | trigger_type | start_time    | end_time | calendar_name | misfire_instr | job_data  |
|-------------------|-----------------------------------------------------|---------------|--------------------------------------------|-----------|-------------------------------------------|----------------|----------------|----------|---------------|--------------|---------------|----------|---------------|---------------|-----------|
| MetabaseScheduler | metabase.task.anonymous-stats.trigger               | DEFAULT       | metabase.task.anonymous-stats.job          | DEFAULT   |                                           |  1731988140000 |  1731901740000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.send-pulse.trigger.111.0_0_0_*_*_?_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        6 | WAITING       | CRON         | 1721962889000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.follow-up-emails.trigger              | DEFAULT       | metabase.task.follow-up-emails.job         | DEFAULT   |                                           |  1731978000000 |  1731891600000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.58           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 58              |  1731972780000 |  1731969180000 |        5 | WAITING       | CRON         | 1683795973000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.creator-sentiment-emails.trigger      | DEFAULT       | metabase.task.creator-sentiment-emails.job | DEFAULT   |                                           |  1732287600000 |  1731682800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.update-field-values.trigger.8         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 8            |  1732042800000 |  1731956400000 |        5 | BLOCKED       | CRON         | 1659406805000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.75.0_0_9_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732053600000 |  1731967200000 |     3575 | WAITING       | CRON         | 1721862025000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.truncate-audit-tables.trigger         | DEFAULT       | metabase.task.truncate-audit-tables.job    | DEFAULT   |                                           |  1731978000000 |  1731934800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 0 bytes   |
| MetabaseScheduler | metabase.task.refresh-channel-cache.trigger         | DEFAULT       | metabase.task.refresh-channel-cache.job    | DEFAULT   |                                           |  1731981120000 |  1731966720000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 0 bytes   |
| MetabaseScheduler | metabase.task.upgrade-checks.trigger                | DEFAULT       | metabase.task.upgrade-checks.job           | DEFAULT   |                                           |  1732000500000 |  1731957300000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.PersistencePrune.scheduled.trigger    | DEFAULT       | metabase.task.PersistencePrune.job         | DEFAULT   | Prune deletable PersistInfo once per hour |  1731970800000 |  1731967200000 |        5 | WAITING       | CRON         | 1731655563000 |        0 |               |             2 | 0 bytes   |
| MetabaseScheduler | metabase.task.update-field-values.trigger.11        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 11           |  1731956400000 |  1731870000000 |        5 | BLOCKED       | CRON         | 1659406816000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.analyze-queries.trigger               | DEFAULT       | metabase.task.analyze-queries.job          | DEFAULT   |                                           |             -1 |  1731884183090 |        5 | COMPLETE      | SIMPLE       | 1731655582686 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.8            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 8               |  1731972300000 |  1731968700000 |        5 | WAITING       | CRON         | 1659320701000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.task-history-cleanup.trigger          | DEFAULT       | metabase.task.task-history-cleanup.job     | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             0 | 0 bytes   |
| MetabaseScheduler | metabase.task.send-pulse.trigger.72.0_0_8_1_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1733000400000 |  1730408400000 |     3469 | WAITING       | CRON         | 1719784930000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.63.0_0_9_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732053600000 |  1731967200000 |     3597 | WAITING       | CRON         | 1721862002000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.50.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |     3596 | WAITING       | CRON         | 1721865604000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.update-field-values.trigger.3         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 3            |  1731967200000 |  1731880800000 |        5 | BLOCKED       | CRON         | 1659320693000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.backfill-query-fields.trigger         | DEFAULT       | metabase.task.backfill-query-fields.job    | DEFAULT   |                                           |  1731979140000 |  1731964740000 |        5 | WAITING       | CRON         | 1731633453000 |        0 |               |            -1 | 0 bytes   |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.11           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 11              |  1731972600000 |  1731969000000 |        5 | WAITING       | CRON         | 1659320705000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.60.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058711000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.74.0_0_8_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732050000000 |  1731963600000 |     3531 | WAITING       | CRON         | 1720389668000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.56           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 56              |  1731972000000 |  1731968400000 |        5 | WAITING       | CRON         | 1659320696000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.update-field-values.trigger.56        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 56           |  1732039200000 |  1731952800000 |        5 | BLOCKED       | CRON         | 1659406968000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.PersistenceRefresh.database.trigger.3 | DEFAULT       | metabase.task.PersistenceRefresh.job       | DEFAULT   | Refresh models for database 3             |  1731970800000 |  1731963600000 |        5 | WAITING       | CRON         | 1731655582000 |        0 |               |             2 | 376 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.67.0_0_8_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732050000000 |  1731963600000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.110.0_0_11_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731974400000 |  1731888000000 |     3558 | WAITING       | CRON         | 1721178042000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.71.0_0_9_1_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1733004000000 |  1730412000000 |     3548 | WAITING       | CRON         | 1719788452000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.update-field-values.trigger.55        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 55           |  1731960000000 |  1731873600000 |        5 | BLOCKED       | CRON         | 1659320690000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.59           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 59              |  1731970560000 |  1731966960000 |        5 | WAITING       | CRON         | 1695701116000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.176.0_0_*_*_*_?_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1731629454000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.61.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058711000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.109.0_0_11_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731974400000 |  1731888000000 |     3554 | WAITING       | CRON         | 1721523645000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.2            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 2               |  1732046400000 |  1731960000000 |        5 | WAITING       | CRON         | 1720681039000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.update-field-values.trigger.58        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 58           |  1732028400000 |  1731942000000 |        5 | BLOCKED       | CRON         | 1687076758000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.update-field-values.trigger.2         | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 2            |  1731963600000 |  1731877200000 |        5 | BLOCKED       | CRON         | 1718930089000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.55           | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 55              |  1731971100000 |  1731967500000 |        5 | WAITING       | CRON         | 1647867550000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.112.0_0_18_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731999600000 |  1731913200000 |        6 | WAITING       | CRON         | 1722071722000 |        0 |               |             1 | 996 bytes |
| MetabaseScheduler | metabase.task.send-pulse.trigger.66.0_0_0_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732021200000 |  1731934800000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.142.0_0_9_?_*_5_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1732140000000 |  1731535200000 |        6 | WAITING       | CRON         | 1725489688000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.send-pulse.trigger.64.0_0_*_*_*_?_*   | DEFAULT       | metabase.task.send-pulses.send-pulse.job   | DEFAULT   |                                           |  1731970800000 |  1731967200000 |        6 | WAITING       | CRON         | 1718058710000 |        0 |               |             1 | 1 KB      |
| MetabaseScheduler | metabase.task.sync-and-analyze.trigger.3            | DEFAULT       | metabase.task.sync-and-analyze.job         | DEFAULT   | sync-and-analyze Database 3               |  1731970500000 |  1731966900000 |        5 | WAITING       | CRON         | 1676941133000 |        0 |               |             2 | 358 bytes |
| MetabaseScheduler | metabase.task.update-field-values.trigger.59        | DEFAULT       | metabase.task.update-field-values.job      | DEFAULT   | update-field-values Database 59           |  1732003200000 |  1731916800000 |        5 | BLOCKED       | CRON         | 1695701116000 |        0 |               |             2 | 358 bytes |



That is indeed what happened. I think the issue with the alerts is maybe unrelated, or at least perhaps worth resolving the first issue and I'll file another one if I think there is still an outstanding problem.

qnkhuat on (2024-11-19 02:15:06 UTC): everything looks normal there, are you getting this error consistently on every deployment? if so, does it happen if you run Metabase on a single instance?

qnkhuat on (2024-11-19 02:16:35 UTC): query analysis is unused for now, so it's just a P2. Alert not sending might be a separate one

github-actions[bot] on (2024-12-04 08:12:27 UTC): 🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)

"
2660429448,issue,open,,`build-ee-extra` CI action build stuff should be integrated into the Clojure build logic,"I think it's kinda unfortunate that 95% of our uberjar build logic is in Clojure code with tests and then we have a random assortment of node scripts and shell scripts to do additional build stuff like update version info or adding partner drivers to the uberjar rather than just have that live with the rest of the Clojure-based build code. 

We ran into a build issue after the recent upgrade to Java 21 for our Docker image that was super hard to debug because we were taking the EE uberjar built with the Clojure build scripts and doing a ton of weird stuff to it with shell scripts and Node scripts. It would have been easier just to build a specific `ee-extra` version in the first place or at the very least integrate this stuff into the rest of the build script code.

See https://metaboat.slack.com/archives/C5XHN8GLW/p1731616635340639?thread_ts=1731504670.951389&cid=C5XHN8GLW for more.",camsaul,2024-11-15 00:38:42+00:00,[],2025-02-04 20:23:39+00:00,,https://github.com/metabase/metabase/issues/50061,"[('.Building & Releasing', ''), ('.Team/DevEx', '')]",[],
2660090286,issue,open,,Customize homepage at the group level,"**Is your feature request related to a problem? Please describe.**
We have several clients that log into Metabase. Each customer has a set of users and we'd like to choose a different homepage to display to each set of customer users. 

**Describe the solution you'd like**
Some way to set a homepage for each user or for a specific group of users. 

**How important is this feature to you?**
This would be ergonomically really great for our customers. Right now they each have a single dashboard and it's weird to have them navigate into a collection to find it when it's the only thing have access to.

**Additional context**
Related to: https://github.com/metabase/metabase/issues/40414

But we specifically do not want user to modify their own homepage.",ixipixi,2024-11-14 21:25:20+00:00,[],2025-02-04 20:31:00+00:00,,https://github.com/metabase/metabase/issues/50057,"[('Type:New Feature', ''), ('Administration/', ''), ('Organization/Homepage', '')]","[{'comment_id': 2483451582, 'issue_id': 2660090286, 'author': 'kmanda95', 'body': 'This would be great!', 'created_at': datetime.datetime(2024, 11, 18, 15, 55, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565650623, 'issue_id': 2660090286, 'author': 'brunobergher', 'body': 'Related to #40414', 'created_at': datetime.datetime(2024, 12, 30, 15, 52, 22, tzinfo=datetime.timezone.utc)}]","kmanda95 on (2024-11-18 15:55:57 UTC): This would be great!

brunobergher on (2024-12-30 15:52:22 UTC): Related to #40414

"
2659515998,issue,open,,Card title with custom viz settings will display briefly before changing into the changed name,"### Describe the bug

If your cpu is slow the card will show the original name rather than the changed name

### To Reproduce

1) create a dashboard with 1 card
2) change the card name
3) go to the performance section of the browser and make the cpu 4x slower
4) refresh the dashboard and see the card showing the original name rather than the changed one

### Expected behavior

we should show the changed name, always

### Logs

NA

### Information about your Metabase installation

```JSON
v51
```

### Severity

P2-3

### Additional context

NA",paoliniluis,2024-11-14 17:20:22+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/50044,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2659171502,issue,closed,completed,Little cosmetic bug in GUI editor when joining tables with names of different lenghts,"### Describe the bug

When a short-named table is joined to a table that has a longer name and the table box name is larger, there's a small cosmetic bug with the editor
![Image](https://github.com/user-attachments/assets/75ee92e4-16ec-49ea-95be-b1e86c1db716)


### To Reproduce

1. Have a table with a long name and join it to a table with a shorter name


### Expected behavior

the account one in this case should adjust 

### Logs

_No response_

### Information about your Metabase installation

```JSON
- master
```

### Severity

P3

### Additional context

_No response_",ignacio-mb,2024-11-14 15:30:27+00:00,['romeovs'],2024-11-18 22:51:02+00:00,2024-11-18 10:54:44+00:00,https://github.com/metabase/metabase/issues/50038,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2658850442,issue,closed,completed,[Safari] Graphs flicker and disappear when hovered over,"### Describe the bug

When opening a dashboard in Safari, charts (specifically Area charts, though other types might also be affected) start flickering when the cursor hovers over different sections of the chart. This issue occurs only within the dashboard view and does not appear when the chart is opened individually.
![Image](https://github.com/user-attachments/assets/3361ee55-3958-4b47-9854-0d7c20fbbef7)


### To Reproduce

1. Open the dashboard containing Area charts in Safari (Ideally with 2+ categories).
2. Hover the cursor over different sections of an Area chart.
3. Observe the flickering behavior as the cursor moves over the chart

### Expected behavior

Chart animations are expected to be smooth as in individual view or in different browsers. Sections of the chart should not disappear.

### Logs

Probably irrelevant

### Information about your Metabase installation

```JSON
- Metabase v0.51.2.3 (Docker)
- Safari Version 18.1 (20619.2.8.11.10), default configuration.
- macOS 15.1 (24B83)
```

### Severity

blocking an upgrade

### Additional context

The issue seems to be partially related to the Safari inability to handle CSS d property out of the box. When the ""CSS d property"" is enabled in Safari Feature Flags, sections of charts stop disappearing completely, although color transitions are still very rough when viewing a chart within a dashboard.",rv-solomasov,2024-11-14 13:37:17+00:00,[],2025-01-30 22:16:36+00:00,2025-01-30 20:04:13+00:00,https://github.com/metabase/metabase/issues/50034,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2550887383, 'issue_id': 2658850442, 'author': 'pavelpolygalov', 'body': 'Please provide information about the plans to resolve this bug. We are unable to upgrade to the new version of Metabase because of it', 'created_at': datetime.datetime(2024, 12, 18, 9, 59, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625461413, 'issue_id': 2658850442, 'author': 'alxnddr', 'body': 'Closed by https://github.com/metabase/metabase/pull/51611', 'created_at': datetime.datetime(2025, 1, 30, 20, 4, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625712077, 'issue_id': 2658850442, 'author': 'rv-solomasov', 'body': '@alxnddr Thank you, really appreciate it! Just to be sure, am I right this should only be available in the future release?', 'created_at': datetime.datetime(2025, 1, 30, 22, 16, 35, tzinfo=datetime.timezone.utc)}]","pavelpolygalov on (2024-12-18 09:59:14 UTC): Please provide information about the plans to resolve this bug. We are unable to upgrade to the new version of Metabase because of it

alxnddr on (2025-01-30 20:04:13 UTC): Closed by https://github.com/metabase/metabase/pull/51611

rv-solomasov (Issue Creator) on (2025-01-30 22:16:35 UTC): @alxnddr Thank you, really appreciate it! Just to be sure, am I right this should only be available in the future release?

"
2658626196,issue,closed,completed,Static embedded report : click on a table column to update a dashboard filter does not work,"**Describe the bug**
Dashboard contains a table with a column you can click on to update the value of a dashboard filter.
The click correctly updates the dashboard filter in the report.
But once the dashboard is embedded (static embed) the click does not update the dashboard filter.
We have this bug in version 0.51.3 but we didn't have this bug before. I can't say in which version exactly this bug was introduced. Our prior version (without the bug) was the stable release as of October 12, so it must have been 0.50.29. So the bug must have been introduced between 0.50.29 and 0.51.3.

**Logs**
I don't have specific logs.

**To Reproduce**
Steps to reproduce the behavior:
1. Create a dashboard with a filter and a table.
2. Edit the dashboard so you can click on the value of a column in the table to update the filter.
3. Embed the report (static embed)
4. In the embedded version, try to click on the column : the filter does not get updated.

**Expected behavior**
Clicking on the column value should update the dashboard filter.

**Severity**
This is very annoying as we have embedded reports that become almost unusable. We have to copy/paste values into the filters. It's not intuitive like clicking on a value.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Debian 16.4-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1053-gke"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",SylvainGravejat,2024-11-14 12:07:54+00:00,[],2024-11-20 20:26:26+00:00,2024-11-20 20:26:24+00:00,https://github.com/metabase/metabase/issues/50028,[],"[{'comment_id': 2489481049, 'issue_id': 2658626196, 'author': 'SylvainGravejat', 'body': 'This bug is now fixed in the 0.51.4 release.', 'created_at': datetime.datetime(2024, 11, 20, 20, 26, 24, tzinfo=datetime.timezone.utc)}]","SylvainGravejat (Issue Creator) on (2024-11-20 20:26:24 UTC): This bug is now fixed in the 0.51.4 release.

"
2658617451,issue,closed,completed,hide gear button from chart type selector,"as per [feedback](https://metaboat.slack.com/archives/C0645JP1W81/p1731330796348969), remove gear icon from the viz settings sidebar and add additional section for Map settings",uladzimirdev,2024-11-14 12:03:43+00:00,['uladzimirdev'],2024-11-18 14:17:11+00:00,2024-11-18 14:17:11+00:00,https://github.com/metabase/metabase/issues/50027,[],[],
2658617245,issue,closed,completed,remove show/hide editor button in the top right corner,"as [per feedback](https://metaboat.slack.com/archives/C0645JP1W81/p1729514301211119?thread_ts=1729287596.325869&cid=C0645JP1W81), remove show/hide editor button from the qb header ",uladzimirdev,2024-11-14 12:03:38+00:00,['uladzimirdev'],2024-11-19 17:36:37+00:00,2024-11-19 17:36:37+00:00,https://github.com/metabase/metabase/issues/50026,[],[],
2658617113,issue,closed,completed,utilize SegmentControl for a new switch component,"- utilize new SegmentControl component
- move ""visualize"" button to the bottom on the editor page
- combine chart settings with viz settings in the same sidebar
- remove tabular data/visualization switch from the bottom center",uladzimirdev,2024-11-14 12:03:34+00:00,['uladzimirdev'],2024-12-30 09:20:16+00:00,2024-12-30 09:20:14+00:00,https://github.com/metabase/metabase/issues/50025,[],"[{'comment_id': 2565226090, 'issue_id': 2658617113, 'author': 'uladzimirdev', 'body': 'abandoned', 'created_at': datetime.datetime(2024, 12, 30, 9, 20, 14, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-12-30 09:20:14 UTC): abandoned

"
2658477112,issue,closed,not_planned,Filters missing for string(K),"### Describe the bug

Strings have a lot of filters ![Image](https://github.com/user-attachments/assets/63ffa1eb-845f-40bf-adbe-0ceb31b6155a)
Strings with a fixed-length, like string(255), string(40) etc only have 2 filters ![Image](https://github.com/user-attachments/assets/eecd2c83-e136-4c68-b601-64c1fba6a9c1)

I don't know if this matters but the source here is BigQuery

### To Reproduce

1. Go to a view through the Browse -> Databases -> Select a database -> Select a dataset -> Select a table
2. Click on the arrow on a string (or string(255)) column name, click on ""filter by this column"".
3. Strings will have a lot of filter options, string(255) will only have ""empty"" or ""not empty""


### Expected behavior

String and string(255) (and string(40 etc)) should have the same filter options

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.16""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.5.0-1024-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

annoying

### Additional context

_No response_",cl-juni,2024-11-14 11:12:08+00:00,[],2024-11-14 16:14:43+00:00,2024-11-14 16:14:22+00:00,https://github.com/metabase/metabase/issues/50022,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/BigQuery', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 2476834524, 'issue_id': 2658477112, 'author': 'snoe', 'body': 'This is a duplicate of https://github.com/metabase/metabase/issues/49786 fixed in 51.3', 'created_at': datetime.datetime(2024, 11, 14, 16, 14, 22, tzinfo=datetime.timezone.utc)}]","snoe on (2024-11-14 16:14:22 UTC): This is a duplicate of https://github.com/metabase/metabase/issues/49786 fixed in 51.3

"
2658387402,issue,closed,completed,Allow more properties for embedding an iframe inside a dashboard,"**Is your feature request related to a problem? Please describe.**

Currently the list of properties here doesn't support all usecases ... What I mean is that this example[example](https://www.metabase.com/docs/v0.51/dashboards/introduction#iframe-cards) provided on the Metabase website, has the following line:

`allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share""`

If I want to record the screen I need to pass the `microphone` but since that list isn't editable the iframe won't work.

More information in the thread [here](https://metaboat.slack.com/archives/C064QMXEV9N/p1730716069118009) 

**Describe the solution you'd like**
Have a way to edit this `Allowed` list manually or add more uses to it like `microphone`

**Describe alternatives you've considered**
None that are relevant 

**Additional context**
One usecase for having `microphone` -  is to analyze dashboard graphs using computer vision chatbots
",Tony-metabase,2024-11-14 10:41:12+00:00,[],2024-11-19 19:29:43+00:00,2024-11-19 18:46:09+00:00,https://github.com/metabase/metabase/issues/50020,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2658298383,issue,open,,Inconsistent API documentation,"### Describe the bug

The following endpoint:

> PUT /api/dashboard/:id
> 
> Update a Dashboard, and optionally the dashcards and tabs of a Dashboard. The request body should be a JSON object with the same structure as the response from GET /api/dashboard/:id.
> PARAMS:
> 
>     id value must be an integer greater than zero.
> 
>     dash-updates map where {:name (optional) -> , :description (optional) -> , :caveats (optional) -> , :points_of_interest (optional) -> , :show_in_getting_started (optional) -> , :enable_embedding (optional) -> , :embedding_params (optional) -> , :parameters (optional) -> <nullable sequence of parameter must be a map with :id and :type keys>, :position (optional) -> , :width (optional) -> <enum of fixed, full>, :archived (optional) -> , :collection_id (optional) -> , :collection_position (optional) -> , :cache_ttl (optional) -> , :dashcards (optional) -> , :tabs (optional) -> }.


Lists **dash-updates** as a parameter to the PUT request. The same parameter is in the examples provided in the https://{my_url}/api/docs/#put-/dashboard/-id-

```
{
  ""dash-updates"": {
    ""description"": ""string"",
    ""archived"": false,
    ""collection_position"": 1,
    ""dashcards"": [
      {
        ""id"": 0,
        ""size_x"": 1,
        ""size_y"": 1,
        ""row"": 0,
        ""col"": 0,
        ""parameter_mappings"": [
          {
            ""parameter_id"": ""A"",
            ""target"": null
          }
        ],
        ""series"": [
          {}
        ]
      }
    ],
    ""tabs"": [
      {
        ""id"": 0,
        ""name"": ""A""
      }
    ],
    ""enable_embedding"": false,
    ""collection_id"": 1,
    ""show_in_getting_started"": false,
    ""name"": ""A"",
    ""width"": ""fixed"",
    ""caveats"": ""string"",
    ""embedding_params"": {},
    ""cache_ttl"": 1,
    ""position"": null,
    ""parameters"": [
      {
        ""slug"": ""string"",
        ""default"": null,
        ""name"": ""string"",
        ""type"": ""A"",
        ""temporal_units"": [
          ""quarter""
        ],
        ""sectionId"": ""A"",
        ""values_source_type"": ""?"",
        ""id"": ""A"",
        ""values_source_config"": {
          ""values"": null,
          ""card_id"": 1,
          ""value_field"": ""?"",
          ""label_field"": ""?""
        }
      }
    ],
    ""points_of_interest"": null
  }
}
```

However, Metabase UI sends the request as a JSON with properties as root JSON items, without **dash-updates**. Example I used was changing the dashboard widtgh to full. Sending the request with dash-updates parameter creates a dashboard revision with no changes.

### To Reproduce

1. Go to a dashboard
2. Click on edit icon
3. Update dashboard width
4. Open network tab
5. Save changes
6. See request with root elements without dash-updates param

1. Attempt sending {""dash-updates"": {""width"": ""full""}} as request body via API
2. Empty revision is created


### Expected behavior

Examples in the docs work as expected

### Logs

_No response_

### Information about your Metabase installation

```JSON
v0.51.1.2
```

### Severity

Mild

### Additional context

_No response_",TLazarevic,2024-11-14 10:06:45+00:00,['thebiglabasky'],2025-02-04 20:31:10+00:00,,https://github.com/metabase/metabase/issues/50016,"[('Type:Documentation', '')]",[],
2658286171,issue,closed,completed,Parameters not passed to target question in custom click behavior,"### Describe the bug

![Image](https://github.com/user-attachments/assets/ac1199bc-b677-4086-9385-4742b0ebb837)


### To Reproduce

1. New > Question > Orders > Visualize > Save
2. Add it to dashboard
3. Configure click behavior for this dashcard: Tax > Go to a custom destination > Choose question from step 1 > Map ""Product ID"" to ""Product -> Vendor"" > Map ""Product ID"" to ""Product -> Category""
4. Save
5. Click any value in Tax column

Filters are not applied.


### Expected behavior

2 filters should be present in the ad-hoc query OR it should not be possible to create such mapping


### Information about your Metabase installation

master, 70ea4a0ab0d372288409c3738a7cf2f204541ee2

### Severity

P2
",kamilmielnik,2024-11-14 10:02:26+00:00,['kamilmielnik'],2025-01-15 10:21:28+00:00,2025-01-15 10:21:27+00:00,https://github.com/metabase/metabase/issues/50015,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/Querying', '')]","[{'comment_id': 2592241090, 'issue_id': 2658286171, 'author': 'kamilmielnik', 'body': '> Map ""Product ID"" to ""Product -> Vendor"" > Map ""Product ID"" to ""Product -> Category""\n\nIt\'s not possible to create such mapping. \n\nI can\'t reproduce it anymore, even at 70ea4a0ab0d372288409c3738a7cf2f204541ee2. I tried v51 and v52 as well.\nI remember reporting this issue while being on a feature branch though, maybe it was a temporary glitch that never really made it to `master`.\n\nClosing without repro as ""cannot reproduce"" (yes, even though I reported it).', 'created_at': datetime.datetime(2025, 1, 15, 10, 21, 27, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2025-01-15 10:21:27 UTC): It's not possible to create such mapping. 

I can't reproduce it anymore, even at 70ea4a0ab0d372288409c3738a7cf2f204541ee2. I tried v51 and v52 as well.
I remember reporting this issue while being on a feature branch though, maybe it was a temporary glitch that never really made it to `master`.

Closing without repro as ""cannot reproduce"" (yes, even though I reported it).

"
2658251892,issue,closed,completed,No padding between metabot icon and greeting text on the homepage,"### Describe the bug

![Image](https://github.com/user-attachments/assets/05d6fe9b-62bb-4ab8-9bbf-4af5a72039ce)


### To Reproduce

1. Open Metabase homepage
2. Set viewport width to 1920px or more


### Information about your Metabase installation

master, 70ea4a0ab0d372288409c3738a7cf2f204541ee2

### Severity

P3
",kamilmielnik,2024-11-14 09:50:31+00:00,[],2025-02-04 18:10:47+00:00,2025-02-04 18:10:47+00:00,https://github.com/metabase/metabase/issues/50012,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Homepage', '')]",[],
2658118483,issue,open,,Incorrect empty state of automagic dashboards on the homepage,"### Describe the bug

![Image](https://github.com/user-attachments/assets/3cb7cfd2-c8b2-4279-a97e-53151c178ed6)


### To Reproduce

1. Make GET `/api/automagic-dashboards/database/:id/candidates` return an empty array
2. Open Metabase
3. See ""Here are some explorations of ClickHouse"" label

There are no explorations



### Expected behavior

There is no ""Here are some explorations of ClickHouse"" label when there are no explorations 


### Information about your Metabase installation

master, aaedddf828

### Severity

P2
",kamilmielnik,2024-11-14 09:06:45+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/50011,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/X-rays', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2657911784,issue,closed,completed,SaveQuestionForm sdk component's save button is not equal in size with cancel,"The save button is using Mantine while the cancel button is using the legacy button component, so the button height is a little bit different.

<img src=""https://github.com/user-attachments/assets/7dded585-f2c2-44a6-a6bf-b22d08d753c8"" width=""200"">

You can especially notice that the two buttons _cancel_ and _save_ isn't equal in size when the save button is in a disabled state.

<img src=""https://github.com/user-attachments/assets/77804c04-c89b-46f7-b0ff-38433c20a991"" width=""200"">

",heypoom,2024-11-14 07:38:08+00:00,['heypoom'],2025-01-27 14:51:06+00:00,2025-01-23 05:55:27+00:00,https://github.com/metabase/metabase/issues/50010,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2657909556,issue,closed,completed,onSave and onBeforeSave does not get called after a question is created in SaveQuestionForm sdk component,"The `onSave` and `onBeforeSave` props on `<InteractiveQuestion />` never gets called even after the save button shows Success. This is because it internally calls `onCreate` and we don't call those handlers there, and we don't expose `onCreate`. We should make sure both `onSave` and `onBeforeSave` are called on question created.

We should also create an end-to-end test for this scenario.",heypoom,2024-11-14 07:36:47+00:00,['heypoom'],2024-11-19 14:47:39+00:00,2024-11-19 13:46:31+00:00,https://github.com/metabase/metabase/issues/50008,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2657857956,issue,closed,completed,Support saving to existing questions in the SaveQuestionForm sdk component,"We should look into whether the `<InteractiveQuestion.SaveQuestionForm />` sdk component supports saving existing questions, not only saving to new questions. It seems like saving new questions doesn't always work.",heypoom,2024-11-14 07:23:01+00:00,[],2025-01-13 17:17:15+00:00,2025-01-13 17:16:52+00:00,https://github.com/metabase/metabase/issues/50007,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2587714659, 'issue_id': 2657857956, 'author': 'heypoom', 'body': 'We already supported that via ""Replace original question""\n\n![Image](https://github.com/user-attachments/assets/10b8e349-4ab7-4eb2-a278-492833bec709)', 'created_at': datetime.datetime(2025, 1, 13, 17, 16, 52, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2025-01-13 17:16:52 UTC): We already supported that via ""Replace original question""

![Image](https://github.com/user-attachments/assets/10b8e349-4ab7-4eb2-a278-492833bec709)

"
2657854256,issue,open,,Support saving to existing questions in SaveQuestionForm sdk component,"The `SaveQuestionForm` component can only save new questions at the moment, but it isn't able to save and modify existing questions. The save modal is able to do this, so we should support the same ability in `SaveQuestionForm` too.",heypoom,2024-11-14 07:20:39+00:00,[],2025-02-04 20:25:56+00:00,,https://github.com/metabase/metabase/issues/50006,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2657849473,issue,closed,completed,Rename onClose to onCancel in SaveQuestionForm sdk component,"The onClose prop on SaveQuestionForm is called only when the cancel button is clicked on, and not when saving the question has succeeded. We should rename this prop to **onCancel** instead so it's more clear that it won't be called on save success.",heypoom,2024-11-14 07:17:35+00:00,['heypoom'],2024-12-04 12:35:56+00:00,2024-12-04 12:35:56+00:00,https://github.com/metabase/metabase/issues/50005,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2657801233,issue,closed,completed,[Epic] Polish the SDK for GA,"**Links**
- product doc: https://www.notion.so/metabase/Polish-the-SDK-for-GA-13869354c90180da932cf9f78207f2c6

***API Breaking Changes***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/48870
``` 

***Bugs***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/50398
- [ ] https://github.com/metabase/metabase/issues/49466
- [ ] https://github.com/metabase/metabase/issues/51846
- [ ] https://github.com/metabase/metabase/issues/49581
- [ ] https://github.com/metabase/metabase/issues/51906
- [ ] https://github.com/metabase/metabase/issues/51680
- [ ] https://github.com/metabase/metabase/issues/52511
- [ ] https://github.com/metabase/metabase/issues/51904
```

**UX Improvements**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/45766
- [ ] https://github.com/metabase/metabase/issues/47562
- [ ] https://github.com/metabase/metabase/issues/49711
- [ ] https://github.com/metabase/metabase/issues/47564
- [ ] https://github.com/metabase/metabase/issues/49581
- [ ] https://github.com/metabase/metabase/issues/51099
```

**Theming improvements**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/47559
- [ ] https://github.com/metabase/metabase/issues/47560
- [ ] https://github.com/metabase/metabase/issues/50394
- [ ] https://github.com/metabase/metabase/issues/45764
- [ ] https://github.com/metabase/metabase/issues/47567
- [ ] https://github.com/metabase/metabase/issues/52027
- [ ] https://github.com/metabase/metabase/issues/50010
- [ ] https://github.com/metabase/metabase/issues/52261
```

**Developer Experience**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/51100
- [ ] https://github.com/metabase/metabase-private/issues/262
- [ ] https://github.com/metabase/metabase/issues/51628
```

**Ugly console & terminal errors**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/48499
- [ ] https://github.com/metabase/metabase/issues/48498
- [ ] https://github.com/metabase/metabase/issues/48497
```

**Improve creating and saving questions**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/50008
```

**Documentation**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/49762
- [ ] https://github.com/metabase/metabase/issues/51790
```

**Pending Requirements**

***Related Epics***
- https://github.com/metabase/metabase/issues/49713",heypoom,2024-11-14 06:49:54+00:00,['heypoom'],2025-02-05 17:47:37+00:00,2025-02-05 17:47:36+00:00,https://github.com/metabase/metabase/issues/50002,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2657606365,issue,open,,"""plot the average upvotes per month"" errors out","go to https://stats.metabase.com/model/6117-pull-request
ask ""plot the average upvotes per month"" 
error",perivamsi,2024-11-14 05:12:28+00:00,[],2024-11-14 05:12:29+00:00,,https://github.com/metabase/metabase/issues/50000,[],[],
2657598756,issue,open,,"""which month had the highest number of pull requests"" errors out","go to https://stats.metabase.com/model/6117-pull-request
ask ""which month had the highest number of pull requests""
errors out",perivamsi,2024-11-14 05:07:08+00:00,[],2024-11-14 05:07:09+00:00,,https://github.com/metabase/metabase/issues/49999,[],[],
2657594342,issue,open,,"""how many bugs are there?"" produces incorrect query","go to 
ask ""how many bugs are there?""
it does a [simple count](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiYWdncmVnYXRpb24iOltbImNvdW50Il1dLCJzb3VyY2UtdGFibGUiOiJjYXJkX182MTEzIn19LCJkaXNwbGF5IjoidGFibGUiLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6e30sIm9yaWdpbmFsX2NhcmRfaWQiOjYxMTMsInR5cGUiOiJxdWVzdGlvbiJ9) without adding a filter for is_bug",perivamsi,2024-11-14 05:03:30+00:00,[],2024-11-14 05:03:31+00:00,,https://github.com/metabase/metabase/issues/49998,[],[],
2657588976,issue,open,,"""which repository has the highest number of issues?"" errors out","go to https://stats.metabase.com/model/6113-issue
ask ""which repository has the highest number of issues?""
errors out with ""I'm currently offline, try again later.""",perivamsi,2024-11-14 04:58:54+00:00,[],2024-11-14 04:58:55+00:00,,https://github.com/metabase/metabase/issues/49997,[],[],
2657572868,issue,open,,"""what is the revenue in November 2024"" produces incorrect query","got to https://stats.metabase.com/model/14023-monthly-revenue-customer
ask ""what is the revenue in November 2024""
I expect break out by ""recognized at"", aggregated by ""amount""
It does this

![Image](https://github.com/user-attachments/assets/7f9b7beb-b9e8-492c-b9fd-10ce7a2d2ecf)
",perivamsi,2024-11-14 04:46:32+00:00,[],2024-11-14 04:47:43+00:00,,https://github.com/metabase/metabase/issues/49996,[],[],
2657529492,issue,open,,"""who is the highest paying customer?"" errors out with max loops","go to https://stats.metabase.com/model/14023-monthly-revenue-customer
ask ""who is the highest paying customer""
you get ""I'm currently offline, try again later.""

",perivamsi,2024-11-14 04:33:36+00:00,[],2024-11-14 04:33:37+00:00,,https://github.com/metabase/metabase/issues/49995,[],[],
2657520671,issue,open,,"""show me top 10 customers by ARR"" sorts by ARR asc instead of ARR desc","Go to https://stats.metabase.com/model/14023-monthly-revenue-customer
Ask metabot ""show me top 10 customers by ARR"" 
It takes you [to this query ](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiYWdncmVnYXRpb24iOltbInN1bSIsWyJmaWVsZCIsImFyciIseyJiYXNlLXR5cGUiOiJ0eXBlL0Zsb2F0In1dXV0sImJyZWFrb3V0IjpbWyJmaWVsZCIsImN1c3RvbWVyX25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dXSwib3JkZXItYnkiOltbImFzYyIsWyJhZ2dyZWdhdGlvbiIsMF1dXSwibGltaXQiOjEwLCJzb3VyY2UtdGFibGUiOiJjYXJkX18xNDAyMyJ9fSwiZGlzcGxheSI6InRhYmxlIiwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnt9LCJvcmlnaW5hbF9jYXJkX2lkIjoxNDAyMywidHlwZSI6InF1ZXN0aW9uIn0=)",perivamsi,2024-11-14 04:24:50+00:00,['ranquild'],2024-11-14 04:30:45+00:00,,https://github.com/metabase/metabase/issues/49994,[],[],
2657505659,issue,open,,Too many roundtrips is showing as Metabot being offline,,perivamsi,2024-11-14 04:09:12+00:00,[],2024-11-14 04:10:31+00:00,,https://github.com/metabase/metabase/issues/49993,[],"[{'comment_id': 2475374316, 'issue_id': 2657505659, 'author': 'perivamsi', 'body': '![Image](https://github.com/user-attachments/assets/316f08f3-6e53-4051-97d5-751e4cb88103)', 'created_at': datetime.datetime(2024, 11, 14, 4, 10, 30, tzinfo=datetime.timezone.utc)}]","perivamsi (Issue Creator) on (2024-11-14 04:10:30 UTC): ![Image](https://github.com/user-attachments/assets/316f08f3-6e53-4051-97d5-751e4cb88103)

"
2657413398,issue,open,,Render multi-value search filter results inline in the filter popover instead of in a second popover.,"[project doc](https://www.notion.so/metabase/Render-the-multi-select-dropdown-inline-in-the-filter-value-select-13d69354c9018079a272c3beb19cb82b)

**Is your feature request related to a problem? Please describe.**

We introduced the multi autocomplete component for filters in v51, but are getting some complaints that the double popover is distracting and hard to work with. We should render the results inline instead.

![Image](https://github.com/user-attachments/assets/a753dbb6-98d2-4262-9643-eb2ed3fa38f7)



**Describe the solution you'd like**
Render the results inline. The rest of the functionality should remain the same.

![Image](https://github.com/user-attachments/assets/b679eba9-c78a-4be4-935c-a92dab07cfb7)
",romeovs,2024-11-14 03:06:47+00:00,['romeovs'],2025-02-04 20:30:43+00:00,,https://github.com/metabase/metabase/issues/49992,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('Querying/', '')]",[],
2656958219,issue,open,,Allow choosing column for gauge (Gauge Requires a Number),"**Is your feature request related to a problem? Please describe.**
We are getting an error Gauge Requires a Number because we are grouping by a text column for the gauge and gauge automatically grabs the first column. You also cant change the order of a group by and summarize columns.





**Describe the solution you'd like**
We should be able to choose the column to display just like the number tile.
Same with Progress chart.


**Describe alternatives you've considered**
Need to remove the text column and reduce the usability of the question

**How important is this feature to you?**

**Additional context**
Add any other context or screenshots about the feature request here.
",mnetkin,2024-11-13 22:08:56+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/49989,"[('Visualization/', ''), ('Type:New Feature', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('Administration/Settings', '')]",[],
2656810317,issue,closed,completed,Sandboxing using a parameterized SQL card errors until an admin runs the sandboxing card successfully for the first time,"### Describe the bug

Breaking this out from https://github.com/metabase/metabase/issues/49969

When a non-admin user attempts to query a table with sandboxing applied via a parameterized SQL question, they encounter the error: `Current context not Array but root`. The error appears if the question has not yet been successfully executed with a parameter value. Once an admin user runs the parameterized question successfully with a parameter, the non-admin query works without issue.

Investigation so far:
The error seems to be coming from the `.writeEndArray` method on the `com.fasterxml.jackson.core.JsonGenerator` object, used in streaming results back to the client. `begin!` on the `StreamingResultsWriter` doesn't seem to be called properly, so when `finish!` is called, it's trying to terminate a JSON array that was never started. 

Not sure yet why `begin!` doesn't get called in this case, or why running the card as an admin fixes it.

### To Reproduce

1. As an admin, create and save a SQL question like `select * from products where category = {{cat}}`. Don't run the question with template
2. Create a non-admin test user and give them the attribute `cat = Gizmo`
3. Sandbox the non-admin user on the Products table, using the SQL question as the source, and link the user's `cat` attribute with the template tag
4. Log in as the non-admin and try to run an ad-hoc query over the Products table. You should get the error `Current context not Array but root`
5. As the admin, run the SQL question again with a parameter value
6. As the non-admin, run the ad-hoc query again. It should now succeed.
7. As the admin, edit the SQL question in any way and re-save it, without re-running it. Now it will be broken again for the non-admin.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master (4418173684) but repros at least back to 51.3
```

### Severity

Unsure about p1 or p2

### Additional context

_No response_",noahmoss,2024-11-13 21:15:31+00:00,['noahmoss'],2024-11-15 21:52:52+00:00,2024-11-15 21:09:43+00:00,https://github.com/metabase/metabase/issues/49985,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2474900289, 'issue_id': 2656810317, 'author': 'noahmoss', 'body': ""Seems to be same same root cause as https://github.com/metabase/metabase/issues/38888\n\n`query_metadata` on the card is `[]` if the card hasn't yet been run successfully, and that (somehow) triggers this error."", 'created_at': datetime.datetime(2024, 11, 13, 21, 54, 45, tzinfo=datetime.timezone.utc)}]","noahmoss (Issue Creator) on (2024-11-13 21:54:45 UTC): Seems to be same same root cause as https://github.com/metabase/metabase/issues/38888

`query_metadata` on the card is `[]` if the card hasn't yet been run successfully, and that (somehow) triggers this error.

"
2656650480,issue,open,,Paying Metabase customers that aren't admins should be directed on where to get help,"In the product, when you go to Help:
* If you are a paying customer and a Metabase admin, we take you to a page where you can contact Success Engineering.
* If you are an OSS user, we take you to a help page with other resources
* If you are a paying customer, and not a Metabase admin, you get the same experience as an OSS user

This is confusing because the OSS page has some wording about ""Looking for more hands-on support?  Explore paid plans""  But you already have a paid plan.  And you don't know where to go to help",cbalusek,2024-11-13 20:10:42+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/49983,"[('Type:New Feature', ''), ('Administration/Troubleshooting', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2474690874, 'issue_id': 2656650480, 'author': 'cbalusek', 'body': 'One potential solution is https://github.com/metabase/metabase/issues/49980', 'created_at': datetime.datetime(2024, 11, 13, 20, 10, 57, tzinfo=datetime.timezone.utc)}]","cbalusek (Issue Creator) on (2024-11-13 20:10:57 UTC): One potential solution is https://github.com/metabase/metabase/issues/49980

"
2656631632,issue,closed,completed,Faster sync with describe-indexes,Implement a faster sync with `describe-indexes` that follows `describe-fields` and `describe-fks` to allow for a database wide sync step rather per table `describe-table-indexes`,snoe,2024-11-13 19:59:56+00:00,['snoe'],2024-12-09 23:49:28+00:00,2024-12-06 21:31:37+00:00,https://github.com/metabase/metabase/issues/49981,"[('.Team/Drivers', '')]",[],
2656631031,issue,open,,"Show ""email for help requests"" when a paying customer that isn't an admin hits the help page","Current, we surface different help pages for OSS users and paying customers.  

If you are a paying customer and an admin, you get a giant button that says ""Contact Support"" which goes to Metabase success engineering.

If you are a paying customer and not an admin, you get the same help page that OSS users get which is confusing  

If you are a paying customer and not an admin, you should get the help page paying admins get, but the button should be reworded and the button destination should be the email from the ""email address for help requests"" setting

",cbalusek,2024-11-13 19:59:35+00:00,[],2025-02-04 20:30:24+00:00,,https://github.com/metabase/metabase/issues/49980,"[('Type:New Feature', ''), ('Administration/Troubleshooting', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2486714033, 'issue_id': 2656631031, 'author': 'luizarakaki', 'body': 'Proposed solution:\n\n- Paid, non-admin user clicks on Help in the gear menu\n- They are redirected to `/help/premium-regular-user?contact={{email_address_help_requests}}`\n- The page is exactly the same as `https://www.metabase.com/help/premium` but instead of `Contact Support` we show `Contact internal help` (not sure about the copy of this button) with `mailto:{{email_address_help_requests}}`', 'created_at': datetime.datetime(2024, 11, 19, 20, 43, 56, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-11-19 20:43:56 UTC): Proposed solution:

- Paid, non-admin user clicks on Help in the gear menu
- They are redirected to `/help/premium-regular-user?contact={{email_address_help_requests}}`
- The page is exactly the same as `https://www.metabase.com/help/premium` but instead of `Contact Support` we show `Contact internal help` (not sure about the copy of this button) with `mailto:{{email_address_help_requests}}`

"
2656381004,issue,closed,completed,"Exporting pivots to XLSX with ""Keep Data Pivoted"" selected can Crash Metabase (Heap memory error) and pegs CPU","### Describe the bug

Exporting Pivots to XLSX can eat memory and can cause the JVM to crash. 

### To Reproduce

1. Set up v51.1 locally with 1GB RAM
2. Create a pivot with accounts and invoices that has a handful of breakouts (Loom recording below)
3. Export to XLSX with ""Keep Data Pivoted"" selected
4. Metabase crashed with OOM error


https://www.loom.com/share/9446d6efe8af4bba8ebc23b322c8d3e6

### Expected behavior

We [recommend deploying with 1G](https://www.metabase.com/learn/metabase-basics/administration/administration-and-operation/metabase-in-production#metabase-application-server-size) for every 20 concurrent users so I wouldn't expect to to hit heap memory in this case. The pivot table wasn't very large:


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""sqlserver"",
      ""mysql"",
      ""oracle"",
      ""databricks""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

blocking upgrade

### Additional context

Customer that initially reported this is running on 2GB and sees their instances crash intermittently with pivot exports. They want to upgrade to the next minor release to see some other patches but they're concerned about moving to a version where exporting these files pivoted is the default behavior given these crashes.",ixipixi,2024-11-13 18:21:41+00:00,"['alexander-yakushev', 'noahmoss']",2025-01-27 19:28:09+00:00,2025-01-27 17:37:08+00:00,https://github.com/metabase/metabase/issues/49977,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables'), ('Querying/Pivot', 'Queries that generate pivot tables')]","[{'comment_id': 2477094397, 'issue_id': 2656381004, 'author': 'Tony-metabase', 'body': 'Note that this is also impacting the CPU ...When i try to download this pivot now  [question on stats](https://stats.metabase.com/question/20344-large-pivots-break-download-tony)\nIt seems I am able to bring stats down\n\n\n![Image](https://github.com/user-attachments/assets/7fcda101-92f0-45d8-b8c2-e5ca9ad120fb)\n\nThis was me pressing that download pivot button (Keep Formatting) .... I guess we reached the CPU limit and kubernetes was killing the pod.', 'created_at': datetime.datetime(2024, 11, 14, 18, 8, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520415154, 'issue_id': 2656381004, 'author': 'sgarbesi', 'body': 'running into the same issue on the latest version of Metabase.\nanytime we try to export a CSV with a pivot and formatting, the server memory jumps to 8GB and crashes.\nusing the latest version of Metabase.\n\n@ixipixi did you ever come up with a resolution to this?', 'created_at': datetime.datetime(2024, 12, 5, 14, 3, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520532241, 'issue_id': 2656381004, 'author': 'paoliniluis', 'body': '@sgarbesi what\'s the ""latest version"" for you?', 'created_at': datetime.datetime(2024, 12, 5, 14, 50, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525868104, 'issue_id': 2656381004, 'author': 'sgarbesi', 'body': '@paoliniluis 0.51.6.1', 'created_at': datetime.datetime(2024, 12, 8, 13, 20, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527318303, 'issue_id': 2656381004, 'author': 'paoliniluis', 'body': '@sgarbesi try with 51.7', 'created_at': datetime.datetime(2024, 12, 9, 9, 0, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533016759, 'issue_id': 2656381004, 'author': 'pmcmanaman', 'body': ""@paoliniluis We've updated to v0.52.1.3 and still see the same issue"", 'created_at': datetime.datetime(2024, 12, 10, 22, 3, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546632900, 'issue_id': 2656381004, 'author': 'sgarbesi', 'body': '@paoliniluis anything we can provide that may help?', 'created_at': datetime.datetime(2024, 12, 16, 20, 13, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547249704, 'issue_id': 2656381004, 'author': 'paoliniluis', 'body': ""@sgarbesi @pmcmanaman please send us:\n- sizing of the container (also how much memory the process gets on start)\n- logs\n- environment variables used (we're interested in the ones that modify the api response and the downloads)\n- the size of the data and the pivot table (how massive is the query)"", 'created_at': datetime.datetime(2024, 12, 17, 0, 35, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562875990, 'issue_id': 2656381004, 'author': 'pmcmanaman', 'body': '@paoliniluis \n- The container gets at least 3CPU and 8GB of memory with limits of 4CPU and 16GB.\n- logs below\n- no environment variables, so just default\n\n```\n2024-12-26 15:09:21,354 ERROR middleware.process-userland-query :: Error saving field usages\nclojure.lang.ExceptionInfo: Unknown type of ref {:ref [:contains {:case-sensitive false, :effective-type :type/Boolean, :lib/uuid ""ff904e48-203f-4d62-a7f9-a5a8c5588ad5""} [:field {:base-type :type/Text, :lib/uuid ""90052ad0-f81e-4564-a128-41eb19671b00""} ""subscription_plan_name""] [:value {:effective_type :type/Text, :base-type :type/Text, :effective-type :type/Text, :lib/uuid ""aefa5b8a-ff9f-43f4-af1e-ea92f9c3f4bb""} ""gold""]]}\n\tat metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:308)\n\tat metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)\n\tat metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:321)\n\tat metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)\n\tat metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:311)\n\tat metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)\n\tat metabase.lib.filter$filter_parts32794__32795.invokeStatic(filter.cljc:552)\n\tat metabase.lib.filter$filter_parts32794__32795.invoke(filter.cljc:540)\n\tat metabase.models.field_usage$filter__GT_field_usage.invokeStatic(field_usage.clj:29)\n\tat metabase.models.field_usage$filter__GT_field_usage.invoke(field_usage.clj:27)\n\tat metabase.models.field_usage$stage__GT_field_usages$fn__78326.invoke(field_usage.clj:76)\n\tat clojure.core$keep$fn__8691.invoke(core.clj:7529)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$concat$fn__5577.invoke(core.clj:727)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$concat$cat__5579$fn__5580.invoke(core.clj:736)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.lockAndForce(LazySeq.java:60)\n\tat clojure.lang.LazySeq.sval(LazySeq.java:69)\n\tat clojure.lang.LazySeq.unwrap(LazySeq.java:77)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:93)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$map$fn__5954.invoke(core.clj:2763)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$concat$cat__5579$fn__5580.invoke(core.clj:736)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.lockAndForce(LazySeq.java:60)\n\tat clojure.lang.LazySeq.sval(LazySeq.java:69)\n\tat clojure.lang.LazySeq.unwrap(LazySeq.java:77)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:93)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$map$fn__5954.invoke(core.clj:2763)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core$dorun.invokeStatic(core.clj:3141)\n\tat clojure.core$doall.invokeStatic(core.clj:3156)\n\tat clojure.walk$walk.invokeStatic(walk.clj:47)\n\tat clojure.walk$prewalk.invokeStatic(walk.clj:65)\n\tat clojure.walk$prewalk.invoke(walk.clj:61)\n\tat clojure.core$partial$fn__5927.invoke(core.clj:2641)\n\tat clojure.core$map$fn__5954.invoke(core.clj:2772)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.Cons.next(Cons.java:41)\n\tat clojure.lang.RT.next(RT.java:733)\n\tat clojure.core$next__5470.invokeStatic(core.clj:64)\n\tat clojure.core$dorun.invokeStatic(core.clj:3150)\n\tat clojure.core$doall.invokeStatic(core.clj:3156)\n\tat clojure.walk$walk.invokeStatic(walk.clj:47)\n\tat clojure.walk$prewalk.invokeStatic(walk.clj:65)\n\tat clojure.walk$prewalk.invoke(walk.clj:61)\n\tat clojure.core$partial$fn__5927.invoke(core.clj:2641)\n\tat clojure.walk$walk.invokeStatic(walk.clj:46)\n\tat clojure.walk$prewalk.invokeStatic(walk.clj:65)\n\tat clojure.walk$prewalk.invoke(walk.clj:61)\n\tat clojure.core$partial$fn__5927.invoke(core.clj:2641)\n\tat clojure.core$map$fn__5954.invoke(core.clj:2772)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.Cons.next(Cons.java:41)\n\tat clojure.lang.RT.next(RT.java:733)\n\tat clojure.core$next__5470.invokeStatic(core.clj:64)\n\tat clojure.core.protocols$fn__8275.invokeStatic(protocols.clj:168)\n\tat clojure.core.protocols$fn__8275.invoke(protocols.clj:123)\n\tat clojure.core.protocols$fn__8229$G__8224__8238.invoke(protocols.clj:19)\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\n\tat clojure.core.protocols$fn__8262.invokeStatic(protocols.clj:74)\n\tat clojure.core.protocols$fn__8262.invoke(protocols.clj:74)\n\tat clojure.core.protocols$fn__8203$G__8198__8216.invoke(protocols.clj:13)\n\tat clojure.core$reduce.invokeStatic(core.clj:6965)\n\tat clojure.core$into.invokeStatic(core.clj:7038)\n\tat clojure.walk$walk.invokeStatic(walk.clj:50)\n\tat clojure.walk$prewalk.invokeStatic(walk.clj:65)\n\tat clojure.walk$prewalk.invoke(walk.clj:61)\n\tat clojure.core$partial$fn__5927.invoke(core.clj:2641)\n\tat clojure.core$map$fn__5954.invoke(core.clj:2770)\n\tat clojure.lang.LazySeq.force(LazySeq.java:50)\n\tat clojure.lang.LazySeq.realize(LazySeq.java:89)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:106)\n\tat clojure.lang.RT.seq(RT.java:555)\n\tat clojure.core$seq__5486.invokeStatic(core.clj:139)\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)\n\tat clojure.core.protocols$fn__8262.invokeStatic(protocols.clj:74)\n\tat clojure.core.protocols$fn__8262.invoke(protocols.clj:74)\n\tat clojure.core.protocols$fn__8203$G__8198__8216.invoke(protocols.clj:13)\n\tat clojure.core$reduce.invokeStatic(core.clj:6965)\n\tat clojure.core$into.invokeStatic(core.clj:7038)\n\tat clojure.walk$walk.invokeStatic(walk.clj:50)\n\tat clojure.walk$prewalk.invokeStatic(walk.clj:65)\n\tat clojure.walk$prewalk.invoke(walk.clj:61)\n\tat toucan2.util$add_context_to_ex_data$fn__22416.invoke(util.clj:53)\n\tat clojure.core$update.invokeStatic(core.clj:6259)\n\tat clojure.core$update.invoke(core.clj:6251)\n\tat toucan2.util$add_context_to_ex_data.invokeStatic(util.clj:51)\n\tat toucan2.util$add_context_to_ex_data.invoke(util.clj:50)\n\tat toucan2.util$fn__22422.invokeStatic(util.clj:78)\n\tat toucan2.util$fn__22422.invoke(util.clj:72)\n\tat toucan2.util$fn__22402$G__22397__22409.invoke(util.clj:47)\n\tat toucan2.query$parse_args_with_spec.invokeStatic(query.clj:69)\n\tat toucan2.query$parse_args_with_spec.invoke(query.clj:66)\n\tat toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invokeStatic(insert.clj:35)\n\tat toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invoke(insert.clj:32)\n\tat methodical.impl.combo.common$partial_STAR_$fn__19388.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)\n\tat toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:315)\n\tat toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311)\n\tat toucan2.pipeline$transduce_unparsed_with_default_rf.invokeStatic(pipeline.clj:374)\n\tat toucan2.pipeline$transduce_unparsed_with_default_rf.invoke(pipeline.clj:368)\n\tat toucan2.insert$insert_BANG_.invokeStatic(insert.clj:124)\n\tat toucan2.insert$insert_BANG_.doInvoke(insert.clj:74)\n\tat clojure.lang.RestFn.invoke(RestFn.java:424)\n\tat metabase.query_processor.middleware.process_userland_query$fn__78349$fn__78350$fn__78351.invoke(process_userland_query.clj:43)\n\tat grouper.core$body_fn$fn__62202.invoke(core.clj:72)\n\tat grouper.core$start_BANG_$thread__62245.invoke(core.clj:135)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.base/java.lang.Thread.run(Unknown Source)\n```', 'created_at': datetime.datetime(2024, 12, 26, 15, 11, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562884909, 'issue_id': 2656381004, 'author': 'Tony-metabase', 'body': '@pmcmanaman one important factor missing there. What about the size of the data and the pivot table (how massive is the query)', 'created_at': datetime.datetime(2024, 12, 26, 15, 23, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562897577, 'issue_id': 2656381004, 'author': 'pmcmanaman', 'body': '@Tony-metabase \n1 pivot rows\n8 pivot columns\n31920 rows', 'created_at': datetime.datetime(2024, 12, 26, 15, 42, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562974220, 'issue_id': 2656381004, 'author': 'paoliniluis', 'body': ""@pmcmanaman if you're using the defaults then there's a problem, since Metabase will use just 1/4 of the RAM of the server and if it goes above a certain threshold the CPU will start doing garbage collection aggresively. Have you seen https://www.metabase.com/docs/latest/troubleshooting-guide/running#allocating-more-memory-to-the-jvm?"", 'created_at': datetime.datetime(2024, 12, 26, 17, 31, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563934479, 'issue_id': 2656381004, 'author': 'pmcmanaman', 'body': '@paoliniluis This happens when the JVM has a large amount of RAM\n\n2024-12-27 18:18:14,606 INFO metabase.util :: Maximum memory available to JVM: 8.0 GB', 'created_at': datetime.datetime(2024, 12, 27, 18, 25, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603404506, 'issue_id': 2656381004, 'author': 'paoliniluis', 'body': ""@pmcmanaman just reproduced ON CSV'S, did you hit it on Excels? do you download these on xlsx or csv?"", 'created_at': datetime.datetime(2025, 1, 21, 0, 29, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605242562, 'issue_id': 2656381004, 'author': 'dpsutton', 'body': 'In profiling, I found the CSV export did an enormous amount of work in `metabase.query-processor.pivot.postprocess/build-pivot-output`.', 'created_at': datetime.datetime(2025, 1, 21, 16, 45, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605303371, 'issue_id': 2656381004, 'author': 'alexander-yakushev', 'body': 'Oh no, not pivot again:).', 'created_at': datetime.datetime(2025, 1, 21, 17, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616709951, 'issue_id': 2656381004, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52.8](https://github.com/metabase/metabase/milestone/302)', 'created_at': datetime.datetime(2025, 1, 27, 19, 28, 7, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-11-14 18:08:27 UTC): Note that this is also impacting the CPU ...When i try to download this pivot now  [question on stats](https://stats.metabase.com/question/20344-large-pivots-break-download-tony)
It seems I am able to bring stats down


![Image](https://github.com/user-attachments/assets/7fcda101-92f0-45d8-b8c2-e5ca9ad120fb)

This was me pressing that download pivot button (Keep Formatting) .... I guess we reached the CPU limit and kubernetes was killing the pod.

sgarbesi on (2024-12-05 14:03:44 UTC): running into the same issue on the latest version of Metabase.
anytime we try to export a CSV with a pivot and formatting, the server memory jumps to 8GB and crashes.
using the latest version of Metabase.

@ixipixi did you ever come up with a resolution to this?

paoliniluis on (2024-12-05 14:50:19 UTC): @sgarbesi what's the ""latest version"" for you?

sgarbesi on (2024-12-08 13:20:17 UTC): @paoliniluis 0.51.6.1

paoliniluis on (2024-12-09 09:00:31 UTC): @sgarbesi try with 51.7

pmcmanaman on (2024-12-10 22:03:51 UTC): @paoliniluis We've updated to v0.52.1.3 and still see the same issue

sgarbesi on (2024-12-16 20:13:17 UTC): @paoliniluis anything we can provide that may help?

paoliniluis on (2024-12-17 00:35:42 UTC): @sgarbesi @pmcmanaman please send us:
- sizing of the container (also how much memory the process gets on start)
- logs
- environment variables used (we're interested in the ones that modify the api response and the downloads)
- the size of the data and the pivot table (how massive is the query)

pmcmanaman on (2024-12-26 15:11:22 UTC): @paoliniluis 
- The container gets at least 3CPU and 8GB of memory with limits of 4CPU and 16GB.
- logs below
- no environment variables, so just default

```
2024-12-26 15:09:21,354 ERROR middleware.process-userland-query :: Error saving field usages
clojure.lang.ExceptionInfo: Unknown type of ref {:ref [:contains {:case-sensitive false, :effective-type :type/Boolean, :lib/uuid ""ff904e48-203f-4d62-a7f9-a5a8c5588ad5""} [:field {:base-type :type/Text, :lib/uuid ""90052ad0-f81e-4564-a128-41eb19671b00""} ""subscription_plan_name""] [:value {:effective_type :type/Text, :base-type :type/Text, :effective-type :type/Text, :lib/uuid ""aefa5b8a-ff9f-43f4-af1e-ea92f9c3f4bb""} ""gold""]]}
	at metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:308)
	at metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)
	at metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:321)
	at metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)
	at metabase.lib.equality$find_matching_column31939__31942.invokeStatic(equality.cljc:311)
	at metabase.lib.equality$find_matching_column31939__31942.invoke(equality.cljc:264)
	at metabase.lib.filter$filter_parts32794__32795.invokeStatic(filter.cljc:552)
	at metabase.lib.filter$filter_parts32794__32795.invoke(filter.cljc:540)
	at metabase.models.field_usage$filter__GT_field_usage.invokeStatic(field_usage.clj:29)
	at metabase.models.field_usage$filter__GT_field_usage.invoke(field_usage.clj:27)
	at metabase.models.field_usage$stage__GT_field_usages$fn__78326.invoke(field_usage.clj:76)
	at clojure.core$keep$fn__8691.invoke(core.clj:7529)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$concat$fn__5577.invoke(core.clj:727)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$concat$cat__5579$fn__5580.invoke(core.clj:736)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.lockAndForce(LazySeq.java:60)
	at clojure.lang.LazySeq.sval(LazySeq.java:69)
	at clojure.lang.LazySeq.unwrap(LazySeq.java:77)
	at clojure.lang.LazySeq.realize(LazySeq.java:93)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$map$fn__5954.invoke(core.clj:2763)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$concat$cat__5579$fn__5580.invoke(core.clj:736)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.lockAndForce(LazySeq.java:60)
	at clojure.lang.LazySeq.sval(LazySeq.java:69)
	at clojure.lang.LazySeq.unwrap(LazySeq.java:77)
	at clojure.lang.LazySeq.realize(LazySeq.java:93)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$map$fn__5954.invoke(core.clj:2763)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core$dorun.invokeStatic(core.clj:3141)
	at clojure.core$doall.invokeStatic(core.clj:3156)
	at clojure.walk$walk.invokeStatic(walk.clj:47)
	at clojure.walk$prewalk.invokeStatic(walk.clj:65)
	at clojure.walk$prewalk.invoke(walk.clj:61)
	at clojure.core$partial$fn__5927.invoke(core.clj:2641)
	at clojure.core$map$fn__5954.invoke(core.clj:2772)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.Cons.next(Cons.java:41)
	at clojure.lang.RT.next(RT.java:733)
	at clojure.core$next__5470.invokeStatic(core.clj:64)
	at clojure.core$dorun.invokeStatic(core.clj:3150)
	at clojure.core$doall.invokeStatic(core.clj:3156)
	at clojure.walk$walk.invokeStatic(walk.clj:47)
	at clojure.walk$prewalk.invokeStatic(walk.clj:65)
	at clojure.walk$prewalk.invoke(walk.clj:61)
	at clojure.core$partial$fn__5927.invoke(core.clj:2641)
	at clojure.walk$walk.invokeStatic(walk.clj:46)
	at clojure.walk$prewalk.invokeStatic(walk.clj:65)
	at clojure.walk$prewalk.invoke(walk.clj:61)
	at clojure.core$partial$fn__5927.invoke(core.clj:2641)
	at clojure.core$map$fn__5954.invoke(core.clj:2772)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.Cons.next(Cons.java:41)
	at clojure.lang.RT.next(RT.java:733)
	at clojure.core$next__5470.invokeStatic(core.clj:64)
	at clojure.core.protocols$fn__8275.invokeStatic(protocols.clj:168)
	at clojure.core.protocols$fn__8275.invoke(protocols.clj:123)
	at clojure.core.protocols$fn__8229$G__8224__8238.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8262.invokeStatic(protocols.clj:74)
	at clojure.core.protocols$fn__8262.invoke(protocols.clj:74)
	at clojure.core.protocols$fn__8203$G__8198__8216.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6965)
	at clojure.core$into.invokeStatic(core.clj:7038)
	at clojure.walk$walk.invokeStatic(walk.clj:50)
	at clojure.walk$prewalk.invokeStatic(walk.clj:65)
	at clojure.walk$prewalk.invoke(walk.clj:61)
	at clojure.core$partial$fn__5927.invoke(core.clj:2641)
	at clojure.core$map$fn__5954.invoke(core.clj:2770)
	at clojure.lang.LazySeq.force(LazySeq.java:50)
	at clojure.lang.LazySeq.realize(LazySeq.java:89)
	at clojure.lang.LazySeq.seq(LazySeq.java:106)
	at clojure.lang.RT.seq(RT.java:555)
	at clojure.core$seq__5486.invokeStatic(core.clj:139)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
	at clojure.core.protocols$fn__8262.invokeStatic(protocols.clj:74)
	at clojure.core.protocols$fn__8262.invoke(protocols.clj:74)
	at clojure.core.protocols$fn__8203$G__8198__8216.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6965)
	at clojure.core$into.invokeStatic(core.clj:7038)
	at clojure.walk$walk.invokeStatic(walk.clj:50)
	at clojure.walk$prewalk.invokeStatic(walk.clj:65)
	at clojure.walk$prewalk.invoke(walk.clj:61)
	at toucan2.util$add_context_to_ex_data$fn__22416.invoke(util.clj:53)
	at clojure.core$update.invokeStatic(core.clj:6259)
	at clojure.core$update.invoke(core.clj:6251)
	at toucan2.util$add_context_to_ex_data.invokeStatic(util.clj:51)
	at toucan2.util$add_context_to_ex_data.invoke(util.clj:50)
	at toucan2.util$fn__22422.invokeStatic(util.clj:78)
	at toucan2.util$fn__22422.invoke(util.clj:72)
	at toucan2.util$fn__22402$G__22397__22409.invoke(util.clj:47)
	at toucan2.query$parse_args_with_spec.invokeStatic(query.clj:69)
	at toucan2.query$parse_args_with_spec.invoke(query.clj:66)
	at toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invokeStatic(insert.clj:35)
	at toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invoke(insert.clj:32)
	at methodical.impl.combo.common$partial_STAR_$fn__19388.invoke(common.clj:12)
	at methodical.util.FnWithMeta.invoke(util.clj:46)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)
	at toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:315)
	at toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311)
	at toucan2.pipeline$transduce_unparsed_with_default_rf.invokeStatic(pipeline.clj:374)
	at toucan2.pipeline$transduce_unparsed_with_default_rf.invoke(pipeline.clj:368)
	at toucan2.insert$insert_BANG_.invokeStatic(insert.clj:124)
	at toucan2.insert$insert_BANG_.doInvoke(insert.clj:74)
	at clojure.lang.RestFn.invoke(RestFn.java:424)
	at metabase.query_processor.middleware.process_userland_query$fn__78349$fn__78350$fn__78351.invoke(process_userland_query.clj:43)
	at grouper.core$body_fn$fn__62202.invoke(core.clj:72)
	at grouper.core$start_BANG_$thread__62245.invoke(core.clj:135)
	at clojure.lang.AFn.run(AFn.java:22)
	at java.base/java.lang.Thread.run(Unknown Source)
```

Tony-metabase on (2024-12-26 15:23:57 UTC): @pmcmanaman one important factor missing there. What about the size of the data and the pivot table (how massive is the query)

pmcmanaman on (2024-12-26 15:42:30 UTC): @Tony-metabase 
1 pivot rows
8 pivot columns
31920 rows

paoliniluis on (2024-12-26 17:31:15 UTC): @pmcmanaman if you're using the defaults then there's a problem, since Metabase will use just 1/4 of the RAM of the server and if it goes above a certain threshold the CPU will start doing garbage collection aggresively. Have you seen https://www.metabase.com/docs/latest/troubleshooting-guide/running#allocating-more-memory-to-the-jvm?

pmcmanaman on (2024-12-27 18:25:49 UTC): @paoliniluis This happens when the JVM has a large amount of RAM

2024-12-27 18:18:14,606 INFO metabase.util :: Maximum memory available to JVM: 8.0 GB

paoliniluis on (2025-01-21 00:29:02 UTC): @pmcmanaman just reproduced ON CSV'S, did you hit it on Excels? do you download these on xlsx or csv?

dpsutton on (2025-01-21 16:45:55 UTC): In profiling, I found the CSV export did an enormous amount of work in `metabase.query-processor.pivot.postprocess/build-pivot-output`.

alexander-yakushev (Assginee) on (2025-01-21 17:11:55 UTC): Oh no, not pivot again:).

github-actions[bot] on (2025-01-27 19:28:07 UTC): 🚀 This should also be released by [v0.52.8](https://github.com/metabase/metabase/milestone/302)

"
2656241566,issue,closed,completed,Add Data box is showing in version 50.33 and should not be in 50 at all,"### Describe the bug

The ""Add data"" box is appearing in 50

![Image](https://github.com/user-attachments/assets/94981e3b-40ed-429a-8fbe-49d32eab8e68)
![Image](https://github.com/user-attachments/assets/fd6bc910-30a9-4f2b-b7f3-a3b7bf2edc93)


### To Reproduce

1.  Upgrade or install 50.33 or 50.32
2. Log in

### Expected behavior

This shouldn't appear

### Logs

_No response_

### Information about your Metabase installation

```JSON
Chrome, v 1.50.33

Reported by a customer on 1.50.32 as well
```

### Severity

P1

### Additional context

New UI features should not appear for customer when they take a minor release, which is why I am labeling as a P1 or escalation",cbalusek,2024-11-13 17:29:27+00:00,['nemanjaglumac'],2024-11-14 14:01:55+00:00,2024-11-14 14:01:39+00:00,https://github.com/metabase/metabase/issues/49973,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Escalation', '')]","[{'comment_id': 2474297602, 'issue_id': 2656241566, 'author': 'cbalusek', 'body': 'more context  https://metaboat.slack.com/archives/C013N8XL286/p1730480254654209', 'created_at': datetime.datetime(2024, 11, 13, 17, 34, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476433010, 'issue_id': 2656241566, 'author': 'nemanjaglumac', 'body': 'Resolved by #49984', 'created_at': datetime.datetime(2024, 11, 14, 14, 1, 39, tzinfo=datetime.timezone.utc)}]","cbalusek (Issue Creator) on (2024-11-13 17:34:41 UTC): more context  https://metaboat.slack.com/archives/C013N8XL286/p1730480254654209

nemanjaglumac (Assginee) on (2024-11-14 14:01:39 UTC): Resolved by #49984

"
2656147205,issue,closed,completed,Get cloud able to sync the attached datawarehouses,"I restored the `api/notify` endpoints. But this is not _quite_ enough: they don't know the db-id of the `metabase_database.is_attached_dwh` db.

See https://www.notion.so/metabase/Magic-Google-Sheets-integration-with-MB-Cloud-12e69354c90180289a2bd8f764382c2f?pvs=4#13b69354c90180dfb9c0fca5521bbd07 for more information",dpsutton,2024-11-13 16:52:48+00:00,[],2024-11-14 14:49:57+00:00,2024-11-14 14:07:40+00:00,https://github.com/metabase/metabase/issues/49971,[],[],
2656089012,issue,closed,completed,Block perms incorrectly block queries are sandboxed based on a native card,"### Describe the bug

Advanced Sandboxing is Broken on 51

### To Reproduce

1. Go to New People -> Add Person -> Give attribute product with value as Gizmo

![Image](https://github.com/user-attachments/assets/8282ce53-5004-461a-8c67-fdbd30707194)

2. Create new SQL question which will be used for sandboxing ->  

```
Select orders.* from orders
JOIN products on orders.product_id = products.id
WHERE Category = {{category}}
```

![Image](https://github.com/user-attachments/assets/2b4bb26d-3327-432c-8e93-7e05f451f874)


3. Go to permission -> All Users -> Products -> Assign the above question to the Orders table (assign the create queries with query builder to the products table) -> Save

![Image](https://github.com/user-attachments/assets/1486f522-9812-4245-8787-ef3497d71d4b)

![Image](https://github.com/user-attachments/assets/4fb8b130-1980-4697-b720-c19f53864381)



4. Login with the Sandboxed user and try to access the Orders table from the browse data. You will notice this works! 

5. Now go to new question -> Select the Orders Table -> Check that the preview works (and it works)

![Image](https://github.com/user-attachments/assets/38107451-9cb9-41f0-9893-f44dac2d0567)

6. Save the Question and then refresh the page. The moment you refresh the page you get:

![Image](https://github.com/user-attachments/assets/996dea4f-4dd2-4adb-b70d-f90b952d0481)

Even if the Admin created a question from the orders table this question will load with the above error. So things are very strange here

### Expected behavior

The Question should load since it's properly sandboxed

### Logs

<details>
<summary> expand to see logs </summary>

```
[c2abaa4e-b380-4b88-8f1f-930adebdd5dc] 2024-11-13T17:37:38+01:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: You do not have permissions to run this query.
{:database_id 1,
 :started_at #t ""2024-11-13T17:37:38.863542+01:00[Europe/Malta]"",
 :action_id nil,
 :error_type :missing-required-permissions,
 :json_query
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :middleware
  {:js-int-to-string? true, :ignore-cached-results? false, :process-viz-settings? false, :userland-query? true},
  :cache-strategy nil,
  :viz-settings {},
  :database 1,
  :query {:source-table 5},
  :parameters []},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> metabase_enterprise.advanced_permissions.models.permissions.block_permissions$throw_block_permissions_exception.invokeStatic(block_permissions.clj:14)""
  ""metabase_enterprise.advanced_permissions.models.permissions.block_permissions$throw_block_permissions_exception.invoke(block_permissions.clj:12)""
  ""metabase_enterprise.advanced_permissions.models.permissions.block_permissions$fn__119130$check_block_permissions__119132.invoke(block_permissions.clj:34)""
  ""public_settings.premium_features$dynamic_ee_oss_fn$fn__57112.doInvoke(premium_features.clj:615)""
  ""query_processor.middleware.permissions$check_query_permissions_STAR_73942__73944.invokeStatic(permissions.clj:115)""
  ""query_processor.middleware.permissions$check_query_permissions_STAR_73942__73944.invoke(permissions.clj:99)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__73971.invoke(permissions.clj:146)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__113843$check_download_permissions__113844$fn__113845.invoke(permissions.clj:91)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74682.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__115782$maybe_apply_column_level_perms_check__115783$fn__115784.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74692.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute77011__77012$fn__77013.invoke(execute.clj:94)""
  ""query_processor.setup$do_with_qp_setup75207__75208.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup75207__75208.invoke(setup.clj:216)""
  ""query_processor.execute$execute77011__77012.invokeStatic(execute.clj:93)""
  ""query_processor.execute$execute77011__77012.invoke(execute.clj:89)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__87801$handle_audit_app_internal_queries__87802$fn__87803.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74720.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware77867__77868$fn__77869.invoke(process_userland_query.clj:204)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions77932__77933$fn__77934.invoke(catch_exceptions.clj:132)""
  ""query_processor$process_query77973__77974$fn__77975.invoke(query_processor.clj:80)""
  ""query_processor.setup$do_with_canceled_chan75202__75203$fn__75204.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings75195__75196$fn__75197.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver75188__75189$fn__75190$fn__75191.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:106)""
  ""driver$do_with_driver.invoke(driver.clj:101)""
  ""query_processor.setup$do_with_driver75188__75189$fn__75190.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider75179__75180$fn__75181$fn__75184.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider58714__58715.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider58714__58715.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider58714__58715.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider58714__58715.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider75179__75180$fn__75181.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database75169__75170$fn__75171.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup75207__75208.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup75207__75208.invoke(setup.clj:216)""
  ""query_processor$process_query77973__77974.invokeStatic(query_processor.clj:78)""
  ""query_processor$process_query77973__77974.invoke(query_processor.clj:71)""
  ""query_processor.card$process_query_for_card_default_qp89650__89651.invokeStatic(card.clj:186)""
  ""query_processor.card$process_query_for_card_default_qp89650__89651.invoke(card.clj:182)""
  ""query_processor.card$process_query_for_card_default_run_fn$fn__89653$fn__89654.invoke(card.clj:193)""
  ""query_processor.streaming$_streaming_response$fn__61545$fn__61546$fn__61547.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__61545$fn__61546.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__61545.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__53198.invoke(streaming_response.clj:97)""],
 :card_id 112,
 :context :question,
 :error ""You do not have permissions to run this query."",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :metabase.models.query.permissions/perms
  {:gtaps {:perms/create-queries :query-builder-and-native, :perms/view-data :unrestricted}},
  :type :query,
  :middleware
  {:js-int-to-string? true, :ignore-cached-results? false, :process-viz-settings? false, :userland-query? true},
  :viz-settings {},
  :metabase-enterprise.sandbox.query-processor.middleware.row-level-restrictions/original-metadata
  [{:description
    ""This is a unique ID for the product. It is also called the “Invoice number” or “Confirmation number” in customer facing emails and screens."",
    :database_type ""BIGINT"",
    :semantic_type :type/PK,
    :table_id 5,
    :coercion_strategy nil,
    :name ""ID"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 37 nil],
    :effective_type :type/BigInteger,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 37,
    :position 0,
    :visibility_type :normal,
    :display_name ""ID"",
    :fingerprint nil,
    :base_type :type/BigInteger}
   {:description
    ""The id of the user who made this order. Note that in some cases where an order was created on behalf of a customer who phoned the order in, this might be the employee who handled the request."",
    :database_type ""INTEGER"",
    :semantic_type :type/FK,
    :table_id 5,
    :coercion_strategy nil,
    :name ""USER_ID"",
    :settings nil,
    :source :fields,
    :fk_target_field_id 46,
    :field_ref [:field 43 nil],
    :effective_type :type/Integer,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 43,
    :position 1,
    :visibility_type :normal,
    :display_name ""User ID"",
    :fingerprint {:global {:distinct-count 929, :nil% 0.0}},
    :base_type :type/Integer}
   {:description ""The product ID. This is an internal identifier for the product, NOT the SKU."",
    :database_type ""INTEGER"",
    :semantic_type :type/FK,
    :table_id 5,
    :coercion_strategy nil,
    :name ""PRODUCT_ID"",
    :settings nil,
    :source :fields,
    :fk_target_field_id 62,
    :field_ref [:field 40 nil],
    :effective_type :type/Integer,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 40,
    :position 2,
    :visibility_type :normal,
    :display_name ""Product ID"",
    :fingerprint {:global {:distinct-count 200, :nil% 0.0}},
    :base_type :type/Integer}
   {:description
    ""The raw, pre-tax cost of the order. Note that this might be different in the future from the product price due to promotions, credits, etc."",
    :database_type ""DOUBLE PRECISION"",
    :semantic_type nil,
    :table_id 5,
    :coercion_strategy nil,
    :name ""SUBTOTAL"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 44 nil],
    :effective_type :type/Float,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 44,
    :position 3,
    :visibility_type :normal,
    :display_name ""Subtotal"",
    :fingerprint
    {:global {:distinct-count 340, :nil% 0.0},
     :type
     {:type/Number
      {:min 15.691943673970439,
       :q1 49.74894519060184,
       :q3 105.42965746993103,
       :max 148.22900526552291,
       :sd 32.53705013056317,
       :avg 77.01295465356547}}},
    :base_type :type/Float}
   {:description
    ""This is the amount of local and federal taxes that are collected on the purchase. Note that other governmental fees on some products are not included here, but instead are accounted for in the subtotal."",
    :database_type ""DOUBLE PRECISION"",
    :semantic_type nil,
    :table_id 5,
    :coercion_strategy nil,
    :name ""TAX"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 38 nil],
    :effective_type :type/Float,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 38,
    :position 4,
    :visibility_type :normal,
    :display_name ""Tax"",
    :fingerprint
    {:global {:distinct-count 797, :nil% 0.0},
     :type
     {:type/Number
      {:min 0.0,
       :q1 2.273340386603857,
       :q3 5.337275338216307,
       :max 11.12,
       :sd 2.3206651358900316,
       :avg 3.8722100000000004}}},
    :base_type :type/Float}
   {:description ""The total billed amount."",
    :database_type ""DOUBLE PRECISION"",
    :semantic_type nil,
    :table_id 5,
    :coercion_strategy nil,
    :name ""TOTAL"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 42 nil],
    :effective_type :type/Float,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 42,
    :position 5,
    :visibility_type :normal,
    :display_name ""Total"",
    :fingerprint
    {:global {:distinct-count 4426, :nil% 0.0},
     :type
     {:type/Number
      {:min 8.93914247937167,
       :q1 51.34535490743823,
       :q3 110.29428389265787,
       :max 159.34900526552292,
       :sd 34.26469575709948,
       :avg 80.35871658771228}}},
    :base_type :type/Float}
   {:description ""Discount amount."",
    :database_type ""DOUBLE PRECISION"",
    :semantic_type :type/Discount,
    :table_id 5,
    :coercion_strategy nil,
    :name ""DISCOUNT"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 36 nil],
    :effective_type :type/Float,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 36,
    :position 6,
    :visibility_type :normal,
    :display_name ""Discount"",
    :fingerprint
    {:global {:distinct-count 701, :nil% 0.898},
     :type
     {:type/Number
      {:min 0.17088996672584322,
       :q1 2.9786226681458743,
       :q3 7.338187788658235,
       :max 61.69684269960571,
       :sd 3.053663125001991,
       :avg 5.161255547580326}}},
    :base_type :type/Float}
   {:description ""The date and time an order was submitted."",
    :database_type ""TIMESTAMP"",
    :semantic_type :type/CreationTimestamp,
    :table_id 5,
    :coercion_strategy nil,
    :name ""CREATED_AT"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 41 nil],
    :effective_type :type/DateTime,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 41,
    :position 7,
    :visibility_type :normal,
    :display_name ""Created At"",
    :fingerprint
    {:global {:distinct-count 10001, :nil% 0.0},
     :type {:type/DateTime {:earliest ""2022-04-30T18:56:13.352Z"", :latest ""2026-04-19T14:07:15.657Z""}}},
    :base_type :type/DateTime}
   {:description ""Number of products bought."",
    :database_type ""INTEGER"",
    :semantic_type :type/Quantity,
    :table_id 5,
    :coercion_strategy nil,
    :name ""QUANTITY"",
    :settings nil,
    :source :fields,
    :fk_target_field_id nil,
    :field_ref [:field 39 nil],
    :effective_type :type/Integer,
    :active true,
    :nfc_path nil,
    :parent_id nil,
    :id 39,
    :position 8,
    :visibility_type :normal,
    :display_name ""Quantity"",
    :fingerprint
    {:global {:distinct-count 62, :nil% 0.0},
     :type
     {:type/Number
      {:min 0.0, :q1 1.755882607764982, :q3 4.882654507928044, :max 100.0, :sd 4.214258386403798, :avg 3.7015}}},
    :base_type :type/Integer}],
  :info {:executed-by 2, :context :question, :card-id 112, :card-name ""Orders""},
  :database 1,
  :query
  {:fields
   [[:field 37 nil]
    [:field 43 nil]
    [:field 40 nil]
    [:field 44 nil]
    [:field 38 nil]
    [:field 42 nil]
    [:field 36 nil]
    [:field 41 nil]
    [:field 39 nil]],
   :source-query
   {:params [""Gizmo""],
    :native ""Select orders.* from orders\nJOIN products on orders.product_id = products.id\nWHERE Category = ?""},
   :source-metadata
   [{:description
     ""This is a unique ID for the product. It is also called the “Invoice number” or “Confirmation number” in customer facing emails and screens."",
     :database_type ""BIGINT"",
     :semantic_type :type/PK,
     :table_id 5,
     :name ""ID"",
     :source :fields,
     :field_ref [:field 37 nil],
     :effective_type :type/BigInteger,
     :active true,
     :id 37,
     :position 0,
     :visibility_type :normal,
     :display_name ""ID"",
     :base_type :type/BigInteger}
    {:description
     ""The id of the user who made this order. Note that in some cases where an order was created on behalf of a customer who phoned the order in, this might be the employee who handled the request."",
     :database_type ""INTEGER"",
     :semantic_type :type/FK,
     :table_id 5,
     :name ""USER_ID"",
     :source :fields,
     :fk_target_field_id 46,
     :field_ref [:field 43 nil],
     :effective_type :type/Integer,
     :active true,
     :id 43,
     :position 1,
     :visibility_type :normal,
     :display_name ""User ID"",
     :fingerprint {:global {:distinct-count 929, :nil% 0.0}},
     :base_type :type/Integer}
    {:description ""The product ID. This is an internal identifier for the product, NOT the SKU."",
     :database_type ""INTEGER"",
     :semantic_type :type/FK,
     :table_id 5,
     :name ""PRODUCT_ID"",
     :source :fields,
     :fk_target_field_id 62,
     :field_ref [:field 40 nil],
     :effective_type :type/Integer,
     :active true,
     :id 40,
     :position 2,
     :visibility_type :normal,
     :display_name ""Product ID"",
     :fingerprint {:global {:distinct-count 200, :nil% 0.0}},
     :base_type :type/Integer}
    {:description
     ""The raw, pre-tax cost of the order. Note that this might be different in the future from the product price due to promotions, credits, etc."",
     :database_type ""DOUBLE PRECISION"",
     :table_id 5,
     :name ""SUBTOTAL"",
     :source :fields,
     :field_ref [:field 44 nil],
     :effective_type :type/Float,
     :active true,
     :id 44,
     :position 3,
     :visibility_type :normal,
     :display_name ""Subtotal"",
     :fingerprint
     {:global {:distinct-count 340, :nil% 0.0},
      :type
      {:type/Number
       {:min 15.691943673970439,
        :q1 49.74894519060184,
        :q3 105.42965746993103,
        :max 148.22900526552291,
        :sd 32.53705013056317,
        :avg 77.01295465356547}}},
     :base_type :type/Float}
    {:description
     ""This is the amount of local and federal taxes that are collected on the purchase. Note that other governmental fees on some products are not included here, but instead are accounted for in the subtotal."",
     :database_type ""DOUBLE PRECISION"",
     :table_id 5,
     :name ""TAX"",
     :source :fields,
     :field_ref [:field 38 nil],
     :effective_type :type/Float,
     :active true,
     :id 38,
     :position 4,
     :visibility_type :normal,
     :display_name ""Tax"",
     :fingerprint
     {:global {:distinct-count 797, :nil% 0.0},
      :type
      {:type/Number
       {:min 0.0,
        :q1 2.273340386603857,
        :q3 5.337275338216307,
        :max 11.12,
        :sd 2.3206651358900316,
        :avg 3.8722100000000004}}},
     :base_type :type/Float}
    {:description ""The total billed amount."",
     :database_type ""DOUBLE PRECISION"",
     :table_id 5,
     :name ""TOTAL"",
     :source :fields,
     :field_ref [:field 42 nil],
     :effective_type :type/Float,
     :active true,
     :id 42,
     :position 5,
     :visibility_type :normal,
     :display_name ""Total"",
     :fingerprint
     {:global {:distinct-count 4426, :nil% 0.0},
      :type
      {:type/Number
       {:min 8.93914247937167,
        :q1 51.34535490743823,
        :q3 110.29428389265787,
        :max 159.34900526552292,
        :sd 34.26469575709948,
        :avg 80.35871658771228}}},
     :base_type :type/Float}
    {:description ""Discount amount."",
     :database_type ""DOUBLE PRECISION"",
     :semantic_type :type/Discount,
     :table_id 5,
     :name ""DISCOUNT"",
     :source :fields,
     :field_ref [:field 36 nil],
     :effective_type :type/Float,
     :active true,
     :id 36,
     :position 6,
     :visibility_type :normal,
     :display_name ""Discount"",
     :fingerprint
     {:global {:distinct-count 701, :nil% 0.898},
      :type
      {:type/Number
       {:min 0.17088996672584322,
        :q1 2.9786226681458743,
        :q3 7.338187788658235,
        :max 61.69684269960571,
        :sd 3.053663125001991,
        :avg 5.161255547580326}}},
     :base_type :type/Float}
    {:description ""The date and time an order was submitted."",
     :database_type ""TIMESTAMP"",
     :semantic_type :type/CreationTimestamp,
     :table_id 5,
     :name ""CREATED_AT"",
     :source :fields,
     :field_ref [:field 41 nil],
     :effective_type :type/DateTime,
     :active true,
     :id 41,
     :position 7,
     :visibility_type :normal,
     :display_name ""Created At"",
     :fingerprint
     {:global {:distinct-count 10001, :nil% 0.0},
      :type {:type/DateTime {:earliest ""2022-04-30T18:56:13.352Z"", :latest ""2026-04-19T14:07:15.657Z""}}},
     :base_type :type/DateTime}
    {:description ""Number of products bought."",
     :database_type ""INTEGER"",
     :semantic_type :type/Quantity,
     :table_id 5,
     :name ""QUANTITY"",
     :source :fields,
     :field_ref [:field 39 nil],
     :effective_type :type/Integer,
     :active true,
     :id 39,
     :position 8,
     :visibility_type :normal,
     :display_name ""Quantity"",
     :fingerprint
     {:global {:distinct-count 62, :nil% 0.0},
      :type
      {:type/Number
       {:min 0.0, :q1 1.755882607764982, :q3 4.882654507928044, :max 100.0, :sd 4.214258386403798, :avg 3.7015}}},
     :base_type :type/Integer}],
   :limit 2000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :ex-data
 {:type :missing-required-permissions,
  :actual-permissions
  #{""/collection/2/""
    ""/collection/namespace/snippets/root/""
    ""/collection/1/""
    ""/collection/root/""
    ""/application/subscription/""
    ""/collection/6/""},
  :permissions-error? true},
 :data {:rows [], :cols []}}
```

</details>

### Information about your Metabase installation

```JSON
51.3 (doesn't happen on 50.33)
```

### Severity

Blocker cause it breaks Advanced serialization

### Additional context

_No response_",Tony-metabase,2024-11-13 16:39:57+00:00,['noahmoss'],2024-11-20 20:03:18+00:00,2024-11-14 15:08:49+00:00,https://github.com/metabase/metabase/issues/49969,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2474170785, 'issue_id': 2656089012, 'author': 'Tony-metabase', 'body': 'For who picks this up cause there is no need to open a separate issue and copy paste the replication. If you go to `Step 2` above and change the filter from an Input list to a dropdown list it breaks everything with the below:\n\n![Image](https://github.com/user-attachments/assets/c123097e-8383-4e36-a0b2-a61ac0848b77)\n\nWe need to fix this as well', 'created_at': datetime.datetime(2024, 11, 13, 16, 46, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474397774, 'issue_id': 2656089012, 'author': 'noahmoss', 'body': 'To clarify: this is specifically about a sandbox with a native source card, where other tables in the DB have table-level block set up.', 'created_at': datetime.datetime(2024, 11, 13, 18, 19, 8, tzinfo=datetime.timezone.utc)}]","Tony-metabase (Issue Creator) on (2024-11-13 16:46:40 UTC): For who picks this up cause there is no need to open a separate issue and copy paste the replication. If you go to `Step 2` above and change the filter from an Input list to a dropdown list it breaks everything with the below:

![Image](https://github.com/user-attachments/assets/c123097e-8383-4e36-a0b2-a61ac0848b77)

We need to fix this as well

noahmoss (Assginee) on (2024-11-13 18:19:08 UTC): To clarify: this is specifically about a sandbox with a native source card, where other tables in the DB have table-level block set up.

"
2656083406,issue,closed,not_planned,Charts in Outlook subscriptions are huge impacting readability,"[More context](https://www.notion.so/metabase/Monthly-Product-Advocate-Summary-13669354c901808cad1bca0d5881b8eb?pvs=4#13869354c901800290c6dfd63239e83d)

[Grain video](https://metaboat.slack.com/archives/C064QSP4FNU/p1731508185209809?thread_ts=1731460905.927609&cid=C064QSP4FNU)

Running on 50.26",cdeweyx,2024-11-13 16:37:26+00:00,['adam-james-v'],2024-11-13 16:43:27+00:00,2024-11-13 16:43:27+00:00,https://github.com/metabase/metabase/issues/49968,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2474154774, 'issue_id': 2656083406, 'author': 'paoliniluis', 'body': 'Dupe of https://github.com/metabase/metabase/issues/6874?', 'created_at': datetime.datetime(2024, 11, 13, 16, 40, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474161480, 'issue_id': 2656083406, 'author': 'cdeweyx', 'body': ""Yeah dupe, I'll close this and re-open the old issue"", 'created_at': datetime.datetime(2024, 11, 13, 16, 43, 14, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-13 16:40:35 UTC): Dupe of https://github.com/metabase/metabase/issues/6874?

cdeweyx (Issue Creator) on (2024-11-13 16:43:14 UTC): Yeah dupe, I'll close this and re-open the old issue

"
2655699226,issue,open,,Add ability to remove clauses in the query tool,"**Context**


- issue links: _related issues if any_

",ranquild,2024-11-13 14:30:39+00:00,['ranquild'],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/49961,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2655698067,issue,open,,Migrate some of viz tools to no context / small context,"**Context**


- issue links: _related issues if any_

",ranquild,2024-11-13 14:30:16+00:00,['ranquild'],2025-02-04 20:23:54+00:00,,https://github.com/metabase/metabase/issues/49960,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2655510312,issue,closed,completed,"Serialization Import Fails with Unique Constraint Error on ""idx_unique_field""","### Describe the bug

Importing via CLI works the first time then subsequently fails.

`ERROR: duplicate key value violates unique constraint ""idx_unique_field""\n  Detail: Key (name, table_id, unique_field_helper)=(71788a7e-3c0e-474c-bdd0-a94f452ab583, 74, 397) already exists.\n  caused by: ERROR: duplicate key value violates unique constraint ""idx_unique_field""\n  Detail: Key (name, table_id, unique_field_helper)=(71788a7e-3c0e-474c-bdd0-a94f452ab583, 74, 397) already exists.`

### To Reproduce

I don't have clear reproduction steps yet but it seems like the 1st customer reporting is using MongoDB. They tested 50.27 and 50.32. They generate an export, then run import via CLI. It runs without error the first time. Import a second time and they hit this error.

### Expected behavior

Serialization should work.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Customer tested in 50.27 and 50.32
```

### Severity

Blocking for customer has has a Deliverable this Week

### Additional context

_No response_",ixipixi,2024-11-13 13:22:26+00:00,[],2024-11-14 21:34:10+00:00,2024-11-14 21:32:17+00:00,https://github.com/metabase/metabase/issues/49958,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2477454546, 'issue_id': 2655510312, 'author': 'ixipixi', 'body': 'Not a bug - resolved with the customer.', 'created_at': datetime.datetime(2024, 11, 14, 21, 34, 8, tzinfo=datetime.timezone.utc)}]","ixipixi (Issue Creator) on (2024-11-14 21:34:08 UTC): Not a bug - resolved with the customer.

"
2655450893,issue,open,,Downloaded pivot table grand totals with cumulative sums don't match in-product behavior,"### Describe the bug

When creating a question that uses the cumulative sum feature for a column and attempting to visualize it in a Pivot Table, the column total does not display correctly. Instead of showing the sum of all rows in the column, it appears to return the value of the last row.

![Image](https://github.com/user-attachments/assets/cd9b4c54-be9b-41ff-902b-95f501083a36)


### To Reproduce

1. Click ""New"" -> ""Question""
2. Select Sample Database - Orders as your starting data
3. Summarize using cumulative sum of the total column and group by day using the created at column
4. Click visualize and select ""Pivot Table"", make sure ""Show column totals"" is enabled.
5. The grand total at the bottom is not correct


### Expected behavior

The grand total should show the summed value of the column for all rows in the resultset. 
In the example above it should show a total of ""44 716,64"" instead of ""11 609,16""

If you export the resultset as an .xlsx and tick the checkbox for ""Keep data pivoted"" it appears to contain the correct grand totals.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v1.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.8 (Debian 14.8-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.0-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Annoying

### Additional context

_No response_",andreasenberg,2024-11-13 13:07:35+00:00,['noahmoss'],2025-02-04 20:29:48+00:00,,https://github.com/metabase/metabase/issues/49957,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]","[{'comment_id': 2512257076, 'issue_id': 2655450893, 'author': 'cdeweyx', 'body': ""I think the in-product behavior is actually correct, unless @andreasenberg you can share more about your use case? I'm struggling to understand when it would be beneficial to sum all cumulative sums.\n\nFor now, I'm changing this to a P2 and re-centering this issue around the download not matching in-product behavior."", 'created_at': datetime.datetime(2024, 12, 2, 17, 40, 11, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-12-02 17:40:11 UTC): I think the in-product behavior is actually correct, unless @andreasenberg you can share more about your use case? I'm struggling to understand when it would be beneficial to sum all cumulative sums.

For now, I'm changing this to a P2 and re-centering this issue around the download not matching in-product behavior.

"
2655315140,issue,closed,not_planned,"administration role get error 'Sorry, you don’t have permission to see that.'","### Describe the bug

i have metabase version v0.50.11 and i have administration access but on root collection and some questions i get 'Sorry, you don’t have permission to see that.'
i checked all permissions and log but i couldnt find any thing that can change to fix this.
can you help me to find the problem plz.

### To Reproduce

GET /api/collection/root 403 8.1 ms (2 DB calls) {:metabase-user-id 102} 
""You don't have permissions to do that.""



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
metabase version v0.50.11 
postgres version 15.3
```

### Severity

blocking some users

### Additional context

_No response_",negahsol,2024-11-13 12:25:20+00:00,[],2024-12-02 02:30:05+00:00,2024-12-02 02:30:04+00:00,https://github.com/metabase/metabase/issues/49952,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2473542989, 'issue_id': 2655315140, 'author': 'paoliniluis', 'body': ""Please send the permission structure screenshot where we can clearly see if you're an administrator or not"", 'created_at': datetime.datetime(2024, 11, 13, 12, 55, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473606232, 'issue_id': 2655315140, 'author': 'negahsol', 'body': '![Image](https://github.com/user-attachments/assets/f28dba72-dec4-41c9-978a-26cc14cd1a1e)\n in postgresql database\n![Image](https://github.com/user-attachments/assets/5382d05f-92eb-430d-b1f8-4112fa697438)\nin metabase UI', 'created_at': datetime.datetime(2024, 11, 13, 13, 21, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474348481, 'issue_id': 2655315140, 'author': 'npfitz', 'body': '@negahsol Are you able to go to the permissions page, and check collection permissions for ""Our Analytics""? The route should look like this: `/admin/permissions/collections/root`.', 'created_at': datetime.datetime(2024, 11, 13, 17, 54, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508049898, 'issue_id': 2655315140, 'author': 'ignacio-mb', 'body': 'Hi, @negahsol. Friendly nudge for the question above. Thanks!', 'created_at': datetime.datetime(2024, 11, 29, 15, 38, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510433995, 'issue_id': 2655315140, 'author': 'paoliniluis', 'body': 'closing due to no response', 'created_at': datetime.datetime(2024, 12, 2, 2, 30, 4, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-13 12:55:21 UTC): Please send the permission structure screenshot where we can clearly see if you're an administrator or not

negahsol (Issue Creator) on (2024-11-13 13:21:34 UTC): ![Image](https://github.com/user-attachments/assets/f28dba72-dec4-41c9-978a-26cc14cd1a1e)
 in postgresql database
![Image](https://github.com/user-attachments/assets/5382d05f-92eb-430d-b1f8-4112fa697438)
in metabase UI

npfitz on (2024-11-13 17:54:30 UTC): @negahsol Are you able to go to the permissions page, and check collection permissions for ""Our Analytics""? The route should look like this: `/admin/permissions/collections/root`.

ignacio-mb on (2024-11-29 15:38:29 UTC): Hi, @negahsol. Friendly nudge for the question above. Thanks!

paoliniluis on (2024-12-02 02:30:04 UTC): closing due to no response

"
2655222505,issue,open,,"Error with the prompt ""Who is the highest paying customer?""","Too many roundtrips 

```
""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": ""Error: too many round trips."",
            ""data"": {
                ""envelope"": {
                    ""session-id"": ""4ff6df65-f736-e5cb-0915-a70a9c8a73ea"",
                    ""history"": [
                        {
                            ""role"": ""user"",
                            ""content"": ""Who is the highest paying customer?""
                        },
                        {
                            ""content"": """",
                            ""role"": ""assistant"",
                            ""tool-calls"": [
                                {
                                    ""id"": ""call_03hGTyNfWFpTM9Xy4TF0WTJ2"",
```",perivamsi,2024-11-13 11:45:42+00:00,[],2024-11-13 11:46:01+00:00,,https://github.com/metabase/metabase/issues/49948,[],[],
2655151625,issue,open,,"Documentation on the best practices for tools, reactions and error handling for tool creators",,perivamsi,2024-11-13 11:23:17+00:00,[],2024-11-13 11:23:17+00:00,,https://github.com/metabase/metabase/issues/49944,[],[],
2655150128,issue,open,,Documentation on how to write a new tool,,perivamsi,2024-11-13 11:22:33+00:00,[],2024-11-13 11:22:33+00:00,,https://github.com/metabase/metabase/issues/49943,[],[],
2655147447,issue,closed,completed,Proposal and prototype for frontend agent loop,"From Slack: https://metaboat.slack.com/archives/C07SJT1P0ET/p1731393941366249?thread_ts=1731126677.845579&cid=C07SJT1P0ET

Thomas's message:
>I think I'll start a document around where the agent loop should live. We planned this in one of our standups if I recall correctly and I haven't seen one.
>Let's please also not confuse ""frontend tools"" with ""frontend agent loop"".
>I see that we are often talking about FE Tools when we mean where the agent loop happens. This has nothing to do with where the logic for a tool lives eventually - but I'll try to clarify that in the doc
>What is important to me is, wherever the agent loop lives, we should NEVER just mock a tool result but make sure this is always provided to the agent. Right now, I think frontend reactions artificially end the agent loop / or we just say ""yes that tool worked successfully"" even though we don't know. That confuses the agent as we saw in many feedback looms",perivamsi,2024-11-13 11:21:15+00:00,[],2025-01-22 16:07:57+00:00,2025-01-22 16:07:55+00:00,https://github.com/metabase/metabase/issues/49942,[],"[{'comment_id': 2607654608, 'issue_id': 2655147447, 'author': 'retro', 'body': 'Closing this for now. Loop lives in the backend land in the current approach.', 'created_at': datetime.datetime(2025, 1, 22, 16, 7, 55, tzinfo=datetime.timezone.utc)}]","retro on (2025-01-22 16:07:55 UTC): Closing this for now. Loop lives in the backend land in the current approach.

"
2655139318,issue,closed,completed,Tool benchmarking,,perivamsi,2024-11-13 11:17:24+00:00,[],2025-01-22 06:42:56+00:00,2025-01-22 06:42:56+00:00,https://github.com/metabase/metabase/issues/49941,[],"[{'comment_id': 2475972008, 'issue_id': 2655139318, 'author': 'Somtom', 'body': 'https://github.com/metabase/ai-service/pull/60', 'created_at': datetime.datetime(2024, 11, 14, 10, 26, 40, tzinfo=datetime.timezone.utc)}]","Somtom on (2024-11-14 10:26:40 UTC): https://github.com/metabase/ai-service/pull/60

"
2655134197,issue,closed,completed,Finalize the default context to be sent,https://www.notion.so/metabase/Get-v1-LLM-Metabot-complete-enough-for-stats-and-more-tool-building-10d69354c90180c4aa35ee5a83a39c40?pvs=4#12e69354c901809d9835f2b7fa0c4efc,perivamsi,2024-11-13 11:15:34+00:00,[],2025-01-22 16:06:47+00:00,2025-01-22 16:06:45+00:00,https://github.com/metabase/metabase/issues/49940,"[('Metabot/Infra', 'Infra for the multi tool agent LLM')]","[{'comment_id': 2607651481, 'issue_id': 2655134197, 'author': 'retro', 'body': 'This is now handled with the dummy tools approach.', 'created_at': datetime.datetime(2025, 1, 22, 16, 6, 45, tzinfo=datetime.timezone.utc)}]","retro on (2025-01-22 16:06:45 UTC): This is now handled with the dummy tools approach.

"
2654957981,issue,closed,completed,Remove button for conditional formatting rule collapses if rule has many columns,"### Describe the bug

The remove button (X) for a conditional formatting rule collapses into one pixel if the rule contains a large number of columns.

![Image](https://github.com/user-attachments/assets/69dc5c3a-1bdc-4e20-9081-9c66edf25d82)



### To Reproduce

Just create a rule with 7+ columns

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.8""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.112-124.190.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Low

### Additional context

_No response_",mkrauter,2024-11-13 10:20:15+00:00,[],2025-02-07 08:33:50+00:00,2025-02-06 15:40:45+00:00,https://github.com/metabase/metabase/issues/49931,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Chart Settings', ''), ('Customization/Formatting', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2640488228, 'issue_id': 2654957981, 'author': 'mkrauter', 'body': 'Thank you!', 'created_at': datetime.datetime(2025, 2, 6, 17, 5, 45, tzinfo=datetime.timezone.utc)}]","mkrauter (Issue Creator) on (2025-02-06 17:05:45 UTC): Thank you!

"
2654956123,issue,open,,[SDK] some popovers (like date range filter in dashboard) make the scroll jump to the bottom,"It only happens the first time you open them, it probably has something to do with portals, maybe the input in them gets focused when the popover is in the wrong place

https://github.com/user-attachments/assets/35ef46fe-2475-4dba-9b43-12ff022723a3


",npretto,2024-11-13 10:19:28+00:00,['WiNloSt'],2025-02-07 05:47:24+00:00,,https://github.com/metabase/metabase/issues/49930,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2654914660,issue,open,,Conditional formatting is unavailable for boolean fields,"### Describe the bug

Boolean fields simply don't show up in the list of columns available for conditional formatting.

### To Reproduce

1. Create a new SQL query as
```
SELECT 'test A' AS name, true AS is_finished
UNION ALL
SELECT 'test B', false
UNION ALL
SELECT 'test C', null
```
2. Check conditional formatting: the `is_finished` field won't show up in the list of columns

The situation is the same if the data source is physical table.
If I cast the the field to e.g. an int, it becomes available.

![Image](https://github.com/user-attachments/assets/281a96a7-954f-4b7a-81b7-7578295db965)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.8""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.112-124.190.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Low

### Additional context

_No response_",mkrauter,2024-11-13 10:02:21+00:00,[],2025-02-04 20:25:21+00:00,,https://github.com/metabase/metabase/issues/49929,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/Formatting', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2654735609,issue,open,,Deleted/restored sub-collections not updated in UI,"### Describe the bug

https://github.com/user-attachments/assets/1cc95ac8-302c-41df-bbd8-ed76c054dcbf


### To Reproduce

1. Go to ""Our analytics""
2. Make sure ""Examples"" is in the list
3. Select all items
4. Click ""Move to trash""
5. Wait for requests to complete

❌ items count in pagination (bottom-right corner) is incorrrect
❌ ""Examples"" collection is still on the list

6. Select all items

❌ ""Move to trash"" is disabled

7. Go to ""Trash"" 
8. Select all items

❌ ""Delete permanently"" is disabled

9. Refresh the page
10. Select all items
11. Click ""Restore""
12. Wait for requests to complete

❌ ""Examples"" collection is still shown in the ""Trash""


### Information about your Metabase installation

master, 03af173dbc

### Severity

P2
",kamilmielnik,2024-11-13 08:55:41+00:00,[],2025-02-04 20:26:59+00:00,,https://github.com/metabase/metabase/issues/49927,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Collections', ''), ('.Frontend', ''), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2654557122,issue,closed,completed,Fix some backport PRs aren't included in the changelog,"[Reported on Slack](https://metaboat.slack.com/archives/C063Q3F1HPF/p1731435086478389?thread_ts=1731424896.947319&cid=C063Q3F1HPF).

The reason was that some commits on the release branch have this prefix `🤖 backported`, and some don't. This breaks the current changelog generation.

`🤖 backported ` prefix only appears sometimes, from my investigation it seems like this only happens when there are edits to the backport PR and it contains more than 1 non-merge commit. So if the backport PR got merged automatically the commit message would look almost like on master.

For example, this is [auto merged](https://github.com/metabase/metabase/commit/c6378ef4b90db8f4481c289b99c74df503a55324), [this isn't](https://github.com/metabase/metabase/commit/56e415225a8be13d534274e196183e2c45fb2810) and we edited it.

![Image](https://github.com/user-attachments/assets/2e5eae2f-8b48-4053-83c8-c7d451fd4b13)
",WiNloSt,2024-11-13 07:46:13+00:00,['WiNloSt'],2024-11-14 09:55:35+00:00,2024-11-14 09:55:35+00:00,https://github.com/metabase/metabase/issues/49925,"[('.CI & Tests', '')]",[],
2654437360,issue,open,,always require a value can be circumvented if removed value in url,"**Describe the bug**
If any filter with variable of SQL is set to ""always require a value"" it will still show the results of the dashboard as if the filter is empty if the filter value is removed from url.

**Logs**

**To Reproduce**
Steps to reproduce the behavior:
Create any filter with SQL variabel, set default value and option always require a value. Then remove the filter value from public link url. The dashboard will show all results.

**Expected behavior**
No results to be shown.

**Screenshots**

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: This prevents us from using the dashboards for our use, so severe.

",zygimantas-EG,2024-11-13 06:54:42+00:00,[],2024-11-13 06:54:42+00:00,,https://github.com/metabase/metabase/issues/49923,[],[],
2653824636,issue,open,,Test Webhook Always 404s,"### Describe the bug

I pasted a Discord webhook and when I click Test Webhook it just 404s.

### To Reproduce

Create a discord webhook and test

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": ""America/New_York""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-33-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Medium

### Additional context

_No response_",k2xl,2024-11-13 01:23:03+00:00,[],2025-02-04 20:26:26+00:00,,https://github.com/metabase/metabase/issues/49919,"[('.Team/Workflows', 'aka BEC'), ('Notifications/Webhooks', '')]","[{'comment_id': 2472365408, 'issue_id': 2653824636, 'author': 'qnkhuat', 'body': ""Similar to https://github.com/metabase/metabase/issues/49533, we don't have a way to configure the test request. It's always a POST and with a limited method of authentication"", 'created_at': datetime.datetime(2024, 11, 13, 4, 45, 35, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-11-13 04:45:35 UTC): Similar to https://github.com/metabase/metabase/issues/49533, we don't have a way to configure the test request. It's always a POST and with a limited method of authentication

"
2653793157,issue,closed,completed,Webhook Doesn't Allow HTTP Method to be configured?,"### Describe the bug

Trying to use webhooks with discord. I have the discord URL, but the webhook test keeps failing (unsure what HTTP method it is using). So I get 404s

### To Reproduce

1. make a discord webhook
2. paste it into the box

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase 0.51
```

### Severity

Medium

### Additional context

_No response_",k2xl,2024-11-13 01:07:01+00:00,[],2025-01-06 07:09:31+00:00,2024-11-13 01:11:45+00:00,https://github.com/metabase/metabase/issues/49918,"[('Type:New Feature', ''), ('.Needs Triage', ''), ('.Team/Workflows', 'aka BEC'), ('Notifications/Webhooks', '')]","[{'comment_id': 2472085965, 'issue_id': 2653793157, 'author': 'k2xl', 'body': ""Looks like every url is 404. I don't know what is going on (running metabase with docker, so unclear why it is having weird issues like this)"", 'created_at': datetime.datetime(2024, 11, 13, 1, 12, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475771132, 'issue_id': 2653793157, 'author': 'piranha', 'body': '@k2xl we\'ve looked into the issue and the request method (while it\'s static) is POST, as Discord expects it to be. The problem is that we send an empty request to check that the URL exist and lots of services do not expect this — we\'re removing that check (you\'ll be able to ""test"" webhook in Card interface) and also plan to surface service response somewhere.\n\nSo if everything goes well this will work a bit better soon. :)', 'created_at': datetime.datetime(2024, 11, 14, 8, 59, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480671101, 'issue_id': 2653793157, 'author': 'k2xl', 'body': 'Okay great, which version should have this fix?', 'created_at': datetime.datetime(2024, 11, 16, 17, 14, 49, tzinfo=datetime.timezone.utc)}]","k2xl (Issue Creator) on (2024-11-13 01:12:07 UTC): Looks like every url is 404. I don't know what is going on (running metabase with docker, so unclear why it is having weird issues like this)

piranha on (2024-11-14 08:59:40 UTC): @k2xl we've looked into the issue and the request method (while it's static) is POST, as Discord expects it to be. The problem is that we send an empty request to check that the URL exist and lots of services do not expect this — we're removing that check (you'll be able to ""test"" webhook in Card interface) and also plan to surface service response somewhere.

So if everything goes well this will work a bit better soon. :)

k2xl (Issue Creator) on (2024-11-16 17:14:49 UTC): Okay great, which version should have this fix?

"
2653525757,issue,closed,completed,Numeric/decimal column filters for bigquery databases no longer does greater than/less than comparison,"### Describe the bug

More issues for 1.51.x version, similar to #49786 but for our numeric fields.  

Rollback for us would not be easy, please investigate and fix, are there other field types which do not filter properly anymore? 

![Image](https://github.com/user-attachments/assets/f819ae34-97d9-42d5-af09-fde3cbce4759)


### To Reproduce

1. Go to a big query database
2. Click on a table with numeric/decimal fields
3. On the column header try and Filter by this column
4. Notice that the ability to compare using > < = equalities is not available anymore


### Expected behavior

numeric columns used to be able to be filtered by > < =


### Logs

_No response_

### Information about your Metabase installation

```JSON
- any browser
- bigquery
- metabase 1.51.3
```

### Severity

blocking normal usage of much of the site

### Additional context

please fix and let us know what other field types are impacted by the changes which created this bug",rojomisin,2024-11-12 22:43:34+00:00,['snoe'],2024-11-18 16:31:08+00:00,2024-11-13 22:52:05+00:00,https://github.com/metabase/metabase/issues/49913,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2471747963, 'issue_id': 2653525757, 'author': 'rojomisin', 'body': 'similar to #49829 too', 'created_at': datetime.datetime(2024, 11, 12, 22, 45, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483538279, 'issue_id': 2653525757, 'author': 'rojomisin', 'body': 'when can we expect x.51.4 this bug is preventing normal operation. Our bad for not catching it in validation but we are looking forward to the release.', 'created_at': datetime.datetime(2024, 11, 18, 16, 31, 7, tzinfo=datetime.timezone.utc)}]","rojomisin (Issue Creator) on (2024-11-12 22:45:06 UTC): similar to #49829 too

rojomisin (Issue Creator) on (2024-11-18 16:31:07 UTC): when can we expect x.51.4 this bug is preventing normal operation. Our bad for not catching it in validation but we are looking forward to the release.

"
2653480119,issue,closed,completed,We don't sync materialized views fields,"### Describe the bug

At least in postgres we're not getting the fields for the materialized views so you can't query these

### To Reproduce

1) on postgres with the sample DB do 
```
CREATE MATERIALIZED VIEW orders_m as select * from orders
```
2) sync it
3) try to see the table via browse data

### Expected behavior

we should sync the fields in the same way you do on a normal view

### Logs

```
2024-11-12 22:25:04,114 INFO sync-metadata.tables :: Found new table: Table  ''public.orders_m''
2024-11-12 22:25:04,130 INFO sync-metadata.tables :: Updating table metadata for Table 28 ''public.accounts''
2024-11-12 22:25:04,133 INFO sync-metadata.tables :: Updating table metadata for Table 29 ''public.feedback''
2024-11-12 22:25:04,134 INFO sync-metadata.tables :: Updating table metadata for Table 22 ''public.products''
2024-11-12 22:25:04,136 INFO sync-metadata.tables :: Updating table metadata for Table 23 ''public.reviews''
2024-11-12 22:25:04,138 INFO sync-metadata.tables :: Updating table metadata for Table 25 ''public.invoices''
2024-11-12 22:25:04,140 INFO sync-metadata.tables :: Updating table metadata for Table 24 ''public.orders''
2024-11-12 22:25:04,142 INFO sync-metadata.tables :: Updating table metadata for Table 26 ''public.people''
2024-11-12 22:25:04,143 INFO sync-metadata.tables :: Updating table metadata for Table 27 ''public.analytic_events''
2024-11-12 22:25:04,145 INFO sync-metadata.tables :: Updating table metadata for Table 140 ''public.orders_m''
2024-11-12 22:25:04,146 INFO sync-metadata.tables :: :estimated_row_count of Table 140 ''public.orders_m'' changed from null to 18760
2024-11-12 22:25:04,153 INFO sync.util :: FINISHED: step ''sync-tables'' for postgres Database 2 ''pg'' (43.4 ms)
```

but there are no errors on the fields of the views

### Information about your Metabase installation

```JSON
v51.x
```

### Severity

P1

### Additional context

_No response_",paoliniluis,2024-11-12 22:29:13+00:00,[],2024-11-18 06:33:59+00:00,2024-11-15 23:09:20+00:00,https://github.com/metabase/metabase/issues/49912,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Escalation', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('.Team/Drivers', '')]","[{'comment_id': 2471734531, 'issue_id': 2653480119, 'author': 'paoliniluis', 'body': ""For god's sake https://www.postgresql.org/message-id/CAH7T-ao6ece1mgCsCvsE04W59ZZJP9gGXVK97wkUzRV5gsDqQQ%40mail.gmail.com"", 'created_at': datetime.datetime(2024, 11, 12, 22, 37, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476730260, 'issue_id': 2653480119, 'author': 'paoliniluis', 'body': 'New query in https://github.com/metabase/metabase/blob/290165d96610e43cbe46fa1c1c8578f960dcafee/src/metabase/driver/postgres.clj#L282\n\n```\nSELECT ""c"".""column_name""                                                                                              AS ""name"",\n       ""c"".""udt_name""                                                                                                 AS ""database-type"",\n       ""c"".""ordinal_position"" - 1                                                                                     AS ""database-position"",\n       ""c"".""table_schema""                                                                                             AS ""table-schema"",\n       ""c"".""table_name""                                                                                               AS ""table-name"",\n       ""pk"".""column_name"" IS NOT NULL                                                                                 AS ""pk?"",\n       COL_DESCRIPTION(CAST(CAST(FORMAT(\'%I.%I\', CAST(""c"".""table_schema"" AS TEXT),\n                                        CAST(""c"".""table_name"" AS TEXT)) AS REGCLASS) AS OID),\n                       ""c"".""ordinal_position"")                                                                        AS ""field-comment"",\n       ((""column_default"" IS NULL) OR (LOWER(""column_default"") = \'null\')) AND (""is_nullable"" = \'NO\') AND\n       NOT (((""column_default"" IS NOT NULL) AND (""column_default"" LIKE \'%nextval(%\')) OR\n            (""is_identity"" <> \'NO\'))                                                                                  AS ""database-required"",\n       ((""column_default"" IS NOT NULL) AND (""column_default"" LIKE \'%nextval(%\')) OR\n       (""is_identity"" <> \'NO\')                                                                                        AS ""database-is-auto-increment""\nFROM ""information_schema"".""columns"" AS ""c""\n         LEFT JOIN (SELECT ""tc"".""table_schema"", ""tc"".""table_name"", ""kc"".""column_name""\n                    FROM ""information_schema"".""table_constraints"" AS ""tc""\n                             INNER JOIN ""information_schema"".""key_column_usage"" AS ""kc""\n                                        ON (""tc"".""constraint_name"" = ""kc"".""constraint_name"") AND\n                                           (""tc"".""table_schema"" = ""kc"".""table_schema"") AND\n                                           (""tc"".""table_name"" = ""kc"".""table_name"")\n                    WHERE ""tc"".""constraint_type"" = \'PRIMARY KEY\') AS ""pk""\n                   ON (""c"".""table_schema"" = ""pk"".""table_schema"") AND (""c"".""table_name"" = ""pk"".""table_name"") AND\n                      (""c"".""column_name"" = ""pk"".""column_name"")\nWHERE c.table_schema !~ \'^information_schema|catalog_history|pg_\'\n  AND (""c"".""table_schema"" IN (\'public\'))\nUNION ALL\nSELECT pg_attribute.attname AS ""name"",\n       pg_type.typname as ""database-type"",\n       pg_attribute.attnum AS ""ordinal_position"",\n       pg_namespace.nspname AS ""table_schema"",\n       pg_class.relname AS ""table_name"",\n       FALSE as ""pk?"",\n       NULL as ""field-comment"",\n       FALSE as ""database-required"",\n       FALSE as ""database-is-auto-increment""\nFROM pg_catalog.pg_class\n    INNER JOIN pg_catalog.pg_namespace\n        ON pg_class.relnamespace = pg_namespace.oid\n    INNER JOIN pg_catalog.pg_attribute\n        ON pg_class.oid = pg_attribute.attrelid\n    INNER JOIN pg_catalog.pg_type ON pg_type.oid = pg_attribute.atttypid\nWHERE pg_class.relkind = \'m\'\n    AND pg_attribute.attnum >= 1\nORDER BY 4\n    , 5\n    , 3\n```', 'created_at': datetime.datetime(2024, 11, 14, 15, 36, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478581791, 'issue_id': 2653480119, 'author': 'vinceve', 'body': ""It seems that we're impacted by this issue as well."", 'created_at': datetime.datetime(2024, 11, 15, 11, 10, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478586671, 'issue_id': 2653480119, 'author': 'YvesBos', 'body': ""Following the upgrade to v1.51.2 we suddenly run into an issue where Metabase doesn't pick up the fields for 1 materialized view, all other are fine. Exactly the same scenario as you describe, our materialized view just selects from a non-materialized view & syncing shows no errors.\n\nThe query that you linked does detect the fields when we execute it manually."", 'created_at': datetime.datetime(2024, 11, 15, 11, 13, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478639970, 'issue_id': 2653480119, 'author': 'YvesBos', 'body': ""OK it seems the sync is broken for **all** materialized views, I've spun up a fresh Metabase instance and none of the fields in any of the materialized views are being picked up. We're blocked from releasing due to this issue, is there a timeline for a fix?"", 'created_at': datetime.datetime(2024, 11, 15, 11, 46, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480066341, 'issue_id': 2653480119, 'author': 'paoliniluis', 'body': '@YvesBos being fixed as we speak', 'created_at': datetime.datetime(2024, 11, 15, 22, 41, 12, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-11-12 22:37:43 UTC): For god's sake https://www.postgresql.org/message-id/CAH7T-ao6ece1mgCsCvsE04W59ZZJP9gGXVK97wkUzRV5gsDqQQ%40mail.gmail.com

paoliniluis (Issue Creator) on (2024-11-14 15:36:12 UTC): New query in https://github.com/metabase/metabase/blob/290165d96610e43cbe46fa1c1c8578f960dcafee/src/metabase/driver/postgres.clj#L282

```
SELECT ""c"".""column_name""                                                                                              AS ""name"",
       ""c"".""udt_name""                                                                                                 AS ""database-type"",
       ""c"".""ordinal_position"" - 1                                                                                     AS ""database-position"",
       ""c"".""table_schema""                                                                                             AS ""table-schema"",
       ""c"".""table_name""                                                                                               AS ""table-name"",
       ""pk"".""column_name"" IS NOT NULL                                                                                 AS ""pk?"",
       COL_DESCRIPTION(CAST(CAST(FORMAT('%I.%I', CAST(""c"".""table_schema"" AS TEXT),
                                        CAST(""c"".""table_name"" AS TEXT)) AS REGCLASS) AS OID),
                       ""c"".""ordinal_position"")                                                                        AS ""field-comment"",
       ((""column_default"" IS NULL) OR (LOWER(""column_default"") = 'null')) AND (""is_nullable"" = 'NO') AND
       NOT (((""column_default"" IS NOT NULL) AND (""column_default"" LIKE '%nextval(%')) OR
            (""is_identity"" <> 'NO'))                                                                                  AS ""database-required"",
       ((""column_default"" IS NOT NULL) AND (""column_default"" LIKE '%nextval(%')) OR
       (""is_identity"" <> 'NO')                                                                                        AS ""database-is-auto-increment""
FROM ""information_schema"".""columns"" AS ""c""
         LEFT JOIN (SELECT ""tc"".""table_schema"", ""tc"".""table_name"", ""kc"".""column_name""
                    FROM ""information_schema"".""table_constraints"" AS ""tc""
                             INNER JOIN ""information_schema"".""key_column_usage"" AS ""kc""
                                        ON (""tc"".""constraint_name"" = ""kc"".""constraint_name"") AND
                                           (""tc"".""table_schema"" = ""kc"".""table_schema"") AND
                                           (""tc"".""table_name"" = ""kc"".""table_name"")
                    WHERE ""tc"".""constraint_type"" = 'PRIMARY KEY') AS ""pk""
                   ON (""c"".""table_schema"" = ""pk"".""table_schema"") AND (""c"".""table_name"" = ""pk"".""table_name"") AND
                      (""c"".""column_name"" = ""pk"".""column_name"")
WHERE c.table_schema !~ '^information_schema|catalog_history|pg_'
  AND (""c"".""table_schema"" IN ('public'))
UNION ALL
SELECT pg_attribute.attname AS ""name"",
       pg_type.typname as ""database-type"",
       pg_attribute.attnum AS ""ordinal_position"",
       pg_namespace.nspname AS ""table_schema"",
       pg_class.relname AS ""table_name"",
       FALSE as ""pk?"",
       NULL as ""field-comment"",
       FALSE as ""database-required"",
       FALSE as ""database-is-auto-increment""
FROM pg_catalog.pg_class
    INNER JOIN pg_catalog.pg_namespace
        ON pg_class.relnamespace = pg_namespace.oid
    INNER JOIN pg_catalog.pg_attribute
        ON pg_class.oid = pg_attribute.attrelid
    INNER JOIN pg_catalog.pg_type ON pg_type.oid = pg_attribute.atttypid
WHERE pg_class.relkind = 'm'
    AND pg_attribute.attnum >= 1
ORDER BY 4
    , 5
    , 3
```

vinceve on (2024-11-15 11:10:47 UTC): It seems that we're impacted by this issue as well.

YvesBos on (2024-11-15 11:13:54 UTC): Following the upgrade to v1.51.2 we suddenly run into an issue where Metabase doesn't pick up the fields for 1 materialized view, all other are fine. Exactly the same scenario as you describe, our materialized view just selects from a non-materialized view & syncing shows no errors.

The query that you linked does detect the fields when we execute it manually.

YvesBos on (2024-11-15 11:46:01 UTC): OK it seems the sync is broken for **all** materialized views, I've spun up a fresh Metabase instance and none of the fields in any of the materialized views are being picked up. We're blocked from releasing due to this issue, is there a timeline for a fix?

paoliniluis (Issue Creator) on (2024-11-15 22:41:12 UTC): @YvesBos being fixed as we speak

"
2653390748,issue,closed,not_planned,Support lineage,"**Is your feature request related to a problem? Please describe.**
When changing a table or schema you have very little visibility of the impact it would have on the already created questions/dashboards in Metabase. 

Having a way to visualize all the dependencies would be ideal. 

**How important is this feature to you?**
Request by a customer

**Additional context**
Related to the [ParseSQL Epic](https://github.com/metabase/metabase/issues/36911)",psalinasy,2024-11-12 21:33:10+00:00,[],2024-12-27 20:52:42+00:00,2024-12-27 20:52:42+00:00,https://github.com/metabase/metabase/issues/49910,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2471990800, 'issue_id': 2653390748, 'author': 'paoliniluis', 'body': 'Related if not the same as https://github.com/metabase/metabase/issues/27106?', 'created_at': datetime.datetime(2024, 11, 13, 0, 12, 51, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-13 00:12:51 UTC): Related if not the same as https://github.com/metabase/metabase/issues/27106?

"
2653293888,issue,closed,not_planned,Revisit the add question to dashboard button,"[Figma](https://www.figma.com/design/XVoU2cfo33QnvYoY2Nrc6K/Untitled?node-id=3-75&node-type=section&t=9Mlr45PkZEJuEQT7-11)
[Loom](https://www.loom.com/share/aedaf52e9c1a487686254bb825870fd7)
[Thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1731437678400329)",luizarakaki,2024-11-12 20:46:12+00:00,[],2024-12-11 17:34:04+00:00,2024-12-11 17:34:04+00:00,https://github.com/metabase/metabase/issues/49909,[],[],
2653242919,issue,open,,Snowflake varchar ISO8601 datetime issue with filters,"### Describe the bug

I have timestamps like this in a varchar column:
2024-11-08T19:21:07Z

I've tried to force casting to ISO8601 -> datetime. Whenever I try to use the date filter using relative dates on the column I get an error generating query.

It should generate this where clause instead:
CAST(""DW"".""APPLICATION"".""captureTime"" AS timestamp) >= DATEADD(day, -7, CURRENT_DATE)

If I use specific dates like Before 11/8/2024 it works. 
It generates the following SQL
CAST(
""DW"".""APPLICATION"".""captureTime"" AS timestamp
) < '2024-11-08 00:00:00.000':: timestamp_ntz

Using between dates also works.
It generates the following SQL
AND (
CAST(
""DW"".""APPLICATION"".""captureTime"" AS timestamp
) >= '2024-10-09 00:00:00.000':: timestamp_ntz
)
AND (
CAST(
""DW"".""APPLICATION"".""captureTime"" AS timestamp
) < '2024-11-09 00:00:00.000':: timestamp_ntz
)

### To Reproduce

Try to query a snowflake table with a varchar column that's storing an ISO8601 datetime using relative dates datefilter.


### Expected behavior

It should work for relative dates and generate a where clause as follows:
CAST(""DW"".""APPLICATION"".""captureTime"" AS timestamp) >= DATEADD(day, -7, CURRENT_DATE)

### Logs

[eaee5184-6ac0-44b6-b0c9-bd40ba4a4a84] 2024-11-08T16:02:03-05:00 ERROR metabase.server.middleware.log POST /api/dataset/native 500 26.0 ms (5 DB calls) {:metabase-user-id 1}
{:via
[{:type clojure.lang.ExceptionInfo,
:message ""Error compiling query: No matching clause: :type/Text"",
:data
{:query
{:database 12,
:type :query,
:query
{:source-table 438,
:fields
[[:field 13697 nil]
[:field 13702 nil]
[:field 13699 nil]
[:field 13688 nil]
[:field 13706 nil]
[:field 13693 nil]
[:field 13696 nil]
[:field 13701 nil]
[:field 13687 nil]
[:field 13698 nil]
[:field 13691 nil]
[:field 13695 nil]
[:field 13690 nil]
[:field 13694 nil]
[:field 13705 nil]
[:field 13700 nil]
[:field 13704 nil]
[:field 13703 nil]
[:field 13692 nil]
[:field 13689 nil]],
:filter
[:and
[:>= [:field 13704 {:base-type :type/Text, :temporal-unit :default}] [:relative-datetime -7 :day]]
[:< [:field 13704 {:base-type :type/Text, :temporal-unit :default}] [:relative-datetime 0 :day]]],
:limit 1048575,
:metabase.query-processor.middleware.limit/original-limit nil}},
:type :driver},
:at [metabase.query_processor.compile$compile_preprocessed75746__75747$fn__75748 invoke ""compile.clj"" 35]}
{:type java.lang.IllegalArgumentException,
:message ""No matching clause: :type/Text"",
:at
[metabase.query_processor.util.relative_datetime$maybe_truncate_dt_value invokeStatic ""relative_datetime.clj"" 18]}],
:trace
[[metabase.query_processor.util.relative_datetime$maybe_truncate_dt_value invokeStatic ""relative_datetime.clj"" 18]
[metabase.query_processor.util.relative_datetime$maybe_truncate_dt_value invoke ""relative_datetime.clj"" 16]
[metabase.query_processor.util.relative_datetime$relative_datetime_sql_str invokeStatic ""relative_datetime.clj"" 30]
[metabase.query_processor.util.relative_datetime$relative_datetime_sql_str invoke ""relative_datetime.clj"" 23]
[metabase.query_processor.util.relative_datetime$maybe_cacheable_relative_datetime_honeysql
invokeStatic
""relative_datetime.clj""
44]
[metabase.query_processor.util.relative_datetime$maybe_cacheable_relative_datetime_honeysql
doInvoke
""relative_datetime.clj""
33]
[clojure.lang.RestFn invoke ""RestFn.java"" 470]
[metabase.driver.snowflake$fn__125206 invokeStatic ""snowflake.clj"" 478]
[metabase.driver.snowflake$fn__125206 invoke ""snowflake.clj"" 476]
[clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
[metabase.driver.sql.query_processor$fn__70446$fn__70448 invoke ""query_processor.clj"" 1433]
[clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
[clojure.core$partial$fn__5927 invoke ""core.clj"" 2641]
[clojure.core$map$fn__5950$fn__5951 invoke ""core.clj"" 2759]
[clojure.lang.PersistentVector$ChunkedSeq reduce ""PersistentVector.java"" 549]
[clojure.core$transduce invokeStatic ""core.clj"" 7025]
[clojure.core$into invokeStatic ""core.clj"" 7042]
[clojure.core$into invoke ""core.clj"" 7029]
[metabase.driver.sql.query_processor$fn__70497 invokeStatic ""query_processor.clj"" 1464]
[metabase.driver.sql.query_processor$fn__70497 invoke ""query_processor.clj"" 1462]
[clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
[metabase.driver.sql.query_processor$fn__70515 invokeStatic ""query_processor.clj"" 1485]
[metabase.driver.sql.query_processor$fn__70515 invoke ""query_processor.clj"" 1483]
[clojure.lang.MultiFn invoke ""MultiFn.java"" 244]
[metabase.driver.sql.query_processor$apply_top_level_clauses$fn__70622 invoke ""query_processor.clj"" 1719]
[clojure.lang.ArraySeq reduce ""ArraySeq.java"" 119]
[clojure.core$transduce invokeStatic ""core.clj"" 7025]
[clojure.core$transduce invoke ""core.clj"" 7012]
[metabase.driver.sql.query_processor$apply_top_level_clauses invokeStatic ""query_processor.clj"" 1713]
[metabase.driver.sql.query_processor$apply_top_level_clauses invoke ""query_processor.clj"" 1706]
[metabase.driver.sql.query_processor$apply_top_level_clauses invokeStatic ""query_processor.clj"" 1710]
[metabase.driver.sql.query_processor$apply_top_level_clauses invoke ""query_processor.clj"" 1706]
[metabase.driver.sql.query_processor$apply_clauses invokeStatic ""query_processor.clj"" 1776]
[metabase.driver.sql.query_processor$apply_clauses invoke ""query_processor.clj"" 1764]
[metabase.driver.sql.query_processor$mbql__GT_honeysql70675__70677 invokeStatic ""query_processor.clj"" 1829]
[metabase.driver.sql.query_processor$mbql__GT_honeysql70675__70677 invoke ""query_processor.clj"" 1822]
[metabase.driver.sql.query_processor$mbql__GT_native70686__70687 invokeStatic ""query_processor.clj"" 1842]
[metabase.driver.sql.query_processor$mbql__GT_native70686__70687 invoke ""query_processor.clj"" 1835]
[metabase.driver.sql$fn__87989 invokeStatic ""sql.clj"" 47]
[metabase.driver.sql$fn__87989 invoke ""sql.clj"" 45]
[clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
[metabase.query_processor.compile$compile_STAR_ invokeStatic ""compile.clj"" 24]
[metabase.query_processor.compile$compile_STAR_ invoke ""compile.clj"" 20]
[metabase.query_processor.compile$compile_preprocessed75746__75747$fn__75748 invoke ""compile.clj"" 32]
[metabase.query_processor.setup$do_with_qp_setup75135__75136 invokeStatic ""setup.clj"" 225]
[metabase.query_processor.setup$do_with_qp_setup75135__75136 invoke ""setup.clj"" 216]
[metabase.query_processor.compile$compile_preprocessed75746__75747 invokeStatic ""compile.clj"" 30]
[metabase.query_processor.compile$compile_preprocessed75746__75747 invoke ""compile.clj"" 26]
[metabase.query_processor.compile$compile75753__75754$fn__75755 invoke ""compile.clj"" 43]
[metabase.query_processor.setup$do_with_canceled_chan75130__75131$fn__75132 invoke ""setup.clj"" 189]
[metabase.query_processor.setup$do_with_database_local_settings75123__75124$fn__75125 invoke ""setup.clj"" 181]
[metabase.query_processor.setup$do_with_driver75116__75117$fn__75118$fn__75119 invoke ""setup.clj"" 166]
[metabase.driver$do_with_driver invokeStatic ""driver.clj"" 106]
[metabase.driver$do_with_driver invoke ""driver.clj"" 101]
[metabase.query_processor.setup$do_with_driver75116__75117$fn__75118 invoke ""setup.clj"" 165]
[metabase.query_processor.setup$do_with_metadata_provider75107__75108$fn__75109$fn__75112 invoke ""setup.clj"" 151]
[metabase.query_processor.store$do_with_metadata_provider58710__58711 invokeStatic ""store.clj"" 170]
[metabase.query_processor.store$do_with_metadata_provider58710__58711 invoke ""store.clj"" 150]
[metabase.query_processor.store$do_with_metadata_provider58710__58711 invokeStatic ""store.clj"" 159]
[metabase.query_processor.store$do_with_metadata_provider58710__58711 invoke ""store.clj"" 150]
[metabase.query_processor.setup$do_with_metadata_provider75107__75108$fn__75109 invoke ""setup.clj"" 150]
[metabase.query_processor.setup$do_with_resolved_database75097__75098$fn__75099 invoke ""setup.clj"" 128]
[metabase.query_processor.setup$do_with_qp_setup75135__75136 invokeStatic ""setup.clj"" 232]
[metabase.query_processor.setup$do_with_qp_setup75135__75136 invoke ""setup.clj"" 216]
[metabase.query_processor.compile$compile75753__75754 invokeStatic ""compile.clj"" 42]
[metabase.query_processor.compile$compile75753__75754 invoke ""compile.clj"" 39]
[metabase.query_processor.compile$compile_with_inline_parameters75764__75765 invokeStatic ""compile.clj"" 74]
[metabase.query_processor.compile$compile_with_inline_parameters75764__75765 invoke ""compile.clj"" 64]
[metabase.api.dataset$fn__98842$fn__98845 invoke ""dataset.clj"" 176]
[metabase.api.dataset$fn__98842 invokeStatic ""dataset.clj"" 172]
[metabase.api.dataset$fn__98842 invoke ""dataset.clj"" 167]
[compojure.core$wrap_response$fn__53940 invoke ""core.clj"" 160]
[compojure.core$wrap_route_middleware$fn__53924 invoke ""core.clj"" 132]
[compojure.core$wrap_route_info$fn__53929 invoke ""core.clj"" 139]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 151]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 152]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 152]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 152]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 152]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952 invoke ""core.clj"" 200]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[metabase.server.middleware.auth$enforce_authentication$fn__102156 invoke ""auth.clj"" 18]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952 invoke ""core.clj"" 200]
[compojure.core$make_context$handler__53980 invoke ""core.clj"" 290]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 300]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 301]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 153]
[clojure.lang.Var invoke ""Var.java"" 395]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[metabase.api.routes$fn__107556$fn__107559 invoke ""routes.clj"" 73]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952 invoke ""core.clj"" 200]
[clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[clojure.lang.AFn applyTo ""AFn.java"" 144]
[clojure.core$apply invokeStatic ""core.clj"" 667]
[clojure.core$apply invoke ""core.clj"" 662]
[metabase.server.routes$fn__107836$fn__107837 doInvoke ""routes.clj"" 73]
[clojure.lang.RestFn invoke ""RestFn.java"" 439]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952 invoke ""core.clj"" 200]
[compojure.core$make_context$handler__53980 invoke ""core.clj"" 290]
[compojure.core$make_context$fn__53984 invoke ""core.clj"" 300]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 153]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 153]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 153]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[compojure.core$wrap_route_matches$fn__53933 invoke ""core.clj"" 153]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952$f__53953$respond_SINGLEQUOTE___53954 invoke ""core.clj"" 197]
[metabase.server.routes$fn__107819$fn__107821 invoke ""routes.clj"" 47]
[compojure.core$routes$fn__53952$f__53953 invoke ""core.clj"" 198]
[compojure.core$routes$fn__53952 invoke ""core.clj"" 200]
[metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__104276 invoke ""exceptions.clj"" 111]
[metabase.server.middleware.exceptions$catch_api_exceptions$fn__104273 invoke ""exceptions.clj"" 100]
[metabase.server.middleware.log$log_api_call$fn__108169$fn__108170$fn__108171 invoke ""log.clj"" 233]
[metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 17]
[metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
[metabase.server.middleware.log$log_api_call$fn__108169$fn__108170 invoke ""log.clj"" 224]
[toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
[toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
[metabase.server.middleware.log$log_api_call$fn__108169 invoke ""log.clj"" 223]
[metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__111690 invoke ""browser_cookie.clj"" 40]
[metabase.server.middleware.security$add_security_headers$fn__104232 invoke ""security.clj"" 273]
[ring.middleware.json$wrap_json_body$fn__111949 invoke ""json.clj"" 64]
[metabase.server.middleware.offset_paging$handle_paging$fn__92238 invoke ""offset_paging.clj"" 49]
[metabase.server.middleware.json$wrap_streamed_json_response$fn__55611 invoke ""json.clj"" 88]
[ring.middleware.keyword_params$wrap_keyword_params$fn__112038 invoke ""keyword_params.clj"" 55]
[ring.middleware.params$wrap_params$fn__112057 invoke ""params.clj"" 77]
[metabase.server.middleware.misc$maybe_set_site_url$fn__71666 invoke ""misc.clj"" 59]
[metabase.server.middleware.session$reset_session_timeout$fn__73471 invoke ""session.clj"" 565]
[metabase.server.middleware.session$bind_current_user$fn__73437$fn__73438 invoke ""session.clj"" 459]
[metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 438]
[metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 421]
[metabase.server.middleware.session$bind_current_user$fn__73437 invoke ""session.clj"" 458]
[metabase.server.middleware.session$wrap_current_user_info$fn__73414 invoke ""session.clj"" 383]
[metabase.analytics.sdk$embedding_mw$embedding_mw_fn__77618 invoke ""sdk.clj"" 51]
[metabase.server.middleware.session$wrap_session_id$fn__73386 invoke ""session.clj"" 261]
[metabase.server.middleware.auth$wrap_static_api_key$fn__102164 invoke ""auth.clj"" 32]
[ring.middleware.cookies$wrap_cookies$fn__111877 invoke ""cookies.clj"" 200]
[metabase.server.middleware.misc$add_content_type$fn__71648 invoke ""misc.clj"" 28]
[metabase.server.middleware.misc$disable_streaming_buffering$fn__71674 invoke ""misc.clj"" 75]
[ring.middleware.gzip$wrap_gzip$fn__111919 invoke ""gzip.clj"" 86]
[metabase.server.middleware.request_id$wrap_request_id$fn__107898 invoke ""request_id.clj"" 9]
[metabase.server.middleware.misc$bind_request$fn__71677 invoke ""misc.clj"" 91]
[metabase.server.middleware.ssl$redirect_to_https_middleware$fn__111706 invoke ""ssl.clj"" 51]
[metabase.server$async_proxy_handler$fn__61858 invoke ""server.clj"" 77]
[metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
[org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
[org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
[org.eclipse.jetty.server.Server handle ""Server.java"" 563]
[org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
[org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
[org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
[org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
[org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
[org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
[org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
[org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
[org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
[org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
[org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
[org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
[org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
[org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
[org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
[java.lang.Thread run ""Thread.java"" 829]],
:cause ""No matching clause: :type/Text"",
:message ""Error compiling query: No matching clause: :type/Text"",
:query
{:database 12,
:type :query,
:query
{:source-table 438,
:fields
[[:field 13697 nil]
[:field 13702 nil]
[:field 13699 nil]
[:field 13688 nil]
[:field 13706 nil]
[:field 13693 nil]
[:field 13696 nil]
[:field 13701 nil]
[:field 13687 nil]
[:field 13698 nil]
[:field 13691 nil]
[:field 13695 nil]
[:field 13690 nil]
[:field 13694 nil]
[:field 13705 nil]
[:field 13700 nil]
[:field 13704 nil]
[:field 13703 nil]
[:field 13692 nil]
[:field 13689 nil]],
:filter
[:and
[:>= [:field 13704 {:base-type :type/Text, :temporal-unit :default}] [:relative-datetime -7 :day]]
[:< [:field 13704 {:base-type :type/Text, :temporal-unit :default}] [:relative-datetime 0 :day]]],
:limit 1048575,
:metabase.query-processor.middleware.limit/original-limit nil}}}

### Information about your Metabase installation

```JSON
{
""browser-info"": {
""language"": ""en-US"",
""platform"": ""MacIntel"",
""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
""vendor"": ""Google Inc.""
},
""metabase-info"": {
""databases"": [
""h2"",
""oracle"",
""mysql"",
""snowflake""
],
""run-mode"": ""prod"",
""plan-alias"": """",
""version"": {
""date"": ""2024-11-04"",
""tag"": ""v0.51.2"",
""hash"": ""8bdb22c""
},
""settings"": {
""report-timezone"": null
},
""hosting-env"": ""unknown"",
""application-database"": ""mysql"",
""application-database-details"": {
""database"": {
""name"": ""MySQL"",
""version"": ""8.0.36""
},
""jdbc-driver"": {
""name"": ""MariaDB Connector/J"",
""version"": ""2.7.10""
}
}
},
""system-info"": {
""file.encoding"": ""UTF-8"",
""java.runtime.name"": ""OpenJDK Runtime Environment"",
""java.runtime.version"": ""11.0.24+8-LTS"",
""java.vendor"": ""Red Hat, Inc."",
""java.vendor.url"": ""https://www.redhat.com/"",
""java.version"": ""11.0.24"",
""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
""java.vm.version"": ""11.0.24+8-LTS"",
""os.name"": ""Linux"",
""os.version"": ""4.18.0-553.22.1.el8_10.x86_64"",
""user.language"": ""en"",
""user.timezone"": ""America/New_York""
}
}
```

### Severity

It is blocking our usage of Metabase against Snowflake data.

### Additional context

You can find pictures in this post: https://discourse.metabase.com/t/snowflake-varchar-iso8601-datetime-filter-issue/178986",cabarria,2024-11-12 20:27:42+00:00,[],2025-02-04 20:25:30+00:00,,https://github.com/metabase/metabase/issues/49907,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Snowflake', ''), ('.Team/Drivers', '')]",[],
2653176302,issue,open,,LLM/AI code assistant for SQL,"**Is your feature request related to a problem? Please describe.**
You might want an AI to help you write some SQL  that understands the underlying data 

**Describe the solution you'd like**
Some interface that would help you create code and debug issues based on a prompt

**Describe alternatives you've considered**
Using an external code editor, but it can be tricky for it to know the data and schema syntax and wording 

**How important is this feature to you?**
Requested by a customer, internal ticket: 

**Additional context**

",ignacio-mb,2024-11-12 19:52:23+00:00,[],2025-02-04 20:31:04+00:00,,https://github.com/metabase/metabase/issues/49905,"[('Type:New Feature', ''), ('Metabot/General', 'General Metabot AI'), ('Querying/Native', 'The SQL/native query editor'), ('Metabot/LLMService', '(we can change this name) aka ai-proxy aka LLM agent service')]","[{'comment_id': 2606422534, 'issue_id': 2653176302, 'author': 'Somtom', 'body': 'Related to this:\n\nFirst [experiment](https://metaboat.slack.com/archives/C06UF8TBYH2/p1737360117918379) and [PR](https://github.com/metabase/ai-service/pull/96#issuecomment-2604209072)', 'created_at': datetime.datetime(2025, 1, 22, 6, 45, 8, tzinfo=datetime.timezone.utc)}]","Somtom on (2025-01-22 06:45:08 UTC): Related to this:

First [experiment](https://metaboat.slack.com/archives/C06UF8TBYH2/p1737360117918379) and [PR](https://github.com/metabase/ai-service/pull/96#issuecomment-2604209072)

"
2653169563,issue,open,,Questions in `Usage analytics` should never open the native query panel,"### Describe the bug

We hide the ""Show SQL"" on Usage analytics questions, but if the user had it open in another question, it opens in Usage analytics questions too.

### To Reproduce

1. Go to a question where you have ""Create native query"" permission
2. Click on ""Show editor"" > ""View the SQL""
3. Now go to a Usage analytics question
4. See the SQL


### Expected behavior

Questions in Usage analytics should never show the SQL or the Convert to SQL button

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.51.3
```

### Severity

P3

### Additional context

[Thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1731433937754949)",luizarakaki,2024-11-12 19:50:06+00:00,[],2025-02-05 19:19:28+00:00,,https://github.com/metabase/metabase/issues/49904,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2653088645,issue,closed,completed,Notebook editor should open up a simple dropdown instead of entity picker by default in the sdk,"The notebook editor inside the sdk (via the `<InteractiveQuestion.Editor />` sdk component) should open up a simple dropdown in place of the entity picker. See [this private Loom from Maz](https://www.loom.com/share/4f14a2e8b9354e88bf1743fd3c1c6724?sid=55fd71a5-4591-41ea-b99f-eb820c69046b) for the design draft of the dropdown.

This would happen in two scenarios:

- When the component is first rendered, we should just open a simple dropdown underneath the ""Pick your starting data"" button
- When we click on the ""Pick your starting data"" button, the same dropdown should appear.

See [this product doc](https://www.notion.so/metabase/Make-low-hanging-fruit-improvements-to-Shoppy-12a69354c9018011be49edf18852c7c0?pvs=4#12a69354c90180faa3eefa7e6deb7b72) for where this idea originated.

The dropdown should appear under ""Pick your starting data""

<img src=""https://github.com/user-attachments/assets/c2d11dad-f4ab-4dd8-b983-d5bd2bb93a55"" width=""400"">
",heypoom,2024-11-12 19:16:05+00:00,[],2025-01-10 14:20:40+00:00,2025-01-10 14:20:40+00:00,https://github.com/metabase/metabase/issues/49902,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2652928513,issue,open,,Column reordering quirks,"### Describe the bug

We've made improvements to column reordering in the past, and it's much better than it was before, but according to user feedback and from what can be observed from the video, it could use some work:

https://www.loom.com/share/ce68eb4775924fd4a082523020dd094c?sid=81ce29f0-78d9-4c10-94f0-82063b317d86

A couple of things that we can note here:
- There's a highlight of table content and fields that can be a bit annoying
- Dragging the column to right/left of the screen to move to unseen parts of the table works very inconsistently
- Sometimes the mouse ends in places where the column isn't, making it difficult to know where the column is and where it will end
- The table refreshes after letting the column go and that can be weird. I wasn't able to reproduce consistently, but sometimes it would make a hard refresh of the table content or prompt for a reload and that is not good




### To Reproduce

1. Create a big table with lots of columns
2. Drag the columns around

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 1.51.2
```

### Severity

P2

### Additional context

_No response_",ignacio-mb,2024-11-12 17:57:12+00:00,[],2025-02-04 20:31:53+00:00,,https://github.com/metabase/metabase/issues/49898,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2652922390,issue,closed,not_planned,Curl SSL_read error with Metabase version 1.51.3,"### Describe the bug

When I curl metabase API, I get the required json with this error at the end : `curl: (56) OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0` 

Bug with the last version v1.51.3 (enterprise)

With 1.51.2, it works properly (I had to downgrade).

### To Reproduce

1. Curl 
```
curl --location 'https:/yourdomain/api/card/yourquestion/query/json' \
--header 'Content-Type: text/plain' \
--header 'x-api-key: mb_youapikey' \
--data '{
  ""parameters"": ""string"",
  ""format_rows"": false
}'
```
2. See error

### Expected behavior

No final error `curl: (56) OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0` which crashes my scripts

### Logs

```
<some json>
curl: (56) OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0
]%    
```

### Information about your Metabase installation

openjdk 11.0.25 2024-10-15
OpenJDK Runtime Environment Temurin-11.0.25+9 (build 11.0.25+9)
OpenJDK 64-Bit Server VM Temurin-11.0.25+9 (build 11.0.25+9, mixed mode, sharing)

Exherbo Linux 6.11.6

From metabase.jar

### Severity

Medium

### Additional context

My prod environment is Clever Cloud (www.clever-cloud.com)",sebartyr,2024-11-12 17:54:22+00:00,[],2024-11-21 19:32:26+00:00,2024-11-21 19:32:25+00:00,https://github.com/metabase/metabase/issues/49897,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2484129532, 'issue_id': 2652922390, 'author': 'maximepvrt', 'body': 'same error with v0.50.33', 'created_at': datetime.datetime(2024, 11, 18, 21, 5, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484273745, 'issue_id': 2652922390, 'author': 'maximepvrt', 'body': 'I think this is due to this pull request : https://github.com/metabase/metabase/pull/49773', 'created_at': datetime.datetime(2024, 11, 18, 22, 33, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484503682, 'issue_id': 2652922390, 'author': 'paoliniluis', 'body': '@sebartyr @maximepvrt does this happen with the export json endpoint, or with all endpoints?', 'created_at': datetime.datetime(2024, 11, 19, 1, 14, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484507002, 'issue_id': 2652922390, 'author': 'paoliniluis', 'body': ""BTW: I'm using pop OS LTS\ncurl 7.81.0 (x86_64-pc-linux-gnu) libcurl/7.81.0 OpenSSL/3.0.2 zlib/1.2.11 brotli/1.0.9 zstd/1.4.8 libidn2/2.3.2 libpsl/0.21.0 (+libidn2/2.3.2) libssh/0.9.6/openssl/zlib nghttp2/1.43.0 librtmp/2.3 OpenLDAP/2.5.18\nRelease-Date: 2022-01-05\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp \nFeatures: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM NTLM_WB PSL SPNEGO SSL TLS-SRP UnixSockets zstd\n\nand I don't get this issue"", 'created_at': datetime.datetime(2024, 11, 19, 1, 17, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486723706, 'issue_id': 2652922390, 'author': 'maximepvrt', 'body': ""I'm encountering a problem when using curl on Clever Cloud, while it works perfectly on my local machine.\n\nLocal machine Environment :\n```\ncurl 8.7.1 (x86_64-apple-darwin24.0) libcurl/8.7.1 (SecureTransport) LibreSSL/3.3.6 zlib/1.2.12 nghttp2/1.62.0\nRelease-Date: 2024-03-27\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns ldap ldaps mqtt pop3 pop3s rtsp smb smbs smtp smtps telnet tftp\nFeatures: alt-svc AsynchDNS GSS-API HSTS HTTP2 HTTPS-proxy IPv6 Kerberos Largefile libz MultiSSL NTLM SPNEGO SSL threadsafe UnixSockets\n```\n\nClever Cloud Environment :\n```\ncurl 8.8.0 (x86_64-pc-linux-gnu) libcurl/8.8.0 OpenSSL/3.3.1 zlib/1.3.1 zstd/1.5.6 libidn2/2.3.7 libssh2/1.11.0 nghttp2/1.62.1\nRelease-Date: 2024-05-22\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns pop3 pop3s rtsp scp sftp smtp smtps telnet tftp\nFeatures: AsynchDNS HTTP2 HTTPS-proxy IDN IPv6 Largefile libz SSL threadsafe TLS-SRP UnixSockets zstd\n```"", 'created_at': datetime.datetime(2024, 11, 19, 20, 49, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487024965, 'issue_id': 2652922390, 'author': 'paoliniluis', 'body': 'So I would say here that the problem is the TLS termination being done on the hosting environment… could that be the case here?', 'created_at': datetime.datetime(2024, 11, 20, 0, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490610903, 'issue_id': 2652922390, 'author': 'sebartyr', 'body': ""But why with the same environment, we don't have the same issue with the v1.51.2 ?"", 'created_at': datetime.datetime(2024, 11, 21, 9, 52, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491140017, 'issue_id': 2652922390, 'author': 'maximepvrt', 'body': 'I have the same issue. In my case, everything works perfectly with v0.50.32, but the problem appears with v0.50.33.', 'created_at': datetime.datetime(2024, 11, 21, 13, 23, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491488792, 'issue_id': 2652922390, 'author': 'paoliniluis', 'body': 'have you tried with an older curl version?', 'created_at': datetime.datetime(2024, 11, 21, 15, 9, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491491131, 'issue_id': 2652922390, 'author': 'sebartyr', 'body': ""I think I have understood what's wrong\n\nI need to make more tests"", 'created_at': datetime.datetime(2024, 11, 21, 15, 9, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491492275, 'issue_id': 2652922390, 'author': 'sebartyr', 'body': '> have you tried with an older curl version?\n\nyes (the same as yours, with the same openSSL version) and with rustls as TLS backend too', 'created_at': datetime.datetime(2024, 11, 21, 15, 10, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491553081, 'issue_id': 2652922390, 'author': 'sebartyr', 'body': '```\n16:31:21.728872 [0-0] == Info: [WRITE] cw_out, wrote 7225 body bytes -> 7225\n16:31:21.728931 [0-0] == Info: [WRITE] download_write body(type=1, blen=7225) -> 0\n16:31:21.729013 [0-0] == Info: [WRITE] client_write(type=1, len=7225) -> 0\n16:31:21.729086 [0-0] == Info: [WRITE] xfer_write_resp(len=7225, eos=0) -> 0\n16:31:21.729163 [0-0] == Info: [SSL] ossl_bio_cf_in_read(len=5) -> 0, err=0\n16:31:21.729243 [0-0] == Info: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0\n16:31:21.729317 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56\n16:31:21.729391 [0-0] == Info: [WRITE] cw-out done\n16:31:21.729446 [0-0] == Info: closing connection #0\n16:31:21.729498 [0-0] == Info: [HTTPS-CONNECT] close\n16:31:21.729552 [0-0] == Info: [SETUP] close\n16:31:21.729636 [0-0] == Info: [SETUP] destroy\n16:31:21.729681 [0-0] == Info: [HTTPS-CONNECT] destroy\ncurl: (56) OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0\n```\n\nIt seems there is a bad interaction with Clever Cloud reverse-proxies.\n\nOpenSSL\n\n```\ncurl 8.11.0 (x86_64-pc-linux-gnu) libcurl/8.11.0 OpenSSL/3.4.0 zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 libssh2/1.11.0 nghttp2/1.64.0 nghttp3/1.6.0\nRelease-Date: 2024-11-06\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp ws wss\nFeatures: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTP3 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM PSL SPNEGO SSL threadsafe TLS-SRP UnixSockets zstd\n```', 'created_at': datetime.datetime(2024, 11, 21, 15, 32, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491558960, 'issue_id': 2652922390, 'author': 'sebartyr', 'body': '```\n16:33:35.283578 [0-0] == Info: [WRITE] download_write body(type=1, blen=102400) -> 0\n16:33:35.283643 [0-0] == Info: [WRITE] client_write(type=1, len=102400) -> 0\n16:33:35.283705 [0-0] == Info: [WRITE] xfer_write_resp(len=102400, eos=0) -> 0\n16:33:35.283786 [0-0] == Info: [SSL] cf->next recv(len=5741) -> 5741, 0\n16:33:35.283886 [0-0] == Info: [SSL] cf->next recv(len=6616) -> 6616, 0\n16:33:35.283992 [0-0] == Info: [SSL] cf->next recv(len=6647) -> 6647, 0\n16:33:35.284095 [0-0] == Info: [SSL] cf->next recv(len=6663) -> 6663, 0\n16:33:35.284197 [0-0] == Info: [SSL] cf->next recv(len=6597) -> 6597, 0\n16:33:35.284306 [0-0] == Info: [SSL] cf->next recv(len=6610) -> 6610, 0\n16:33:35.284402 [0-0] == Info: [SSL] cf->next recv(len=6630) -> 6630, 0\n16:33:35.284508 [0-0] == Info: [SSL] cf->next recv(len=6560) -> 6560, 0\n16:33:35.284601 [0-0] == Info: [SSL] cf->next recv(len=6575) -> 6575, 0\n16:33:35.284700 [0-0] == Info: [SSL] cf->next recv(len=6445) -> 6445, 0\n16:33:35.284806 [0-0] == Info: [SSL] cf->next recv(len=6483) -> 6483, 0\n16:33:35.284904 [0-0] == Info: [SSL] cf->next recv(len=6566) -> 6566, 0\n16:33:35.284999 [0-0] == Info: [SSL] cf->next recv(len=6026) -> 3283, 0\n16:33:35.285092 [0-0] == Info: [SSL] cf->next recv(len=4096) -> 0, 0\n16:33:35.285177 [0-0] == Info: rustls: peer closed TCP connection without first closing TLS connection\n16:33:35.285310 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56\n16:33:35.285402 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56\n16:33:35.285489 [0-0] == Info: [WRITE] cw-out done\n16:33:35.285555 [0-0] == Info: closing connection #0\n16:33:35.285621 [0-0] == Info: [HTTPS-CONNECT] close\n16:33:35.285685 [0-0] == Info: [SETUP] close\n16:33:35.285774 [0-0] == Info: [SETUP] destroy\n16:33:35.285834 [0-0] == Info: [HTTPS-CONNECT] destroy\ncurl: (56) rustls: peer closed TCP connection without first closing TLS connection\nl,""patter%  \n```\n\nSame with rustls\n\n```\ncurl 8.11.0 (x86_64-pc-linux-gnu) libcurl/8.11.0 rustls-ffi/0.14.0/rustls/0.23.13/aws-lc-rs zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 nghttp2/1.64.0 librtmp/2.3 libgsasl/2.2.1 OpenLDAP/2.6.8\nRelease-Date: 2024-11-06\nProtocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns ldap ldaps mqtt pop3 pop3s rtmp rtsp smtp smtps telnet tftp ws wss\nFeatures: alt-svc AsynchDNS brotli gsasl HSTS HTTP2 HTTPS-proxy IDN IPv6 Largefile libz PSL SSL threadsafe UnixSockets zstd\n```', 'created_at': datetime.datetime(2024, 11, 21, 15, 34, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492093827, 'issue_id': 2652922390, 'author': 'paoliniluis', 'body': 'Told ya', 'created_at': datetime.datetime(2024, 11, 21, 19, 32, 25, tzinfo=datetime.timezone.utc)}]","maximepvrt on (2024-11-18 21:05:55 UTC): same error with v0.50.33

maximepvrt on (2024-11-18 22:33:50 UTC): I think this is due to this pull request : https://github.com/metabase/metabase/pull/49773

paoliniluis on (2024-11-19 01:14:41 UTC): @sebartyr @maximepvrt does this happen with the export json endpoint, or with all endpoints?

paoliniluis on (2024-11-19 01:17:49 UTC): BTW: I'm using pop OS LTS
curl 7.81.0 (x86_64-pc-linux-gnu) libcurl/7.81.0 OpenSSL/3.0.2 zlib/1.2.11 brotli/1.0.9 zstd/1.4.8 libidn2/2.3.2 libpsl/0.21.0 (+libidn2/2.3.2) libssh/0.9.6/openssl/zlib nghttp2/1.43.0 librtmp/2.3 OpenLDAP/2.5.18
Release-Date: 2022-01-05
Protocols: dict file ftp ftps gopher gophers http https imap imaps ldap ldaps mqtt pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp 
Features: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM NTLM_WB PSL SPNEGO SSL TLS-SRP UnixSockets zstd

and I don't get this issue

maximepvrt on (2024-11-19 20:49:04 UTC): I'm encountering a problem when using curl on Clever Cloud, while it works perfectly on my local machine.

Local machine Environment :
```
curl 8.7.1 (x86_64-apple-darwin24.0) libcurl/8.7.1 (SecureTransport) LibreSSL/3.3.6 zlib/1.2.12 nghttp2/1.62.0
Release-Date: 2024-03-27
Protocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns ldap ldaps mqtt pop3 pop3s rtsp smb smbs smtp smtps telnet tftp
Features: alt-svc AsynchDNS GSS-API HSTS HTTP2 HTTPS-proxy IPv6 Kerberos Largefile libz MultiSSL NTLM SPNEGO SSL threadsafe UnixSockets
```

Clever Cloud Environment :
```
curl 8.8.0 (x86_64-pc-linux-gnu) libcurl/8.8.0 OpenSSL/3.3.1 zlib/1.3.1 zstd/1.5.6 libidn2/2.3.7 libssh2/1.11.0 nghttp2/1.62.1
Release-Date: 2024-05-22
Protocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns pop3 pop3s rtsp scp sftp smtp smtps telnet tftp
Features: AsynchDNS HTTP2 HTTPS-proxy IDN IPv6 Largefile libz SSL threadsafe TLS-SRP UnixSockets zstd
```

paoliniluis on (2024-11-20 00:14:06 UTC): So I would say here that the problem is the TLS termination being done on the hosting environment… could that be the case here?

sebartyr (Issue Creator) on (2024-11-21 09:52:29 UTC): But why with the same environment, we don't have the same issue with the v1.51.2 ?

maximepvrt on (2024-11-21 13:23:44 UTC): I have the same issue. In my case, everything works perfectly with v0.50.32, but the problem appears with v0.50.33.

paoliniluis on (2024-11-21 15:09:01 UTC): have you tried with an older curl version?

sebartyr (Issue Creator) on (2024-11-21 15:09:55 UTC): I think I have understood what's wrong

I need to make more tests

sebartyr (Issue Creator) on (2024-11-21 15:10:21 UTC): yes (the same as yours, with the same openSSL version) and with rustls as TLS backend too

sebartyr (Issue Creator) on (2024-11-21 15:32:39 UTC): ```
16:31:21.728872 [0-0] == Info: [WRITE] cw_out, wrote 7225 body bytes -> 7225
16:31:21.728931 [0-0] == Info: [WRITE] download_write body(type=1, blen=7225) -> 0
16:31:21.729013 [0-0] == Info: [WRITE] client_write(type=1, len=7225) -> 0
16:31:21.729086 [0-0] == Info: [WRITE] xfer_write_resp(len=7225, eos=0) -> 0
16:31:21.729163 [0-0] == Info: [SSL] ossl_bio_cf_in_read(len=5) -> 0, err=0
16:31:21.729243 [0-0] == Info: OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0
16:31:21.729317 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56
16:31:21.729391 [0-0] == Info: [WRITE] cw-out done
16:31:21.729446 [0-0] == Info: closing connection #0
16:31:21.729498 [0-0] == Info: [HTTPS-CONNECT] close
16:31:21.729552 [0-0] == Info: [SETUP] close
16:31:21.729636 [0-0] == Info: [SETUP] destroy
16:31:21.729681 [0-0] == Info: [HTTPS-CONNECT] destroy
curl: (56) OpenSSL SSL_read: SSL_ERROR_SYSCALL, errno 0
```

It seems there is a bad interaction with Clever Cloud reverse-proxies.

OpenSSL

```
curl 8.11.0 (x86_64-pc-linux-gnu) libcurl/8.11.0 OpenSSL/3.4.0 zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 libssh2/1.11.0 nghttp2/1.64.0 nghttp3/1.6.0
Release-Date: 2024-11-06
Protocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns mqtt pop3 pop3s rtsp scp sftp smb smbs smtp smtps telnet tftp ws wss
Features: alt-svc AsynchDNS brotli GSS-API HSTS HTTP2 HTTP3 HTTPS-proxy IDN IPv6 Kerberos Largefile libz NTLM PSL SPNEGO SSL threadsafe TLS-SRP UnixSockets zstd
```

sebartyr (Issue Creator) on (2024-11-21 15:34:42 UTC): ```
16:33:35.283578 [0-0] == Info: [WRITE] download_write body(type=1, blen=102400) -> 0
16:33:35.283643 [0-0] == Info: [WRITE] client_write(type=1, len=102400) -> 0
16:33:35.283705 [0-0] == Info: [WRITE] xfer_write_resp(len=102400, eos=0) -> 0
16:33:35.283786 [0-0] == Info: [SSL] cf->next recv(len=5741) -> 5741, 0
16:33:35.283886 [0-0] == Info: [SSL] cf->next recv(len=6616) -> 6616, 0
16:33:35.283992 [0-0] == Info: [SSL] cf->next recv(len=6647) -> 6647, 0
16:33:35.284095 [0-0] == Info: [SSL] cf->next recv(len=6663) -> 6663, 0
16:33:35.284197 [0-0] == Info: [SSL] cf->next recv(len=6597) -> 6597, 0
16:33:35.284306 [0-0] == Info: [SSL] cf->next recv(len=6610) -> 6610, 0
16:33:35.284402 [0-0] == Info: [SSL] cf->next recv(len=6630) -> 6630, 0
16:33:35.284508 [0-0] == Info: [SSL] cf->next recv(len=6560) -> 6560, 0
16:33:35.284601 [0-0] == Info: [SSL] cf->next recv(len=6575) -> 6575, 0
16:33:35.284700 [0-0] == Info: [SSL] cf->next recv(len=6445) -> 6445, 0
16:33:35.284806 [0-0] == Info: [SSL] cf->next recv(len=6483) -> 6483, 0
16:33:35.284904 [0-0] == Info: [SSL] cf->next recv(len=6566) -> 6566, 0
16:33:35.284999 [0-0] == Info: [SSL] cf->next recv(len=6026) -> 3283, 0
16:33:35.285092 [0-0] == Info: [SSL] cf->next recv(len=4096) -> 0, 0
16:33:35.285177 [0-0] == Info: rustls: peer closed TCP connection without first closing TLS connection
16:33:35.285310 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56
16:33:35.285402 [0-0] == Info: [SSL] cf_recv(len=102400) -> -1, 56
16:33:35.285489 [0-0] == Info: [WRITE] cw-out done
16:33:35.285555 [0-0] == Info: closing connection #0
16:33:35.285621 [0-0] == Info: [HTTPS-CONNECT] close
16:33:35.285685 [0-0] == Info: [SETUP] close
16:33:35.285774 [0-0] == Info: [SETUP] destroy
16:33:35.285834 [0-0] == Info: [HTTPS-CONNECT] destroy
curl: (56) rustls: peer closed TCP connection without first closing TLS connection
l,""patter%  
```

Same with rustls

```
curl 8.11.0 (x86_64-pc-linux-gnu) libcurl/8.11.0 rustls-ffi/0.14.0/rustls/0.23.13/aws-lc-rs zlib/1.3.1 brotli/1.1.0 zstd/1.5.6 libidn2/2.3.7 libpsl/0.21.5 nghttp2/1.64.0 librtmp/2.3 libgsasl/2.2.1 OpenLDAP/2.6.8
Release-Date: 2024-11-06
Protocols: dict file ftp ftps gopher gophers http https imap imaps ipfs ipns ldap ldaps mqtt pop3 pop3s rtmp rtsp smtp smtps telnet tftp ws wss
Features: alt-svc AsynchDNS brotli gsasl HSTS HTTP2 HTTPS-proxy IDN IPv6 Largefile libz PSL SSL threadsafe UnixSockets zstd
```

paoliniluis on (2024-11-21 19:32:25 UTC): Told ya

"
2652497834,issue,closed,not_planned,[Epic] Rationalize Metabase Colors,"[Designs](https://www.figma.com/design/OlyKP09vro7EkQ2ZzXDDla/Colors?node-id=720-2712&node-type=frame&t=RNVNnU0lOUcxoCpI-0)

[Product Doc](https://www.notion.so/metabase/Establish-a-semantic-color-system-beach-head-15169354c90180a6918df34315dff29c)

- #49356 
- #49539
- [ ] Figure out how to reconcile JS + CSS colors",iethree,2024-11-12 15:17:49+00:00,[],2025-02-05 14:45:52+00:00,2025-02-05 14:45:51+00:00,https://github.com/metabase/metabase/issues/49887,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2652483495,issue,closed,completed,Move model details into sidesheets,"[Designs](https://www.figma.com/design/NOCVfjRaqkVhNqNq8jL9mX/Rework-the-info-sidebar-and-entity-actions?node-id=6753-63879&node-type=section&t=FpEgSE3Tff8tRuCo-0)

[Discussion](https://metaboat.slack.com/archives/C064EB1UE5P/p1730125129805129)
",iethree,2024-11-12 15:11:42+00:00,['rafpaf'],2025-01-31 13:53:21+00:00,2025-01-31 13:53:21+00:00,https://github.com/metabase/metabase/issues/49886,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2652477807,issue,open,,Rework the +New Menu,[Product Doc](https://www.notion.so/metabase/Revise-the-New-button-s-menu-e679b00415184a6f9eabd75c34d5b123),iethree,2024-11-12 15:09:21+00:00,[],2024-12-16 14:24:37+00:00,,https://github.com/metabase/metabase/issues/49885,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2652386439,issue,closed,completed,Notebook expression editor autocomplete issues,"### Describe the bug

Slack thread: https://metaboat.slack.com/archives/C0645JP1W81/p1730974411711279 (there's a [loom](https://metaboat.slack.com/archives/C0645JP1W81/p1730987756533899?thread_ts=1730974411.711279&cid=C0645JP1W81) in it).

It affects custom expressions in filters, custom columns, custom aggregations.



### To Reproduce

0. Prerequisite for all cases: New > Question > Orders > Custom Column

----

#### 1. Applying autocomplete suggestion eats up subsequent characters

1. Type `case([Total] > 200, , ""Nothing"")` 
2. Put cursor right before the second comma
3. Type `[tot` and hit Enter

❌  Remaining text disappears

----

#### 2. Expression input gets cleared unexpectedly

1. Type `case([Tax] > 1, case([Total] > 200, [Total], ""Nothing""), [Tax])` 
2. Select the last `[Tax]` and cut it
3. Click to put cursor right before the second `case`
4. Paste
5. Hit space
6. Click away?

❌ Expression disappears
❌ Error is not shown even though the expression is invalid

----

#### 3. Up/Down arrow keys do not move the cursor when expression wraps in multiple lines

1. Type `case([Tax] > 1, case([Total] > 200, [Total], ""Nothing""), [Tax])` 
2. Move cursor into second `[Total]`
3. Hit arrow key

❌  Arrow key does not move cursor to the next line

----

#### 4. No suggestion selected after moving cursor

1. Type `[Product` 
2. Hit Arrow Down until `[Product → Vendor]` is selected
3. Hit Enter
4. Hit Arrow Left twice 

❌ Suggestion is shown but it's not highlighted


### Information about your Metabase installation

master, a6a1e56a12136b0aebf8ca9c78fae36ce656ecbf

### Severity

P2

### Additional context

- When do we show suggestions, when do we show autocomplete items
- The expression area should be bigger
- The help popover for the function should highlight the currently edited argument
",kamilmielnik,2024-11-12 14:38:06+00:00,['kamilmielnik'],2024-11-20 12:54:41+00:00,2024-11-20 12:10:42+00:00,https://github.com/metabase/metabase/issues/49882,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2652333431,issue,closed,completed,Prevent SDK version from upgrading unintentionally,"We're currently using `1.51.x` and `1.52.x` for the SDK version. The problem is, by default, npm/yarn installs the package as `^` which allows minor version upgrades. This could lead to a situation where the package lock file got updated when some other dependencies are added/removed and causes the SDK version to be bumped unintentionally, since `1.52.x` also satisfies `^1.51.0` which it not what we intended.

The solution is to use `0.51.x` instead since the version has [a special meaning](https://semver.org/).

> Major version zero (0.y.z) is for initial development. Anything MAY change at any time. The public API SHOULD NOT be considered stable.

Also, while we're at it we want to make sure the version of `master` has a proper version suffix to indicate that it's not stable.

```[tasklist]
### Tasks
- [x] Use version `0.x.y` instead
- [x] Make sure the next version `0.52.x-nightly` has a proper version suffix and has the dist-tag `nightly`
```",WiNloSt,2024-11-12 14:21:40+00:00,['WiNloSt'],2024-11-13 04:22:06+00:00,2024-11-13 04:22:06+00:00,https://github.com/metabase/metabase/issues/49881,"[('.CI & Tests', '')]",[],
2652315047,issue,closed,not_planned,"Serialization import breaks when an ID number is followed by ""e"" or ""E"" due to it being interpreted as scientific notation","### Describe the bug

 YAML, when a number is followed by ""e"" or ""E"", it's interpreted as scientific notation causing an exception with ` ##inf`

### To Reproduce

Create a new metabase instance since this would come with an Example Collection, always having an ID of 1

![Image](https://github.com/user-attachments/assets/16a4eb97-e48a-47c0-acfd-985d68e78648)

Create an API key and export that collection

```
 curl \        
  -H 'x-api-key: your_api_key' \
  -X POST 'http://localhost:3000/api/ee/serialization/export?collection=1&full_stacktrace=true' \ 
  -o metabase_data.tgz 
```

If you go to the ecommerce insights YAML file, which is the dashboard inside the Examples Collection

![Image](https://github.com/user-attachments/assets/15e5e213-61e0-465e-9bc7-b05ad6a301af)

You will find a number of IDs which are not exported with the `''` 

![Image](https://github.com/user-attachments/assets/cf1e3ca9-d346-4546-8a54-de7bbf506d02)


Now the above will not hit the issue since it doesn't have any IDs that have an `e` followed by a sequence of numbers such as `89e41117` the serialization process will interpret this in the scientific notation and will fail the serialization with the following error:


`#ordered/map ([:id ##Inf] [:isMultiSelect false] [:name ""Name""] [:sectionId ""string""] [:slug ""name""] [:type ""string/=""] [:values_source_config #ordered/map ([:card_id 5579] [:value_field [""field"" ""empl_fullname"" #ordered/map ([:base-type ""type/Text""])]])] [:values_source_type ""card""])`

Notice the `id ##Inf` at the beginning 

### Expected behavior

**These kind of IDs are interpreted as a string so there is no confusion of scientific notations**

metabase.util.yaml> (yaml/parse-string ""a: 1\nb: 2"")
{:a 1, :b 2}

metabase.util.yaml> (yaml/parse-string ""a: 1\nb: 89"")
{:a 1, :b 89}

metabase.util.yaml> (yaml/parse-string ""a: 1\nb: 89e41117"")
{:a 1, :b ##Inf} -- `WRONG`

metabase.util.yaml> (-> {:a 1, :b ""89e41117""} yaml/generate-string)
""{a: 1, b: '89e41117'}\n"" -- `RIGHT`

### Logs

`#ordered/map ([:id ##Inf] [:isMultiSelect false] [:name ""Name""] [:sectionId ""string""] [:slug ""name""] [:type ""string/=""] [:values_source_config #ordered/map ([:card_id 5579] [:value_field [""field"" ""empl_fullname"" #ordered/map ([:base-type ""type/Text""])]])] [:values_source_type ""card""])`


### Information about your Metabase installation

```JSON
Happens in 49, 50 and 51
```

### Severity

A customer in 49 flagged this since it broke the serialization process

### Additional context

A workaround for this would be to manually add the `''` directly in the yaml file ",Tony-metabase,2024-11-12 14:14:00+00:00,[],2024-12-20 15:25:21+00:00,2024-12-20 15:25:19+00:00,https://github.com/metabase/metabase/issues/49880,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2476153889, 'issue_id': 2652315047, 'author': 'piranha', 'body': 'Cannot reproduce this, tests in #49967 show that YAML quotes strings if they resemble numbers (even in scientific notation).', 'created_at': datetime.datetime(2024, 11, 14, 11, 51, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476174340, 'issue_id': 2652315047, 'author': 'Tony-metabase', 'body': ""Thanks @piranha !! \n\nI also confirm from my end. these kind of numbers get a `''` when dumped. I am asking for more details around 2 the customers that hit this like their Diagnostic Info, Environment and how they integrated serialization with the whole import/export flow"", 'created_at': datetime.datetime(2024, 11, 14, 12, 2, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476175315, 'issue_id': 2652315047, 'author': 'Tony-metabase', 'body': 'I will drop the escalation for now since we need more information around this', 'created_at': datetime.datetime(2024, 11, 14, 12, 3, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491163113, 'issue_id': 2652315047, 'author': 'Tony-metabase', 'body': ""Moving this to P2 since we cannot replicate and we don't have more information to work on right now"", 'created_at': datetime.datetime(2024, 11, 21, 13, 31, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557216398, 'issue_id': 2652315047, 'author': 'Tony-metabase', 'body': 'Closing this one since there has been inactivity form the user that reached out about this issue and internally cannot be replicated', 'created_at': datetime.datetime(2024, 12, 20, 15, 25, 19, tzinfo=datetime.timezone.utc)}]","piranha on (2024-11-14 11:51:40 UTC): Cannot reproduce this, tests in #49967 show that YAML quotes strings if they resemble numbers (even in scientific notation).

Tony-metabase (Issue Creator) on (2024-11-14 12:02:58 UTC): Thanks @piranha !! 

I also confirm from my end. these kind of numbers get a `''` when dumped. I am asking for more details around 2 the customers that hit this like their Diagnostic Info, Environment and how they integrated serialization with the whole import/export flow

Tony-metabase (Issue Creator) on (2024-11-14 12:03:30 UTC): I will drop the escalation for now since we need more information around this

Tony-metabase (Issue Creator) on (2024-11-21 13:31:11 UTC): Moving this to P2 since we cannot replicate and we don't have more information to work on right now

Tony-metabase (Issue Creator) on (2024-12-20 15:25:19 UTC): Closing this one since there has been inactivity form the user that reached out about this issue and internally cannot be replicated

"
2652282084,issue,closed,completed,We broke premium token caching,"### Describe the bug

We refactored the token check mechanism in https://github.com/metabase/metabase/pull/48147
Looks like we have two problems:

1. We Log that we are checking the token with the metastore _a lot_.

```shell
2024-11-12 07:46:39,006 DEBUG middleware.log :: GET /api/setup/admin_checklist 200 6.5 ms (11 DB calls) App DB connections: 0/10 Jetty threads: 8/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,213 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,217 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,219 DEBUG middleware.log :: GET /api/setting 200 230.5 ms (20 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,221 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,221 DEBUG middleware.log :: GET /api/session/properties 200 235.7 ms (14 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,235 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,240 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,240 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,241 DEBUG middleware.log :: GET /api/session/properties 200 15.4 ms (14 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,243 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
```

2. And *far more serious*, we are not honoring the 24 hour cache policy but only a 5 minute cache policy. 

The thing to note from https://github.com/metabase/metabase/pull/48147 is that the function`metabase.public-settings.premium-features/fetch-token-status` went from a TTL of 24 hours to no caching. And the only thing catching us is that we had some double redundancy in `fetch-token-and-parse-body*` of `(u/minutes->ms 5)`.

### To Reproduce

`MB_JETTY_PORT=3006 MB_PREMIUM_EMBEDDING_TOKEN=$TOKEN java ""$(socket-repl 6006)"" -jar $JARS/1.51.1.8.jar`

and then see the logs. I've instrumented my jar to print out when it is actually making the request and i dropped the cache duration from 5 minutes to 20 seconds to illustrate the problem.

```
2024-11-12 07:43:25,561 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:25,561 DEBUG middleware.log :: GET /api/user/current 200 12.8 ms (12 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (6 idle, 0 queued) (64 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
******************************************************************************
MAKING THE REQUEST
******************************************************************************
2024-11-12 07:43:25,592 DEBUG middleware.log :: GET /api/database 200 4.4 ms (1 DB calls) App DB connections: 0/10 Jetty threads: 10/50 (4 idle, 0 queued) (64 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:43:25,617 DEBUG middleware.log :: GET /api/search 200 27.7 ms (5 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (4 idle, 0 queued) (64 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
...
2024-11-12 07:43:50,355 DEBUG middleware.log :: GET /api/session/properties 200 19.5 ms (14 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (65 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:43:50,361 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,364 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,365 DEBUG middleware.log :: GET /api/setting 200 30.4 ms (20 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (65 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:43:50,391 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,405 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,406 DEBUG middleware.log :: GET /api/session/properties 200 40.9 ms (14 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (65 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:43:50,411 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,414 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:43:50,415 DEBUG middleware.log :: GET /api/setting 200 45.4 ms (20 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (65 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:45:57,965 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:45:57,966 DEBUG middleware.log :: GET /api/collection/tree 200 22.4 ms (4 DB calls) App DB connections: 0/10 Jetty threads: 10/50 (0 idle, 0 queued) (60 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:45:57,966 DEBUG middleware.log :: GET /api/activity/recents 200 20.2 ms (2 DB calls) App DB connections: 0/10 Jetty threads: 10/50 (0 idle, 0 queued) (60 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:45:57,966 DEBUG middleware.log :: GET /api/database 200 21.8 ms (1 DB calls) App DB connections: 0/10 Jetty threads: 10/50 (0 idle, 0 queued) (60 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
******************************************************************************
MAKING THE REQUEST
******************************************************************************
...
2024-11-12 07:45:58,010 DEBUG middleware.log :: GET /api/automagic-dashboards/database/1/candidates 200 17.9 ms (12 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:45:58,194 DEBUG middleware.log :: GET /api/util/bug_report_details 200 250.1 ms (1 DB calls) App DB connections: 0/10 Jetty threads: 5/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,003 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
******************************************************************************
MAKING THE REQUEST
******************************************************************************
2024-11-12 07:46:39,006 DEBUG middleware.log :: GET /api/setup/admin_checklist 200 6.5 ms (11 DB calls) App DB connections: 0/10 Jetty threads: 8/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,213 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,217 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...
2024-11-12 07:46:39,219 DEBUG middleware.log :: GET /api/setting 200 230.5 ms (20 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (67 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-11-12 07:46:39,221 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token 'f325...d01a' is valid...

```

So over a span of a few minutes (`07:46:39,221` - `07:43:25,561`) i've made three actual token requests to the store and have logged _myriad_ logs of ""Checking with the MetaStore to see whether token""

### Expected behavior

We should cache token checks for 24 hours

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.51.1.8.jar
```

### Severity

p2

### Additional context

_No response_",dpsutton,2024-11-12 14:01:06+00:00,[],2024-11-19 21:46:56+00:00,2024-11-15 21:41:59+00:00,https://github.com/metabase/metabase/issues/49879,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2652266299,issue,closed,completed,Variable - Missing trunc when field filter is calling a date column with date and time,"### Describe the bug

I use a field filter called date, with default value Today. 
This variable is compared with a date column with date and time.
The variabel look like this:
and ""KUNDE"".""EKKONTRIMPORT"".""LOGGDATOTIDNY"" = date '2024-11-12'

since LOGGDATOTIDNY have date and time, this two dates will never be correct without a trunc, like this.
and trunc(""KUNDE"".""EKKONTRIMPORT"".""LOGGDATOTIDNY"") = date '2024-11-12'

I have upgrade to last version, then trunc dissapear from the variable.

Could you please add trunc again to the column we comparing against, or let me choose to use trunc or not?

best regards Vilfred Gangsøy

### To Reproduce

1. Define a field variable with date widget type, select Today as default value.
2. Compare against a column with date and time
3. Will never be equal without trunc(fildname)


### Expected behavior

Use trunc around the field, as used in previus releases.
and trunc(""KUNDE"".""EKKONTRIMPORT"".""LOGGDATOTIDNY"") = date '2024-11-12'

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.51.3 
- Oracle 19
```

### Severity

Annoying with this kind of issues.

### Additional context

Please fix thisi ssue.",VilfredGang,2024-11-12 13:55:38+00:00,['ericnormand'],2025-01-27 22:10:33+00:00,2025-01-23 23:23:18+00:00,https://github.com/metabase/metabase/issues/49878,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2605883773, 'issue_id': 2652266299, 'author': 'ericnormand', 'body': 'I can\'t reproduce this on 4f6373a71dceff5085bb829aaffa6be7d089e5df. Something changed where it generates a date-time range for the whole day:\n\nNative query:\n\n```\nSELECT\n  *\nFROM\n      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""\n  \nWHERE\n  rownum <= 1048575 AND {{date_filter}}\n```\n\nFilter config:\n\n<img width=""341"" alt=""Image"" src=""https://github.com/user-attachments/assets/cdb5002c-283d-4e69-ba20-52bfa74e911f"" />\n\nGenerated SQL:\n\n```\nSELECT\n  *\nFROM\n      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""\n  \nWHERE\n  rownum <= 1048575\n   AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" >= timestamp \'2024-11-06 00:00:00.000 UTC\' AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" < timestamp \'2024-11-07 00:00:00.000 UTC\'\n```', 'created_at': datetime.datetime(2025, 1, 21, 22, 38, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605929200, 'issue_id': 2652266299, 'author': 'ericnormand', 'body': ""I've tried every type of date option that work on a single date:\n\n* Single Date\n* Relative Date\n* All Options\n  * Today\n  * Specific Dates -> On\n\nAll seem to generate a >= AND < clauses instead of = clauses."", 'created_at': datetime.datetime(2025, 1, 21, 23, 12, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605943425, 'issue_id': 2652266299, 'author': 'ericnormand', 'body': 'Okay, I checked out `0.51.3` and it is indeed broken there:\n\n```\nSELECT\n  *\nFROM\n      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""\n  \nWHERE\n  rownum <= 1048575\n   AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" = date \'2024-11-06\'\n```\n\nSame options as above:\n\n```\nSELECT\n  *\nFROM\n      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""\nWHERE\n  rownum <= 1048575 AND {{date_filter}}\n```\n\n<img width=""342"" alt=""Image"" src=""https://github.com/user-attachments/assets/def5ac74-8cbc-451d-9d4a-f00fb4b67e7a"" />', 'created_at': datetime.datetime(2025, 1, 21, 23, 23, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605951876, 'issue_id': 2652266299, 'author': 'ericnormand', 'body': 'Fixed on master (on or before 4f6373a71dceff5085bb829aaffa6be7d089e5df).', 'created_at': datetime.datetime(2025, 1, 21, 23, 30, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609104539, 'issue_id': 2652266299, 'author': 'kamilmielnik', 'body': '@ericnormand please add a repro before closing the issue as fixed 🙏 We always do that to prevent regressions.', 'created_at': datetime.datetime(2025, 1, 23, 8, 4, 34, tzinfo=datetime.timezone.utc)}]","ericnormand (Assginee) on (2025-01-21 22:38:32 UTC): I can't reproduce this on 4f6373a71dceff5085bb829aaffa6be7d089e5df. Something changed where it generates a date-time range for the whole day:

Native query:

```
SELECT
  *
FROM
      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""
  
WHERE
  rownum <= 1048575 AND {{date_filter}}
```

Filter config:

<img width=""341"" alt=""Image"" src=""https://github.com/user-attachments/assets/cdb5002c-283d-4e69-ba20-52bfa74e911f"" />

Generated SQL:

```
SELECT
  *
FROM
      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""
  
WHERE
  rownum <= 1048575
   AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" >= timestamp '2024-11-06 00:00:00.000 UTC' AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" < timestamp '2024-11-07 00:00:00.000 UTC'
```

ericnormand (Assginee) on (2025-01-21 23:12:01 UTC): I've tried every type of date option that work on a single date:

* Single Date
* Relative Date
* All Options
  * Today
  * Specific Dates -> On

All seem to generate a >= AND < clauses instead of = clauses.

ericnormand (Assginee) on (2025-01-21 23:23:45 UTC): Okay, I checked out `0.51.3` and it is indeed broken there:

```
SELECT
  *
FROM
      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""
  
WHERE
  rownum <= 1048575
   AND ""mb_test"".""date_cols_with_datetime_values_dates_with_time"".""date_with_time"" = date '2024-11-06'
```

Same options as above:

```
SELECT
  *
FROM
      ""mb_test"".""date_cols_with_datetime_values_dates_with_time""
WHERE
  rownum <= 1048575 AND {{date_filter}}
```

<img width=""342"" alt=""Image"" src=""https://github.com/user-attachments/assets/def5ac74-8cbc-451d-9d4a-f00fb4b67e7a"" />

ericnormand (Assginee) on (2025-01-21 23:30:28 UTC): Fixed on master (on or before 4f6373a71dceff5085bb829aaffa6be7d089e5df).

kamilmielnik on (2025-01-23 08:04:34 UTC): @ericnormand please add a repro before closing the issue as fixed 🙏 We always do that to prevent regressions.

"
2652078401,issue,closed,completed,Incorrect Y-axis displayed when hovering over series in dual Y-axis plot,"### Describe the bug

When using a plot with two Y-axes (left and right) for different series, the axis display behavior is incorrect when hovering over a series or its corresponding legend.

### To Reproduce

1. Create a plot with two series, each associated with a different Y-axis (left and right).
2. Hover over the series associated with the left Y-axis.
3. Observe that the right Y-axis is displayed instead of the left one.

![Image](https://github.com/user-attachments/assets/faf344cb-fecc-4ebe-ba5f-8bafe5c7fe50)
![Image](https://github.com/user-attachments/assets/33e70f49-8d53-4e6b-b01b-badad2c489ee)


### Expected behavior

When hovering over a series, the Y-axis associated with that series should be displayed, while the other axis should be hidden.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.8 (Debian 15.8-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-1018-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

This issue affects the readability and usability of dual Y-axis plots, as users cannot easily associate the correct scale with the series they are examining.

### Additional context

_No response_",Juanfer-HM,2024-11-12 12:43:31+00:00,['alxnddr'],2024-11-14 23:15:39+00:00,2024-11-14 22:32:44+00:00,https://github.com/metabase/metabase/issues/49874,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2651396707,issue,closed,not_planned,Click Behavior Not Working in Embedded Dashboard - Need Help,"### Describe the bug

I'm experiencing an issue where the Click Behavior functionality, which normally allows updating dashboard filters when clicking on table values, is not working in embedded tables. While this feature works perfectly in regular dashboard views, it becomes non-functional when the same dashboard is embedded.


### To Reproduce

Steps to Reproduce:
1. Create a dashboard with multiple visualizations
2. Add a table visualization
3. Configure Click Behavior on the table to update a dashboard filter
4. Test the behavior in regular dashboard view (works correctly)
5. Embed the dashboard
6. Try to use the Click Behavior functionality in the embedded view (doesn't work)

### Expected behavior

Expected Behavior: 
- Clicking on a value in the embedded table should trigger the configured Click Behavior
- Dashboard filters should update according to the Click Behavior settings
- The filtered results should refresh automatically

Actual Behavior:
- Clicking on table values in the embedded view produces no response
- The Click Behavior configurations set in the dashboard do not trigger
- No filter updates occur when interacting with the table

### Logs

Console log of embedded page
```
Unchecked runtime.lastError: The message port closed before a response was received.Understand this errorAI
vendor.1d6eb12d1c69bf84.js:1 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-wEG0FrntzA'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-bgUp5tqDCSC1xokY+fdYcHMM/Fap5RX+TCFkA0sXuRk='), or a nonce ('nonce-...') is required to enable inline execution.

e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
e @ vendor.1d6eb12d1c69bf84.js:1
aJ @ vendor.1d6eb12d1c69bf84.js:1
aZ @ vendor.1d6eb12d1c69bf84.js:1
aK @ vendor.1d6eb12d1c69bf84.js:1
aZ @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
sH @ vendor.1d6eb12d1c69bf84.js:1
sS @ vendor.1d6eb12d1c69bf84.js:1
w @ vendor.1d6eb12d1c69bf84.js:1
B @ vendor.1d6eb12d1c69bf84.js:1Understand this errorAI
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
nx @ core.cljs:4009
ny @ core.cljs:4003
nv @ core.cljs:3997
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
(anonymous) @ console.cljs:33
t @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
p.kE @ glogi.cljs:26
R @ normalize.cljc:46
lx.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2416
l @ normalize.cljc:85
m.LZ.j @ normalize.cljc:91
m.LZ.g @ normalize.cljc:80
m.LZ.h @ normalize.cljc:77
(anonymous) @ convert.cljc:233
lx.g.h @ core.cljs:11497
u @ convert.cljc:635
er.N1 @ cache.cljc:114
q.j @ cache.cljc:165
e @ js.cljs:148
S @ query.ts:28
query @ app-embed.5906fd5e6592052e.js:1
b @ targets.ts:156
f @ targets.ts:83
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
g @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ data-fetching.ts:736
await in (anonymous)
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
F @ PublicOrEmbeddedDashboard.tsx:90
(anonymous) @ app-embed.5906fd5e6592052e.js:198
aH @ vendor.1d6eb12d1c69bf84.js:1
sj @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
w @ vendor.1d6eb12d1c69bf84.js:1
B @ vendor.1d6eb12d1c69bf84.js:1Understand this warningAI
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[w [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[w [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
nx @ core.cljs:4009
ny @ core.cljs:4003
nv @ core.cljs:3997
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
(anonymous) @ console.cljs:33
t @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
p.kE @ glogi.cljs:26
R @ normalize.cljc:46
lx.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2416
l @ normalize.cljc:85
m.LZ.j @ normalize.cljc:91
m.LZ.g @ normalize.cljc:80
m.LZ.h @ normalize.cljc:77
(anonymous) @ query.cljc:211
lx.g.g @ core.cljs:11503
I.Z2 @ query.cljc:291
nv @ core.cljs:3996
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
n @ core.cljc:80
u @ js.cljs:184
er.N1 @ cache.cljc:114
q.j @ cache.cljc:165
e @ js.cljs:148
S @ query.ts:28
query @ app-embed.5906fd5e6592052e.js:1
b @ targets.ts:156
f @ targets.ts:83
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
g @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ data-fetching.ts:736
await in (anonymous)
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
F @ PublicOrEmbeddedDashboard.tsx:90
(anonymous) @ app-embed.5906fd5e6592052e.js:198
aH @ vendor.1d6eb12d1c69bf84.js:1
sj @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
w @ vendor.1d6eb12d1c69bf84.js:1
B @ vendor.1d6eb12d1c69bf84.js:1Understand this warningAI
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
nx @ core.cljs:4009
ny @ core.cljs:4003
nv @ core.cljs:3997
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
(anonymous) @ console.cljs:33
t @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
p.kE @ glogi.cljs:26
R @ normalize.cljc:46
lx.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2416
l @ normalize.cljc:85
m.LZ.j @ normalize.cljc:91
m.LZ.g @ normalize.cljc:80
m.LZ.h @ normalize.cljc:77
(anonymous) @ convert.cljc:233
lx.g.h @ core.cljs:11497
u @ convert.cljc:635
er.N1 @ cache.cljc:114
q.j @ cache.cljc:165
e @ js.cljs:148
S @ query.ts:28
query @ app-embed.5906fd5e6592052e.js:1
b @ targets.ts:156
f @ targets.ts:83
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
g @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:180
(anonymous) @ vendor.1d6eb12d1c69bf84.js:15
a @ vendor.1d6eb12d1c69bf84.js:15
(anonymous) @ vendor.1d6eb12d1c69bf84.js:15
a @ vendor.1d6eb12d1c69bf84.js:15
(anonymous) @ PublicOrEmbeddedDashboard.tsx:45
r @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
f @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
notify @ vendor.1d6eb12d1c69bf84.js:11
notifyNestedSubs @ vendor.1d6eb12d1c69bf84.js:11
f @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
notify @ vendor.1d6eb12d1c69bf84.js:11
notifyNestedSubs @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
g @ vendor.1d6eb12d1c69bf84.js:8
dispatch @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
dispatch @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
await in (anonymous)
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
pZ @ app.js:88
pM @ app-embed.5906fd5e6592052e.js:475
18314 @ app-embed.js:12
a @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:478
a.O @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:478
u @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:1Understand this warningAI
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[w [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[w [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
nx @ core.cljs:4009
ny @ core.cljs:4003
nv @ core.cljs:3997
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
(anonymous) @ console.cljs:33
t @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
p.kE @ glogi.cljs:26
R @ normalize.cljc:46
lx.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2416
l @ normalize.cljc:85
m.LZ.j @ normalize.cljc:91
m.LZ.g @ normalize.cljc:80
m.LZ.h @ normalize.cljc:77
(anonymous) @ query.cljc:211
lx.g.g @ core.cljs:11503
I.Z2 @ query.cljc:291
nv @ core.cljs:3996
nb @ core.cljs:3991
lx.O.g @ core.cljs:3985
n @ core.cljc:80
u @ js.cljs:184
er.N1 @ cache.cljc:114
q.j @ cache.cljc:165
e @ js.cljs:148
S @ query.ts:28
query @ app-embed.5906fd5e6592052e.js:1
b @ targets.ts:156
f @ targets.ts:83
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:183
g @ app-embed.5906fd5e6592052e.js:183
(anonymous) @ app-embed.5906fd5e6592052e.js:180
(anonymous) @ vendor.1d6eb12d1c69bf84.js:15
a @ vendor.1d6eb12d1c69bf84.js:15
(anonymous) @ vendor.1d6eb12d1c69bf84.js:15
a @ vendor.1d6eb12d1c69bf84.js:15
(anonymous) @ PublicOrEmbeddedDashboard.tsx:45
r @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
f @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
notify @ vendor.1d6eb12d1c69bf84.js:11
notifyNestedSubs @ vendor.1d6eb12d1c69bf84.js:11
f @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:11
notify @ vendor.1d6eb12d1c69bf84.js:11
notifyNestedSubs @ vendor.1d6eb12d1c69bf84.js:11
a @ vendor.1d6eb12d1c69bf84.js:11
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
g @ vendor.1d6eb12d1c69bf84.js:8
dispatch @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:1
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
dispatch @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
await in (anonymous)
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
(anonymous) @ vendor.1d6eb12d1c69bf84.js:8
pZ @ app.js:88
pM @ app-embed.5906fd5e6592052e.js:475
18314 @ app-embed.js:12
a @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:478
a.O @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:478
u @ runtime.93459c27ecdfc4e2.js:1
(anonymous) @ app-embed.5906fd5e6592052e.js:1Understand this warningAI
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""tr"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-11"",
      ""tag"": ""v0.51.3"",
      ""hash"": ""d757d0b""
    },
    ""settings"": {
      ""report-timezone"": ""Turkey""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.8 (Debian 15.8-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-198-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Istanbul""
  }
}
```

### Severity

High Impact - Blocking Core Functionality
This issue significantly impacts our team's ability to effectively use embedded analytics. Interactive data exploration is a key feature our team members rely on for their daily analysis work. While not completely blocking Metabase usage, it severely limits our ability to drill down into data within embedded dashboards. Our analysts currently have to switch between embedded and regular dashboard views to perform detailed analysis, which disrupts their workflow and reduces productivity.

### Additional context

Environment Details:

- Metabase Version: 0.51.3 
- Embedding Method: iframe/standalone/static embedding
- Dashboard Type: Embedded
- Browser: Chrome 130.0.6723.117
- Operating system: OS X Apple Silicon 15.0.1
- My Database: MsSQL
- Metabase Hosting: Docker/Ubuntu (Open Source Version)
- Internal DB: PostgreSQL

Questions:
1. Is this a known limitation of embedded dashboards?
2. Are there any workarounds available to achieve similar functionality in embedded views?
3. If this is not supported, are there plans to add this feature in future releases?

Additional Context:
This functionality is crucial for our embedded analytics implementation as it enables users to drill down into data directly from the embedded dashboard. Any insights or suggestions would be greatly appreciated.

Thank you in advance for your help!",EfraimGENC,2024-11-12 08:15:20+00:00,[],2024-11-14 08:55:06+00:00,2024-11-12 09:08:36+00:00,https://github.com/metabase/metabase/issues/49867,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2469972101, 'issue_id': 2651396707, 'author': 'Tony-metabase', 'body': ""Drill Through doesn't work with Static Embedding. If you want to embed charts with additional interactive features, like [drill-down](https://www.metabase.com/learn/metabase-basics/querying-and-dashboards/questions/drill-through) and [self-service querying](https://www.metabase.com/docs/latest/questions/query-builder/introduction), see [Interactive embedding](https://www.metabase.com/docs/latest/embedding/interactive-embedding)."", 'created_at': datetime.datetime(2024, 11, 12, 9, 8, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475761776, 'issue_id': 2651396707, 'author': 'hds1999', 'body': 'Can revert to version Metabase v0.50.31', 'created_at': datetime.datetime(2024, 11, 14, 8, 55, 5, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-11-12 09:08:36 UTC): Drill Through doesn't work with Static Embedding. If you want to embed charts with additional interactive features, like [drill-down](https://www.metabase.com/learn/metabase-basics/querying-and-dashboards/questions/drill-through) and [self-service querying](https://www.metabase.com/docs/latest/questions/query-builder/introduction), see [Interactive embedding](https://www.metabase.com/docs/latest/embedding/interactive-embedding).

hds1999 on (2024-11-14 08:55:05 UTC): Can revert to version Metabase v0.50.31

"
2651268655,issue,closed,completed,There are instance locale texts on static embeds when using `#locale` hash parameter,"### Describe the bug

During the testing of #8490 I found out that there are still texts that use instance locale, these texts are determined at load time. I used [`ttag/no-module-declaration`](https://github.com/ttag-org/eslint-plugin-ttag/blob/master/docs/rules/no-module-declaration.md) to pinpoint files that need to be fixed.

The problem was that there were 1381 errors when enabling that ESLint rule, so I only selectively focused on files related to visualizations and I drilled them down to just 3 places
1. Pie chart - Other
     ![Image](https://github.com/user-attachments/assets/f24c50f1-d626-4c6d-b83a-3ce09a56178c)

1. Trend chart - No data
     ![Image](https://github.com/user-attachments/assets/c9f4a4d2-6a6a-44cd-9677-4e3020a2686e)

1. Line chart - Tooltip aggregation name
     ![Image](https://github.com/user-attachments/assets/39a462da-8838-4f14-9b20-7e0e006798cd)


### To Reproduce

1. Set the instance locale to something not English, so we can see the problem clearer
2. Embed a pie chart with a lot of data points, so it shows an ""Other"" slice
3. Embed a trend chart, link it to a dashboard filter, and when embedding set the filter so that it shows no data
4. Embed a bar chart with a lot of breakout data points. e.g. summarize orders by created and user.state
5. Put all of the above charts in a dashboard and embed it. You'll need to link a filter to the trend chart for this. Make the filter ""editable"", then publish the embed.
6. View this dashboard in either a static embedding or public link.
7. Filter the embed so that the trend chart shows no data,
8. for bar chart, hover over the ""other"" bar (the last one). And see the tooltip label.

### Expected behavior

All the 3 places mentioned should have proper translated text according to `#locale=xxx`

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-11-07"",
      ""src_hash"": ""83d542c00dfed390ffebec623205a11417eac506"",
      ""tag"": ""v1.1.39-SNAPSHOT"",
      ""hash"": ""9585f56""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""15.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```

### Severity

could be really blocking, but this is such a rare case and it isn't as severe if the instance locale is set to English

### Additional context

_No response_",WiNloSt,2024-11-12 07:16:46+00:00,['WiNloSt'],2024-11-26 18:51:20+00:00,2024-11-14 12:56:13+00:00,https://github.com/metabase/metabase/issues/49864,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Public', 'Simple public iframe embeds'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', ''), ('Sharing/Public', '')]",[],
2650188465,issue,closed,completed,"Dashboard date filter ""Previous Month, Starting 1 Month Ago"" is off by one day","### Describe the bug

When started from a dashboard, the date filter ""Previous Month, Starting 1 Month Ago"" filters an incorrect range of records.

### To Reproduce

1. Create a GUI question:
- Sample Database, Orders
- Group by: Created at: Day
- Summarize: Count, Min of Created at: Day (don't bin), Max of Created at: Day (don't bin)

2. Add it to a dashboard, and wire a date filter to Created at: Day
3. Filter on: 'Previous month, starting 1 months ago'
* the filter widget shows a correct date range: Sep 1 - Sep 30
![Image](https://github.com/user-attachments/assets/dda4a5ca-9c09-49d7-a2fb-50f3fad5cdc2)
* the actual results are not correct: Sep 1 - Oct 1
![Image](https://github.com/user-attachments/assets/88c01034-dd4c-4c2e-8bc5-6a56f7773076)
4. Open the filtered card
![Image](https://github.com/user-attachments/assets/a21a5262-6e2d-4639-86dc-ed8ac7bfb19f)
* the results are still not correct
5. Click on the filter expression to open the filter widget
![Image](https://github.com/user-attachments/assets/cdc6dc06-6980-425a-973c-c9bcc1ee914d)
* it shows the correct range
6. Click on apply filter
![Image](https://github.com/user-attachments/assets/53727fad-7108-42cf-a895-dfd69f80a54e)
* the updated results are now correct



### Expected behavior

It should always return records between Sep 1 - Sep 30 .

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk"",
      ""mysql"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""internal"",
    ""version"": {
      ""date"": ""2024-11-01"",
      ""tag"": ""v1.51.1.8"",
      ""hash"": ""488b888""
    },
    ""settings"": {
      ""report-timezone"": ""America/Denver""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}
```

### Severity

P1 - incorrect results, affecting a customer

### Additional context

Reported in v1.50.30-x03, reproduced in v1.51.1.8 .",zbodi74,2024-11-11 19:22:43+00:00,['ranquild'],2024-11-26 17:46:26+00:00,2024-11-26 16:37:40+00:00,https://github.com/metabase/metabase/issues/49853,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Correctness', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2471187272, 'issue_id': 2650188465, 'author': 'appleby', 'body': 'Unclear on the cause, but the filter sent to the dataset endpoint differs between the working and non-working cases.\n\n**non-working when first navigating to card from dashboard**\n\n```json\n""filter"": [\n    ""between"",\n    [\n        ""+"",\n        [\n            ""field"",\n            ""CREATED_AT"",\n            {\n                ""base-type"": ""type/DateTime""\n            }\n        ],\n        [\n            ""interval"",\n            1,\n            ""month""\n        ]\n    ],\n    [\n        ""relative-datetime"",\n        -1,\n        ""month""\n    ],\n    [\n        ""relative-datetime"",\n        0,\n        ""month""\n    ]\n]\n```\n\n**working, after clicking ""update filter"" from the filter widget**\n\n```json\n""filter"": [\n    ""relative-time-interval"",\n    [\n        ""field"",\n        ""CREATED_AT"",\n        {\n            ""base-type"": ""type/DateTime""\n        }\n    ],\n    -1,\n    ""month"",\n    -1,\n    ""month""\n]\n```', 'created_at': datetime.datetime(2024, 11, 12, 17, 44, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472302117, 'issue_id': 2650188465, 'author': 'epbarger', 'body': ""I'm also seeing this issue"", 'created_at': datetime.datetime(2024, 11, 13, 3, 34, 15, tzinfo=datetime.timezone.utc)}]","appleby on (2024-11-12 17:44:16 UTC): Unclear on the cause, but the filter sent to the dataset endpoint differs between the working and non-working cases.

**non-working when first navigating to card from dashboard**

```json
""filter"": [
    ""between"",
    [
        ""+"",
        [
            ""field"",
            ""CREATED_AT"",
            {
                ""base-type"": ""type/DateTime""
            }
        ],
        [
            ""interval"",
            1,
            ""month""
        ]
    ],
    [
        ""relative-datetime"",
        -1,
        ""month""
    ],
    [
        ""relative-datetime"",
        0,
        ""month""
    ]
]
```

**working, after clicking ""update filter"" from the filter widget**

```json
""filter"": [
    ""relative-time-interval"",
    [
        ""field"",
        ""CREATED_AT"",
        {
            ""base-type"": ""type/DateTime""
        }
    ],
    -1,
    ""month"",
    -1,
    ""month""
]
```

epbarger on (2024-11-13 03:34:15 UTC): I'm also seeing this issue

"
2650150840,issue,open,,Maps: show values on data points,It would be nice to be able to show values ​​on data points for map chart.,fer-batista,2024-11-11 19:08:13+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/49852,"[('Type:New Feature', ''), ('Visualization/Maps', '')]",[],
2650029249,issue,open,,Problems with migration v50 in a huge database with mysql 8,"Hi, I'm working with Metabase v48, and during the migration to v50 with MySQL 8 database, we cannot complete the job if we are unable to create new indexes on the data_permissions structure. Without these indexes, the inserts never finish.

Currently, my database has more than 33k entries in the metabase_table.

All migrations with the table ""data_permissions"" stuck on this database, run for more than 12h and not finish.

I am running on AWS RDS, and the indexes I need to create are as follows:

CREATE INDEX idx_data_permissions_group ON data_permissions(group_id, db_id, table_id, perm_type);
CREATE INDEX idx_permissions_group_name ON permissions_group(name);
CREATE INDEX idx_metabase_table ON metabase_table(db_id, `schema`, id);
CREATE INDEX idx_data_permissions_main ON data_permissions(group_id, db_id, table_id, perm_type);
CREATE INDEX idx_data_permissions_subquery ON data_permissions(group_id, db_id, perm_type);
CREATE INDEX idx_data_permissions_full ON data_permissions(group_id, db_id, table_id, perm_type, perm_value);
",warren-leonardo-souza,2024-11-11 18:07:52+00:00,[],2024-11-14 09:06:22+00:00,,https://github.com/metabase/metabase/issues/49849,[],"[{'comment_id': 2468858135, 'issue_id': 2650029249, 'author': 'paoliniluis', 'body': ""@warren-leonardo-souza can you remove tables that you don't use? or you use them all?"", 'created_at': datetime.datetime(2024, 11, 11, 19, 11, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475785476, 'issue_id': 2650029249, 'author': 'flipace', 'body': 'We had the same issue with ""just"" 9.5k rows in `metabase_table` the permission inserts taking many minutes or even getting stuck. Adding the indexes suggested by @warren-leonardo-souza made the INSERT queries blast through with no problems', 'created_at': datetime.datetime(2024, 11, 14, 9, 6, 21, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-11 19:11:24 UTC): @warren-leonardo-souza can you remove tables that you don't use? or you use them all?

flipace on (2024-11-14 09:06:21 UTC): We had the same issue with ""just"" 9.5k rows in `metabase_table` the permission inserts taking many minutes or even getting stuck. Adding the indexes suggested by @warren-leonardo-souza made the INSERT queries blast through with no problems

"
2649907978,issue,closed,completed,Embed dashboard table cards filters not working,"### Describe the bug

In the new 0.51.2 version, the cross filters in the table cards are not doing anything when the dashboard is embedded.
However, they are working as usual on the Metabase UI dashboard page.

### To Reproduce

Go to an embedded dashboard and try to use the cross-filters in a table card.
The filters are not working but they are working in the metabase UI Dashboard.
https://github.com/user-attachments/assets/17af1bb7-c24a-4726-ac49-13ec8d8fe651

### Expected behavior

Filter the table using the table cards fields.
https://github.com/user-attachments/assets/0513e9f2-2c93-4156-84a4-ae7bfc1c025b


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v0.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-47-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Blocking the usage of Metabase filtering experience

### Additional context

_No response_",jatorna,2024-11-11 17:10:31+00:00,[],2024-12-19 09:25:18+00:00,2024-12-19 09:25:18+00:00,https://github.com/metabase/metabase/issues/49846,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2553175980, 'issue_id': 2649907978, 'author': 'jatorna', 'body': 'It is working again now', 'created_at': datetime.datetime(2024, 12, 19, 9, 25, 15, tzinfo=datetime.timezone.utc)}]","jatorna (Issue Creator) on (2024-12-19 09:25:15 UTC): It is working again now

"
2649861100,issue,closed,completed,Add a `force` param to update permission graph endpoints that always update permissions and doesn't require a `revision` number,An intermediate step before we solve https://github.com/metabase/metabase/issues/13884,paoliniluis,2024-11-11 16:47:13+00:00,['noahmoss'],2024-11-12 16:14:36+00:00,2024-11-12 15:26:00+00:00,https://github.com/metabase/metabase/issues/49845,"[('.Performance', ''), ('Misc/API', ''), ('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions')]","[{'comment_id': 2468788118, 'issue_id': 2649861100, 'author': 'luizarakaki', 'body': 'Discussion [here](https://metaboat.slack.com/archives/C05MPF0TM3L/p1731343498768859)\n\nI think adding a `force` property to the update graph endpoint that ignores the `revision` makes sense and avoid making another request just to get the number.', 'created_at': datetime.datetime(2024, 11, 11, 18, 25, 35, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-11-11 18:25:35 UTC): Discussion [here](https://metaboat.slack.com/archives/C05MPF0TM3L/p1731343498768859)

I think adding a `force` property to the update graph endpoint that ignores the `revision` makes sense and avoid making another request just to get the number.

"
2649446581,issue,open,,Let users know that model persistence has also to be enabled for the database connection,"**Is your feature request related to a problem? Please describe.**
In Admin Settings / Performance / Models, Admins can enable model persistence globally, but there is no indication that they will also need to enable it at the database connection as well for the setting to take effect. This can lead to confusion, as admins may assume the global setting alone is sufficient.

Additionally, users may expect the persistence to work on certain databases where this is not supported at all.

![Image](https://github.com/user-attachments/assets/2501420e-0dcf-46ba-989a-ad01c2847bf5)

The wording is confusing, as once enabled, they may expect it to work without any further configuration.
Additionally, they may expect it to work for databases where it is not supported.

**Describe the solution you'd like**
Change the wording of the page to make evident that additional condiguration is required at the database level.

Ideally, implement a dynamic status message or warning notification to notify admins when:
- There are databases that support model persistence, but they have not yet been configured to use it. This would remind admins to take further action.
- No databases support model persistence. In this case, display a message suggesting that admins might consider disabling the global setting entirely if it won’t be useful for any existing database connections.

**How important is this feature to you?**
Nice to have, it would provide a better experience for users who are setting model persistence up the first time.",zbodi74,2024-11-11 14:08:01+00:00,[],2025-02-04 20:31:04+00:00,,https://github.com/metabase/metabase/issues/49839,"[('Type:New Feature', ''), ('Administration/Databases', ''), ('Querying/Cache', '')]",[],
2649166532,issue,closed,completed,Metabase dataset query breaks when alias contains space,"### Describe the bug

Previously, this code worked:

```
        query = {
            ""type"": ""query"",
            ""query"": {
                ""source-table"": lab_users_table_id,
                ""joins"": [
                    {
                        ""fields"": [
                            [""field"", self.get_field_id(labs_table_id, ""Name""), {""join-alias"": ""Labs""}],
                            [
                                ""field"",
                                self.get_field_id(
                                    labs_table_id, ""Global Module Code"", ""global_module_code"", has_parent_id=False
                                ),
                                {""join-alias"": ""Labs""},
                            ],
                        ],
                        ""alias"": ""Labs"",
                        ""condition"": [
                            ""="",
                            [""field"", self.get_field_id(lab_users_table_id, ""Lab ID""), None],
                            [""field"", self.get_field_id(labs_table_id, ""ID"", ""_id""), {""join-alias"": ""Labs""}],
                        ],
                        ""source-table"": labs_table_id,
                    },
                    {
                        ""fields"": ""none"",
                        ""strategy"": ""left-join"",
                        ""alias"": ""Company Users"",
                        ""condition"": [
                            ""="",
                            [
                                ""field"",
                                self.get_field_id(lab_users_table_id, ""Company User ID""),
                                {""base-type"": ""type/MongoBSONID""},
                            ],
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""ID""),
                                {""base-type"": ""type/MongoBSONID"", ""join-alias"": ""Company Users""},
                            ],
                        ],
                        ""source-table"": company_users_table_id,
                    },
                    {
                        ""fields"": [
                            [
                                ""field"",
                                self.get_field_id(users_view_table_id, ""Email""),
                                {""base-type"": ""type/Text"", ""join-alias"": ""Users View - User""},
                            ],
                        ],
                        ""strategy"": ""left-join"",
                        ""alias"": ""Users View - User"",
                        ""condition"": [
                            ""="",
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""User ID""),
                                {""base-type"": ""type/MongoBSONID""},
                            ],
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""ID""),
                                {""base-type"": ""type/MongoBSONID"", ""join-alias"": ""Users View - User""},
                            ],
                        ],
                        ""source-table"": users_view_table_id,
                    },
                ],
                ""order-by"": [[""desc"", [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None]]],
                ""fields"": [
                    [""field"", self.get_field_id(lab_users_table_id, ""Feedback""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Rating""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Progress"", ""progress"", has_parent_id=False), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Company User ID""), None],
                ],
                ""filter"": [
                    ""and"",
                    [""not-empty"", [""field"", self.get_field_id(lab_users_table_id, ""Feedback""), None]],
                    [
                        ""time-interval"",
                        [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None],
                        -days,
                        ""day"",
                        {""include_current"": False},
                    ],
                ],
            },
            ""database"": self.get_database_id(database_name),
        }
        if module_name:
            query[""query""][""filter""].append(
                [""="", [""field"", self.get_field_id(labs_table_id, ""Name""), {""join-alias"": ""Labs""}], module_name]
            )
        url = f""https://{self.config.host}/api/dataset""
        headers = {""Content-Type"": ""application/json"", ""X-Metabase-Session"": self.get_session_token()}
        response = requests.post(url, json=query, headers=headers)
        response.raise_for_status()

```


However, after a recent upgrade, I started receiving 0 results and had to investigate. It turns out the Metabase endpoint responds with a 202 Accepted and gives 0 rows, but also gives an error:

```
""Command failed with error 9 (FailedToParse): 'let_join_alias_Company Users_user_id___3' contains an invalid character for a variable name: ' '""
```

The issue is that Metabase tries to directly convert an alias into a variable name with no sanitation.

As a workaround, I replaced the spaces and dashes with underscores and it started working again:

```
        query = {
            ""type"": ""query"",
            ""query"": {
                ""source-table"": lab_users_table_id,
                ""joins"": [
                    {
                        ""fields"": [
                            [""field"", self.get_field_id(labs_table_id, ""Name""), {""join-alias"": ""Labs""}],
                            [
                                ""field"",
                                self.get_field_id(
                                    labs_table_id, ""Global Module Code"", ""global_module_code"", has_parent_id=False
                                ),
                                {""join-alias"": ""Labs""},
                            ],
                        ],
                        ""alias"": ""Labs"",
                        ""condition"": [
                            ""="",
                            [""field"", self.get_field_id(lab_users_table_id, ""Lab ID""), None],
                            [""field"", self.get_field_id(labs_table_id, ""ID"", ""_id""), {""join-alias"": ""Labs""}],
                        ],
                        ""source-table"": labs_table_id,
                    },
                    {
                        ""fields"": ""none"",
                        ""strategy"": ""left-join"",
                        ""alias"": ""company_users"",
                        ""condition"": [
                            ""="",
                            [
                                ""field"",
                                self.get_field_id(lab_users_table_id, ""Company User ID""),
                                {""base-type"": ""type/MongoBSONID""},
                            ],
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""ID""),
                                {""base-type"": ""type/MongoBSONID"", ""join-alias"": ""company_users""},
                            ],
                        ],
                        ""source-table"": company_users_table_id,
                    },
                    {
                        ""fields"": [
                            [
                                ""field"",
                                self.get_field_id(users_view_table_id, ""Email""),
                                {""base-type"": ""type/Text"", ""join-alias"": ""users_view_user""},
                            ],
                        ],
                        ""strategy"": ""left-join"",
                        ""alias"": ""users_view_user"",
                        ""condition"": [
                            ""="",
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""User ID""),
                                {""base-type"": ""type/MongoBSONID""},
                            ],
                            [
                                ""field"",
                                self.get_field_id(company_users_table_id, ""ID""),
                                {""base-type"": ""type/MongoBSONID"", ""join-alias"": ""users_view_user""},
                            ],
                        ],
                        ""source-table"": users_view_table_id,
                    },
                ],
                ""order-by"": [[""desc"", [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None]]],
                ""fields"": [
                    [""field"", self.get_field_id(lab_users_table_id, ""Feedback""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Rating""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Progress"", ""progress"", has_parent_id=False), None],
                    [""field"", self.get_field_id(lab_users_table_id, ""Company User ID""), None],
                ],
                ""filter"": [
                    ""and"",
                    [""not-empty"", [""field"", self.get_field_id(lab_users_table_id, ""Feedback""), None]],
                    [
                        ""time-interval"",
                        [""field"", self.get_field_id(lab_users_table_id, ""Created At""), None],
                        -days,
                        ""day"",
                        {""include_current"": False},
                    ],
                ],
            },
            ""database"": self.get_database_id(database_name),
        }

```

### To Reproduce

Run a query with an alias that contains a space. You will get an error in the HTTP 202 response.

### Expected behavior

I expect it to not give an error because it used to work.

Also I expect it not to respond with HTTP 2xx because that makes it much more difficult to debug

### Logs

```
""{\\""database_id\\"":5,\\""started_at\\"":\\""2024-11-11T11:33:34.74166Z\\"",\\""via\\"":[{\\""status\\"":\\""failed\\"",\\""class\\"":\\""class clojure.lang.ExceptionInfo\\"",\\""error\\"":\\""Error executing query: Command failed with error 9 (FailedToParse): \'\'let_join_alias_Company Users_user_id___3\' contains an invalid character for a variable name: \' \'\' on server ...
""data\\"":{\\""rows\\"":[],\\""cols\\"":[]}}""'
```

### Information about your Metabase installation

```JSON
""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mongo"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-01"",
      ""tag"": ""v0.51.1.8"",
      ""hash"": ""488b888""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.6 (Debian 13.6-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

blocking script-based usage. Workaround exists.

### Additional context

_No response_",sassrf,2024-11-11 12:11:50+00:00,[],2025-02-07 16:21:48+00:00,2025-02-07 16:21:48+00:00,https://github.com/metabase/metabase/issues/49833,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Team/Drivers', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2468220347, 'issue_id': 2649166532, 'author': 'paoliniluis', 'body': '@sassrf hi there, why are you writing the MBQL yourself?', 'created_at': datetime.datetime(2024, 11, 11, 13, 46, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468237035, 'issue_id': 2649166532, 'author': 'sassrf', 'body': 'Hi. I needed to fetch some data from the metabase API and this seemed like the easiest way at the time I guess', 'created_at': datetime.datetime(2024, 11, 11, 13, 54, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470593199, 'issue_id': 2649166532, 'author': 'npfitz', 'body': 'Early diagnosis [here](https://metaboat.slack.com/archives/C05NXACAG1G/p1731337341978109?thread_ts=1731327121.352169&cid=C05NXACAG1G)', 'created_at': datetime.datetime(2024, 11, 12, 13, 54, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477875275, 'issue_id': 2649166532, 'author': 'qianthinking', 'body': 'Same issue in editor.\n\n![Image](https://github.com/user-attachments/assets/3f3bd419-e6b7-4e4a-b92e-20bc518199d7)', 'created_at': datetime.datetime(2024, 11, 15, 3, 21, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586073241, 'issue_id': 2649166532, 'author': 'Avery246813579', 'body': ""It's happening for me with MongoDB. The the join_alias is adding a space. Fixed with converting to a native query but kinda defeats the purpose."", 'created_at': datetime.datetime(2025, 1, 13, 2, 39, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616975260, 'issue_id': 2649166532, 'author': 'stygmate', 'body': 'any news on this one ?', 'created_at': datetime.datetime(2025, 1, 27, 21, 53, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2621543136, 'issue_id': 2649166532, 'author': 'MatthiasBiskop', 'body': 'Most likely there is a solution coming. Check out this one: https://github.com/metabase/metabase/issues/52807', 'created_at': datetime.datetime(2025, 1, 29, 12, 45, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2643391764, 'issue_id': 2649166532, 'author': 'luizarakaki', 'body': 'fixed by https://github.com/metabase/metabase/pull/52862', 'created_at': datetime.datetime(2025, 2, 7, 16, 21, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-11 13:46:44 UTC): @sassrf hi there, why are you writing the MBQL yourself?

sassrf (Issue Creator) on (2024-11-11 13:54:51 UTC): Hi. I needed to fetch some data from the metabase API and this seemed like the easiest way at the time I guess

npfitz on (2024-11-12 13:54:43 UTC): Early diagnosis [here](https://metaboat.slack.com/archives/C05NXACAG1G/p1731337341978109?thread_ts=1731327121.352169&cid=C05NXACAG1G)

qianthinking on (2024-11-15 03:21:42 UTC): Same issue in editor.

![Image](https://github.com/user-attachments/assets/3f3bd419-e6b7-4e4a-b92e-20bc518199d7)

Avery246813579 on (2025-01-13 02:39:21 UTC): It's happening for me with MongoDB. The the join_alias is adding a space. Fixed with converting to a native query but kinda defeats the purpose.

stygmate on (2025-01-27 21:53:03 UTC): any news on this one ?

MatthiasBiskop on (2025-01-29 12:45:34 UTC): Most likely there is a solution coming. Check out this one: https://github.com/metabase/metabase/issues/52807

luizarakaki on (2025-02-07 16:21:46 UTC): fixed by https://github.com/metabase/metabase/pull/52862

"
2649156015,issue,open,,Visualization Settings at Questions/Dashboard level don't get reset/removed if Question Source gets changed,"### Describe the bug

This is very similar to what is happening in [49667](https://github.com/metabase/metabase/issues/49667)

What happens is that if you created a Model -> Then a Question based on this model (edited some Visualization Settings) -> Created a Dashboard (edited some Visualization Settings) and then you decide to change the Model like pointing it to a new Table all the Visualization Settings would remain pointed to the old table.

At metabase level the frontend is able to ignore it but the problem would end up popping out in Serialization. If you are using Serialization the way it's supposed to be used you shouldn't hit this issue cause the target and source environment should match but if you are duplicating stuff from one instance to another you might not be migrating the whole Data Model and some of these references would be lost and break serialization during import

Also you have no way of resetting these Viz settings since any other viz setting you apply on the new question would still keep referenced to the old model

### To Reproduce

In my case I used the App DB to show what is going on:

Connected to the App DB -> Created a Model form `core_users` -> Created a Question form this model (edited Viz zettings) -> Added this Question to a dashboard (edited Viz zettings)

Now go to the Question and swap the model with another model `api_key` and save the Question. You will notice that the result metadata for the question got updated but the Viz settings still points to the column in core_users `last_login` which is the column I applied some Viz Settings on (the is not present in the api_key table):

![Image](https://github.com/user-attachments/assets/42ef6110-db1c-4d5b-b5e5-3eade1397cb7)


Same thing for the Dashboard:

![Image](https://github.com/user-attachments/assets/eda5f5ee-7a83-4e22-a02a-798a7fc037ac)




### Expected behavior

There shouldn't be any invalid Viz Settings applied to Model/Source that isn't even in the Question. So I guess we need to find a way to drop those when the model/source is changed. 

On the serialization front until the above gets fixed we can add logic to check the references, and drop the invalid ones before serializing.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Has been like this since forever I think ... I tested on 51
```

### Severity

Would be cosmetic at first but might be a problem for people using Serialization and are doing ""strange"" stuff ... Like losing that table/column reference

### Additional context

_No response_",Tony-metabase,2024-11-11 12:06:55+00:00,[],2024-11-12 13:57:01+00:00,,https://github.com/metabase/metabase/issues/49832,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2470583417, 'issue_id': 2649156015, 'author': 'npfitz', 'body': ""I think this is actually expected. Unless something has changed, Viz Settings are always validated before rendering a particular visualization (this usually involves looking at the data that is returned by the query). If they fail validation, then we generate and use some defaults, which may get overwritten as the user interacts with the card. I'll let someone from the DashViz team confirm though."", 'created_at': datetime.datetime(2024, 11, 12, 13, 50, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470598691, 'issue_id': 2649156015, 'author': 'Tony-metabase', 'body': ""I agree and that's what is happening cause the frontend is able to handle those bad references.\n\nBut these bad references end up breaking things like serialization. So if it's fine for the frontend it's not necessarily fine for the backend. We might need to rewrite the issue to be serialization specific in this case to handle these bad references. Note this is similar to the following:\n\nhttps://github.com/metabase/metabase/issues/49667\n\nBut the root cause of evil here are bad references that aren't cleaned up"", 'created_at': datetime.datetime(2024, 11, 12, 13, 57, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-11-12 13:50:45 UTC): I think this is actually expected. Unless something has changed, Viz Settings are always validated before rendering a particular visualization (this usually involves looking at the data that is returned by the query). If they fail validation, then we generate and use some defaults, which may get overwritten as the user interacts with the card. I'll let someone from the DashViz team confirm though.

Tony-metabase (Issue Creator) on (2024-11-12 13:57:00 UTC): I agree and that's what is happening cause the frontend is able to handle those bad references.

But these bad references end up breaking things like serialization. So if it's fine for the frontend it's not necessarily fine for the backend. We might need to rewrite the issue to be serialization specific in this case to handle these bad references. Note this is similar to the following:

https://github.com/metabase/metabase/issues/49667

But the root cause of evil here are bad references that aren't cleaned up

"
2649145053,issue,open,,[Spike] investigate ResizeObserver-related sdk issues on tooltip visibility and visualization sizes,"There are several issues related to the use of ResizeObserver in ExplicitSize in the sdk. We should investigate if there is a way to fix these issues. This is possibly tricky and difficult to tackle.

- We should not show tooltips for values in the SDK when hovering on Trend or Number charts.
- We should not show tooltip when hovering on the title of a dashboard card, unless the full title can’t be displayed due to its length.
- Visualization sizes when clicking through should fit the container by default. Currently trend charts looks [small and tiny](https://www.notion.so/metabase/Make-low-hanging-fruit-improvements-to-Shoppy-12a69354c9018011be49edf18852c7c0?pvs=4#12a69354c90180d1a062cfe72bcc379e) when clicked through.

Refer to the [product doc](https://www.notion.so/metabase/Make-low-hanging-fruit-improvements-to-Shoppy-12a69354c9018011be49edf18852c7c0?pvs=4#12a69354c90180b6b4cdcfbc7bc8dfcd) for more info.",heypoom,2024-11-11 12:01:43+00:00,[],2024-11-11 12:06:30+00:00,,https://github.com/metabase/metabase/issues/49831,[],[],
2649137305,issue,open,,Expose a prop to allow saving questions in the InteractiveDashboard sdk component,"We should add a prop to `InteractiveDashboard` that enables or disables saving a new question from the question view, after clicking on a dashboard card.

### How to reproduce

- Go to a dashboard
- Click on a dashboard card 
- Dashboard card should take you to a fullscreen question view. This is customizable via `renderDrillThroughQuestion`
- Modify the question (e.g. add a new filter)
- Click on **Save**.",heypoom,2024-11-11 11:58:10+00:00,[],2025-01-13 17:18:32+00:00,,https://github.com/metabase/metabase/issues/49830,[],[],
2648979750,issue,closed,duplicate,Dynamic Number Filter,"Hi!

I've noticed that the number filter could have dynamic functionality, which would look like this:

- a field to select the operator (<, >, between, !=, ...)
- a field to select (or type) the value

With these 2 fields, almost all number filter questions could be solved, as countless filters can be performed: greater, lesser, equal and different... with 2 fields the user has more filter possibilities.

If this has already been considered, you can delete this topic.

I'm on version 0.50.31 at the moment.",felipegranado,2024-11-11 10:54:32+00:00,[],2025-01-02 18:13:43+00:00,2025-01-02 18:13:43+00:00,https://github.com/metabase/metabase/issues/49829,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2568176282, 'issue_id': 2648979750, 'author': 'brunobergher', 'body': 'I believe this is the same as #30731, so closing as duplicate. Please let me know if otherwise.', 'created_at': datetime.datetime(2025, 1, 2, 18, 13, 30, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 18:13:30 UTC): I believe this is the same as #30731, so closing as duplicate. Please let me know if otherwise.

"
2648884127,issue,closed,completed,Text column is being ready by Metabase as a number (thus can't select values to filter on) ,"### Describe the bug

I was trying to filter by a text value in a table and column I have previously filtered on before. I can't seem to select a value. When I click on one, the 'Add filter' button becomes clickable, but the value I selected isn't highlighted, and a new one `NaN` shows up. 

The field is definitely of type text but Metabase seems to think it is a number. This is specific to this column; other text columns work just fine. ![Image](https://github.com/user-attachments/assets/f842da3c-048d-4f67-b5e7-ef5ea9fff4d2)
![Image](https://github.com/user-attachments/assets/069c76c3-7f2a-4c48-82d4-08f87eb1d6b9)
![Image](https://github.com/user-attachments/assets/31c1d471-9074-4cd6-a156-af10c721de44)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

I cannot reproduce this bug on another dataset or column, whether one of mine or the Metabase sample database. 

### Expected behavior

I should be able to select a value to filter on. It should show as selected after I click on it.

### Logs

[metabase_log_20241111.txt](https://github.com/user-attachments/files/17700870/metabase_log_20241111.txt)


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.226-214.880.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

Blocking partial usage

### Additional context

https://github.com/user-attachments/assets/95a51322-cb3e-40b4-be0a-9209a7200686
",zz-hh-aa,2024-11-11 10:28:42+00:00,[],2024-11-11 11:08:27+00:00,2024-11-11 11:08:27+00:00,https://github.com/metabase/metabase/issues/49828,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]",[],
2648593934,issue,open,,Ability to use modular components in InteractiveDashboard to render custom views,"We should allow customization of the question view [when clicking through to a question from dashboard cards](https://github.com/12a69354c9018011be49edf18852c7c0?d=13169354c90180009c08001ce5e61fec&pvs=25#12a69354c90180b7bdc6d3951ce4f505). Currently, it is not customizable because it uses the InteractiveAdHocQuestion component with a default InteractiveQuestionResult view under the hood.

We want to make the underlying view of the ad-hoc question be customizable, same as the modular components in InteractiveQuestion. We can provide a modular component API for InteractiveDashboard, similar to what we do in InteractiveQuestion. This would allow them to supply their own design for header and footer.

We can separate the dashboard / EmbedFrame into different components e.g. DashboardHeader, DashboardGrid.

Example:

```tsx
<InteractiveDashboard>
  <header>my header</header>
  <InteractiveDashboard.DashboardGrid />
  <div>my footer</div>
</InteractiveDashboard>
```

In addition, we should [provide a hook](https://github.com/13169354c901802582a8ca9389c544bd?pvs=25#13769354c9018052beffd1ed47eeaaf9) that allows the InteractiveDashboard's custom view to get the current dashboard title. We can create a separate part for this.

```tsx
const DashboardView = () => {
  const dashboard = useDashboard()

  return (
    <div>
      <h1>{dashboard.title}</h1>
      <InteractiveDashboard.DashboardCards />
    </div>
  )
}

<InteractiveDashboard>
  <DashboardView />
</InteractiveDashboard>
```",heypoom,2024-11-11 08:42:16+00:00,[],2025-02-04 20:25:57+00:00,,https://github.com/metabase/metabase/issues/49823,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2471604372, 'issue_id': 2648593934, 'author': 'heypoom', 'body': '@albertoperdomo should I deprioritize this from MS2 of https://github.com/metabase/metabase/issues/49713, or should I continue working on this? Not sure if this is out-of-scope of the work for GA', 'created_at': datetime.datetime(2024, 11, 12, 21, 18, 31, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-12 21:18:31 UTC): @albertoperdomo should I deprioritize this from MS2 of https://github.com/metabase/metabase/issues/49713, or should I continue working on this? Not sure if this is out-of-scope of the work for GA

"
2648097298,issue,open,,Also allow the use of column names as variables for custom URL destinaitons,"We cannot insert ""column names"" as URL variables for:

Go to a custom destination → URL values you can reference

Only variables we can use are ""value of columns"" or ""dashboard filters"".

This especially matters when we use pivot tables, because they don't allow us to set click behavior by columns, while simple tables allow them. We cannot set different destination to each column of pivots.

If we can use ""column names"" as URL variables, we can set correct custom destination URL on each pivot column.

https://discourse.metabase.com/t/cannot-get-column-names-when-set-url-variables-for-custom-destination/175389",ryutaro9434,2024-11-11 04:24:27+00:00,[],2025-02-07 00:56:42+00:00,,https://github.com/metabase/metabase/issues/49819,"[('Type:New Feature', ''), ('Reporting/Dashboards/Click Behavior', '')]","[{'comment_id': 2641552096, 'issue_id': 2648097298, 'author': 'albertocubeddu', 'body': 'Those are not working on static embedding and the click behaviour. \n\nGo to a custom Url -> https://whatever.com/{{id}}\nWorks on the dashboard inside metabase \nDO NOT WORK outside. \n\nThe only parameters that work is the result of the query (e.g. {{resutl}})', 'created_at': datetime.datetime(2025, 2, 7, 0, 56, 41, tzinfo=datetime.timezone.utc)}]","albertocubeddu on (2025-02-07 00:56:41 UTC): Those are not working on static embedding and the click behaviour. 

Go to a custom Url -> https://whatever.com/{{id}}
Works on the dashboard inside metabase 
DO NOT WORK outside. 

The only parameters that work is the result of the query (e.g. {{resutl}})

"
2646663925,issue,closed,completed,Can't filter on a custom column on a multi-stage question (even if it's on the last stage),"### Describe the bug

If a question has multiple stages, the filter won't be able to connect to the second stage. Similar to https://github.com/metabase/metabase/issues/19744, but not the same

### To Reproduce

1) create a question that has a custom column on the first stage (e.g. a custom column that gets the year)
2) then use that year as an aggregation on the first stage and then also in the second stage
e.g. something like 
![Image](https://github.com/user-attachments/assets/eb1517e9-be18-4b4b-8737-2446f87b6b21)

3) add the question to a dashboard, you won't be able to connect the filter to the year
![Image](https://github.com/user-attachments/assets/315aca97-66db-4870-b567-bf5b0cab339f)


### Expected behavior

Allow users to connect filters to custom columns

### Logs

NA

### Information about your Metabase installation

```JSON
it's been like this since... forever?
```

### Severity

P2ish

### Additional context

_No response_",paoliniluis,2024-11-09 23:32:41+00:00,[],2025-01-10 15:01:34+00:00,2025-01-10 15:01:32+00:00,https://github.com/metabase/metabase/issues/49816,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2582906803, 'issue_id': 2646663925, 'author': 'mngr', 'body': 'Fixed by https://github.com/metabase/metabase/pull/47167', 'created_at': datetime.datetime(2025, 1, 10, 15, 1, 32, tzinfo=datetime.timezone.utc)}]","mngr on (2025-01-10 15:01:32 UTC): Fixed by https://github.com/metabase/metabase/pull/47167

"
2646037712,issue,open,,Sync throws errors with JSONs that have keys with the same name,"### Describe the bug

Saw this on the logs of a 50.x tenant
```
2024-11-09 12:44:08.810	
{""lvl"":""INFO"",""lgr"":""metabase.driver.sql-jdbc.sync.describe-table"",""m"":""Inferring schema for 1 JSON fields in Table 5530 ''Messaging.webhook''""}
2024-11-09 12:44:08.760	
ds.clj:92)\n\tat metabase.sync.sync_metadata.fields$sync_fields_BANG_$fn__86683$fn__86684.invoke(fields.clj:92)\n\tat clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)\n\tat clojure.core$partition_by$fn__8601$fn__8602.invoke(core.clj:7260)\n\tat clojure.core$completing$fn__8528.invoke(core.clj:6932)\n\tat clojure.core$preserving_reduced$fn__8848.invoke(core.clj:7683)\n\tat clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:168)\n\tat clojure.core.protocols$fn__8249.invoke(protocols.clj:124)\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\n\tat clojure.core$…""}}
2024-11-09 12:44:08.760	
{""lvl"":""ERROR"",""lgr"":""metabase.sync.sync-metadata.fields"",""m"":"""",""exception"":{""exception_class"":""clojure.lang.ExceptionInfo"",""exception_message"":""ERROR: duplicate key value violates unique constraint \""idx_unique_field\""\n  Detail: Key (name, table_id, unique_field_helper)=(requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1, 5481, 0) already exists."",""stacktrace"":""clojure.lang.ExceptionInfo: ERROR: duplicate key value violates unique constraint \""idx_unique_field\""\n  Detail: Key (name, table_id, unique_field_helper)=(requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1, 5481, 0) already exists. {:toucan2/context-trace [[\""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection\"" {:toucan2.jdbc.query/sql-args [\""UPDATE \\\""metabase_field\\\"" SET \\\""name\\\"" = ?, \\\""updated_at\\\"" = NOW() WHERE \\\""id\\\"" = ?\"" \""requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1\"" 253712]}] [\""resolve connection\"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [\""resolve connection\"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$completing$fn__8528 0x2304f618 \""clojure.core$completing$fn__8528@2304f618\""]} [\""with compiled query\"" {:toucan2.pipeline/compiled-query [\""UPDATE \\\""metabase_field\\\"" SET \\\""name\\\"" = ?, \\\""updated_at\\\"" = NOW() WHERE \\\""id\\\"" = ?\"" \""requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1\"" 253712]}] [\""with built query\"" {:toucan2.pipeline/built-query {:update [:metabase_field], :set {:name \""requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1\"", :updated_at [:metabase.util.honey-sql-2/typed :%now {:database-type \""timestamptz\""}]}, :where [:= :id 253712]}}] [\""resolve connection\"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [\""resolve connection\"" {:toucan2.connection/connectable nil}] [\""with resolved query\"" {:toucan2.pipeline/resolved-query {}}] [\""with parsed args\"" {:toucan2.pipeline/query-type :toucan.query-type/update.update-count, :toucan2.pipeline/parsed-args {:changes {:name \""requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1\""}, :queryable {}, :kv-args {:toucan/pk 253712}}}] [\""with model\"" {:toucan2.pipeline/model :model/Field}] [\""with unparsed args\"" {:toucan2.pipeline/query-type :toucan.query-type/update.update-count, :toucan2.pipeline/unparsed-args (:model/Field 253712 {:name \""requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1\""})}]]}\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)\n\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)\n\tat org.postgresql.jdbc.PgPreparedStatement.execute(PgPreparedStatement.java:180)\n\tat com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)\n\tat toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:40)\n\tat toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22)\n\tat toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19)\n\tat toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:15)\n\tat methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497.invoke(threaded.clj:64)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:216)\n\tat toucan2.pipeline$transduce_execute$with_connection_STAR___21600$with_transaction_STAR___21601.invoke(pipeline.clj:75)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:180)\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:162)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:13)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:13)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:212)\n\tat toucan2.pipeline$transduce_execute$with_connection_STAR___21600.invoke(pipeline.clj:74)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)\n\tat toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)\n\tat toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)\n\tat toucan2.pipeline$transduce_execute.invokeStatic(pipeline.clj:74)\n\tat toucan2.pipeline$transduce_execute.invoke(pipeline.clj:64)\n\tat clojure.lang.Var.invoke(Var.java:399)\n\tat toucan2.pipeline$transduce_compiled_query.invokeStatic(pipeline.clj:244)\n\tat toucan2.pipeline$transduce_compiled_query.invoke(pipeline.clj:240)\n\tat toucan2.pipeline$transduce_built_query.invokeStatic(pipeline.clj:252)\n\tat toucan2.pipeline$transduce_built_query.invoke(pipeline.clj:246)\n\tat toucan2.pipeline$transduce_query_primary_method_default.invokeStatic(pipeline.clj:272)\n\tat toucan2.pipeline$transduce_query_primary_method_default.invoke(pipeline.clj:269)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:15)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.tools.before_update$transduce_query_primary_method_toucan_query_type_update__STAR__toucan2_tools_before_update_before_update_default$with_connection_STAR___25845$with_transaction_STAR___25846$fn__25847.invoke(before_update.clj:115)\n\tat clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)\n\tat clojure.lang.PersistentVector.reduce(PersistentVector.java:343)\n\tat clojure.core$transduce.invokeStatic(core.clj:6947)\n\tat clojure.core$transduce.invokeStatic(core.clj:6943)\n\tat clojure.core$transduce.invoke(core.clj:6934)\n\tat toucan2.tools.before_update$transduce_query_primary_method_toucan_query_type_update__STAR__toucan2_tools_before_update_before_update_default$with_connection_STAR___25845$with_transaction_STAR___25846.invoke(before_update.clj:113)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat metabase.db.connection$do_transaction$thunk__42433.invoke(connection.clj:140)\n\tat metabase.db.connection$do_transaction.invokeStatic(connection.clj:152)\n\tat metabase.db.connection$do_transaction.invoke(connection.clj:136)\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:189)\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:162)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:13)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:13)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:212)\n\tat toucan2.tools.before_update$transduce_query_primary_method_toucan_query_type_update__STAR__toucan2_tools_before_update_before_update_default$with_connection_STAR___25845.invoke(before_update.clj:112)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat toucan2.connection$bind_current_connectable_fn$fn__21281.invoke(connection.clj:104)\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)\n\tat toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)\n\tat toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:12)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210)\n\tat toucan2.tools.before_update$transduce_query_primary_method_toucan_query_type_update__STAR__toucan2_tools_before_update_before_update_default.invokeStatic(before_update.clj:112)\n\tat toucan2.tools.before_update$transduce_query_primary_method_toucan_query_type_update__STAR__toucan2_tools_before_update_before_update_default.invoke(before_update.clj:94)\n\tat methodical.impl.combo.common$partial_STAR_$fn__18186.invoke(common.clj:15)\n\tat methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497.invoke(threaded.clj:64)\n\tat methodical.util.FnWithMeta.invoke(util.clj:46)\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:216)\n\tat toucan2.pipeline$transduce_query_STAR_.invokeStatic(pipeline.clj:278)\n\tat toucan2.pipeline$transduce_query_STAR_.invoke(pipeline.clj:274)\n\tat toucan2.pipeline$transduce_with_model.invokeStatic(pipeline.clj:293)\n\tat toucan2.pipeline$transduce_with_model.invoke(pipeline.clj:280)\n\tat toucan2.pipeline$transduce_parsed.invokeStatic(pipeline.clj:309)\n\tat toucan2.pipeline$transduce_parsed.invoke(pipeline.clj:295)\n\tat toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:317)\n\tat toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311)\n\tat toucan2.pipeline$transduce_unparsed_with_default_rf.invokeStatic(pipeline.clj:374)\n\tat toucan2.pipeline$transduce_unparsed_with_default_rf.invoke(pipeline.clj:368)\n\tat toucan2.update$update_BANG_.invokeStatic(update.clj:53)\n\tat toucan2.update$update_BANG_.doInvoke(update.clj:50)\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\n\tat metabase.sync.sync_metadata.fields.sync_metadata$update_field_metadata_if_needed_BANG_.invokeStatic(sync_metadata.clj:143)\n\tat metabase.sync.sync_metadata.fields.sync_metadata$update_field_metadata_if_needed_BANG_.invoke(sync_metadata.clj:17)\n\tat metabase.sync.sync_metadata.fields.sync_metadata$update_metadata_BANG_$iter__86589__86593$fn__86594.invoke(sync_metadata.clj:170)\n\tat clojure.lang.LazySeq.sval(LazySeq.java:42)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:51)\n\tat clojure.lang.RT.seq(RT.java:535)\n\tat clojure.core$seq__5467.invokeStatic(core.clj:139)\n\tat clojure.core$filter$fn__5962.invoke(core.clj:2826)\n\tat clojure.lang.LazySeq.sval(LazySeq.java:42)\n\tat clojure.lang.LazySeq.seq(LazySeq.java:51)\n\tat clojure.lang.Cons.next(Cons.java:39)\n\tat clojure.lang.RT.next(RT.java:713)\n\tat clojure.core$next__5451.invokeStatic(core.clj:64)\n\tat clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:169)\n\tat clojure.core.protocols$fn__8249.invoke(protocols.clj:124)\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:27)\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\n\tat clojure.core$reduce.invokeStatic(core.clj:6883)\n\tat clojure.core$reduce.invoke(core.clj:6869)\n\tat metabase.sync.util$sum_for_STAR_.invokeStatic(util.clj:586)\n\tat metabase.sync.util$sum_for_STAR_.invoke(util.clj:583)\n\tat metabase.sync.sync_metadata.fields.sync_metadata$update_metadata_BANG_.invokeStatic(sync_metadata.clj:166)\n\tat metabase.sync.sync_metadata.fields.sync_metadata$update_metadata_BANG_.invoke(sync_metadata.clj:160)\n\tat metabase.sync.sync_metadata.fields$sync_and_update_BANG_.invokeStatic(fields.clj:69)\n\tat metabase.sync.sync_metadata.fields$sync_and_update_BANG_.invoke(fields.clj:60)\n\tat metabase.sync.sync_metadata.fields$sync_fields_BANG_$fn__86683$fn__86684$fn__86686.invoke(fiel
2024-11-09 12:44:08.751	
{""lvl"":""INFO"",""lgr"":""metabase.sync.sync-metadata.fields.sync-metadata"",""m"":""Name of Table 5481 ''logs.api'' Field 'requestBody → envelop → messageBody → orderHeader → shipTo → shipToAdd1' has changed from 'requestBody → envelop → messageBody → orderHeader → shipTo → shipToAdd1' to 'requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1'.""}
2024-11-09 12:44:08.751	
{""lvl"":""WARN"",""lgr"":""metabase.sync.sync-metadata.fields.common"",""m"":""Found multiple matching field metadata for: requestBody → envelop → messageBody → orderHeader → shipTo → shipToAdd1 (requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1 requestBody → Envelop → messageBody → orderHeader → shipTo → shipToAdd1)""}
2024-11-09 12:44:08.738	
{""lvl"":""WARN"",""lgr"":""metabase.sync.sync-metadata.fields.common"",""m"":""Found multiple matching field metadata for: requestBody → envelop → messageBody → orderHeader → shipTo → shipToAdd1 (requestBody → Envelop → MessageBody → OrderHeader → ShipTo → ShipToAdd1 requestBody → Envelop → messageBody → orderHeader → shipTo → shipToAdd1)""}
```

### To Reproduce

Don't know how to reproduce, yet

### Expected behavior

We should not have these errors

### Logs

Above

### Information about your Metabase installation

```JSON
v50.x
```

### Severity

P2?

### Additional context

_No response_",paoliniluis,2024-11-09 13:27:21+00:00,[],2025-02-04 20:24:36+00:00,,https://github.com/metabase/metabase/issues/49814,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2645344958,issue,closed,completed,Sorting by Unbinned Date After Summarize Fails (if date is custom column),"### Describe the bug

You cannot sort by a custom expression date column after the aggregate stage if it's unbinned.

### To Reproduce

1. Create a question with the Reviews table from the Sample DB
2. Use a custom expression to assign a new column name to ""created at"" - like ""date_expr""
3. Do a count of records grouped by ""date_expr"" (unbinned)
4. After the aggregate stage, apply a sort to the unbinned date
5. See error - looks like we generate invalid group clause

### Expected behavior

Sort should work

### Logs

_No response_

### Information about your Metabase installation

```JSON
Reproduced on 50.32 and Stats
```

### Severity

annoying

### Additional context

I was able to repro on H2 and Postgres",ixipixi,2024-11-08 23:14:21+00:00,['ericnormand'],2025-01-17 00:13:55+00:00,2025-01-16 23:38:30+00:00,https://github.com/metabase/metabase/issues/49809,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2470531725, 'issue_id': 2645344958, 'author': 'npfitz', 'body': 'Repro in our [stats instance](https://metaboat.slack.com/archives/C05NXACAG1G/p1731107695940489?thread_ts=1731107672.814149&cid=C05NXACAG1G)', 'created_at': datetime.datetime(2024, 11, 12, 13, 28, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507904478, 'issue_id': 2645344958, 'author': 'bshepherdson', 'body': 'We\'re actually generating two ORDER BY clauses - one correct, and one broken.\n\n```sql\nSELECT CAST(""source"".""date_expr"" AS date) AS ""date_expr"", COUNT(*) AS ""count"" FROM (SELECT ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""CREATED_AT"", ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""date_expr"" FROM ""PUBLIC"".""REVIEWS"") AS ""source""\nGROUP BY CAST(""source"".""date_expr"" AS date)\nORDER BY ""source"".""date_expr"" ASC, CAST(""source"".""date_expr"" AS date) ASC\n```\nthe first one is the unbucketed one and is the problem; the second is what we should be generating.\n\nThe logic in `add-implicit-clauses` is supposed to find an existing sort order for the same column rather than adding a new one.\n\nThis will be fixed by the field refs overhaul eventually, but should be practical to fix more directly in the meantime.', 'created_at': datetime.datetime(2024, 11, 29, 14, 15, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593808062, 'issue_id': 2645344958, 'author': 'ericnormand', 'body': '`add-implicit-clauses` is receiving this query:\n\n```\n    {:database 1,\n     :middleware {:js-int-to-string? true,\n                  :userland-query? true,\n                  :add-default-userland-constraints? true},\n     :info {:executed-by 1, :context :ad-hoc},\n     :constraints {:max-results 10000, :max-results-bare-rows 2000},\n     :type :query,\n     :query {:source-table 4,\n             :expressions {date_expr [:field 55 {:base-type :type/DateTime}]},\n             :breakout [[:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]], \n             :order-by [[:asc [:expression date_expr {:base-type :type/DateTime}]]],\n             :limit 10,\n             :breakout-idents {0 psAFGbhrlVAjCy9K8zAkx},\n             :expression-idents {date_expr kSd5OZgcC0De7C7yznGIx}}}\n```\n\nNotice that it has the order by (un-cast to `date`)\n\nAnd it generates this:\n\n```\n    {:database 1,\n     :middleware {:js-int-to-string? true,\n                  :userland-query? true,\n                  :add-default-userland-constraints? true},\n     :info {:executed-by 1, :context :ad-hoc},\n     :constraints {:max-results 10000, :max-results-bare-rows 2000},\n     :type :query,\n     :query {:source-table 4,\n             :expressions {date_expr [:field 55 {:base-type :type/DateTime}]},\n             :breakout [[:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]],\n             :order-by [[:asc [:expression date_expr {:base-type :type/DateTime}]]\n                        [:asc [:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]]],\n             :limit 10,\n             :breakout-idents {0 psAFGbhrlVAjCy9K8zAkx},\n             :expression-idents {date_expr kSd5OZgcC0De7C7yznGIx}}}\n\n```\n\nIt added the order-by field with the cast.', 'created_at': datetime.datetime(2025, 1, 15, 19, 52, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593830762, 'issue_id': 2645344958, 'author': 'ericnormand', 'body': 'I have confirmed that unbinned `GROUP BY` with unbinned `SORT BY` of the date_expr field works in SQL:\n\n```\nSELECT\n  CAST(""source"".""date_expr"" AS date) AS ""date_expr""\nFROM\n  (\n    SELECT\n      ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""CREATED_AT"",\n      ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""date_expr""\n    FROM\n      ""PUBLIC"".""REVIEWS""\n  ) AS ""source""\nGROUP BY\n  ""source"".""date_expr""\nORDER BY\n  ""source"".""date_expr"" ASC\nLIMIT\n  1048575\n```', 'created_at': datetime.datetime(2025, 1, 15, 20, 5, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593857924, 'issue_id': 2645344958, 'author': 'ericnormand', 'body': '`auto-bucket-datetimes` is binning the unbinned `date_expr` in the `GROUP BY` clause but not in the `ORDER BY` clause. \n\n⚠  It seems weird to bin it when the user explicitly selected ""unbinned"".\n\nHowever, it also seems like if we are going to bin it in the `GROUP BY`, we should bin it also in the `ORDER BY`. That\'s the way SQL works.', 'created_at': datetime.datetime(2025, 1, 15, 20, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593903922, 'issue_id': 2645344958, 'author': 'ericnormand', 'body': 'Simpler reproduction:\n\n1. Create a question with the Reviews table from the Sample DB\n2. Add Summarize (count rows) by ""Created At"" field unbinned (click More.... and look for ""Unbinned"").\n3. Add Sort by ""Created At""\n\nWill generate this SQL:\n\n```\nSELECT\n  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date) AS ""CREATED_AT"",\n  COUNT(*) AS ""count""\nFROM\n  ""PUBLIC"".""REVIEWS""\nGROUP BY\n  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date)\nORDER BY\n  ""PUBLIC"".""REVIEWS"".""CREATED_AT"" ASC,\n  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date) ASC\n```\n\nThe problem is that the ORDER BY clause contains both:\n1. an unbinned (uncast) version of the field\n2. a binned version of the field\nBut SQL does not allow expressions in the ORDER BY that do not appear in the GROUP BY (unless you run some aggregate).', 'created_at': datetime.datetime(2025, 1, 15, 20, 47, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593914862, 'issue_id': 2645344958, 'author': 'ericnormand', 'body': 'The behavior of our system is:\n\nThe MBQL query contains the unbinned field in the ORDER BY.\n\nThere is a middleware step (`auto-bucket-datetimes`) that automatically bins date time ""breakout"" fields (GROUP BYs).\n\nThere is a later middleware step (`add-implicit-clauses`) that adds the (now binned) breakout fields to the ORDER BY clauses. \n\nThis makes both the binned and unbinned versions show up.\n\nThe correct output would need the GROUP BY and ORDER BY expressions to match. The question is: Do we stop automatically binning date time fields in the breakout, or do we automatically bin data time fields in the order-by?', 'created_at': datetime.datetime(2025, 1, 15, 20, 54, 21, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-11-12 13:28:30 UTC): Repro in our [stats instance](https://metaboat.slack.com/archives/C05NXACAG1G/p1731107695940489?thread_ts=1731107672.814149&cid=C05NXACAG1G)

bshepherdson on (2024-11-29 14:15:14 UTC): We're actually generating two ORDER BY clauses - one correct, and one broken.

```sql
SELECT CAST(""source"".""date_expr"" AS date) AS ""date_expr"", COUNT(*) AS ""count"" FROM (SELECT ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""CREATED_AT"", ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""date_expr"" FROM ""PUBLIC"".""REVIEWS"") AS ""source""
GROUP BY CAST(""source"".""date_expr"" AS date)
ORDER BY ""source"".""date_expr"" ASC, CAST(""source"".""date_expr"" AS date) ASC
```
the first one is the unbucketed one and is the problem; the second is what we should be generating.

The logic in `add-implicit-clauses` is supposed to find an existing sort order for the same column rather than adding a new one.

This will be fixed by the field refs overhaul eventually, but should be practical to fix more directly in the meantime.

ericnormand (Assginee) on (2025-01-15 19:52:10 UTC): `add-implicit-clauses` is receiving this query:

```
    {:database 1,
     :middleware {:js-int-to-string? true,
                  :userland-query? true,
                  :add-default-userland-constraints? true},
     :info {:executed-by 1, :context :ad-hoc},
     :constraints {:max-results 10000, :max-results-bare-rows 2000},
     :type :query,
     :query {:source-table 4,
             :expressions {date_expr [:field 55 {:base-type :type/DateTime}]},
             :breakout [[:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]], 
             :order-by [[:asc [:expression date_expr {:base-type :type/DateTime}]]],
             :limit 10,
             :breakout-idents {0 psAFGbhrlVAjCy9K8zAkx},
             :expression-idents {date_expr kSd5OZgcC0De7C7yznGIx}}}
```

Notice that it has the order by (un-cast to `date`)

And it generates this:

```
    {:database 1,
     :middleware {:js-int-to-string? true,
                  :userland-query? true,
                  :add-default-userland-constraints? true},
     :info {:executed-by 1, :context :ad-hoc},
     :constraints {:max-results 10000, :max-results-bare-rows 2000},
     :type :query,
     :query {:source-table 4,
             :expressions {date_expr [:field 55 {:base-type :type/DateTime}]},
             :breakout [[:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]],
             :order-by [[:asc [:expression date_expr {:base-type :type/DateTime}]]
                        [:asc [:expression date_expr {:base-type :type/DateTime, :temporal-unit :day}]]],
             :limit 10,
             :breakout-idents {0 psAFGbhrlVAjCy9K8zAkx},
             :expression-idents {date_expr kSd5OZgcC0De7C7yznGIx}}}

```

It added the order-by field with the cast.

ericnormand (Assginee) on (2025-01-15 20:05:25 UTC): I have confirmed that unbinned `GROUP BY` with unbinned `SORT BY` of the date_expr field works in SQL:

```
SELECT
  CAST(""source"".""date_expr"" AS date) AS ""date_expr""
FROM
  (
    SELECT
      ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""CREATED_AT"",
      ""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS ""date_expr""
    FROM
      ""PUBLIC"".""REVIEWS""
  ) AS ""source""
GROUP BY
  ""source"".""date_expr""
ORDER BY
  ""source"".""date_expr"" ASC
LIMIT
  1048575
```

ericnormand (Assginee) on (2025-01-15 20:22:00 UTC): `auto-bucket-datetimes` is binning the unbinned `date_expr` in the `GROUP BY` clause but not in the `ORDER BY` clause. 

⚠  It seems weird to bin it when the user explicitly selected ""unbinned"".

However, it also seems like if we are going to bin it in the `GROUP BY`, we should bin it also in the `ORDER BY`. That's the way SQL works.

ericnormand (Assginee) on (2025-01-15 20:47:53 UTC): Simpler reproduction:

1. Create a question with the Reviews table from the Sample DB
2. Add Summarize (count rows) by ""Created At"" field unbinned (click More.... and look for ""Unbinned"").
3. Add Sort by ""Created At""

Will generate this SQL:

```
SELECT
  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date) AS ""CREATED_AT"",
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""REVIEWS""
GROUP BY
  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date)
ORDER BY
  ""PUBLIC"".""REVIEWS"".""CREATED_AT"" ASC,
  CAST(""PUBLIC"".""REVIEWS"".""CREATED_AT"" AS date) ASC
```

The problem is that the ORDER BY clause contains both:
1. an unbinned (uncast) version of the field
2. a binned version of the field
But SQL does not allow expressions in the ORDER BY that do not appear in the GROUP BY (unless you run some aggregate).

ericnormand (Assginee) on (2025-01-15 20:54:21 UTC): The behavior of our system is:

The MBQL query contains the unbinned field in the ORDER BY.

There is a middleware step (`auto-bucket-datetimes`) that automatically bins date time ""breakout"" fields (GROUP BYs).

There is a later middleware step (`add-implicit-clauses`) that adds the (now binned) breakout fields to the ORDER BY clauses. 

This makes both the binned and unbinned versions show up.

The correct output would need the GROUP BY and ORDER BY expressions to match. The question is: Do we stop automatically binning date time fields in the breakout, or do we automatically bin data time fields in the order-by?

"
2645134064,issue,open,,"Add aggregation function type to query result column metadata and use it when grouping series into ""Other""","**Context**

When grouping series into ""Other"" on bar charts, we make users to select the aggregation function:
![Image](https://github.com/user-attachments/assets/117dd142-e55f-4bad-ae7a-eb96800d6c7e)

This is good on native queries since we do not know the aggregation function, however, for structured questions we know what it is and can provide the function name as a part of column metadata. Expected aggregation types:
```
""count""
""sum""
""cum-sum""
""cum-count""
""distinct""
""min""
""max""
""avg""
""median""
""stddev""
```

## Tasks
- [ ] BE: Provide the aggregation function name in the column metadata of aggregates for structured questions
- [ ] FE: Use the provided value




",alxnddr,2024-11-08 20:50:33+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/49801,"[('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2644750030,issue,closed,not_planned,Users with collection access to `Usage analytics` should have download access to the internal db,"### Describe the bug

Users with collection access to `Usage analytics` are granted `View data` on the internal db.
We should also grant `Download` 1M rows to them.

### To Reproduce

1. As a non-admin user with access to Usage analytics, open a Usage analytics question and try to download results
2. Download not available



### Expected behavior

Users with collection access to `Usage analytics` should be able to download question results

### Logs

_No response_

### Information about your Metabase installation

```JSON
- v1.51
```

### Severity

P2

### Additional context

_No response_",luizarakaki,2024-11-08 17:52:53+00:00,['noahmoss'],2024-11-08 19:31:45+00:00,2024-11-08 19:31:45+00:00,https://github.com/metabase/metabase/issues/49793,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2644741502,issue,closed,completed,Update in-product links to Learn,"There are a couple of links to Learn in product.
We updated all URLs in Learn recently, and there are redirects in place to ensure that links to Learn from product are still valid, but redirects mess up source attribution for our page views - a redirected view will be attributed to have come from the old URL rather than from the product - which complicates Learn analytics.
Updating the links to the current state to avoid redirects will ensure that the source will be attributed correctly. 

I found following changes:

|Old|New|
|-|-|
|`getLearnUrl(""getting-started/models"")`|`getLearnUrl(""metabase-basics/getting-started/models"")`|
|`getLearnUrl(""data-modeling/models"")` | `getLearnUrl(""metabase-basics/getting-started/models"")` |
|`getLearnUrl(""data-modeling/models#skip-the-sql-variables"")` | `getLearnUrl(""metabase-basics/getting-started/models#skip-the-sql-variables"")`|
|`getLearnUrl(""debugging-sql/sql-syntax"")`| `getLearnUrl(""grow-your-data-skills/learn-sql/debugging-sql/sql-syntax"")`|",alexyarosh,2024-11-08 17:48:10+00:00,['NevRA'],2025-01-27 22:12:39+00:00,2025-01-03 11:51:55+00:00,https://github.com/metabase/metabase/issues/49791,"[('Type:Documentation', ''), ('Type:New Feature', ''), ('Querying/', ''), ('.Team/Querying', '')]",[],
2644671093,issue,closed,completed,Add viz settings to InteractiveQuestion component,"**Context**


- issue links: _related issues if any_

",albertoperdomo,2024-11-08 17:25:29+00:00,['oisincoveney'],2024-11-08 17:29:13+00:00,2024-11-08 17:29:11+00:00,https://github.com/metabase/metabase/issues/49790,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2465378648, 'issue_id': 2644671093, 'author': 'albertoperdomo', 'body': 'Closed via https://github.com/metabase/metabase/pull/49167', 'created_at': datetime.datetime(2024, 11, 8, 17, 29, 11, tzinfo=datetime.timezone.utc)}]","albertoperdomo (Issue Creator) on (2024-11-08 17:29:11 UTC): Closed via https://github.com/metabase/metabase/pull/49167

"
2644600376,issue,closed,completed,[Epic] Better Onboarding Follow-Ups,"## Links
- [product doc](https://www.notion.so/metabase/Better-Onboarding-pt-3-iterations-13469354c90180bebbdfe315a42552de)
- [Figma](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?t=I1qrCjvYrz7lIJlz-0)

```[tasklist]
- [x] Better placement for the checklist when the sidebar is closed (#50368)
- [x] Tweak/replace the video content (#50367)
- [x] Fix the help section ([product spec](https://www.notion.so/metabase/Better-Onboarding-pt-3-iterations-13469354c90180bebbdfe315a42552de?pvs=4#13469354c90181b68873fc5a57dd142c)) #50579
- [x] Replace the ""data stack"" image ([product spec](https://www.notion.so/metabase/Better-Onboarding-pt-3-iterations-13469354c90180bebbdfe315a42552de?pvs=4#14269354c90180d9ba2dc496bb125fba)) #50579
```",nemanjaglumac,2024-11-08 16:55:53+00:00,['nemanjaglumac'],2024-12-12 10:59:30+00:00,2024-12-12 10:59:30+00:00,https://github.com/metabase/metabase/issues/49788,[],[],
2644533909,issue,closed,completed,"Column filters broken in 1.51.1 and 1.51.2.3 only show ""Is empty"" and ""Not empty"" for bigquery datasets","### Describe the bug

Upgraded from 1.50 to 1.51 and now all column filters for our bigquery backend datasets.![Image](https://github.com/user-attachments/assets/71adca62-ddf4-421c-a0a6-f47b4651ee6d)

This is affecting all users.
I have gone through and resynced and re-fingerprint tables, I have gone into Admin -> Table Metadata and try to see if I can force some update of the filters, but nothing so far works.

I dont understand how a bug this bad could be released, are there workarounds?

### To Reproduce

1. Go to a table which is a bigquery dataset backend
2. Click on a column to filter like ""Type"" which should have several filter value options
3. Only ""Is empty"" or ""Not empty"" is available for all columns



### Expected behavior

Column filters should show values obviously

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-07"",
      ""tag"": ""v1.51.2.3"",
      ""hash"": ""33c6105""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.20""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

P1 triage, blocking any meaningful use of the site

### Additional context

_No response_",rojomisin,2024-11-08 16:38:39+00:00,['snoe'],2024-11-11 22:25:32+00:00,2024-11-11 18:42:29+00:00,https://github.com/metabase/metabase/issues/49786,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('Database/BigQuery', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Drivers', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2465265682, 'issue_id': 2644533909, 'author': 'luizarakaki', 'body': 'Can you provide more information about the column?\nWhat is its data type in BigQuery? Does it happen on other columns?\n\nUnable to reproduce so far', 'created_at': datetime.datetime(2024, 11, 8, 16, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465311200, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': 'surprising you cannot reproduce, we have 300 tables in this bigquery\ndatabase, and none of the columns filter, they all say ""empt/not empty"" now\n\nI will try to show the simplest example, but all the fields are broken.\nI\'ll use our `users` -> `lastname` as a simple example\n\nit has 233 individual values to filter on, and it only shows empty/not\nempty, it\'s just a simple string field type as far as I can tell\n\nI\'ve attached images of the source bigquery table, there have been no changes to it schema wise so fairly confident this is a metabase change-induced issue\n\n![Image](https://github.com/user-attachments/assets/d313ecef-e6e6-42c6-8f52-a6bae74f6f9a)\n![Image](https://github.com/user-attachments/assets/66c0883a-31cd-429e-9ff9-910ca6c770e4)\n![Image](https://github.com/user-attachments/assets/1d608a9f-0b95-413d-a994-23b04f9120fd)\n![Image](https://github.com/user-attachments/assets/e104b64a-3075-4b2f-876d-4174d0cba665)\n![Image](https://github.com/user-attachments/assets/8b694bef-cad6-4176-a11a-f92d9237d62a)\n![Image](https://github.com/user-attachments/assets/64e6a567-356d-4796-b8f0-24def37df25e)', 'created_at': datetime.datetime(2024, 11, 8, 17, 14, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465520617, 'issue_id': 2644533909, 'author': 'ranquild', 'body': ""@rojomisin could you share `/api/card/:id/query_metadata` response for a question where all filters doesn't work? I'd like to know `base_type` and `effective_type` of columns in the tables.\n\nFor now I think that the only reason why this could happen is the sync using `type/*` for the fields or some unsupported type."", 'created_at': datetime.datetime(2024, 11, 8, 18, 45, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465561093, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': ""> [@rojomisin](https://github.com/rojomisin) could you share `/api/card/:id/query_metadata` response for a question where all filters doesn't work? I'd like to know `base_type` and `effective_type` of columns in the tables.\n\nhi @ranquild thanks for the reply, but could you include more details on what you are asking me to share?  I tried appending that to my table (i'm just viewing in the databases => tables manner) but please clarify how to share that response\n\n> \n> For now I think that the only reason why this could happen is the sync using `type/*` for the fields or some unsupported type.\nit's not just type, here's the `name` column same thing\n![Image](https://github.com/user-attachments/assets/ec6d540c-b5f7-47e8-9a2b-6286cc5c12ac)"", 'created_at': datetime.datetime(2024, 11, 8, 19, 8, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465574230, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': 'the comment from the email wont format the images correctly \n\n![Image](https://github.com/user-attachments/assets/283343f3-8a8e-4f97-83f7-cdac3b7209c9)\n![Image](https://github.com/user-attachments/assets/3f06d19d-774e-43f8-87cd-098e558dc782)\n![Image](https://github.com/user-attachments/assets/ca698e37-abf8-4b7d-abf4-41f029560f66)\n![Image](https://github.com/user-attachments/assets/a3d9a595-2eab-46ca-abd5-ca4a67273f2f)\n![Image](https://github.com/user-attachments/assets/bfe12406-f5ac-4a50-948d-40749ef2d745)\n![Image](https://github.com/user-attachments/assets/bf10f2f5-80c6-45f3-8290-178972444a30)', 'created_at': datetime.datetime(2024, 11, 8, 19, 13, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465622980, 'issue_id': 2644533909, 'author': 'luizarakaki', 'body': '@rojomisin when you go to ""Table metadata"", navigate to a field, and click on the gear\n![Image](https://github.com/user-attachments/assets/369e91de-051c-420b-8a5c-6bee6ea3dffe)\n\nCan you check what\'s the API response for GET `/api/field/:field_id`? You can check this in the network tab.\n![Image](https://github.com/user-attachments/assets/fe122dea-aafd-466b-9389-10596b935037)\n\nWe need to check database_type and effective_type', 'created_at': datetime.datetime(2024, 11, 8, 19, 40, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465640431, 'issue_id': 2644533909, 'author': 'luizarakaki', 'body': ""Ok, we found the issue.\n\nWe made changes to BigQuery sync on 51, it is way faster now.\nBut we didn't handle parameterized strings STRING(X), only variable-length strings.\n\nWe are working on a hotfix"", 'created_at': datetime.datetime(2024, 11, 8, 19, 51, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468755243, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': '@ranquild @luizarakaki \nthis is not fixed in 1.51.3 ❗ \nhuge blocker to using the site/app\n\ncan you provide any workarounds or troubleshooting steps?  \n\n![Image](https://github.com/user-attachments/assets/b1d4442a-0e42-4b8a-8af9-ad1b09f32e9d)\n![Image](https://github.com/user-attachments/assets/61290d0b-17f1-4b17-bb0c-3fc67fbddfca)', 'created_at': datetime.datetime(2024, 11, 11, 18, 5, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468814342, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': ""correction, after about an hour it's working now i guess there was some field value migrations going on\nthanks and sorry for firedrill"", 'created_at': datetime.datetime(2024, 11, 11, 18, 42, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468814711, 'issue_id': 2644533909, 'author': 'luizarakaki', 'body': '@rojomisin did you resync the db?', 'created_at': datetime.datetime(2024, 11, 11, 18, 42, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468814836, 'issue_id': 2644533909, 'author': 'luizarakaki', 'body': 'Oh ok', 'created_at': datetime.datetime(2024, 11, 11, 18, 42, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469190857, 'issue_id': 2644533909, 'author': 'rojomisin', 'body': ""> [@rojomisin](https://github.com/rojomisin) did you resync the db?\n\nI didn't have to do anything other than wait, so perhaps my auto-sync for the db is setup eh?  not sure."", 'created_at': datetime.datetime(2024, 11, 11, 22, 25, 31, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-11-08 16:51:45 UTC): Can you provide more information about the column?
What is its data type in BigQuery? Does it happen on other columns?

Unable to reproduce so far

rojomisin (Issue Creator) on (2024-11-08 17:14:08 UTC): surprising you cannot reproduce, we have 300 tables in this bigquery
database, and none of the columns filter, they all say ""empt/not empty"" now

I will try to show the simplest example, but all the fields are broken.
I'll use our `users` -> `lastname` as a simple example

it has 233 individual values to filter on, and it only shows empty/not
empty, it's just a simple string field type as far as I can tell

I've attached images of the source bigquery table, there have been no changes to it schema wise so fairly confident this is a metabase change-induced issue

![Image](https://github.com/user-attachments/assets/d313ecef-e6e6-42c6-8f52-a6bae74f6f9a)
![Image](https://github.com/user-attachments/assets/66c0883a-31cd-429e-9ff9-910ca6c770e4)
![Image](https://github.com/user-attachments/assets/1d608a9f-0b95-413d-a994-23b04f9120fd)
![Image](https://github.com/user-attachments/assets/e104b64a-3075-4b2f-876d-4174d0cba665)
![Image](https://github.com/user-attachments/assets/8b694bef-cad6-4176-a11a-f92d9237d62a)
![Image](https://github.com/user-attachments/assets/64e6a567-356d-4796-b8f0-24def37df25e)

ranquild on (2024-11-08 18:45:39 UTC): @rojomisin could you share `/api/card/:id/query_metadata` response for a question where all filters doesn't work? I'd like to know `base_type` and `effective_type` of columns in the tables.

For now I think that the only reason why this could happen is the sync using `type/*` for the fields or some unsupported type.

rojomisin (Issue Creator) on (2024-11-08 19:08:28 UTC): hi @ranquild thanks for the reply, but could you include more details on what you are asking me to share?  I tried appending that to my table (i'm just viewing in the databases => tables manner) but please clarify how to share that response

it's not just type, here's the `name` column same thing
![Image](https://github.com/user-attachments/assets/ec6d540c-b5f7-47e8-9a2b-6286cc5c12ac)

rojomisin (Issue Creator) on (2024-11-08 19:13:52 UTC): the comment from the email wont format the images correctly 

![Image](https://github.com/user-attachments/assets/283343f3-8a8e-4f97-83f7-cdac3b7209c9)
![Image](https://github.com/user-attachments/assets/3f06d19d-774e-43f8-87cd-098e558dc782)
![Image](https://github.com/user-attachments/assets/ca698e37-abf8-4b7d-abf4-41f029560f66)
![Image](https://github.com/user-attachments/assets/a3d9a595-2eab-46ca-abd5-ca4a67273f2f)
![Image](https://github.com/user-attachments/assets/bfe12406-f5ac-4a50-948d-40749ef2d745)
![Image](https://github.com/user-attachments/assets/bf10f2f5-80c6-45f3-8290-178972444a30)

luizarakaki on (2024-11-08 19:40:30 UTC): @rojomisin when you go to ""Table metadata"", navigate to a field, and click on the gear
![Image](https://github.com/user-attachments/assets/369e91de-051c-420b-8a5c-6bee6ea3dffe)

Can you check what's the API response for GET `/api/field/:field_id`? You can check this in the network tab.
![Image](https://github.com/user-attachments/assets/fe122dea-aafd-466b-9389-10596b935037)

We need to check database_type and effective_type

luizarakaki on (2024-11-08 19:51:35 UTC): Ok, we found the issue.

We made changes to BigQuery sync on 51, it is way faster now.
But we didn't handle parameterized strings STRING(X), only variable-length strings.

We are working on a hotfix

rojomisin (Issue Creator) on (2024-11-11 18:05:50 UTC): @ranquild @luizarakaki 
this is not fixed in 1.51.3 ❗ 
huge blocker to using the site/app

can you provide any workarounds or troubleshooting steps?  

![Image](https://github.com/user-attachments/assets/b1d4442a-0e42-4b8a-8af9-ad1b09f32e9d)
![Image](https://github.com/user-attachments/assets/61290d0b-17f1-4b17-bb0c-3fc67fbddfca)

rojomisin (Issue Creator) on (2024-11-11 18:42:08 UTC): correction, after about an hour it's working now i guess there was some field value migrations going on
thanks and sorry for firedrill

luizarakaki on (2024-11-11 18:42:24 UTC): @rojomisin did you resync the db?

luizarakaki on (2024-11-11 18:42:29 UTC): Oh ok

rojomisin (Issue Creator) on (2024-11-11 22:25:31 UTC): I didn't have to do anything other than wait, so perhaps my auto-sync for the db is setup eh?  not sure.

"
2644521862,issue,open,,Duplicating a dashboard sometimes duplicates it multiple times,"### Describe the bug

We will duplicate a dashboard along with its questions and it'll take a long time to duplicate and then duplicate the item 9 times. This has happened pretty consistently over the past couple of months.

### To Reproduce

1. Select dashboard to duplicate
2. Duplicate the dashboard and its questions
3. The prompt window won't close for a long time
4. The collection it's being duplicated into now has multiple duplicated dashboards

### Expected behavior

It should duplicate once

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""heroku"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1070-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

very annoying

### Additional context

_No response_",dokidzung,2024-11-08 16:32:13+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/49784,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2465445102, 'issue_id': 2644521862, 'author': 'paoliniluis', 'body': 'logs?', 'created_at': datetime.datetime(2024, 11, 8, 18, 0, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465475898, 'issue_id': 2644521862, 'author': 'dokidzung', 'body': '[logs.txt](https://github.com/user-attachments/files/17682545/logs.txt)', 'created_at': datetime.datetime(2024, 11, 8, 18, 16, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465592801, 'issue_id': 2644521862, 'author': 'paoliniluis', 'body': ""your app db is taking minutes to perform the copy operations, and I believe that it's doing some nasty things there. Have you checked that?"", 'created_at': datetime.datetime(2024, 11, 8, 19, 26, 8, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-08 18:00:08 UTC): logs?

dokidzung (Issue Creator) on (2024-11-08 18:16:05 UTC): [logs.txt](https://github.com/user-attachments/files/17682545/logs.txt)

paoliniluis on (2024-11-08 19:26:08 UTC): your app db is taking minutes to perform the copy operations, and I believe that it's doing some nasty things there. Have you checked that?

"
2644412828,issue,open,,Schema sync should not add multiple columns with the Entity Name type,"### Describe the bug

The schema sync process can mark multiple columns with the Entity Name type in the same table. This may lead to the entity name being displayed in field filters from the wrong column.

### To Reproduce

Sync a table with multiple candidate columns for Entity Name:
```
create table test7( id serial, fullName varchar, firstName varchar, lastName varchar );
insert into test7(fullName, firstName, lastName) values
                                                     ('Alice Smith', 'Alice', 'Smith'),
                                                     ('Bob Johnson', 'Bob', 'Johnson');
```

Run schema sync:
![Image](https://github.com/user-attachments/assets/efd76735-7efb-4ea9-a46c-ab8abe90e991)



### Expected behavior

A table is expected to have only one Entity Name type column. Even if schema sync can't pick the correct column with certainty, it should better respect this limitation and not set this type for multiple columns to avoid confusing behavior.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.51.1.8
```

### Severity

P2? - it is confusing.

### Additional context

Reported in v51 and also seen in v49. It likely existed in earlier versions as well.

Related feature request: when multiple columns exist with this type, ideally we should issue a warning in the metadata editor: https://github.com/metabase/metabase/issues/49763 .",zbodi74,2024-11-08 15:45:01+00:00,[],2025-02-04 20:24:34+00:00,,https://github.com/metabase/metabase/issues/49783,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2644405290,issue,closed,not_planned,Use `:column` refs elsewhere in the FE,,NevRA,2024-11-08 15:41:42+00:00,[],2025-01-24 19:30:09+00:00,2025-01-24 19:30:07+00:00,https://github.com/metabase/metabase/issues/49782,[],"[{'comment_id': 2613239891, 'issue_id': 2644405290, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 30, 8, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2025-01-24 19:30:08 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2644384286,issue,closed,completed,"When you rename pie chart segments, the labels are truncated until you save or change settings","### Describe the bug

When you rename pie chart segments, the labels are truncated until you save or change settings.  This would lead me to not use this visualization or rename the wedges as it looks terrible

### To Reproduce

1.  I created a question using sample data:  Join Products to Order and summarize count by product category
2. I relabeled the pie slices with longer labels
3. Notice how they look truncating

![Image](https://github.com/user-attachments/assets/f444cc97-af09-4971-a45e-c8953c72eeba)


After saving, the page refreshes and it looks fine.  In real life though, I wouldn't save, I would just change the chart type or rename the labels to be smaller.

Loom  https://www.loom.com/share/03e7df71af334a2e864da2bd94eba777?sid=e722b6ab-90a5-44ec-85ae-ebe7e3df3043

### Expected behavior

If we need to refresh to show it, we should refresh

### Logs

_No response_

### Information about your Metabase installation

```JSON
master, Built on 2024-11-07

Hash: 5669cb0
```

### Severity

It would prevent me from using this new feature

### Additional context

_No response_",cbalusek,2024-11-08 15:34:26+00:00,['alxnddr'],2024-11-18 20:51:15+00:00,2024-11-18 20:04:34+00:00,https://github.com/metabase/metabase/issues/49779,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2644352381,issue,closed,completed,Expose FilterPicker querying component for the sdk,,heypoom,2024-11-08 15:26:28+00:00,[],2024-12-18 14:55:50+00:00,2024-12-18 14:55:50+00:00,https://github.com/metabase/metabase/issues/49778,[],[],
2644215175,issue,closed,completed,After update 0.51.2 On public Dashboard the link goes to URL don't work,"### Describe the bug

Hello 

After update on 0.51.2 i noticed that on **public dashboard** on a section ""Lien goes to URL"" the link don't Work .

if I am connected to metabase and not in public link mode it works very well

### To Reproduce

1. Go to a public Dashboard which has a section with an external https link. if we click on the button of the section the click does not work nothing happens
2. Click on the button of the section the click does not work nothing happens



### Expected behavior

if we do the same action while connected to metabase on the same dashboard it works normally

### Logs

_No response_

### Information about your Metabase installation

CHrome 130.0.6723.92
Metabase 0.51.2

### Severity

Blocking Public dashboard 

### Additional context

_No response_",DooBio,2024-11-08 14:34:02+00:00,['uladzimirdev'],2024-11-18 12:25:35+00:00,2024-11-18 11:21:44+00:00,https://github.com/metabase/metabase/issues/49776,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Embedding/Public', 'Simple public iframe embeds'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/Querying', '')]","[{'comment_id': 2465948751, 'issue_id': 2644215175, 'author': 'brettcvz', 'body': 'Relatedly, we just recently upgrade to 51.2 from a 50. release and noticed that in our Static Embeds ""Click on a column to set dashboard filters"" no longer works on table views either.\n\nI was able to trace it to [this line](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/components/Visualization/Visualization.jsx#L249) returning `true` in our metabase instance (and therefore continuing on to getClickActions) but returning `false` in the static embed, but I wasn\'t able to narrow down the specific recent change that broke it.', 'created_at': datetime.datetime(2024, 11, 9, 0, 47, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478289428, 'issue_id': 2644215175, 'author': 'uladzimirdev', 'body': '@DooBio which version did you upgrade from?', 'created_at': datetime.datetime(2024, 11, 15, 9, 5, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478316650, 'issue_id': 2644215175, 'author': 'DooBio', 'body': 'I was in 0.50.25', 'created_at': datetime.datetime(2024, 11, 15, 9, 19, 27, tzinfo=datetime.timezone.utc)}]","brettcvz on (2024-11-09 00:47:03 UTC): Relatedly, we just recently upgrade to 51.2 from a 50. release and noticed that in our Static Embeds ""Click on a column to set dashboard filters"" no longer works on table views either.

I was able to trace it to [this line](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/components/Visualization/Visualization.jsx#L249) returning `true` in our metabase instance (and therefore continuing on to getClickActions) but returning `false` in the static embed, but I wasn't able to narrow down the specific recent change that broke it.

uladzimirdev (Assginee) on (2024-11-15 09:05:54 UTC): @DooBio which version did you upgrade from?

DooBio (Issue Creator) on (2024-11-15 09:19:27 UTC): I was in 0.50.25

"
2644184234,issue,open,,Allow Conditional Hiding of Cards that Return NULL or 0,"**Is your feature request related to a problem? Please describe.**
We have questions that are SUM or COUNT of records. If there are records to sum, the card returns ""null"". If there are no records to count, it returns ""0"". We want to hide these cards from the dashboard if there are no records to perform these aggregates on but the ""Hide if no results"" option will not work in this case because there are technically results for the card.

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
- Native SQL question
- In the final summary stage instead of just doing ""count"" or ""sum"" you can group by every field. Having a group by clause let's you filter out NULL or 0 results in the final stage of the query. This allows the ""hide card"" option on the dashboard to work.
- Building another Question on the aggregate question to filter out results.  This allows the ""hide card"" option on the dashboard to work.

**How important is this feature to you?**
The work arounds in the notebook editor are cumbersome and create clutter.
",ixipixi,2024-11-08 14:21:39+00:00,[],2025-02-05 14:54:43+00:00,,https://github.com/metabase/metabase/issues/49772,"[('.Team/DashViz', 'Dashboard and Viz team'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2644031413,issue,closed,completed,Command Palette shows Search results out of order,"### Description

The results shown in the command palette do not appear to match the order they are returned from the BE, they appear to be scrambled.

See below where I added the ordering to the name of the result:

![Image](https://github.com/user-attachments/assets/9c349674-4f86-4ed6-83e1-452ba4353a07)

This scrambling occurs after the results are read from the JSON, but before the results are truncated, hence we may not even show the top result.

We should probably also fix this overfetch issue - it currently fetched 20 results.


### Version

I caught this on master, but suspect it was not a recent regression.",crisptrutski,2024-11-08 13:15:06+00:00,['npfitz'],2024-11-18 16:17:07+00:00,2024-11-18 15:33:46+00:00,https://github.com/metabase/metabase/issues/49766,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2643928751,issue,closed,not_planned,Copying a dashboard doesn't keep original dashboard width.,"### Describe the bug

When dashboard is copied to another collection, it is by default set to lower width setting, instead of keeping the original dashboard's setting.

### To Reproduce

1. Copy a dashboard set to 'Full Width' to another collection
2. Locate the copy
3. Copied dashboard is limited width


### Expected behavior

Copied dashboard resembles the original one, including the desired width setting.

### Logs

_No response_

### Information about your Metabase installation

v0.51.1.2, self hosted

### Severity

Not severe, P3, as this is a mild annoyance. Could potentially slow down automated development though.

### Additional context

_No response_",TLazarevic,2024-11-08 12:36:19+00:00,[],2024-11-08 12:51:31+00:00,2024-11-08 12:51:29+00:00,https://github.com/metabase/metabase/issues/49764,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2464682871, 'issue_id': 2643928751, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/44640', 'created_at': datetime.datetime(2024, 11, 8, 12, 51, 29, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-08 12:51:29 UTC): duplicate of https://github.com/metabase/metabase/issues/44640

"
2643924152,issue,open,,Add input validation and guidance to the metadata editor,"**Is your feature request related to a problem? Please describe.**

Currently, the metadata editor allows column settings to be configured without much guidance or validation, which can make configuration error-prone — especially for less experienced users. Since many features rely on metadata settings, misconfigurations can lead to unexpected or confusing behavior which is challenging to troubleshoot.

**Describe the solution you'd like**

Implement a set of validation rules based on common, best-practice assumptions for metadata configuration. 
When a table is opened in the editor, Metabase should use these rules to perform checks on column-level settings and highlight configurations that may lead to issues.

For instance, warn users if there are multiple columns assigned the ""Entity Name"" field type. As far as I know, we expect only a single column with this setting (to display the entity name in field filter drop-downs), and a warning would help users avoid setting multiple columns to Entity Name, which leads to undefined behavior.

**Describe alternatives you've considered**
n/a

**How important is this feature to you?**
It would help both new and experienced users configure metadata more intuitively and correctly, reducing confusion and improving the overall experience.",zbodi74,2024-11-08 12:33:45+00:00,[],2025-02-04 20:30:49+00:00,,https://github.com/metabase/metabase/issues/49763,"[('Type:New Feature', ''), ('Administration/Table Metadata', ''), ('Semantic Model', '')]",[],
2643922288,issue,closed,completed,Update docs and sample app to not deserialize & re-serialize the session in the auth provider,https://www.notion.so/metabase/Make-troubleshooting-SDK-auth-easier-11f69354c90180319a05e4b652adc249?pvs=4#11f69354c90180859197e284a0213f0f,npretto,2024-11-08 12:32:47+00:00,['npretto'],2024-11-12 10:39:34+00:00,2024-11-12 10:36:45+00:00,https://github.com/metabase/metabase/issues/49762,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2643529730,issue,closed,completed,Check if the mantine branch breaks something on the sdk,"Updated: I tried again on the original branch (without rebasing on master) and everything seems correct.
It's interesting that a lot of stuff broke with the rebase on master, we should probably do another check when the mantine branch is picked up again by admin web app.

---
**OLD RESULTS  on the branch rebase on master**


Results:

# Colors
Not sure if it's caused by me rebasing the mantine branch on master, but some colors were missing and it made the sdk crash, i manually added some renames to make it work:
```ts
export function themeColor(colorName: string, theme: MantineTheme): string {
  console.log(""themeColor"", colorName, theme);
  const remaps: Record<string, string> = {
    ""text-primary"": ""text-medium"",
    ""text-secondary"": ""text-light"",
    ""text-tertiary"": ""text-white"",
    background: ""bg-white"",
  };
  const keyToUse = remaps[colorName] ?? colorName;
  return theme.colors[keyToUse][0] ?? ""transparent"";
}
```

Edit: it's probably caused because master switched to the new colors and the mantine branch didn't


# Static Question
it seems there are some issues with default sizing and with the layout of the numeric vis
![Image](https://github.com/user-attachments/assets/22ca3b33-66d9-4ac4-a31b-3b1d2a0a8e2c)


# Static Dashboard
The filters popover are rendered at the bottom of the page
![Image](https://github.com/user-attachments/assets/3a6a88e2-35cb-4ab8-957e-3cc8ea3cf586)
Other layout issues
![Image](https://github.com/user-attachments/assets/a0b75c27-b77b-4121-9123-c3095555b208)

# Interactive question
Seems to be completely broken
![Image](https://github.com/user-attachments/assets/5a9b0b0a-2bcb-42d0-9491-2587a0c4e208)

",npretto,2024-11-08 10:00:43+00:00,['npretto'],2024-11-13 11:31:09+00:00,2024-11-13 11:30:31+00:00,https://github.com/metabase/metabase/issues/49756,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2464500566, 'issue_id': 2643529730, 'author': 'heypoom', 'body': ""> Not sure if it's caused by me rebasing the mantine branch on master, but some colors were missing and it made the sdk crash\n\nThe crash is likely new -- I didn't get that before when I was building the SDK and testing it on Shoppy. I think interactive question was working well visually at that time: https://metaboat.slack.com/archives/C063Q3F1HPF/p1730713830351609?thread_ts=1730711693.450249&cid=C063Q3F1HPF\n\n(I think the SDK build was working, as I  got the Mantine provider leak issue and that confirmed that Mantine v7 was used)"", 'created_at': datetime.datetime(2024, 11, 8, 11, 38, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473306317, 'issue_id': 2643529730, 'author': 'npretto', 'body': 'Updated the body of the issue, closing this.', 'created_at': datetime.datetime(2024, 11, 13, 11, 30, 31, tzinfo=datetime.timezone.utc)}]","heypoom on (2024-11-08 11:38:12 UTC): The crash is likely new -- I didn't get that before when I was building the SDK and testing it on Shoppy. I think interactive question was working well visually at that time: https://metaboat.slack.com/archives/C063Q3F1HPF/p1730713830351609?thread_ts=1730711693.450249&cid=C063Q3F1HPF

(I think the SDK build was working, as I  got the Mantine provider leak issue and that confirmed that Mantine v7 was used)

npretto (Issue Creator) on (2024-11-13 11:30:31 UTC): Updated the body of the issue, closing this.

"
2643423519,issue,closed,completed,Expose FilterPicker querying component to the sdk,"We should expose the `FilterPicker` querying component that we have to the sdk

![Image](https://github.com/user-attachments/assets/2b86d3b2-2a44-4de5-b9c9-162fdcec5ed3)
",heypoom,2024-11-08 09:24:37+00:00,['heypoom'],2024-11-12 20:44:04+00:00,2024-11-12 20:00:14+00:00,https://github.com/metabase/metabase/issues/49752,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2643365180,issue,closed,completed,[Spike] Explore creating a brand-agnostic theme for the sdk using Mantine's theme configuration,"We should explore creating a brand-agnostic look by leveraging Mantine's theme configuration / theme overrides. Let's explore how we can de-Mantineify or de-Metabasify the UI's looks by tweaking the Mantine config.

Reference: see [Maz's Loom video](https://www.loom.com/share/0f1df1ec8cbb486797b084ae2ebbc45e) here on how the ""brand-agnostic look"" looks like. Imagine Tailwind or Shadcn's stock looks.

Reference Image:

![Image](https://github.com/user-attachments/assets/5eaa6380-90cd-4ed3-8ddb-05fc5767eb3d)
",heypoom,2024-11-08 08:59:17+00:00,[],2025-01-17 05:27:08+00:00,2025-01-17 05:26:39+00:00,https://github.com/metabase/metabase/issues/49748,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2597462327, 'issue_id': 2643365180, 'author': 'heypoom', 'body': ""I think I will close this for now as the theme looks generic enough to apply to any sort of apps already - as demonstrated by using the default layout in Shoppy's 4 themes. We can re-open this when the need for more styling customization actually arises, cc @oisincoveney @albertoperdomo"", 'created_at': datetime.datetime(2025, 1, 17, 5, 26, 39, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2025-01-17 05:26:39 UTC): I think I will close this for now as the theme looks generic enough to apply to any sort of apps already - as demonstrated by using the default layout in Shoppy's 4 themes. We can re-open this when the need for more styling customization actually arises, cc @oisincoveney @albertoperdomo

"
2643191489,issue,closed,not_planned,wrong repo..trying to delete,,morgenstern,2024-11-08 07:54:20+00:00,[],2024-11-08 07:59:55+00:00,2024-11-08 07:59:55+00:00,https://github.com/metabase/metabase/issues/49744,[],[],
2643165744,issue,closed,completed,feat(sdk): Add BreakoutPicker component,,oisincoveney,2024-11-08 07:43:27+00:00,['oisincoveney'],2024-11-28 14:22:20+00:00,2024-11-28 14:18:21+00:00,https://github.com/metabase/metabase/issues/49743,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2643165501,issue,closed,completed,feat(sdk): Add SummarizePicker component,,oisincoveney,2024-11-08 07:43:17+00:00,['oisincoveney'],2024-11-28 14:22:16+00:00,2024-11-28 14:17:58+00:00,https://github.com/metabase/metabase/issues/49742,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2643057461,issue,closed,not_planned,"HTTP ERROR 500 on ""/"" for Prometheus Server http requests","### Describe the bug

An HTTP ERROR 500 on ""/"" for MB_PROMETHEUS_SERVER_PORT http requests (example: localhost:9191/) is returned.

### To Reproduce

To reproduce this issue run the following command:

```shell
docker run --env MB_PROMETHEUS_SERVER_PORT=9191 --publish 3000:3000 --publish 9191:9191 metabase/metabase:v0.51.2.3
```

Then run the following command (or visit in a browser):

```shell
curl http://localhost:9191/ # or visit in a browser
```

The following will be returned:

```
<html>
<head>
<meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/>
<title>Error 500 java.lang.AssertionError: Assert failed: (instance? ExceptionCounterChild child)</title>
</head>
<body><h2>HTTP ERROR 500 java.lang.AssertionError: Assert failed: (instance? ExceptionCounterChild child)</h2>
<table>
<tr><th>URI:</th><td>/</td></tr>
<tr><th>STATUS:</th><td>500</td></tr>
<tr><th>MESSAGE:</th><td>java.lang.AssertionError: Assert failed: (instance? ExceptionCounterChild child)</td></tr>
<tr><th>SERVLET:</th><td>org.eclipse.jetty.servlet.ServletHandler$Default404Servlet-36de215d</td></tr>
<tr><th>CAUSED BY:</th><td>java.lang.AssertionError: Assert failed: (instance? ExceptionCounterChild child)</td></tr>
</table>
<h3>Caused by:</h3><pre>java.lang.AssertionError: Assert failed: (instance? ExceptionCounterChild child)
	at iapetos.collector.exceptions$record_exception_BANG_.invokeStatic(exceptions.clj:70)
	at iapetos.collector.exceptions$record_exception_BANG_.invoke(exceptions.clj:70)
	at iapetos.collector.ring$run_instrumented.invokeStatic(ring.clj:133)
	at iapetos.collector.ring$run_instrumented.invoke(ring.clj:131)
	at iapetos.collector.ring$wrap_instrumentation$fn__62871.invoke(ring.clj:173)
	at iapetos.collector.ring$wrap_metrics_expose$fn__62880.invoke(ring.clj:194)
	at ring.adapter.jetty$proxy_handler$fn__61822.invoke(jetty.clj:109)
	at ring.adapter.jetty.proxy$org.eclipse.jetty.servlet.ServletHandler$ff19274a.doHandle(Unknown Source)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:221)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1381)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:176)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:484)
	at ring.adapter.jetty.proxy$org.eclipse.jetty.servlet.ServletHandler$ff19274a.doScope(Unknown Source)
	at org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:174)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1303)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:129)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Unknown Source)
</pre>
<hr/><a href=""https://jetty.org"">Powered by Jetty:// 11.0.24</a><hr/>

</body>
</html>
```


### Expected behavior

Expected behavior: my feeling is a redirect to `/metrics` or a `404 Not Found` might be more appropriate.


### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-07"",
      ""tag"": ""v0.51.2.3"",
      ""hash"": ""33c6105""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.4-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}


### Severity

Low

### Additional context

Note: this bug was/is filed as a result of human error (I now know the prometheus endpoint is at `/metrics`) but I had tried to access `/` and feel a few other metabase users may be surprised by this behavior as well.",colinbjohnson,2024-11-08 06:50:34+00:00,[],2025-02-05 20:51:26+00:00,2025-02-05 20:51:26+00:00,https://github.com/metabase/metabase/issues/49741,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/', ''), ('Operation/Docker', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2643006568,issue,closed,completed,Drill-through actions for the wrong column are displayed when grouping by fields with null values,"### Describe the bug

When grouping by a field with null values and then clicking on a result corresponding to the null group, you'll get actions like sort and filter by this column (not present for non-null groups). 
![Image](https://github.com/user-attachments/assets/5a011d57-bfda-4f14-b645-9e36f1c7289a)

If you try to actually use one of them, you'll find they actually apply to the group by column, not the result column.
If you have a combo of multiple null values, wrong drill-through actions will stack.


Look at this glorious creature I accidentally made on stats:
![Image](https://github.com/user-attachments/assets/500db34c-ed7f-4dd1-ac7e-b03e16f19c96)



### To Reproduce

1. Create a new question from the `Accounts` table
2. Count by `Source`
3. Visualize
4. Switch to table visualization _(not necessary, but easier to see what's going on)_
5. Click on the Count cell corresponding to the `null` Source
(note: click on the number itself, not the empty Source cell)

There will be drill-trhough actions to Sort and ""filter by this column""

If you try ""Filter by this column"", a dropdown will open with values for Source which fill filter by the Source column

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Started in v49

### Severity

Confusing

### Additional context

https://github.com/user-attachments/assets/7033d095-d5fc-478c-91d3-698f2fa31165
",alexyarosh,2024-11-08 06:27:55+00:00,['appleby'],2025-01-29 21:28:14+00:00,2025-01-29 01:15:05+00:00,https://github.com/metabase/metabase/issues/49740,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2575498749, 'issue_id': 2643006568, 'author': 'bshepherdson', 'body': 'This might have been fixed by recent changes to how _dimensions_ are handled for drill-thru. This issue should be reproduced after eg. #51489 .', 'created_at': datetime.datetime(2025, 1, 7, 14, 54, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603439810, 'issue_id': 2643006568, 'author': 'appleby', 'body': 'Likely the same as #51741', 'created_at': datetime.datetime(2025, 1, 21, 1, 17, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622891295, 'issue_id': 2643006568, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 1, 29, 21, 28, 13, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2025-01-07 14:54:22 UTC): This might have been fixed by recent changes to how _dimensions_ are handled for drill-thru. This issue should be reproduced after eg. #51489 .

appleby (Assginee) on (2025-01-21 01:17:58 UTC): Likely the same as #51741

github-actions[bot] on (2025-01-29 21:28:13 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2642905077,issue,closed,not_planned,Join block disappears when swapping the data source,"### Describe the bug

Join block disappears when swapping the data source... sometimes. 
I have only been able to reliably reproduce it when:
- swapping from model or saved question to a table
- both the model/question and the table have the same name

but I think I had it happen when the names didn't match too, just can't figure out repro steps.

### To Reproduce

1. Save People table as a question called ""People""
2. Start a New question from the Orders table
3. Add a Join block to the People _question_
4. Click on the People card to swap the data source to People _table_

The entire Join block disappears


### Expected behavior

The join block remains with the new data source picked

### Logs

_No response_

### Information about your Metabase installation

v50+

### Severity

P3

### Additional context

https://github.com/user-attachments/assets/07807bfd-d766-4aad-865a-755384e8a00b
",alexyarosh,2024-11-08 05:33:48+00:00,[],2024-11-08 11:32:11+00:00,2024-11-08 11:32:10+00:00,https://github.com/metabase/metabase/issues/49738,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2464481344, 'issue_id': 2642905077, 'author': 'ranquild', 'body': 'It should always disappear. We don’t support data source swapping now.', 'created_at': datetime.datetime(2024, 11, 8, 11, 32, 10, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-08 11:32:10 UTC): It should always disappear. We don’t support data source swapping now.

"
2642848358,issue,open,,Pie charts don't handle drillthrough on (empty) slices correctly,"### Describe the bug

When drilling into slices with `(empty)` values using ""See these records"" action,  a wrong filter is applied: `=""(empty)""` which of course doesn't return the records with actual empty values in the breakout column.

For comparison, bar chart handles this case correctly. Old pie charts handled it correctly as well.

### To Reproduce

1. Start a question from the `Accounts` table
2. Count by `Source`
3. Visualize
4. Switch the visualization to Pie chart
5. Click on `(empty)` slice and select ""See these accounts""

-> Get a screen with no results, and filter for `[Source] = ""(empty)""`

![Image](https://github.com/user-attachments/assets/4b41b713-2fc3-478a-adec-7d4e5b439709)


### Expected behavior

Show records that have nulls in the breakout column

### Logs

_No response_

### Information about your Metabase installation

51.2

### Severity

P2

### Additional context

https://github.com/user-attachments/assets/b6a487fd-f7e0-4181-a65b-4ddb8b0ed20a
",alexyarosh,2024-11-08 04:48:51+00:00,[],2025-02-04 20:27:04+00:00,,https://github.com/metabase/metabase/issues/49737,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Frequency:Often', 'Something users bump into often'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2503123126, 'issue_id': 2642848358, 'author': 'kamilmielnik', 'body': 'It\'s FE bug in viz: `clicked.dimensions[0].value` is `""(empty)""` instead of `null` [here](https://github.com/metabase/metabase/blob/4aa67506aa001805ef99b47239465b2e8f82dc5d/frontend/src/metabase/querying/drills/utils/query-drill.ts#L11).', 'created_at': datetime.datetime(2024, 11, 27, 7, 37, 59, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-11-27 07:37:59 UTC): It's FE bug in viz: `clicked.dimensions[0].value` is `""(empty)""` instead of `null` [here](https://github.com/metabase/metabase/blob/4aa67506aa001805ef99b47239465b2e8f82dc5d/frontend/src/metabase/querying/drills/utils/query-drill.ts#L11).

"
2642768063,issue,closed,completed,Move Apache hive to 4.x version,"**Is your feature request related to a problem? Please describe.**
The hive team marked the 3.x version of the driver EoL: https://hive.apache.org/general/downloads/, we need to move to 4.x, which can affect many of our drivers

**Describe the solution you'd like**
Move to 4.x

**Describe alternatives you've considered**
None

**How important is this feature to you?**
We won't have more patches of this version of the driver

**Additional context**
NA
",paoliniluis,2024-11-08 03:51:41+00:00,[],2025-01-10 17:33:18+00:00,2025-01-10 17:30:03+00:00,https://github.com/metabase/metabase/issues/49735,"[('.Security related', ''), ('Type:New Feature', ''), ('dependencies', None)]",[],
2642721288,issue,open,,Format settings don't respect decimal separator,"### Describe the bug

Auto and Compact series format options will sometimes use the period as a decimal separator, even if comma separator is chosen in Admin > Localization or in the series setting.


Case 1:
**Compact** series format will _always_ show period separator. This applies to both displaying small decimals and displaying shortened versions of large numbers. Namely, if comma is chosen as a decimal separator
- `52,37` will be displayed as `52.37`instead of `52,37`
- `38 569,7` will be displayed as `38.6k` instead of `38,6k`

Case 2:
**Auto** series will always use a period separator when shortening large numbers
- `38 569,7` will be displayed as `38.6k`

Case 3:
 
For small decimal on a single series, Auto will use correct separator. But if another series is added, it might change the behavior of Auto to use the period for small decimals as well.

These look like 3 symptoms of the same thing so I'm making one issue.


Possibly related: #43347, #28574, #24695


### To Reproduce

1. Go to Admin > Localization and set `Separator style` to `100 000,00` (or any other style with comma as decimal separator)

Case 1:
2. Create a new question: Orders > **Average of Total** by Created At: Month
3. On the line chart, go to Settings > Display
4. Toggle on ""Show values on data points"". _The data points will have comma as decimal separator_
5. Change the ""Auto formatting""  from Auto to Compact. _The data points will have period as decimal separator_


Case 2:
2. Create a new question: Orders > **Sum of Total** by Created At: Month
3. On the line chart, go to Settings > Display
4.  Toggle on ""Show values on data points"".
5. Keep the formatting as ""Auto"". _Large numbers will be shortened with period as decimal separator_

Case 3:
2. Create a new question: Orders >  **Average of Total** and  **Sum of Total**  by Created At: Month
3. On the line chart, go to Settings > Display
4.  Toggle on ""Show values on data points""
5. Keep the formatting as ""Auto"". _All numbers will use period as decimal separator_
(if you just had Average, Auto separator would be correct)

Changing the separator is series formatting does not affect the display

### Expected behavior

All format options respect the instance-wide and series-level decimal separators. Separator doesn't change depending on the number of series added

### Logs

_No response_

### Information about your Metabase installation

51.2 but at least since 49

### Severity

Confusing

### Additional context

Case 1:

https://github.com/user-attachments/assets/40b65e49-5dfd-4157-ac45-4c002be5c6b7

",alexyarosh,2024-11-08 03:22:57+00:00,[],2025-02-04 20:31:28+00:00,,https://github.com/metabase/metabase/issues/49734,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2529367814, 'issue_id': 2642721288, 'author': 'ixipixi', 'body': 'Possibly related: https://github.com/metabase/metabase/issues/51075', 'created_at': datetime.datetime(2024, 12, 9, 20, 23, 25, tzinfo=datetime.timezone.utc)}]","ixipixi on (2024-12-09 20:23:25 UTC): Possibly related: https://github.com/metabase/metabase/issues/51075

"
2642209884,issue,closed,completed,Command palette should not show you admin actions if you do not have access to them,"### Describe the bug

The command palette will show you links to the admin app, even if you are not an admin

### To Reproduce

1. Sign in as a non admin
2. open the command palette
3. type ""settings""


### Expected behavior

We should not show you settings links if you are not an admin

### Logs

_No response_

### Information about your Metabase installation

1815b5248fc4cafce942a1e2e99285fe9fb5a7f9

### Severity

Low

### Additional context

_No response_",npfitz,2024-11-07 21:16:29+00:00,['npfitz'],2024-12-20 20:28:28+00:00,2024-12-20 19:45:41+00:00,https://github.com/metabase/metabase/issues/49729,"[('Type:Bug', 'Product defects'), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2641811702,issue,closed,not_planned,Trash folder - collections cannot be deleted permanently,"### Describe the bug

Collections cannot permanently deleted from trash folder.
Should administrators see the deleted items from all users or just items they delete themselves?

![Image](https://github.com/user-attachments/assets/8a5fb254-2ad4-463b-8e9b-17628abd28a8)


### To Reproduce

1. Create a collection
2. Delete
3. Go to trash
4. Try do delete permanently


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v1.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P3

### Additional context

_No response_",fer-batista,2024-11-07 18:12:40+00:00,[],2024-11-18 15:52:43+00:00,2024-11-07 18:50:34+00:00,https://github.com/metabase/metabase/issues/49724,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2462984219, 'issue_id': 2641811702, 'author': 'paoliniluis', 'body': 'Duplicate', 'created_at': datetime.datetime(2024, 11, 7, 18, 50, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-07 18:50:34 UTC): Duplicate

"
2641688749,issue,open,,Add strict mode to Storybook decorators in the sdk,We should be aware of strict mode problems in the sdk. Let's add `<StrictMode>` to the Storybook decorators in the sdk.,heypoom,2024-11-07 17:20:25+00:00,[],2025-02-04 20:25:57+00:00,,https://github.com/metabase/metabase/issues/49721,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2462820378, 'issue_id': 2641688749, 'author': 'npretto', 'body': 'I think there is a way to also make a global button/knob to enable/disable it, which could be handy when testing', 'created_at': datetime.datetime(2024, 11, 7, 17, 22, 52, tzinfo=datetime.timezone.utc)}]","npretto on (2024-11-07 17:22:52 UTC): I think there is a way to also make a global button/knob to enable/disable it, which could be handy when testing

"
2641650502,issue,closed,completed,[Spike] Split breakout and summary querying components,"The goal is to be able to expose the ""Breakout"" and ""Summary"" components separately in the embedding sdk, so folks can build a more customized querying experience, where the summary and breakout is not tied together.

Here is a visual example that we want to be able to do in the end. (See [Figma](https://www.figma.com/design/W307FIujMcLXD7alT1M0qc/Improve-UX-for-self-service-analytics-using-SDK?node-id=0-1&node-type=canvas&t=Rt46sDH5WnBChwh3-0) for more screens)

![Image](https://github.com/user-attachments/assets/2e940041-4c4b-4969-a85b-688ec2ccea59)
",heypoom,2024-11-07 17:02:36+00:00,['oisincoveney'],2024-11-28 14:18:32+00:00,2024-11-28 14:18:32+00:00,https://github.com/metabase/metabase/issues/49720,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641575023,issue,closed,completed,Improve usability of InteractiveQuestion's default view by using contextual querying components,"After we have implemented the modular querying components such as `FilterSelector`, `FilterPanel` and `BreakoutSelector`, we want to use those components to improve the default question view (the `InteractiveQuestionResult`).

We can [follow the design](https://www.figma.com/design/W307FIujMcLXD7alT1M0qc/Improve-UX-for-self-service-analytics-using-SDK?t=Rt46sDH5WnBChwh3-0) here and use contextual querying components in place of full-screen components, such as `FilterSelector` in a popover for selecting filters. This makes the default querying experience better than switching between components that takes up the full screen.

See the [tech docs](https://www.notion.so/metabase/Tech-Improving-the-question-component-s-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4#13769354c90180e98136c53dfbadd084) for more info.",heypoom,2024-11-07 16:41:46+00:00,[],2024-12-10 12:27:48+00:00,2024-12-10 12:27:48+00:00,https://github.com/metabase/metabase/issues/49719,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641560339,issue,closed,completed,Ability to render custom question views when clicking on a dashcard in InteractiveDashboard,"We should allow customization of the question view when clicking through to a question from dashboard cards. We can expose the `renderQuestion` prop for rendering the custom question view when we click on a dashcard. We can then use the same namespaced components such as `InteractiveQuestion.FilterPicker` to build the custom view here. It would look like this:

```
<InteractiveDashboard
  dashboardId={1}
  renderQuestion={QuestionView}
/>

const QuestionView = () => (
  <div>
    <InteractiveQuestion.FilterPicker />
  </div>
)
```

See the [tech doc](https://www.notion.so/metabase/Tech-Improving-the-question-component-s-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4#13169354c901803fa026ca4323e6fc6a) for more info.",heypoom,2024-11-07 16:36:29+00:00,['heypoom'],2024-11-19 20:42:55+00:00,2024-11-19 20:00:37+00:00,https://github.com/metabase/metabase/issues/49718,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641552628,issue,closed,completed,Ability to create questions via the InteractiveQuestion sdk component,"Our goal is to deprecate the `CreateQuestion` component (https://github.com/metabase/metabase/issues/49715) and let people use the `InteractiveQuestion` component for creating new questions. We want to add the [ability to create new questions](https://www.notion.so/metabase/Tech-Improving-the-question-component-s-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4#13169354c90180afafc8ceb6ea0c6aeb) to InteractiveQuestion.
",heypoom,2024-11-07 16:32:37+00:00,['heypoom'],2024-11-12 19:13:06+00:00,2024-11-12 19:11:27+00:00,https://github.com/metabase/metabase/issues/49717,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2467590559, 'issue_id': 2641552628, 'author': 'heypoom', 'body': '~To check if this is blocked by https://github.com/metabase/metabase/issues/49581~ no, not related', 'created_at': datetime.datetime(2024, 11, 11, 9, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471353470, 'issue_id': 2641552628, 'author': 'heypoom', 'body': 'Using `InteractiveQuestion` to create questions is almost working. The `questionId` issue is my fault - I didn\'t realize that the `QuestionVisualization` component shows ""Question not found"" initially when `questionId` is `null`, but creating questions in the notebook editor still works. I think we can improve this behaviour to reduce confusion though (e.g. by not showing ""question not found"" if ID is null or undefined)? I\'ll open a discussion in Slack.\n\nThe biggest issue right now that I noticed is that the `onSave` and `onBeforeSave` props did NOT get called when using the save question form in Shoppy, for some reason. Therefore I cannot close the save modal.\n\nI\'ll create separate granular issues for improving the create question flow then. For now, I will close this issue since creating question works as expected.', 'created_at': datetime.datetime(2024, 11, 12, 19, 11, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471355706, 'issue_id': 2641552628, 'author': 'heypoom', 'body': ""I replaced the create question implementation in Shoppy: https://github.com/metabase/shoppy/pull/86. I'll add a SDK documentation on how to implement create questions with `InteractiveQuestion` in issue https://github.com/metabase/metabase/issues/49715."", 'created_at': datetime.datetime(2024, 11, 12, 19, 12, 45, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-11 09:01:00 UTC): ~To check if this is blocked by https://github.com/metabase/metabase/issues/49581~ no, not related

heypoom (Issue Creator) on (2024-11-12 19:11:27 UTC): Using `InteractiveQuestion` to create questions is almost working. The `questionId` issue is my fault - I didn't realize that the `QuestionVisualization` component shows ""Question not found"" initially when `questionId` is `null`, but creating questions in the notebook editor still works. I think we can improve this behaviour to reduce confusion though (e.g. by not showing ""question not found"" if ID is null or undefined)? I'll open a discussion in Slack.

The biggest issue right now that I noticed is that the `onSave` and `onBeforeSave` props did NOT get called when using the save question form in Shoppy, for some reason. Therefore I cannot close the save modal.

I'll create separate granular issues for improving the create question flow then. For now, I will close this issue since creating question works as expected.

heypoom (Issue Creator) on (2024-11-12 19:12:45 UTC): I replaced the create question implementation in Shoppy: https://github.com/metabase/shoppy/pull/86. I'll add a SDK documentation on how to implement create questions with `InteractiveQuestion` in issue https://github.com/metabase/metabase/issues/49715.

"
2641549674,issue,closed,completed,Deprecate ModifyQuestion sdk component,"We should deprecate the `ModifyQuestion` component, as `InteractiveQuestion` with `isSaveEnabled` already does the trick.",heypoom,2024-11-07 16:31:15+00:00,['heypoom'],2024-11-08 10:47:41+00:00,2024-11-08 10:02:07+00:00,https://github.com/metabase/metabase/issues/49716,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641549510,issue,closed,completed,Deprecate CreateQuestion and migrate cli and docs to InteractiveQuestion,"We can deprecate the CreateQuestion component now that the InteractiveQuestion component supports creating questions.

- We should add a code sample on how to do this in the docs as well, as it can be a little tricky to implement by yourself.
- We should also update the CLI to use InteractiveQuestion.",heypoom,2024-11-07 16:31:10+00:00,['heypoom'],2024-11-15 15:16:38+00:00,2024-11-15 15:16:37+00:00,https://github.com/metabase/metabase/issues/49715,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2479118743, 'issue_id': 2641549510, 'author': 'heypoom', 'body': 'This is superseded by https://github.com/metabase/metabase/issues/50082 as we want to still provide a sensible default for creating questions, albeit with a nicer API.', 'created_at': datetime.datetime(2024, 11, 15, 15, 16, 37, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-15 15:16:37 UTC): This is superseded by https://github.com/metabase/metabase/issues/50082 as we want to still provide a sensible default for creating questions, albeit with a nicer API.

"
2641531494,issue,closed,completed,[Epic] Improve InteractiveQuestion and InteractiveDashboard sdk component (Part 1),"**Links**
- product docs:
- [Improvements to Question and Dashboard SDK components](https://www.notion.so/metabase/Improvements-to-Question-and-Dashboard-SDK-components-12469354c90180acbdbcdb8cfeecc455?pvs=4)
- [Make low-hanging fruit improvements to Shoppy](https://www.notion.so/metabase/Make-low-hanging-fruit-improvements-to-Shoppy-12a69354c9018011be49edf18852c7c0?pvs=4)
- eng doc: [improving the question component’s querying experience for embedding sdk](https://www.notion.so/metabase/Tech-Improving-the-question-component-s-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4)

***Milestone 1***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/49672
- [ ] https://github.com/metabase/metabase/issues/49716
- [ ] https://github.com/metabase/shoppy/issues/79
- [ ] https://github.com/metabase/metabase/issues/49712
- [ ] https://github.com/metabase/metabase/issues/45766
- [ ] https://github.com/metabase/metabase/issues/49752
- [ ] https://github.com/metabase/metabase/issues/47559
```

***Milestone 2***
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/49717
- [ ] https://github.com/metabase/metabase/issues/49715
- [ ] https://github.com/metabase/metabase/issues/49718
- [ ] https://github.com/metabase/metabase/issues/50082
- [ ] https://github.com/metabase/metabase/issues/50008
- [ ] https://github.com/metabase/shoppy/issues/85
- [ ] https://github.com/metabase/metabase/issues/47560
```

***Milestone 3***
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/49719
- [ ] https://github.com/metabase/metabase/issues/49720
- [ ] https://github.com/metabase/metabase/issues/49742
- [ ] https://github.com/metabase/metabase/issues/49743
- [ ] https://github.com/metabase/metabase/pull/50506
- [ ] https://github.com/metabase/metabase/pull/50226
- [ ] https://github.com/metabase/metabase/pull/50401
- [ ] https://github.com/metabase/metabase/pull/50039
- [ ] https://github.com/metabase/metabase/pull/50509
- [ ] https://github.com/metabase/metabase/pull/50522
```

***Related Epics***
- Moved tasks that can be done after the GA release to a separate epic: https://github.com/metabase/metabase/issues/50393",heypoom,2024-11-07 16:23:14+00:00,['oisincoveney'],2024-12-13 14:15:53+00:00,2024-12-13 14:15:52+00:00,https://github.com/metabase/metabase/issues/49713,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641507827,issue,closed,completed,[Spike] Proof-of-concept for FilterPicker component in the sdk,Let's create a proof-of-concept for the FilterSelector component in the sdk - which is a modular component for the `InteractiveQuestion` component. See the [tech docs](https://www.notion.so/metabase/Tech-Improving-the-question-component-s-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4) for more.,heypoom,2024-11-07 16:13:35+00:00,['heypoom'],2024-11-08 15:25:46+00:00,2024-11-08 15:25:44+00:00,https://github.com/metabase/metabase/issues/49712,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2465036038, 'issue_id': 2641507827, 'author': 'heypoom', 'body': ""Closing spike as I got a working PR, albeit it is still Metabase-themed as opposed of neutral branding. We'll work on that next. https://github.com/metabase/metabase/pull/49768"", 'created_at': datetime.datetime(2024, 11, 8, 15, 25, 44, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-08 15:25:44 UTC): Closing spike as I got a working PR, albeit it is still Metabase-themed as opposed of neutral branding. We'll work on that next. https://github.com/metabase/metabase/pull/49768

"
2641491214,issue,closed,completed,[SDK] detect mismatch between sdk version and metabase version,"
Context: https://metaboat.slack.com/archives/C063Q3F1HPF/p1730995200421519?thread_ts=1730986265.758069&cid=C063Q3F1HPF

We should be able to do it in the initialization of auth, since we fetch the instance settings there",npretto,2024-11-07 16:07:57+00:00,['npretto'],2024-11-19 09:33:15+00:00,2024-11-19 08:08:17+00:00,https://github.com/metabase/metabase/issues/49711,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2641353069,issue,closed,not_planned,Trash accessible to people without permissions,"### Describe the bug

I work with a use case of separate teams having separate collection access. I set different teams up with view access to only their collections. 
I was testing things out and realized teams have access to see the collections in trash, and every question inside them, and even run the questions they would never have access to! On another note, I was not able to perma delete the problematic trashed collections at all and revoke the access, so I had to move them somewhere else. This is a very recent behavior probably, introduced with trash sidebar

### To Reproduce

1. Have trashed collections
2. Give out view access to some collections to some user groups
3. Log in as a test user from said group
4. Freely roam trash


### Expected behavior

Trash is kept secret

### Logs

_No response_

### Information about your Metabase installation

v51.1.2, self hosted

### Severity

P1 to me

### Additional context

_No response_",TLazarevic,2024-11-07 15:21:37+00:00,[],2024-11-08 14:30:10+00:00,2024-11-07 20:49:10+00:00,https://github.com/metabase/metabase/issues/49705,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2462577650, 'issue_id': 2641353069, 'author': 'noahmoss', 'body': ""@TLazarevic I'm not able to repro. Could you provide more details about your permissions setup?"", 'created_at': datetime.datetime(2024, 11, 7, 15, 48, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462594130, 'issue_id': 2641353069, 'author': 'TLazarevic', 'body': ""> @TLazarevic I'm not able to repro. Could you provide more details about your permissions setup? \n\nI'd share more info but I had to react quickly. Maybe it's an issue on my side but it goes like this:\n\nI'm an admin. I create collection C1 and user group G1. I add view access to G1 on C1 and it's subcollections. I log in as a member of G1 and I can see trashed collections that I shouldnt see. I don't think the whole trash was visible, just the stuff that was in a folder (collection) and then everything inside it. When I return to admin account, I can't perma delete those collections from trash"", 'created_at': datetime.datetime(2024, 11, 7, 15, 54, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462602896, 'issue_id': 2641353069, 'author': 'TLazarevic', 'body': ""> @TLazarevic I'm not able to repro. Could you provide more details about your permissions setup? \n\nI also quickly checked the docs for trash and it said that you should see stuff that you have a curate access to only, but my group members should not have curate access to anything, let alone stuff outside their scope, so I think it's a bug. But also, I could be doing something wrong with the permissions"", 'created_at': datetime.datetime(2024, 11, 7, 15, 58, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462739572, 'issue_id': 2641353069, 'author': 'johnswanson', 'body': '@TLazarevic when you say\n\n> On another note, I was not able to perma delete the problematic trashed collections at all and revoke the access, so I had to move them somewhere else\n\ndid you change permissions after the move to ""somewhere else""? Or only move the trashed collections to a different location? If the permissions are unchanged, I\'m wondering if I could ask you to go to the Permissions section of the admin panel, then go to Collections and navigate to one of the problematic collections, and just make sure that its permissions look correct - it should say ""No Access"" for all groups that the relevant user(s) are in. This would definitely include G1, but also ""All Users,"" because permissions are additive (in other words, if your user has ""Read"" permissions from ""All Users"" and ""No Access"" permissions from ""G1"", the ""Read"" permission ""wins""). If any group the user is in has ""Read"" or higher, the user will be able to view and run questions inside it.\n\nAlso, you probably know this, but note that collection permissions aren\'t recursive, so e.g. if a user has ""No Access"" to collection C1 but Read access to its subcollection C2, they\'ll still be able to get to and view C2. If C1 is in the ""Our Analytics"" collection and C2 is in C1, this user would instead see C2 in the ""Our Analytics"" collection.\n\nThanks for reporting this btw, definitely want to get this figured out as soon as possible.', 'created_at': datetime.datetime(2024, 11, 7, 16, 48, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462910033, 'issue_id': 2641353069, 'author': 'TLazarevic', 'body': '> @TLazarevic when you say\n> \n> > On another note, I was not able to perma delete the problematic trashed collections at all and revoke the access, so I had to move them somewhere else\n> \n> did you change permissions after the move to ""somewhere else""? Or only move the trashed collections to a different location? If the permissions are unchanged, I\'m wondering if I could ask you to go to the Permissions section of the admin panel, then go to Collections and navigate to one of the problematic collections, and just make sure that its permissions look correct - it should say ""No Access"" for all groups that the relevant user(s) are in. This would definitely include G1, but also ""All Users,"" because permissions are additive (in other words, if your user has ""Read"" permissions from ""All Users"" and ""No Access"" permissions from ""G1"", the ""Read"" permission ""wins""). If any group the user is in has ""Read"" or higher, the user will be able to view and run questions inside it.\n> \n> Also, you probably know this, but note that collection permissions aren\'t recursive, so e.g. if a user has ""No Access"" to collection C1 but Read access to its subcollection C2, they\'ll still be able to get to and view C2. If C1 is in the ""Our Analytics"" collection and C2 is in C1, this user would instead see C2 in the ""Our Analytics"" collection.\n> \n> Thanks for reporting this btw, definitely want to get this figured out as soon as possible.\n\nI will check these things in a few hours when I\'m available, I\'m aware of the permission \'unioning\' so I also did first check that All users have no access almost everywhere, but I\'ll recheck the little details and return with more confident answer. The deleted collections should be from different sources as well but I\'ll check, don\'t waste more time on this until then', 'created_at': datetime.datetime(2024, 11, 7, 18, 8, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463098137, 'issue_id': 2641353069, 'author': 'TLazarevic', 'body': '> [@TLazarevic](https://github.com/TLazarevic) when you say\n> \n> > On another note, I was not able to perma delete the problematic trashed collections at all and revoke the access, so I had to move them somewhere else\n> \n> did you change permissions after the move to ""somewhere else""? Or only move the trashed collections to a different location? If the permissions are unchanged, I\'m wondering if I could ask you to go to the Permissions section of the admin panel, then go to Collections and navigate to one of the problematic collections, and just make sure that its permissions look correct - it should say ""No Access"" for all groups that the relevant user(s) are in. This would definitely include G1, but also ""All Users,"" because permissions are additive (in other words, if your user has ""Read"" permissions from ""All Users"" and ""No Access"" permissions from ""G1"", the ""Read"" permission ""wins""). If any group the user is in has ""Read"" or higher, the user will be able to view and run questions inside it.\n> \n> Also, you probably know this, but note that collection permissions aren\'t recursive, so e.g. if a user has ""No Access"" to collection C1 but Read access to its subcollection C2, they\'ll still be able to get to and view C2. If C1 is in the ""Our Analytics"" collection and C2 is in C1, this user would instead see C2 in the ""Our Analytics"" collection.\n> \n> Thanks for reporting this btw, definitely want to get this figured out as soon as possible.\n\nOne of the collections I remember, after I moved it from trash to my personal collection and now to Our Analytics has Curate for admins, View for data team, and All Users and other groups have No Access.\nI will now try to reproduce with an empty collection', 'created_at': datetime.datetime(2024, 11, 7, 19, 58, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463120165, 'issue_id': 2641353069, 'author': 'TLazarevic', 'body': '> [@TLazarevic](https://github.com/TLazarevic) when you say\n> \n> > On another note, I was not able to perma delete the problematic trashed collections at all and revoke the access, so I had to move them somewhere else\n> \n> did you change permissions after the move to ""somewhere else""? Or only move the trashed collections to a different location? If the permissions are unchanged, I\'m wondering if I could ask you to go to the Permissions section of the admin panel, then go to Collections and navigate to one of the problematic collections, and just make sure that its permissions look correct - it should say ""No Access"" for all groups that the relevant user(s) are in. This would definitely include G1, but also ""All Users,"" because permissions are additive (in other words, if your user has ""Read"" permissions from ""All Users"" and ""No Access"" permissions from ""G1"", the ""Read"" permission ""wins""). If any group the user is in has ""Read"" or higher, the user will be able to view and run questions inside it.\n> \n> Also, you probably know this, but note that collection permissions aren\'t recursive, so e.g. if a user has ""No Access"" to collection C1 but Read access to its subcollection C2, they\'ll still be able to get to and view C2. If C1 is in the ""Our Analytics"" collection and C2 is in C1, this user would instead see C2 in the ""Our Analytics"" collection.\n> \n> Thanks for reporting this btw, definitely want to get this figured out as soon as possible.\n\nI cannot reproduce anymore ☠ We can close for now, I have no idea what to check.\nI tried with trashing an empty collection, and trashing a collection with a random question, and it\'s invisible to users with limited permissions. No clue what else to check. Can you repro inability to perma delete folders from trash? I still run into that one.', 'created_at': datetime.datetime(2024, 11, 7, 20, 9, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464905639, 'issue_id': 2641353069, 'author': 'johnswanson', 'body': ""@TLazarevic \n\n> Can you repro inability to perma delete folders from trash? I still run into that one.\n\nYes, that is actually intentional for now. We'd like to be able to delete collections eventually, but it's not prioritized right now. Agreed that it's weird, and we should probably try to make it more obvious that it's expected.\n\nThanks again for reporting this and definitely let us know if you see it in the future."", 'created_at': datetime.datetime(2024, 11, 8, 14, 30, 9, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-11-07 15:48:18 UTC): @TLazarevic I'm not able to repro. Could you provide more details about your permissions setup?

TLazarevic (Issue Creator) on (2024-11-07 15:54:29 UTC): I'd share more info but I had to react quickly. Maybe it's an issue on my side but it goes like this:

I'm an admin. I create collection C1 and user group G1. I add view access to G1 on C1 and it's subcollections. I log in as a member of G1 and I can see trashed collections that I shouldnt see. I don't think the whole trash was visible, just the stuff that was in a folder (collection) and then everything inside it. When I return to admin account, I can't perma delete those collections from trash

TLazarevic (Issue Creator) on (2024-11-07 15:58:02 UTC): I also quickly checked the docs for trash and it said that you should see stuff that you have a curate access to only, but my group members should not have curate access to anything, let alone stuff outside their scope, so I think it's a bug. But also, I could be doing something wrong with the permissions

johnswanson on (2024-11-07 16:48:17 UTC): @TLazarevic when you say


did you change permissions after the move to ""somewhere else""? Or only move the trashed collections to a different location? If the permissions are unchanged, I'm wondering if I could ask you to go to the Permissions section of the admin panel, then go to Collections and navigate to one of the problematic collections, and just make sure that its permissions look correct - it should say ""No Access"" for all groups that the relevant user(s) are in. This would definitely include G1, but also ""All Users,"" because permissions are additive (in other words, if your user has ""Read"" permissions from ""All Users"" and ""No Access"" permissions from ""G1"", the ""Read"" permission ""wins""). If any group the user is in has ""Read"" or higher, the user will be able to view and run questions inside it.

Also, you probably know this, but note that collection permissions aren't recursive, so e.g. if a user has ""No Access"" to collection C1 but Read access to its subcollection C2, they'll still be able to get to and view C2. If C1 is in the ""Our Analytics"" collection and C2 is in C1, this user would instead see C2 in the ""Our Analytics"" collection.

Thanks for reporting this btw, definitely want to get this figured out as soon as possible.

TLazarevic (Issue Creator) on (2024-11-07 18:08:05 UTC): I will check these things in a few hours when I'm available, I'm aware of the permission 'unioning' so I also did first check that All users have no access almost everywhere, but I'll recheck the little details and return with more confident answer. The deleted collections should be from different sources as well but I'll check, don't waste more time on this until then

TLazarevic (Issue Creator) on (2024-11-07 19:58:04 UTC): One of the collections I remember, after I moved it from trash to my personal collection and now to Our Analytics has Curate for admins, View for data team, and All Users and other groups have No Access.
I will now try to reproduce with an empty collection

TLazarevic (Issue Creator) on (2024-11-07 20:09:55 UTC): I cannot reproduce anymore ☠ We can close for now, I have no idea what to check.
I tried with trashing an empty collection, and trashing a collection with a random question, and it's invisible to users with limited permissions. No clue what else to check. Can you repro inability to perma delete folders from trash? I still run into that one.

johnswanson on (2024-11-08 14:30:09 UTC): @TLazarevic 


Yes, that is actually intentional for now. We'd like to be able to delete collections eventually, but it's not prioritized right now. Agreed that it's weird, and we should probably try to make it more obvious that it's expected.

Thanks again for reporting this and definitely let us know if you see it in the future.

"
2641251016,issue,open,,Probably also in the FE code (eg. dashboard filters),,bshepherdson,2024-11-07 14:45:29+00:00,[],2024-11-07 14:45:29+00:00,,https://github.com/metabase/metabase/issues/49698,[],[],
2641250832,issue,open,,"Loads of legacy code in `metabase.lib.*` for dealing with old refs, which can now be dropped!",,bshepherdson,2024-11-07 14:45:26+00:00,[],2024-11-07 14:45:26+00:00,,https://github.com/metabase/metabase/issues/49697,[],[],
2641250424,issue,open,,"BE: Convert existing dashboard parameter mappings, native query filters, and viz settings to `:column` refs on read.",,bshepherdson,2024-11-07 14:45:18+00:00,[],2024-11-07 14:45:18+00:00,,https://github.com/metabase/metabase/issues/49696,[],[],
2641249856,issue,open,,FE: Use `:column` refs in viz settings,,bshepherdson,2024-11-07 14:45:06+00:00,[],2024-11-07 14:45:06+00:00,,https://github.com/metabase/metabase/issues/49695,[],[],
2641249684,issue,open,,FE: Use `:column` refs (or raw idents?) in dashboard parameter mapping,,bshepherdson,2024-11-07 14:45:02+00:00,[],2024-11-07 14:45:02+00:00,,https://github.com/metabase/metabase/issues/49694,[],[],
2641249391,issue,open,,BE: Accept `:column` refs for native query filters,,bshepherdson,2024-11-07 14:44:56+00:00,[],2024-11-07 14:44:56+00:00,,https://github.com/metabase/metabase/issues/49693,[],[],
2641249177,issue,open,,BE: Accept `:column` refs for dashboard parameters,,bshepherdson,2024-11-07 14:44:52+00:00,[],2024-11-07 14:44:52+00:00,,https://github.com/metabase/metabase/issues/49692,[],[],
2641247893,issue,closed,not_planned,Use `:column` refs for `:field` refs within MBQL lib,,bshepherdson,2024-11-07 14:44:26+00:00,[],2025-01-24 19:30:14+00:00,2025-01-24 19:30:14+00:00,https://github.com/metabase/metabase/issues/49691,[],"[{'comment_id': 2613239778, 'issue_id': 2641247893, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 30, 3, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-24 19:30:03 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2641247521,issue,closed,not_planned,Use `:column` refs in place of `:expression` refs,,bshepherdson,2024-11-07 14:44:19+00:00,[],2025-01-24 19:30:29+00:00,2025-01-24 19:30:29+00:00,https://github.com/metabase/metabase/issues/49690,[],"[{'comment_id': 2613239631, 'issue_id': 2641247521, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 29, 57, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-24 19:29:57 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2641247313,issue,closed,not_planned,Use `:column` refs in place of `:aggregation` refs,,bshepherdson,2024-11-07 14:44:15+00:00,[],2025-01-24 19:29:52+00:00,2025-01-24 19:29:51+00:00,https://github.com/metabase/metabase/issues/49689,[],"[{'comment_id': 2613239480, 'issue_id': 2641247313, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 29, 51, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-24 19:29:51 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2641246470,issue,closed,not_planned,Consume the reified column lists to implement `visible-columns` etc.,,bshepherdson,2024-11-07 14:43:57+00:00,[],2025-01-24 19:29:06+00:00,2025-01-24 19:29:04+00:00,https://github.com/metabase/metabase/issues/49688,[],"[{'comment_id': 2613238274, 'issue_id': 2641246470, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 29, 5, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-24 19:29:05 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2641246084,issue,closed,not_planned,Reify the column lists on every edit to a query,,bshepherdson,2024-11-07 14:43:50+00:00,[],2025-01-24 19:28:54+00:00,2025-01-24 19:28:53+00:00,https://github.com/metabase/metabase/issues/49687,[],"[{'comment_id': 2613237983, 'issue_id': 2641246084, 'author': 'bshepherdson', 'body': 'Obsoleted by the evolving plans for the field refs overhaul.', 'created_at': datetime.datetime(2025, 1, 24, 19, 28, 53, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-24 19:28:53 UTC): Obsoleted by the evolving plans for the field refs overhaul.

"
2641245900,issue,closed,completed,"Return `:ident`s from `MetadataProvider`s, both JVM and JS",,bshepherdson,2024-11-07 14:43:46+00:00,[],2025-01-27 22:12:23+00:00,2025-01-08 16:12:54+00:00,https://github.com/metabase/metabase/issues/49686,[],[],
2641245584,issue,closed,completed,Send `:ident`s over the wire in `/query_metadata` and `result_metadata`.,,bshepherdson,2024-11-07 14:43:40+00:00,[],2025-01-02 15:17:29+00:00,2025-01-02 15:17:28+00:00,https://github.com/metabase/metabase/issues/49685,[],"[{'comment_id': 2567932760, 'issue_id': 2641245584, 'author': 'bshepherdson', 'body': 'This step turned out not to be needed. The FE metadata contains everything it needs to know to be able to synthesize `:ident`s rather than get them from the BE.', 'created_at': datetime.datetime(2025, 1, 2, 15, 17, 28, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2025-01-02 15:17:28 UTC): This step turned out not to be needed. The FE metadata contains everything it needs to know to be able to synthesize `:ident`s rather than get them from the BE.

"
2641245146,issue,closed,completed,"Backfill any missing `:ident`s (in a serdes-portable way, rather than random) for existing queries, when we read them from AppDB.",,bshepherdson,2024-11-07 14:43:31+00:00,[],2025-01-27 22:12:41+00:00,2024-12-31 16:47:05+00:00,https://github.com/metabase/metabase/issues/49684,[],[],
2641244882,issue,closed,completed,Update `lib.convert` to preserve `:ident`s,,bshepherdson,2024-11-07 14:43:25+00:00,[],2025-01-27 22:13:38+00:00,2024-12-10 15:04:24+00:00,https://github.com/metabase/metabase/issues/49683,[],[],
2641244666,issue,closed,completed,"Modify legacy MBQL to preserve the randomly-generated `:ident`s of aggregations, join clauses, etc.",,bshepherdson,2024-11-07 14:43:21+00:00,[],2025-01-27 22:13:38+00:00,2024-12-10 15:04:23+00:00,https://github.com/metabase/metabase/issues/49682,[],[],
2641244460,issue,closed,completed,"Randomly generate `:ident` for new aggregations, expressions, breakouts, and explicit joins.",,bshepherdson,2024-11-07 14:43:16+00:00,[],2025-01-27 22:14:20+00:00,2024-11-29 16:56:08+00:00,https://github.com/metabase/metabase/issues/49681,[],[],
2640944498,issue,open,reopened,POST `/api/mt/gtap` should throw an exception when related card does not have `result_metadata`,"### Describe the bug

See: https://github.com/metabase/metabase-enterprise/issues/520#issuecomment-772528159

----

We have this test: https://github.com/metabase/metabase/blob/86ff88a/e2e/test/scenarios/permissions/sandboxes.cy.spec.js#L591-L606
The ""normal"" variant is an actual repro for https://github.com/metabase/metabase-enterprise/issues/520.
This test is currently `@quarantine`d because it fails.
It fails because `card.result_metadata` of related card is `null`.
It's `null` because the question has never been run.

There are 2 real-world use-cases where it can happen:
1. admin creates an SQL question via UI without running it
2. admin creates a question via API without running it - this is exactly what the test reproduces

So it means the problem (https://github.com/metabase/metabase-enterprise/issues/520) is still there. Sandboxing won't work correctly if the card's `result_metadata` is `null`.

Suggested solution: POST `/api/mt/gtap` should throw an exception when related card does not have `result_metadata`.
Thanks to this, in 2 aforementioned cases we'd just inform the user that they need to run the question first before sandboxing it.

Once we do this, we should replace [these tests](https://github.com/metabase/metabase/blob/86ff88a/e2e/test/scenarios/permissions/sandboxes.cy.spec.js#L591-L606).
We'd probably need 2 new tests:
- one that asserts if POST `/api/mt/gtap` throws an error when question has not been run and that this error is shown to the user
- one that asserts everything works when the question has been run (basically the ""workaround"" version)




### To Reproduce

1. Run [this test](https://github.com/metabase/metabase/blob/86ff88a/e2e/test/scenarios/permissions/sandboxes.cy.spec.js#L591-L606) - the ""normal"" version


### Information about your Metabase installation

master, 6bf6a5de38

### Severity

P3
",kamilmielnik,2024-11-07 12:56:31+00:00,['noahmoss'],2025-02-04 20:24:05+00:00,,https://github.com/metabase/metabase/issues/49671,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2479764868, 'issue_id': 2640944498, 'author': 'noahmoss', 'body': ""@kamilmielnik FYI I've fixed the underlying issue on the backend in https://github.com/metabase/metabase/pull/50049 and re-enabled the Cypress test in question. So I think this can be closed once that merges. Let me know if you have any concerns."", 'created_at': datetime.datetime(2024, 11, 15, 19, 22, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482312976, 'issue_id': 2640944498, 'author': 'kamilmielnik', 'body': ""> [@kamilmielnik](https://github.com/kamilmielnik) FYI I've fixed the underlying issue on the backend in [#50049](https://github.com/metabase/metabase/pull/50049) and re-enabled the Cypress test in question. So I think this can be closed once that merges. Let me know if you have any concerns.\n\n@noahmoss Suggested solution was to present user with an error when they're trying to use this endpoint without running the question first.\nI don't see a test for that in #50049 - let's add it and I think we're good to close this issue.\n\n> We'd probably need 2 new tests:\n> - one that asserts if POST /api/mt/gtap throws an error when question has not been run and that this error is shown to the user"", 'created_at': datetime.datetime(2024, 11, 18, 8, 52, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483371065, 'issue_id': 2640944498, 'author': 'noahmoss', 'body': ""@kamilmielnik To clarify —\xa0I fixed the underlying issue, so that a sandbox based on a question that hasn't been run will not error. So the test you're describing is no longer relevant, I believe.\n\nI'll go ahead and close this. Let me know if I'm misunderstanding anything."", 'created_at': datetime.datetime(2024, 11, 18, 15, 26, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484899400, 'issue_id': 2640944498, 'author': 'kamilmielnik', 'body': '> [@kamilmielnik](https://github.com/kamilmielnik) To clarify —\xa0I fixed the underlying issue, so that a sandbox based on a question that hasn\'t been run will not error. So the test you\'re describing is no longer relevant, I believe.\n\nThat test had 2 versions: ""normal"" and ""workaround"".\nThe ""workaround"" version was always passing (because it explicitly run the question).\nThe ""normal"" version was the actual repro.\n\nI see in #50049 the ""normal"" version was removed and ""workaround"" was left.\n@noahmoss instead we should have kept the e2e test version which does not explicitly run the question.', 'created_at': datetime.datetime(2024, 11, 19, 7, 34, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486102336, 'issue_id': 2640944498, 'author': 'noahmoss', 'body': ""@kamilmielnik Got it, thanks for clarifying. I must have misread the test. \n\nI've tried removing the `runQuestion` calls in this PR https://github.com/metabase/metabase/pull/50218 but I'm seeing the test fail, specifically when [this line](https://github.com/metabase/metabase/pull/50218/files#diff-1d393e7cf61b793bb98924140ca7ae067add9229432d9c24fb182cd3c90b146bL607) is removed. It's a weird failure though —\xa0the sandboxed query results are correct, but Cypress isn't able to click on `View details` to open the object details: \n![Image](https://github.com/user-attachments/assets/f5bd830f-2781-4781-95d8-2d1309a808ed)\n\nDo you have any idea why this would be? I'm wondering if this is a quirk of Cypress rather than an actual issue in the app, since I can't reproduce this outside of Cypress."", 'created_at': datetime.datetime(2024, 11, 19, 15, 55, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486857965, 'issue_id': 2640944498, 'author': 'noahmoss', 'body': 'Actually, it seems like an unrelated issue from sandoxing? I see this error on the FE every time you try to click ""View details"": `No method in multimethod \'metabase.lib.query/query-method\' for dispatch value: :dispatch-type/nil`', 'created_at': datetime.datetime(2024, 11, 19, 22, 12, 18, tzinfo=datetime.timezone.utc)}]","noahmoss (Assginee) on (2024-11-15 19:22:22 UTC): @kamilmielnik FYI I've fixed the underlying issue on the backend in https://github.com/metabase/metabase/pull/50049 and re-enabled the Cypress test in question. So I think this can be closed once that merges. Let me know if you have any concerns.

kamilmielnik (Issue Creator) on (2024-11-18 08:52:47 UTC): @noahmoss Suggested solution was to present user with an error when they're trying to use this endpoint without running the question first.
I don't see a test for that in #50049 - let's add it and I think we're good to close this issue.

noahmoss (Assginee) on (2024-11-18 15:26:01 UTC): @kamilmielnik To clarify — I fixed the underlying issue, so that a sandbox based on a question that hasn't been run will not error. So the test you're describing is no longer relevant, I believe.

I'll go ahead and close this. Let me know if I'm misunderstanding anything.

kamilmielnik (Issue Creator) on (2024-11-19 07:34:58 UTC): That test had 2 versions: ""normal"" and ""workaround"".
The ""workaround"" version was always passing (because it explicitly run the question).
The ""normal"" version was the actual repro.

I see in #50049 the ""normal"" version was removed and ""workaround"" was left.
@noahmoss instead we should have kept the e2e test version which does not explicitly run the question.

noahmoss (Assginee) on (2024-11-19 15:55:10 UTC): @kamilmielnik Got it, thanks for clarifying. I must have misread the test. 

I've tried removing the `runQuestion` calls in this PR https://github.com/metabase/metabase/pull/50218 but I'm seeing the test fail, specifically when [this line](https://github.com/metabase/metabase/pull/50218/files#diff-1d393e7cf61b793bb98924140ca7ae067add9229432d9c24fb182cd3c90b146bL607) is removed. It's a weird failure though — the sandboxed query results are correct, but Cypress isn't able to click on `View details` to open the object details: 
![Image](https://github.com/user-attachments/assets/f5bd830f-2781-4781-95d8-2d1309a808ed)

Do you have any idea why this would be? I'm wondering if this is a quirk of Cypress rather than an actual issue in the app, since I can't reproduce this outside of Cypress.

noahmoss (Assginee) on (2024-11-19 22:12:18 UTC): Actually, it seems like an unrelated issue from sandoxing? I see this error on the FE every time you try to click ""View details"": `No method in multimethod 'metabase.lib.query/query-method' for dispatch value: :dispatch-type/nil`

"
2640903159,issue,open,,"Metabase Cloud failing to properly close SSH tunnels, leading to gradual memory leak on the bastion host","**Describe the bug**
Metabase Cloud seems to have an issue with effectively closing inactive SSH tunnels when new ones are opened. This leads to a gradual accumulation of total SSH connections over time, causing a steady increase in memory usage on the bastion host.

**Logs**
I have attached a graph showing the memory consumption on the bastion host over several weeks. The graph indicates that even though the connections are sometimes closed (sharp drops in memory usage), the issue persists, and eventually, I found over 100 SSH connections from Metabase's IP address.

**Expected behavior**
I would expect Metabase Cloud to properly manage and close SSH tunnels when they are no longer in use, preventing the accumulation of connections and the associated memory usage.

**Screenshots**
![Image](https://github.com/user-attachments/assets/5b56df89-276d-4bd7-913c-fd696e90c55a)

**Severity**
This is quite severe, as it is gradually causing the bastion host to run out of memory.

**Additional Context**
This may be relevant #24445.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""starter"",
    ""version"": {
      ""date"": ""2024-10-15"",
      ""tag"": ""v1.50.30"",
      ""hash"": ""a49cb77""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}
```",justin-lau,2024-11-07 12:37:37+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/49670,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2462404891, 'issue_id': 2640903159, 'author': 'paoliniluis', 'body': ""P1'ish IMHO"", 'created_at': datetime.datetime(2024, 11, 7, 14, 40, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470632414, 'issue_id': 2640903159, 'author': 'justin-lau', 'body': 'FWIW, here’s my temporary workaround. I run it as an hourly cron job to purge any Metabase connections that have been open for 24 hours or more, which effectively prevents my bastion hosts from running out of memory.\n\n```bash\n#!/bin/bash\n\n# List of Metabase public IP addresses\n# https://www.metabase.com/docs/latest/cloud/ip-addresses-to-whitelist\nIP_LIST=(""18.207.81.126"" ""3.211.20.157"" ""50.17.234.169"")\n\n# Set the connection timeout in seconds (24 hours)\nCONNECTION_TIMEOUT=86400\n\n# Loop through each IP in the list\nfor IP in ""${IP_LIST[@]}""; do\n    # Find all SSH connection PIDs from this IP\n    PIDS=$(netstat -tnpa |  grep ""$IP"" | awk \'{print $7}\' | sed \'s/\\/.*//\')\n\n    # Loop through each PID\n    for PID in $PIDS; do\n        # Get the process\'s start time in seconds since the epoch\n        START_TIME=$(ps -p ""$PID"" -o etimes=)\n\n        # Check if process has been running for more than 24 hours (86400 seconds)\n        if [ ""$START_TIME"" -gt ""$CONNECTION_TIMEOUT"" ]; then\n            echo ""Killing process $PID from Metabase IP $IP (running for more than $CONNECTION_TIMEOUT seconds)""\n            kill -9 ""$PID""\n        fi\n    done\ndone\n```', 'created_at': datetime.datetime(2024, 11, 12, 14, 8, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486733197, 'issue_id': 2640903159, 'author': 'perivamsi', 'body': '@justin-lau what is your metabase instance name?', 'created_at': datetime.datetime(2024, 11, 19, 20, 54, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488532009, 'issue_id': 2640903159, 'author': 'justin-lau', 'body': '> [@justin-lau](https://github.com/justin-lau) what is your metabase instance name?\n\nIt’s `moonshot-compost`.', 'created_at': datetime.datetime(2024, 11, 20, 13, 4, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488881273, 'issue_id': 2640903159, 'author': 'imrkd', 'body': ""@justin-lau can you check the configuration of your bastion host's sshd (/etc/ssh/sshd_config) and confirm whether you have `ClientAliveInterval`, `ServerAliveInterval` or `ClientAliveCountMax` set, and if so what are the values?"", 'created_at': datetime.datetime(2024, 11, 20, 15, 26, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491541921, 'issue_id': 2640903159, 'author': 'justin-lau', 'body': ""> [@justin-lau](https://github.com/justin-lau) can you check the configuration of your bastion host's sshd (/etc/ssh/sshd_config) and confirm whether you have `ClientAliveInterval`, `ServerAliveInterval` or `ClientAliveCountMax` set, and if so what are the values?\n\nI have `ClientAliveInterval` and `ClientAliveCountMax` on the bastion host's sshd:\n\n```\nClientAliveInterval 300\nClientAliveCountMax 12\n```\n\nI believe `ServerAliveInterval` is a client side configuration. I have it configured to 180 on my ssh client when I connect to the bastion host from my Macbook. It's working perfectly. Also, without this `ServerAliveInterval`, idle connections are terminated as expected."", 'created_at': datetime.datetime(2024, 11, 21, 15, 28, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2497664301, 'issue_id': 2640903159, 'author': 'perivamsi', 'body': ""Moving this to P2 based on @alexander-yakushev's investigations"", 'created_at': datetime.datetime(2024, 11, 25, 10, 51, 22, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-07 14:40:04 UTC): P1'ish IMHO

justin-lau (Issue Creator) on (2024-11-12 14:08:27 UTC): FWIW, here’s my temporary workaround. I run it as an hourly cron job to purge any Metabase connections that have been open for 24 hours or more, which effectively prevents my bastion hosts from running out of memory.

```bash
#!/bin/bash

# List of Metabase public IP addresses
# https://www.metabase.com/docs/latest/cloud/ip-addresses-to-whitelist
IP_LIST=(""18.207.81.126"" ""3.211.20.157"" ""50.17.234.169"")

# Set the connection timeout in seconds (24 hours)
CONNECTION_TIMEOUT=86400

# Loop through each IP in the list
for IP in ""${IP_LIST[@]}""; do
    # Find all SSH connection PIDs from this IP
    PIDS=$(netstat -tnpa |  grep ""$IP"" | awk '{print $7}' | sed 's/\/.*//')

    # Loop through each PID
    for PID in $PIDS; do
        # Get the process's start time in seconds since the epoch
        START_TIME=$(ps -p ""$PID"" -o etimes=)

        # Check if process has been running for more than 24 hours (86400 seconds)
        if [ ""$START_TIME"" -gt ""$CONNECTION_TIMEOUT"" ]; then
            echo ""Killing process $PID from Metabase IP $IP (running for more than $CONNECTION_TIMEOUT seconds)""
            kill -9 ""$PID""
        fi
    done
done
```

perivamsi on (2024-11-19 20:54:42 UTC): @justin-lau what is your metabase instance name?

justin-lau (Issue Creator) on (2024-11-20 13:04:04 UTC): It’s `moonshot-compost`.

imrkd on (2024-11-20 15:26:20 UTC): @justin-lau can you check the configuration of your bastion host's sshd (/etc/ssh/sshd_config) and confirm whether you have `ClientAliveInterval`, `ServerAliveInterval` or `ClientAliveCountMax` set, and if so what are the values?

justin-lau (Issue Creator) on (2024-11-21 15:28:36 UTC): I have `ClientAliveInterval` and `ClientAliveCountMax` on the bastion host's sshd:

```
ClientAliveInterval 300
ClientAliveCountMax 12
```

I believe `ServerAliveInterval` is a client side configuration. I have it configured to 180 on my ssh client when I connect to the bastion host from my Macbook. It's working perfectly. Also, without this `ServerAliveInterval`, idle connections are terminated as expected.

perivamsi on (2024-11-25 10:51:22 UTC): Moving this to P2 based on @alexander-yakushev's investigations

"
2640861925,issue,closed,completed,Click behavior does not get removed when the destination card is deleted,"### Describe the bug

New Trash functionality doesn't remove click behaviour reference to deleted card. This might work on the frontend part even though the behaviour is strange but Serialization will fail in these cases

### To Reproduce

1. Go to New -> Question -> Sample DB -> Orders -> Save as Question 1
2. Go to New -> Question -> Sample DB -> Products -> Save as Question 2
3. Add both to a dashboard:

![Image](https://github.com/user-attachments/assets/2945619a-bef1-4fdc-84f4-b6f684e7a391)

4. Setup Click behaviour on Question 1 to go to Question 2

![Image](https://github.com/user-attachments/assets/35ea9db8-2264-4a94-9d1f-c6037ae76eb3)

5. Now go to Question 2 -> Archive it (or as we call it now - Move to trash) ... Notice the changes that happen int he dashboard. The Question gets removed as well (so far so good)

![Image](https://github.com/user-attachments/assets/53cb4d7d-0058-439f-8a25-41c04aa86b5f)

6. When you click on the Click behaviour it still takes you to the archive (not sure if it's by design):

![Image](https://github.com/user-attachments/assets/806a10a9-9bab-4238-ac4d-f7282eb2a82e)

7. Now go back to that archived question and delete it permanently. Nothing changes on the dashboard which is good but now try to click on Question 1 Click behaviour and the click behviour redirects you to Question 1 and if you check the settings it shows Not Found:

![Image](https://github.com/user-attachments/assets/26340631-5f65-4f82-8e8c-6347d63aff77)

NOW THIS IS THE PROBLEM I AM SEEING WITH THIS. If you check the Database. report_dashbaordcard you will notice the click behaviour still points to card 213 but that card doesn't exist anymore

![Image](https://github.com/user-attachments/assets/9e4b751b-e59a-4c63-8777-558268af0998)

The main problem would be around serialization cause the frontend seems to have away to handle this even though it's kind of buggy (instead of just removing the reference on all click behaviour) it redirects to the same question when the question on click behaviour is not Found. But Serailization will fail cause these references don't exist anymore

![Image](https://github.com/user-attachments/assets/3211b24b-e59f-4b66-998e-826251b9aff9)

to get the logs above you need to pass the `?full_stacktrace=true` else they wound show up and the serialization will just fail

### Expected behavior

Not sure but when we permanently delete a Question we should completely delete every reference there is to it

### Logs

_No response_

### Information about your Metabase installation

51

### Severity

Not sure of the severity right now but this flow can make serialization hard to work with

### Additional context

_No response_",Tony-metabase,2024-11-07 12:19:32+00:00,[],2024-11-21 14:09:30+00:00,2024-11-21 13:23:08+00:00,https://github.com/metabase/metabase/issues/49667,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Organization/Collections', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2464793802, 'issue_id': 2640861925, 'author': 'luizarakaki', 'body': ""[Discussion here](https://metaboat.slack.com/archives/CEM835PJP/p1730982280283309)\n\nWe should remove click_behavior references when deleting a card.\nIf a card is permanently deleted, it shouldn't have references elsewhere, including dashboardcard click behavior.\n\nThis will resolve the Serialization and other inconsistency symptoms"", 'created_at': datetime.datetime(2024, 11, 8, 13, 40, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479820034, 'issue_id': 2640861925, 'author': 'johnswanson', 'body': ""Two notes: first, unfortunately, it seems like this might be the tip of an iceberg: it seems that serialization has quite a few places where we're serializing entities that may no longer exist. This is one example, but another would be if Card A uses Card B as a data source, and then Card B is deleted - that triggers exactly the same issue.\n\nSecond, while the existence of the Trash has made it easier/more common to delete cards or dashboards, this bug actually predates the Trash - I've verified that it happens on v49 as well. I'm not sure if this should be a cloud blocker given that - although, if this was a rare bug before and the Trash makes it a more common bug (because no one went to the archive and permanently deleted items?) then I can see it being a blocker. @Tony-metabase what do you think?"", 'created_at': datetime.datetime(2024, 11, 15, 19, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480447278, 'issue_id': 2640861925, 'author': 'Tony-metabase', 'body': ""@johnswanson indeed! This is pre-exists 51 and we have other bad references throughout our Database like:\n\nhttps://github.com/metabase/metabase/issues/49832\n\nWhat concerns me the most is that yes I feel it's much easier to hit due to the new Trash Feature (especially because of Step 6 above) ... I could be wrong here and it could be just some stupid feeling I have. We can remove it from a blocker and see how it goes since as you said it has been there before 51 and the fact that Trash makes it easier to hit doesn't mean it will become common to hit.\n\nI know this is very hard to fix at Metabase level, even due to the way these bad references are stored. Not sure how easy/hard it is to  check what the reference is during serialization and if it's an archived card then just remove the reference? Instead of completely getting rid of the bad reference at Application Level?"", 'created_at': datetime.datetime(2024, 11, 16, 6, 21, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481330507, 'issue_id': 2640861925, 'author': 'perivamsi', 'body': 'I propose we keep this as a P1 but remove the cloud-blocker tag since this issue has been existing since before and I am not convinced that the trash feature makes it any worse.', 'created_at': datetime.datetime(2024, 11, 17, 16, 1, 27, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-11-08 13:40:11 UTC): [Discussion here](https://metaboat.slack.com/archives/CEM835PJP/p1730982280283309)

We should remove click_behavior references when deleting a card.
If a card is permanently deleted, it shouldn't have references elsewhere, including dashboardcard click behavior.

This will resolve the Serialization and other inconsistency symptoms

johnswanson on (2024-11-15 19:55:43 UTC): Two notes: first, unfortunately, it seems like this might be the tip of an iceberg: it seems that serialization has quite a few places where we're serializing entities that may no longer exist. This is one example, but another would be if Card A uses Card B as a data source, and then Card B is deleted - that triggers exactly the same issue.

Second, while the existence of the Trash has made it easier/more common to delete cards or dashboards, this bug actually predates the Trash - I've verified that it happens on v49 as well. I'm not sure if this should be a cloud blocker given that - although, if this was a rare bug before and the Trash makes it a more common bug (because no one went to the archive and permanently deleted items?) then I can see it being a blocker. @Tony-metabase what do you think?

Tony-metabase (Issue Creator) on (2024-11-16 06:21:35 UTC): @johnswanson indeed! This is pre-exists 51 and we have other bad references throughout our Database like:

https://github.com/metabase/metabase/issues/49832

What concerns me the most is that yes I feel it's much easier to hit due to the new Trash Feature (especially because of Step 6 above) ... I could be wrong here and it could be just some stupid feeling I have. We can remove it from a blocker and see how it goes since as you said it has been there before 51 and the fact that Trash makes it easier to hit doesn't mean it will become common to hit.

I know this is very hard to fix at Metabase level, even due to the way these bad references are stored. Not sure how easy/hard it is to  check what the reference is during serialization and if it's an archived card then just remove the reference? Instead of completely getting rid of the bad reference at Application Level?

perivamsi on (2024-11-17 16:01:27 UTC): I propose we keep this as a P1 but remove the cloud-blocker tag since this issue has been existing since before and I am not convinced that the trash feature makes it any worse.

"
2640630492,issue,closed,completed,Add browser details in the JSON to display along with system info,"Adding web browser information would be helpful in case of bug reports about frontend-centric issues.
We should add it to the reported JSON file and make room for it in the ""system information"" section here: 
![Image](https://github.com/user-attachments/assets/40fe9d4a-5c86-4bcc-a164-3a9b90b20891)
",thebiglabasky,2024-11-07 10:47:23+00:00,['filiphric'],2024-12-12 14:22:49+00:00,2024-12-12 14:22:49+00:00,https://github.com/metabase/metabase/issues/49664,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Reporter', '')]",[],
2640618268,issue,closed,completed,Adapt system info to the new JSON format,This is mostly about adapting the existing log viewer from https://metabase-debugger.vercel.app/ to the new JSON format.,thebiglabasky,2024-11-07 10:42:45+00:00,['filiphric'],2024-11-28 21:11:09+00:00,2024-11-28 21:11:09+00:00,https://github.com/metabase/metabase/issues/49663,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Debugger', '')]",[],
2640567625,issue,open,,Timeseries Chart Scale skips to the next month showing confusing results,"### Describe the bug

Easier to see than to explain. This is the data as a Table:

![Image](https://github.com/user-attachments/assets/eddc5475-d406-485a-a1a0-5b441ad70990)

This is the Data as a bar chart with Ordinal Scale:

![Image](https://github.com/user-attachments/assets/f1913fbf-8c5a-4959-b24e-7740d100e4ce)

This is the Data as a bar chart with Timeseries Scale:

![Image](https://github.com/user-attachments/assets/a2f61595-dd94-4860-8ba7-fbe91b9f55d6)



### To Reproduce

I am using Postgres but you can checkout this [question on stats](https://stats.metabase.com/question/20453-timeseries-confusing-chart)
 
1. Go to New -> SQL Question -> Run the below:

```
Select TO_DATE('30/06/2015', 'DD/MM/YYYY') AS date, 5555 AS value
UNION
Select TO_DATE('30/09/2015', 'DD/MM/YYYY') AS date, 6555 AS value
```

2. Visualise as a Bar chart and set the Scale to a Timeseries, notice the actual Data doesn't match with the chart:

![Image](https://github.com/user-attachments/assets/e3bd3aef-9e9f-410b-b8e0-b478a6da1cfa)

![Image](https://github.com/user-attachments/assets/d673ef4f-ec40-4c88-8fb0-30f0591ed9ff)


### Expected behavior

The Timeseries scale matches what you get in the chart. So my expectation would be to get a June Bar and a July, August empty bars then a September Bar. Something like the below when you change the Date from 30th to 14th

![Image](https://github.com/user-attachments/assets/668396cc-798c-4a46-8f0a-b69c37664ecd)


### Logs

None that are relevant

### Information about your Metabase installation

Happens both on 50 and 51

### Severity

Might look like a cosmetic bug but when you hit this you don't understand what is going on

### Additional context

_No response_",Tony-metabase,2024-11-07 10:29:49+00:00,[],2025-02-04 20:31:22+00:00,,https://github.com/metabase/metabase/issues/49662,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2640398379,issue,closed,not_planned,Some tables in Mongo are not synching,"**Describe the bug**
A clear and concise description of what the bug is.

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""mongo""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v0.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-119-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",pradeepkakarlapudi,2024-11-07 09:29:02+00:00,[],2024-11-08 03:12:57+00:00,2024-11-08 03:12:56+00:00,https://github.com/metabase/metabase/issues/49658,[],"[{'comment_id': 2463673234, 'issue_id': 2640398379, 'author': 'paoliniluis', 'body': ""we can't reproduce without steps or logs"", 'created_at': datetime.datetime(2024, 11, 8, 3, 12, 56, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-08 03:12:56 UTC): we can't reproduce without steps or logs

"
2640366081,issue,closed,not_planned,Performance: static embedding - Lighten app/dist/vendor.XXX.js file - 1.4MB,"### Describe the bug

For static embedding on a website the JS assets' (pp/dist/vendor.XXX.js ) size is 5.66 MB and Gzipped is 1.43MB.

Would it be possible to configure what to use or not to lighten the final size ?


### To Reproduce

1. Go to a static embedded dashboard
2. Inspect JS assets size



### Expected behavior

Possible to have a light JS assets  with less options (core only mode)

### Logs

_No response_

### Information about your Metabase installation

Metabase 0.50.28

### Severity

low

### Additional context

_No response_",polomarcus,2024-11-07 09:14:04+00:00,[],2024-11-07 14:52:53+00:00,2024-11-07 14:52:53+00:00,https://github.com/metabase/metabase/issues/49657,"[('Type:New Feature', ''), ('.Needs Triage', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2461800800, 'issue_id': 2640366081, 'author': 'albertoperdomo', 'body': 'Hello @polomarcus,\n\nis this for static embedding or interactive embedding?', 'created_at': datetime.datetime(2024, 11, 7, 9, 59, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461823539, 'issue_id': 2640366081, 'author': 'polomarcus', 'body': 'Hi @albertoperdomo \n\nFor static embedding, just updated my issue.\n\nThanks ✨', 'created_at': datetime.datetime(2024, 11, 7, 10, 8, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462429049, 'issue_id': 2640366081, 'author': 'paoliniluis', 'body': 'related, if not the same as https://github.com/metabase/metabase/issues/33220', 'created_at': datetime.datetime(2024, 11, 7, 14, 49, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462436526, 'issue_id': 2640366081, 'author': 'paoliniluis', 'body': 'https://github.com/metabase/metabase/issues/4665', 'created_at': datetime.datetime(2024, 11, 7, 14, 52, 42, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-11-07 09:59:36 UTC): Hello @polomarcus,

is this for static embedding or interactive embedding?

polomarcus (Issue Creator) on (2024-11-07 10:08:56 UTC): Hi @albertoperdomo 

For static embedding, just updated my issue.

Thanks ✨

paoliniluis on (2024-11-07 14:49:53 UTC): related, if not the same as https://github.com/metabase/metabase/issues/33220

paoliniluis on (2024-11-07 14:52:42 UTC): https://github.com/metabase/metabase/issues/4665

"
2640342878,issue,open,,[Task] Remove dependencies that we don't need in the package.json of the sdk,"**Context**
https://metaboat.slack.com/archives/C063Q3F1HPF/p1730969278072639?thread_ts=1730968803.487599&cid=C063Q3F1HPF

At the moment we bundle all of the dependencies in the bundle, but we also list them as dependencies in the sdk package.json.

Unless we dynamically `require` the packages, we should be able to remove them from the package.json with the added benefits that:
- the install time/size of sdk users should go down as they don't install extra deps not used
- we should remove a lot of warnings about deps from the output of customers trying out the sdk



",npretto,2024-11-07 09:03:07+00:00,[],2025-02-04 20:25:58+00:00,,https://github.com/metabase/metabase/issues/49655,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2473066947, 'issue_id': 2640342878, 'author': 'npretto', 'body': ""~Would help with [[Task] Remove dependencies that we don't need in the package.json of the sdk](https://github.com/metabase/metabase/issues/49655)~\n\nedit: i have no idea what I wanted to link to, but definitely not to this same issue"", 'created_at': datetime.datetime(2024, 11, 13, 10, 8, 44, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-11-13 10:08:44 UTC): ~Would help with [[Task] Remove dependencies that we don't need in the package.json of the sdk](https://github.com/metabase/metabase/issues/49655)~

edit: i have no idea what I wanted to link to, but definitely not to this same issue

"
2640240214,issue,closed,completed,Generated CLI component has inconsistent styles after the style leak fix,"The components generated from the Embedding CLI currently has incorrect/inconsistent styles, which is caused by the styling changes from the style leak fix. We should fix the generated components.",heypoom,2024-11-07 08:22:27+00:00,['heypoom'],2024-11-08 15:14:21+00:00,2024-11-08 14:30:18+00:00,https://github.com/metabase/metabase/issues/49652,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2639876414,issue,open,,"[Notification] We shouldn't retry sending slack if it has error ""channel_not_found""","### Describe the bug

When sending notifications to a slack channel that's no longer exists, we keep retrying until the retry attempts are maxed-out.
The retry mechanism includes uploading the assets and posting the message.

This is necessary, we should stop sending the channel at the first attempt and have the task_history.status = failed.

### To Reproduce

1. On slack: create a channel ""testing-alert"" 
2. On metabase: Setup slack connection
3. Create an alert that send to ""testing-alert"" channel
4. Delete the ""testing-alert"" channel
5. Trigger sending the ""alert""

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

master

### Severity

p3

### Additional context

_No response_",qnkhuat,2024-11-07 04:54:27+00:00,[],2025-02-04 20:26:25+00:00,,https://github.com/metabase/metabase/issues/49647,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Difficulty:Easy', ''), ('.Backend', ''), ('Notifications/Slack', ''), (':broom:', 'no-brainer cleanup issues to clear out when you have an hour left until EoD or something'), ('.Team/Workflows', 'aka BEC'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2623468889, 'issue_id': 2639876414, 'author': 'harrylewis', 'body': ""Hey @qnkhuat 👋🏻 \n\nI'm new to the codebase and was trying to figure out where in the code this would require changes. Would it be in this file?\n\nhttps://github.com/metabase/metabase/blob/cd209344c6175fbd8bb9b4b5a9ac5565d96f420e/src/metabase/notification/send.clj#L53-L56"", 'created_at': datetime.datetime(2025, 1, 30, 4, 3, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2629790090, 'issue_id': 2639876414, 'author': 'qnkhuat', 'body': 'hey @harrylewis, `metabase.notification.send` is where we decide what to do with the error from each channel. you also need to look at https://github.com/metabase/metabase/blob/e2fd234cc27e568016bdff03561fa328664040d3/src/metabase/integrations/slack.clj#L118 , this is where we classify errors from slack.', 'created_at': datetime.datetime(2025, 2, 3, 3, 2, 34, tzinfo=datetime.timezone.utc)}]","harrylewis on (2025-01-30 04:03:27 UTC): Hey @qnkhuat 👋🏻 

I'm new to the codebase and was trying to figure out where in the code this would require changes. Would it be in this file?

https://github.com/metabase/metabase/blob/cd209344c6175fbd8bb9b4b5a9ac5565d96f420e/src/metabase/notification/send.clj#L53-L56

qnkhuat (Issue Creator) on (2025-02-03 03:02:34 UTC): hey @harrylewis, `metabase.notification.send` is where we decide what to do with the error from each channel. you also need to look at https://github.com/metabase/metabase/blob/e2fd234cc27e568016bdff03561fa328664040d3/src/metabase/integrations/slack.clj#L118 , this is where we classify errors from slack.

"
2639749327,issue,open,,MongoDB join perf optimization,"### Describe the bug

The way Metabase creates aggregation queries around filters + joins could be optimized quite a bit.

In particular, it's adding the $lookup + $unwind before the $match, even if the $match only applies to the initial collection.

This means that if the collections you're joining have millions of documents, but your match filters down to just 100 documents, Metabase asks MongoDB to fetch and join millions of documents before filtering down. Instead it could just fetch the 100 that actually matter, and then join.

### To Reproduce

1. Create a new question
2. Join with one or more other collections
3. Add a filter on the initial collection
4. Aggregation query will be:

```
$lookup + $unwind: ... (join)
$match: ... (filter)
```


### Expected behavior

Aggregation query should be:

```
$match: ... (filter)
$lookup + $unwind: ... (join)
```

### Logs

_No response_

### Information about your Metabase installation

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-LTS"",
    ""java.vendor"": ""Red Hat, Inc."",
    ""java.vendor.url"": ""https://www.redhat.com/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.348-265.565.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-30"",
      ""tag"": ""v0.50.18"",
      ""hash"": ""c323ffc""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```

### Severity

annoying, but workaround available (rewrite queries manually)

### Additional context

Obviously if you are filtering on one of the joined collections the logic is a bit more complicated, but there's still significant optimization to be had... Let's say you join A → B and then B → C and filter on B... In that case it should:

```
$lookup + $unwind (join A to B)
$match (filter on B)
$lookup + $unwind (join B to C)
```

Instead it currently does:

```
$lookup + $unwind (join A to B)
$lookup + $unwind (join B to C)
$match (filter on B)
```",arasmussen,2024-11-07 03:25:18+00:00,[],2025-02-04 20:30:59+00:00,,https://github.com/metabase/metabase/issues/49643,"[('Database/Mongo', None), ('.Performance', ''), ('Type:New Feature', ''), ('.Team/Drivers', '')]",[],
2639748594,issue,closed,completed,The dropdown list cannot search for models with more than 1000 results when I upgrade from v0.51.1.8 to v0.51.2,"### Describe the bug

when I upgrade from v0.51.1.8 to v0.51.2, If I have a dropdown list of over 1000 results as a filter, I will only be able to search for the values of the first 1000 results, and when searching for other values, it will display 'Didn't find anything'

### To Reproduce

1. Create a model from a database with over 1000 results
2. Create any table and use it as dashboard content
3. Add a filter for a text type dropdown list in the dashboard
4. Try searching for content in the dashboard filter, only the first 1000 results from the drop-down list can be found

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-06"",
      ""tag"": ""v0.51.2.2"",
      ""hash"": ""1d5dd2c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-25-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

This bug is blocking our usage of Metabase entirely, preventing us from accessing critical data and completing essential tasks.

### Additional context

_No response_",lssdo12,2024-11-07 03:24:33+00:00,['romeovs'],2024-11-25 22:11:45+00:00,2024-11-21 04:53:32+00:00,https://github.com/metabase/metabase/issues/49642,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]",[],
2639640991,issue,closed,not_planned,[BUG] using filter 'month & year' in dashboard missing last 1 day of month.,"**Describe the bug**

using filter 'month & year' in dashboard missing last 1 day of month. 

![Image](https://github.com/user-attachments/assets/44889480-7872-4ded-ba32-5fb663044b0f)

E.g.: pick ' Oct - 2024 ' then the table just add filter maybe `datetime > 2024-10-01T00:00:00 and datetime < 2024-10-31T00:00:00` I guess.

![Image](https://github.com/user-attachments/assets/863e053e-d928-4830-84df-27953e3f3118)

Then. the table on this dasboard only show 30 days (missing last 1day).

![Image](https://github.com/user-attachments/assets/376cb8a6-2b1c-4661-b708-cb925892b20d)

**To Reproduce**
Steps to reproduce the behavior:
1. create any of date list table.
2. add table to a dashboard.
3. add a 'month & year' filter to this dashboard.
4. pick a month and last 1day missing at table.

**Expected behavior**

A clear and concise description of what you expected to happen.

**Screenshots**

maybe `datetime > 2024-10-01T00:00:00 and datetime < 2024-10-31T00:00:00` in fitler ??

maybe should fix to be `<= month range2` or `< dateAdd([range1], '+1', 'month')` I think... 🤔

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""oracle""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""tag"": ""v0.51.2"",
      ""hash"": ""8bdb22c""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Shanghai""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""17.0 (Debian 17.0-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.18.0-553.22.1.el8_10.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Shanghai""
  }
}
```",evil7,2024-11-07 02:02:13+00:00,[],2024-11-19 18:15:38+00:00,2024-11-19 18:15:13+00:00,https://github.com/metabase/metabase/issues/49641,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Correctness', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 2477882633, 'issue_id': 2639640991, 'author': 'evil7', 'body': ""when I trying filter `Year and Month` or `this month` / `this week` / `Today` for testing. I found this `query` log of web response json:\n\n```sql\n-- E.g: filter today\nWHERE\n    ( xxx_some_user_filter_xxxx )\n    AND ( 'source'.'REGISTER_TIME' = TRUNC(CURRENT_TIMESTAMP, 'dd') )\n```\n\nBut in this main model. I have checking it's already set the `REGISTER_TIME` type to `Creation timestamp` it should be `date + time` type.\n\nSo the `TRUNC(CURRENT_TIMESTAMP, 'dd')` will be `yyyy-mm-dd 00:00:00` and the `REGISTER_TIME` will be `yyyy-mm-dd hh24:mm:ss` so it's will never be same.\n\nI think maybe this dashboard filter should be fix like:\n\n```sql\n-- trunc both side to fix\nAND ( TRUNC(source.REGISTER_TIME, 'dd') = TRUNC(CURRENT_TIMESTAMP, 'dd') )\n```\n\nthen it will work fine will my tests.\n\n## my test\n\n```sql\n-- oracle 11g\nWITH\n  source AS (\n    SELECT\n      (TRUNC(SYSDATE) + DBMS_RANDOM.VALUE (0, 1)) AS REGISTER_TIME\n    FROM\n      dual\n    CONNECT BY LEVEL <= 10\n  )\nSELECT\n  REGISTER_TIME,\n  TO_CHAR(REGISTER_TIME, 'yyyy-mm-dd hh24:mi:ss') AS register_time_to_char,\n  TO_CHAR(TRUNC(REGISTER_TIME, 'dd'), 'yyyy-mm-dd hh24:mi:ss') AS register_trunc_dd_to_char,\n  TO_CHAR(TRUNC(CURRENT_TIMESTAMP, 'dd'), 'yyyy-mm-dd hh24:mi:ss') AS filter_trunc_dd_to_char\nFROM\n  source\nWHERE\n--   source.REGISTER_TIME = TRUNC(CURRENT_TIMESTAMP, 'dd') -- the BUG happend here!\n  TRUNC(source.REGISTER_TIME, 'dd') = TRUNC(CURRENT_TIMESTAMP, 'dd')\n```\n\n![Image](https://github.com/user-attachments/assets/2897bf55-702f-4a4d-ad47-d2b5aacac19c)\n\n```sql\n-- postgresql 17\nWITH source AS (\n    SELECT\n        (CURRENT_DATE + INTERVAL '1 second' * FLOOR(RANDOM() * 86400)) AS register_time\n    FROM\n        generate_series(1, 10)\n)\nSELECT\n    register_time,\n    TO_CHAR(register_time, 'yyyy-mm-dd hh24:mi:ss') AS register_time_to_char,\n    TO_CHAR(DATE_TRUNC('day', register_time), 'yyyy-mm-dd hh24:mi:ss') AS register_trunc_dd_to_char,\n    TO_CHAR(DATE_TRUNC('day', CURRENT_TIMESTAMP), 'yyyy-mm-dd hh24:mi:ss') AS filter_trunc_dd_to_char\nFROM\n    source\nWHERE\n    -- source.register_time = DATE_TRUNC('day', CURRENT_TIMESTAMP) -- the BUG happend here!\n    DATE_TRUNC('day', source.register_time) = DATE_TRUNC('day', CURRENT_TIMESTAMP)\n```\n\n![Image](https://github.com/user-attachments/assets/435f1e93-dac4-42f4-a96b-a5ddeeaffbee)\n\nIt's both happend with oracle and postresql.\n\n## suggestion\n\nI think it should be modify for all filter of times. To keep left and right of filter can be same timestamp format.\ninclude `TRUNC('xxx', 'dd')` and `yyyy` or `mm` too and some others.\n\nAnd maybe we can have a option to show `datetime display format` with full `yyyy-mm-dd hh24:mi:ss` not like only show `yyyy-mm-dd` now.\n\nnow I need spend many time to add custom cols every times every where to convert all `datetime` to `char` or `Text` ot `Link`.\n\nhelp u good and plz fix this soon. 📅 ⛏"", 'created_at': datetime.datetime(2024, 11, 15, 3, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478136589, 'issue_id': 2639640991, 'author': 'evil7', 'body': 'I think can fix from 2 way:\n\n- keep `the_col` clean\n\n```sql\n( the_col >= TRUNC(CURRENT_TIMESTAMP, dd)\nAND the_col < TRUNC(CURRENT_TIMESTAMP, dd) + 1day )\n```\n\n- let both in same convert function\n\n```sql\n( TRUNC(the_col, dd) = TRUNC(CURRENT_TIMESTAMP, dd)\n```', 'created_at': datetime.datetime(2024, 11, 15, 7, 32, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486425669, 'issue_id': 2639640991, 'author': 'ranquild', 'body': 'https://github.com/metabase/metabase/issues/49641', 'created_at': datetime.datetime(2024, 11, 19, 18, 15, 36, tzinfo=datetime.timezone.utc)}]","evil7 (Issue Creator) on (2024-11-15 03:31:07 UTC): when I trying filter `Year and Month` or `this month` / `this week` / `Today` for testing. I found this `query` log of web response json:

```sql
-- E.g: filter today
WHERE
    ( xxx_some_user_filter_xxxx )
    AND ( 'source'.'REGISTER_TIME' = TRUNC(CURRENT_TIMESTAMP, 'dd') )
```

But in this main model. I have checking it's already set the `REGISTER_TIME` type to `Creation timestamp` it should be `date + time` type.

So the `TRUNC(CURRENT_TIMESTAMP, 'dd')` will be `yyyy-mm-dd 00:00:00` and the `REGISTER_TIME` will be `yyyy-mm-dd hh24:mm:ss` so it's will never be same.

I think maybe this dashboard filter should be fix like:

```sql
-- trunc both side to fix
AND ( TRUNC(source.REGISTER_TIME, 'dd') = TRUNC(CURRENT_TIMESTAMP, 'dd') )
```

then it will work fine will my tests.

## my test

```sql
-- oracle 11g
WITH
  source AS (
    SELECT
      (TRUNC(SYSDATE) + DBMS_RANDOM.VALUE (0, 1)) AS REGISTER_TIME
    FROM
      dual
    CONNECT BY LEVEL <= 10
  )
SELECT
  REGISTER_TIME,
  TO_CHAR(REGISTER_TIME, 'yyyy-mm-dd hh24:mi:ss') AS register_time_to_char,
  TO_CHAR(TRUNC(REGISTER_TIME, 'dd'), 'yyyy-mm-dd hh24:mi:ss') AS register_trunc_dd_to_char,
  TO_CHAR(TRUNC(CURRENT_TIMESTAMP, 'dd'), 'yyyy-mm-dd hh24:mi:ss') AS filter_trunc_dd_to_char
FROM
  source
WHERE
--   source.REGISTER_TIME = TRUNC(CURRENT_TIMESTAMP, 'dd') -- the BUG happend here!
  TRUNC(source.REGISTER_TIME, 'dd') = TRUNC(CURRENT_TIMESTAMP, 'dd')
```

![Image](https://github.com/user-attachments/assets/2897bf55-702f-4a4d-ad47-d2b5aacac19c)

```sql
-- postgresql 17
WITH source AS (
    SELECT
        (CURRENT_DATE + INTERVAL '1 second' * FLOOR(RANDOM() * 86400)) AS register_time
    FROM
        generate_series(1, 10)
)
SELECT
    register_time,
    TO_CHAR(register_time, 'yyyy-mm-dd hh24:mi:ss') AS register_time_to_char,
    TO_CHAR(DATE_TRUNC('day', register_time), 'yyyy-mm-dd hh24:mi:ss') AS register_trunc_dd_to_char,
    TO_CHAR(DATE_TRUNC('day', CURRENT_TIMESTAMP), 'yyyy-mm-dd hh24:mi:ss') AS filter_trunc_dd_to_char
FROM
    source
WHERE
    -- source.register_time = DATE_TRUNC('day', CURRENT_TIMESTAMP) -- the BUG happend here!
    DATE_TRUNC('day', source.register_time) = DATE_TRUNC('day', CURRENT_TIMESTAMP)
```

![Image](https://github.com/user-attachments/assets/435f1e93-dac4-42f4-a96b-a5ddeeaffbee)

It's both happend with oracle and postresql.

## suggestion

I think it should be modify for all filter of times. To keep left and right of filter can be same timestamp format.
include `TRUNC('xxx', 'dd')` and `yyyy` or `mm` too and some others.

And maybe we can have a option to show `datetime display format` with full `yyyy-mm-dd hh24:mi:ss` not like only show `yyyy-mm-dd` now.

now I need spend many time to add custom cols every times every where to convert all `datetime` to `char` or `Text` ot `Link`.

help u good and plz fix this soon. 📅 ⛏

evil7 (Issue Creator) on (2024-11-15 07:32:41 UTC): I think can fix from 2 way:

- keep `the_col` clean

```sql
( the_col >= TRUNC(CURRENT_TIMESTAMP, dd)
AND the_col < TRUNC(CURRENT_TIMESTAMP, dd) + 1day )
```

- let both in same convert function

```sql
( TRUNC(the_col, dd) = TRUNC(CURRENT_TIMESTAMP, dd)
```

ranquild on (2024-11-19 18:15:36 UTC): https://github.com/metabase/metabase/issues/49641

"
2639253656,issue,closed,duplicate,Ability to turn off Pop up messages,"**Is your feature request related to a problem? Please describe.**
Admins might want their users to see pop ups 

The ones i could find were:
![Image](https://github.com/user-attachments/assets/fe254039-a5d5-4fd6-bdea-ee6f6a84915c)

[You can make this dashboard snappier by turning off auto-applying filters
](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/dashboard/actions/parameters.ts#L717)
and 
   [This dashboard has been set as your homepage](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/home/components/CustomHomePageModal/CustomHomePageModal.tsx#L51C17-L51C62).

**Describe the solution you'd like**
Env var? That let's you disable this for an instance

**Describe alternatives you've considered**
N/a

**How important is this feature to you?**
Requested by a customer, internal ticket: [427](https://app.usepylon.com/issues?conversationID=1ed1e17e-406a-446e-9568-a827d159f961)

**Additional context**
N/A
",ignacio-mb,2024-11-06 21:19:52+00:00,[],2025-01-21 09:55:58+00:00,2025-01-21 09:55:57+00:00,https://github.com/metabase/metabase/issues/49633,"[('Type:New Feature', ''), ('Administration/Settings', ''), ('Operation/Environment variables', '')]","[{'comment_id': 2568173594, 'issue_id': 2639253656, 'author': 'brunobergher', 'body': 'Duplicate of #31336, no?', 'created_at': datetime.datetime(2025, 1, 2, 18, 11, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604215273, 'issue_id': 2639253656, 'author': 'ignacio-mb', 'body': 'Yes indeed. Sorry', 'created_at': datetime.datetime(2025, 1, 21, 9, 55, 58, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 18:11:11 UTC): Duplicate of #31336, no?

ignacio-mb (Issue Creator) on (2025-01-21 09:55:58 UTC): Yes indeed. Sorry

"
2639202430,issue,open,,Improve visualizations and dashboards resizing smoothness,"**Context**

[Slack convo](https://metaboat.slack.com/archives/C064QMXEV9N/p1730917441872909?thread_ts=1730911055.803239&cid=C064QMXEV9N)

When resizing visualizations in the QB or on dashboards we debounce rendering to avoid lagging rerenders. This was a bigger issue previously with dc.js because we rerendered charts entirely on every resize, however, with ECharts resizing is faster and we can enable it in the QB. Nevertheless, on dashboards with many cards it will still lag so there is an opportunity to optimize rendering of each viz type and add some smart logic which based on numer of cards and sizes of datasets will determine whether we can have smooth resizing without debounce.

- [ ] Enable smooth resizing in QB except for huge datasets
- [ ] Profile and optimize rendering of every viz type
- [ ] Enable smooth resizing in dashboards when it won't cause lags
",alxnddr,2024-11-06 20:51:43+00:00,[],2025-02-04 20:29:55+00:00,,https://github.com/metabase/metabase/issues/49632,"[('Visualization/', ''), ('.Performance', ''), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2639030935,issue,open,,Not displaying the full path on the search leads to users clicking on the wrong items,"### Describe the bug

Let's say you have the same name of collections in a deeply nested collection structure... when searching for an item in the search bar you might end up selecting the wrong item
![Image](https://github.com/user-attachments/assets/ba1ff24d-914b-4198-af0b-1fe212498776)

### To Reproduce

1) create a ""dataset"" collection inside our analytics
2) create a dataset collection inside your personal collection
3) create a people question and then save it in the first dataset collection with the ""people question"" name
4) duplicate the question, save it with the same ""people question"" name in the second dataset collection
5) try searching for ""people question"" in the search bar, which one would you pick?

### Expected behavior

we should show the full paths on the search bar when hovering over the collection name

### Logs

NA

### Information about your Metabase installation

-v50+

### Severity

P2

### Additional context

It's annoying",paoliniluis,2024-11-06 19:30:14+00:00,[],2025-02-04 20:30:32+00:00,,https://github.com/metabase/metabase/issues/49630,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2596269747, 'issue_id': 2639030935, 'author': 'luizarakaki', 'body': ""I agree with the request, but this is behaving as intended. I'm changing to feature request and assigning to this project [Help users understand and trust search results](https://www.notion.so/metabase/Help-users-understand-and-trust-search-results-15969354c901806f89e8c8fe77016410)"", 'created_at': datetime.datetime(2025, 1, 16, 17, 9, 24, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-16 17:09:24 UTC): I agree with the request, but this is behaving as intended. I'm changing to feature request and assigning to this project [Help users understand and trust search results](https://www.notion.so/metabase/Help-users-understand-and-trust-search-results-15969354c901806f89e8c8fe77016410)

"
2638995091,issue,open,,Update API for moderation review creation,"Now that we have statuses and expiration dates, we need some more constraints on the sorts of moderation reviews that are allowed.

1. If the status is ""verified"", then we must include an expiration_date.



## Open Questions: What's the difference between `nil` and `""neutral""` status",escherize,2024-11-06 19:16:49+00:00,[],2024-11-06 19:19:12+00:00,,https://github.com/metabase/metabase/issues/49628,[],[],
2638952184,issue,closed,completed,Faster sync on Snowflake,,snoe,2024-11-06 18:54:10+00:00,['snoe'],2025-01-20 20:59:42+00:00,2025-01-17 22:45:38+00:00,https://github.com/metabase/metabase/issues/49624,"[('.Team/Drivers', '')]",[],
2638897242,issue,open,,Bar & Row chart - Summarized tool tip values between bar charts and row chart can show different results,"### Describe the bug

Summarized tool tip values between bar charts and row chart can show different results.

### To Reproduce


![Image](https://github.com/user-attachments/assets/5cb713bf-e44a-474a-8270-159684309a70)


<br>
<br>

Bar chart series configuration
![Image](https://github.com/user-attachments/assets/e2e32cce-9c3f-44c9-85a8-5126b8a0446d)

<br>

Bar chart tooltip values
![Image](https://github.com/user-attachments/assets/fb4fc658-833f-41ed-9aa8-3ad69fa5942d)
<br>
![Image](https://github.com/user-attachments/assets/6ece59a1-b56b-45e8-bc6c-643c36b77e1d)

<br>
<br>

Row chart series configuration
![Image](https://github.com/user-attachments/assets/3134892b-6db6-4b42-a582-eff516a9cab2)

<br>

Row chart tooltip values
![Image](https://github.com/user-attachments/assets/3e076b3e-e384-4ddf-98a0-2d4122dd7704)
<br>
![Image](https://github.com/user-attachments/assets/07b8d937-ad3b-4dd8-91f8-916597d2b47e)







### Expected behavior

For tooltip values to be similar between both charts.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Chicago""
  }
}

### Severity

P2 - consistency

### Additional context

_No response_",FilmonK,2024-11-06 18:32:33+00:00,[],2025-02-04 20:31:19+00:00,,https://github.com/metabase/metabase/issues/49623,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2638875233,issue,closed,completed,Dropdowns in the notebook editor look weird in some cases,"### Describe the bug

1. When there is not enough space, text is moved to the next line inside a token.
![Image](https://github.com/user-attachments/assets/bae48b28-0a77-49b4-830c-093c7ec751e5)

2. When the fonts are custom the dropdown button has different height
![Image](https://github.com/user-attachments/assets/e5187c72-14fc-4f16-b301-1f6d3f6dc337)
https://metaboat.slack.com/archives/C01LQQ2UW03/p1713467787557739

### To Reproduce

1. https://metaboat.slack.com/archives/C02H619CJ8K/p1718819545954389
2. https://metaboat.slack.com/archives/C01LQQ2UW03/p1713467787557739

### Expected behavior

https://metaboat.slack.com/archives/C02H619CJ8K/p1718830565955209?thread_ts=1718819545.954389&cid=C02H619CJ8K

### Logs

_No response_

### Information about your Metabase installation

dba17e6

### Severity

Cosmetic, but ugly

### Additional context

_No response_",mngr,2024-11-06 18:21:02+00:00,[],2025-01-31 13:21:11+00:00,2025-01-31 13:19:42+00:00,https://github.com/metabase/metabase/issues/49621,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('.Team/Querying', ''), ('Frequency:Often', 'Something users bump into often')]","[{'comment_id': 2627280395, 'issue_id': 2638875233, 'author': 'kamilmielnik', 'body': '@romeovs is this a duplicate of #50038? Can we close it?', 'created_at': datetime.datetime(2025, 1, 31, 13, 3, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627299865, 'issue_id': 2638875233, 'author': 'romeovs', 'body': '@kamilmielnik I think so! https://github.com/metabase/metabase/pull/50064 fixed all cases I could reproduce.\n\n<img width=""802"" alt=""Image"" src=""https://github.com/user-attachments/assets/f65fe139-e8a9-4bd2-80aa-d9070f9861c7"" />', 'created_at': datetime.datetime(2025, 1, 31, 13, 9, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627325035, 'issue_id': 2638875233, 'author': 'kamilmielnik', 'body': ""Let's close it then.\nDuplicate of #50038.\nFixed by #50064."", 'created_at': datetime.datetime(2025, 1, 31, 13, 19, 42, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2025-01-31 13:03:42 UTC): @romeovs is this a duplicate of #50038? Can we close it?

romeovs on (2025-01-31 13:09:26 UTC): @kamilmielnik I think so! https://github.com/metabase/metabase/pull/50064 fixed all cases I could reproduce.

<img width=""802"" alt=""Image"" src=""https://github.com/user-attachments/assets/f65fe139-e8a9-4bd2-80aa-d9070f9861c7"" />

kamilmielnik on (2025-01-31 13:19:42 UTC): Let's close it then.
Duplicate of #50038.
Fixed by #50064.

"
2638797814,issue,open,,"[SDK] Strict mode causes issues on network calls of static question, causing it to render an error for a brief moment","### Describe the bug

After we merged https://github.com/metabase/metabase/pull/48808, it seems that the static question component renders an error for a brief moment.

This is happening on my vite test app in dev mode, not on storybook, and not in the vite app in prod mode (took a very long time to figure this out).

I concluded that the issue is caused by strict mode that's calling the cleanup of the ""mount"" useEffect, making us cancel the ongoing request, which is then going in error before we start loading the second one, which makes the error show up for a render or two.

The ideal solution for this is probably migrating the request to rtk as it doesn't seem other requests have this issue


Demo:

https://github.com/user-attachments/assets/12b75c39-3b49-420e-9a1d-69ab64c16ff1
",npretto,2024-11-06 17:43:20+00:00,['heypoom'],2025-02-04 20:25:57+00:00,,https://github.com/metabase/metabase/issues/49620,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2468098531, 'issue_id': 2638797814, 'author': 'npretto', 'body': 'For context, we put a ""bandage"" on this specific behaviour via https://github.com/metabase/metabase/pull/49659, but that PR is more like a ""hide the issue from showing up"" than ""fix the root cause""', 'created_at': datetime.datetime(2024, 11, 11, 12, 46, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607360491, 'issue_id': 2638797814, 'author': 'heypoom', 'body': ""Deprioritized for now as it's not a GA blocker"", 'created_at': datetime.datetime(2025, 1, 22, 14, 13, 55, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-11-11 12:46:38 UTC): For context, we put a ""bandage"" on this specific behaviour via https://github.com/metabase/metabase/pull/49659, but that PR is more like a ""hide the issue from showing up"" than ""fix the root cause""

heypoom (Assginee) on (2025-01-22 14:13:55 UTC): Deprioritized for now as it's not a GA blocker

"
2638550361,issue,open,,You can't rename a single tab in dashboards,"What it says on the label:
![Image](https://github.com/user-attachments/assets/81027d3c-b50d-4993-935d-3992d6f79dd9)

[More context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1730751781122189).",cdeweyx,2024-11-06 16:06:57+00:00,[],2025-02-04 20:30:25+00:00,,https://github.com/metabase/metabase/issues/49615,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2638285877,issue,open,,"Date style does not update for ""Week"" grouping in chart settings","### Describe the bug

You can't change the date style when grouping by week for a table view. See in the video that it works for other time groupings like month or day:
https://github.com/user-attachments/assets/98e124c3-f2c8-4b56-b9d2-4af93fdeec76
https://www.loom.com/share/bcaaa33d2d6b4f2ead8ed0b6259c1d1b?sid=1955264f-95a7-404c-b834-de5368635292

### To Reproduce

1. Create a gui question from Orders, Count by Created At
2. Change viz to table view and view All time by Week
3. Go to chart settings, Data and try to change Date Style



### Expected behavior

Should change the viz settings

### Logs

_No response_

### Information about your Metabase installation

- 51.2

### Severity

P3

### Additional context

Take into account that exports, when exported with format, respect the desired date style",ignacio-mb,2024-11-06 14:39:49+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/49607,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2638264240,issue,closed,duplicate,Excel Pivot Table Export - Summarized Column Names,"### Describe the bug

First, let me say that being able to export pivot tables is a great addition!

When exporting summarized columns to Excel, the column names are being generalized based on the type of aggregation I think instead of using the Column name that is displayed on the report in Metabase. 

### To Reproduce

1. Create a Pivot Table Visualization in Metabase with one or more aggregated fields, add a column name to the field(s). 
2. Export the Report to .xlsx with ""keep data pivoted"" enabled. 
3. Open the excel file and see that the Metabase column names are not reflected in the Excel File Pivot Table. 

![Image](https://github.com/user-attachments/assets/f30afd05-4087-44d0-b2be-cd665a0b0208)


### Expected behavior

The same Column Names that are displayed in Metabase should be included in the Pivot Table in Excel. 

### Logs

_No response_

### Information about your Metabase installation


      ""tag"": ""v0.51.2"",


### Severity

annoying

### Additional context

_No response_",dkidd255,2024-11-06 14:34:17+00:00,[],2025-01-31 18:41:48+00:00,2025-01-31 18:41:46+00:00,https://github.com/metabase/metabase/issues/49605,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]","[{'comment_id': 2628060592, 'issue_id': 2638264240, 'author': 'paoliniluis', 'body': 'Closing as duplicate', 'created_at': datetime.datetime(2025, 1, 31, 18, 41, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2025-01-31 18:41:46 UTC): Closing as duplicate

"
2638213781,issue,closed,completed,Inaccurate API Response when Serialization Fails,"### Describe the bug

If you run a serialization import via the API and it fails you're still presented with a 200 code.

### To Reproduce

1. Set up Metabase v50+
2. Create QuestionA
3. Create Question B on Question A
4. Export via API
5. delete YAML for QuestionA
6. Import via API to another target instance

API returns ""200 ok"" but the final message in the response is something like ""ERROR serialization.api :: Error during serialization: Failed to read file for Card ...""

### Expected behavior

API response code should indicate error

### Logs

_No response_

### Information about your Metabase installation

v50

### Severity

annoying / partial blocking

### Additional context

For people that are automating the promotion of assets from one instance to another this is problematic. There isn't an easy way to identify when a failure occurs. Currently some are working around this by attempting to parse the contents of the response body but it's not ideal.",ixipixi,2024-11-06 14:14:17+00:00,['piranha'],2024-11-07 10:20:37+00:00,2024-11-06 16:18:56+00:00,https://github.com/metabase/metabase/issues/49602,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2461848545, 'issue_id': 2638213781, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.3](https://github.com/metabase/metabase/milestone/279)', 'created_at': datetime.datetime(2024, 11, 7, 10, 20, 36, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-07 10:20:36 UTC): 🚀 This should also be released by [v0.51.3](https://github.com/metabase/metabase/milestone/279)

"
2638167023,issue,closed,completed,Inconsistency in Character Limit for Card Titles,"### Describe the bug

You can save a card with a 200 character title but you cannot duplicate it without truncating the title. In the ""duplicate"" modal you're presented with an error that the title must be 100 characters or less. If you shorten the title and save it then you can lengthen the title again to your hearts content from the Question itself (or to 255 characters -whichever comes first). 

### To Reproduce

1. Create a card with s title with over 100 characters
2. Try to duplicate it

### Expected behavior

The limit, whatever it will be, should probably be enforced consistently.

### Logs

_No response_

### Information about your Metabase installation

v50

### Severity

confusing

### Additional context

_No response_",ixipixi,2024-11-06 13:54:40+00:00,['ranquild'],2025-01-29 21:33:19+00:00,2025-01-29 20:13:34+00:00,https://github.com/metabase/metabase/issues/49600,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2617036894, 'issue_id': 2638167023, 'author': 'ericnormand', 'body': 'I created a related issue while reproducing this one: https://github.com/metabase/metabase/issues/52770', 'created_at': datetime.datetime(2025, 1, 27, 22, 32, 22, tzinfo=datetime.timezone.utc)}]","ericnormand on (2025-01-27 22:32:22 UTC): I created a related issue while reproducing this one: https://github.com/metabase/metabase/issues/52770

"
2638073700,issue,closed,completed,Display Metabase entity details,"As a first step, we should be able to display the JSON details of the relevant Metabase entity/entities that are part of the diagnostics information. 

Note that, in the case of dashboards, the JSON contains ALL dashboard details, not just the one from the user's URL. In such a case, we should hide irrelevant details and only show the one dashboard's JSON structure. An option might be to avoid sending everything over, but just the relevant dashboard in the first place.

As to how we should show that, a first step should be to show the raw JSON (nicely formatted).",thebiglabasky,2024-11-06 13:16:06+00:00,['filiphric'],2024-11-28 21:11:10+00:00,2024-11-28 21:11:10+00:00,https://github.com/metabase/metabase/issues/49598,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Debugger', '')]",[],
2638072096,issue,closed,completed,Non-admins creators can't change question/dashboard cache settings,"### Describe the bug

[Context in Slack](https://metaboat.slack.com/archives/C01LQQ2UW03/p1730838603477989)

We are requiring users to be admins to change single dashboard/question cache settings.
Any creator with curate access should be able to change cache settings.
Admin-level is required to configure root/db-level cache.

### To Reproduce

1. As a non-admin, go to cache settings on any question/dashboard
2. Trying to change the cache settings return an error


### Expected behavior

Any non-admin creator can change cache settings on questions and dashboards

### Logs

_No response_

### Information about your Metabase installation

v1.50.6 until v1.51.1

### Severity

P2

### Additional context

_No response_",luizarakaki,2024-11-06 13:15:19+00:00,[],2024-12-10 17:21:52+00:00,2024-12-10 17:21:51+00:00,https://github.com/metabase/metabase/issues/49597,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2532340980, 'issue_id': 2638072096, 'author': 'noahmoss', 'body': 'Fixed by https://github.com/metabase/metabase/pull/49804', 'created_at': datetime.datetime(2024, 12, 10, 17, 21, 51, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-12-10 17:21:51 UTC): Fixed by https://github.com/metabase/metabase/pull/49804

"
2638067230,issue,closed,completed,Adapt the display of Metabase information to the new JSON format,"Show details about the Metabase instance.
This is mostly about adapting the existing log viewer from https://metabase-debugger.vercel.app/ to the new JSON format.",thebiglabasky,2024-11-06 13:13:09+00:00,['filiphric'],2024-11-28 21:11:11+00:00,2024-11-28 21:11:11+00:00,https://github.com/metabase/metabase/issues/49596,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Debugger', '')]",[],
2638065952,issue,closed,completed,Adapt server logs viewer to new JSON format,"Have a place to display server logs if available. Ideally provide the ability to search them (can be postponed if not straightforward)
This is mostly about adapting the existing log viewer from https://metabase-debugger.vercel.app/ to the new JSON format",thebiglabasky,2024-11-06 13:12:36+00:00,['filiphric'],2024-11-28 21:11:13+00:00,2024-11-28 21:11:13+00:00,https://github.com/metabase/metabase/issues/49595,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Debugger', '')]",[],
2638062637,issue,closed,completed,Adapt browser logs to JSON format,"Have a place to display browser logs. Ideally allow searching into them (can be postponed if not straightforward).
This is mostly about adapting the existing log viewer from https://metabase-debugger.vercel.app/ to the new JSON format",thebiglabasky,2024-11-06 13:11:15+00:00,['filiphric'],2024-12-05 09:54:17+00:00,2024-12-05 09:54:17+00:00,https://github.com/metabase/metabase/issues/49594,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Debugger', '')]","[{'comment_id': 2519802154, 'issue_id': 2638062637, 'author': 'filiphric', 'body': 'I added this to ""in progress"" along with https://github.com/metabase/metabase/issues/49664 and hadn’t realized this is something else. console logs from browser are already part of debugger and are searchable (as is everything in debugger)', 'created_at': datetime.datetime(2024, 12, 5, 9, 54, 5, tzinfo=datetime.timezone.utc)}]","filiphric (Assginee) on (2024-12-05 09:54:05 UTC): I added this to ""in progress"" along with https://github.com/metabase/metabase/issues/49664 and hadn’t realized this is something else. console logs from browser are already part of debugger and are searchable (as is everything in debugger)

"
2638058571,issue,closed,completed,Visualize bug report information in Debugger,"**Links**
- product doc: [_link to product doc_](https://www.notion.so/metabase/Make-it-blazingly-fast-for-people-to-report-bugs-11f69354c90180aaa6ffd17c1cd147c6?pvs=4#13569354c9018087a315eed0952a174c)

We want information shared by the bug reporter to be easy to visualize in order to facilitate troubleshooting. As such, we need to adapt the Debugger to appropriately display the diagnostics information such as: browser logs, server logs (all, user, error), Metabase version information, relevant Metabase entities and details.",thebiglabasky,2024-11-06 13:09:41+00:00,"['thebiglabasky', 'filiphric']",2025-01-29 16:27:53+00:00,2025-01-29 16:27:53+00:00,https://github.com/metabase/metabase/issues/49593,[],"[{'comment_id': 2504110508, 'issue_id': 2638058571, 'author': 'filiphric', 'body': 'UPDATE: I practically finished the work on this. Few polishes (lints, types etc.) and I’ll do PR (tomorrow). The only thing that will be unfinished is the **browser** data. we need to collect this on the metabase app and then implement it in debugger, so this will be a two-step process. \n\nAlso at some point we should probably add some tests to this', 'created_at': datetime.datetime(2024, 11, 27, 15, 6, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504125863, 'issue_id': 2638058571, 'author': 'thebiglabasky', 'body': 'Nice, to which degree should I update [this proposal](https://metaboat.slack.com/archives/C07S2HE8M29/p1732719886981069) based on what you did? How can I test it?', 'created_at': datetime.datetime(2024, 11, 27, 15, 12, 45, tzinfo=datetime.timezone.utc)}]","filiphric (Assginee) on (2024-11-27 15:06:15 UTC): UPDATE: I practically finished the work on this. Few polishes (lints, types etc.) and I’ll do PR (tomorrow). The only thing that will be unfinished is the **browser** data. we need to collect this on the metabase app and then implement it in debugger, so this will be a two-step process. 

Also at some point we should probably add some tests to this

thebiglabasky (Issue Creator) on (2024-11-27 15:12:45 UTC): Nice, to which degree should I update [this proposal](https://metaboat.slack.com/archives/C07S2HE8M29/p1732719886981069) based on what you did? How can I test it?

"
2637736329,issue,closed,not_planned,"Possibility to select a month in the future in the 'month and year"" date filter.","**Is your feature request related to a problem? Please describe.**
I can't select a month in the future using the 'month and year"" date filter. But I can select a month from 1901 which is frustrating.

**Describe the solution you'd like**
I can select a month in the future. January 2025 - 2026

**Describe alternatives you've considered**
Using other filter date type. But the the 'month and year"" date filter is the most adapted filter to my monitoring.

**How important is this feature to you?**
Very important, we are monitoring deals performance month by month

**Additional context**
![Image](https://github.com/user-attachments/assets/32c6c644-8a2f-4e82-93fb-bfe79ed0c6c9)

",Guillaume-CORRE,2024-11-06 10:50:55+00:00,[],2024-11-06 11:43:30+00:00,2024-11-06 11:43:28+00:00,https://github.com/metabase/metabase/issues/49588,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2459527101, 'issue_id': 2637736329, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/26386', 'created_at': datetime.datetime(2024, 11, 6, 11, 43, 28, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-06 11:43:28 UTC): duplicate of https://github.com/metabase/metabase/issues/26386

"
2637676673,issue,closed,completed,Row limit doesn't work in Firefox by clicking arrows,"### Describe the bug

If You make a new question and set the row limit by clicking (not by entering value), it returs all rows in the table.

### To Reproduce

1. Go to 'New Question => [Sample Database] =>Accounts'
2. Click on 'Row limit => click the arrows to increase value in field (for example ""3"")'
3. Click ""Visualize""
4. It lists all rows, not the number you wanted

- If you enter the number you want, then row limit works
- Works in Chrome
![Image](https://github.com/user-attachments/assets/7fc0a031-0041-4fc1-8e7d-21940f4a623f)



### Expected behavior

It should return as many rows I'd wanted, not all

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""fi-FI"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-cloud"",
    ""version"": {
      ""date"": ""2024-10-15"",
      ""tag"": ""v1.50.30"",
      ""hash"": ""a49cb77""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Helsinki""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}

### Severity

annoyuing

### Additional context

_No response_",juheok,2024-11-06 10:34:11+00:00,['romeovs'],2024-11-13 06:34:45+00:00,2024-11-12 11:43:43+00:00,https://github.com/metabase/metabase/issues/49587,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2460493529, 'issue_id': 2637676673, 'author': 'ranquild', 'body': 'Yes, currently the row limit is updated on blur.', 'created_at': datetime.datetime(2024, 11, 6, 18, 29, 26, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-06 18:29:26 UTC): Yes, currently the row limit is updated on blur.

"
2637668946,issue,closed,completed,Adjust the diagnostics dialog towards filing a bug (vs downloading diagnostics),"**Context**
The current diagnostics dialog is oriented towards downloading (and reviewing) a JSON file containing diagnostics, which are eventually useful to file a bug.

We'd like this dialog to be about filing a bug that contains the diagnostics information, along with extra context users could add themselves, so the bug could be more easily filled.

**Current dialog**
![Image](https://github.com/user-attachments/assets/c98eb33a-1ad6-4079-86bb-0091df5175ae)

**Proposal**
Update the dialog's title to ""Report a bug""
Add a ""Context"" free form text area with a placeholder ""Please describe your issue and steps to help us reproduce it""
Place the diagnostics option below, possibly in a toggled area to ensure most context remain ticked by default
For now keep the ""Download"" action the main one for end users",thebiglabasky,2024-11-06 10:31:36+00:00,['filiphric'],2024-12-12 14:22:20+00:00,2024-12-12 14:22:20+00:00,https://github.com/metabase/metabase/issues/49586,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Reporter', '')]","[{'comment_id': 2464878870, 'issue_id': 2637668946, 'author': 'thebiglabasky', 'body': '[Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6934&t=iHy3stv3hBUcYvOL-4)', 'created_at': datetime.datetime(2024, 11, 8, 14, 17, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488690890, 'issue_id': 2637668946, 'author': 'filiphric', 'body': 'update: the issue is now on PR, I need to update tests so that they reflect the newly added buttons and textarea', 'created_at': datetime.datetime(2024, 11, 20, 14, 12, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489141718, 'issue_id': 2637668946, 'author': 'filiphric', 'body': 'tests are done, waiting for peer review', 'created_at': datetime.datetime(2024, 11, 20, 17, 10, 41, tzinfo=datetime.timezone.utc)}]","thebiglabasky (Issue Creator) on (2024-11-08 14:17:43 UTC): [Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6934&t=iHy3stv3hBUcYvOL-4)

filiphric (Assginee) on (2024-11-20 14:12:13 UTC): update: the issue is now on PR, I need to update tests so that they reflect the newly added buttons and textarea

filiphric (Assginee) on (2024-11-20 17:10:41 UTC): tests are done, waiting for peer review

"
2637652571,issue,closed,completed,"Introduce a Cmd/Ctrl + K command called ""File a bug""","People should also be able to report a bug via the Cmd/Ctrl + K command.
Flow:
1. Cmd or Ctrl + K
2. Type ""bu"" or ""report"" (or whatever else matches ""Report a bug"")
3. Select ""Report a bug""
4. Pop the diagnostics dialog",thebiglabasky,2024-11-06 10:26:09+00:00,['filiphric'],2024-12-12 14:22:13+00:00,2024-12-12 14:22:13+00:00,https://github.com/metabase/metabase/issues/49585,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Organization/Entity picker', ''), ('Bug reporter/Reporter', '')]","[{'comment_id': 2464880715, 'issue_id': 2637652571, 'author': 'thebiglabasky', 'body': '[Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6211&node-type=frame&t=iHy3stv3hBUcYvOL-11)', 'created_at': datetime.datetime(2024, 11, 8, 14, 18, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483466770, 'issue_id': 2637652571, 'author': 'filiphric', 'body': 'currently blocked by https://github.com/metabase/metabase/pull/49875', 'created_at': datetime.datetime(2024, 11, 18, 16, 1, 49, tzinfo=datetime.timezone.utc)}]","thebiglabasky (Issue Creator) on (2024-11-08 14:18:31 UTC): [Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6211&node-type=frame&t=iHy3stv3hBUcYvOL-11)

filiphric (Assginee) on (2024-11-18 16:01:49 UTC): currently blocked by https://github.com/metabase/metabase/pull/49875

"
2637648580,issue,closed,completed,"Add ""File a bug"" option to the top-right cog menu","We want to make it more obvious that people can report bugs directly from the interface. To that end, we should add a new menu entry to the ""cog"" menu at the top right, between ""Help"" and ""About Metabase"" called ""Report bug"". This would open the Diagnostics dialog as it exists today",thebiglabasky,2024-11-06 10:24:52+00:00,['filiphric'],2024-12-12 14:22:17+00:00,2024-12-12 14:22:16+00:00,https://github.com/metabase/metabase/issues/49584,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Reporter', '')]","[{'comment_id': 2464880170, 'issue_id': 2637648580, 'author': 'thebiglabasky', 'body': '[Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-5996&t=iHy3stv3hBUcYvOL-4)', 'created_at': datetime.datetime(2024, 11, 8, 14, 18, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483467267, 'issue_id': 2637648580, 'author': 'filiphric', 'body': 'currently blocked by https://github.com/metabase/metabase/pull/49875', 'created_at': datetime.datetime(2024, 11, 18, 16, 2, 1, tzinfo=datetime.timezone.utc)}]","thebiglabasky (Issue Creator) on (2024-11-08 14:18:16 UTC): [Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-5996&t=iHy3stv3hBUcYvOL-4)

filiphric (Assginee) on (2024-11-18 16:02:01 UTC): currently blocked by https://github.com/metabase/metabase/pull/49875

"
2637494191,issue,closed,completed,SDK components madness with different entity ID formats,"### Describe the bug

All 5 SDK questions and dashboards components behave vastly differently with different entity ID formats.

|                                             | InteractiveQuestion      | StaticQuestion                     | InteractiveDashboard | StaticDashboard    | EditableDashboard  |
|---------------------------------------------|--------------------------|------------------------------------|----------------------|--------------------|--------------------|
| **Entity ID**                               |                          |                                    |                      |                    |                    |
| Correct ID                                  | -                        | -                                  | -                    | -                  | -                  |
| 1 too many character/1 too little character | Error Question not found | Error API endpoint does not exist. | Loading spinner      | Loading spinner    | Loading spinner    |
| 21 characters but wrong ID                  | Error Question not found | Loading spinner                    | Error ID not found   | Error ID not found | Error ID not found |
| **Number ID (number and string)**           |                          |                                    |                      |                    |                    |
| Correct ID                                  | -                        | -                                  | -                    | -                  | -                  |
| Wrong ID                                    | Error Question not found | Error Not found.                   | Loading spinner      | Loading spinner    | Loading spinner    |

For example
![Image](https://github.com/user-attachments/assets/10607237-1ada-47bc-9f18-f2d94e4a219a)


### To Reproduce

1. Use the SDK, and embed either a dashboard or a question using the above-mentioned components with various ID formats
2. Observe the results.

### <a id='expected-behavior'></a>Expected behavior

The error state should be consistent, for example.

|                                             | InteractiveQuestion      | StaticQuestion           | InteractiveDashboard      | StaticDashboard           | EditableDashboard         |
|---------------------------------------------|--------------------------|--------------------------|---------------------------|---------------------------|---------------------------|
| **Entity ID**                               |                          |                          |                           |                           |                           |
| Correct ID                                  | -                        | -                        | -                         | -                         | -                         |
| 1 too many character/1 too little character | Error Question not found | Error Question not found | Error Dashboard not found | Error Dashboard not found | Error Dashboard not found |
| 21 characters but wrong ID                  | Error Question not found | Error Question not found | Error Dashboard not found | Error Dashboard not found | Error Dashboard not found |
| **Number ID (number and string)**           |                          |                          |                           |                           |                           |
| Correct ID                                  | -                        | -                        | -                         | -                         | -                         |
| Wrong ID                                    | Error Question not found | Error Question not found | Error Dashboard not found | Error Dashboard not found | Error Dashboard not found |

### Logs

_No response_

### Information about your Metabase installation

-

### Severity

maybe high? This makes the SDK looks highly unpolished.

### Additional context

_No response_",WiNloSt,2024-11-06 09:24:13+00:00,['WiNloSt'],2025-01-16 09:46:19+00:00,2025-01-15 02:03:21+00:00,https://github.com/metabase/metabase/issues/49581,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2461708407, 'issue_id': 2637494191, 'author': 'WiNloSt', 'body': 'Might encountered https://github.com/metabase/metabase/issues/49620 while working on this.', 'created_at': datetime.datetime(2024, 11, 7, 9, 17, 13, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-11-07 09:17:13 UTC): Might encountered https://github.com/metabase/metabase/issues/49620 while working on this.

"
2636688008,issue,open,,Support Currency Conversions / Numeric Conversions on Dashboards,"**Is your feature request related to a problem? Please describe.**
For business that deal with multiple currencies it would be ideal if there were a way to view the same financial analytics dashboard in a variety of different currencies easily. Often, cards may be presented in a ""Base"" currency which could be converted to other currencies with a multiplier.
 
The conversion factors for these can change regularly so they would need to be easily configurable and associated with a date.

For example:

- Today is May 3rd and there is a column called ""baseCurr"" with data stored in a base currency for May 1st, 2nd and 3rd 
- The conversion factor changed on each of those days (May 1st: 1.25, May 2nd: 1.29, May 3rd: 1.28)

The desired outcome when you view the results in a dashboard is that the most recent available conversion rate is applied to every record in ""baseCurr"". Such that:

- If no date filter is applied the multiple 1.28 is used
- If a date range ending on May 1st is applied the multiple 1.25 is used


**Describe the solution you'd like**

There are probably many potential ways to approach this. Once idea:

Something like the time granularity variable on a dashboard that provides that option to apply multipliers to numeric fields on dashboards. Could envision this as a linked filter that must return a scalar to be used as a multiplier.

Another would be to allow admins to define a currency conversion table via the admin panel and choose which financial fields it could apply to.

**Describe alternatives you've considered**
Creating report views that contain all possible conversions, syncing them into Metabase as tables and then using a filter to return the correct one. Presents other problems.

",ixipixi,2024-11-05 23:13:10+00:00,[],2025-02-04 20:30:57+00:00,,https://github.com/metabase/metabase/issues/49573,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', '')]","[{'comment_id': 2568183536, 'issue_id': 2636688008, 'author': 'brunobergher', 'body': 'Conceptually very related to #6514', 'created_at': datetime.datetime(2025, 1, 2, 18, 19, 52, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 18:19:52 UTC): Conceptually very related to #6514

"
2636653365,issue,open,,"Format date values as date, not datetime, in `format-rows` middleware",Current behavior can make the UI confusing as per [this slack discussion](https://metaboat.slack.com/archives/C0645JP1W81/p1730835580260359).,lbrdnk,2024-11-05 22:53:41+00:00,['lbrdnk'],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/49572,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/Processor', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2636503726,issue,open,,Support :median aggregation in MongoDB,"**Describe the solution you'd like**
Be able to use the median function as a custom expression when using MongoDB

**Additional context**
Requested by a user",psalinasy,2024-11-05 21:27:16+00:00,[],2025-02-04 20:30:18+00:00,,https://github.com/metabase/metabase/issues/49569,"[('Database/Mongo', None), ('Type:New Feature', '')]",[],
2636264898,issue,open,,[Epic] Database sandboxing,[Product doc](https://www.notion.so/metabase/Introduce-Database-level-Sandboxing-12669354c901809f9d20cd94bc8e153c),luizarakaki,2024-11-05 19:15:49+00:00,[],2025-02-04 20:24:02+00:00,,https://github.com/metabase/metabase/issues/49562,"[('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Epic', 'Feature Implementation or Project')]",[],
2636223064,issue,closed,completed,Change refresh icon to use a `reset` icon,,deniskaber,2024-11-05 18:51:39+00:00,['deniskaber'],2024-11-05 19:03:42+00:00,2024-11-05 19:03:41+00:00,https://github.com/metabase/metabase/issues/49560,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2457947823, 'issue_id': 2636223064, 'author': 'deniskaber', 'body': 'We already use [reset icon](https://storybook.metabase.com/?path=/story/icons-icon--list) [for InteractiveQuestion](https://github.com/metabase/metabase/blob/e8e77d643eb6784839982bd4b43b15a731f4b9b7/enterprise/frontend/src/embedding-sdk/components/private/ResetButton.tsx#L26) , which is different from our refresh icon:\n\n![Image](https://github.com/user-attachments/assets/c5a3c43f-eb5b-4d49-b1e2-076fe651ce66)\n![Image](https://github.com/user-attachments/assets/24e71ee8-bd16-4929-9e13-bddbbbfb4a16)\n![Image](https://github.com/user-attachments/assets/cd8ef6bd-9077-4bbe-851c-482a3a1c3c14)', 'created_at': datetime.datetime(2024, 11, 5, 19, 3, 41, tzinfo=datetime.timezone.utc)}]","deniskaber (Issue Creator) on (2024-11-05 19:03:41 UTC): We already use [reset icon](https://storybook.metabase.com/?path=/story/icons-icon--list) [for InteractiveQuestion](https://github.com/metabase/metabase/blob/e8e77d643eb6784839982bd4b43b15a731f4b9b7/enterprise/frontend/src/embedding-sdk/components/private/ResetButton.tsx#L26) , which is different from our refresh icon:

![Image](https://github.com/user-attachments/assets/c5a3c43f-eb5b-4d49-b1e2-076fe651ce66)
![Image](https://github.com/user-attachments/assets/24e71ee8-bd16-4929-9e13-bddbbbfb4a16)
![Image](https://github.com/user-attachments/assets/cd8ef6bd-9077-4bbe-851c-482a3a1c3c14)

"
2636175704,issue,open,,Increase Snippets 10000 characters limit,"**Is your feature request related to a problem? Please describe.**
A customer has snippets with more than 1000 and, and after upgrading to a later version, they can't save the snippets.

**Describe the solution you'd like**
Increase the limit, maybe with an environment variable?

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket: [31753](https://metabase.zendesk.com/agent/tickets/31753)

**Additional context**
In the customer words:
> Our snippets usecase is that we have cdc near real time table summaries that can’t be as latent as pre-calculating the summaries via GBQ Dataform. We actually have snippets that used to fit before the limit was put in, so now we can’t edit them because it won’t let us save them since we are already over the limit, doubling the limit would work for us since it was previously allowed it seems. Thats because we exist right now in a space where a lot of our SQL snippets are not quite large enough that they are slow querying near real-time cdc tables…but they would become too latent as a GBQ Dataform model for customers who want to see invoice data via these summaries within around a minute or less.",ignacio-mb,2024-11-05 18:27:32+00:00,[],2025-02-04 20:31:05+00:00,,https://github.com/metabase/metabase/issues/49557,"[('Type:New Feature', ''), ('Querying/Snippets', '')]",[],
2636170475,issue,closed,completed,Removing the source filter from a linked filter will leave the latter broken (and with an invalid reference),"### Describe the bug

If you link 2 filters and remove one, then it will leave the linked filter with a broken reference

### To Reproduce

1) create a question (e.g. get all rows from the table)
2) create a dashboard
3) add the question
4) create 2 text filters
5) connect the 2 text filters to different fields and link them
6) save
7) edit the dashboard and remove the source filter
8) try to edit the dropdown, you can't
![Image](https://github.com/user-attachments/assets/4409fcdf-78cb-495c-8c71-afa6e8c373be)


### Expected behavior

We should remove the linkage when you delete the source filter

### Logs

NA

### Information about your Metabase installation

v50.x

### Severity

P2-1

### Additional context

You'll need to recreate the filters to make this to work again...",paoliniluis,2024-11-05 18:24:14+00:00,['kamilmielnik'],2025-01-14 08:48:48+00:00,2025-01-14 08:10:33+00:00,https://github.com/metabase/metabase/issues/49556,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2636106122,issue,closed,completed,[SDK] investigate the need for NODE_OPTIONS=--max_old_space_size=XXX,"**Context**
https://metaboat.slack.com/archives/C063Q3F1HPF/p1730826514822569
and 
https://metaboat.slack.com/archives/C063Q3F1HPF/p1730826806913799


We're trying to understand if we need it and when, and what value to suggest.

It seems like the default heap size changes across envs, it could be related to the amount of ram of the device.

It's also likely that 8GB (what we used so far) is a value way above what we really need, we should find a lower value that would make the sdk work with webpack but still not eat up all the RAM of the users.

We can use this script ([source](https://blog.openreplay.com/javascript-heap-out-of-memory-error/)) to check how much rum node can use on a specific pc
```js
const array = [];
while (true) {
  array.push(new Array(10000000));
  const memory = process.memoryUsage();
  console.log((memory.heapUsed / 1024 / 1024 / 1024).toFixed(4), ""GB"");
}
```",npretto,2024-11-05 17:47:51+00:00,['npretto'],2024-11-08 09:53:30+00:00,2024-11-08 09:53:30+00:00,https://github.com/metabase/metabase/issues/49553,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2457815345, 'issue_id': 2636106122, 'author': 'npretto', 'body': 'It seems that on my machine I get a value of 3.9515 GB, while on a 8GB mac it stops at ~2GB', 'created_at': datetime.datetime(2024, 11, 5, 17, 48, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460100406, 'issue_id': 2636106122, 'author': 'npretto', 'body': 'Seems like an empty CRA project with a hello world of the sdk needs needs at least `NODE_OPTIONS=--max_old_space_size=3200`', 'created_at': datetime.datetime(2024, 11, 6, 15, 39, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460151641, 'issue_id': 2636106122, 'author': 'npretto', 'body': 'For context, an empty CRA app runs fine with 200', 'created_at': datetime.datetime(2024, 11, 6, 15, 59, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460174990, 'issue_id': 2636106122, 'author': 'npretto', 'body': 'On a VM i have that has 12GB of ram, it seems the default value is ~2gb', 'created_at': datetime.datetime(2024, 11, 6, 16, 4, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464107194, 'issue_id': 2636106122, 'author': 'npretto', 'body': ""Closing this as we moved the [sample project to vite](https://github.com/metabase/metabase-nodejs-react-sdk-embedding-sample/pull/4) to avoid the issue, and we're on our way to add a note on the docs."", 'created_at': datetime.datetime(2024, 11, 8, 8, 25, 10, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-11-05 17:48:37 UTC): It seems that on my machine I get a value of 3.9515 GB, while on a 8GB mac it stops at ~2GB

npretto (Issue Creator) on (2024-11-06 15:39:17 UTC): Seems like an empty CRA project with a hello world of the sdk needs needs at least `NODE_OPTIONS=--max_old_space_size=3200`

npretto (Issue Creator) on (2024-11-06 15:59:26 UTC): For context, an empty CRA app runs fine with 200

npretto (Issue Creator) on (2024-11-06 16:04:28 UTC): On a VM i have that has 12GB of ram, it seems the default value is ~2gb

npretto (Issue Creator) on (2024-11-08 08:25:10 UTC): Closing this as we moved the [sample project to vite](https://github.com/metabase/metabase-nodejs-react-sdk-embedding-sample/pull/4) to avoid the issue, and we're on our way to add a note on the docs.

"
2636052021,issue,open,,MongoDB - Generate schema information based on existing indices,"**Is your feature request related to a problem? Please describe.**
This is an continuation on a related issue (bug) after a follow up with the customer. I believe this falls inline as a feature request but please feel free to join it with existing issue if you feel that is correct.
https://github.com/metabase/metabase/issues/49438

As another part of their automation, can the schema information that is brought into Admin Settings → Table Metadata be based on existing indices for a collection?

<br>

![Image](https://github.com/user-attachments/assets/20dc6673-494c-49f2-812f-fefbe86f6c3f)

<br>

![Image](https://github.com/user-attachments/assets/f01e4fdb-2a3e-4d7e-851b-c4be82243349)

<br>

**Describe alternatives you've considered**
Continue to utilize existing scanning methods

",FilmonK,2024-11-05 17:23:37+00:00,[],2025-02-04 20:30:54+00:00,,https://github.com/metabase/metabase/issues/49550,"[('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('Type:New Feature', '')]","[{'comment_id': 2468377947, 'issue_id': 2636052021, 'author': 'luizarakaki', 'body': 'Not sure if I understand. What if not all fields are indexed? How would we learn about the others?', 'created_at': datetime.datetime(2024, 11, 11, 14, 58, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468443565, 'issue_id': 2636052021, 'author': 'paoliniluis', 'body': 'Have a feeling that we need to continue on the path of https://github.com/metabase/metabase/issues/10484 or https://github.com/metabase/metabase/issues/15576. @luizarakaki this issue could be part of sync indexes and then forcing the user to pick these if the admin wants', 'created_at': datetime.datetime(2024, 11, 11, 15, 28, 10, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-11-11 14:58:16 UTC): Not sure if I understand. What if not all fields are indexed? How would we learn about the others?

paoliniluis on (2024-11-11 15:28:10 UTC): Have a feeling that we need to continue on the path of https://github.com/metabase/metabase/issues/10484 or https://github.com/metabase/metabase/issues/15576. @luizarakaki this issue could be part of sync indexes and then forcing the user to pick these if the admin wants

"
2635783225,issue,open,,"Offer option to disable the ""Report bug"" button from profile settings","If we go with a relatively invasive option (like a floating, always-on button) for the ""Report bug"" button (cf. #49543) there should likely be a way for users to deactivate it by default, knowing they can use `Cmd/Ctrl` + `F1` to do the same.",thebiglabasky,2024-11-05 15:30:38+00:00,[],2025-02-04 20:23:51+00:00,,https://github.com/metabase/metabase/issues/49544,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2635782485,issue,closed,completed,"Introduce ""File a bug"" button","**The problem:** the Cmd/Ctrl + F1 shortcut to surface the diagnostics modal is way too difficult to think about for an end user. As a result people don't make use of it and we can't benefit from the extra context this provides to bug reports.

**The idea:** having ""something"" (to be designed) allowing to report a bug almost instantly (at first we'll just post something on Slack without a need to confirm, but we should have a step to ask for more context / give more options soon). This being a floating button, or something else. We could consider making it an option to disable it if too invasive, but the goal here is to increase the amount of bugs we reporting to ourselves by making it dead easy to do.

[Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6934&node-type=section&t=iHy3stv3hBUcYvOL-11)",thebiglabasky,2024-11-05 15:30:19+00:00,['filiphric'],2024-12-13 20:17:02+00:00,2024-12-13 20:17:02+00:00,https://github.com/metabase/metabase/issues/49543,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.'), ('Bug reporter/Reporter', '')]","[{'comment_id': 2459233692, 'issue_id': 2635782485, 'author': 'thebiglabasky', 'body': ""More details available in [this convo](https://metaboat.slack.com/archives/C02H619CJ8K/p1730820992395459) but essentially we'd look at adding more places where people can pop the diagnostics tool dialog. I'll create sub-issues for that here"", 'created_at': datetime.datetime(2024, 11, 6, 10, 23, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464881420, 'issue_id': 2635782485, 'author': 'thebiglabasky', 'body': '[Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6934&node-type=section&t=iHy3stv3hBUcYvOL-11)', 'created_at': datetime.datetime(2024, 11, 8, 14, 18, 52, tzinfo=datetime.timezone.utc)}]","thebiglabasky (Issue Creator) on (2024-11-06 10:23:05 UTC): More details available in [this convo](https://metaboat.slack.com/archives/C02H619CJ8K/p1730820992395459) but essentially we'd look at adding more places where people can pop the diagnostics tool dialog. I'll create sub-issues for that here

thebiglabasky (Issue Creator) on (2024-11-08 14:18:52 UTC): [Figma designs](https://www.figma.com/design/Hnb7RXZaL4gMjINWQPjhhf/Bug-reporting?node-id=14001-6934&node-type=section&t=iHy3stv3hBUcYvOL-11)

"
2635780252,issue,closed,completed,Send diagnostics tool info to Slack,"Whenever clicking the ""Report bug"" button (cf. #49543) we should send to Slack a summary message along with the JSON file currently generated by the diagnostics tool.",thebiglabasky,2024-11-05 15:29:31+00:00,['filiphric'],2025-01-10 15:33:12+00:00,2024-11-22 08:31:08+00:00,https://github.com/metabase/metabase/issues/49542,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Bug reporter/Reporter', '')]","[{'comment_id': 2467643693, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'update: the PR Is open, but I need to do some more adjustments to it. We discussed my approach with Vamsi. I chose to add another module so that bugs are reported to our slack only. The thing is, that we already have an existing slack integration that allows people to integrate slack server of their choice. My assumption was that we only want to have bug reports sent to us, but Vamsi pointed out, that there’s a strong argument for our users to be able to set up an internal bug reporting channel for themselves and forward bug reports to us when needed. I’m going to adjust the diagnostic tool for that and open PR', 'created_at': datetime.datetime(2024, 11, 11, 9, 25, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468344712, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'UPDATE: most of the logic for this was done today. Just making finishing touches to the slack message formatting. After that, I’ll make PR, and fix tests if needed.', 'created_at': datetime.datetime(2024, 11, 11, 14, 43, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469843950, 'issue_id': 2635780252, 'author': 'thebiglabasky', 'body': ""Nice. The Slack argument is fair, though we will push bugs primarily to Pylon and GitHub for end users since not all of them use Slack (some MS Teams) and not all of them have a shared channel with us. So we'll start with what everyone can use. Now all that is subsequent to this initial Slack task which is for us only so that's all fine 👌🏻"", 'created_at': datetime.datetime(2024, 11, 12, 8, 6, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470463740, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'Created a [new PR](https://github.com/metabase/metabase/pull/49875) for this issue. the feature is fully working and needs `MB_BUG_REPORTER_ENABLED` env variable. Waiting for PR to be merged and fix tests in case any fail\n\n![Image](https://github.com/user-attachments/assets/8aacb037-9c9e-4fea-82d1-ecebcacc4fd2)\n![Image](https://github.com/user-attachments/assets/21080e82-2c67-4a6b-8314-dc1756892173)\n![Image](https://github.com/user-attachments/assets/129ac6bd-6157-4a8d-8dc9-ecfd6ef50eb9)', 'created_at': datetime.datetime(2024, 11, 12, 12, 57, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473485618, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'UPDATE: there were indeed some failed tests, lint and type errors. as of now, they are all fixed and PR is waiting for review.', 'created_at': datetime.datetime(2024, 11, 13, 12, 33, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483461179, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'update: some requests on the implementation logic were requested by fellow developers. these have now been addressed and PR was updated. I haven’t got any feedback from backend developers yet.', 'created_at': datetime.datetime(2024, 11, 18, 15, 59, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483587961, 'issue_id': 2635780252, 'author': 'thebiglabasky', 'body': 'Okay, let me know if you need help to push this a little forward and unblock the rest', 'created_at': datetime.datetime(2024, 11, 18, 16, 52, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483606149, 'issue_id': 2635780252, 'author': 'filiphric', 'body': 'nothing at the moment. I’m not blocked, I can still work on other tasks until backend developers can prioritize this', 'created_at': datetime.datetime(2024, 11, 18, 17, 0, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582972408, 'issue_id': 2635780252, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52.1](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2025, 1, 10, 15, 33, 11, tzinfo=datetime.timezone.utc)}]","filiphric (Assginee) on (2024-11-11 09:25:57 UTC): update: the PR Is open, but I need to do some more adjustments to it. We discussed my approach with Vamsi. I chose to add another module so that bugs are reported to our slack only. The thing is, that we already have an existing slack integration that allows people to integrate slack server of their choice. My assumption was that we only want to have bug reports sent to us, but Vamsi pointed out, that there’s a strong argument for our users to be able to set up an internal bug reporting channel for themselves and forward bug reports to us when needed. I’m going to adjust the diagnostic tool for that and open PR

filiphric (Assginee) on (2024-11-11 14:43:32 UTC): UPDATE: most of the logic for this was done today. Just making finishing touches to the slack message formatting. After that, I’ll make PR, and fix tests if needed.

thebiglabasky (Issue Creator) on (2024-11-12 08:06:03 UTC): Nice. The Slack argument is fair, though we will push bugs primarily to Pylon and GitHub for end users since not all of them use Slack (some MS Teams) and not all of them have a shared channel with us. So we'll start with what everyone can use. Now all that is subsequent to this initial Slack task which is for us only so that's all fine 👌🏻

filiphric (Assginee) on (2024-11-12 12:57:02 UTC): Created a [new PR](https://github.com/metabase/metabase/pull/49875) for this issue. the feature is fully working and needs `MB_BUG_REPORTER_ENABLED` env variable. Waiting for PR to be merged and fix tests in case any fail

![Image](https://github.com/user-attachments/assets/8aacb037-9c9e-4fea-82d1-ecebcacc4fd2)
![Image](https://github.com/user-attachments/assets/21080e82-2c67-4a6b-8314-dc1756892173)
![Image](https://github.com/user-attachments/assets/129ac6bd-6157-4a8d-8dc9-ecfd6ef50eb9)

filiphric (Assginee) on (2024-11-13 12:33:20 UTC): UPDATE: there were indeed some failed tests, lint and type errors. as of now, they are all fixed and PR is waiting for review.

filiphric (Assginee) on (2024-11-18 15:59:41 UTC): update: some requests on the implementation logic were requested by fellow developers. these have now been addressed and PR was updated. I haven’t got any feedback from backend developers yet.

thebiglabasky (Issue Creator) on (2024-11-18 16:52:37 UTC): Okay, let me know if you need help to push this a little forward and unblock the rest

filiphric (Assginee) on (2024-11-18 17:00:35 UTC): nothing at the moment. I’m not blocked, I can still work on other tasks until backend developers can prioritize this

github-actions[bot] on (2025-01-10 15:33:11 UTC): 🚀 This should also be released by [v0.52.1](https://github.com/metabase/metabase/milestone/283)

"
2635778020,issue,closed,not_planned,"Introduce ""Report bug"" button",,thebiglabasky,2024-11-05 15:28:42+00:00,[],2024-11-05 15:29:48+00:00,2024-11-05 15:29:48+00:00,https://github.com/metabase/metabase/issues/49541,[],[],
2635777665,issue,closed,completed,Offer to instantly report bugs to Slack (internal-only),"**Links**
- product doc: https://www.notion.so/metabase/Make-it-blazingly-fast-for-people-to-report-bugs-11f69354c90180aaa6ffd17c1cd147c6?pvs=4#12069354c90180efa2ffc6662c43b997

**Implementation Plan**
Port some functionality (Slack reporting) from the bug reporter POC into Metabase for internal purposes only as a first step, and make the bug reporting option more prominent.",thebiglabasky,2024-11-05 15:28:32+00:00,['filiphric'],2024-12-13 20:18:07+00:00,2024-12-13 20:18:07+00:00,https://github.com/metabase/metabase/issues/49540,"[('.Epic', 'Feature Implementation or Project'), ('Bug reporter/Reporter', '')]","[{'comment_id': 2503282489, 'issue_id': 2635777665, 'author': 'filiphric', 'body': 'UPDATE: multiple PRs are waiting for reviews. I had to make some changes last week, but they were now implemented, so no it’s pretty much just about the capacity of other developers to provide a review and approve merging.\n\nbasic functionality is implemented and should be enabled on stats.metabase.com [soon](https://metaboat.slack.com/archives/C0669P4AF9N/p1732629122718799)\n\nthere’s still seems to be one bug in the new layout window - description does [not seem to make it](https://github.com/metabase/metabase/pull/50277#pullrequestreview-2463171335) into the slack channel. we’ll sync with Ryan to see where the problem is.\n\nI already switched my focus to the debugger part in the meantime, although I’ve spent better part of the week switching back and forth between PR work and debugger. I’d appreciate some help with getting some more dev eyes on this PR as the length of the review seems to be the tightest bottleneck right now', 'created_at': datetime.datetime(2024, 11, 27, 8, 54, 56, tzinfo=datetime.timezone.utc)}]","filiphric (Assginee) on (2024-11-27 08:54:56 UTC): UPDATE: multiple PRs are waiting for reviews. I had to make some changes last week, but they were now implemented, so no it’s pretty much just about the capacity of other developers to provide a review and approve merging.

basic functionality is implemented and should be enabled on stats.metabase.com [soon](https://metaboat.slack.com/archives/C0669P4AF9N/p1732629122718799)

there’s still seems to be one bug in the new layout window - description does [not seem to make it](https://github.com/metabase/metabase/pull/50277#pullrequestreview-2463171335) into the slack channel. we’ll sync with Ryan to see where the problem is.

I already switched my focus to the debugger part in the meantime, although I’ve spent better part of the week switching back and forth between PR work and debugger. I’d appreciate some help with getting some more dev eyes on this PR as the length of the review seems to be the tightest bottleneck right now

"
2635540221,issue,open,,"`lang` attribute doesn't respect user locale, uses instance locale instead.","### Describe the bug

Given these locales:
- Instance: Chinese
- User: Korean

This confuses some features e.g. Chrome's auto-translation asked if I wanted to translate from Chinese when the whole page is practically Korean and English.

- ![Image](https://github.com/user-attachments/assets/7e6b70aa-a146-4962-9eb5-5b312462f670)
- ![Image](https://github.com/user-attachments/assets/361a189e-dbcd-4bb9-b258-e6077662a733)


### To Reproduce

1. Set the instance locale to a locale, not English e.g. Chinese.
2. Set the user locale to a different locale, also not English e.g. Korean.
3. Restart the BE. This is necessary since it seems some locales are cached when changed.
4. Open the devtools and you'll see the `lang` on `html` is set to Chinese instead of Korean.

### Expected behavior

`lang` is set to the user locale correctly.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-11-05"",
      ""src_hash"": ""61381b2c44169665196f7efa174e090082b917c7"",
      ""tag"": ""v1.1.39-SNAPSHOT"",
      ""hash"": ""5dd8fd3""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""15.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}

### Severity

annoying, but not severe

### Additional context

_No response_",WiNloSt,2024-11-05 13:55:59+00:00,[],2025-02-05 19:28:40+00:00,,https://github.com/metabase/metabase/issues/49538,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/i18n', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2635528229,issue,closed,completed,No tooltip anymore in static embedded bar chart,"### Describe the bug

Regression detected when upgrading Metabase from v1.50.27 to v1.51.1 and the issue persists in v1.51.2:

In the Metabase editor a tooltip appears on hover in a bar chart:

![Image](https://github.com/user-attachments/assets/a35a83a0-c7af-4191-bb3b-d4387db2d4b7)

But once the dashboard is embedded statically the tooltip is not displayed anymore when hovering the mouse pointer on the same bar:
![Image](https://github.com/user-attachments/assets/d883a13c-99fa-42b3-a324-d6f0ba507ed5)



### To Reproduce

1. Create a bar chart with a native query question
2. Hover on a bar when static embedded


### Expected behavior

A tooltip should popup giving more value details.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}

### Severity

major

### Additional context

_No response_",nicovl-rombit,2024-11-05 13:51:34+00:00,['npretto'],2024-11-21 21:43:22+00:00,2024-11-18 06:02:05+00:00,https://github.com/metabase/metabase/issues/49537,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2463718285, 'issue_id': 2635528229, 'author': 'robswanLL', 'body': 'Reproducible on 0.51.2 docker self-hosted', 'created_at': datetime.datetime(2024, 11, 8, 4, 11, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467501339, 'issue_id': 2635528229, 'author': 'WiNloSt', 'body': 'I tested on both `1.51.1` using H2 and `0.52.2` using H2 and PostgreSQL.\n\nUsing this question\n```sql\nSELECT\n  DATE_TRUNC(\'month\', ""public"".""orders"".""created_at"") AS ""created_at"",\n  ""products__via__product_id"".""category"" AS ""products__via__product_id__category"",\n  COUNT(*) AS ""count""\nFROM\n  ""public"".""orders""\n \nLEFT JOIN ""public"".""products"" AS ""products__via__product_id"" ON ""public"".""orders"".""product_id"" = ""products__via__product_id"".""id""\nGROUP BY\n  DATE_TRUNC(\'month\', ""public"".""orders"".""created_at""),\n  ""products__via__product_id"".""category""\nORDER BY\n  DATE_TRUNC(\'month\', ""public"".""orders"".""created_at"") ASC,\n  ""products__via__product_id"".""category"" ASC\n```\nSet the viz type to ""Line"" and changed the display to stacked, and I can still hover the embed.\n\n![Image](https://github.com/user-attachments/assets/623b77e7-29ac-4491-8e6d-c51cc395856d)', 'created_at': datetime.datetime(2024, 11, 11, 8, 17, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467948089, 'issue_id': 2635528229, 'author': 'npretto', 'body': ""@nicovl-rombit thanks for reporting this. Unfortunately I also wasn't able to reproduce this on `v1.51.1 `, could you give us some more details?\nSome info that could help use reproduce and fix this faster:\n- does this happen only on sql queries or also on queries create via the UI editor?\n- does this happen on public links?\n- does it happen only on data coming from postgres?"", 'created_at': datetime.datetime(2024, 11, 11, 11, 29, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471112204, 'issue_id': 2635528229, 'author': 'YvesBos', 'body': 'It seems to be related to static embedding in combination with `iframe-resizer`, tooltips work fine when not resizing the iframe but that obviously introduces other issues. \n\nI managed to make it work by configuring `iframe-resizer` with `waitForLoad: true`. The option has been introduced only recently, in versions for which we now require a commercial license. The [Metabase documentation](https://www.metabase.com/docs/latest/embedding/static-embedding#resizing-dashboards-to-fit-their-content) states that we should use version 4.3.2 or lower due to the licensing change but that version does not have to `waitForLoad` option and leaves us with broken tooltips.', 'created_at': datetime.datetime(2024, 11, 12, 17, 9, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473324815, 'issue_id': 2635528229, 'author': 'nicovl-rombit', 'body': '@npretto are you using the `iframe-resizer` when trying to reproduce this issue on your local dev environment?', 'created_at': datetime.datetime(2024, 11, 13, 11, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473851111, 'issue_id': 2635528229, 'author': 'npretto', 'body': ""Thanks to both, we were able to reproduce the issue with `iframe-resizer` and we're investigating.\n\nIt seems like without the iframe resizer the tooltip container has this size\n![Image](https://github.com/user-attachments/assets/97bff20a-70b2-4bbe-ab22-7592560b802e)\n\nbut with the iframe resizer it's moved to the bottom of the page with height 0:\n![Image](https://github.com/user-attachments/assets/1dfaff71-8b7c-440d-9a6a-47bb1229033a)\n\nRemoving `overflow:hidden` shows the the tooltip have the wrong offset because of that:\n![Image](https://github.com/user-attachments/assets/0e6628af-0dad-4310-bfdd-45110c7ce109)"", 'created_at': datetime.datetime(2024, 11, 13, 14, 55, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473917264, 'issue_id': 2635528229, 'author': 'YvesBos', 'body': 'Given the restrictive nature of the commercial license for SaaS products we have looked for alternatives and found https://github.com/Lemick/open-iframe-resizer. We were able to use it as a drop-in replacement without any additional config and the issue is gone. Maybe worth investigating and recommending it over `iframe-resizer` in the docs.', 'created_at': datetime.datetime(2024, 11, 13, 15, 17, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476783674, 'issue_id': 2635528229, 'author': 'WiNloSt', 'body': 'This is caused by https://github.com/metabase/metabase/pull/46359, and https://github.com/metabase/metabase/pull/49964 should fix it.', 'created_at': datetime.datetime(2024, 11, 14, 15, 57, 35, tzinfo=datetime.timezone.utc)}]","robswanLL on (2024-11-08 04:11:30 UTC): Reproducible on 0.51.2 docker self-hosted

WiNloSt on (2024-11-11 08:17:15 UTC): I tested on both `1.51.1` using H2 and `0.52.2` using H2 and PostgreSQL.

Using this question
```sql
SELECT
  DATE_TRUNC('month', ""public"".""orders"".""created_at"") AS ""created_at"",
  ""products__via__product_id"".""category"" AS ""products__via__product_id__category"",
  COUNT(*) AS ""count""
FROM
  ""public"".""orders""
 
LEFT JOIN ""public"".""products"" AS ""products__via__product_id"" ON ""public"".""orders"".""product_id"" = ""products__via__product_id"".""id""
GROUP BY
  DATE_TRUNC('month', ""public"".""orders"".""created_at""),
  ""products__via__product_id"".""category""
ORDER BY
  DATE_TRUNC('month', ""public"".""orders"".""created_at"") ASC,
  ""products__via__product_id"".""category"" ASC
```
Set the viz type to ""Line"" and changed the display to stacked, and I can still hover the embed.

![Image](https://github.com/user-attachments/assets/623b77e7-29ac-4491-8e6d-c51cc395856d)

npretto (Assginee) on (2024-11-11 11:29:58 UTC): @nicovl-rombit thanks for reporting this. Unfortunately I also wasn't able to reproduce this on `v1.51.1 `, could you give us some more details?
Some info that could help use reproduce and fix this faster:
- does this happen only on sql queries or also on queries create via the UI editor?
- does this happen on public links?
- does it happen only on data coming from postgres?

YvesBos on (2024-11-12 17:09:21 UTC): It seems to be related to static embedding in combination with `iframe-resizer`, tooltips work fine when not resizing the iframe but that obviously introduces other issues. 

I managed to make it work by configuring `iframe-resizer` with `waitForLoad: true`. The option has been introduced only recently, in versions for which we now require a commercial license. The [Metabase documentation](https://www.metabase.com/docs/latest/embedding/static-embedding#resizing-dashboards-to-fit-their-content) states that we should use version 4.3.2 or lower due to the licensing change but that version does not have to `waitForLoad` option and leaves us with broken tooltips.

nicovl-rombit (Issue Creator) on (2024-11-13 11:39:12 UTC): @npretto are you using the `iframe-resizer` when trying to reproduce this issue on your local dev environment?

npretto (Assginee) on (2024-11-13 14:55:15 UTC): Thanks to both, we were able to reproduce the issue with `iframe-resizer` and we're investigating.

It seems like without the iframe resizer the tooltip container has this size
![Image](https://github.com/user-attachments/assets/97bff20a-70b2-4bbe-ab22-7592560b802e)

but with the iframe resizer it's moved to the bottom of the page with height 0:
![Image](https://github.com/user-attachments/assets/1dfaff71-8b7c-440d-9a6a-47bb1229033a)

Removing `overflow:hidden` shows the the tooltip have the wrong offset because of that:
![Image](https://github.com/user-attachments/assets/0e6628af-0dad-4310-bfdd-45110c7ce109)

YvesBos on (2024-11-13 15:17:29 UTC): Given the restrictive nature of the commercial license for SaaS products we have looked for alternatives and found https://github.com/Lemick/open-iframe-resizer. We were able to use it as a drop-in replacement without any additional config and the issue is gone. Maybe worth investigating and recommending it over `iframe-resizer` in the docs.

WiNloSt on (2024-11-14 15:57:35 UTC): This is caused by https://github.com/metabase/metabase/pull/46359, and https://github.com/metabase/metabase/pull/49964 should fix it.

"
2635514495,issue,closed,completed,CTA needs link and verbiage tweak,"https://github.com/metabase/metabase/blob/master/frontend/src/metabase/admin/upsells/UpsellSSO.tsx#L27

- should link `/upgrade` not `/cloud`
- button text should be ""Try Metabase Pro"" not ""Learn more""

![Image](https://github.com/user-attachments/assets/1c606217-2a86-411c-b95e-d9513490e58d)

slack context: https://metaboat.slack.com/archives/C064EB1UE5P/p1730810602211689",dpsutton,2024-11-05 13:46:09+00:00,[],2024-11-11 14:06:01+00:00,2024-11-07 23:18:34+00:00,https://github.com/metabase/metabase/issues/49534,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), (':broom:', 'no-brainer cleanup issues to clear out when you have an hour left until EoD or something'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2635499352,issue,closed,completed,Google chat webhook - crateChannel & testChannel not working,"Edit.: this is a limitation of our implementation, but it isn't a bug.
This will be fixed with custom notification templates.


### Describe the bug

In section notification channels, in admin, section webhooks for alerts - its not possible to add google chat as webhook destination. Error response says ""message"": ""Message cannot be empty"" and creation of this webhook fails. Is there any possible workaround or fix?

### To Reproduce

1. Go to 'admin -> notfication channels -> webhooks for alerts '
2. Click on 'add a webhook'
3. Put url to google chat webhook and press send test button -> see error
4. Fill formular fields 'give it a name' and 'description' and press 'create destination' -> see error

### Expected behavior

Create channel works

### Logs

{
    ""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": ""Unable to connect channel"",
            ""data"": {
                ""status-code"": 400,
                ""request-status"": 400,
                ""request-body"": ""{\n  \""error\"": {\n    \""code\"": 400,\n    \""message\"": \""Message cannot be empty.\"",\n    \""status\"": \""INVALID_ARGUMENT\""\n  }\n}\n""
            },
            ""at"": [
                ""metabase.api.channel$test_channel_connection_BANG_"",
                ""invokeStatic"",
                ""channel.clj"",
                41
            ]
        }
    ],

### Information about your Metabase installation

each browser, version v0.51.1.3 

### Severity

HOTFIX

### Additional context

_No response_",FoltanMilos,2024-11-05 13:40:16+00:00,[],2025-01-31 19:05:34+00:00,2024-11-20 16:00:41+00:00,https://github.com/metabase/metabase/issues/49533,"[('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Notifications/Webhooks', '')]","[{'comment_id': 2457444182, 'issue_id': 2635499352, 'author': 'FoltanMilos', 'body': '@ranquild could you provide me some more information?\n\ni can easily simulate that via postman with sending no body, it looks like /channel/test and /channel/create does not send body with parameter ""text"" as google requires. \n\nIs there any easy work around? Could you provide me some estimation of fixing this?', 'created_at': datetime.datetime(2024, 11, 5, 15, 16, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457694866, 'issue_id': 2635499352, 'author': 'luizarakaki', 'body': ""This is a limitation, not a bug.\n\nWe currently don't support customizing the webhook payload. This will be possible in a future release.\nYou can check the [current payload schema here](https://www.metabase.com/docs/latest/configuring-metabase/webhooks).\n\nAn easy workaround is to create a lambda function or add Zapier to translate our payload into the Google Chat expected payload."", 'created_at': datetime.datetime(2024, 11, 5, 16, 52, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507544950, 'issue_id': 2635499352, 'author': 'wadjeroudi', 'body': ""@qnkhuat @luizarakaki it has been closed by mistake no ? The payload isn't customizable."", 'created_at': datetime.datetime(2024, 11, 29, 10, 42, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627501102, 'issue_id': 2635499352, 'author': 'ipapast', 'body': ""> This is a limitation, not a bug.\n> \n> We currently don't support customizing the webhook payload. This will be possible in a future release. You can check the [current payload schema here](https://www.metabase.com/docs/latest/configuring-metabase/webhooks).\n> \n> An easy workaround is to create a lambda function or add Zapier to translate our payload into the Google Chat expected payload.\n\nHi, do you have a link where we can collow this feature (customising payload)? @luizarakaki"", 'created_at': datetime.datetime(2025, 1, 31, 14, 35, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627578955, 'issue_id': 2635499352, 'author': 'paoliniluis', 'body': 'most probably you need https://github.com/metabase/metabase/issues/9966', 'created_at': datetime.datetime(2025, 1, 31, 15, 10, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628101067, 'issue_id': 2635499352, 'author': 'ipapast', 'body': ""> most probably you need [#9966](https://github.com/metabase/metabase/issues/9966)\n\nI'm not sure it's exactly the same. I'd like to be able to customise the payload of the webhook."", 'created_at': datetime.datetime(2025, 1, 31, 19, 5, 33, tzinfo=datetime.timezone.utc)}]","FoltanMilos (Issue Creator) on (2024-11-05 15:16:10 UTC): @ranquild could you provide me some more information?

i can easily simulate that via postman with sending no body, it looks like /channel/test and /channel/create does not send body with parameter ""text"" as google requires. 

Is there any easy work around? Could you provide me some estimation of fixing this?

luizarakaki on (2024-11-05 16:52:44 UTC): This is a limitation, not a bug.

We currently don't support customizing the webhook payload. This will be possible in a future release.
You can check the [current payload schema here](https://www.metabase.com/docs/latest/configuring-metabase/webhooks).

An easy workaround is to create a lambda function or add Zapier to translate our payload into the Google Chat expected payload.

wadjeroudi on (2024-11-29 10:42:29 UTC): @qnkhuat @luizarakaki it has been closed by mistake no ? The payload isn't customizable.

ipapast on (2025-01-31 14:35:02 UTC): Hi, do you have a link where we can collow this feature (customising payload)? @luizarakaki

paoliniluis on (2025-01-31 15:10:50 UTC): most probably you need https://github.com/metabase/metabase/issues/9966

ipapast on (2025-01-31 19:05:33 UTC): I'm not sure it's exactly the same. I'd like to be able to customise the payload of the webhook.

"
2635385888,issue,open,,Dynamic calculated values using filters - non SQL,"**Feature Request**
Ability to have dynamic calculated fields without having to convert the questions into SQL versions. 

**Issue**
We managed to achieve the ability to create dynamic calculations using a number filter. In our case it allows us to manipulate the margin calculation of a cost related metric. 

In order to achieve this though we had to create the question in stages since a field filter (campaign_code) gotcha is that they don't work on queries that contain aliases. As you can see below, we did manage it with an alias but first had to make the query without them, then save the question, then add the field filter (campaign_code), save it, then add the alias back in else every time you change the margin, it would change the formatting of the bar chart we were using and adjust the colours. 

```
SELECT
  `default`.`ads`.`adset_term1`,
  `median`(`default`.`ads`.`cpc`) * (1 + {{margin}} / 50) AS ""Value"",
  `median`(`default`.`ads`.`ctr`)
FROM
  `default`.`ads`
WHERE
  `default`.`ads`.`spend` IS NOT NULL
  [[AND {{campaign_code}}]]
GROUP BY
  `default`.`ads`.`adset_term1`
ORDER BY
  `median`(`default`.`ads`.`ctr`) DESC,
  `default`.`ads`.`adset_term1` ASC
```

![Image](https://github.com/user-attachments/assets/ffda75aa-7b85-43ea-9da9-9476258dd932)
",bubbaspaarx,2024-11-05 12:59:07+00:00,[],2025-02-05 14:51:58+00:00,,https://github.com/metabase/metabase/issues/49532,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]",[],
2635346732,issue,open,,Dashboard card download result using date locale from instance and ignore user locale,"### Describe the bug

With this locale:
- Instance: Dutch
- User: Korean
Here's the result download from one of the card in a dashboard in the example collection.

![Image](https://github.com/user-attachments/assets/5e690565-210c-4b37-99ff-e2207426db89)

You can see that despite the column name being translated to the user locale, the date format is using an instance locale.

Here's the CSV
[revenue_and_orders_over_time_2024-11-05T12_17_26.373252Z.csv](https://github.com/user-attachments/files/17632553/revenue_and_orders_over_time_2024-11-05T12_17_26.373252Z.csv)


### To Reproduce

1. Set up a new Metabase instance
2. Set the instance locale to one locale
3. Set the user locale to _a different_ locale
4. Go to ""E-commerce insights"" dashboard in the example collection and download ""Revenue and orders over time"" as CSV (formatted)
    ![Image](https://github.com/user-attachments/assets/9d10235d-7b66-4c1b-b664-e3add06471dd)



### Expected behavior

The date format should use the user locale

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-29"",
      ""src_hash"": ""6cf5d807461368ec5df45dce530813f52de7c483"",
      ""tag"": ""v1.1.39-SNAPSHOT"",
      ""hash"": ""c2a6bd0""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""15.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}

### Severity

Could be severe for static embedding since we could embed the same dashboard with different locales

### Additional context

While fixing [Support language localization in static embedding](https://github.com/metabase/metabase/issues/8490#top), I tested the static embed as well and it had the same result.

If we fix this issue on the main app, it should fix the static embed download as well since I'm passing `X-Metabase-Locale` to the download endpoint, and we have a [BE patch](https://github.com/metabase/metabase/pull/49441/commits/83d8d1358ce30019291b5a0b17d69528f196227a) that will propagate that in BE.",WiNloSt,2024-11-05 12:40:22+00:00,[],2025-02-04 20:31:32+00:00,,https://github.com/metabase/metabase/issues/49531,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Customization/i18n', ''), ('.Backend', ''), ('Visualization/Download', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2635221093,issue,closed,completed,Row visualization settings sidebar crashes,"### Describe the bug

![Image](https://github.com/user-attachments/assets/18eed282-cebb-4d47-b1af-a8ccfcb6f432)


### To Reproduce

1. New > Question > Orders > Visualize
2. Change viz type to Row
3. Open viz settings sidebar
4. Select some Y-axis 
5. Click ""Add series breakout"" and select some Y-Axis

Sidebar crashes

### Information about your Metabase installation

master, 518e79b8fb292ba17b402042b05ccdfb64b30ad6

### Severity

P1

### Additional context

Error in JS console: `TypeError: Cannot read properties of undefined (reading 'filter')` coming from [here](https://github.com/metabase/metabase/blob/9b4d3d2b2ebb24975ed8a673f86e15d9417d1215/frontend/src/metabase/visualizations/components/settings/ChartSettingSeriesOrder.tsx#L83)",kamilmielnik,2024-11-05 11:40:43+00:00,['alxnddr'],2024-11-26 14:38:34+00:00,2024-11-26 14:38:33+00:00,https://github.com/metabase/metabase/issues/49529,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Visualization/Charts/Row', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2456949570, 'issue_id': 2635221093, 'author': 'kamilmielnik', 'body': ""I also got a crash from [here](https://github.com/metabase/metabase/blob/dbdef76e639d3f5857f8e787d5435530f0ebaac7/frontend/src/metabase/visualizations/lib/settings/graph.js#L175) because `transformedSeries` was `undefined` but I can't remember repro steps."", 'created_at': datetime.datetime(2024, 11, 5, 11, 42, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458636382, 'issue_id': 2635221093, 'author': 'romeovs', 'body': 'This is a dupe of https://github.com/metabase/metabase/issues/49523', 'created_at': datetime.datetime(2024, 11, 6, 3, 4, 37, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-11-05 11:42:29 UTC): I also got a crash from [here](https://github.com/metabase/metabase/blob/dbdef76e639d3f5857f8e787d5435530f0ebaac7/frontend/src/metabase/visualizations/lib/settings/graph.js#L175) because `transformedSeries` was `undefined` but I can't remember repro steps.

romeovs on (2024-11-06 03:04:37 UTC): This is a dupe of https://github.com/metabase/metabase/issues/49523

"
2634978973,issue,closed,not_planned,"Non-Admin user found error in search box ""PreparedStatement can have at most 65,535 parameters. Please consider using arrays, or splitting the query in several ones, or using COPY. ""","### Describe the bug

Whenever non-admin user search on search box on home page or search box to add question, metabase end up with error 

> 'PreparedStatement can have at most 65,535 parameters. Please consider using arrays, or splitting the query in several ones, or using COPY. '



### To Reproduce

1. Set your account as non-admin role
2. Click on search box and type any value
3. Enter and wait for result
4. See error


### Expected behavior

Metabase be able to show the related item

### Logs

![Image](https://github.com/user-attachments/assets/d4f75a08-c41b-43ea-8f6a-467b61ebac77)


### Information about your Metabase installation

- Metabase Version: v0.48.4-SNAPSHOT

### Severity

Urgent

### Additional context

_No response_",unnyns-307,2024-11-05 09:57:36+00:00,[],2024-11-07 14:49:16+00:00,2024-11-05 10:06:14+00:00,https://github.com/metabase/metabase/issues/49526,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2456750013, 'issue_id': 2634978973, 'author': 'paoliniluis', 'body': 'We fixed this probably in a more recent version, please upgrade', 'created_at': datetime.datetime(2024, 11, 5, 10, 6, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461263490, 'issue_id': 2634978973, 'author': 'unnyns-307', 'body': '@paoliniluis Hi, thank you so much for checking on this. We need some information to track and understand the issue better.\nWould you mind elaborating us a bit more what is the root cause of this issue and the issue was resolve in which version?', 'created_at': datetime.datetime(2024, 11, 7, 3, 51, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462427506, 'issue_id': 2634978973, 'author': 'paoliniluis', 'body': '@unnyns-307 my bad, this is a duplicate of https://github.com/metabase/metabase/issues/33037', 'created_at': datetime.datetime(2024, 11, 7, 14, 49, 14, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-05 10:06:14 UTC): We fixed this probably in a more recent version, please upgrade

unnyns-307 (Issue Creator) on (2024-11-07 03:51:38 UTC): @paoliniluis Hi, thank you so much for checking on this. We need some information to track and understand the issue better.
Would you mind elaborating us a bit more what is the root cause of this issue and the issue was resolve in which version?

paoliniluis on (2024-11-07 14:49:14 UTC): @unnyns-307 my bad, this is a duplicate of https://github.com/metabase/metabase/issues/33037

"
2634964238,issue,closed,completed,"""Keep data pivoted"" option is not retained in dashboard subscription settings","### Describe the bug

When configuring email subscriptions for a dashboard containing a question with a pivot table visualization, the ""Keep data pivoted"" option does not remain selected. 

### To Reproduce

1. Create a GUI question with a pivot table viz and add it to a dashboard
2. Save the dashboard
3. In the dashboard, go to: Sharing > Subscriptions > Email it,
- set **Attach results as files**
- check the question to be sent as an attachment
- set **Keep data pivoted**
3. Click **Send email now**
4. (!) In the email, the attachment does not have a pivoted format
5. Click **Done**
6. (!) Open the subscription settings again and see that the **Keep data pivoted** option is unchecked


### Expected behavior

The *Keep data pivoted* option should stay checked in subscription settings and the attachment should be in pivoted format as specified.

### Logs

_No response_

### Information about your Metabase installation

Customer reported this in: 1.51.1, reproduced in: 1.51.1.8 .

### Severity

Blocking for users expecting to send pivoted attachments

### Additional context

_No response_",zbodi74,2024-11-05 09:51:44+00:00,[],2024-11-08 22:31:56+00:00,2024-11-08 21:06:25+00:00,https://github.com/metabase/metabase/issues/49525,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Alerts', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]",[],
2634862818,issue,closed,not_planned,"Clicking ""Add series to breakout"" crashes the visualisation options editor","### Describe the bug

Introduced in https://github.com/metabase/metabase/pull/48265
Related to https://github.com/metabase/metabase/issues/49529

The viz settings editor crashes when selecting `Add series to breakout` for specific query.

This happens on `master` at 518e79b8fb292ba17b402042b05ccdfb64b30ad6. 

https://github.com/user-attachments/assets/b47c0d3d-9d66-4d8a-804f-babc1a3005be

### To Reproduce

To reproduce:

1. New > Question > Orders > Visualize
3. Visualize or Save the question
4. Pick any visualization that allows breakouts (Row, Bar, Line, ...)
5. In the viz settings, for the X-Axis (or Y-axis, depending on the viz type) pick `main_group`.
6. Click `Add series breakout`

❌ The viz settings editor crashes
❌ The problem persists after reloading the page

The following error is displayed in the browser console:

```
TypeError: transformedSeries is undefined
    getHidden graph.js:173
    getSettingWidget settings.js:150
    getSettingsWidgets settings.js:189
    getSettingsWidgets settings.js:189
    getSettingsWidgetsForSeries visualization.js:118
    widgets QuestionChartSettings.tsx:22
    React 3
    QuestionChartSettings QuestionChartSettings.tsx:22
```

coming from [ChartSettingSeriesOrder.tsx#L83](https://github.com/metabase/metabase/blob/9b4d3d2b2ebb24975ed8a673f86e15d9417d1215/frontend/src/metabase/visualizations/components/settings/ChartSettingSeriesOrder.tsx#L83).

### Expected behavior

The viz editor should not crash and allow me to pick `sub_group` as a breakout.



### Logs

Labelled it as P1 because there is no workaround. It might be limited to this pathological SQL query however, so feel free to bump the priority down.

### Information about your Metabase installation

<details>

<summary>Installation Details</summary>

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:132.0) Gecko/20100101 Firefox/132.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-11-04"",
      ""src_hash"": ""cc7c5fadd76698e2f7a64d1eafd541abbdc5698e"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""516f03f""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.20.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.20.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.20.1+1"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.6.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Australia/Melbourne""
  }
}
```

</details>

### Severity

P1",romeovs,2024-11-05 09:10:20+00:00,[],2024-11-21 21:42:56+00:00,2024-11-21 21:42:54+00:00,https://github.com/metabase/metabase/issues/49523,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2457350672, 'issue_id': 2634862818, 'author': 'ranquild', 'body': 'Most likely caused by recent SDK-related changes', 'created_at': datetime.datetime(2024, 11, 5, 14, 38, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492397739, 'issue_id': 2634862818, 'author': 'cdeweyx', 'body': 'Closing as dupe of https://github.com/metabase/metabase/issues/49529', 'created_at': datetime.datetime(2024, 11, 21, 21, 42, 54, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-05 14:38:26 UTC): Most likely caused by recent SDK-related changes

cdeweyx on (2024-11-21 21:42:54 UTC): Closing as dupe of https://github.com/metabase/metabase/issues/49529

"
2634037636,issue,open,,"Trend: ""Group only by a time field to see how this has changed over time""","### Describe the bug

Getting an error ""Group only by a time field to see how this has changed over time"" when trying to make Trend chart.

![Image](https://github.com/user-attachments/assets/f1aa2e88-28ec-4325-9eb4-2a265f734056)

![Image](https://github.com/user-attachments/assets/6175d08d-3a29-4a53-a3fc-fff60356fd90)

- In the sample database (H2), the issue does not occur, only in MSSQL and Postgres
- If I convert question to SQL it works!

![Image](https://github.com/user-attachments/assets/e47361ae-6476-4f97-a4df-ce86848ff129)


### To Reproduce

- Go to New Question and summarize group by a time field.
- Select ""Trend""



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

You're on version v0.50.31
Built on 2024-10-22


### Severity

Medium

### Additional context

_No response_",vidz1979,2024-11-04 23:00:08+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/49515,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2457342386, 'issue_id': 2634037636, 'author': 'ranquild', 'body': 'Based on code it could happen only if `insights` is missing from query results', 'created_at': datetime.datetime(2024, 11, 5, 14, 35, 20, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-05 14:35:20 UTC): Based on code it could happen only if `insights` is missing from query results

"
2633911024,issue,closed,not_planned,"Dashboard embedding - passing a value into an editable field, makes the filter widget disappear","### Describe the bug

We have a dashboard with two editable mandatory fields:

- start_date
- end_date

![Image](https://github.com/user-attachments/assets/997c7de5-c971-4665-9d84-024908ca6021)

if set from the requesting code:

```python
params={
            # for whatever reason, setting this make them disappear from the widget, even though, as per the documentation, they should be ok
            ""start_date"": start_date.strftime(""%Y-%m-%d""),
            ""end_date"": end_date.strftime(""%Y-%m-%d""),
        },
```

they are applied, but the settings are not changeable by the user:

![Image](https://github.com/user-attachments/assets/6a9ef3c8-08b4-45bd-9694-68cd05720b67)


if we are not passing them, they are correctly shown:

```python
params={
            ""project_id"": metabase_project_id,
        },
```

![Image](https://github.com/user-attachments/assets/ab2bb126-745c-4c05-b120-a3d91eeed412)



### To Reproduce

1. Create a question that uses two variables `start_date`, `end_date`
2. Add the question to the dashboard
3. Add two filters:
     1. Date Picker, Single Date, and apply it to the questions
4. Make the dashboard embeddable
5. Set the two parameters as `Editable`
6. Try and embed them with and without passed in variables

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""sqlite""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v0.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8-post-Ubuntu-1ubuntu320.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8-post-Ubuntu-1ubuntu320.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1071-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  }
}

### Severity

Blocking the correct usage of the embedded dashboards

### Additional context

_No response_",berill,2024-11-04 21:42:51+00:00,[],2024-11-05 15:51:32+00:00,2024-11-05 15:13:11+00:00,https://github.com/metabase/metabase/issues/49508,"[('Type:Bug', 'Product defects'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Backend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2457336055, 'issue_id': 2633911024, 'author': 'ranquild', 'body': ""This looks like the expected behavior to me - you can't change values in the jwt token. To be confirmed with Product"", 'created_at': datetime.datetime(2024, 11, 5, 14, 32, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457436142, 'issue_id': 2633911024, 'author': 'mngr', 'body': ""Yes, this is what happens when you pass parameter values in the jwt token, as explained [here](https://www.metabase.com/learn/metabase-basics/embedding/securing-embeds).\nTo pass the default filter values but allow editing it's possible either to set them [in the dashboard settings](https://www.metabase.com/docs/latest/dashboards/filters#set-a-default-filter-value) or [in the url](https://www.metabase.com/docs/latest/embedding/static-embedding-parameters#populating-an-embedded-filter-widget-with-a-default-value)."", 'created_at': datetime.datetime(2024, 11, 5, 15, 12, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457535558, 'issue_id': 2633911024, 'author': 'berill', 'body': 'Hi @ranquild ,\n\nthanks for the quick turn around on this; you can even see from the documentation that it is not what is ""expected"":\n\n- ""locked"": hidden from end-users but you can set their values from the app\n- ""editable"": so end users can see them and modify them\n\nHow do you propose for us to then give them a default start and end date which is relative to now (can\'t do relative on single date field defaults) and that they can edit as they please?', 'created_at': datetime.datetime(2024, 11, 5, 15, 48, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457549447, 'issue_id': 2633911024, 'author': 'berill', 'body': 'Sorry, had replied before the UI updated with @mngr reply. Will try the URL way, thanks!', 'created_at': datetime.datetime(2024, 11, 5, 15, 51, 31, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-05 14:32:41 UTC): This looks like the expected behavior to me - you can't change values in the jwt token. To be confirmed with Product

mngr on (2024-11-05 15:12:58 UTC): Yes, this is what happens when you pass parameter values in the jwt token, as explained [here](https://www.metabase.com/learn/metabase-basics/embedding/securing-embeds).
To pass the default filter values but allow editing it's possible either to set them [in the dashboard settings](https://www.metabase.com/docs/latest/dashboards/filters#set-a-default-filter-value) or [in the url](https://www.metabase.com/docs/latest/embedding/static-embedding-parameters#populating-an-embedded-filter-widget-with-a-default-value).

berill (Issue Creator) on (2024-11-05 15:48:41 UTC): Hi @ranquild ,

thanks for the quick turn around on this; you can even see from the documentation that it is not what is ""expected"":

- ""locked"": hidden from end-users but you can set their values from the app
- ""editable"": so end users can see them and modify them

How do you propose for us to then give them a default start and end date which is relative to now (can't do relative on single date field defaults) and that they can edit as they please?

berill (Issue Creator) on (2024-11-05 15:51:31 UTC): Sorry, had replied before the UI updated with @mngr reply. Will try the URL way, thanks!

"
2633613597,issue,closed,completed,"[T2] Add Data Discoverability: Easy-to-discover ""Upload CSV"" button","## Links
- [Product doc](https://www.notion.so/metabase/Better-Onboarding-pt-2-Add-Data-discoverability-12769354c90180fb9579f11ce55e7ef2?pvs=4#13469354c90180789b26caedec2363e7)
- [Figma](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=7095-37060&m=dev)
- Feature branch: `t2-add-data-upload-csv`
- Previous implementation: https://github.com/metabase/metabase/pull/43511
## Implementation Plan
Bring back the ""Upload CSV"" button in the main menu for the users with Metabase Storage (DWH) only.

```[tasklist]
### Testing Plan
- [x] Make sure the button doesn't render on instances without DWH attached
- [x] DWH attached: Make sure the button renders for admins
- [x] DWH attached: Make sure the button renders for non-admins who have sufficient permissions (root collection curate permission + `canUpload` on the DWH)
```",nemanjaglumac,2024-11-04 19:02:52+00:00,['nemanjaglumac'],2024-11-26 18:51:46+00:00,2024-11-07 14:50:21+00:00,https://github.com/metabase/metabase/issues/49500,[],[],
2633606405,issue,closed,completed,"[T1] Add Data discoverability: ""Add database"" button in the main navbar","## Links
[Product doc](https://www.notion.so/metabase/Better-Onboarding-pt-2-Add-Data-discoverability-12769354c90180fb9579f11ce55e7ef2?pvs=4#12769354c9018072ad59ffd9a425d6e3)
Figma
- [+Add button](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6972-13606&m=dev)
- [Add database button](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6972-13607&m=dev)
Feature branch: TBD

## Implementation Plan
1. Implement ""Add database"" button in a main sidebar below the ""Browse"" section
2. Implement ""Add database"" _card_ in a `/browse/databases` page

### Testing Plan
```[tasklist]
#### ""Add database"" button
- [x] Should not render for regular users
- [x] Should render for admins
- [x] Should render only when no additional database has been added
- [x] Should not render for DWH instances
- [x] Make sure Snowplow events are triggered on click
```

```[tasklist]
#### ""Add database"" card
- [x] should not render for regular users
- [x] should render for admins
- [x] should render when no databases exist
- [x] Make sure Snowplow events are triggered on click
```",nemanjaglumac,2024-11-04 18:58:58+00:00,['nemanjaglumac'],2024-11-26 18:51:36+00:00,2024-11-09 12:26:00+00:00,https://github.com/metabase/metabase/issues/49499,[],[],
2633592706,issue,closed,completed,"[MS3] Better Onboarding: ""Add Data"" discoverability","This epic is a follow up after some initial impressions and insights from #48335 and #48325.

## Links
[Product doc](https://www.notion.so/metabase/Better-Onboarding-pt-2-Add-Data-discoverability-12769354c90180fb9579f11ce55e7ef2)
[Figma](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=7095-37060&node-type=section&m=dev)
feature branch: TBD

## Implementation Plan
Break down the existing ""Add data"" section (main nav footer) into two separate units:
1. [Add database](https://www.notion.so/metabase/Better-Onboarding-pt-2-Add-Data-discoverability-12769354c90180fb9579f11ce55e7ef2?pvs=4#12769354c9018072ad59ffd9a425d6e3)
2. [Upload CSV button](https://www.notion.so/metabase/Better-Onboarding-pt-2-Add-Data-discoverability-12769354c90180fb9579f11ce55e7ef2?pvs=4#13469354c90180789b26caedec2363e7) (visible only to customers with the Metabase Storage)",nemanjaglumac,2024-11-04 18:53:01+00:00,['nemanjaglumac'],2024-11-11 09:11:39+00:00,2024-11-09 12:26:01+00:00,https://github.com/metabase/metabase/issues/49498,[],[],
2633586568,issue,closed,completed,Upgrade to 51.1 failed due to a migration error,"### Describe the bug

Upgrading from 0.49.17 to 0.51.1 failed with the following error

2024-11-04 18:42:12,286 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 18:42:12,611 INFO db.setup :: Running Database Migrations...
2024-11-04 18:42:12,613 INFO db.setup :: Setting up Liquibase...
2024-11-04 18:42:12,948 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 18:42:12,982 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-11-04 18:42:13,008 INFO liquibase.lockservice :: Successfully acquired change log lock
2024-11-04 18:42:13,010 INFO db.liquibase :: No migration lock found.
2024-11-04 18:42:13,011 INFO db.liquibase :: Migration lock acquired.
2024-11-04 18:42:13,041 INFO liquibase.lockservice :: Successfully released change log lock
2024-11-04 18:42:13,073 ERROR metabase.core :: Metabase Initialization FAILED
java.sql.BatchUpdateException: (conn=53968) Duplicate entry 'v00.00-000-qnkhuat-migrations/001_update_migrations.yaml' for key 'idx_databasechangelog_id_author_filename'
	at org.mariadb.jdbc.MariaDbStatement.executeBatchExceptionEpilogue(MariaDbStatement.java:323)
	at org.mariadb.jdbc.ClientSidePreparedStatement.executeBatch(ClientSidePreparedStatement.java:299)
	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeBatch(NewProxyPreparedStatement.java:2544)
	at clojure.java.jdbc$execute_batch.invokeStatic(jdbc.clj:598)


### To Reproduce

Upgrading from 0.49.17 to 0.51.1 


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Database: MariaDB

### Severity

P1

### Additional context

_No response_",digarcia78,2024-11-04 18:50:02+00:00,['johnswanson'],2024-11-21 19:10:40+00:00,2024-11-21 18:26:21+00:00,https://github.com/metabase/metabase/issues/49497,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2455522613, 'issue_id': 2633586568, 'author': 'paoliniluis', 'body': 'What version of mariadb?', 'created_at': datetime.datetime(2024, 11, 4, 19, 24, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455724980, 'issue_id': 2633586568, 'author': 'digarcia78', 'body': '10.6.15', 'created_at': datetime.datetime(2024, 11, 4, 21, 20, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455730901, 'issue_id': 2633586568, 'author': 'digarcia78', 'body': 'Version: 0.49.25\n\n2024-11-04 21:20:28,178 INFO db.liquibase :: Ejecutando 13 migraciones ...\n2024-11-04 21:20:28,674 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries encountered an exception.\n\nUPDATE SUMMARY\nRun:                         13\nPreviously run:             320\nFiltered out:                 5\n-------------------------------\nTotal change sets:          338\n\n\nFILTERED CHANGE SETS SUMMARY\nDBMS mismatch:                5\n\n2024-11-04 21:20:28,772 ERROR metabase.core :: La inicialización de Metabase ha FALLADO\nliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries:\n     Reason: liquibase.exception.DatabaseException: (conn=56584) Can\'t create table `metabase`.`metabase_field` (errno: 121 ""Duplicate key on write or update"") [Failed SQL: (1005) ALTER TABLE `metabase`.`metabase_field` ADD CONSTRAINT `fk_field_parent_ref_field_id` FOREIGN KEY (`parent_id`) REFERENCES `metabase`.`metabase_field` (`id`) ON DELETE RESTRICT]\n\tat liquibase.command.CommandScope.execute(CommandScope.java:253)\n\tat liquibase.Liquibase.lambda$update$0(Liquibase.java:245)\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\n\tat liquibase.Scope.child(Scope.java:195)\n\tat liquibase.Scope.child(Scope.java:185)\n\tat liquibase.Scope.child(Scope.java:164)\n\tat liquibase.Liquibase.runInScope(Liquibase.java:1419)\n\tat liquibase.Liquibase.update(Liquibase.java:234)\n\tat liquibase.Liquibase.update(Liquibase.java:212)\n\tat liquibase.Liquibase.update(Liquibase.java:194)\n\tat metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)\n\tat metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)\n\tat metabase.db.setup$migrate_BANG_$fn__51646.invoke(setup.clj:80)\n\tat metabase.db.liquibase$do_with_liquibase$f_STAR___49147.invoke(liquibase.clj:139)\n\tat metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)\n\tat metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)\n\tat metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)\n\tat metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)\n\tat clojure.lang.RestFn.invoke(RestFn.java:445)\n\tat metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)\n\tat metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)\n\tat metabase.db.setup$setup_db_BANG_$fn__51674$fn__51675.invoke(setup.clj:165)\n\tat metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)\n\tat metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)\n\tat metabase.db.setup$setup_db_BANG_$fn__51674.invoke(setup.clj:160)\n\tat metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)\n\tat metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)\n\tat metabase.db$setup_db_BANG_$fn__51694.invoke(db.clj:69)\n\tat metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)\n\tat metabase.db$setup_db_BANG_.invoke(db.clj:55)\n\tat metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)\n\tat metabase.core$init_BANG__STAR_.invoke(core.clj:101)\n\tat metabase.core$init_BANG_.invokeStatic(core.clj:159)\n\tat metabase.core$init_BANG_.invoke(core.clj:154)\n\tat metabase.core$start_normally.invokeStatic(core.clj:171)\n\tat metabase.core$start_normally.invoke(core.clj:165)\n\tat metabase.core$entrypoint.invokeStatic(core.clj:204)\n\tat metabase.core$entrypoint.doInvoke(core.clj:198)\n\tat clojure.lang.RestFn.invoke(RestFn.java:397)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\n\tat clojure.lang.Var.applyTo(Var.java:705)\n\tat clojure.core$apply.invokeStatic(core.clj:667)\n\tat clojure.core$apply.invoke(core.clj:662)\n\tat metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)\n\tat metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)\n\tat clojure.lang.RestFn.invoke(RestFn.java:397)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\n\tat metabase.bootstrap.main(Unknown Source)\nCaused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries:\n     Reason: liquibase.exception.DatabaseException: (conn=56584) Can\'t create table `metabase`.`metabase_field` (errno: 121 ""Duplicate key on write or update"") [Failed SQL: (1005) ALTER TABLE `metabase`.`metabase_field` ADD CONSTRAINT `fk_field_parent_ref_field_id` FOREIGN KEY (`parent_id`) REFERENCES `metabase`.`metabase_field` (`id`) ON DELETE RESTRICT]\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)\n\tat liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\n\tat liquibase.Scope.child(Scope.java:195)\n\tat liquibase.Scope.child(Scope.java:185)\n\tat liquibase.Scope.child(Scope.java:164)\n\tat liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)\n\tat liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)\n\tat liquibase.command.CommandScope.execute(CommandScope.java:217)', 'created_at': datetime.datetime(2024, 11, 4, 21, 23, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459723588, 'issue_id': 2633586568, 'author': 'crisptrutski', 'body': ""Unfortunately I'm struggling to reproduce. I've tried the following, using the same MariaDB version:\n\n1. Installing v1.49.7 with an empty database, migrating to the latest 51 release.\n2. Installing v47 (before we merged the migrations), migrating to 1.49.7, then to 51.\n\nCould I get a dump of your `databasechangelog` table to investigate further?"", 'created_at': datetime.datetime(2024, 11, 6, 13, 14, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459728599, 'issue_id': 2633586568, 'author': 'crisptrutski', 'body': ""Something that jumps out is that both the failing migrations predate v51, so I'm not sure whether this should be tagged as a release blocker. Especially in the first case, seeing that it is failing on the very first migration post the v47 roll-up, makes it sound like the database was already corrupted in some case, presumably through a bug in an earlier release, or manual changes made to the db."", 'created_at': datetime.datetime(2024, 11, 6, 13, 16, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459830882, 'issue_id': 2633586568, 'author': 'paoliniluis', 'body': ""@digarcia78 you downgraded the version without restoring a database backup? I'm talking about the second log you sent"", 'created_at': datetime.datetime(2024, 11, 6, 13, 59, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459869054, 'issue_id': 2633586568, 'author': 'digarcia78', 'body': 'I was then able to install v0.50.2. How do I proceed to upgrade to a new version? Once a version is installed, can I revert to a previous or newer version?', 'created_at': datetime.datetime(2024, 11, 6, 14, 15, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467407614, 'issue_id': 2633586568, 'author': 'crisptrutski', 'body': '> Could I get a dump of your databasechangelog table to investigate further?\n\nAre you able to provide this? It would be invaluable to diagnosing the issue.', 'created_at': datetime.datetime(2024, 11, 11, 7, 19, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469013490, 'issue_id': 2633586568, 'author': 'digarcia78', 'body': ""I'm closing this issue because I couldn't reproduce it when updating to the new version. Thanks"", 'created_at': datetime.datetime(2024, 11, 11, 21, 1, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488953513, 'issue_id': 2633586568, 'author': 'ofinsterbusch', 'body': ""Hey, I'm also having the same issue upgrading 0.50.4 to 0.51.x. \n\nI can provide logs and databasechangelog dump if you need and reopen the issue"", 'created_at': datetime.datetime(2024, 11, 20, 15, 52, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490113873, 'issue_id': 2633586568, 'author': 'crisptrutski', 'body': 'Thanks, please provide those details so we can look into it further', 'created_at': datetime.datetime(2024, 11, 21, 5, 29, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490733534, 'issue_id': 2633586568, 'author': 'ofinsterbusch', 'body': ""I've attached a CSV, if you prefer another format just let me know.\n[DATABASECHANGELOG.csv](https://github.com/user-attachments/files/17844115/DATABASECHANGELOG.csv)\n\nSome of the errors I'm seen in the logs is: \n\n2024-11-20T14:34:52.551452+00:00 server metabase[1599023]: 2024-11-20 14:34:52,541 ERROR metabase.core :: Metabase Initialization FAILED\n2024-11-20T14:34:52.551611+00:00 server metabase[1599023]: liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-05-29T18:42:14::johnswanson:\n2024-11-20T14:34:52.551681+00:00 server metabase[1599023]:      Reason: liquibase.exception.DatabaseException: (conn=1030077) In recursive query block of Recursive Common Table Expression 'parent', the recursive table must neither be in the right argument of a LEFT JOIN, nor be forced to be non-first with join order hints [Failed SQL: (3576) -- Set `collection.archive_operation_id` for descendants of collections that were archived directly\n2024-11-20T14:34:52.551728+00:00 server metabase[1599023]: WITH RECURSIVE Ancestors (id, archived, archived_directly, archive_operation_id, location) AS (\n2024-11-20T14:34:52.551762+00:00 server metabase[1599023]:   SELECT\n2024-11-20T14:34:52.551795+00:00 server metabase[1599023]:     id,\n2024-11-20T14:34:52.551827+00:00 server metabase[1599023]:     archived,\n2024-11-20T14:34:52.551860+00:00 server metabase[1599023]:     archived_directly,\n2024-11-20T14:34:52.551894+00:00 server metabase[1599023]:     archive_operation_id,\n2024-11-20T14:34:52.551927+00:00 server metabase[1599023]:     location\n2024-11-20T14:34:52.551958+00:00 server metabase[1599023]:   FROM\n2024-11-20T14:34:52.551991+00:00 server metabase[1599023]:     collection\n2024-11-20T14:34:52.552023+00:00 server metabase[1599023]:   WHERE\n2024-11-20T14:34:52.552056+00:00 server metabase[1599023]:     archived_directly = true\n2024-11-20T14:34:52.552089+00:00 server metabase[1599023]:     AND archived = true\n2024-11-20T14:34:52.552122+00:00 server metabase[1599023]:   UNION ALL\n2024-11-20T14:34:52.552150+00:00 server metabase[1599023]:   SELECT\n2024-11-20T14:34:52.552179+00:00 server metabase[1599023]:     collection.id,\n2024-11-20T14:34:52.552213+00:00 server metabase[1599023]:     collection.archived,\n2024-11-20T14:34:52.552259+00:00 server metabase[1599023]:     collection.archived_directly,\n2024-11-20T14:34:52.552288+00:00 server metabase[1599023]:     parent.archive_operation_id,\n2024-11-20T14:34:52.552316+00:00 server metabase[1599023]:     collection.location\n2024-11-20T14:34:52.552351+00:00 server metabase[1599023]:     FROM collection\n2024-11-20T14:34:52.552390+00:00 server metabase[1599023]:     JOIN Ancestors parent ON collection.location = concat(parent.location, parent.id, '/')\n2024-11-20T14:34:52.552430+00:00 server metabase[1599023]:   WHERE collection.archived = true\n2024-11-20T14:34:52.552468+00:00 server metabase[1599023]: )\n2024-11-20T14:34:52.552495+00:00 server metabase[1599023]: UPDATE collection\n2024-11-20T14:34:52.552524+00:00 server metabase[1599023]: JOIN Ancestors ancestor ON collection.id = ancestor.id\n2024-11-20T14:34:52.552554+00:00 server metabase[1599023]: SET collection.archive_operation_id = ancestor.archive_operation_id, collection.archived_directly = false\n2024-11-20T14:34:52.552586+00:00 server metabase[1599023]: WHERE collection.archive_operation_id IS NULL AND collection.archived = true]"", 'created_at': datetime.datetime(2024, 11, 21, 10, 28, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490740547, 'issue_id': 2633586568, 'author': 'crisptrutski', 'body': ""I'm passing this onto the engineer that wrote the migration to investigate"", 'created_at': datetime.datetime(2024, 11, 21, 10, 31, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491453167, 'issue_id': 2633586568, 'author': 'johnswanson', 'body': ""@ofinsterbusch from the error it looks like you're using MySQL, correct? What version of MySQL are you using?"", 'created_at': datetime.datetime(2024, 11, 21, 14, 56, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491597042, 'issue_id': 2633586568, 'author': 'ofinsterbusch', 'body': 'Yes, Mysql 8.0', 'created_at': datetime.datetime(2024, 11, 21, 15, 49, 1, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-04 19:24:17 UTC): What version of mariadb?

digarcia78 (Issue Creator) on (2024-11-04 21:20:25 UTC): 10.6.15

digarcia78 (Issue Creator) on (2024-11-04 21:23:55 UTC): Version: 0.49.25

2024-11-04 21:20:28,178 INFO db.liquibase :: Ejecutando 13 migraciones ...
2024-11-04 21:20:28,674 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries encountered an exception.

UPDATE SUMMARY
Run:                         13
Previously run:             320
Filtered out:                 5
-------------------------------
Total change sets:          338


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:                5

2024-11-04 21:20:28,772 ERROR metabase.core :: La inicialización de Metabase ha FALLADO
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries:
     Reason: liquibase.exception.DatabaseException: (conn=56584) Can't create table `metabase`.`metabase_field` (errno: 121 ""Duplicate key on write or update"") [Failed SQL: (1005) ALTER TABLE `metabase`.`metabase_field` ADD CONSTRAINT `fk_field_parent_ref_field_id` FOREIGN KEY (`parent_id`) REFERENCES `metabase`.`metabase_field` (`id`) ON DELETE RESTRICT]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
	at metabase.db.setup$migrate_BANG_$fn__51646.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___49147.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
	at clojure.lang.RestFn.invoke(RestFn.java:445)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
	at metabase.db.setup$setup_db_BANG_$fn__51674$fn__51675.invoke(setup.clj:165)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__51674.invoke(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__51694.invoke(db.clj:69)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
	at metabase.core$init_BANG_.invoke(core.clj:154)
	at metabase.core$start_normally.invokeStatic(core.clj:171)
	at metabase.core$start_normally.invoke(core.clj:165)
	at metabase.core$entrypoint.invokeStatic(core.clj:204)
	at metabase.core$entrypoint.doInvoke(core.clj:198)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries:
     Reason: liquibase.exception.DatabaseException: (conn=56584) Can't create table `metabase`.`metabase_field` (errno: 121 ""Duplicate key on write or update"") [Failed SQL: (1005) ALTER TABLE `metabase`.`metabase_field` ADD CONSTRAINT `fk_field_parent_ref_field_id` FOREIGN KEY (`parent_id`) REFERENCES `metabase`.`metabase_field` (`id`) ON DELETE RESTRICT]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)

crisptrutski on (2024-11-06 13:14:20 UTC): Unfortunately I'm struggling to reproduce. I've tried the following, using the same MariaDB version:

1. Installing v1.49.7 with an empty database, migrating to the latest 51 release.
2. Installing v47 (before we merged the migrations), migrating to 1.49.7, then to 51.

Could I get a dump of your `databasechangelog` table to investigate further?

crisptrutski on (2024-11-06 13:16:35 UTC): Something that jumps out is that both the failing migrations predate v51, so I'm not sure whether this should be tagged as a release blocker. Especially in the first case, seeing that it is failing on the very first migration post the v47 roll-up, makes it sound like the database was already corrupted in some case, presumably through a bug in an earlier release, or manual changes made to the db.

paoliniluis on (2024-11-06 13:59:49 UTC): @digarcia78 you downgraded the version without restoring a database backup? I'm talking about the second log you sent

digarcia78 (Issue Creator) on (2024-11-06 14:15:02 UTC): I was then able to install v0.50.2. How do I proceed to upgrade to a new version? Once a version is installed, can I revert to a previous or newer version?

crisptrutski on (2024-11-11 07:19:08 UTC): Are you able to provide this? It would be invaluable to diagnosing the issue.

digarcia78 (Issue Creator) on (2024-11-11 21:01:19 UTC): I'm closing this issue because I couldn't reproduce it when updating to the new version. Thanks

ofinsterbusch on (2024-11-20 15:52:46 UTC): Hey, I'm also having the same issue upgrading 0.50.4 to 0.51.x. 

I can provide logs and databasechangelog dump if you need and reopen the issue

crisptrutski on (2024-11-21 05:29:28 UTC): Thanks, please provide those details so we can look into it further

ofinsterbusch on (2024-11-21 10:28:43 UTC): I've attached a CSV, if you prefer another format just let me know.
[DATABASECHANGELOG.csv](https://github.com/user-attachments/files/17844115/DATABASECHANGELOG.csv)

Some of the errors I'm seen in the logs is: 

2024-11-20T14:34:52.551452+00:00 server metabase[1599023]: 2024-11-20 14:34:52,541 ERROR metabase.core :: Metabase Initialization FAILED
2024-11-20T14:34:52.551611+00:00 server metabase[1599023]: liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-05-29T18:42:14::johnswanson:
2024-11-20T14:34:52.551681+00:00 server metabase[1599023]:      Reason: liquibase.exception.DatabaseException: (conn=1030077) In recursive query block of Recursive Common Table Expression 'parent', the recursive table must neither be in the right argument of a LEFT JOIN, nor be forced to be non-first with join order hints [Failed SQL: (3576) -- Set `collection.archive_operation_id` for descendants of collections that were archived directly
2024-11-20T14:34:52.551728+00:00 server metabase[1599023]: WITH RECURSIVE Ancestors (id, archived, archived_directly, archive_operation_id, location) AS (
2024-11-20T14:34:52.551762+00:00 server metabase[1599023]:   SELECT
2024-11-20T14:34:52.551795+00:00 server metabase[1599023]:     id,
2024-11-20T14:34:52.551827+00:00 server metabase[1599023]:     archived,
2024-11-20T14:34:52.551860+00:00 server metabase[1599023]:     archived_directly,
2024-11-20T14:34:52.551894+00:00 server metabase[1599023]:     archive_operation_id,
2024-11-20T14:34:52.551927+00:00 server metabase[1599023]:     location
2024-11-20T14:34:52.551958+00:00 server metabase[1599023]:   FROM
2024-11-20T14:34:52.551991+00:00 server metabase[1599023]:     collection
2024-11-20T14:34:52.552023+00:00 server metabase[1599023]:   WHERE
2024-11-20T14:34:52.552056+00:00 server metabase[1599023]:     archived_directly = true
2024-11-20T14:34:52.552089+00:00 server metabase[1599023]:     AND archived = true
2024-11-20T14:34:52.552122+00:00 server metabase[1599023]:   UNION ALL
2024-11-20T14:34:52.552150+00:00 server metabase[1599023]:   SELECT
2024-11-20T14:34:52.552179+00:00 server metabase[1599023]:     collection.id,
2024-11-20T14:34:52.552213+00:00 server metabase[1599023]:     collection.archived,
2024-11-20T14:34:52.552259+00:00 server metabase[1599023]:     collection.archived_directly,
2024-11-20T14:34:52.552288+00:00 server metabase[1599023]:     parent.archive_operation_id,
2024-11-20T14:34:52.552316+00:00 server metabase[1599023]:     collection.location
2024-11-20T14:34:52.552351+00:00 server metabase[1599023]:     FROM collection
2024-11-20T14:34:52.552390+00:00 server metabase[1599023]:     JOIN Ancestors parent ON collection.location = concat(parent.location, parent.id, '/')
2024-11-20T14:34:52.552430+00:00 server metabase[1599023]:   WHERE collection.archived = true
2024-11-20T14:34:52.552468+00:00 server metabase[1599023]: )
2024-11-20T14:34:52.552495+00:00 server metabase[1599023]: UPDATE collection
2024-11-20T14:34:52.552524+00:00 server metabase[1599023]: JOIN Ancestors ancestor ON collection.id = ancestor.id
2024-11-20T14:34:52.552554+00:00 server metabase[1599023]: SET collection.archive_operation_id = ancestor.archive_operation_id, collection.archived_directly = false
2024-11-20T14:34:52.552586+00:00 server metabase[1599023]: WHERE collection.archive_operation_id IS NULL AND collection.archived = true]

crisptrutski on (2024-11-21 10:31:40 UTC): I'm passing this onto the engineer that wrote the migration to investigate

johnswanson (Assginee) on (2024-11-21 14:56:14 UTC): @ofinsterbusch from the error it looks like you're using MySQL, correct? What version of MySQL are you using?

ofinsterbusch on (2024-11-21 15:49:01 UTC): Yes, Mysql 8.0

"
2633548278,issue,closed,duplicate,Improve experience when working through query performance issues,"**Is your feature request related to a problem? Please describe.**
Once you have a very complex/resource-intensive query, can be difficult to improve upon it to make it run faster and perform better.
Each time you make changes to the query and try to see if the cost improved, you may need to download the explain results to see the new cost because it isn't exposed in the Metabase results. Related: https://github.com/metabase/metabase/issues/10007 

Would be even better if there were tools in Metabase to suggest query improvements. 

**Describe the solution you'd like**
- we could graphically signal how difficult a question will be by exposing the query cost that comes from the explain command
- we could send the sql query and query plan to an LLM so it gives recommendations to the user

The explain command takes milliseconds to run in the data warehouse, and we can quickly tell someone if their query will take a long time. 

**Describe alternatives you've considered**
- Manually downloading the query plan and editing the query to try and improve performance. 
  - slow, painful process 
- Materializing views
  - usually requires data engineers or people other than the analyst trying to write the query
  - might not make sense for every use case 
- change to a more efficient database for your type of analysis/query 
  - requires more resources
  - might not make sense for every use case

**How important is this feature to you?**
Would greatly improve the analyst experience when writing complex queries. 

",jessicaul,2024-11-04 18:30:07+00:00,[],2024-12-17 22:58:48+00:00,2024-12-17 22:58:47+00:00,https://github.com/metabase/metabase/issues/49496,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2549448202, 'issue_id': 2633548278, 'author': 'paoliniluis', 'body': ""@jessicaul isn't this the same as https://github.com/metabase/metabase/issues/10007?"", 'created_at': datetime.datetime(2024, 12, 17, 19, 38, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549828792, 'issue_id': 2633548278, 'author': 'jessicaul', 'body': 'Thanks Luis, closing this issue as a duplicate', 'created_at': datetime.datetime(2024, 12, 17, 22, 58, 47, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-12-17 19:38:08 UTC): @jessicaul isn't this the same as https://github.com/metabase/metabase/issues/10007?

jessicaul (Issue Creator) on (2024-12-17 22:58:47 UTC): Thanks Luis, closing this issue as a duplicate

"
2633404585,issue,open,,Can't drag personal-collection items into sidenav,To reproduce: drag an item from your personal collection into a different collection in the sidenav,rafpaf,2024-11-04 17:27:45+00:00,[],2024-11-04 17:28:18+00:00,,https://github.com/metabase/metabase/issues/49493,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround')]",[],
2633137973,issue,closed,completed,Return key triggers events outside of the Metabot,"### Describe the bug

When using the LLM Metabot in chill mode, since the `return` key is bound to show row details, it triggers _that_ every time I send a request.

### To Reproduce

1. Go to any table or model
2. Open the Metabot
3. Type anything
4. Hit `return`


### Expected behavior

We should probably stopEventPropagation or something when the user hits `return` in the Metabot text intput.

### Logs

_No response_

### Information about your Metabase installation

https://github.com/metabase/metabase/pull/48814 @ `8cbb0f4d442c71c733234c3954cfe11ee9d29a42`

### Severity

P1

### Additional context

_No response_",brunobergher,2024-11-04 15:33:44+00:00,['sloansparger'],2024-11-05 04:10:53+00:00,2024-11-05 04:10:52+00:00,https://github.com/metabase/metabase/issues/49488,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Metabot/UX', ""Metabot's user experience and chatbot"")]","[{'comment_id': 2456192743, 'issue_id': 2633137973, 'author': 'sloansparger', 'body': 'Fixed in `0dabbb8071451dbedca1ed83e6706061607b9ee3`', 'created_at': datetime.datetime(2024, 11, 5, 4, 10, 52, tzinfo=datetime.timezone.utc)}]","sloansparger (Assginee) on (2024-11-05 04:10:52 UTC): Fixed in `0dabbb8071451dbedca1ed83e6706061607b9ee3`

"
2633120196,issue,closed,completed,Check if use cases without multi-tenancy is supported in embedding cli,"The CLI used to require multi tenancy, which is likely a bug. We should quickly re-check and make sure the CLI works without multi-tenancy (i.e. it doesn't quit if you select ""no multi-tenancy""), as most people don't have that in their database.
",heypoom,2024-11-04 15:26:09+00:00,[],2024-11-08 09:03:57+00:00,2024-11-06 14:26:04+00:00,https://github.com/metabase/metabase/issues/49487,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]","[{'comment_id': 2459896914, 'issue_id': 2633120196, 'author': 'heypoom', 'body': 'Tested that we don\'t abort after multi-tenancy is not selected. Selecting ""no"" continues to the setup steps.', 'created_at': datetime.datetime(2024, 11, 6, 14, 26, 4, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-06 14:26:04 UTC): Tested that we don't abort after multi-tenancy is not selected. Selecting ""no"" continues to the setup steps.

"
2633118147,issue,closed,completed,Support falling back to sample database for users without a database in the embedding cli,"We should fallback to the sample database if the CLI user don't have a database. If the user selects ""no"" at the first step (asking if they have database credentials), then the CLI could produce a working instance and adds code samples to your project that works with the sample database.

This might help reduce drop-off on the CLI for users who don't want to enter their database credentials right away.",heypoom,2024-11-04 15:25:17+00:00,[],2024-11-08 09:03:32+00:00,2024-11-08 09:01:52+00:00,https://github.com/metabase/metabase/issues/49486,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2633112171,issue,closed,completed,Ask for database credentials as a first step in the embedding cli,"We should ask for database credentials first in the embedding cli, as if they don't have those they cannot proceed. Otherwise the CLI does a bunch of stuff, you wait a bit, then it fails.
",heypoom,2024-11-04 15:22:44+00:00,[],2024-11-08 09:03:50+00:00,2024-11-06 16:50:21+00:00,https://github.com/metabase/metabase/issues/49485,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2633088605,issue,closed,completed,MetabaseProvider should not reload the store when its parent component re-renders,"When the parent component re-renders, the underlying Metabase components under `MetabaseProvider` will show the loading indicator again. This happens in every re-render. This is caused by how we [re-create the store](https://github.com/metabase/metabase/pull/48071/files#r1776753555) by default in MetabaseProvider.

### How to reproduce

Try rendering this code snippet, and click on the `reload (+1)` button. You can see the loading spinner triggers every time you click the button. If you move the `store` variable to a singleton, this issue goes away.

```tsx
const Example = (props: Props) => {
  const [_, forceReload] = useReducer(x => x + 1, 0);

  return (
    <div style={{ padding: ""1rem"" }}>
      <button onClick={forceReload}>reload (+1)</button>
        <MetabaseProvider config={storybookSdkDefaultConfig}>
          <InteractiveQuestion {...props} />;
        </MetabaseProvider>
      </div>
    </div>
  );
}
```

### Related issues

This also causes an issue in the auth code PR (https://github.com/metabase/metabase/pull/49214), where the component shows ""Initializing..."" whenever we navigate back and forth between pages.

![Image](https://github.com/user-attachments/assets/c3faa6ca-4f74-4e4f-8ea0-f59ffda8bdff)
",heypoom,2024-11-04 15:12:58+00:00,[],2024-11-08 09:53:10+00:00,2024-11-08 09:50:48+00:00,https://github.com/metabase/metabase/issues/49482,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2464268239, 'issue_id': 2633088605, 'author': 'heypoom', 'body': 'Closing this as https://github.com/metabase/metabase/pull/49492 has been merged already, cc @npretto', 'created_at': datetime.datetime(2024, 11, 8, 9, 50, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464272708, 'issue_id': 2633088605, 'author': 'npretto', 'body': 'Thanks @heypoom , weird that it didn\'t pick up the ""Fixes"" keyword, [it should be a supported keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/using-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)', 'created_at': datetime.datetime(2024, 11, 8, 9, 53, 9, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-08 09:50:48 UTC): Closing this as https://github.com/metabase/metabase/pull/49492 has been merged already, cc @npretto

npretto on (2024-11-08 09:53:09 UTC): Thanks @heypoom , weird that it didn't pick up the ""Fixes"" keyword, [it should be a supported keyword](https://docs.github.com/en/issues/tracking-your-work-with-issues/using-issues/linking-a-pull-request-to-an-issue#linking-a-pull-request-to-an-issue-using-a-keyword)

"
2632478004,issue,closed,completed,Migration v0.49 to v0.50 or v0.51,"### Describe the bug

Long live before around release v0.46, we migrated from mysql to postgres.

Through upgrades we never encouter any issue upgrading until version v0.50.x and now v0.51.1, we are stuck with latest v0.49.25


![Image](https://github.com/user-attachments/assets/d1903813-3ae6-4843-9eac-ef9ff5c8130d)

![Image](https://github.com/user-attachments/assets/fe9c0c33-f4c0-4d51-944d-8fb49d40e45a)


2024-11-04 11:32:33,872 ERROR middleware.catch-exceptions :: Error processing query: Table ""degussa_data_collector.null.selenium_marktanalyse_wettbewerb"" is inactive.


### To Reproduce

Before
![Image](https://github.com/user-attachments/assets/65a8f81f-fa78-4d5e-9ccf-ea7932158f40)


1. Migrate from v0.49 to any v0.50.x or v0.51.1
2. Click to open the dashboard
3. See error

![Image](https://github.com/user-attachments/assets/12648494-8c83-49ab-a00b-728994a591b3)


### Expected behavior

Was supposed to show all diagrams after migration

### Logs

[adm_ds@dtvmli001 ~]$ docker compose up -d
[+] Running 8/8
 ✔ metabase Pulled                                                                                                                                                                                                                                                                                                     69.9s
   ✔ 43c4264eed91 Already exists                                                                                                                                                                                                                                                                                        0.0s
   ✔ fdc1ae931895 Pull complete                                                                                                                                                                                                                                                                                         3.1s
   ✔ d2178d1ac988 Pull complete                                                                                                                                                                                                                                                                                        13.1s
   ✔ 36fa798630fa Pull complete                                                                                                                                                                                                                                                                                        13.1s
   ✔ 125366907af1 Pull complete                                                                                                                                                                                                                                                                                        13.1s
   ✔ 6ba90bc32e13 Pull complete                                                                                                                                                                                                                                                                                        23.5s
   ✔ bcfafac31b1c Pull complete                                                                                                                                                                                                                                                                                        68.6s
[+] Running 5/5
 ✔ Container mariaDB         Running                                                                                                                                                                                                                                                                                    0.0s
 ✔ Container postgreSQL      Running                                                                                                                                                                                                                                                                                    0.0s
 ✔ Container nginx-metabase  Running                                                                                                                                                                                                                                                                                    0.0s
 ✔ Container watchtower      Running                                                                                                                                                                                                                                                                                    0.0s
 ✔ Container metabase        Started                                                                                                                                                                                                                                                                                    0.7s
[adm_ds@dtvmli001 ~]$ docker logs metabase
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
OpenJDK 64-Bit Server VM warning: Failed to reserve shared memory. (error = 1)
Warning: environ value jdk-11.0.24+8 for key :java-version has been overwritten with 11.0.24
2024-11-04 10:03:32,912 INFO metabase.util :: Maximum memory available to JVM: 7.8 GB
2024-11-04 10:03:35,592 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. 🔓
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-11-04 10:03:37,648 INFO i18n.impl :: Reading available locales from locales.clj...
WARNING: infinite? already refers to: #'kixi.stats.math/infinite? in namespace: kixi.stats.core, being replaced by: #'clojure.core/infinite?
2024-11-04 10:03:42,635 INFO driver.impl :: Registered abstract driver :sql  🚚
2024-11-04 10:03:42,689 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) 🚚
2024-11-04 10:03:42,698 INFO metabase.util :: Lade Treiber :sql-jdbc took 28.9 ms
2024-11-04 10:03:42,698 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:43,039 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:43,119 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:45,506 INFO metabase.core ::
Metabase v0.51.1 (b8178a8)

Copyright © 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-11-04 10:03:45,520 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-11-04 10:03:45,584 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

2024-11-04 10:03:45,642 INFO metabase.core :: Starting Metabase version v0.51.1 (b8178a8) ...
2024-11-04 10:03:45,648 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.24+8"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.24"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.24+8"",
 ""os.name"" ""Linux"",
 ""os.version"" ""4.18.0-553.22.1.el8_10.x86_64"",
 ""user.language"" ""en"",
 ""user.timezone"" ""Europe/Berlin""}

2024-11-04 10:03:45,651 INFO metabase.plugins :: Loading plugins in /plugins...
2024-11-04 10:03:45,843 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-11-04 10:03:45,873 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-11-04 10:03:46,152 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-11-04 10:03:46,241 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-11-04 10:03:46,249 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-11-04 10:03:46,624 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-11-04 10:03:46,626 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-11-04 10:03:46,630 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-11-04 10:03:46,680 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-11-04 10:03:46,682 INFO util.files :: Extract file /modules/hive-like.metabase-driver.jar -> /plugins/hive-like.metabase-driver.jar
2024-11-04 10:03:46,748 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-11-04 10:03:46,751 INFO util.files :: Extract file /modules/databricks.metabase-driver.jar -> /plugins/databricks.metabase-driver.jar
2024-11-04 10:03:46,873 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-11-04 10:03:46,935 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-11-04 10:03:46,956 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-11-04 10:03:47,258 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-11-04 10:03:47,266 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,286 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-11-04 10:03:47,287 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) 🚚
2024-11-04 10:03:47,301 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-11-04 10:03:47,302 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,307 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-11-04 10:03:47,307 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) 🚚
2024-11-04 10:03:47,341 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-11-04 10:03:47,341 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,345 INFO plugins.dependencies :: Plugin ""Metabase Spark SQL Driver"" hängt ab von Plugin ""Metabase Hive Like Abstract Driver""
2024-11-04 10:03:47,347 INFO plugins.dependencies :: Metabase Spark SQL Driver Abhängigkeit {:plugin Metabase Hive Like Abstract Driver} erfüllt? false
2024-11-04 10:03:47,348 INFO plugins.dependencies :: Plugins mit nicht erfüllten Abhängigkeiten: [""Metabase Spark SQL Driver""]
2024-11-04 10:03:47,351 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-11-04 10:03:47,351 INFO driver.impl :: Registered driver :druid  🚚
2024-11-04 10:03:47,356 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-11-04 10:03:47,356 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,359 INFO plugins.dependencies :: Metabase kann das Plugin Metabase Vertica Driver wegen benötigten Abhängigkeiten nicht initialisieren. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-11-04 10:03:47,360 INFO plugins.dependencies :: Metabase Vertica Driver Abhängigkeit {:class com.vertica.jdbc.Driver} erfüllt? false
2024-11-04 10:03:47,360 INFO plugins.dependencies :: Plugins mit nicht erfüllten Abhängigkeiten: [""Metabase Vertica Driver"" ""Metabase Spark SQL Driver""]
2024-11-04 10:03:47,366 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-11-04 10:03:47,366 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,367 INFO plugins.dependencies :: Metabase Spark SQL Driver Abhängigkeit {:plugin Metabase Hive Like Abstract Driver} erfüllt? true
2024-11-04 10:03:47,367 DEBUG plugins.initialize :: Dependencies satisfied; these plugins will now be loaded: [""Metabase Spark SQL Driver""]
2024-11-04 10:03:47,368 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-11-04 10:03:47,368 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) 🚚
2024-11-04 10:03:47,371 INFO plugins.dependencies :: Metabase kann das Plugin Metabase Oracle Driver wegen benötigten Abhängigkeiten nicht initialisieren. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-11-04 10:03:47,372 INFO plugins.dependencies :: Metabase Oracle Driver Abhängigkeit {:class oracle.jdbc.OracleDriver} erfüllt? false
2024-11-04 10:03:47,372 INFO plugins.dependencies :: Plugins mit nicht erfüllten Abhängigkeiten: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""]
2024-11-04 10:03:47,384 INFO plugins.dependencies :: Plugin ""Metabase Databricks Driver"" hängt ab von Plugin ""Metabase Hive Like Abstract Driver""
2024-11-04 10:03:47,385 INFO plugins.dependencies :: Metabase Databricks Driver Abhängigkeit {:plugin Metabase Hive Like Abstract Driver} erfüllt? true
2024-11-04 10:03:47,385 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :databricks...
2024-11-04 10:03:47,385 INFO driver.impl :: Registered driver :databricks (parents: [:hive-like]) 🚚
2024-11-04 10:03:47,395 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-11-04 10:03:47,396 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,401 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-11-04 10:03:47,401 INFO driver.impl :: Registered driver :mongo  🚚
2024-11-04 10:03:47,403 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-11-04 10:03:47,404 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
2024-11-04 10:03:47,412 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-11-04 10:03:47,414 INFO db.setup :: Verifying postgres Database Connection ...
2024-11-04 10:03:47,740 INFO db.setup :: Successfully verified PostgreSQL 16.4 application database connection. ✅
2024-11-04 10:03:47,741 INFO db.setup :: Checking if a database downgrade is required...
2024-11-04 10:03:47,887 INFO liquibase.database :: Set default schema name to public
2024-11-04 10:03:48,461 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 10:03:48,606 INFO db.setup :: Running Database Migrations...
2024-11-04 10:03:48,607 INFO db.setup :: Setting up Liquibase...
2024-11-04 10:03:48,617 INFO liquibase.database :: Set default schema name to public
2024-11-04 10:03:49,091 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 10:03:49,119 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-11-04 10:03:49,162 INFO liquibase.lockservice :: Successfully acquired change log lock
2024-11-04 10:03:49,164 INFO db.liquibase :: No migration lock found.
2024-11-04 10:03:49,164 INFO db.liquibase :: Migration lock acquired.
2024-11-04 10:03:49,186 INFO liquibase.lockservice :: Successfully released change log lock
2024-11-04 10:03:49,187 INFO db.setup :: Liquibase is ready.
2024-11-04 10:03:49,187 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-11-04 10:03:49,204 INFO liquibase.database :: Set default schema name to public
2024-11-04 10:03:49,351 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 10:03:49,387 INFO liquibase.changelog :: Reading from public.databasechangelog
2024-11-04 10:03:49,683 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-11-04 10:03:49,691 INFO liquibase.lockservice :: Successfully acquired change log lock
2024-11-04 10:03:49,692 INFO db.liquibase :: No migration lock found.
2024-11-04 10:03:49,692 INFO db.liquibase :: Migration lock acquired.
2024-11-04 10:03:49,699 INFO liquibase.database :: Set default schema name to public
2024-11-04 10:03:49,852 INFO liquibase :: Parsed changelog file 'liquibase.yaml'
2024-11-04 10:03:49,869 INFO liquibase.changelog :: Reading from public.databasechangelog
2024-11-04 10:03:49,968 INFO db.liquibase :: Running 50 migrations ...
2024-11-04 10:03:50,070 INFO liquibase.changelog :: Reading from public.databasechangelog
2024-11-04 10:03:50,206 INFO liquibase.command :: Using deploymentId: 0711030206
2024-11-04 10:03:50,209 INFO liquibase.changelog :: Reading from public.databasechangelog
2024-11-04 10:03:50,304 INFO liquibase.changelog :: Custom SQL executed
2024-11-04 10:03:50,306 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-14T12:42:42::johnswanson ran successfully in 57ms
2024-11-04 10:03:50,326 INFO liquibase.changelog :: Columns archived_directly(boolean) added to report_dashboard
2024-11-04 10:03:50,327 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T14:04:47::johnswanson ran successfully in 13ms
2024-11-04 10:03:50,334 INFO liquibase.changelog :: Columns archived_directly(boolean) added to report_card
2024-11-04 10:03:50,335 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T14:04:53::johnswanson ran successfully in 5ms
2024-11-04 10:03:50,341 INFO liquibase.changelog :: Columns archive_operation_id(char(36)) added to collection
2024-11-04 10:03:50,341 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T14:04:58::johnswanson ran successfully in 4ms
2024-11-04 10:03:50,347 INFO liquibase.changelog :: Columns archived_directly(boolean) added to collection
2024-11-04 10:03:50,347 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T14:05:01::johnswanson ran successfully in 3ms
2024-11-04 10:03:50,400 INFO liquibase.changelog :: SQL in file trash/postgres.sql executed
2024-11-04 10:03:50,401 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T14:05:03::johnswanson ran successfully in 51ms
2024-11-04 10:03:50,406 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T18:42:13::johnswanson ran successfully in 2ms
2024-11-04 10:03:50,409 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T18:42:14::johnswanson ran successfully in 1ms
2024-11-04 10:03:50,412 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-29T18:42:15::johnswanson ran successfully in 1ms
2024-11-04 10:03:50,418 INFO liquibase.changelog :: Columns dataset_query_metrics_v2_migration_backup(text) added to report_card
2024-11-04 10:03:50,419 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-05-13T15:30:57::metamben ran successfully in 4ms
2024-11-04 10:03:50,552 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateMetricsToV2
2024-11-04 10:03:50,553 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-05-13T16:00:00::metamben ran successfully in 131ms
2024-11-04 10:03:50,561 INFO liquibase.changelog :: Column query_field.direct_reference renamed to explicit_reference
2024-11-04 10:03:50,562 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-06-07T12:37:36::crisptrutski ran successfully in 6ms
2024-11-04 10:03:50,574 INFO liquibase.changelog :: Index idx_user_id_device_id dropped from table login_history
2024-11-04 10:03:50,593 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-06-12T18:53:02::noahmoss ran successfully in 28ms
2024-11-04 10:03:50,608 INFO liquibase.changelog :: Index idx_user_id_device_id created
2024-11-04 10:03:50,610 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-06-12T18:53:03::noahmoss ran successfully in 14ms
2024-11-04 10:03:50,617 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:50,767 INFO liquibase.changelog :: Table channel created
2024-11-04 10:03:50,769 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-08T10:00:00::qnkhuat ran successfully in 156ms
2024-11-04 10:03:50,783 INFO liquibase.changelog :: Columns channel_id(integer) added to pulse_channel
2024-11-04 10:03:50,784 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-08T10:00:01::qnkhuat ran successfully in 11ms
2024-11-04 10:03:51,638 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:51,651 INFO liquibase.changelog :: Foreign key constraint added to pulse_channel (channel_id)
2024-11-04 10:03:51,651 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-08T10:00:02::qnkhuat ran successfully in 865ms
2024-11-04 10:03:51,658 INFO liquibase.changelog :: Columns last_viewed_at(timestamp with time zone) added to report_dashboard
2024-11-04 10:03:51,658 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-10T12:28:10::johnswanson ran successfully in 4ms
2024-11-04 10:03:51,664 INFO liquibase.changelog :: Columns embedding_client(varchar(254)) added to query_execution
2024-11-04 10:03:51,665 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-22T15:49:37::escherize ran successfully in 5ms
2024-11-04 10:03:51,669 INFO liquibase.changelog :: Columns embedding_version(varchar(254)) added to query_execution
2024-11-04 10:03:51,670 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-22T15:49:38::escherize ran successfully in 4ms
2024-11-04 10:03:51,675 INFO liquibase.changelog :: Columns embedding_client(varchar(254)) added to view_log
2024-11-04 10:03:51,675 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-22T15:49:39::escherize ran successfully in 4ms
2024-11-04 10:03:51,679 INFO liquibase.changelog :: Columns embedding_version(varchar(254)) added to view_log
2024-11-04 10:03:51,680 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-22T15:49:40::escherize ran successfully in 4ms
2024-11-04 10:03:51,684 INFO liquibase.changelog :: Data deleted from query_field
2024-11-04 10:03:51,684 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-25T11:56:27::crisptrutski ran successfully in 3ms
2024-11-04 10:03:51,689 INFO liquibase.changelog :: Columns column(varchar(254)) added to query_field
2024-11-04 10:03:51,689 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-25T11:57:27::crisptrutski ran successfully in 3ms
2024-11-04 10:03:51,695 INFO liquibase.changelog :: Columns table(varchar(254)) added to query_field
2024-11-04 10:03:51,695 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-25T11:58:27::crisptrutski ran successfully in 5ms
2024-11-04 10:03:51,698 INFO liquibase.changelog :: Null constraint dropped from query_field.field_id
2024-11-04 10:03:51,699 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-25T12:02:21::crisptrutski ran successfully in 2ms
2024-11-04 10:03:51,703 INFO liquibase.changelog :: Columns table_id(int) added to query_field
2024-11-04 10:03:51,704 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-26T11:56:27::crisptrutski ran successfully in 4ms
2024-11-04 10:03:51,707 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:51,735 INFO liquibase.changelog :: Table query_analysis created
2024-11-04 10:03:51,736 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:22:12::crisptrutski ran successfully in 31ms
2024-11-04 10:03:51,740 INFO liquibase.changelog :: Index idx_query_analysis_card_id created
2024-11-04 10:03:51,740 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:23:12::crisptrutski ran successfully in 3ms
2024-11-04 10:03:51,744 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:51,774 INFO liquibase.changelog :: Table query_table created
2024-11-04 10:03:51,774 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:24:13::crisptrutski ran successfully in 32ms
2024-11-04 10:03:51,778 INFO liquibase.changelog :: Index idx_query_table_card_id created
2024-11-04 10:03:51,779 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:25:13::crisptrutski ran successfully in 3ms
2024-11-04 10:03:51,782 INFO liquibase.changelog :: Index idx_query_table_analysis_id created
2024-11-04 10:03:51,782 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:25:14::crisptrutski ran successfully in 2ms
2024-11-04 10:03:51,786 INFO liquibase.changelog :: Index idx_query_table_table_id created
2024-11-04 10:03:51,787 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T09:25:15::crisptrutski ran successfully in 3ms
2024-11-04 10:03:51,789 INFO liquibase.changelog :: Data deleted from query_field
2024-11-04 10:03:51,790 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T10:03:27::crisptrutski ran successfully in 2ms
2024-11-04 10:03:51,798 INFO liquibase.changelog :: Columns analysis_id(int) added to query_field
2024-11-04 10:03:51,798 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T10:04:13::crisptrutski ran successfully in 7ms
2024-11-04 10:03:51,802 INFO liquibase.changelog :: Index idx_query_field_analysis_id created
2024-11-04 10:03:51,802 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-07-29T11:25:13::crisptrutski ran successfully in 2ms
2024-11-04 10:03:51,807 INFO liquibase.changelog :: Columns schema(varchar(254)) added to query_field
2024-11-04 10:03:51,808 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-02T11:56:27::crisptrutski ran successfully in 4ms
2024-11-04 10:03:51,810 INFO liquibase.changelog :: Null constraint dropped from query_field.table
2024-11-04 10:03:51,810 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-02T12:02:21::crisptrutski ran successfully in 1ms
2024-11-04 10:03:51,815 INFO liquibase.changelog :: Columns source_card_id(int) added to report_card
2024-11-04 10:03:51,816 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-05T16:00:00::metamben ran successfully in 4ms
2024-11-04 10:03:51,820 INFO liquibase.changelog :: Foreign key constraint added to report_card (source_card_id)
2024-11-04 10:03:51,820 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-05T16:00:01::metamben ran successfully in 3ms
2024-11-04 10:03:51,831 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:51,837 INFO liquibase.changelog :: Index idx_report_card_source_card_id created
2024-11-04 10:03:51,837 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-05T16:00:02::metamben ran successfully in 15ms
2024-11-04 10:03:52,135 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateLegacyColumnKeysInCardVizSettings
2024-11-04 10:03:52,135 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-07T10:00:00::ranquild ran successfully in 296ms
2024-11-04 10:03:52,189 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateLegacyColumnKeysInDashboardCardVizSettings
2024-11-04 10:03:52,190 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-07T11:00:00::ranquild ran successfully in 53ms
2024-11-04 10:03:52,199 INFO liquibase.changelog :: Columns status(text) added to query_analysis
2024-11-04 10:03:52,200 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-08-26T08:53:46::crisptrutski ran successfully in 7ms
2024-11-04 10:03:52,207 INFO liquibase.changelog :: Columns pivot_results(boolean) added to pulse_card
2024-11-04 10:03:52,207 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-09-03T16:54:18::adam-james ran successfully in 5ms
2024-11-04 10:03:52,214 INFO liquibase.snapshot :: Creating snapshot
2024-11-04 10:03:52,221 INFO liquibase.changelog :: Index idx_collection_type created
2024-11-04 10:03:52,221 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-09-09T15:11:16::johnswanson ran successfully in 12ms
2024-11-04 10:03:52,228 INFO liquibase.changelog :: Custom SQL executed
2024-11-04 10:03:52,229 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-09-26T03:01:00::escherize ran successfully in 5ms
2024-11-04 10:03:52,234 INFO liquibase.changelog :: Custom SQL executed
2024-11-04 10:03:52,235 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-09-26T03:02:00::escherize ran successfully in 3ms
2024-11-04 10:03:52,240 INFO liquibase.changelog :: Custom SQL executed
2024-11-04 10:03:52,240 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v51.2024-09-26T03:03:00::escherize ran successfully in 3ms
2024-11-04 10:03:52,245 INFO liquibase.changelog :: Marking ChangeSet: ""migrations/001_update_migrations.yaml::v51.2024-09-26T03:04:00::escherize"" as ran despite precondition failure due to onFail='MARK_RAN':
          liquibase.yaml : SQL Precondition failed.  Expected '1' got '0'
          liquibase.yaml : DBMS Precondition failed: expected mysql,mariadb, got postgresql
          liquibase.yaml : DBMS Precondition failed: expected h2, got postgresql


UPDATE SUMMARY
Run:                         50
Previously run:             367
Filtered out:                51
-------------------------------
Total change sets:          468


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               51

2024-11-04 10:03:52,264 INFO liquibase.util :: UPDATE SUMMARY
2024-11-04 10:03:52,266 INFO liquibase.util :: Run:                         50
2024-11-04 10:03:52,266 INFO liquibase.util :: Previously run:             367
2024-11-04 10:03:52,266 INFO liquibase.util :: Filtered out:                51
2024-11-04 10:03:52,266 INFO liquibase.util :: -------------------------------
2024-11-04 10:03:52,266 INFO liquibase.util :: Total change sets:          468
2024-11-04 10:03:52,266 INFO liquibase.util :: FILTERED CHANGE SETS SUMMARY
2024-11-04 10:03:52,266 INFO liquibase.util :: DBMS mismatch:               51
2024-11-04 10:03:52,278 INFO liquibase.util :: Update summary generated
2024-11-04 10:03:52,284 INFO liquibase.command :: Update command completed successfully.
2024-11-04 10:03:52,286 INFO liquibase.lockservice :: Successfully released change log lock
2024-11-04 10:03:52,287 INFO liquibase.command :: Command execution complete
2024-11-04 10:03:52,288 INFO db.liquibase :: Migration complete in 2.3 s
2024-11-04 10:03:52,290 INFO liquibase.lockservice :: Successfully released change log lock
2024-11-04 10:03:52,296 INFO db.setup :: Database Migrations Current ... ✅
2024-11-04 10:03:52,297 INFO metabase.util :: Datenbankkonfiguration took 4.9 s
2024-11-04 10:03:52,326 ERROR middleware.log :: GET /api/health 503 1.0 ms (0 DB-Aufrufe) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}



### Information about your Metabase installation

Chrome Version 126.0.6478.231
Windows 10
Databanse used in this report: Postgres 16.1
Metabase v0.51.1
On-Prem Docker on Rockylinux
Internal Metabase DB: Postgres 16.1

### Severity

showstopper

### Additional context

_No response_",dhiegosilva,2024-11-04 10:53:53+00:00,[],2024-11-04 14:56:57+00:00,2024-11-04 12:02:25+00:00,https://github.com/metabase/metabase/issues/49473,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2454417384, 'issue_id': 2632478004, 'author': 'paoliniluis', 'body': 'Activate the tables that were marked as inactive', 'created_at': datetime.datetime(2024, 11, 4, 11, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454534823, 'issue_id': 2632478004, 'author': 'dhiegosilva', 'body': 'thank you, i learned, need to activate manually per SQL in metabase_table\n\nworked!', 'created_at': datetime.datetime(2024, 11, 4, 12, 2, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-04 11:03:43 UTC): Activate the tables that were marked as inactive

dhiegosilva (Issue Creator) on (2024-11-04 12:02:25 UTC): thank you, i learned, need to activate manually per SQL in metabase_table

worked!

"
2632271969,issue,open,,Unsupported unit: Seconds,"### Describe the bug

![Image](https://github.com/user-attachments/assets/54ec5011-000e-4a52-b8b5-1cad6b4ee28e)


### To Reproduce

1. Open https://stats.metabase.com/question/11693
2. Use brush filter to select a range in the chart
3. Click filter pill to edit the applied filter

❌ notice that ""Remove time"" button is there - this is not expected

4. Click ""Update filter""

❌ query fails


### Information about your Metabase installation

master, 403c260eca

### Severity

P2

### Additional context

Kind of similar to #48608",kamilmielnik,2024-11-04 09:23:27+00:00,['ericnormand'],2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/49469,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2454930444, 'issue_id': 2632271969, 'author': 'ranquild', 'body': ""The same issue as with time filters in https://github.com/metabase/metabase/issues/48608 - MBQL lib doesn't check for supported temporal buckets and binning strategies in brush filters"", 'created_at': datetime.datetime(2024, 11, 4, 14, 55, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617726607, 'issue_id': 2632271969, 'author': 'ranquild', 'body': 'Similar to https://github.com/metabase/metabase/issues/48608', 'created_at': datetime.datetime(2025, 1, 28, 2, 57, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617728387, 'issue_id': 2632271969, 'author': 'ranquild', 'body': '`Lib.updateTemporalFilter` should be fixed - it should not use units not supported by the column type', 'created_at': datetime.datetime(2025, 1, 28, 2, 58, 20, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-04 14:55:16 UTC): The same issue as with time filters in https://github.com/metabase/metabase/issues/48608 - MBQL lib doesn't check for supported temporal buckets and binning strategies in brush filters

ranquild on (2025-01-28 02:57:13 UTC): Similar to https://github.com/metabase/metabase/issues/48608

ranquild on (2025-01-28 02:58:20 UTC): `Lib.updateTemporalFilter` should be fixed - it should not use units not supported by the column type

"
2632081767,issue,closed,completed,SDK modal z-index loses to other element from other stacking contexts,"In this case `z-index: 3` of the modal is losing to Mantine's [AppShell](https://mantine.dev/core/app-shell/) (z-index: 100)

![Image](https://github.com/user-attachments/assets/c79ef516-eff5-42f3-b338-d0df1b324977)

Maybe modal is a kind of type that we could justify having a very high `z-index`?",WiNloSt,2024-11-04 07:46:09+00:00,['rafpaf'],2025-01-27 22:13:10+00:00,2024-12-17 17:48:17+00:00,https://github.com/metabase/metabase/issues/49466,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2456805610, 'issue_id': 2632081767, 'author': 'WiNloSt', 'body': 'This seems to be fixed by #49442 in my setup.\n\n![Image](https://github.com/user-attachments/assets/c06963b1-575f-47d0-94ac-60c7af15c667)', 'created_at': datetime.datetime(2024, 11, 5, 10, 31, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465217290, 'issue_id': 2632081767, 'author': 'albertoperdomo', 'body': 'Can this be closed @WiNloSt ?', 'created_at': datetime.datetime(2024, 11, 8, 16, 29, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468086924, 'issue_id': 2632081767, 'author': 'heypoom', 'body': ""@albertoperdomo the above PR (https://github.com/metabase/metabase/pull/49442) isn't merged yet, so we should wait until the PR is merged to close this issue."", 'created_at': datetime.datetime(2024, 11, 11, 12, 40, 44, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-11-05 10:31:12 UTC): This seems to be fixed by #49442 in my setup.

![Image](https://github.com/user-attachments/assets/c06963b1-575f-47d0-94ac-60c7af15c667)

albertoperdomo on (2024-11-08 16:29:53 UTC): Can this be closed @WiNloSt ?

heypoom on (2024-11-11 12:40:44 UTC): @albertoperdomo the above PR (https://github.com/metabase/metabase/pull/49442) isn't merged yet, so we should wait until the PR is merged to close this issue.

"
2631454697,issue,open,,Grid map broken with native queries,"### Describe the bug

Grid map works good with GUI queries. Selecting from a table, grouping latitude and longitude by 0.1 and counting the rows displays the grids well.

 ![Image](https://github.com/user-attachments/assets/a420e722-d526-49b4-b2ec-b9ef436c3571)

However, converting the same question to native, SQL, renders the map unusable. Grids get turned into awkward stripes.

 ![Image](https://github.com/user-attachments/assets/10a3dc67-8ce4-46f4-96af-0e6b228d9a56)


### To Reproduce

1. Create a GUI question, summarized by count, grouped by coordinates and select grid map as a viz type
2. Click on Convert this question to SQL
3. Select the same visualization settings
4. See the issue


### Expected behavior

Grid map works fine with native queries.

### Logs

_No response_

### Information about your Metabase installation

I am running the latest Metabase (0.51.1.2, self hosted).

### Severity

This renders the map unusable for any non-trivial analysis or a dashboard that requires more complex filtering

### Additional context

_No response_",TLazarevic,2024-11-03 20:30:39+00:00,[],2025-02-04 20:31:54+00:00,,https://github.com/metabase/metabase/issues/49462,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2540179893, 'issue_id': 2631454697, 'author': 'lhunath', 'body': 'This is a regression from #17930, following the verification steps indicated in that PR demonstrate that the feature has now failed.\nNote that we need to reduce the auto-boxing down below 1 degree (eg. 0.1 as indicated by the OP) in order to see this failure.', 'created_at': datetime.datetime(2024, 12, 12, 23, 2, 8, tzinfo=datetime.timezone.utc)}]","lhunath on (2024-12-12 23:02:08 UTC): This is a regression from #17930, following the verification steps indicated in that PR demonstrate that the feature has now failed.
Note that we need to reduce the auto-boxing down below 1 degree (eg. 0.1 as indicated by the OP) in order to see this failure.

"
2631295866,issue,open,,Offer a way to track individual User Activity on Static Embedding with Usage Analytics,"**Is your feature request related to a problem? Please describe.**
Right now there is no way to track what is going on around a static embedding dashboard. You can see how much usage the dashboards have from the Usage Analytics section but the problem is this activity will be all aggregates as `External Users`, a placeholder for users that view queries outside of metabase (includes both public and static) 

![Image](https://github.com/user-attachments/assets/7ad7b96a-22c8-4320-9a92-4723ae23c60b)

**Describe the solution you'd like**
A way to track unique external users and their activity. Like able to cluster by a group or specific user.

An idea is to store the JWT token parms together with the Query call. Tracking the Locked Params also gives an indication which group or users are using the dashboard. Better would be a way to pass params for tracking in the JWT itself so even email and username can be tracked outside of metabase when using static embedding


**Describe alternatives you've considered**
None that are relevant 

**How important is this feature to you?**
",Tony-metabase,2024-11-03 15:56:31+00:00,[],2025-02-04 20:30:50+00:00,,https://github.com/metabase/metabase/issues/49461,"[('Type:New Feature', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]","[{'comment_id': 2453479471, 'issue_id': 2631295866, 'author': 'Tony-metabase', 'body': 'Might feel related to https://github.com/metabase/metabase/issues/5462 but this is specific to Usage Analytics', 'created_at': datetime.datetime(2024, 11, 3, 16, 7, 24, tzinfo=datetime.timezone.utc)}]","Tony-metabase (Issue Creator) on (2024-11-03 16:07:24 UTC): Might feel related to https://github.com/metabase/metabase/issues/5462 but this is specific to Usage Analytics

"
2630513550,issue,open,,Babelfish: Tables not displayed,"### Describe the bug

[Babelfish](https://babelfishpg.org/) is an MS-SQL protocol adapter for PostgreSQL databases.

I have a database with some data. When I connected this database to Metabase using MS-SQL protocol, I received the message ""This database doesn't have any tables.""

However, manual queries executed directly in Metabase successfully return results:
```sql
SELECT * FROM INFORMATION_SCHEMA.TABLES;

drillinginfo_dibi	adldp	dataset_column_info	BASE TABLE
drillinginfo_dibi	adldp	dataset_info	BASE TABLE
drillinginfo_dibi	env	dataset_column_info	VIEW
drillinginfo_dibi	env	dataset_info	VIEW
...
```
Select queries are working too

### To Reproduce

1. Start Babelfish. I use [this](https://github.com/jonathanpotts/docker-babelfishpg) container for testing.
2. Populate it with some data using the MS-SQL protocol.
3. Launch Metabase and go to the ""Databases"" section.
4. Add a new connection for your MSSQL Server database.
5. Check if Metabase shows ""This database doesn't have any tables.""
6. Execute SELECT * FROM INFORMATION_SCHEMA.TABLES; in Metabase.
7. Confirm that the query returns tables and check that you have select permissions for these tables
8. Verify whether these tables are still not visible in the Metabase interface.

### Expected behavior

I expect that all tables and views should be visible from any schema.

### Logs

<details> 

```
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:51+06:00 DEBUG metabase.server.middleware.log POST /api/database/3/sync_schema 200 407.3 ms (1 DB calls) App DB connections: 0/10 Jetty threads: 3/50 (3 idle, 0 queued) (111 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:51+06:00 INFO metabase.sync.util STARTING: step ''sync-dbms-version'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:51+06:00 INFO metabase.sync.util FINISHED: step ''sync-dbms-version'' for sqlserver Database 3 ''Env'' (155.5 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:51+06:00 INFO metabase.sync.util STARTING: step ''sync-timezone'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.sync-metadata.sync-timezone :sqlserver database 3 default timezone is #object[java.time.ZoneOffset 0x1c1acf2c ""Z""]
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-timezone'' for sqlserver Database 3 ''Env'' (183.1 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-tables'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-tables'' for sqlserver Database 3 ''Env'' (24.9 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-fields'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-fields'' for sqlserver Database 3 ''Env'' (21.4 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-fks'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-fks'' for sqlserver Database 3 ''Env'' (27.9 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-indexes'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-indexes'' for sqlserver Database 3 ''Env'' (22.3 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-metabase-metadata'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-metabase-metadata'' for sqlserver Database 3 ''Env'' (19.5 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''sync-table-privileges'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''sync-table-privileges'' for sqlserver Database 3 ''Env'' (19.5 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: Sync metadata for sqlserver Database 3 ''Env'' (793.5 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: Analyze data for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''fingerprint-fields'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''fingerprint-fields'' for sqlserver Database 3 ''Env'' (24.9 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''classify-fields'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''classify-fields'' for sqlserver Database 3 ''Env'' (20.4 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util STARTING: step ''classify-tables'' for sqlserver Database 3 ''Env''
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: step ''classify-tables'' for sqlserver Database 3 ''Env'' (20.3 ms)
[dc12a234-ba53-42ae-9bd9-335cc3f0c635] 2024-11-02T21:11:52+06:00 INFO metabase.sync.util FINISHED: Analyze data for sqlserver Database 3 ''Env'' (95.0 ms)
```

</details> 

### Information about your Metabase installation

<details> 

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v0.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.2""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.146+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

</details>


### Severity

Low

### Additional context

I have only client access to the database via the MS-SQL protocol. I would obviously prefer to use direct access with the psql protocol without using such kind of adapters.",mazzz1y,2024-11-02 15:19:20+00:00,[],2025-02-04 20:25:35+00:00,,https://github.com/metabase/metabase/issues/49459,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/SQLServer', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2453461894, 'issue_id': 2630513550, 'author': 'paoliniluis', 'body': 'What SQL server do you have and which permissions does the user have?', 'created_at': datetime.datetime(2024, 11, 3, 15, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455357477, 'issue_id': 2630513550, 'author': 'ixipixi', 'body': ""I am unable to reproduce this. It's possible for the user to have access to query Information Schema / list the tables without having access to the tables themselves. From within Metabase - if you select data from one of the tables that isn't coming in via sync do you see an error message?"", 'created_at': datetime.datetime(2024, 11, 4, 17, 55, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457221306, 'issue_id': 2630513550, 'author': 'mazzz1y', 'body': '> What SQL server do you have and which permissions does the user have?\n\nUnfortunately, my issue does not reflect the real problem. I researched a bit more and found that this involves some kind of Amazon SaaS service for their PostgreSQL database with a SQL Server adapter:\n```\nBabelfish for Aurora PostgreSQL with SQL Server Compatibility - 12.0.2000.8\nAug 21 2024 11:39:48\nCopyright (c) Amazon Web Services\nPostgreSQL 16.1 on aarch64-unknown-linux-gnu (Babelfish 4.0.2)\n```\nI\'ve never seen such a thing before, which is why I\'m confused. _I\'ve updated the issue description_\n\nI am able to reproduce the issue. I started a database instance, populated it with some data using the MSSQL protocol, and encountered ""This database doesn\'t have any tables"" in Metabase.\n\n> It\'s possible for the user to have access to query Information Schema / list the tables without having access to the tables themselves. From within Metabase - if you select data from one of the tables that isn\'t coming in via sync do you see an error message?\n\nYes, I am able to select data', 'created_at': datetime.datetime(2024, 11, 5, 13, 44, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457578385, 'issue_id': 2630513550, 'author': 'paoliniluis', 'body': ""ok ok ok ok... this was not SQL server from the first place but rather SQL server through babelfish...\n\nwhy didn't you connect directly to SQL Server with the SQL server driver? why do you use babelfish?"", 'created_at': datetime.datetime(2024, 11, 5, 16, 3, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457619921, 'issue_id': 2630513550, 'author': 'mazzz1y', 'body': '> why\n\nI anticipated this question, so I added a clarification to the additional context in the main post. \n\nI was given this client access as a service. I do not have access to the Postgres protocol or server parameters. I understand that this is a rare and not expected scenario, which is why I marked the severity as low', 'created_at': datetime.datetime(2024, 11, 5, 16, 20, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475347995, 'issue_id': 2630513550, 'author': 'perivamsi', 'body': 'Lowering this to a P2', 'created_at': datetime.datetime(2024, 11, 14, 3, 39, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-03 15:12:34 UTC): What SQL server do you have and which permissions does the user have?

ixipixi on (2024-11-04 17:55:30 UTC): I am unable to reproduce this. It's possible for the user to have access to query Information Schema / list the tables without having access to the tables themselves. From within Metabase - if you select data from one of the tables that isn't coming in via sync do you see an error message?

mazzz1y (Issue Creator) on (2024-11-05 13:44:28 UTC): Unfortunately, my issue does not reflect the real problem. I researched a bit more and found that this involves some kind of Amazon SaaS service for their PostgreSQL database with a SQL Server adapter:
```
Babelfish for Aurora PostgreSQL with SQL Server Compatibility - 12.0.2000.8
Aug 21 2024 11:39:48
Copyright (c) Amazon Web Services
PostgreSQL 16.1 on aarch64-unknown-linux-gnu (Babelfish 4.0.2)
```
I've never seen such a thing before, which is why I'm confused. _I've updated the issue description_

I am able to reproduce the issue. I started a database instance, populated it with some data using the MSSQL protocol, and encountered ""This database doesn't have any tables"" in Metabase.


Yes, I am able to select data

paoliniluis on (2024-11-05 16:03:12 UTC): ok ok ok ok... this was not SQL server from the first place but rather SQL server through babelfish...

why didn't you connect directly to SQL Server with the SQL server driver? why do you use babelfish?

mazzz1y (Issue Creator) on (2024-11-05 16:20:28 UTC): I anticipated this question, so I added a clarification to the additional context in the main post. 

I was given this client access as a service. I do not have access to the Postgres protocol or server parameters. I understand that this is a rare and not expected scenario, which is why I marked the severity as low

perivamsi on (2024-11-14 03:39:39 UTC): Lowering this to a P2

"
2630276008,issue,open,,Allow for configurable asset hosts/CDNs for faster static asset delivery (eg `MB_ASSET_HOST`),"**Is your feature request related to a problem? Please describe.**

Our team is distributed across the globe, and the asset loading times can be slow for users located far from the application host. This can lead to a less-than-ideal user experience.

**Describe the solution you'd like**

An `MB_ASSET_HOST` configuration option would be highly beneficial, as it would allow to specify an alternative host for serving static assets. This would enable the use of a CDN or a dedicated asset server.

**Describe alternatives you've considered**

We have considered configuring a reverse proxy to replace all asset URLs using [sub_filter](https://nginx.org/en/docs/http/ngx_http_sub_module.html#sub_filter) in nginx to serve static assets from a different location. However, this method is complex and requires ongoing maintenance. A built-in configuration option would greatly simplify the process.

**How important is this feature to you?**

This feature would be a valuable enhancement, as it could improve performance and user experience in Metabase for teams like ours that are distributed across the globe.

**Additional context**

Implementing this feature would align with best practices for web performance optimization, as it's not always possible to use the same domain for dynamic and static content.
",dmeremyanin,2024-11-02 07:05:31+00:00,[],2025-02-04 20:31:01+00:00,,https://github.com/metabase/metabase/issues/49458,"[('.Performance', ''), ('Type:New Feature', ''), ('Operation/', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted')]","[{'comment_id': 2569608696, 'issue_id': 2630276008, 'author': 'brunobergher', 'body': '@dmeremyanin we were discussing this internally just the other day. One thing which has discouraged us from moving forward though is that, in general, DB latency is a lot bigger than asset download latency. So while this would make things better, it would probably not make a big impact.\n\nHave you considered this angle? How would you handle DB access latency for your users?', 'created_at': datetime.datetime(2025, 1, 3, 17, 55, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569635765, 'issue_id': 2630276008, 'author': 'paoliniluis', 'body': 'Leaving this here ![Image](https://github.com/user-attachments/assets/88c79af8-3c67-4fcf-8acf-28be521d72d0)\n\nMetabase assets are very big and for people that use embedding, this is a bummer', 'created_at': datetime.datetime(2025, 1, 3, 18, 17, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571369945, 'issue_id': 2630276008, 'author': 'dmeremyanin', 'body': 'I agree that DB latency is a more significant factor overall, but as @paoliniluis mentioned, the size of Metabase\'s static assets could still be a reason to consider this change. For instance, Metabase loads around 3MB of Brotli-compressed assets on the main page, which makes up about 90% of all the transferred traffic (3.3MB in total).\n\nUsing a CDN can improve responsiveness, and it\'s a common best practice in web development to offload static content. A good example of this approach can be seen in the [Ruby on Rails asset pipeline](https://guides.rubyonrails.org/asset_pipeline.html#set-up-a-cdn-to-serve-static-assets), where static assets are configured via `config.asset_host = ""assets.metabase-is-awesome.com""`.\n\nThanks for considering this, and I\'d be happy to discuss further or clarify any details.', 'created_at': datetime.datetime(2025, 1, 4, 18, 1, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572868218, 'issue_id': 2630276008, 'author': 'brunobergher', 'body': ""Completely agree, @dmeremyanin. I'll work on prioritizing this on our side. Thank you."", 'created_at': datetime.datetime(2025, 1, 6, 10, 57, 2, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 17:55:12 UTC): @dmeremyanin we were discussing this internally just the other day. One thing which has discouraged us from moving forward though is that, in general, DB latency is a lot bigger than asset download latency. So while this would make things better, it would probably not make a big impact.

Have you considered this angle? How would you handle DB access latency for your users?

paoliniluis on (2025-01-03 18:17:28 UTC): Leaving this here ![Image](https://github.com/user-attachments/assets/88c79af8-3c67-4fcf-8acf-28be521d72d0)

Metabase assets are very big and for people that use embedding, this is a bummer

dmeremyanin (Issue Creator) on (2025-01-04 18:01:36 UTC): I agree that DB latency is a more significant factor overall, but as @paoliniluis mentioned, the size of Metabase's static assets could still be a reason to consider this change. For instance, Metabase loads around 3MB of Brotli-compressed assets on the main page, which makes up about 90% of all the transferred traffic (3.3MB in total).

Using a CDN can improve responsiveness, and it's a common best practice in web development to offload static content. A good example of this approach can be seen in the [Ruby on Rails asset pipeline](https://guides.rubyonrails.org/asset_pipeline.html#set-up-a-cdn-to-serve-static-assets), where static assets are configured via `config.asset_host = ""assets.metabase-is-awesome.com""`.

Thanks for considering this, and I'd be happy to discuss further or clarify any details.

brunobergher on (2025-01-06 10:57:02 UTC): Completely agree, @dmeremyanin. I'll work on prioritizing this on our side. Thank you.

"
2629961049,issue,closed,completed,Verified model isn't showing up in typeahead list when looking for models to select from in native editor,"### Describe the bug

In native editor, I am trying to find the Account model, which is a verified model by typing {{#account}} but nothing shows up. This does work for some models, so it seems to be specific to the instance data. This can be reproduced in Stats using the Analytics Data Warehouse connection. 

```
select * from {{#account}}
```

Normally, I don't report issues only in Stats, but adding one just to make sure someone look at it as it is a **potential release blocker**.  Someone should investigate to see what the real problem is and then update this issue. 

### To Reproduce

1. Go to Stats
2. Open native editor for Analytics Data Warehouse and try to select from the verified Account model by typing: `select * from {{#account}}`
3. Notice nothing shows up -- no typeahead selection preview

### Expected behavior

Typeahead selection preview box should show up with the Account model as it is verified. 

### Logs

n/a

### Information about your Metabase installation

Master @ Postgres

### Severity

Medium as it makes it hard to select from other models in native editor for new users that don't know the workaround (could be worked around by manually typing the model id). 

### Additional context

_No response_",maxzheng,2024-11-01 22:25:55+00:00,['romeovs'],2024-11-26 18:51:56+00:00,2024-11-05 07:32:44+00:00,https://github.com/metabase/metabase/issues/49454,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Querying', '')]","[{'comment_id': 2457918138, 'issue_id': 2629961049, 'author': 'maxzheng', 'body': '@romeovs Works better in Stats now as I see more models, but the verified Account model is still not showing up -- as stated in original ticket.', 'created_at': datetime.datetime(2024, 11, 5, 18, 46, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459554102, 'issue_id': 2629961049, 'author': 'romeovs', 'body': '@maxzheng can you have another look, stats has been deployed now.', 'created_at': datetime.datetime(2024, 11, 6, 11, 55, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460310388, 'issue_id': 2629961049, 'author': 'maxzheng', 'body': ""@romeovs Yep, it's working now. Thanks for fixing this! Hopefully we have tests to prevent regression as this has happened before."", 'created_at': datetime.datetime(2024, 11, 6, 16, 57, 49, tzinfo=datetime.timezone.utc)}]","maxzheng (Issue Creator) on (2024-11-05 18:46:50 UTC): @romeovs Works better in Stats now as I see more models, but the verified Account model is still not showing up -- as stated in original ticket.

romeovs (Assginee) on (2024-11-06 11:55:37 UTC): @maxzheng can you have another look, stats has been deployed now.

maxzheng (Issue Creator) on (2024-11-06 16:57:49 UTC): @romeovs Yep, it's working now. Thanks for fixing this! Hopefully we have tests to prevent regression as this has happened before.

"
2629716177,issue,closed,completed,Databricks Catalog is not Validated when the Connection is Set Up,"### Describe the bug

When you set up a Databricks connection a catalog is required - but you can provide an invalid catalog and the connection will still save, the sync modal will pop up and it looks like it's syncing successfully. You have to go to the logs to identify that there's an error.



### To Reproduce

1. Add a Databricks connection to v51
2. Provide the name of a catalog that doesn't exist

### Expected behavior

The catalog should be validated

### Logs

_No response_

### Information about your Metabase installation

v51

### Severity

annoying 

### Additional context

_No response_",ixipixi,2024-11-01 19:19:21+00:00,['lbrdnk'],2024-11-27 22:16:43+00:00,2024-11-27 10:06:11+00:00,https://github.com/metabase/metabase/issues/49444,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Administration/Databases', ''), ('.Team/Querying', ''), ('Database/Databricks', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2454902161, 'issue_id': 2629716177, 'author': 'ranquild', 'body': 'This is a common flow + the ""successful"" sync modal is misleading; hard to debug; thus P1.', 'created_at': datetime.datetime(2024, 11, 4, 14, 44, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504889397, 'issue_id': 2629716177, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2024, 11, 27, 22, 16, 42, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-04 14:44:26 UTC): This is a common flow + the ""successful"" sync modal is misleading; hard to debug; thus P1.

github-actions[bot] on (2024-11-27 22:16:42 UTC): 🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)

"
2629472006,issue,closed,completed,Oracle DATE type doesn't work properly on metabase version 50,"### Describe the bug

Oracle has a special type of column type [DATE](https://docs.oracle.com/en/database/oracle/oracle-database/19/nlspg/datetime-data-types-and-time-zone-support.html#GUID-3A1B7AC6-2EDB-4DDC-9C9D-223D4C72AC74) this allows you to have a time element inside of it (similar to a DateTime)

Metabase has odd behaviour around filtering on this date

### To Reproduce

So you need an Oracle for this and this lab might help you https://github.com/paoliniluis/metabase-oracle

Create a Table which has a DATE type column and. Populate this Table

Then try to filter on it, you will notice metabase is able to interpret it as a Date in the UI but still keeps adding timezone information around the filter:

https://github.com/user-attachments/assets/16f197b7-efbb-4f04-8b1e-2a2e1b60a872

Even if you manually remove the time element (which is added by default for some reason) metabase still seems to be using it behind the scenes

### Expected behavior

Filtering works properly

### Logs

None that are relevant cause the question is getting executed

### Information about your Metabase installation

50.31

### Severity

Breaks functionality for people moving from 49 to 50 and are using Oracle with DATE type filter

### Additional context

This doesn't seem to be an issue on 49",Tony-metabase,2024-11-01 17:02:20+00:00,['lbrdnk'],2024-11-14 23:25:28+00:00,2024-11-11 14:11:05+00:00,https://github.com/metabase/metabase/issues/49440,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 2477610837, 'issue_id': 2629472006, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.4](https://github.com/metabase/metabase/milestone/281)', 'created_at': datetime.datetime(2024, 11, 14, 23, 25, 27, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-14 23:25:27 UTC): 🚀 This should also be released by [v0.51.4](https://github.com/metabase/metabase/milestone/281)

"
2629461330,issue,closed,completed,"Exporting to Formatted CSV or JSON Rounds Numeric Fields When Using ""Multiply by a Value""","### Describe the bug

If you're displaying numeric fields in a table viz and use the ""Multiply by a number"" formatting option, the new values may contain decimals. Exporting to Formatted CSV or JSON rounds the results in these columns. Works as expected in Excel exports.

### To Reproduce

1. Create a question that's just a count() of some field
2. View in a table or pivot
3. Modify the count using the ""Multiply by a value"" options - make sure to include decimals so the results are decimal
4. Export formatted to Excel - note it works
5. Export formatted to JSON or CSV - note the value is rounded

https://www.loom.com/share/3ee362c5e07d4a11afdd1b447755d1e9

### Expected behavior

Formatted exports should match like the data displayed in the user interface.

### Logs

_No response_

### Information about your Metabase installation

Tested in v50 & v51

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-11-01 16:56:49+00:00,[],2024-12-17 05:51:04+00:00,2024-12-17 05:09:20+00:00,https://github.com/metabase/metabase/issues/49439,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]",[],
2629418152,issue,open,,MongoDB - Can’t connect to database if it doesn’t contain a collection,"### Describe the bug

You can't connect to a MongoDB instance if the database doesn't have at least a single collection.
Normally this isn't an issue but we have customer who is heavily using the API to generate connections as part of their automation. Often there will not be a default collection until a later point.
Their goal is to be able implement their automation logic without having to create a ""dummy"" collection, which is a workaround at the moment.

Tested this in 1.51.1 and 1.50.30.

### To Reproduce


1. Create a Mongo instance using a command like the following:

`docker run --name mongodb -p 27017:27017  -e MONGO_INITDB_ROOT_USERNAME=root -e MONGO_INITDB_ROOT_PASSWORD=password -d mongo:8`

Or YAML
```
version: '3.8'

services:
  mongodb:
    image: mongo:latest 
    container_name: mongodb-container
    ports:
      - ""27017:27017"" 
    environment:
      MONGO_INITDB_ROOT_USERNAME: root  
      MONGO_INITDB_ROOT_PASSWORD: password  
    volumes:
      - ./mongo-data:/data/db 

volumes:
  mongo-data:
    driver: local
```

<br>
<br>

2. Confirm you're able to connect from Metabase using a connection string like the following:
`mongodb://root:password@localhost:27017/admin`

<br>
<br>

3. If browse the container, you’ll see the following databases and collections created by default and the reason you're able to connect with the string above.

> **show dbs**
> Databases:
> admin
> config
> local
> 
> **show collections**
> Collections:
> system.users
> system.version

<br>
<br>

4. Now, create a new database, new user, and grant permissions
```
use newdb

db.createUser({
  user: ""appUser"",
  pwd: ""password"",
  roles: [ { role: ""readWrite"", db: ""newdb"" } ]
});

```

<br>
<br>

5. Confirm you can connect to this database using the newly created account directly.
```
docker exec -it <Docker container> /bin/bash

mongosh --username appUser --password password --authenticationDatabase newdb
```

<br>
<br>

6. Try to connect within Metabase using a connection string like the following and won't be able. I've posted the logs below.
```
mongodb://appUser:password@localhost:27017/newdb
or
mongodb://appUser:password@localhost:27017/newdb?authSource=newdb
```

<br>
<br>

7. Create a collection in the newdb database. You should be able to connect from within Metabase.
```
use newdb
db.sampleCollection.insertOne({ name: ""testDocument"", value: 123 });
```


### Expected behavior

For a user to be able to connect to an empty database in the same way you can with something like postgres.

### Logs

2024-11-01 10:20:15,009 DEBUG mongo.connection :: Opened new MongoClient.
2024-11-01 10:20:15,072 DEBUG mongo.connection :: Closed MongoClient.
2024-11-01 10:20:15,072 ERROR driver.util :: Failed to connect to Database
java.lang.Exception: Failed to connect to Database
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56584.invoke(util.clj:167)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-11-01 10:20:15,075 DEBUG mongo.connection :: Opened new MongoClient.
2024-11-01 10:20:15,109 DEBUG mongo.connection :: Closed MongoClient.
2024-11-01 10:20:15,109 ERROR driver.util :: Failed to connect to Database
java.lang.Exception: Failed to connect to Database
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56584.invoke(util.clj:167)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-11-01 10:20:15,110 ERROR api.database :: Cannot connect to Database
clojure.lang.ExceptionInfo: Failed to connect to Database {:message ""Failed to connect to Database""}
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:184)
	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155)
	at clojure.lang.RestFn.invoke(RestFn.java:442)
	at metabase.api.database$test_database_connection.invokeStatic(database.clj:730)
	at metabase.api.database$test_database_connection.doInvoke(database.clj:720)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.api.database$test_connection_details.invokeStatic(database.clj:784)
	at metabase.api.database$test_connection_details.invoke(database.clj:764)
	at metabase.api.database$fn__100408.invokeStatic(database.clj:805)
	at metabase.api.database$fn__100408.invoke(database.clj:788)
	at compojure.core$wrap_response$fn__52791.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__52775.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__52780.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.server.middleware.auth$enforce_authentication$fn__98681.invoke(auth.clj:18)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$make_context$handler__52831.invoke(core.clj:290)
	at compojure.core$make_context$fn__52835.invoke(core.clj:300)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at metabase.api.routes$fn__104362$fn__104363.invoke(routes.clj:70)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__104642$fn__104643.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$make_context$handler__52831.invoke(core.clj:290)
	at compojure.core$make_context$fn__52835.invoke(core.clj:300)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:153)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:153)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:153)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52784.invoke(core.clj:153)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:199)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$make_context$handler__52831.invoke(core.clj:290)
	at compojure.core$make_context$fn__52835.invoke(core.clj:300)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803$f__52804$respond_SINGLEQUOTE___52805.invoke(core.clj:197)
	at compojure.core$make_context$fn__52835.invoke(core.clj:301)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at compojure.core$routes$fn__52803$f__52804.invoke(core.clj:198)
	at compojure.core$routes$fn__52803.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100715.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__100712.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__106990$fn__106991$fn__106992.invoke(log.clj:233)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__106990$fn__106991.invoke(log.clj:224)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__106990.invoke(log.clj:223)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__113194.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__100671.invoke(security.clj:246)
	at ring.middleware.json$wrap_json_body$fn__113453.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__89034.invoke(offset_paging.clj:43)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__54419.invoke(json.clj:83)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__113542.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__113561.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__64764.invoke(misc.clj:59)
	at metabase.server.middleware.session$reset_session_timeout$fn__66317.invoke(session.clj:549)
	at metabase.server.middleware.session$bind_current_user$fn__66283$fn__66284.invoke(session.clj:443)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:405)
	at metabase.server.middleware.session$bind_current_user$fn__66283.invoke(session.clj:442)
	at metabase.server.middleware.session$wrap_current_user_info$fn__66264.invoke(session.clj:381)
	at metabase.server.middleware.session$wrap_session_id$fn__66236.invoke(session.clj:259)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__98689.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__113381.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__64746.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__64772.invoke(misc.clj:75)
	at ring.middleware.gzip$wrap_gzip$fn__113423.invoke(gzip.clj:86)
	at metabase.server.middleware.misc$bind_request$fn__64775.invoke(misc.clj:91)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__113210.invoke(ssl.clj:41)
	at metabase.server$async_proxy_handler$fn__72520.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.Exception: Failed to connect to Database
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56584.invoke(util.clj:167)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more
2024-11-01 10:20:15,117 DEBUG middleware.log :: POST /api/database 400 121.2 ms (1 DB calls) {:metabase-user-id 1} 
{:message ""Failed to connect to Database""}

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Chicago""
  }
}

### Severity

P2

### Additional context

_No response_",FilmonK,2024-11-01 16:37:03+00:00,[],2025-02-04 20:25:12+00:00,,https://github.com/metabase/metabase/issues/49438,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2629405684,issue,closed,completed,Pivoted Exports Aren't Pivoted After Sorts Applied in Viz Settings (Until Save),"### Describe the bug

If you're modifying the sorts on rows and columns in Pivot viz settings, sometimes the pivoted exports aren't pivoted. Saving the visualization corrects this.

### To Reproduce

1. Create a pivot table in v51
2. Export to CSV with ""Keep Data Pivoted"" selected
3. Note that the export is pivoted
4. Modify the sorts on the rows and columns (don't save)
5. Export to CSV with ""Keep Data Pivoted"" selected
6. Note that the export is not pivoted this time
7. Save it
8. Export again 
9. Export is correct

https://www.loom.com/share/cfe4b4e1bd574d12be733f75ea583222

### Expected behavior

When ""Keep data pivoted"" is selected the export should be pivoted.

### Logs

v51

[metabase-diagnostic-info-2024-11-01T16_29_25.637Z.json](https://github.com/user-attachments/files/17601853/metabase-diagnostic-info-2024-11-01T16_29_25.637Z.json)


### Information about your Metabase installation

v51

### Severity

confusing when it occurs

### Additional context

_No response_",ixipixi,2024-11-01 16:31:00+00:00,['adam-james-v'],2024-11-13 22:41:46+00:00,2024-11-13 21:58:03+00:00,https://github.com/metabase/metabase/issues/49437,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]",[],
2629245622,issue,closed,completed,Oracle can't aggregate by minute or hour,"### Describe the bug

If you do a simple count by a timestamp->minute/hour then Oracle will return the day
![Image](https://github.com/user-attachments/assets/997afcb9-8270-4797-84c1-4d8af81af30b)


### To Reproduce

1) spin up Metabase v50
2) create a simple question like
![Image](https://github.com/user-attachments/assets/4ccca513-55e2-49c9-b3c8-9cb1fed0793a)

(pay attention that the time field is aggregated by minute)

3) see that the results come back as days.

### Expected behavior

it should be truncated to the hour or to the minute

### Logs

NA

### Information about your Metabase installation

v50.x

### Severity

P1

### Additional context

The interesting fact is that if you run the SAME query on an external IDE it will work",paoliniluis,2024-11-01 15:14:25+00:00,['lbrdnk'],2025-01-27 22:10:41+00:00,2025-01-23 09:29:38+00:00,https://github.com/metabase/metabase/issues/49433,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Oracle', None), ('.Frontend', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2452134612, 'issue_id': 2629245622, 'author': 'bshepherdson', 'body': ""Should double-check what's coming over the wire. We don't return empty buckets, so this might be correct per-minute results poorly rendered as dates rather than datetimes. Might be a driver/QP issue reading from JDBC, or a FE issue visualizing what gets returned."", 'created_at': datetime.datetime(2024, 11, 1, 16, 6, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452178992, 'issue_id': 2629245622, 'author': 'paoliniluis', 'body': ""There's some other interesting things about Oracle that @Tony-metabase is creating, so there might be more on this"", 'created_at': datetime.datetime(2024, 11, 1, 16, 31, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452239047, 'issue_id': 2629245622, 'author': 'Tony-metabase', 'body': ""@bshepherdson something between 49 and 50 seems to have changed though (in my case it's for DATE type columns)\n\nhttps://github.com/metabase/metabase/issues/49440"", 'created_at': datetime.datetime(2024, 11, 1, 17, 3, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452566044, 'issue_id': 2629245622, 'author': 'paoliniluis', 'body': 'FE error, the wire brings the data correctly:\n![Image](https://github.com/user-attachments/assets/dffe8174-8c08-4581-8eb3-3b065878fa60)', 'created_at': datetime.datetime(2024, 11, 1, 20, 46, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460177816, 'issue_id': 2629245622, 'author': 'lbrdnk', 'body': 'The PR https://github.com/metabase/metabase/pull/49592 seems to fix also this issue. It is to be further investigated why as on first glance the PR is just tangentially related to this (here the TIMESTAMP column is used, the PR addresses DATE columns). \n\nI believe that problem on screenshots is just the rendering issue -- datetime values are missing the time parts. _I believe_ the we\'ve typed _something somewhere_ incorrectly and this is rather ML issue, because of what follows.\n\nIf I attempt to _sort drill_ the erronously rendered column, I get a schema error. The attached snippet contains ref that has a different type in breakout and order by.\n\n```\n;   {:database 2,\n;    :type :query,\n;    :query\n;    {:source-table 24,\n;     :aggregation [[:count]],\n;     :breakout [[:field 258 {:base-type :type/DateTimeWithTZ, :temporal-unit :minute}]],\n;     :order-by [[:asc [:field 258 {:base-type :type/Date, :temporal-unit :minute}]]]},\n;    :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},\n;    :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x4305077f ""[B@4305077f""]}},\n;   :fn-name normalize-or-throw},\n;  :data {:rows [], :cols []}}\n```', 'created_at': datetime.datetime(2024, 11, 6, 16, 5, 2, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-11-01 16:06:21 UTC): Should double-check what's coming over the wire. We don't return empty buckets, so this might be correct per-minute results poorly rendered as dates rather than datetimes. Might be a driver/QP issue reading from JDBC, or a FE issue visualizing what gets returned.

paoliniluis (Issue Creator) on (2024-11-01 16:31:21 UTC): There's some other interesting things about Oracle that @Tony-metabase is creating, so there might be more on this

Tony-metabase on (2024-11-01 17:03:02 UTC): @bshepherdson something between 49 and 50 seems to have changed though (in my case it's for DATE type columns)

https://github.com/metabase/metabase/issues/49440

paoliniluis (Issue Creator) on (2024-11-01 20:46:03 UTC): FE error, the wire brings the data correctly:
![Image](https://github.com/user-attachments/assets/dffe8174-8c08-4581-8eb3-3b065878fa60)

lbrdnk (Assginee) on (2024-11-06 16:05:02 UTC): The PR https://github.com/metabase/metabase/pull/49592 seems to fix also this issue. It is to be further investigated why as on first glance the PR is just tangentially related to this (here the TIMESTAMP column is used, the PR addresses DATE columns). 

I believe that problem on screenshots is just the rendering issue -- datetime values are missing the time parts. _I believe_ the we've typed _something somewhere_ incorrectly and this is rather ML issue, because of what follows.

If I attempt to _sort drill_ the erronously rendered column, I get a schema error. The attached snippet contains ref that has a different type in breakout and order by.

```
;   {:database 2,
;    :type :query,
;    :query
;    {:source-table 24,
;     :aggregation [[:count]],
;     :breakout [[:field 258 {:base-type :type/DateTimeWithTZ, :temporal-unit :minute}]],
;     :order-by [[:asc [:field 258 {:base-type :type/Date, :temporal-unit :minute}]]]},
;    :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
;    :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x4305077f ""[B@4305077f""]}},
;   :fn-name normalize-or-throw},
;  :data {:rows [], :cols []}}
```

"
2629178554,issue,closed,completed,Show the demo password in the terminal in the embedding cli,"The embedding CLI should let people know where to find the generated password file (i.e. the `METABASE_LOGIN.json`) and also print it in the console to make the experience better. The password is supposed to be for demo purposes only, so this does not pose a security risk.",heypoom,2024-11-01 14:40:34+00:00,[],2024-11-08 09:03:40+00:00,2024-11-08 09:01:48+00:00,https://github.com/metabase/metabase/issues/49431,"[('.Team/Embedding', ''), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2628825713,issue,closed,completed,Draft tech docs for flexible querying experience for embedding sdk,[Notion docs](https://www.notion.so/metabase/Tech-Flexible-querying-experience-for-embedding-sdk-13169354c901802582a8ca9389c544bd?pvs=4),heypoom,2024-11-01 11:05:52+00:00,['heypoom'],2024-11-07 16:12:03+00:00,2024-11-07 16:12:03+00:00,https://github.com/metabase/metabase/issues/49425,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2627878614,issue,closed,completed,Column Headers in Exports Pivots are Sometimes Ordered Incorrectly,"### Describe the bug

When pivots are exported to Excel in pivot format - values without results aren't exported in the same order in which they're displayed in the UI. Sort selections from viz settings are also ignored.

### To Reproduce

1. Create a pivot with a date grouping
2. Set the date as a column for the pivot
3. Ensure some of the results for the first row have a NULL result
4. Export the pivot
5. Note that columns with NULL cells are displaced in the final export (they're at the end)

https://www.loom.com/share/f24c12c571a84fbba3dfb81f8ad00ee2?sid=59120f7f-457a-4581-ba4b-a7dae2e1025a

### Expected behavior

The exported pivot should match the pivot that's visible in the user interface.

### Logs

_No response_

### Information about your Metabase installation

v51

### Severity

Annoying

### Additional context

_No response_",ixipixi,2024-10-31 21:38:46+00:00,['adam-james-v'],2024-11-15 21:33:46+00:00,2024-11-15 20:39:56+00:00,https://github.com/metabase/metabase/issues/49416,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Reporting/Export/Pivot', 'Exporting data as pivoted tables')]","[{'comment_id': 2451468803, 'issue_id': 2627878614, 'author': 'Tony-metabase', 'body': '@adam-james-v this might explain why that column we where looking at was always getting placed at the end of the CSV', 'created_at': datetime.datetime(2024, 11, 1, 7, 59, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451791540, 'issue_id': 2627878614, 'author': 'bshepherdson', 'body': 'The querying folks discovered last week that the `:result_metadata` for pivot queries is busted. It seems to be the metadata for one of the possibly several SQL queries that were performed to build the pivot query, rather than for the pivot query as a whole.\n\nPerhaps this is a symptom of the [same problem](https://github.com/metabase/metabase/issues/41896#issuecomment-2436169369)?', 'created_at': datetime.datetime(2024, 11, 1, 12, 25, 7, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-11-01 07:59:54 UTC): @adam-james-v this might explain why that column we where looking at was always getting placed at the end of the CSV

bshepherdson on (2024-11-01 12:25:07 UTC): The querying folks discovered last week that the `:result_metadata` for pivot queries is busted. It seems to be the metadata for one of the possibly several SQL queries that were performed to build the pivot query, rather than for the pivot query as a whole.

Perhaps this is a symptom of the [same problem](https://github.com/metabase/metabase/issues/41896#issuecomment-2436169369)?

"
2627433937,issue,closed,completed,[Epic] Migrate pivot viz settings from field refs,"Fixes https://github.com/metabase/metabase/issues/49363

#### Milestone 1

Support both field refs and column names; migrate on an explicit update.

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/49414
```
",ranquild,2024-10-31 17:30:21+00:00,['ranquild'],2024-11-19 20:48:06+00:00,2024-11-19 20:48:06+00:00,https://github.com/metabase/metabase/issues/49405,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]","[{'comment_id': 2486721833, 'issue_id': 2627433937, 'author': 'ranquild', 'body': ""Decided to not implement the migration as we don't seem to have anything similar."", 'created_at': datetime.datetime(2024, 11, 19, 20, 48, 4, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-11-19 20:48:04 UTC): Decided to not implement the migration as we don't seem to have anything similar.

"
2627259889,issue,closed,completed,Surface moderation status in Entity Picker,"- [x] Recents
- [x] Search
- [x] Nested item list",npfitz,2024-10-31 16:09:35+00:00,['npfitz'],2024-11-26 18:52:00+00:00,2024-11-04 00:54:25+00:00,https://github.com/metabase/metabase/issues/49398,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2627254904,issue,closed,not_planned,Rename `jwtProviderUri` to `authProviderUri`,"https://metaboat.slack.com/archives/C06FCQT0KMZ/p1728650041723219?thread_ts=1728550916.555969&cid=C06FCQT0KMZ

The endpoint doesn't really provide a jwt, so we agreed on renaming the prop.

We most likely want to console.error a message to the users still providing the old config to help them migrate

",npretto,2024-10-31 16:07:02+00:00,[],2024-11-08 16:29:04+00:00,2024-11-08 16:29:02+00:00,https://github.com/metabase/metabase/issues/49397,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2465216203, 'issue_id': 2627254904, 'author': 'albertoperdomo', 'body': 'Duplicate of #48870', 'created_at': datetime.datetime(2024, 11, 8, 16, 29, 3, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-11-08 16:29:03 UTC): Duplicate of #48870

"
2627011256,issue,closed,not_planned,"Filter value scan cannot be disabled, kills metabase deployment","### Describe the bug

Disabling ""Scanning for filter Values"" in admin settings has not effect. When clicking on Filter on any data source the frontend triggers column value requests to metabase API.

This leads to a saturation of the threadpool. In turn there are no more threads to pick up liveness/readiness probe requests and metabase gets killed by k8s operator.

Also it causes heavy load on large data sets in clickhouse (our datasource) because the queries are not optimized.

### To Reproduce

1. Go to Admin Settings->Databases->Select a database->Toggle ""Never, I'll do this manually if I need to"" for Scanning for Filter Values->Save
2. Go to Browse->Databases->Select a table from the database that has Filter Value Scanning disabled
3. Open web-console and network tab to be able to monitor api requests
4. Click on 'Filter' in the upper right corner
5. Watch in the web-console (or metabase logs) that API requests to retrieve column values are triggered

### Expected behavior

No column value requests should be triggered

### Logs

Triggered column value API requests:
![Image](https://github.com/user-attachments/assets/caa18852-8a37-4506-a157-fa855c858c3e)


### Information about your Metabase installation

- Chrome, Firefox
- Any
- Clickhouse
- Metabase version: v1.51.1
- Metabase hosting environment: k8s
- Metabase internal database: postgres


### Severity

High severity because the issue leads to frequent service interruption

### Additional context

We're metabase-pro users (deepl.com)",phil-schreiber,2024-10-31 14:31:38+00:00,[],2024-10-31 22:20:59+00:00,2024-10-31 15:41:24+00:00,https://github.com/metabase/metabase/issues/49393,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2450202342, 'issue_id': 2627011256, 'author': 'paoliniluis', 'body': '@phil-schreiber, you need to go to the application database and set all the fields to ""input box"" so Metabase never calls the DW for getting the field values. Please contact support and we can help you with this', 'created_at': datetime.datetime(2024, 10, 31, 15, 41, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450274204, 'issue_id': 2627011256, 'author': 'phil-schreiber', 'body': ""@paoliniluis Thank you for your reply, but that seems like a poor workaround for a feature that is supposed to be disabled. We're talking about roughly 10k columns. I don't think that's doable."", 'created_at': datetime.datetime(2024, 10, 31, 16, 12, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450928063, 'issue_id': 2627011256, 'author': 'paoliniluis', 'body': ""@phil-schreiber if you run self hosted, you can just simply run a query in the app DB that does the following:\n```\nUPDATE metabase_field\nSET has_field_value = 'none'\nWHERE has_field_value = 'list' OR has_field_value = 'auto-list';\n```\n\nas I mentioned before, please contact us so we can help you better with this problem, as we don't provide support via github issues"", 'created_at': datetime.datetime(2024, 10, 31, 22, 20, 58, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-31 15:41:24 UTC): @phil-schreiber, you need to go to the application database and set all the fields to ""input box"" so Metabase never calls the DW for getting the field values. Please contact support and we can help you with this

phil-schreiber (Issue Creator) on (2024-10-31 16:12:07 UTC): @paoliniluis Thank you for your reply, but that seems like a poor workaround for a feature that is supposed to be disabled. We're talking about roughly 10k columns. I don't think that's doable.

paoliniluis on (2024-10-31 22:20:58 UTC): @phil-schreiber if you run self hosted, you can just simply run a query in the app DB that does the following:
```
UPDATE metabase_field
SET has_field_value = 'none'
WHERE has_field_value = 'list' OR has_field_value = 'auto-list';
```

as I mentioned before, please contact us so we can help you better with this problem, as we don't provide support via github issues

"
2626904613,issue,open,,Snowflake vector column causes sync to fail,"### Describe the bug

When running Metabase sync with a vector column on Snowflake, it fails the entire sync (not only the affected table) with this error:
An SQLException was provoked by the following failure: java.lang.IllegalArgumentException: No enum constant net.snowflake.client.jdbc.SnowflakeType.VECTOR

Probably upgrading the Snowflake driver is enough to fix this?

### To Reproduce

Create a Snowflake table with a VECTOR column and sync it

### Expected behavior

Vector columns should not break the sync

### Logs

[ed9270f8-d33d-4d8b-9633-740eab0a7390] 2024-10-31T10:37:45-03:00 ERROR metabase.sync.fetch-metadata Error while fetching metdata with 'table-fields-metadata',java.sql.SQLException: An SQLException was provoked by the following failure: java.lang.IllegalArgumentException: No enum constant net.snowflake.client.jdbc.SnowflakeType.VECTOR,	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118),	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:77),	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:74),	at com.mchange.v2.c3p0.impl.NewPooledConnection.handleThrowable(NewPooledConnection.java:505),	at com.mchange.v2.c3p0.impl.NewProxyResultSet.next(NewProxyResultSet.java:699),	at metabase.driver.sql_jdbc.sync.common$reducible_results$reify__84551$fn__84552.invoke(common.clj:43),	at clojure.core$repeatedly$fn__6531.invoke(core.clj:5175),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.Cons.next(Cons.java:39),	at clojure.lang.RT.next(RT.java:713),	at clojure.core$next__5451.invokeStatic(core.clj:64),	at clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:169),	at clojure.core.protocols$fn__8249.invoke(protocols.clj:124),	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19),	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31),	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75),	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75),	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13),	at clojure.core$reduce.invokeStatic(core.clj:6887),	at clojure.core$reduce.invoke(core.clj:6869),	at metabase.driver.sql_jdbc.sync.common$reducible_results$reify__84551.reduce(common.clj:39),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core.Eduction.reduce(core.clj:7751),	at clojure.core$reduce.invokeStatic(core.clj:6886),	at clojure.core$cat$fn__8851.invoke(core.clj:7694),	at clojure.lang.PersistentVector.reduce(PersistentVector.java:343),	at clojure.core$reduce.invokeStatic(core.clj:6886),	at clojure.core$reduce.invoke(core.clj:6869),	at metabase.driver.sql_jdbc.sync.describe_table$fields_metadata$reify__84602.reduce(describe_table.clj:168),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core$into.invokeStatic(core.clj:6963),	at clojure.core$into.invoke(core.clj:6951),	at metabase.driver.sql_jdbc.sync.describe_table$fn__84623.invokeStatic(describe_table.clj:214),	at metabase.driver.sql_jdbc.sync.describe_table$fn__84623.invoke(describe_table.clj:212),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.driver.snowflake$fn__115407$fn__115409.invoke(snowflake.clj:562),	at metabase.driver.sql_jdbc.execute$fn__82321$fn__82322.invoke(execute.clj:398),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321),	at metabase.driver.sql_jdbc.execute$fn__82321.invokeStatic(execute.clj:392),	at metabase.driver.sql_jdbc.execute$fn__82321.invoke(execute.clj:390),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.driver.snowflake$fn__115407.invokeStatic(snowflake.clj:556),	at metabase.driver.snowflake$fn__115407.invoke(snowflake.clj:554),	at clojure.lang.MultiFn.invoke(MultiFn.java:239),	at metabase.sync.fetch_metadata$table_fields_metadata.invokeStatic(fetch_metadata.clj:45),	at metabase.sync.fetch_metadata$table_fields_metadata.invoke(fetch_metadata.clj:32),	at metabase.sync.fetch_metadata$describe_fields_using_describe_table$fn__85536.invoke(fetch_metadata.clj:60),	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759),	at clojure.core$completing$fn__8528.invoke(core.clj:6932),	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759),	at toucan2.pipeline$with_init$fn__21680.invoke(pipeline.clj:327),	at clojure.core$completing$fn__8528.invoke(core.clj:6932),	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759),	at toucan2.jdbc.result_set$reduce_result_set.invokeStatic(result_set.clj:158),	at toucan2.jdbc.result_set$reduce_result_set.invoke(result_set.clj:125),	at toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:51),	at toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22),	at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19),	at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:15),	at methodical.impl.combo.threaded$combine_methods_thread_last$fn__18492$combined_method_thread_last__18493.invoke(threaded.clj:64),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:216),	at toucan2.pipeline$transduce_execute$with_connection_STAR___21600.invoke(pipeline.clj:78),	at toucan2.connection$bind_current_connectable_fn$fn__21277.invoke(connection.clj:104),	at toucan2.connection$bind_current_connectable_fn$fn__21277.invoke(connection.clj:104),	at toucan2.connection$bind_current_connectable_fn$fn__21277.invoke(connection.clj:104),	at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invokeStatic(connection.clj:18),	at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invoke(connection.clj:15),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210),	at metabase.db.connection$do_with_connection_primary_method_default.invokeStatic(connection.clj:132),	at metabase.db.connection$do_with_connection_primary_method_default.invoke(connection.clj:130),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210),	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204),	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118),	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210),	at toucan2.pipeline$transduce_execute.invokeStatic(pipeline.clj:77),	at toucan2.pipeline$transduce_execute.invoke(pipeline.clj:64),	at clojure.lang.Var.invoke(Var.java:399),	at toucan2.pipeline$transduce_compiled_query.invokeStatic(pipeline.clj:244),	at toucan2.pipeline$transduce_compiled_query.invoke(pipeline.clj:240),	at toucan2.pipeline$transduce_built_query.invokeStatic(pipeline.clj:252),	at toucan2.pipeline$transduce_built_query.invoke(pipeline.clj:246),	at toucan2.pipeline$transduce_query_primary_method_default.invokeStatic(pipeline.clj:272),	at toucan2.pipeline$transduce_query_primary_method_default.invoke(pipeline.clj:269),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:15),	at methodical.impl.combo.threaded$combine_methods_thread_last$fn__18492$combined_method_thread_last__18493.invoke(threaded.clj:64),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:216),	at toucan2.pipeline$transduce_query_STAR_.invokeStatic(pipeline.clj:278),	at toucan2.pipeline$transduce_query_STAR_.invoke(pipeline.clj:274),	at toucan2.pipeline$transduce_with_model.invokeStatic(pipeline.clj:293),	at toucan2.pipeline$transduce_with_model.invoke(pipeline.clj:280),	at toucan2.pipeline$transduce_parsed.invokeStatic(pipeline.clj:309),	at toucan2.pipeline$transduce_parsed.invoke(pipeline.clj:295),	at toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:317),	at toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:669),	at clojure.core$apply.invoke(core.clj:662),	at toucan2.pipeline$reducible_fn$reify__21700.reduce(pipeline.clj:386),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core.Eduction.reduce(core.clj:7751),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core.Eduction.reduce(core.clj:7751),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core$transduce.invoke(core.clj:6934),	at metabase.sync.sync_metadata.fields$sync_fields_BANG_$fn__85598.invoke(fields.clj:82),	at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189),	at metabase.sync.util$do_with_error_handling.invoke(util.clj:182),	at metabase.sync.sync_metadata.fields$sync_fields_BANG_.invokeStatic(fields.clj:76),	at metabase.sync.sync_metadata.fields$sync_fields_BANG_.invoke(fields.clj:71),	at clojure.lang.AFn.applyToHelper(AFn.java:154),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:669),	at clojure.core$apply.invoke(core.clj:662),	at metabase.sync.util$run_step_with_metadata$fn__57869$fn__57872.invoke(util.clj:488),	at metabase.models.task_history$do_with_task_history.invokeStatic(task_history.clj:115),	at metabase.models.task_history$do_with_task_history.invoke(task_history.clj:104),	at metabase.sync.util$run_step_with_metadata$fn__57869.doInvoke(util.clj:482),	at clojure.lang.RestFn.invoke(RestFn.java:397),	at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130),	at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124),	at metabase.sync.util$with_start_and_finish_debug_logging.invokeStatic(util.clj:148),	at metabase.sync.util$with_start_and_finish_debug_logging.invoke(util.clj:144),	at metabase.sync.util$run_step_with_metadata.invokeStatic(util.clj:477),	at metabase.sync.util$run_step_with_metadata.invoke(util.clj:472),	at metabase.sync.util$run_sync_operation$fn__57911$fn__57919.invoke(util.clj:561),	at metabase.sync.util$run_sync_operation$fn__57911.invoke(util.clj:559),	at metabase.models.task_history$do_with_task_history.invokeStatic(task_history.clj:115),	at metabase.models.task_history$do_with_task_history.invoke(task_history.clj:104),	at metabase.sync.util$run_sync_operation.invokeStatic(util.clj:556),	at metabase.sync.util$run_sync_operation.invoke(util.clj:551),	at metabase.sync.sync_metadata$sync_db_metadata_BANG_$fn__86090.invoke(sync_metadata.clj:70),	at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189),	at metabase.sync.util$do_with_error_handling.invoke(util.clj:182),	at clojure.core$partial$fn__5910.invoke(core.clj:2647),	at metabase.driver$fn__55334.invokeStatic(driver.clj:826),	at metabase.driver$fn__55334.invoke(driver.clj:826),	at clojure.lang.MultiFn.invoke(MultiFn.java:239),	at metabase.sync.util$sync_in_context$fn__57780.invoke(util.clj:165),	at metabase.sync.util$with_db_logging_disabled$fn__57777.invoke(util.clj:157),	at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130),	at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124),	at metabase.sync.util$with_start_and_finish_logging$fn__57764.invoke(util.clj:142),	at metabase.sync.util$with_sync_events$fn__57759.invoke(util.clj:116),	at metabase.sync.util$with_duplicate_ops_prevented$fn__57746.invoke(util.clj:88),	at metabase.sync.util$do_sync_operation.invokeStatic(util.clj:214),	at metabase.sync.util$do_sync_operation.invoke(util.clj:208),	at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:68),	at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:65),	at metabase.api.database$fn__99281$fn__99286.invoke(database.clj:1021),	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047),	at clojure.lang.AFn.call(AFn.java:18),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	at java.base/java.lang.Thread.run(Unknown Source),Caused by: java.lang.IllegalArgumentException: No enum constant net.snowflake.client.jdbc.SnowflakeType.VECTOR,	at java.base/java.lang.Enum.valueOf(Unknown Source),	at net.snowflake.client.jdbc.SnowflakeType.valueOf(SnowflakeType.java:23),	at net.snowflake.client.jdbc.SnowflakeType.fromString(SnowflakeType.java:53),	at net.snowflake.client.jdbc.SnowflakeUtil.getSnowflakeType(SnowflakeUtil.java:217),	at net.snowflake.client.jdbc.SnowflakeUtil.extractColumnMetadata(SnowflakeUtil.java:184),	at net.snowflake.client.jdbc.SnowflakeDatabaseMetaData$4.next(SnowflakeDatabaseMetaData.java:1795),	at com.mchange.v2.c3p0.impl.NewProxyResultSet.next(NewProxyResultSet.java:685),	... 184 more

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""snowflake""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-03"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""556ae49""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.28""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.226-214.879.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}

### Severity

Quite annoying, i had to remove the vector column which is used to detect similar tickets

### Additional context

_No response_",sicarul,2024-10-31 13:45:23+00:00,[],2025-02-04 20:25:30+00:00,,https://github.com/metabase/metabase/issues/49388,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2451800843, 'issue_id': 2626904613, 'author': 'bshepherdson', 'body': ""Might not be P1, since it only affects a particular database and only if you're using VECTOR columns."", 'created_at': datetime.datetime(2024, 11, 1, 12, 32, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451834227, 'issue_id': 2626904613, 'author': 'sicarul', 'body': 'If it helps in any way, i see support was added on 3.16: https://docs.snowflake.com/en/release-notes/clients-drivers/jdbc-2024#version-3-16-0-april-29-2024\n\nAnd metabase is currently using 3.15.1 (If i understand correctly):\nhttps://github.com/metabase/metabase/blob/5879f90bfa601fe3a35db153d86cac4d0c1dcc58/modules/drivers/snowflake/deps.edn#L5', 'created_at': datetime.datetime(2024, 11, 1, 13, 0, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452118739, 'issue_id': 2626904613, 'author': 'paoliniluis', 'body': ""just merged the dep bump, but I don't think it will make a difference"", 'created_at': datetime.datetime(2024, 11, 1, 15, 56, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481268412, 'issue_id': 2626904613, 'author': 'perivamsi', 'body': ""I don't think this should be a P1, bumping down to a P2. We can make it a P1 if we have more info."", 'created_at': datetime.datetime(2024, 11, 17, 13, 32, 15, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-11-01 12:32:52 UTC): Might not be P1, since it only affects a particular database and only if you're using VECTOR columns.

sicarul (Issue Creator) on (2024-11-01 13:00:14 UTC): If it helps in any way, i see support was added on 3.16: https://docs.snowflake.com/en/release-notes/clients-drivers/jdbc-2024#version-3-16-0-april-29-2024

And metabase is currently using 3.15.1 (If i understand correctly):
https://github.com/metabase/metabase/blob/5879f90bfa601fe3a35db153d86cac4d0c1dcc58/modules/drivers/snowflake/deps.edn#L5

paoliniluis on (2024-11-01 15:56:58 UTC): just merged the dep bump, but I don't think it will make a difference

perivamsi on (2024-11-17 13:32:15 UTC): I don't think this should be a P1, bumping down to a P2. We can make it a P1 if we have more info.

"
2626483460,issue,open,,"Postgres JSONB ""?"" operator not compatible with field filter","### Describe the bug

Using both the [`?` JSONB operator](https://www.postgresql.org/docs/9.4/functions-json.html#FUNCTIONS-JSONB-OP-TABLE) - checking if a key/element is in a JSON value - and a date time field filter  on Postgres 16 raises a cryptic error ""No value specified for parameter 3.""

EDIT: this seems to be actually the case for any type of field filter (not just date time), though the error message can specify a different parameter with no value specified

### To Reproduce

1. With a PostgreSQL connection, create a table with a JSONB and a timestamp column (minimal example below)

```
CREATE TABLE public.entities (
	id serial4 NOT NULL,
	setup jsonb NULL,
	created_at timestamp DEFAULT (now() AT TIME ZONE 'utc'::text) NOT NULL,
	CONSTRAINT idx_dsfkf_primary PRIMARY KEY (id)
	);
```
```
INSERT INTO entities (setup) VALUES (JSON_BUILD_OBJECT('some_array,' ARRAY['a', 'b']))
```

2. In metabase, create a new sql query with

```
SELECT entities.id
    FROM entities
    WHERE entities.setup -> 'some_array ? 'a
    AND  {{entity_creation_date}}
```

3. Set up the `entity_creation_date` as a `field_filter` pointing to `entities.created_at` and select any value for the filter to be active

4. A cryptic `No value specified for parameter 3.` appears. 

5. Clicking on `preview the query` shows that the same filter is injected on the `?` operator as on the `entity_creation_date` parameter

```
SELECT entities.id
    FROM entities
   
WHERE entities.setup -> 'usage' timestamp with time zone '2024-10-20 00:00:00.000Z' 'collection'
   
   AND  ""public"".""entities"".""created_at"" >= timestamp with time zone '2024-10-27 00:00:00.000Z' AND ""public"".""entities"".""created_at"" < ?
```

6. By removing either filter the query executes correctly.

### Expected behavior

The SQL query should execute correctly

### Logs

_No response_

### Information about your Metabase installation

- Postgres 16
- Running metabase 0.50.31 on Docker

### Severity

Completely blocking the usage of some queries

### Additional context

_No response_",LoicEm,2024-10-31 10:14:56+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/49373,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Postgres', None), ('Querying/Processor', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', '')]",[],
2625685239,issue,closed,completed,sending dashboard to slack using metabase app doesn’t work,"### Describe the bug


[9c7b662c-5340-43f1-ac5a-c34e907a7d73] 2024-10-30T19:41:19-05:00 ERROR metabase.pulse Error sending notification!,clojure.lang.ExceptionInfo: Slack API error: method_deprecated {:error-code ""method_deprecated"", :message ""Slack API error: method_deprecated"", :response {:ok false, :error ""method_deprecated""}, :url ""https://slack.com/api/files.upload""},	at 

gives this error when I try sending a dashboard to slack using the slack integration.



### To Reproduce

1. create slack app
2. add token to metabase
3. send dashboard to slack

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Metabase version: v0.49.1
using postgresql as database
deployed as docker container on ubuntu 22.04 LTS

### Severity

High

### Additional context

_No response_",Souldiv,2024-10-31 00:54:31+00:00,[],2024-10-31 02:03:01+00:00,2024-10-31 02:03:01+00:00,https://github.com/metabase/metabase/issues/49368,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2448867352, 'issue_id': 2625685239, 'author': 'perivamsi', 'body': 'Please upgrade to the latest version: https://github.com/metabase/metabase/releases/tag/v0.50.31\n\nFixed by this PR: https://github.com/metabase/metabase/pull/41974', 'created_at': datetime.datetime(2024, 10, 31, 2, 2, 42, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-10-31 02:02:42 UTC): Please upgrade to the latest version: https://github.com/metabase/metabase/releases/tag/v0.50.31

Fixed by this PR: https://github.com/metabase/metabase/pull/41974

"
2625271332,issue,closed,completed,Time granularity parameters reset pivot table settings,"### Describe the bug

When a time granularity parameter is mapped to a question visualized as a pivot table, changing the unit would lead to pivot table settings being (partially) reset to default values.
Context https://metaboat.slack.com/archives/C01LQQ2UW03/p1730249022766219

### To Reproduce

1. New -> Question -> Orders
2. Aggregate -> Sum of Total, Sum of Tax
3. Breakout -> Created At (Year), Created At (Quarter of Year), Product.Category
4. Visualize as a Pivot Table
5. Go to the viz settings and change the rows/column split, e.g. move `Created At: Quarter of Year` to Columns if was in Rows:
![Image](https://github.com/user-attachments/assets/9b112882-3ae3-4e6f-8bbf-6ea921da9b1b)
6. Save
6. Add this question to a dashboard and add a time granularity parameter. Map it to `Created At: Quarter of Year` (until another bug is solved it would be the second `Created At` column)
7. Set the parameter value to `Month of Year`
8. You should see that the viz settings were reset in the dashboard card
9. Click on the card title to drill to the query builder. See that the settings are reset. Open the viz settings to verify this:
![Image](https://github.com/user-attachments/assets/027c1a66-3a95-449f-948a-f264cb691bf4)

The reason why it happens is because we store pivot settings as field refs:
```
""pivot_table.column_split"": {
  rows: [[""field"", ORDERS.CREATED_AT, { ""temporal-unit"": ""month"" }]],
  columns: [],
  values: [[""aggregation"", 0]],
},
```

When the temporal unit changes, the field ref also changes, and it leads to the settings becoming invalid.

### Expected behavior

The settings should be preserved. 

### Logs

_No response_

### Information about your Metabase installation

v51.1

### Severity

P2

### Additional context

_No response_",ranquild,2024-10-30 20:30:32+00:00,['ranquild'],2024-11-06 02:38:06+00:00,2024-11-06 02:38:00+00:00,https://github.com/metabase/metabase/issues/49363,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2458613737, 'issue_id': 2625271332, 'author': 'ranquild', 'body': 'Fixed by https://github.com/metabase/metabase/pull/49414', 'created_at': datetime.datetime(2024, 11, 6, 2, 38, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-11-06 02:38:00 UTC): Fixed by https://github.com/metabase/metabase/pull/49414

"
2625165842,issue,closed,completed,Migrated metrics do not respect collection permissions,"### Describe the bug

If you move from <51 versions to 51 and you had metrics on your tables, then these will be moved to a new collection called ""migrated metrics v1"". If a group has ""view"" permissions on this collection then they won't be able to see it at all, but they'll be able to see the metrics in the table

### To Reproduce

1) spin up v50 and create 1-2 metrics in the people table
2) create a group and a user inside this new group. Leave permissions as they are
3) now move to v51, where metrics are an entity that live inside a collection (the metrics you created will be included in the ""migrated metrics v1"" collection)
4) Check that the All users ""view only"" to the collection and the new group has a ""no access"" permission
5) authenticate with the new user and check if you can see the collection (you can't), but the new user can see the metrics on the table


### Expected behavior

If the ""All users"" group has ""view"" access, then the user should be able to see the collection

Also, if the user can't see the metrics on the collection, then the user shouldn't be able to see the metric on the table

### Logs

_No response_

### Information about your Metabase installation

v51

### Severity

P2

### Additional context

The weirdest thing ever: several ways in which the user can see the new collection
1) giving curate to all users (?)
2) giving ""view"" on the collection to the new group, saving and then removing the ""view"" permission",paoliniluis,2024-10-30 19:41:53+00:00,['noahmoss'],2024-11-01 21:19:30+00:00,2024-11-01 21:19:30+00:00,https://github.com/metabase/metabase/issues/49357,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Querying/Metrics', 'v2'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2448254921, 'issue_id': 2625165842, 'author': 'ranquild', 'body': 'it seems that there are 2 related issues 1) access to ""Migrated Metrics v1"" collection, 2) Metrics read permission checks.\n\n### Access to ""Migrated Metrics v1"" collection\n\nIt\'s now possible that some users won\'t have read access to ""Migrated Metrics v1"" when migrated to v51. This happens because we only grant access to ""All Users"" group and not others https://github.com/metabase/metabase/blob/d208d800c341f76c5cf66f351a44fecf852040bf/src/metabase/db/custom_migrations/metrics_v2.clj#L25. If a user was in a group (apart from ""All Users"") where access to ""Our analytics"" was blocked, they would not see ""Migrated Metrics V1"" collection after the migration.\n\nRepro:\n- Run v50 (`dcbb060ece9e1b499e36cba1264f827268d73dfc`)\n- Create a test user U1\n- Create a group G1 and add U1 to it\n- Change collection permissions so the G1\'s access to ""Our analytics"" is Blocked\n- Run v51 (`713b55ecac2d2fa2464dec88f3e23ff7fe686d1f`)\n- See that U1 doesn\'t see ""Migrated Metrics v1"" collection\n\nExpected behavior:\n- We should give read access to the newly created ""Migrated Metrics v1"" collection to all existing user groups during the migration.\n\n### Metrics read permission checks\n\nThe repro is the same as for the issue above. While U1 cannot see the ""Migrated Metrics v1"" collection, U1 can create new queries in the query builder and see all metrics. It seems that `can-read?` checks still follow the legacy metrics model and are not based on the collection permissions.\n\nExpetected behavior:\n- Metrics, both migrated and new ones, should follow our regular collection permissions model.\n- We need to make sure this works correctly for data returned by the API and when executing queries. It should not be possible to execute a query with an inaccessible metric.', 'created_at': datetime.datetime(2024, 10, 30, 20, 1, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2449851953, 'issue_id': 2625165842, 'author': 'lbrdnk', 'body': 'Removed my assignment and changed team label as per the discussion [on slack](https://metaboat.slack.com/archives/C0645JP1W81/p1730379488088189?thread_ts=1730318676.199629&cid=C0645JP1W81).', 'created_at': datetime.datetime(2024, 10, 31, 13, 31, 35, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-10-30 20:01:34 UTC): it seems that there are 2 related issues 1) access to ""Migrated Metrics v1"" collection, 2) Metrics read permission checks.

### Access to ""Migrated Metrics v1"" collection

It's now possible that some users won't have read access to ""Migrated Metrics v1"" when migrated to v51. This happens because we only grant access to ""All Users"" group and not others https://github.com/metabase/metabase/blob/d208d800c341f76c5cf66f351a44fecf852040bf/src/metabase/db/custom_migrations/metrics_v2.clj#L25. If a user was in a group (apart from ""All Users"") where access to ""Our analytics"" was blocked, they would not see ""Migrated Metrics V1"" collection after the migration.

Repro:
- Run v50 (`dcbb060ece9e1b499e36cba1264f827268d73dfc`)
- Create a test user U1
- Create a group G1 and add U1 to it
- Change collection permissions so the G1's access to ""Our analytics"" is Blocked
- Run v51 (`713b55ecac2d2fa2464dec88f3e23ff7fe686d1f`)
- See that U1 doesn't see ""Migrated Metrics v1"" collection

Expected behavior:
- We should give read access to the newly created ""Migrated Metrics v1"" collection to all existing user groups during the migration.

### Metrics read permission checks

The repro is the same as for the issue above. While U1 cannot see the ""Migrated Metrics v1"" collection, U1 can create new queries in the query builder and see all metrics. It seems that `can-read?` checks still follow the legacy metrics model and are not based on the collection permissions.

Expetected behavior:
- Metrics, both migrated and new ones, should follow our regular collection permissions model.
- We need to make sure this works correctly for data returned by the API and when executing queries. It should not be possible to execute a query with an inaccessible metric.

lbrdnk on (2024-10-31 13:31:35 UTC): Removed my assignment and changed team label as per the discussion [on slack](https://metaboat.slack.com/archives/C0645JP1W81/p1730379488088189?thread_ts=1730318676.199629&cid=C0645JP1W81).

"
2624927656,issue,closed,completed,Large Pivot Tables fail to download (CSV) when Keep Data Pivoted is enabled,"### Describe the bug

When you try to download a big Pivot table it seems to break (i cannot find the breaking limit though)

### To Reproduce

1. Go to -> Question -> Sample Database and Create a large Table like so:

![Image](https://github.com/user-attachments/assets/434b4a80-64e8-4afe-bac7-69fba448d0f0)

2. Turn it into a Pivot Visual and set the following Rows and Measures:

![Image](https://github.com/user-attachments/assets/093be1dd-adda-492f-b7d8-6895082fc32b)

3. Try to Download the Pivot as a CSV with the Keep Data Pivoted enabled (the error doesn't happen when the toggle is disabled):

![Image](https://github.com/user-attachments/assets/89dd5cad-d3dd-425e-866f-b3a956385cf2)

The file might not download, and the export causes CPU spiking
https://github.com/metabase/metabase/issues/49977#issuecomment-2477094397

There is [question on stats ](https://stats.metabase.com/question/20344-large-pivots-break-download-tony)for this to test it out

### Expected behavior

The download works or we explain why it doesn't

### Information about your Metabase installation

Version 51

### Severity

Even though this is new functionality it will kind of break current implementation since by default the Keep Data Pivoted is enabled and users will notice the download to start failing

### Additional context

_No response_",Tony-metabase,2024-10-30 18:12:05+00:00,['adam-james-v'],2024-11-18 21:22:08+00:00,2024-11-18 21:10:51+00:00,https://github.com/metabase/metabase/issues/49353,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2464809816, 'issue_id': 2624927656, 'author': 'Tony-metabase', 'body': '@adam-james-v this is still a problem even though it looks like the fix is merged ... If you try to download the question i have created on stats it still fails with the same error', 'created_at': datetime.datetime(2024, 11, 8, 13, 48, 13, tzinfo=datetime.timezone.utc)}]","Tony-metabase (Issue Creator) on (2024-11-08 13:48:13 UTC): @adam-james-v this is still a problem even though it looks like the fix is merged ... If you try to download the question i have created on stats it still fails with the same error

"
2624805994,issue,closed,completed,Add userAgent to Databricks connections,"Based on Databricks partner docs, we need to pass User Agent to all Databricks connections:
Should be backported to 51

Passing User Agent Tag for ODBC/JDBC
User application name and version
Simba, starting with JDBC v2.6.16 and ODBC v2.6.15 drivers , has added a new connection string
parameter, through which user applications can specify their entry to the User-Agent. The parameter will
be UserAgentEntry. Simba will validate the value provided by the user application against the format
<isv-name+product-name>/<product-version> <comment>
Only one comment is allowed, without any nesting - ie. any characters except for comma, parentheses or
new lines.
Spaces in connection string values are preserved without any escaping.
Simba will return an error to the user application if the entry does not conform: ""Incorrect format for
User-Agent entry, received: <value obtained from connection string>""

Example 2 : To set the user agent for JDBC in Java
Sample code for setting the User Agent

com.simba.spark.jdbc.DataSource ds = new com.simba.spark.jdbc.DataSource();
ds.setCustomProperty(""UserAgentEntry"", ""<isv-name+product-name>"");

Example 3: To set the user agent for JDBC as part of the JDBC URI
Append "";UserAgentEntry=<isv-name+product-name>"" to the connection URL (the one that starts with
""jdbc:spark://"").


---

If passing only <isv-name+product-name> we pass `Metabase`
Whenever <isv-name+product-name>/<product-version>, we pass `Metabase/vX.XX.X`",luizarakaki,2024-10-30 17:23:41+00:00,['snoe'],2024-11-04 22:54:39+00:00,2024-11-01 15:08:54+00:00,https://github.com/metabase/metabase/issues/49350,"[('Database/Databricks', ''), ('.Team/Drivers', '')]",[],
2624646470,issue,closed,completed,Card Name on Dashboard Incorrect when Card Errors,"### Describe the bug

If you have a bar chart with more than 100 series in it the card title on the dashboard will be set to the name of a record in the break out series from the underlying data.

### To Reproduce

1. Visualize the sample Products table as a bar chart
2. X-Axis breakouts can be Category then Vendor to get to over 100 series
3. Save it and drop it on a dashboard
4. Look at it on the dashboard and note that one of the values from the result set is the card name

Custom names set in viz settings are also ignored when this error occurs. If you go back and add a limit to the question the card title is correct again. 

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

v51 and v50

Didn't include diagnostic information because I was able to reproduce quickly without it.

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-10-30 16:23:34+00:00,['lorem--ipsum'],2025-02-03 06:55:23+00:00,2025-02-03 06:09:53+00:00,https://github.com/metabase/metabase/issues/49348,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2624566015,issue,closed,completed,can't scroll inside fullscreen `InteractiveDashboard` or `EditableDashboard`,"### Describe the bug

Tangentially I couldn't find how to enter the fullscreen mode on `StaticDashboard`

Neither `InteractiveDashboard` nor `EditableDashboard` can scroll when entering the fullscreen mode.

If you have a really long dashboard that doesn't fit on a single screen.

### To Reproduce

1. Embed a long dashboard using `InteractiveDashboard` and `EditableDashboard`
2. Enter fullscreen on both components and test if you could scroll


### Expected behavior

I could scroll inside the fullscreen mode

### Logs

_No response_

### Information about your Metabase installation

- 

### Severity

annoying p2

### Additional context

_No response_",WiNloSt,2024-10-30 15:59:24+00:00,['deniskaber'],2024-11-06 13:33:25+00:00,2024-11-01 11:34:12+00:00,https://github.com/metabase/metabase/issues/49346,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2624539928,issue,closed,completed,Update docs around the limitation on multiple instances of `InteractiveDashboard` and `EditableDashboard`,"### Describe the bug

When using this markup

```tsx
    <MetabaseProvider config={config}>
      <Title order={2}>{'<InteractiveDashboard />'}</Title>
      <InteractiveDashboard dashboardId={8} withDownloads />
      <Divider my=""lg"" />

      <Title order={2}>{'<StaticDashboard />'}</Title>
      <StaticDashboard dashboardId={8} />
      <Divider my=""lg"" />

      <Title order={2}>{'<EditableDashboard />'}</Title>
      <EditableDashboard dashboardId={8} />
      <Divider my=""lg"" />
    </MetabaseProvider>
```

The dashboard tab state is shared among the 3 dashboard components. There might be other states shared unintentionally.

![Image](https://github.com/user-attachments/assets/21554be9-afed-4531-9e45-32d32ee40d7b)


### To Reproduce

1. Use the markup above and embed a dashboard with more than 1 tab
2. Run the user app, and change tab on one of the component, you'll notice that all dashboard components also change the tab.

### Expected behavior

The state isn't shared since they're rendered separately.

### Logs

_No response_

### Information about your Metabase installation

- 

### Severity

annoying

### Additional context

_No response_",WiNloSt,2024-10-30 15:50:02+00:00,['deniskaber'],2024-11-26 18:51:54+00:00,2024-11-05 12:33:41+00:00,https://github.com/metabase/metabase/issues/49345,"[('Type:Documentation', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2448108067, 'issue_id': 2624539928, 'author': 'deniskaber', 'body': ""@WiNloSt , what do you think should be expected behavior?\nWe discussed that currently we don't support multiple dashboards on a page. Apart from tab state there are much more clashes with global state there."", 'created_at': datetime.datetime(2024, 10, 30, 19, 3, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2449277728, 'issue_id': 2624539928, 'author': 'WiNloSt', 'body': ""@deniskaber I'm not aware of the latest discussion, is there a doc or anything I can look at so I could refresh my memory?\n\nBut as you mentioned, if this is not supported, then maybe I could rephrase this bug into a feature request like support more than 1 dashboard in a single provider? What do you thinK?"", 'created_at': datetime.datetime(2024, 10, 31, 8, 10, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2449347201, 'issue_id': 2624539928, 'author': 'heypoom', 'body': ""FYI, we do have this notice in our `README.md` in NPM currently:\n\n```md\n- Embedding multiple instances of interactive dashboards on the same page is not supported.\n  - Please use static dashboards if you need to embed multiple dashboards on the same page.\n```\n\nWe don't explicitly mention the issue with static and interactive dashboards having a shared state though, so we might possibly want to update the README here?"", 'created_at': datetime.datetime(2024, 10, 31, 8, 52, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2449401551, 'issue_id': 2624539928, 'author': 'WiNloSt', 'body': ""> FYI, we do have this notice in our `README.md` in NPM currently:\n> \n> - Embedding multiple instances of interactive dashboards on the same page is not supported.\n>   - Please use static dashboards if you need to embed multiple dashboards on the same page.\n> We don't explicitly mention the issue with static and interactive dashboards having a shared state though, so we might possibly want to update the README here?\n\n@heypoom I think we should update that to reflect the new behavior. Something along the line that only `StaticDashboard` supports multiple instances, the rest (`Interactive*`, and `Editable*`) aren't."", 'created_at': datetime.datetime(2024, 10, 31, 9, 23, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451463929, 'issue_id': 2624539928, 'author': 'heypoom', 'body': '@WiNloSt True. I think the strange behaviour that is worth pointing out is that even using `StaticDashboard` with `InteractiveDashboard` in fact does not work - both dashboard converges to a single shared dashboard id/state.', 'created_at': datetime.datetime(2024, 11, 1, 7, 55, 20, tzinfo=datetime.timezone.utc)}]","deniskaber (Assginee) on (2024-10-30 19:03:06 UTC): @WiNloSt , what do you think should be expected behavior?
We discussed that currently we don't support multiple dashboards on a page. Apart from tab state there are much more clashes with global state there.

WiNloSt (Issue Creator) on (2024-10-31 08:10:18 UTC): @deniskaber I'm not aware of the latest discussion, is there a doc or anything I can look at so I could refresh my memory?

But as you mentioned, if this is not supported, then maybe I could rephrase this bug into a feature request like support more than 1 dashboard in a single provider? What do you thinK?

heypoom on (2024-10-31 08:52:40 UTC): FYI, we do have this notice in our `README.md` in NPM currently:

```md
- Embedding multiple instances of interactive dashboards on the same page is not supported.
  - Please use static dashboards if you need to embed multiple dashboards on the same page.
```

We don't explicitly mention the issue with static and interactive dashboards having a shared state though, so we might possibly want to update the README here?

WiNloSt (Issue Creator) on (2024-10-31 09:23:34 UTC): @heypoom I think we should update that to reflect the new behavior. Something along the line that only `StaticDashboard` supports multiple instances, the rest (`Interactive*`, and `Editable*`) aren't.

heypoom on (2024-11-01 07:55:20 UTC): @WiNloSt True. I think the strange behaviour that is worth pointing out is that even using `StaticDashboard` with `InteractiveDashboard` in fact does not work - both dashboard converges to a single shared dashboard id/state.

"
2623478609,issue,closed,completed,Filters on a full screen dashboard with dark mode does not have a dark background,"Reported in https://metaboat.slack.com/archives/C01LQQ2UW03/p1730246980582729

The filters on a full-screen dashboard with dark mode enabled does not have a dark background. We should make sure that filters has a matching background with the theme.

![Image](https://github.com/user-attachments/assets/49545f13-ef59-4717-9a44-45a0e6236e2e)
",heypoom,2024-10-30 09:53:58+00:00,['WiNloSt'],2024-10-31 15:34:44+00:00,2024-10-31 14:08:32+00:00,https://github.com/metabase/metabase/issues/49332,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Team/Embedding', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2447258341, 'issue_id': 2623478609, 'author': 'WiNloSt', 'body': ""This is caused by this line\n\nhttps://github.com/metabase/metabase/blob/35d99ba88be996f9c95701c4afdeb25e17fae54b/frontend/src/metabase/parameters/components/ParameterWidget/ParameterWidget.styled.ts#L12\nfrom https://github.com/metabase/metabase/pull/46428\n\nOn 50, there's no background set\n- ![Image](https://github.com/user-attachments/assets/a4c248bb-9330-4450-b124-72aca229f7a8)\n- ![Image](https://github.com/user-attachments/assets/6ab7653d-01e4-4702-bebe-8a82687dcc4b)\n\non 51, we have a background and on embedding the color will change to match the background color of the theme.\n- ![Image](https://github.com/user-attachments/assets/3efae9ff-92e2-4d15-8021-f0798cfa4be2)\n\nPlease note that on both versions, the filter popover isn't properly theme, and as a part that we discussed in #46428, at that time we decided not to fix the fullscreen dark theme to match the look of the embedding dark theme."", 'created_at': datetime.datetime(2024, 10, 30, 13, 57, 25, tzinfo=datetime.timezone.utc)}]","WiNloSt (Assginee) on (2024-10-30 13:57:25 UTC): This is caused by this line

https://github.com/metabase/metabase/blob/35d99ba88be996f9c95701c4afdeb25e17fae54b/frontend/src/metabase/parameters/components/ParameterWidget/ParameterWidget.styled.ts#L12
from https://github.com/metabase/metabase/pull/46428

On 50, there's no background set
- ![Image](https://github.com/user-attachments/assets/a4c248bb-9330-4450-b124-72aca229f7a8)
- ![Image](https://github.com/user-attachments/assets/6ab7653d-01e4-4702-bebe-8a82687dcc4b)

on 51, we have a background and on embedding the color will change to match the background color of the theme.
- ![Image](https://github.com/user-attachments/assets/3efae9ff-92e2-4d15-8021-f0798cfa4be2)

Please note that on both versions, the filter popover isn't properly theme, and as a part that we discussed in #46428, at that time we decided not to fix the fullscreen dark theme to match the look of the embedding dark theme.

"
2623396941,issue,closed,not_planned,Failed to connect to sparksql after upgrading metabase to v50.31,"### Describe the bug

After upgrading metabase from v0.47.13(v0.47.13 -> v0.48.13 -> v0.49.25 -> v0.50.31) to v0.50.31, we can no longer query data through sparksql from metabase. 



### To Reproduce

1. running metabase with docker image(metabase:metabase:v0.50.3)
2. adding datasource through sparksql.(should failed here)


### Expected behavior

_No response_

### Logs

logs from metabase server:

```
2024-10-30 09:14:25,509 ERROR driver.util :: Failed to connect to Database
java.lang.NoSuchMethodError: 'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)'
	at org.apache.hive.jdbc.HiveConnection.createHttpTransport(HiveConnection.java:372)
	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:341)
	at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:228)
	at metabase.driver.hive_like.fixed_hive_connection.proxy$org.apache.hive.jdbc.HiveConnection$ff19274a.<init>(Unknown Source)
	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invokeStatic(fixed_hive_connection.clj:9)
	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invoke(fixed_hive_connection.clj:9)
	at metabase.driver.sparksql.SparkSQLDataSource.getConnection(sparksql.clj:95)
	at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372)
	at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274)
	at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111)
	at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093)
	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182)
	at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160)
	at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:348)
	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:345)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_$fn__82691.invoke(connection.clj:357)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__82673.invoke(connection.clj:333)
	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:328)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:324)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:356)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:352)
	at metabase.driver.sql_jdbc$fn__108827.invokeStatic(sql_jdbc.clj:49)
	at metabase.driver.sql_jdbc$fn__108827.invoke(sql_jdbc.clj:47)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56580.invoke(util.clj:167)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.base/java.lang.Thread.run(Unknown Source)
```

### Information about your Metabase installation


```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""postgres"",
      ""sparksql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-22"",
      ""tag"": ""v0.50.31"",
      ""hash"": ""f754eda""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Shanghai""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.18""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-45-ponyai"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

### Severity

 blocking an upgrade

### Additional context

_No response_",guicailiao,2024-10-30 09:24:41+00:00,[],2024-10-30 13:20:30+00:00,2024-10-30 13:20:28+00:00,https://github.com/metabase/metabase/issues/49331,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2446482259, 'issue_id': 2623396941, 'author': 'guicailiao', 'body': 'A simple way to reproduce.\n\n1. start container: \n```\ndocker run -d -p 3000:3000 --name metabase metabase/metabase:v0.50.31\n```\n2. access metabase http://localhost:3000\n3. add spark datasource would fail.\n\n![Image](https://github.com/user-attachments/assets/f819130e-07fb-45a4-a0c5-58a30525f347)\n\nNote: Tried `docker run -d -p 3000:3000 --name metabase metabase/metabase:v0.47.13` and it works. `v0.51.1` also not working.', 'created_at': datetime.datetime(2024, 10, 30, 10, 27, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447130596, 'issue_id': 2623396941, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/46793', 'created_at': datetime.datetime(2024, 10, 30, 13, 20, 28, tzinfo=datetime.timezone.utc)}]","guicailiao (Issue Creator) on (2024-10-30 10:27:45 UTC): A simple way to reproduce.

1. start container: 
```
docker run -d -p 3000:3000 --name metabase metabase/metabase:v0.50.31
```
2. access metabase http://localhost:3000
3. add spark datasource would fail.

![Image](https://github.com/user-attachments/assets/f819130e-07fb-45a4-a0c5-58a30525f347)

Note: Tried `docker run -d -p 3000:3000 --name metabase metabase/metabase:v0.47.13` and it works. `v0.51.1` also not working.

paoliniluis on (2024-10-30 13:20:28 UTC): duplicate of https://github.com/metabase/metabase/issues/46793

"
2623079011,issue,closed,completed,Keep search index up to date via hooks,"The idea is to replace the ""leverage in-place search reducible"" way of indexing with a specification, and use this to derive a map dictating what search-models to update when a given toucan model is updated.",crisptrutski,2024-10-30 06:50:57+00:00,['crisptrutski'],2024-11-04 15:47:48+00:00,2024-11-04 15:47:48+00:00,https://github.com/metabase/metabase/issues/49326,"[('.Backend', ''), ('.Team/Workflows', 'aka BEC')]",[],
2623067188,issue,closed,completed,Expose an isOpen prop in the CreateDashboard modal to control modal state in the sdk,"The `CreateDashboard` modal currently always open by default. We should expose a prop to make it easier to control the modal open state, without having to conditionally render the component.

Reference: [Customer Feedback Notion](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4#12f69354c90180719d6be8502f92324a) - see the Grain video there for more context.",heypoom,2024-10-30 06:44:16+00:00,['deniskaber'],2024-11-05 14:30:32+00:00,2024-11-05 13:45:10+00:00,https://github.com/metabase/metabase/issues/49325,[],[],
2622556742,issue,closed,completed,You need to click twice to add a search filter with multiple values,"### Describe the bug

When adding a contains/endswith/startswith filter or Is filter with a searchbox, and using multiple values, you to click on ""Add filter"" once, then the filter editor will become a bit smaller, and you need to click on ""Add filter"" again. 

https://github.com/user-attachments/assets/77daff23-6a0c-4fc3-947d-52e209fb41c7

### To Reproduce

1. Start a query builder question from Products
2. Add a Title filter and switch the operator to Contains
3. Type `Shoes`, comma, `Wallet` 
4. Click ""Add filter""
> Instead of filter being added, there's another prompt to add filter



### Expected behavior

Clicking on ""Add filter"" adds the filter

### Logs

_No response_

### Information about your Metabase installation

51.1, stats

### Severity

Annoying

### Additional context

_No response_",alexyarosh,2024-10-29 23:59:58+00:00,['romeovs'],2024-11-05 11:20:32+00:00,2024-11-05 10:36:34+00:00,https://github.com/metabase/metabase/issues/49321,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2445536919, 'issue_id': 2622556742, 'author': 'alexyarosh', 'body': 'It seems you just need to click _somewhere_ after putting in the values, and then you get the smaller popup with the functioning Add Filter button. It\'s just confusing when the ""somewhere"" happens to be the add filter button itself', 'created_at': datetime.datetime(2024, 10, 30, 0, 1, tzinfo=datetime.timezone.utc)}]","alexyarosh (Issue Creator) on (2024-10-30 00:01:00 UTC): It seems you just need to click _somewhere_ after putting in the values, and then you get the smaller popup with the functioning Add Filter button. It's just confusing when the ""somewhere"" happens to be the add filter button itself

"
2622532106,issue,open,,Make cruft patterns configurable,"We hardcode the cruft patterns right now, but it would be cool if it's just a default and expert users can configure it
https://github.com/metabase/metabase/blob/a223f819c72efd718e86e1267c3bed8ead447105/src/metabase/sync/sync_metadata/tables.clj#L26

related to https://github.com/metabase/metabase/issues/48047",paoliniluis,2024-10-29 23:39:13+00:00,[],2025-02-04 20:30:58+00:00,,https://github.com/metabase/metabase/issues/49320,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', '')]",[],
2622526218,issue,open,,Errors in dashboard edit mode after setting a default for a new parameter,"### Describe the bug

If you set a default for the time grouping parameter or any filter, click ""Done"", but remain in dashboard edit mode, the card will show an error. 

https://github.com/user-attachments/assets/3c31e21f-8638-4672-b12e-4c1472006cbf


If you save a dashboard, everything looks and works fine, so it's just this intermediate stage after saving a parameter but before saving a dashboard that's a problem

### To Reproduce

1. Create Count of Orders by Created At: Month
2. Add it to a new dashboard
3. Add a `Time grouping` widget and connect it to Created At
4. Set the default for time grouping to ""Month""
5. Click ""Done"" in the parameter settings sidebar
-> Card shows error
![Image](https://github.com/user-attachments/assets/0f27627b-c623-43cf-b664-b5f84d24ec2e)



### Expected behavior

Show the card with the default applied

### Logs

_No response_

### Information about your Metabase installation

51.1, Stats

### Severity

Doesn't seem like the actual functionality is broken but the error looks scary for users

### Additional context

_No response_",alexyarosh,2024-10-29 23:32:24+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/49319,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2447929137, 'issue_id': 2622526218, 'author': 'ranquild', 'body': 'Existing issue (pre 51). Happens to all new parameters in dashboards. Not specific to time granularity parameters.', 'created_at': datetime.datetime(2024, 10, 30, 17, 49, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454992413, 'issue_id': 2622526218, 'author': 'kamilmielnik', 'body': ""POST `/api/dashboard/:id/dashcard/:id/card/:id/query` fails saying that parameter with given id does not exist in the dashboard (because the dashboard has not been saved yet).\n\nBut why does it need to exist in the dashboard?\nPayload sent to POST `/api/dashboard/:id/dashcard/:id/card/:id/query` includes information about the type of parameter - it seems that BE has enough information to run the query.\n\nIt would be great if we could fix it BE-side.\nI can't figure out a reasonable thing to do FE-side to address this without losing some functionality or introducing inconsistent behavior.\n\nRelabeling to BE for now."", 'created_at': datetime.datetime(2024, 11, 4, 15, 19, 23, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-10-30 17:49:43 UTC): Existing issue (pre 51). Happens to all new parameters in dashboards. Not specific to time granularity parameters.

kamilmielnik on (2024-11-04 15:19:23 UTC): POST `/api/dashboard/:id/dashcard/:id/card/:id/query` fails saying that parameter with given id does not exist in the dashboard (because the dashboard has not been saved yet).

But why does it need to exist in the dashboard?
Payload sent to POST `/api/dashboard/:id/dashcard/:id/card/:id/query` includes information about the type of parameter - it seems that BE has enough information to run the query.

It would be great if we could fix it BE-side.
I can't figure out a reasonable thing to do FE-side to address this without losing some functionality or introducing inconsistent behavior.

Relabeling to BE for now.

"
2622387182,issue,closed,completed,Type thunk action cases in embedding sdk reducers to fix type errors,"There is a TypeScript error `Type instantiation is excessively deep and possibly infinite
` in `frontend/src/embedding-sdk/store/reducer.ts` in the [Mantine V7 branch](https://github.com/metabase/metabase/pull/49097). 

This is caused by TypeScript trying to compare the types for the `refreshTokenAsync.fulfilled` action case. We should explicitly type the `action` parameter in the `builder.addCase`'s callback, so we don't run into the stack depth issue.

![Image](https://github.com/user-attachments/assets/c827f2c4-66d8-4b7b-9eb8-06544861e149)
",heypoom,2024-10-29 21:43:25+00:00,['heypoom'],2024-11-01 11:06:37+00:00,2024-11-01 11:06:37+00:00,https://github.com/metabase/metabase/issues/49316,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2447353772, 'issue_id': 2622387182, 'author': 'npretto', 'body': ""@heypoom heads up that I'm refactoring that code in https://github.com/metabase/metabase/pull/49214/, I'll open MY PR today in case you want to wait and avoid conflicts"", 'created_at': datetime.datetime(2024, 10, 30, 14, 31, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2448081764, 'issue_id': 2622387182, 'author': 'heypoom', 'body': ""@npretto whoops, sorry just saw your comment. I had the PR https://github.com/metabase/metabase/pull/49352 here open, but it's very simple - just use Immer's syntax to avoid TypeScript type issues. It'd be fairly easy to replicate once your PR merges 🙏🏻"", 'created_at': datetime.datetime(2024, 10, 30, 18, 49, 48, tzinfo=datetime.timezone.utc)}]","npretto on (2024-10-30 14:31:59 UTC): @heypoom heads up that I'm refactoring that code in https://github.com/metabase/metabase/pull/49214/, I'll open MY PR today in case you want to wait and avoid conflicts

heypoom (Issue Creator) on (2024-10-30 18:49:48 UTC): @npretto whoops, sorry just saw your comment. I had the PR https://github.com/metabase/metabase/pull/49352 here open, but it's very simple - just use Immer's syntax to avoid TypeScript type issues. It'd be fairly easy to replicate once your PR merges 🙏🏻

"
2622380780,issue,open,,"Handle situations where a series is actually called ""other"" and mixed up with viz's automatic ""other"" bucketing","**Is your feature request related to a problem? Please describe.**
From the customer

> We have a ""Other"" label in our database and because MB defaults a certain pie chart slice to ""Other"" it interferers with our label.

**Describe the solution you'd like**
Want to be able to adjust the size of ""Other"" to potentially 0 or some other number as needed to fit the visualization. 

**Describe alternatives you've considered**
none that I'm aware of, except for re-mapping the categories in the field to a higher order / smaller number so that the ""Other"" does not appear in the pie chart. 
",jessicaul,2024-10-29 21:40:38+00:00,[],2025-02-04 20:31:28+00:00,,https://github.com/metabase/metabase/issues/49315,"[('Type:New Feature', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2622218036,issue,open,,CSV Uploads - Sanity Check Post Upload,"**Is your feature request related to a problem? Please describe.**
To have a check on the newly created model against the CSV once it's been uploaded


**Describe the solution you'd like**
- data consistency check: A report summarizing missing values, outliers, and column statistics between newly created model and CSV.

- data validation report: Confirm entity type columns such as ID columns are filled. In the customer's use case, they may have end users uploading CSVs with empty values in these key columns.


**Describe alternatives you've considered**
Manually check.



",FilmonK,2024-10-29 20:05:58+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/49310,"[('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2622188359,issue,closed,completed,Handle iframe-resizer upgrade package logs when using Embedding SDK CLI,"It was reported that SDK CLI has these messages when used:

```
▶ npx @metabase/embedding-sdk-react@latest start
====================================================================

                          IFRAME-RESIZER 5                          

  Iframe-Resizer 5 is now available via the following two packages:

   * @iframe-resizer/parent
   * @iframe-resizer/child

  Additionally their are also new versions of iframe-resizer for
  React, Vue, and jQuery.

  Version 5 of iframe-resizer has been extensively rewritten to
  use modern browser APIs, which has enabled significantly better
  performance and greater accuracy in the detection of content
  resizing events.

  Please see https://iframe-resizer.com/upgrade for more details.

====================================================================

Invalid or unexpected token
``` 

https://metaboat.slack.com/archives/C06FCQT0KMZ/p1730217805758529


We want to avoid this. So, it seems we should lock iframe-resizer to use a version without excess logs",deniskaber,2024-10-29 19:50:25+00:00,['deniskaber'],2024-10-31 19:38:54+00:00,2024-10-31 18:38:38+00:00,https://github.com/metabase/metabase/issues/49307,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2447151320, 'issue_id': 2622188359, 'author': 'WiNloSt', 'body': ""I tested first with node 18 using `npx npx @metabase/embedding-sdk-react@latest start@latest start`, on a fresh vite project bootstrapped with `yarn create vite`, but couldn't reproduce the issue.\n\nThen I test installing `@metabase/embedding-sdk-react` directly using 3 different node versions 18, 20, and 22.\n\nAll 3 versions are tested with 3 options:\n- npm\n- yarn v1\n- yarn v2\n\nbefore testing another option I would remove the SDK package with the current package manager first.\n\n\nStill couldn't reproduce this problem :("", 'created_at': datetime.datetime(2024, 10, 30, 13, 26, 10, tzinfo=datetime.timezone.utc)}]","WiNloSt on (2024-10-30 13:26:10 UTC): I tested first with node 18 using `npx npx @metabase/embedding-sdk-react@latest start@latest start`, on a fresh vite project bootstrapped with `yarn create vite`, but couldn't reproduce the issue.

Then I test installing `@metabase/embedding-sdk-react` directly using 3 different node versions 18, 20, and 22.

All 3 versions are tested with 3 options:
- npm
- yarn v1
- yarn v2

before testing another option I would remove the SDK package with the current package manager first.


Still couldn't reproduce this problem :(

"
2622119561,issue,open,,Cannot sort by a custom column in the source question,"### Describe the bug

If you try to sort by a custom column defined in the source question, the order by clause will be removed.

### To Reproduce

1. New -> Question -> Products
2. Custom column -> `concat([ID], """")` -> Name as `Exp1` -> Done -> Save as `Q1`
3. New -> Question -> `Q1`
4. Summarize -> Count, Breakout -> `Exp1`, Sort -> `Exp1`
5. Notice that the clause is dropped and no sorting is applied

### Expected behavior

It should be possible to sort by custom columns. It works if the custom column is added to the outer question.

### Logs

```
[metabase.lib.normalize] Error normalizing pMBQL:
{:value
 {:lib/type :mbql/query,
  :stages
  [{:lib/type :mbql.stage/mbql,
    :aggregation [[:count {:lib/uuid ""2a27e75c-5535-4b14-99cc-fe3c0d4d5081""}]],
    :breakout [[:field {:base-type :type/Text, :lib/uuid ""a8b1fe2c-2e8c-416a-a883-8fed347e42c2""} ""Exp1""]],
    :order-by
    [[:asc
      {:lib/uuid ""7047fe54-758c-44b6-9442-76e096585a41""}
      [:expression {:base-type :type/Text, :lib/uuid ""76f73983-f9c7-4896-a4b7-9f3a59002a39""} ""Exp1""]]],
    :source-card 35}],
  :database 1},
 :schema #object[malli.core.t_malli$core39848],
 :explain
 {:schema #object[malli.core.t_malli$core39848],
  :value
  {:lib/type :mbql/query,
   :stages
   [{:lib/type :mbql.stage/mbql,
     :aggregation [[:count {:lib/uuid ""2a27e75c-5535-4b14-99cc-fe3c0d4d5081""}]],
     :breakout [[:field {:base-type :type/Text, :lib/uuid ""a8b1fe2c-2e8c-416a-a883-8fed347e42c2""} ""Exp1""]],
     :order-by
     [[:asc
       {:lib/uuid ""7047fe54-758c-44b6-9442-76e096585a41""}
       [:expression {:base-type :type/Text, :lib/uuid ""76f73983-f9c7-4896-a4b7-9f3a59002a39""} ""Exp1""]]],
     :source-card 35}],
   :database 1},
  :errors
  ({:path [0 0 :stages 0 0 0 0 1 :mbql.stage/mbql 0 4 0],
    :in [:stages 0],
    :schema #object[malli.core.t_malli$core39615],
    :value
    {:lib/type :mbql.stage/mbql,
     :aggregation [[:count {:lib/uuid ""2a27e75c-5535-4b14-99cc-fe3c0d4d5081""}]],
     :breakout [[:field {:base-type :type/Text, :lib/uuid ""a8b1fe2c-2e8c-416a-a883-8fed347e42c2""} ""Exp1""]],
     :order-by
     [[:asc
       {:lib/uuid ""7047fe54-758c-44b6-9442-76e096585a41""}
       [:expression {:base-type :type/Text, :lib/uuid ""76f73983-f9c7-4896-a4b7-9f3a59002a39""} ""Exp1""]]],
     :source-card 35}})}}
```

### Information about your Metabase installation

v51.1

### Severity

P2

### Additional context

_No response_",ranquild,2024-10-29 19:15:50+00:00,[],2025-02-04 20:27:12+00:00,,https://github.com/metabase/metabase/issues/49305,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]",[],
2622105085,issue,closed,completed,Editing custom expressions for Contains filter with multiple values causes an error,"### Describe the bug

If you use contains/endwith/startswith filter with multiple values, and then attempt to edit the custom expression, the filter block in the query builder breaks. It works fine when you only have one value in the contains/endwith/startswith filter 

https://github.com/user-attachments/assets/1211a637-3254-4383-ad6e-27707d037fa4


### To Reproduce

1. Start a query builder question from ""Products""
2. Add a filter on `Category`: Contains `Gad`, `Wid`
![Image](https://github.com/user-attachments/assets/8dcbe900-b323-4c5a-83ba-1073799fd146)

4. Click ""Add filter"". (Note: another bug it seems that you have to click ""Add filter"" twice)
5. Once the filter is added, click on it to edit
6. In the filter editing thing, click on the ""Back"" button to get back to the one that has ""Custom expression""
7. Click on ""Custom expression""
8. Error:
![Image](https://github.com/user-attachments/assets/1880d50b-59df-4f7f-a344-9abe32929a04)


### Expected behavior

Opens a custom expression editor with the custom expression for the filter filled in, like it does when there's one value in the filter

### Logs

_No response_

### Information about your Metabase installation

51.1 and master `c3f9a20`

### Severity

P3?

### Additional context

_No response_",alexyarosh,2024-10-29 19:06:56+00:00,['ranquild'],2024-11-29 21:14:41+00:00,2024-11-29 20:30:54+00:00,https://github.com/metabase/metabase/issues/49304,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Hard', ''), ('.Frontend', ''), ('Querying/Notebook/Custom Column', ''), ('.Team/Querying', '')]","[{'comment_id': 2445133995, 'issue_id': 2622105085, 'author': 'ranquild', 'body': ""`format` function in the expression editor doesn't expect the special syntax for multi-value clauses with options"", 'created_at': datetime.datetime(2024, 10, 29, 19, 19, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447175648, 'issue_id': 2622105085, 'author': 'kamilmielnik', 'body': '> `format` function in the expression editor doesn\'t expect the special syntax for multi-value clauses with options\n\nTrue.\n\nAlso `contains` function does not support multiple arguments.\nWhen this is attempted `Lib.diagnoseExpression` throws with `Error: No protocol method IAssociative.-assoc defined for type number: 58`\n\nI don\'t think `contains(...) OR contains(...) OR ...` is acceptable. We need to update MLv2. I added BE label as well.\n\nAnd we need to update [helper text](https://github.com/user-attachments/assets/79ff714e-55b7-4b6c-8f51-8a76a34857f0) which does not mention [the `""case-insensitive""` parameter](https://www.metabase.com/docs/latest/questions/query-builder/expressions-list#contains).', 'created_at': datetime.datetime(2024, 10, 30, 13, 32, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458045604, 'issue_id': 2622105085, 'author': 'ranquild', 'body': '@kamilmielnik this is not an MBQL lib unfortunately. This is legacy MBQL being tricky. We would have to handle it ourselves, there is nothing MBQL lib can do. See this https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/frontend/src/metabase-lib/v1/parameters/utils/mbql.js#L156', 'created_at': datetime.datetime(2024, 11, 5, 19, 59, 40, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-10-29 19:19:50 UTC): `format` function in the expression editor doesn't expect the special syntax for multi-value clauses with options

kamilmielnik on (2024-10-30 13:32:43 UTC): True.

Also `contains` function does not support multiple arguments.
When this is attempted `Lib.diagnoseExpression` throws with `Error: No protocol method IAssociative.-assoc defined for type number: 58`

I don't think `contains(...) OR contains(...) OR ...` is acceptable. We need to update MLv2. I added BE label as well.

And we need to update [helper text](https://github.com/user-attachments/assets/79ff714e-55b7-4b6c-8f51-8a76a34857f0) which does not mention [the `""case-insensitive""` parameter](https://www.metabase.com/docs/latest/questions/query-builder/expressions-list#contains).

ranquild (Assginee) on (2024-11-05 19:59:40 UTC): @kamilmielnik this is not an MBQL lib unfortunately. This is legacy MBQL being tricky. We would have to handle it ourselves, there is nothing MBQL lib can do. See this https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/frontend/src/metabase-lib/v1/parameters/utils/mbql.js#L156

"
2622047296,issue,open,,Support Sandboxing for MongoDB,"**Is your feature request related to a problem? Please describe.**
Yes, interactive embedding can not be used if you have one Mongo database for all your customers since row level security and column level security are not available. 

**Describe the solution you'd like**
Support Sandboxing for MongoDB

**Describe alternatives you've considered**
Piping the data to a SQL db. 

**How important is this feature to you?**
Requested by a user
",psalinasy,2024-10-29 18:36:47+00:00,[],2025-02-04 20:31:01+00:00,,https://github.com/metabase/metabase/issues/49303,"[('Database/Mongo', None), ('Type:New Feature', '')]","[{'comment_id': 2445515672, 'issue_id': 2622047296, 'author': 'paoliniluis', 'body': 'NOTE: if you connect MongoDB via Trino/Presto/Spark you will be able to use sandboxing on MongoDB', 'created_at': datetime.datetime(2024, 10, 29, 23, 36, 56, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-29 23:36:56 UTC): NOTE: if you connect MongoDB via Trino/Presto/Spark you will be able to use sandboxing on MongoDB

"
2621960332,issue,open,,Native query drills should not be available when there are variable template tags,"### Describe the bug

When there are variable template tags, an attempt to drill thru native query results will cause an error. 
Context https://metaboat.slack.com/archives/C01LQQ2UW03/p1728926205066249

### To Reproduce

1. New -> SQL query -> `SELECT * FROM PRODUCTS WHERE {{category}}` -> Field Filter -> Products.Category -> Save
2. Set the filter value to ""Gadget"" and run the query
3. Click on a table column header -> Filter by this column -> Choose anything -> Add filter
4. See the error

### Expected behavior

Just like for unsaved native queries, drills with variable template tags should not be available. Note - `card` and `snippet` template tags should still be allowed.

### Logs

_No response_

### Information about your Metabase installation

v51.1

### Severity

P2

### Additional context

_No response_",ranquild,2024-10-29 17:50:47+00:00,[],2025-02-04 20:27:12+00:00,,https://github.com/metabase/metabase/issues/49300,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]",[],
2621850123,issue,closed,not_planned,Date picker does not pass parameter when opening a card in dashboard,"### Describe the bug

The date picker parameter value is not sent to the card URL when we click on a card in a dashboard.
The issue occurs when SQL is used.

### To Reproduce

1. Create a SQL query
2. Pick a date field and set the variable type = field filter
3. Set filter widget type = all options
4. Create a new dashboard
5. Insert the card
6. Add a filter date picker and Filter operator = all options
7. Connect the filter with the card
8. Save the dashboard
9. Apply the filter like previous 6 months 
10. Click on the card and the parameter for date picket is not passed


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P2

### Additional context

_No response_",fer-batista,2024-10-29 17:01:05+00:00,[],2024-10-29 18:29:14+00:00,2024-10-29 18:29:14+00:00,https://github.com/metabase/metabase/issues/49297,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2444972723, 'issue_id': 2621850123, 'author': 'ranquild', 'body': ""@fer-batista I can't reproduce using the sample database. Could you provide the repro steps? ![Image](https://github.com/user-attachments/assets/757b5431-8328-4a44-b804-c3566157b96a)\n![Image](https://github.com/user-attachments/assets/977625d6-cdee-4a7b-8a70-a5ac141ff2e2)"", 'created_at': datetime.datetime(2024, 10, 29, 17, 54, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445040716, 'issue_id': 2621850123, 'author': 'fer-batista', 'body': '@ranquild Thanks for the reply.\nI contacted the user. He was using the data field twice in the WHERE condition. This caused the filter error.', 'created_at': datetime.datetime(2024, 10, 29, 18, 28, 52, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-10-29 17:54:28 UTC): @fer-batista I can't reproduce using the sample database. Could you provide the repro steps? ![Image](https://github.com/user-attachments/assets/757b5431-8328-4a44-b804-c3566157b96a)
![Image](https://github.com/user-attachments/assets/977625d6-cdee-4a7b-8a70-a5ac141ff2e2)

fer-batista (Issue Creator) on (2024-10-29 18:28:52 UTC): @ranquild Thanks for the reply.
I contacted the user. He was using the data field twice in the WHERE condition. This caused the filter error.

"
2621833293,issue,open,,BE: Add reason to moderation statuses,,escherize,2024-10-29 16:54:28+00:00,[],2024-10-29 16:54:28+00:00,,https://github.com/metabase/metabase/issues/49295,[],[],
2621706006,issue,open,,Command palette shortcut hijacks embedded iframes,"### Describe the bug

Hi there, we are statically embedding Metabase in our application, and our application has a command palette as well which is triggered by `cmd+k` as well. We have upgraded to v0.51.1.4 from a very old version, and now I noticed that our cmd+k shortcut does not work anymore when I click on the iframe, and it works when I click outside. Seems to be related to the recent command palette implementation on Metabase. 

### To Reproduce

1. Embed Metabase in an application that has a support for cmd+k shortcut
2. Try to trigger the shortcut from your application in that embedded page.


### Expected behavior

Embedded application should not hijack the keyboard event.

### Logs

_No response_

### Information about your Metabase installation
```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-28"",
      ""tag"": ""v0.51.1.4"",
      ""hash"": ""9bd8b3c""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.8""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-22-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```
### Severity

Decent, but not critical

### Additional context

_No response_",karakanb,2024-10-29 16:00:44+00:00,[],2025-02-04 20:27:23+00:00,,https://github.com/metabase/metabase/issues/49292,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Search', ''), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', ''), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2602620271, 'issue_id': 2621706006, 'author': 'sanex3339', 'body': '@karakanb hello.\n\n>We have upgraded to v0.51.1.4 from a very old version\n\nCould you please share the version number in which this worked.', 'created_at': datetime.datetime(2025, 1, 20, 14, 50, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604834498, 'issue_id': 2621706006, 'author': 'karakanb', 'body': 'It was working fine on v0.46.6.4.', 'created_at': datetime.datetime(2025, 1, 21, 14, 7, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609146279, 'issue_id': 2621706006, 'author': 'sanex3339', 'body': ""Thank you, @karakanb.\n\nI tested the following three versions:\n- the latest\n- `0.46.6.4`\n- `0.40.*`\n\nAll of them have this behavior.\n\nIt is related to how iframes work for security reasons: events (e.g., click or keypress) inside an iframe do not bubble up to the parent window. Therefore, pressing `cmd + k` when the iframe is in focus won't trigger any keypress listeners on the parent window.\n\nBased on our tests, we have never implemented any logic or hacks to work around this limitation.\n\nI do have one more question, though:\n\nWhen using version `0.46.6.4`, was the `origin` of your application the same as the `origin` of the iframe in which Metabase is embedded? If so, there’s a possibility that the `cmd + k` library you’re using attaches some event listeners directly to the iframe."", 'created_at': datetime.datetime(2025, 1, 23, 8, 26, 49, tzinfo=datetime.timezone.utc)}]","sanex3339 on (2025-01-20 14:50:24 UTC): @karakanb hello.


Could you please share the version number in which this worked.

karakanb (Issue Creator) on (2025-01-21 14:07:49 UTC): It was working fine on v0.46.6.4.

sanex3339 on (2025-01-23 08:26:49 UTC): Thank you, @karakanb.

I tested the following three versions:
- the latest
- `0.46.6.4`
- `0.40.*`

All of them have this behavior.

It is related to how iframes work for security reasons: events (e.g., click or keypress) inside an iframe do not bubble up to the parent window. Therefore, pressing `cmd + k` when the iframe is in focus won't trigger any keypress listeners on the parent window.

Based on our tests, we have never implemented any logic or hacks to work around this limitation.

I do have one more question, though:

When using version `0.46.6.4`, was the `origin` of your application the same as the `origin` of the iframe in which Metabase is embedded? If so, there’s a possibility that the `cmd + k` library you’re using attaches some event listeners directly to the iframe.

"
2621168484,issue,closed,completed,Parameter values missing in public and embedded dashboards,"### Description

Please search for `https://github.com/metabase/metabase/issues/49282` in `dashboard-filters-query-stages.cy.spec.ts` and address the TODOs once this is done. These tests should pass. PR: #49280

### How to reproduce

1. `git checkout dashboard-filter-columns`
2. New > Question > Orders > Join Reviews on Product ID = Product ID > Summarize by Count > Breakout by Category > Summarize by Count > Breakout by Category  ([Image](https://github.com/user-attachments/assets/ab21839f-4c00-49e6-959b-fc816a0a70f4))
3. Save & add to dashboard
4. Add text/category dashboard parameter and connect it to ""Category"" column from last stage (`Summaries (2)`)
5. Save dashboard
6. Notice that you can choose from 4 filter values in the filter ([image](https://github.com/user-attachments/assets/77591d20-6ded-47d6-b5fb-9996b4b51fe0))
7. Create a public link for the dashboard and open it

❌ Notice that you can't choose from filter values in the filter ([image](https://github.com/user-attachments/assets/c36fcb9e-ab40-4b89-9628-e6ee2534ad0a))

~GET `/api/public/dashboard/:id` returns `param_values: null`~
",kamilmielnik,2024-10-29 12:56:40+00:00,['kamilmielnik'],2024-11-12 11:47:09+00:00,2024-11-12 11:47:08+00:00,https://github.com/metabase/metabase/issues/49282,[],"[{'comment_id': 2466770870, 'issue_id': 2621168484, 'author': 'metamben', 'body': 'In this setup, `/api/dashboard/:id` also returns `param_values: null`. Why is that not a problem?', 'created_at': datetime.datetime(2024, 11, 10, 15, 8, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470321847, 'issue_id': 2621168484, 'author': 'kamilmielnik', 'body': '> In this setup, `/api/dashboard/:id` also returns `param_values: null`. Why is that not a problem?\n\nTrue, that wasn\'t source of the issue.\n\nI debugged it further and the reason is that in public dashboards `dashboard.dashcards[].card.dataset_query` is just `{ type: ""query"" }` ([image](https://github.com/user-attachments/assets/a3290cef-69f6-402c-990a-5a5650d38694)). So FE does not have [information needed to compute MLv2 columns](https://github.com/metabase/metabase/blob/fad0ab680ce37fbd589f0fd7955469970390f3c1/frontend/src/metabase-lib/v1/parameters/utils/targets.ts#L180-L188). It is my understanding that this is actually expected behavior in public dashboards as query should not be exposed.\n\nClosing as working as expected.\n\nI updated comments in `dashboard-filters-query-stages.cy.spec.ts` as well (97b903a98cb967fb3fa52594ca0b91b326c0a11d).', 'created_at': datetime.datetime(2024, 11, 12, 11, 47, 8, tzinfo=datetime.timezone.utc)}]","metamben on (2024-11-10 15:08:24 UTC): In this setup, `/api/dashboard/:id` also returns `param_values: null`. Why is that not a problem?

kamilmielnik (Issue Creator) on (2024-11-12 11:47:08 UTC): True, that wasn't source of the issue.

I debugged it further and the reason is that in public dashboards `dashboard.dashcards[].card.dataset_query` is just `{ type: ""query"" }` ([image](https://github.com/user-attachments/assets/a3290cef-69f6-402c-990a-5a5650d38694)). So FE does not have [information needed to compute MLv2 columns](https://github.com/metabase/metabase/blob/fad0ab680ce37fbd589f0fd7955469970390f3c1/frontend/src/metabase-lib/v1/parameters/utils/targets.ts#L180-L188). It is my understanding that this is actually expected behavior in public dashboards as query should not be exposed.

Closing as working as expected.

I updated comments in `dashboard-filters-query-stages.cy.spec.ts` as well (97b903a98cb967fb3fa52594ca0b91b326c0a11d).

"
2620989828,issue,closed,completed,Search Filters are buggy and annoying to work with in 51,"### Describe the bug

The usability of a Text Filter set to a search box is very annoying and also buggy when setup to pick a single value:

![Image](https://github.com/user-attachments/assets/8f1acc36-a022-4771-9512-fe5bae3b1665)


### To Reproduce

1. Go to Admin -> Table Metadata -> Products -> Find the Title column and set it as a search box:

![Image](https://github.com/user-attachments/assets/a019d971-0853-4c0a-9397-4fa9b6fd08f2)

2. Create a question based on products and then link a test filter to it making sure the Filter is set to a search box and a single Value

3. Notice how it allows the addition of multiple values but then removes them. Also the list hides the Add Filter button from being selected and you have to click between the border to be able to go back to the Add Filter button. Check the video here:

https://github.com/user-attachments/assets/1907e139-577c-4b42-be2a-1ae59506006f

This is how it used to be on 50

https://github.com/user-attachments/assets/dc3d1d82-399a-4805-b1ca-952b899d1413



### Expected behavior

I want to be able to use the filter properly and not having to click between borders and also that if i set the filter to select single values then only 1 value is selected.

So there are currently 2 issues with this filter both around usability. 

### Logs

None that are relevant since it's a UI flow (flaw)

### Information about your Metabase installation

version 51.1

### Severity

Makes usability of Search Filters very annoying

### Additional context

_No response_",Tony-metabase,2024-10-29 11:42:25+00:00,['romeovs'],2024-11-01 22:33:52+00:00,2024-11-01 22:33:52+00:00,https://github.com/metabase/metabase/issues/49279,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2620728412,issue,closed,not_planned,Filtering of BigQuery tables in a dataset,"**Is your feature request related to a problem? Please describe.**
The way we integrate BigQuery datasets with Metabase is through service accounts. Where those service accounts frequently only have access to some of the tables in the dataset. As a result, the logs are frequently being spammed with warnings about not having access, approximately 50% of all invocations from Metabase to BigQuery fail on this scenario.

We do not think it is realistic to ask our users to tailor all tables in a dataset for use with Metabase, e.g., they should all be accessible; they might want to use those tables in different contexts.  Furthermore, when we started building our solution we did not recommend that our users make all tables in a dataset accessible for the service account. So, if we were to move to this pattern now, where all tables in a dataset should be open, we would need to ask our users to rebuild all their questions and dashboards, since there is no easy way to change the data source.

**Describe the solution you'd like**
We would like to be able to provide a filter or list of which tables in a BigQuery dataset Metabase tries to search and index

**Describe alternatives you've considered**
Just continue as is, with a lot of warnings or errors in the logs that are expected, and that might impact performance. As noted in the previous description, we have also considered asking our users to make all tables in a dataset accessible, but do not really think this is a good recommendation. 

**How important is this feature to you?**
Hard to set a level of importance on this, as it might only have a small performance impact, and the logs can always be filtered. However, in the latter case of filtering, we might be concealing real errors. Overall, it seems reasonable that the BigQuery driver should support this type of filtering of tables, and that it is more correct behavior.
",paulbes,2024-10-29 09:52:32+00:00,[],2024-10-29 12:58:18+00:00,2024-10-29 12:58:16+00:00,https://github.com/metabase/metabase/issues/49277,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2444145547, 'issue_id': 2620728412, 'author': 'paoliniluis', 'body': 'I believe this is a duplicate of https://github.com/metabase/metabase/issues/5500', 'created_at': datetime.datetime(2024, 10, 29, 12, 58, 16, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-29 12:58:16 UTC): I believe this is a duplicate of https://github.com/metabase/metabase/issues/5500

"
2620677182,issue,open,,"Allow for overriding of BigQuery API endpoint, and disabling of authentication","**Is your feature request related to a problem? Please describe.**
We build a service that allows our users to create data products based on BigQuery datasets and tables, where one part of the functionality is to integrate the data product with Metabase. In some cases, these data products, and thereby the underlying dataset, should not be accessible to all. To test these integrations locally we make use of various emulators, including: https://github.com/goccy/bigquery-emulator. To be able to use this emulator we have had to patch the BigQuery driver, to allow us to override the endpoint and disable authentication. This behavior is supported by the underlying Google SDK, see provided patch for example.

**Describe the solution you'd like**
I would like for it to be possible to override the api endpoint and disable authentication, as demonstrated in the supplied patch. Please ignore the poor quality of the code 🙈 

**Describe alternatives you've considered**
- We are currently patching the Metabase BigQuery driver, for our integration tests only, but this is not sustainable as patch or minor releases frequently break the patch.
- We are considering forking the bigquery driver and adding this custom logic, which is likely more correct, but also very heavy handed.

**How important is this feature to you?**
We consider it very important, as it means we can iterate very quickly with all components running locally.

**Additional context**
```diff
From d7d1dada261df3bb4cb88821043ded665f4e2adc Mon Sep 17 00:00:00 2001
From: ""Paul B. Beskow"" <paul@beskow.no>
Date: Wed, 31 Jul 2024 10:12:15 +0200
Subject: [PATCH] chore(bq): modify driver to allow for local bq

---
 .../resources/metabase-plugin.yaml            | 11 ++++++
 .../metabase/driver/bigquery_cloud_sdk.clj    | 36 ++++++++++++++-----
 .../driver/bigquery_cloud_sdk/common.clj      | 11 ++++--
 package.json                                  |  4 ---
 4 files changed, 48 insertions(+), 14 deletions(-)

diff --git a/modules/drivers/bigquery-cloud-sdk/resources/metabase-plugin.yaml b/modules/drivers/bigquery-cloud-sdk/resources/metabase-plugin.yaml
index bc5be48d86..56e101980a 100644
--- a/modules/drivers/bigquery-cloud-sdk/resources/metabase-plugin.yaml
+++ b/modules/drivers/bigquery-cloud-sdk/resources/metabase-plugin.yaml
@@ -14,6 +14,17 @@ driver:
       helper-text: Project ID to be used for authentication. You can omit this field if you are only querying datasets owned by your organization.
       required: false
       placeholder: 1w08oDRKPrOqBt06yxY8uiCz2sSvOp3u
+    - name: endpoint
+      display-name: Endpoint (override)
+      helper-text: The endpoint to use for the BigQuery API. You can omit this field if you are using the default endpoint. (Ref. https://cloud.google.com/bigquery/docs/reference/rest#service-endpoint)
+      required: false
+      type: text
+      default: https://bigquery.googleapis.com
+    - name: enable-auth
+      display-name: Whether to enable authentication with Google Cloud SDK.
+      required: false
+      type: boolean
+      default: true
     - name: service-account-json
       display-name: Service account JSON file
       helper-text: This JSON file contains the credentials Metabase needs to read and query your dataset.
diff --git a/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk.clj b/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk.clj
index 9480fcda54..46d77fff47 100644
--- a/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk.clj
+++ b/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk.clj
@@ -54,11 +54,22 @@
 
 (mu/defn ^:private database-details->client
   ^BigQuery [details :- :map]
-  (let [creds   (bigquery.common/database-details->service-account-credential details)
-        bq-bldr (doto (BigQueryOptions/newBuilder)
-                  (.setCredentials (.createScoped creds bigquery-scopes)))]
-    (.. bq-bldr build getService)))
-
+  (let [enable-auth (get details :enable-auth true)  ;; Default to true if not specified
+        endpoint (get details :endpoint ""https://bigquery.googleapis.com"")
+        project-id (get details :project-id)
+        bq-bldr (BigQueryOptions/newBuilder)]
+    (log/info ""(client) Enable Auth:"" enable-auth)
+    (log/info ""(client) Endpoint:"" endpoint)
+    (log/info ""(client) Project ID:"" project-id)
+    (-> bq-bldr
+      (cond->
+        (true? enable-auth) (.setCredentials (.createScoped (bigquery.common/database-details->service-account-credential details) bigquery-scopes))
+        (false? enable-auth) (.setCredentials (bigquery.common/get-no-credentials))
+      )
+      (.setHost endpoint)
+      (.setProjectId project-id)
+      (.build)
+      (.getService))))
 ;;; +----------------------------------------------------------------------------------------------------------------+
 ;;; |                                         Transducing Query Results                                              |
 ;;; +----------------------------------------------------------------------------------------------------------------+
@@ -122,9 +133,11 @@
 
 (defn- list-datasets
   ""Fetch all datasets given database `details`, applying dataset filters if specified.""
-  [{:keys [project-id dataset-filters-type dataset-filters-patterns] :as details}]
+  [details]
   (let [client (database-details->client details)
-        project-id (or project-id (bigquery.common/database-details->credential-project-id details))
+        project-id (or (get details :project-id) (bigquery.common/database-details->credential-project-id details))
+        dataset-filters-type (get details :dataset-filters-type)
+        dataset-filters-patterns (get details :dataset-filters-patterns)
         datasets (.listDatasets client project-id (u/varargs BigQuery$DatasetListOption))
         inclusion-patterns (when (= ""inclusion"" dataset-filters-type) dataset-filters-patterns)
         exclusion-patterns (when (= ""exclusion"" dataset-filters-type) dataset-filters-patterns)]
@@ -148,6 +161,13 @@
 
 (defmethod driver/can-connect? :bigquery-cloud-sdk
   [_ details]
+  ;; Debug output for endpoint and enable-auth
+  (let [endpoint (get details :endpoint ""https://bigquery.googleapis.com"")
+        enable-auth (get details :enable-auth true)
+        project-id (get details :project-id ""n/a"")]
+    (log/info ""(can-connect) Endpoint:"" endpoint)
+    (log/info ""(can-connect) Enable Auth:"" enable-auth)
+    (log/info ""(can-connect) Project ID: "" project-id))
   ;; check whether we can connect by seeing whether listing datasets succeeds
   (let [[success? datasets] (try [true (list-datasets details)]
                                  (catch Exception e
@@ -168,7 +188,7 @@
   (u/varargs BigQuery$TableOption))
 
 (mu/defn ^:private get-table :- (lib.schema.common/instance-of-class Table)
-  (^Table [{{:keys [project-id]} :details, :as database} dataset-id table-id]
+  (^Table [{{:keys [project-id endpoint enable-auth]} :details, :as database} dataset-id table-id]
    (get-table (database-details->client (:details database)) project-id dataset-id table-id))
 
   (^Table [^BigQuery client :- (lib.schema.common/instance-of-class BigQuery)
diff --git a/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk/common.clj b/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk/common.clj
index e1b8b311d4..7fc5c88e90 100644
--- a/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk/common.clj
+++ b/modules/drivers/bigquery-cloud-sdk/src/metabase/driver/bigquery_cloud_sdk/common.clj
@@ -7,8 +7,9 @@
    ^{:clj-kondo/ignore [:discouraged-namespace]}
    [toucan2.core :as t2])
   (:import
-   (com.google.auth.oauth2 ServiceAccountCredentials)
-   (java.io ByteArrayInputStream)))
+    (com.google.auth.oauth2 ServiceAccountCredentials)
+    (com.google.cloud NoCredentials)
+    (java.io ByteArrayInputStream)))
 
 (set! *warn-on-reflection* true)
 
@@ -20,6 +21,12 @@
   this dynamic var to the JVM TZ rather than UTC""
   ""UTC"")
 
+(mu/defn get-no-credentials
+  ""Returns a `NoCredentials` instance.""
+  {:added ""0.50.0""}
+  ^NoCredentials []
+  (NoCredentials/getInstance))
+
 (mu/defn service-account-json->service-account-credential
   ""Returns a `ServiceAccountCredentials` (not scoped) for the given `service-account-json` (String).""
   {:added ""0.42.0""}
diff --git a/package.json b/package.json
index a5589cd0f3..bd82b9bf47 100644
--- a/package.json
+++ b/package.json
@@ -419,10 +419,6 @@
     ],
     ""e2e/test/scenarios/*/{*.(js|ts),!(helpers|shared)/*.(js|ts)}"": [
       ""node e2e/validate-e2e-test-files.js""
-    ],
-    ""**/*.{clj,cljc,cljs,bb}"": [
-      ""clj-kondo --config ./.clj-kondo/config.edn --config-dir ./.clj-kondo --parallel --lint"",
-      ""./bin/whitespace_lint_staged.sh""
     ]
   },
   ""browserslist"": [
-- 
2.47.0
```",paulbes,2024-10-29 09:34:49+00:00,[],2025-02-04 20:30:51+00:00,,https://github.com/metabase/metabase/issues/49274,"[('Type:New Feature', ''), ('Database/BigQuery', '')]","[{'comment_id': 2445528612, 'issue_id': 2620677182, 'author': 'paoliniluis', 'body': ""@paulbes I'm not fully understanding the issue here: I would guess that this is just a need specifically for your use case, is this correct? I haven't seen any bigquery connection without authentication ever. Please correct me if I'm wrong"", 'created_at': datetime.datetime(2024, 10, 29, 23, 51, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446011284, 'issue_id': 2620677182, 'author': 'paulbes', 'body': 'The use case is for anyone that wants to be able to run Metabase with a BigQuery emulator on their local machine without any internet connection required. I would imagine most use-cases are for integration testing, or similar.', 'created_at': datetime.datetime(2024, 10, 30, 6, 57, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459653755, 'issue_id': 2620677182, 'author': 'paulbes', 'body': 'An update on this issue, with v1.51 Metabase fetch from the BigQuery INFORMATION_SCHEMA table, which is not supported currently by the bigquery-emulator; https://github.com/goccy/bigquery-emulator/issues/48.', 'created_at': datetime.datetime(2024, 11, 6, 12, 41, 52, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-29 23:51:19 UTC): @paulbes I'm not fully understanding the issue here: I would guess that this is just a need specifically for your use case, is this correct? I haven't seen any bigquery connection without authentication ever. Please correct me if I'm wrong

paulbes (Issue Creator) on (2024-10-30 06:57:55 UTC): The use case is for anyone that wants to be able to run Metabase with a BigQuery emulator on their local machine without any internet connection required. I would imagine most use-cases are for integration testing, or similar.

paulbes (Issue Creator) on (2024-11-06 12:41:52 UTC): An update on this issue, with v1.51 Metabase fetch from the BigQuery INFORMATION_SCHEMA table, which is not supported currently by the bigquery-emulator; https://github.com/goccy/bigquery-emulator/issues/48.

"
2620615295,issue,closed,completed,Incorrect document title when query fails,"### Describe the bug

![Image](https://github.com/user-attachments/assets/eb336f46-ab83-4a99-a54e-6f55a891d953)


### To Reproduce

1. Open orders table
2. Disable network
3. Summarize → Done
4. Error is shown

❌ Page title is ""Doing science..."" ([image](https://github.com/user-attachments/assets/41cf7994-60bf-453c-8073-54f77ba5699c))

5. Wait a bit (15 seconds?)

❌ Page title is ""Still Here..."" ([image](https://github.com/user-attachments/assets/48ce5bb9-a8ce-4ddd-85ef-59ad7549ea6e))


### Expected behavior

Page title does not indicate that something is happening

### Information about your Metabase installation

master, 9b4d3d2b2ebb24975ed8a673f86e15d9417d1215

### Severity

P3
",kamilmielnik,2024-10-29 09:14:55+00:00,['kamilmielnik'],2025-01-31 08:37:15+00:00,2025-01-31 07:18:35+00:00,https://github.com/metabase/metabase/issues/49270,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/', ''), ('.Team/Querying', '')]",[],
2620362724,issue,open,,Disable Crufty Tables or bypass specific ones,"Hello, I have a table ""sessions"" in my BigQuery, I found that it is a part of what so called ""crufty tables"" which Metabase automatically hides them upon sync.
I would like to disable this behaviour for my ""sessions"" table, as I need to use it.
is there a way to do it?",timorkal,2024-10-29 07:16:07+00:00,[],2024-10-30 13:23:24+00:00,,https://github.com/metabase/metabase/issues/49266,[],"[{'comment_id': 2444429474, 'issue_id': 2620362724, 'author': 'paoliniluis', 'body': 'you should be able to unhide those https://github.com/metabase/metabase/blob/a223f819c72efd718e86e1267c3bed8ead447105/src/metabase/sync/sync_metadata/tables.clj#L28C55-L28C93', 'created_at': datetime.datetime(2024, 10, 29, 14, 26, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444512413, 'issue_id': 2620362724, 'author': 'timorkal', 'body': 'so I need to overwrite this file before starting the metabase app?\n\n> you should be able to unhide those https://github.com/metabase/metabase/blob/a223f819c72efd718e86e1267c3bed8ead447105/src/metabase/sync/sync_metadata/tables.clj#L28C55-L28C93', 'created_at': datetime.datetime(2024, 10, 29, 14, 57, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444528281, 'issue_id': 2620362724, 'author': 'paoliniluis', 'body': 'No, you should just go to settings->admin->table metadata and unhide the tables that were marked as cruft', 'created_at': datetime.datetime(2024, 10, 29, 15, 2, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444535028, 'issue_id': 2620362724, 'author': 'timorkal', 'body': '> No, you should just go to settings->admin->table metadata and unhide the tables that were marked as cruft\n\nright, but I find myself doing it each time the schema is changing in the ""sessions"" table in the source database', 'created_at': datetime.datetime(2024, 10, 29, 15, 5, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445509914, 'issue_id': 2620362724, 'author': 'paoliniluis', 'body': ""I'm running v51 right now and I added\n```\n-- Create the sessions table\nCREATE TABLE sessions (\n    session_id SERIAL PRIMARY KEY,\n    user_id INTEGER NOT NULL,\n    start_time TIMESTAMP NOT NULL,\n    end_time TIMESTAMP,\n    status VARCHAR(20) CHECK (status IN ('active', 'completed', 'failed'))\n);\n\n-- Insert sample data into the sessions table\nINSERT INTO sessions (user_id, start_time, end_time, status) VALUES\n(1, '2024-10-01 08:00:00', '2024-10-01 09:00:00', 'completed'),\n(2, '2024-10-01 10:00:00', '2024-10-01 10:45:00', 'completed'),\n(3, '2024-10-02 12:00:00', '2024-10-02 13:30:00', 'completed'),\n(1, '2024-10-02 14:00:00', NULL, 'active'),\n(4, '2024-10-03 09:15:00', '2024-10-03 10:00:00', 'failed'),\n(5, '2024-10-04 11:00:00', '2024-10-04 12:00:00', 'completed'),\n(3, '2024-10-05 08:30:00', '2024-10-05 10:00:00', 'completed'),\n(2, '2024-10-05 14:00:00', NULL, 'active'),\n(1, '2024-10-06 15:00:00', '2024-10-06 15:45:00', 'completed'),\n(5, '2024-10-07 16:00:00', NULL, 'active');\n```\n\nsynced the db and sessions was hidden. So I just click the eye to unhide it\n\nAfter that I synced again and the table kept being unhidden\n\nThen I did\n```\nALTER TABLE sessions\nADD COLUMN session_type VARCHAR(20);\n\nUPDATE sessions\nSET session_type = CASE\n    WHEN session_id % 3 = 0 THEN 'training'\n    WHEN session_id % 3 = 1 THEN 'meeting'\n    ELSE 'support'\nEND;\n```\n\nsynced the table again and it kept being unhidden\n\nAm I doing something wrong?"", 'created_at': datetime.datetime(2024, 10, 29, 23, 30, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446606706, 'issue_id': 2620362724, 'author': 'timorkal', 'body': 'Maybe it\'s because my scenario is little different. I will try to explain more.\nI have PG database but I am using Airbyte to sync the tables to BigQuery, now from there I am connecting with Metabase.\nMaybe because of how the ""session"" table is being synced (maybe recreated or performing other schema changes over time), this effects how the Metabase is handling the syncing.', 'created_at': datetime.datetime(2024, 10, 30, 11, 2, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447134599, 'issue_id': 2620362724, 'author': 'paoliniluis', 'body': 'so just to confirm @timorkal, the table gets hidden is that correct?', 'created_at': datetime.datetime(2024, 10, 30, 13, 21, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447140769, 'issue_id': 2620362724, 'author': 'timorkal', 'body': '> so just to confirm [@timorkal](https://github.com/timorkal), the table gets hidden is that correct?\n\nyes', 'created_at': datetime.datetime(2024, 10, 30, 13, 23, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-29 14:26:53 UTC): you should be able to unhide those https://github.com/metabase/metabase/blob/a223f819c72efd718e86e1267c3bed8ead447105/src/metabase/sync/sync_metadata/tables.clj#L28C55-L28C93

timorkal (Issue Creator) on (2024-10-29 14:57:08 UTC): so I need to overwrite this file before starting the metabase app?

paoliniluis on (2024-10-29 15:02:59 UTC): No, you should just go to settings->admin->table metadata and unhide the tables that were marked as cruft

timorkal (Issue Creator) on (2024-10-29 15:05:07 UTC): right, but I find myself doing it each time the schema is changing in the ""sessions"" table in the source database

paoliniluis on (2024-10-29 23:30:32 UTC): I'm running v51 right now and I added
```
-- Create the sessions table
CREATE TABLE sessions (
    session_id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL,
    start_time TIMESTAMP NOT NULL,
    end_time TIMESTAMP,
    status VARCHAR(20) CHECK (status IN ('active', 'completed', 'failed'))
);

-- Insert sample data into the sessions table
INSERT INTO sessions (user_id, start_time, end_time, status) VALUES
(1, '2024-10-01 08:00:00', '2024-10-01 09:00:00', 'completed'),
(2, '2024-10-01 10:00:00', '2024-10-01 10:45:00', 'completed'),
(3, '2024-10-02 12:00:00', '2024-10-02 13:30:00', 'completed'),
(1, '2024-10-02 14:00:00', NULL, 'active'),
(4, '2024-10-03 09:15:00', '2024-10-03 10:00:00', 'failed'),
(5, '2024-10-04 11:00:00', '2024-10-04 12:00:00', 'completed'),
(3, '2024-10-05 08:30:00', '2024-10-05 10:00:00', 'completed'),
(2, '2024-10-05 14:00:00', NULL, 'active'),
(1, '2024-10-06 15:00:00', '2024-10-06 15:45:00', 'completed'),
(5, '2024-10-07 16:00:00', NULL, 'active');
```

synced the db and sessions was hidden. So I just click the eye to unhide it

After that I synced again and the table kept being unhidden

Then I did
```
ALTER TABLE sessions
ADD COLUMN session_type VARCHAR(20);

UPDATE sessions
SET session_type = CASE
    WHEN session_id % 3 = 0 THEN 'training'
    WHEN session_id % 3 = 1 THEN 'meeting'
    ELSE 'support'
END;
```

synced the table again and it kept being unhidden

Am I doing something wrong?

timorkal (Issue Creator) on (2024-10-30 11:02:08 UTC): Maybe it's because my scenario is little different. I will try to explain more.
I have PG database but I am using Airbyte to sync the tables to BigQuery, now from there I am connecting with Metabase.
Maybe because of how the ""session"" table is being synced (maybe recreated or performing other schema changes over time), this effects how the Metabase is handling the syncing.

paoliniluis on (2024-10-30 13:21:50 UTC): so just to confirm @timorkal, the table gets hidden is that correct?

timorkal (Issue Creator) on (2024-10-30 13:23:23 UTC): yes

"
2619863595,issue,open,,Can't save Athena queries in the cache (Unfreezable type: class com.simba.athena.jdbc.jdbc42.S42Array),"### Describe the bug

Don't know how to repro but I saw this on the logs of a cloud customer

```
{""lvl"":""ERROR"",""lgr"":""metabase.query-processor.middleware.cache"",""m"":""Error saving query results to cache: Unfreezable type: class com.simba.athena.jdbc.jdbc42.S42Array"",""exception"":{""exception_class"":""clojure.lang.ExceptionInfo"",""exception_message"":""Unfreezable type: class com.simba.athena.jdbc.jdbc42.S42Array"",""stacktrace"":""clojure.lang.ExceptionInfo: Unfreezable type: class com.simba.athena.jdbc.jdbc42.S42Array {:type com.simba.athena.jdbc.jdbc42.S42Array, :as-str \""#object[com.simba.athena.jdbc.jdbc42.S42Array 0x5f4a8c09 \\\""Inglês\\\""]\""}\n\tat taoensso.nippy$throw_unfreezable.invokeStatic(nippy.clj:953)\n\tat taoensso.nippy$throw_unfreezable.invoke(nippy.clj:950)\n\tat taoensso.nippy$fn__38872.invokeStatic(nippy.clj:1188)\n\tat taoensso.nippy$fn__38872.invoke(nippy.clj:1170)\n\tat taoensso.nippy$fn__38536$G__38520__38543.invoke(nippy.clj:580)\n\tat taoensso.nippy$fn__38573.invokeStatic(nippy.clj:605)\n\tat taoensso.nippy$fn__38573.invoke(nippy.clj:596)\n\tat taoensso.nippy$fn__38554$G__38549__38561.invoke(nippy.clj:587)\n\tat taoensso.nippy$write_vec$fn__38618$fn__38619.invoke(nippy.clj:746)\n\tat taoensso.nippy$write_vec$fn__38618.invoke(nippy.clj:746)\n\tat clojure.lang.PersistentVector.reduce(PersistentVector.java:343)\n\tat clojure.core$reduce.invokeStatic(core.clj:6886)\n\tat clojure.core$reduce.invoke(core.clj:6869)\n\tat taoensso.nippy$write_vec.invokeStatic(nippy.clj:746)\n\tat taoensso.nippy$write_vec.invoke(nippy.clj:735)\n\tat taoensso.nippy$fn__38817.invokeStatic(nippy.clj:1113)\n\tat taoensso.nippy$fn__38817.invoke(nippy.clj:1113)\n\tat taoensso.nippy$fn__38536$G__38520__38543.invoke(nippy.clj:580)\n\tat taoensso.nippy$fn__38568.invokeStatic(nippy.clj:602)\n\tat taoensso.nippy$fn__38568.invoke(nippy.clj:596)\n\tat taoensso.nippy$fn__38554$G__38549__38561.invoke(nippy.clj:587)\n\tat taoensso.nippy$freeze_to_out_BANG_.invokeStatic(nippy.clj:961)\n\tat taoensso.nippy$freeze_to_out_BANG_.invoke(nippy.clj:958)\n\tat metabase.query_processor.middleware.cache.impl$freeze_BANG_.invokeStatic(impl.clj:51)\n\tat metabase.query_processor.middleware.cache.impl$freeze_BANG_.invoke(impl.clj:48)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization$in_STAR___71927$fn__71928.invoke(impl.clj:86)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization$in_STAR___71927.invoke(impl.clj:85)\n\tat metabase.query_processor.middleware.cache$add_object_to_cache_BANG_.invokeStatic(cache.clj:60)\n\tat metabase.query_processor.middleware.cache$add_object_to_cache_BANG_.invoke(cache.clj:56)\n\tat metabase.query_processor.middleware.cache$save_results_xform$fn__72025.invoke(cache.clj:117)\n\tat metabase.query_processor.pipeline$_STAR_reduce_STAR_$fn__57461$fn__57462$wrapper__57463.invoke(pipeline.clj:70)\n\tat metabase.query_processor.reducible$reducible_rows$reify__57585.reduce(reducible.clj:57)\n\tat clojure.core$transduce.invokeStatic(core.clj:6947)\n\tat clojure.core$transduce.invokeStatic(core.clj:6943)\n\tat clojure.core$transduce.invoke(core.clj:6934)\n\tat metabase.query_processor.pipeline$_STAR_reduce_STAR_$fn__57461.invoke(pipeline.clj:63)\n\tat metabase.query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:62)\n\tat metabase.query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49)\n\tat metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___72072$fn__72073.invoke(cache.clj:211)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)\n\tat metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)\n\tat metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___72072.invoke(cache.clj:207)\n\tat metabase.query_processor.pipeline$_STAR_run_STAR_$respond__57473.invoke(pipeline.clj:95)\n\tat metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__83155.invoke(execute.clj:725)\n\tat metabase.driver.sql_jdbc.execute$fn__82959$fn__82960.invoke(execute.clj:398)\n\tat metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)\n\tat metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)\n\tat metabase.driver.sql_jdbc.execute$fn__82959.invokeStatic(execute.clj:392)\n\tat metabase.driver.sql_jdbc.execute$fn__82959.invoke(execute.clj:390)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:244)\n\tat metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)\n\tat metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)\n\tat metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)\n\tat metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)\n\tat metabase.driver.sql_jdbc$fn__114785.invokeStatic(sql_jdbc.clj:78)\n\tat metabase.driver.sql_jdbc$fn__114785.invoke(sql_jdbc.clj:76)\n\tat metabase.driver.athena$fn__118838.invokeStatic(athena.clj:466)\n\tat metabase.driver.athena$fn__118838.invoke(athena.clj:464)\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:244)\n\tat metabase.query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)\n\tat metabase.query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)\n\tat metabase.query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)\n\tat metabase.query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)\n\tat metabase.query_processor.execute$run.invokeStatic(execute.clj:60)\n\tat metabase.query_processor.execute$run.invoke(execute.clj:54)\n\tat metabase.query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__72113.invoke(update_used_cards.clj:60)\n\tat metabase.query_processor.execute$add_native_form_to_result_metadata$fn__72128.invoke(execute.clj:23)\n\tat metabase.query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__72133.invoke(execute.clj:34)\n\tat metabase.query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)\n\tat metabase.query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)\n\tat metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72086.invoke(cache.clj:238)\n\tat metabase.query_processor.middleware.permissions$check_query_permissions$fn__66715.invoke(permissions.clj:147)\n\tat metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__67327.invoke(enterprise.clj:51)\n\tat metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__67337.invoke(enterprise.clj:64)\n\tat metabase.query_processor.execute$execute$fn__72160.invoke(execute.clj:92)\n\tat metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)\n\tat metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)\n\tat metabase.query_processor.execute$execute.invokeStatic(execute.clj:91)\n\tat metabase.query_processor.execute$execute.invoke(execute.clj:87)\n\tat metabase.query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)\n\tat metabase.query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)\n\tat metabase.query_processor.middleware.enterprise$fn__67354$handle_audit_app_internal_queries__67355$fn__67357.invoke(enterprise.clj:96)\n\tat metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__67365.invoke(enterprise.clj:103)\n\tat metabase.query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__77360.invoke(process_userland_query.clj:198)\n\tat metabase.query_processor.middleware.catch_exceptions$catch_exceptions$fn__77429.invoke(catch_exceptions.clj:128)\n\tat metabase.query_processor$process_query$fn__77466.invoke(query_processor.clj:78)\n\tat metabase.query_processor.setup$do_with_canceled_chan$fn__67769.invoke(setup.clj:187)\n\tat metabase.query_processor.setup$do_with_database_local_settings$fn__67764.invoke(setup.clj:181)\n\tat metabase.query_processor.setup$do_with_driver$fn__67759$fn__67760.invoke(setup.clj:166)\n\tat metabase.driver$do_with_driver.invokeStatic(driver.clj:105)\n\tat metabase.driver$do_with_driver.invoke(driver.clj:100)\n\tat metabase.query_processor.setup$do_with_driver$fn__67759.invoke(setup.clj:165)\n\tat metabase.query_processor.setup$do_with_metadata_provider$fn__67752$fn__67755.invoke(setup.clj:151)\n\tat metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)\n\tat metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)\n\tat metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)\n\tat metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)\n\tat metabase.query_processor.setup$do_with_metadata_provider$fn__67752.invoke(setup.clj:150)\n\tat metabase.query_processor.setup$do_with_resolved_database$fn__67746.invoke(setup.clj:128)\n\tat metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)\n\tat metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)\n\tat metabase.query_processor$process_query.invokeStatic(query_processor.clj:76)\n\tat metabase.query_processor$process_query.invoke(query_processor.clj:69)\n\tat metabase.query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)\n\tat metabase.query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)\n\tat metabase.query_processor.card$process_query_for_card_default_run_fn$fn__85251$fn__85252.invoke(card.clj:177)\n\tat metabase.query_processor.streaming$_streaming_response$fn__70669$fn__70670$fn__70671.invoke(streaming.clj:176)\n\tat metabase.query_processor.streaming$_streaming_response$fn__70669$fn__70670.invoke(streaming.clj:174)\n\tat metabase.query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)\n\tat metabase.query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)\n\tat metabase.query_processor.streaming$_streaming_response$fn__70669.invoke(streaming.clj:171)\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\n\tat clojure.core$apply.invokeStatic(core.clj:667)\n\tat clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990)\n\tat clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990)\n\tat clojure.lang.RestFn.applyTo(RestFn.java:142)\n\tat clojure.core$apply.invokeStatic(core.clj:671)\n\tat clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020)\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\n\tat metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)\n\tat metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)\n\tat metabase.async.streaming_response$do_f_async$task__52053.invoke(streaming_response.clj:97)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\n\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat java.base/java.lang.Thread.run(Unknown Source)\n""}}
```

### To Reproduce

Don't know how to repro this

### Expected behavior

Athena should be able to save to cache

### Logs

Above

### Information about your Metabase installation

50.31

### Severity

P1

### Additional context

_No response_",paoliniluis,2024-10-29 00:51:48+00:00,[],2025-02-04 20:27:52+00:00,,https://github.com/metabase/metabase/issues/49264,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Database/Athena', ''), ('.Team/Querying', '')]","[{'comment_id': 2444834897, 'issue_id': 2619863595, 'author': 'bshepherdson', 'body': 'This might be fixed by #48962 (and its v50 backport #49152). Then again, it might not, since this is about a different unfreezable value that perhaps lives elsewhere in the query.\n\nWe clearly need a driver test that tries to cache both a regular and pivot query, since this regressed for at least two databases.', 'created_at': datetime.datetime(2024, 10, 29, 16, 52, 5, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-10-29 16:52:05 UTC): This might be fixed by #48962 (and its v50 backport #49152). Then again, it might not, since this is about a different unfreezable value that perhaps lives elsewhere in the query.

We clearly need a driver test that tries to cache both a regular and pivot query, since this regressed for at least two databases.

"
2619858026,issue,closed,completed,Explicitly sorting by a temporal column will break the time granularity parameter on a dashboard,"### Describe the bug

If you sort by a time field, it will end up breaking the time granularity filter due to a QP error

### To Reproduce

1) create a question as simple as 
![Image](https://github.com/user-attachments/assets/1838c05f-2a87-4017-8082-341df65662de)

see the temporal field being added to the sort stage

2) add the card to a dashboard and add a time granularity parameter
3) change the time granularity and see the BE breaking

### Expected behavior

should work

### Logs

```
2024-10-29 00:44:54,010 ERROR middleware.catch-exceptions :: Error processing query: ERROR: column ""orders.created_at"" must appear in the GROUP BY clause or be used in an aggregate function
  Position: 332
{:database_id 2,
 :started_at #t ""2024-10-29T00:44:53.982942Z[Etc/UTC]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: ERROR: column \""orders.created_at\"" must appear in the GROUP BY clause or be used in an aggregate function\n  Position: 332"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__86031$fn__86032.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__85835$fn__85836.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__85835.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__85835.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__119504.invokeStatic(sql_jdbc.clj:79)""
    ""driver.sql_jdbc$fn__119504.invoke(sql_jdbc.clj:77)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:62)""
    ""query_processor.execute$run.invoke(execute.clj:56)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_76882__76883$fn__76884.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__76899.invoke(execute.clj:25)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__76905.invoke(execute.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___76855.invoke(cache.clj:241)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__73895.invoke(permissions.clj:147)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__113603$check_download_permissions__113604$fn__113605.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74603.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__115542$maybe_apply_column_level_perms_check__115543$fn__115544.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74613.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute76932__76933$fn__76934.invoke(execute.clj:94)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor.execute$execute76932__76933.invokeStatic(execute.clj:93)""
    ""query_processor.execute$execute76932__76933.invoke(execute.clj:89)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
    ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
    ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:106)""
    ""driver$do_with_driver.invoke(driver.clj:101)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
    ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
    ""query_processor.card$process_query_for_card_default_qp88337__88338.invokeStatic(card.clj:186)""
    ""query_processor.card$process_query_for_card_default_qp88337__88338.invoke(card.clj:182)""
    ""query_processor.card$process_query_for_card_default_run_fn$fn__88340$fn__88341.invoke(card.clj:193)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__53224.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: MBQL queryHash: 0ba59ce7f41a36bd3c549c313b2d43ba4ce8ed6ecf801dc48965a117e214aef9""
     ""SELECT""
     ""  CAST(\""public\"".\""orders\"".\""created_at\"" AS date) AS \""created_at\"",""
     ""  SUM(\""public\"".\""orders\"".\""total\"") AS \""sum\""""
     ""FROM""
     ""  \""public\"".\""orders\""""
     ""GROUP BY""
     ""  CAST(\""public\"".\""orders\"".\""created_at\"" AS date)""
     ""ORDER BY""
     ""  DATE_TRUNC('month', \""public\"".\""orders\"".\""created_at\"") DESC,""
     ""  CAST(\""public\"".\""orders\"".\""created_at\"" AS date) ASC""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :state ""42803"",
 :error_type :invalid-query,
 :json_query
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :cache-strategy nil,
  :viz-settings {:table.cell_column ""sum""},
  :database 2,
  :query
  {:source-table 24,
   :aggregation [[:sum [:field 285 {:base-type :type/Float}]]],
   :breakout [[:field 287 {:base-type :type/DateTime, :temporal-unit :month}]],
   :order-by [[:desc [:field 287 {:base-type :type/DateTime, :temporal-unit :month}]]]},
  :parameters
  [{:type :temporal-unit,
    :value ""day"",
    :id ""3d48aedf"",
    :target [:dimension [:field 287 {:base-type :type/DateTime, :temporal-unit :month}]]}]},
 :native
 {:query
  ""SELECT CAST(\""public\"".\""orders\"".\""created_at\"" AS date) AS \""created_at\"", SUM(\""public\"".\""orders\"".\""total\"") AS \""sum\"" FROM \""public\"".\""orders\"" GROUP BY CAST(\""public\"".\""orders\"".\""created_at\"" AS date) ORDER BY DATE_TRUNC('month', \""public\"".\""orders\"".\""created_at\"") DESC, CAST(\""public\"".\""orders\"".\""created_at\"" AS date) ASC"",
  :params nil},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__85961.invokeStatic(execute.clj:570)""
  ""driver.sql_jdbc.execute$fn__85961.invoke(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:578)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031$fn__86032.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__85835$fn__85836.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__85835.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__85835.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__119504.invokeStatic(sql_jdbc.clj:79)""
  ""driver.sql_jdbc$fn__119504.invoke(sql_jdbc.clj:77)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:62)""
  ""query_processor.execute$run.invoke(execute.clj:56)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_76882__76883$fn__76884.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__76899.invoke(execute.clj:25)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__76905.invoke(execute.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___76855.invoke(cache.clj:241)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__73895.invoke(permissions.clj:147)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__113603$check_download_permissions__113604$fn__113605.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74603.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__115542$maybe_apply_column_level_perms_check__115543$fn__115544.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74613.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute76932__76933$fn__76934.invoke(execute.clj:94)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor.execute$execute76932__76933.invokeStatic(execute.clj:93)""
  ""query_processor.execute$execute76932__76933.invoke(execute.clj:89)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
  ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
  ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:106)""
  ""driver$do_with_driver.invoke(driver.clj:101)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
  ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
  ""query_processor.card$process_query_for_card_default_qp88337__88338.invokeStatic(card.clj:186)""
  ""query_processor.card$process_query_for_card_default_qp88337__88338.invoke(card.clj:182)""
  ""query_processor.card$process_query_for_card_default_run_fn$fn__88340$fn__88341.invoke(card.clj:193)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__53224.invoke(streaming_response.clj:97)""],
 :card_id 113,
 :context :dashboard,
 :error
 ""ERROR: column \""orders.created_at\"" must appear in the GROUP BY clause or be used in an aggregate function\n  Position: 332"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :user-parameters
  [{:value ""day"",
    :type :temporal-unit,
    :id ""3d48aedf"",
    :target [:dimension [:field 287 {:base-type :type/DateTime, :temporal-unit :month}]]}],
  :viz-settings {:table.cell_column ""sum""},
  :info
  {:executed-by 1,
   :context :dashboard,
   :card-id 113,
   :card-name ""orders, Sum of total, Grouped by created_at: Month, Sorted by created_at: Month descending"",
   :dashboard-id 12,
   :visualization-settings {:table.cell_column ""sum""}},
  :database 2,
  :type :query,
  :query
  {:source-table 24,
   :aggregation [[:aggregation-options [:sum [:field 285 {:base-type :type/Float}]] {:name ""sum""}]],
   :breakout [[:field 287 {:base-type :type/DateTime, :temporal-unit :day}]],
   :order-by
   [[:desc [:field 287 {:base-type :type/DateTime, :temporal-unit :month}]]
    [:asc [:field 287 {:base-type :type/DateTime, :temporal-unit :day}]]]}},
 :data {:rows [], :cols []}}

2024-10-29 00:44:54,218 DEBUG middleware.log :: POST /api/dashboard/12/dashcard/97/card/113/query 202 [ASYNC: completed] 251.2 ms (16 DB calls) App DB connections: 0/10 Jetty threads: 3/50 (2 idle, 0 queued) (144 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}
```

### Information about your Metabase installation

v51.1

### Severity

P1

### Additional context

NA",paoliniluis,2024-10-29 00:45:36+00:00,['bshepherdson'],2024-10-31 19:41:02+00:00,2024-10-31 19:41:01+00:00,https://github.com/metabase/metabase/issues/49263,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2444922129, 'issue_id': 2619858026, 'author': 'bshepherdson', 'body': ""Diagnosis: [This logic](https://github.com/metabase/metabase/blob/master/src/metabase/legacy_mbql/util.cljc#L488), called from  [`qp.middle.add-implicit-clauses/add-implicit-breakout-order-by`](https://github.com/metabase/metabase/blob/master/src/metabase/query_processor/middleware/add_implicit_clauses.clj#L180), is using a straight up Clojure set to compare the order-by clauses.\n\nSince the explicitly added sort order and the incoming one from the dashboard parameter have different `:temporal-unit` options, they don't match and both are added, which is a query error. (We generate `ORDER BY` clauses for both of them, but only one is a `:breakout` and therefore listed in the `GROUP BY`.)\n\nI'm preparing a fix - dropping the `:temporal-unit` before the duplicate check."", 'created_at': datetime.datetime(2024, 10, 29, 17, 29, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444928407, 'issue_id': 2619858026, 'author': 'bshepherdson', 'body': 'For posterity, this issue would not occur with parameter mapping, and de-duplicating clauses, based on improved column references. See #49182 .', 'created_at': datetime.datetime(2024, 10, 29, 17, 32, 26, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-10-29 17:29:32 UTC): Diagnosis: [This logic](https://github.com/metabase/metabase/blob/master/src/metabase/legacy_mbql/util.cljc#L488), called from  [`qp.middle.add-implicit-clauses/add-implicit-breakout-order-by`](https://github.com/metabase/metabase/blob/master/src/metabase/query_processor/middleware/add_implicit_clauses.clj#L180), is using a straight up Clojure set to compare the order-by clauses.

Since the explicitly added sort order and the incoming one from the dashboard parameter have different `:temporal-unit` options, they don't match and both are added, which is a query error. (We generate `ORDER BY` clauses for both of them, but only one is a `:breakout` and therefore listed in the `GROUP BY`.)

I'm preparing a fix - dropping the `:temporal-unit` before the duplicate check.

bshepherdson (Assginee) on (2024-10-29 17:32:26 UTC): For posterity, this issue would not occur with parameter mapping, and de-duplicating clauses, based on improved column references. See #49182 .

"
2619784344,issue,open,,Make linked filter cache expiration configurable,"**Is your feature request related to a problem? Please describe.**
We have many use cases where linked filters cache (30 days!) can be problematic: people that change data often might find that the linked filters don't have the latest values (https://github.com/metabase/metabase/issues/49055) and they end up calling support as values are not up to date.

**Describe the solution you'd like**
Make the expiration configurable, up to the level that could be disabled

**Describe alternatives you've considered**
Call the api every certain amount of days/minutes/hours to clean up the filter cache

**How important is this feature to you?**
We've... kind of had tons of tickets around linked filters cache

**Additional context**
NA
",paoliniluis,2024-10-28 23:37:49+00:00,[],2025-02-04 20:30:52+00:00,,https://github.com/metabase/metabase/issues/49261,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 2442880072, 'issue_id': 2619784344, 'author': 'paoliniluis', 'body': 'related to https://github.com/metabase/metabase/issues/668', 'created_at': datetime.datetime(2024, 10, 28, 23, 45, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-10-28 23:45:25 UTC): related to https://github.com/metabase/metabase/issues/668

"
2619714670,issue,closed,completed,Incorrect determination of `:deployment_model` in snowplow stats,"### Describe the bug

We incorrectly report the deployment model in this code:

```clojure
(defn- deployment-model
  []
  (case
   (premium-features/is-hosted?) ""cloud""
   (in-docker?) ""docker""
   :else ""jar""))
```

which is really doing this:

```clojure
(defn- deployment-model
  []
  (case (premium-features/is-hosted?)
    ""cloud"" (in-docker?)
    ""docker"" :else
    ""jar""))
```

This is written as if it is a `cond`, not a case.

```clojure
stats=> (with-redefs [premium-features/is-hosted? (constantly ""cloud"")
                      in-docker? (constantly ""this doesn't do what you think it does"")]
          (case
              (premium-features/is-hosted?) ""cloud""
              (in-docker?) ""docker""
              :else ""jar""))
""this doesn't do what you think it does""
```

### To Reproduce

see desc

### Expected behavior

it should correctly report but it does not:

```clojure
stats=> (with-redefs [premium-features/is-hosted? (constantly true)
                      ]
          (case
              (premium-features/is-hosted?) ""cloud""
              (in-docker?) ""docker""
              :else ""jar""))
""jar""
stats=> (with-redefs [in-docker? (constantly true)]
          (case
              (premium-features/is-hosted?) ""cloud""
              (in-docker?) ""docker""
              :else ""jar""))
""jar""
stats=> (with-redefs [premium-features/is-hosted? (constantly ""docker"")]
          (case
              (premium-features/is-hosted?) ""cloud""
              (in-docker?) ""docker""
              :else ""jar""))
:else
```

### Logs

_No response_

### Information about your Metabase installation

master

### Severity

p2

### Additional context

_No response_",dpsutton,2024-10-28 22:42:40+00:00,['noahmoss'],2024-10-29 15:13:47+00:00,2024-10-29 14:15:28+00:00,https://github.com/metabase/metabase/issues/49258,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Needs Triage', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2619681112,issue,closed,completed,"The Fields List in ""Learn about this Table"" isn't very legible","### Describe the bug

The columns in the table of fields in the data reference no longer appear to be verified to the column.

### To Reproduce

1. Go to:  Databases ->Sample Database -> Learn about this table

![Image](https://github.com/user-attachments/assets/0d9a6109-8ab8-4dad-935b-07c8dac669e3)


### Expected behavior

The table should be pretty

### Logs

_No response_

### Information about your Metabase installation

Checked v51.1 and v50.30

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-10-28 22:16:18+00:00,['npfitz'],2024-10-29 20:46:37+00:00,2024-10-29 20:02:41+00:00,https://github.com/metabase/metabase/issues/49257,"[('Type:Bug', 'Product defects'), ('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2442833351, 'issue_id': 2619681112, 'author': 'iethree', 'body': 'caused by https://github.com/metabase/metabase/pull/47747', 'created_at': datetime.datetime(2024, 10, 28, 23, 2, 38, tzinfo=datetime.timezone.utc)}]","iethree on (2024-10-28 23:02:38 UTC): caused by https://github.com/metabase/metabase/pull/47747

"
2619276545,issue,open,,"Search functionality in ""Learn about your data"" in SQL editor","**Is your feature request related to a problem? Please describe.**
You might know the field/column you are looking for but not know in which table/model it is, so it's time-consuming to look into every table until you find what you need

**Describe the solution you'd like**
A horizontal search in ""Learn about your data"" section when doing SQL
![Image](https://github.com/user-attachments/assets/7184a3c7-87fa-4b51-ba91-f5a62160519c)

**Describe alternatives you've considered**
Search in global search, but you are not building the query

**How important is this feature to you?**
Requested by a customer, internal ticket: 

**Additional context**
N/A
",ignacio-mb,2024-10-28 18:57:08+00:00,[],2025-02-04 20:30:28+00:00,,https://github.com/metabase/metabase/issues/49249,"[('Type:New Feature', ''), ('Querying/Native', 'The SQL/native query editor')]",[],
2618483119,issue,closed,completed,FE - e2e - Click behavior,,kamilmielnik,2024-10-28 13:48:02+00:00,['kamilmielnik'],2024-10-30 07:52:19+00:00,2024-10-30 07:52:18+00:00,https://github.com/metabase/metabase/issues/49233,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2446094193, 'issue_id': 2618483119, 'author': 'kamilmielnik', 'body': 'Closed by #49239', 'created_at': datetime.datetime(2024, 10, 30, 7, 52, 18, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-30 07:52:18 UTC): Closed by #49239

"
2618426050,issue,closed,completed,"Ability to hide ""Last edited at/by"" on the Collection Browser component in the sdk",We should expose a prop to hide the **last edited at / by** column in the CollectionBrowser component in the sdk.,heypoom,2024-10-28 13:26:24+00:00,['deniskaber'],2024-11-26 18:51:52+00:00,2024-11-05 16:23:16+00:00,https://github.com/metabase/metabase/issues/49232,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2618413923,issue,closed,completed,Maximum loop pattern,"Limit the number of roundtrips between backend and AI service (running out of gas, apparently)",perivamsi,2024-10-28 13:21:27+00:00,['johnswanson'],2024-10-29 21:01:32+00:00,2024-10-29 21:01:31+00:00,https://github.com/metabase/metabase/issues/49230,[],[],
2618411016,issue,closed,completed,Ability to control the entity picker's open state in the ModifyQuestion component,"The ModifyQuestion component opens the entity picker by default when the component is rendered. The customer wants to open it based on an action in their app, not open it by default.

The modal's open-close state could be controlled by a prop.",heypoom,2024-10-28 13:20:19+00:00,['deniskaber'],2024-10-29 20:06:38+00:00,2024-10-29 20:04:48+00:00,https://github.com/metabase/metabase/issues/49229,[],"[{'comment_id': 2441582645, 'issue_id': 2618411016, 'author': 'heypoom', 'body': 'NOTE: We are deprecating the `ModifyQuestion` component soon, so we should first check if the same behaviour can be done with `InteractiveQuestion`. If so, we can close this issue, and direct the customer to use `InteractiveQuestion`.', 'created_at': datetime.datetime(2024, 10, 28, 13, 24, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445220691, 'issue_id': 2618411016, 'author': 'deniskaber', 'body': ""As @heypoom mentioned, `InteractiveQuestion` doesn't have this issue.\n\n@albertoperdomo , could you please check if a customer could switch to use `InteractiveQuestion` component"", 'created_at': datetime.datetime(2024, 10, 29, 20, 4, 36, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-10-28 13:24:18 UTC): NOTE: We are deprecating the `ModifyQuestion` component soon, so we should first check if the same behaviour can be done with `InteractiveQuestion`. If so, we can close this issue, and direct the customer to use `InteractiveQuestion`.

deniskaber (Assginee) on (2024-10-29 20:04:36 UTC): As @heypoom mentioned, `InteractiveQuestion` doesn't have this issue.

@albertoperdomo , could you please check if a customer could switch to use `InteractiveQuestion` component

"
2618410345,issue,open,,Undo pattern,,perivamsi,2024-10-28 13:20:05+00:00,[],2024-10-28 13:20:06+00:00,,https://github.com/metabase/metabase/issues/49228,[],[],
2618384727,issue,closed,not_planned,Split viz tool into simpler tools,,perivamsi,2024-10-28 13:10:29+00:00,[],2024-11-13 14:29:33+00:00,2024-11-13 14:29:20+00:00,https://github.com/metabase/metabase/issues/49227,[],"[{'comment_id': 2441602645, 'issue_id': 2618384727, 'author': 'Somtom', 'body': 'Example PR with idea how to split the tools https://github.com/metabase/ai-proxy/pull/38', 'created_at': datetime.datetime(2024, 10, 28, 13, 32, 24, tzinfo=datetime.timezone.utc)}]","Somtom on (2024-10-28 13:32:24 UTC): Example PR with idea how to split the tools https://github.com/metabase/ai-proxy/pull/38

"
2618370493,issue,open,,Frontend error handling,,perivamsi,2024-10-28 13:04:20+00:00,['sloansparger'],2024-10-28 13:04:21+00:00,,https://github.com/metabase/metabase/issues/49226,[],[],
2618360947,issue,closed,completed,Unit of time parameters don't always work,"### How to reproduce

1. `git checkout dashboard-filter-columns`
2. Run any of these tests in `temporal-unit-parameters.cy.spec.js`:
    - `should connect a parameter to a question and drill thru`
    - `should connect multiple parameters to a card with multiple breakouts`

Example CI run: https://github.com/metabase/metabase/actions/runs/11552486348?pr=47167
    
### Additional info

In POST `/api/dashboard/:id/dashcard/:id/card/:id/query` FE sends `parameters` with `""stage-number"": 0` present - these parameters don't get applied.

If FE omits `""stage-number"": 0` - the query will work as expected",kamilmielnik,2024-10-28 13:00:16+00:00,[],2024-10-28 14:18:47+00:00,2024-10-28 14:18:45+00:00,https://github.com/metabase/metabase/issues/49225,[],"[{'comment_id': 2441724093, 'issue_id': 2618360947, 'author': 'kamilmielnik', 'body': 'Not a BE bug. Pivot table detection does not kick in.', 'created_at': datetime.datetime(2024, 10, 28, 14, 18, 45, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-28 14:18:45 UTC): Not a BE bug. Pivot table detection does not kick in.

"
2618216786,issue,open,,"Add support for comments/replies on questions, dashboards, etc.","**Is your feature request related to a problem? Please describe.**
There is no way to make a comment on a dashboard component or question, so the only way to provide feedback to the owner/author is outside of Metabase where you have to describe which component in a dashboard or provide a link before you can comment.

**Describe the solution you'd like**
Being able to select components in a dashboard or question (optional) and then add a comment/feedback that gets sent to the owner/author.

**Describe alternatives you've considered**
Provide feedback to owner/author outside of Metabase via Slack, Email, etc.

**How important is this feature to you?**
It would make collaboration much easier


**Additional context**
Forked from #33967 by @maxzheng 
",brunobergher,2024-10-28 11:59:36+00:00,[],2025-02-04 20:30:42+00:00,,https://github.com/metabase/metabase/issues/49221,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Organization/Saved Questions', '')]",[],
2618103387,issue,closed,completed,Tooltips Stop Working When Using iFrameResize with Embedded Metabase Dashboards,"### Describe the bug

Hello,
when embedding a static dashboard, the popup that appears on hover is not visible when iframeResizer is being used.


it's working on the embed url when navigating to the url of the iframe, or when the hosted iframe isn't using iframeResizer, also works on the dashboard/question on the mb instance.

![Image](https://github.com/user-attachments/assets/2ecff1ae-28f6-4cab-a2d4-13c283313053)
as you can see, the hover is in place but the pop-up doesn't appear.


### To Reproduce

1. Go to a dashboard
2. create a static embed
3. create a simple html page with an iframe with the metabase url and add the iframeresizer (<script src=""http://metabaseinstance/app/iframeResizer.js""></script>
4. open the html page
5. hover on a chart.
6. no pop-up appears.

### Expected behavior

![Image](https://github.com/user-attachments/assets/2b051899-9121-44c3-998d-6dfcad14dedd)


### Logs

```

 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-D6qzYMYshE'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-bgUp5tqDCSC1xokY+fdYcHMM/Fap5RX+TCFkA0sXuRk='), or a nonce ('nonce-...') is required to enable inline execution.

e @ vendor.66cc5cf07b44f626.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-HzzqMf4edF'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-bgUp5tqDCSC1xokY+fdYcHMM/Fap5RX+TCFkA0sXuRk='), or a nonce ('nonce-...') is required to enable inline execution.

e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
e @ vendor.66cc5cf07b44f626.js:1
aJ @ vendor.66cc5cf07b44f626.js:1
aZ @ vendor.66cc5cf07b44f626.js:1
aK @ vendor.66cc5cf07b44f626.js:1
aZ @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
sj @ vendor.66cc5cf07b44f626.js:1
sS @ vendor.66cc5cf07b44f626.js:1
w @ vendor.66cc5cf07b44f626.js:1
E @ vendor.66cc5cf07b44f626.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
nx @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
t @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
r @ app-embed.c17169454236fce9.js:1
a @ app-embed.c17169454236fce9.js:1
p.kE @ app-embed.c17169454236fce9.js:1
q @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
l @ app-embed.c17169454236fce9.js:1
m.KZ.j @ app-embed.c17169454236fce9.js:1
m.KZ.g @ app-embed.c17169454236fce9.js:1
m.KZ.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
u @ app-embed.c17169454236fce9.js:1
er.M1 @ app-embed.c17169454236fce9.js:1
N.j @ app-embed.c17169454236fce9.js:1
e @ app-embed.c17169454236fce9.js:1
S @ app-embed.c17169454236fce9.js:1
query @ app-embed.c17169454236fce9.js:1
databaseId @ app-embed.c17169454236fce9.js:1
database @ app-embed.c17169454236fce9.js:1
m @ app-embed.c17169454236fce9.js:496
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
n.<computed> @ vendor.66cc5cf07b44f626.js:11
(anonymous) @ app-embed.c17169454236fce9.js:213
aj @ vendor.66cc5cf07b44f626.js:1
sH @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
sj @ vendor.66cc5cf07b44f626.js:1
sR @ vendor.66cc5cf07b44f626.js:1
r8 @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
nx @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
t @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
r @ app-embed.c17169454236fce9.js:1
a @ app-embed.c17169454236fce9.js:1
p.kE @ app-embed.c17169454236fce9.js:1
q @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
l @ app-embed.c17169454236fce9.js:1
m.KZ.j @ app-embed.c17169454236fce9.js:1
m.KZ.g @ app-embed.c17169454236fce9.js:1
m.KZ.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
ly.g.g @ app-embed.c17169454236fce9.js:1
I.Y2 @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
n @ app-embed.c17169454236fce9.js:1
u @ app-embed.c17169454236fce9.js:1
er.M1 @ app-embed.c17169454236fce9.js:1
N.j @ app-embed.c17169454236fce9.js:1
e @ app-embed.c17169454236fce9.js:1
S @ app-embed.c17169454236fce9.js:1
query @ app-embed.c17169454236fce9.js:1
databaseId @ app-embed.c17169454236fce9.js:1
database @ app-embed.c17169454236fce9.js:1
m @ app-embed.c17169454236fce9.js:496
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
n.<computed> @ vendor.66cc5cf07b44f626.js:11
(anonymous) @ app-embed.c17169454236fce9.js:213
aj @ vendor.66cc5cf07b44f626.js:1
sH @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
sj @ vendor.66cc5cf07b44f626.js:1
sR @ vendor.66cc5cf07b44f626.js:1
r8 @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
nx @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
t @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
r @ app-embed.c17169454236fce9.js:1
a @ app-embed.c17169454236fce9.js:1
p.kE @ app-embed.c17169454236fce9.js:1
q @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
l @ app-embed.c17169454236fce9.js:1
m.KZ.j @ app-embed.c17169454236fce9.js:1
m.KZ.g @ app-embed.c17169454236fce9.js:1
m.KZ.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
u @ app-embed.c17169454236fce9.js:1
er.M1 @ app-embed.c17169454236fce9.js:1
N.j @ app-embed.c17169454236fce9.js:1
e @ app-embed.c17169454236fce9.js:1
S @ app-embed.c17169454236fce9.js:1
query @ app-embed.c17169454236fce9.js:1
databaseId @ app-embed.c17169454236fce9.js:1
database @ app-embed.c17169454236fce9.js:1
m @ app-embed.c17169454236fce9.js:496
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
n.<computed> @ vendor.66cc5cf07b44f626.js:11
(anonymous) @ app-embed.c17169454236fce9.js:213
aj @ vendor.66cc5cf07b44f626.js:1
sH @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
sj @ vendor.66cc5cf07b44f626.js:1
sR @ vendor.66cc5cf07b44f626.js:1
r8 @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
 %c[%c%cmetabase.lib.normalize%c%c]%c %c""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""%c color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#ffffff;background-color:#f5871f color:black;background-color:inherit color:#3e999f color:black
ny @ app-embed.c17169454236fce9.js:1
nx @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
t @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
r @ app-embed.c17169454236fce9.js:1
a @ app-embed.c17169454236fce9.js:1
p.kE @ app-embed.c17169454236fce9.js:1
q @ app-embed.c17169454236fce9.js:1
ly.g.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
l @ app-embed.c17169454236fce9.js:1
m.KZ.j @ app-embed.c17169454236fce9.js:1
m.KZ.g @ app-embed.c17169454236fce9.js:1
m.KZ.h @ app-embed.c17169454236fce9.js:1
(anonymous) @ app-embed.c17169454236fce9.js:1
ly.g.g @ app-embed.c17169454236fce9.js:1
I.Y2 @ app-embed.c17169454236fce9.js:1
nv @ app-embed.c17169454236fce9.js:1
nw @ app-embed.c17169454236fce9.js:1
ly.O.g @ app-embed.c17169454236fce9.js:1
n @ app-embed.c17169454236fce9.js:1
u @ app-embed.c17169454236fce9.js:1
er.M1 @ app-embed.c17169454236fce9.js:1
N.j @ app-embed.c17169454236fce9.js:1
e @ app-embed.c17169454236fce9.js:1
S @ app-embed.c17169454236fce9.js:1
query @ app-embed.c17169454236fce9.js:1
databaseId @ app-embed.c17169454236fce9.js:1
database @ app-embed.c17169454236fce9.js:1
m @ app-embed.c17169454236fce9.js:496
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
dispatch @ vendor.66cc5cf07b44f626.js:8
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ app-embed.c17169454236fce9.js:159
(anonymous) @ vendor.66cc5cf07b44f626.js:8
n.<computed> @ vendor.66cc5cf07b44f626.js:11
(anonymous) @ app-embed.c17169454236fce9.js:213
aj @ vendor.66cc5cf07b44f626.js:1
sH @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
sj @ vendor.66cc5cf07b44f626.js:1
sR @ vendor.66cc5cf07b44f626.js:1
r8 @ vendor.66cc5cf07b44f626.js:1
(anonymous) @ vendor.66cc5cf07b44f626.js:1
vendor.66cc5cf07b44f626.js:1 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-Mof5AYav0W'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-bgUp5tqDCSC1xokY+fdYcHMM/Fap5RX+TCFkA0sXuRk='), or a nonce ('nonce-...') is required to enable inline execution.

e @ vendor.66cc5cf07b44f626.js:1
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
ny @ core.cljs:4009
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
ny @ core.cljs:4009
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
ny @ core.cljs:4009
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
ny @ core.cljs:4009
html2canvas-pro.js:6063 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-Mof5AYav0W'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-UP0QZg7irvSMvOBz9mH2PIIE28+57UiavRfeVea0l3g='), or a nonce ('nonce-...') is required to enable inline execution.

A.toIFrame @ html2canvas-pro.js:6063
Show 1 more frame
Show less
html2canvas-pro.js:6063 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-Mof5AYav0W'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-bgUp5tqDCSC1xokY+fdYcHMM/Fap5RX+TCFkA0sXuRk='), or a nonce ('nonce-...') is required to enable inline execution.

A.toIFrame @ html2canvas-pro.js:6063
Show 1 more frame
Show less



```

### Information about your Metabase installation


```json
{
  ""browser-info"": {
    ""language"": ""it-IT"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""oracle"",
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-24"",
      ""tag"": ""v1.51.1.2"",
      ""hash"": ""4721f20""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15rc2 (Debian 15~rc2-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.25+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.25"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.25+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.14.0-427.18.1.el9_4.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

```

### Severity

it prevents all users from getting an insight of the data they're viewing, for example it's not always possible to see which month a data point is refering to, etc.

### Additional context

_No response_",joaquinjsb,2024-10-28 11:11:40+00:00,[],2024-11-21 06:06:44+00:00,2024-11-21 06:06:44+00:00,https://github.com/metabase/metabase/issues/49219,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Embedding', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2441435664, 'issue_id': 2618103387, 'author': 'paoliniluis', 'body': '@joaquinjsb are you a paid customer? if so please contact us', 'created_at': datetime.datetime(2024, 10, 28, 12, 20, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441448862, 'issue_id': 2618103387, 'author': 'joaquinjsb', 'body': 'yes I am, which form should I use?', 'created_at': datetime.datetime(2024, 10, 28, 12, 26, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442355313, 'issue_id': 2618103387, 'author': 'bshepherdson', 'body': ""Triage note: I'm not sure if this is a regression from v50 -> v51 or not. I can't readily reproduce embedding issues."", 'created_at': datetime.datetime(2024, 10, 28, 18, 41, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443649156, 'issue_id': 2618103387, 'author': 'joaquinjsb', 'body': 'I just did a test with v1.50.29 and v1.50.31.2, and it was working properly, after I upgraded to 1.51.x, the issue started.', 'created_at': datetime.datetime(2024, 10, 29, 9, 11, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445185835, 'issue_id': 2618103387, 'author': 'ixipixi', 'body': 'Confirmed - can repro in 51.1 but not 50.30.', 'created_at': datetime.datetime(2024, 10, 29, 19, 44, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490152781, 'issue_id': 2618103387, 'author': 'WiNloSt', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/49537 and was fixed by https://github.com/metabase/metabase/pull/49964 which is included in [0.51.4](https://github.com/metabase/metabase/releases/tag/v0.51.4)', 'created_at': datetime.datetime(2024, 11, 21, 6, 6, 37, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-28 12:20:42 UTC): @joaquinjsb are you a paid customer? if so please contact us

joaquinjsb (Issue Creator) on (2024-10-28 12:26:22 UTC): yes I am, which form should I use?

bshepherdson on (2024-10-28 18:41:33 UTC): Triage note: I'm not sure if this is a regression from v50 -> v51 or not. I can't readily reproduce embedding issues.

joaquinjsb (Issue Creator) on (2024-10-29 09:11:39 UTC): I just did a test with v1.50.29 and v1.50.31.2, and it was working properly, after I upgraded to 1.51.x, the issue started.

ixipixi on (2024-10-29 19:44:39 UTC): Confirmed - can repro in 51.1 but not 50.30.

WiNloSt on (2024-11-21 06:06:37 UTC): Duplicate of https://github.com/metabase/metabase/issues/49537 and was fixed by https://github.com/metabase/metabase/pull/49964 which is included in [0.51.4](https://github.com/metabase/metabase/releases/tag/v0.51.4)

"
2618044789,issue,closed,completed,Show columns from all stages in click behavior (target question),,kamilmielnik,2024-10-28 10:47:27+00:00,['kamilmielnik'],2024-11-05 08:26:34+00:00,2024-11-05 08:26:32+00:00,https://github.com/metabase/metabase/issues/49218,"[('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2456527968, 'issue_id': 2618044789, 'author': 'kamilmielnik', 'body': 'Closed by #48828', 'created_at': datetime.datetime(2024, 11, 5, 8, 26, 32, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-11-05 08:26:32 UTC): Closed by #48828

"
2617933387,issue,closed,completed,Rename ai-proxy to ai-service,We decided to change the naming from `ai-proxy` to `ai-service`. This will conclude work in the ai-proxy repo to rename it but also potential URL changes in the BE.,Somtom,2024-10-28 10:05:10+00:00,['johnswanson'],2024-11-13 12:07:35+00:00,2024-11-13 12:07:35+00:00,https://github.com/metabase/metabase/issues/49215,[],"[{'comment_id': 2443984298, 'issue_id': 2617933387, 'author': 'Somtom', 'body': 'https://github.com/metabase/ai-proxy/pull/45', 'created_at': datetime.datetime(2024, 10, 29, 11, 44, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444997199, 'issue_id': 2617933387, 'author': 'Somtom', 'body': '@johnswanson the repo and service are renamed. New URL `https://ai-service.coredev.metabase.com/`', 'created_at': datetime.datetime(2024, 10, 29, 18, 6, 31, tzinfo=datetime.timezone.utc)}]","Somtom (Issue Creator) on (2024-10-29 11:44:25 UTC): https://github.com/metabase/ai-proxy/pull/45

Somtom (Issue Creator) on (2024-10-29 18:06:31 UTC): @johnswanson the repo and service are renamed. New URL `https://ai-service.coredev.metabase.com/`

"
2616174110,issue,open,,Regression analysis,"**Is your feature request related to a problem? Please describe.**
Now that we can write back into some databases we could do some regression analysis with some ML libraries out there.

**Describe the solution you'd like**
Let's say that I have a time series data set, e.g. how much I've been selling per day: I would like Metabase to tell me how much I should be selling in the next X days. I will define a training set (e.g. total of sales from the last few years) and test set (how much I've been selling this year) and a field or a set of fields that will act as features

**Describe alternatives you've considered**
Doing this outside of Metabase and then writing back

**How important is this feature to you?**
Could be cool

**Additional context**
NA
",paoliniluis,2024-10-26 22:03:07+00:00,[],2025-02-04 20:30:43+00:00,,https://github.com/metabase/metabase/issues/49208,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2616162010,issue,closed,not_planned,Problem with the docs,"The doc https://www.metabase.com/docs/latest/questions/query-builder/expressions/cumulative#queries-without-datetime-dimension said you will do the cummulative sum along the last dimension specified in the Group By block. However it's actually using the first one. Could you check?
![Image](https://github.com/user-attachments/assets/8ccb0682-e483-4b35-955e-9ade1aea0c77)
",zjasper666,2024-10-26 21:40:29+00:00,[],2024-10-26 22:27:04+00:00,2024-10-26 22:27:02+00:00,https://github.com/metabase/metabase/issues/49207,[],"[{'comment_id': 2439754653, 'issue_id': 2616162010, 'author': 'paoliniluis', 'body': ""if this is a question please create one on the forums, we don't answer questions here"", 'created_at': datetime.datetime(2024, 10, 26, 22, 27, 2, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-26 22:27:02 UTC): if this is a question please create one on the forums, we don't answer questions here

"
2615242475,issue,closed,completed,Editing and saving a question when a dashboard time grouping parameter is applied with new time granularity breaks the parameter wiring,"### Describe the bug

If you connect a time grouping widget to a question, select a grouping that different from original, then edit and save the question, the time grouping will not be doing anything anymore.

This can be confusing because someone can go edit the question to, for example, add filters (which is how I ran into this issue) or change chart settings, and it'll break the connection between the parameter widget and the column.

Here's an [example stats dashboard+questions](https://stats.metabase.com/dashboard/2681-time-parameter-testing?time_grouping=quarter)

Disconnecting and reconnecting the widget will fix the issue.

### To Reproduce

1. Create a question Sample DB > Orders > Count of Orders by `Created At: Month`
2. Add the question to a dashboard
3. Add a time grouping widget to the dashboard and connect the widget to `Created At`
5. Save
6. Pick a different time grouping (e.g. week)
7. While the grouping is applied, click on the question to edit it
8. Save the question and pick ""replace""
9. Go back to the dashboard
10. Try to change the grouping 
-> doesn't do anything

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

51.1, master

### Severity

P2

### Additional context

https://github.com/user-attachments/assets/6f80cb12-b744-4fc8-ae5b-dc746ec45fb2
",alexyarosh,2024-10-25 22:17:26+00:00,['lbrdnk'],2024-11-04 23:10:29+00:00,2024-10-31 17:49:23+00:00,https://github.com/metabase/metabase/issues/49202,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2441450575, 'issue_id': 2615242475, 'author': 'fer-batista', 'body': '@alexyarosh Taking advantage of the topic about time grouping. Do you have any tips on how to insert the variable into a native SQL Query?\nWhen I pick the time grouping:\n\n_Add a variable to this question to connect it to a dashboard filter._\n\n![Image](https://github.com/user-attachments/assets/2efdbcf6-d7c9-4cc5-a3ae-ef30a70b0fac)', 'created_at': datetime.datetime(2024, 10, 28, 12, 27, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441526483, 'issue_id': 2615242475, 'author': 'paoliniluis', 'body': ""@fer-batista you can't insert time grouping variables in SQL questions yet"", 'created_at': datetime.datetime(2024, 10, 28, 13, 1, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442290109, 'issue_id': 2615242475, 'author': 'ranquild', 'body': ""The original issue with changing the temporal unit in the source question:\n1. The breakout reference is used for the parameter mapping\n2. The breakout gets changed so the breakout reference also gets changed\n3. The parameter mapping is no longer valid, we cannot find the column\n\nThis issue could be solved by the field refs project but we're too far away to get it merged, so we need a temporary fix.\n\nTo fix it right now, we could add logic to the BE to try to find a breakout clause with another temporal unit for the same column. If we found exactly 1, then we can use it instead. If more than 1, then we should ignore this parameter mapping, like we do now. The fix is not ideal but it would work for simple cases where there are no multiple breakouts of the same column."", 'created_at': datetime.datetime(2024, 10, 28, 18, 10, 17, tzinfo=datetime.timezone.utc)}]","fer-batista on (2024-10-28 12:27:11 UTC): @alexyarosh Taking advantage of the topic about time grouping. Do you have any tips on how to insert the variable into a native SQL Query?
When I pick the time grouping:

_Add a variable to this question to connect it to a dashboard filter._

![Image](https://github.com/user-attachments/assets/2efdbcf6-d7c9-4cc5-a3ae-ef30a70b0fac)

paoliniluis on (2024-10-28 13:01:06 UTC): @fer-batista you can't insert time grouping variables in SQL questions yet

ranquild on (2024-10-28 18:10:17 UTC): The original issue with changing the temporal unit in the source question:
1. The breakout reference is used for the parameter mapping
2. The breakout gets changed so the breakout reference also gets changed
3. The parameter mapping is no longer valid, we cannot find the column

This issue could be solved by the field refs project but we're too far away to get it merged, so we need a temporary fix.

To fix it right now, we could add logic to the BE to try to find a breakout clause with another temporal unit for the same column. If we found exactly 1, then we can use it instead. If more than 1, then we should ignore this parameter mapping, like we do now. The fix is not ideal but it would work for simple cases where there are no multiple breakouts of the same column.

"
2615098866,issue,open,,Add an easy way to see all queries that metabase sends,"@paoliniluis often wants to see the actual queries that metabase issues. He had learned which logging level in the qp would allow this. This has recently changed. He now has to have a quite chatty low level enabled in order to see queries. This leaves him flying blind.

The feature:
we want to be able to easily see all queries that metabase sends over (question: what about sync? this can be quite a lot). For the time being lets go with user queries.

",dpsutton,2024-10-25 20:55:09+00:00,[],2025-02-04 20:30:14+00:00,,https://github.com/metabase/metabase/issues/49198,"[('Type:New Feature', ''), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]",[],
2615076252,issue,closed,completed,Document loader and error components in sdk's docs,We should add the loader and error components to the docs.,heypoom,2024-10-25 20:46:25+00:00,['heypoom'],2024-10-28 19:03:36+00:00,2024-10-28 19:00:48+00:00,https://github.com/metabase/metabase/issues/49194,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2615063723,issue,closed,completed,Specify the collection to save to via a prop in the sdk's save modal,"We want to restrict where users can save into programmatically, i.e. which collection to save to, so the user don't have to ever think about collections).

When saving, we currently ask whether to create a new question or overwrite the question. If they choose ""new question"", they should pick a name, but they don't need to choose where to save to. Just disabling the selection would be enough for the customer at the moment.

We should make sure this covers the components we have that allows saving, i.e. dashboard, question, etc.

Reference: [Customer Feedback in Notion](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4#12a69354c9018035aba2ff570816a57d)",heypoom,2024-10-25 20:38:57+00:00,['heypoom'],2024-11-05 09:42:38+00:00,2024-11-04 13:49:15+00:00,https://github.com/metabase/metabase/issues/49193,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2614943446,issue,closed,not_planned,Bring Actions to Clickhouse,,psalinasy,2024-10-25 19:27:54+00:00,[],2024-10-29 14:22:38+00:00,2024-10-29 14:22:38+00:00,https://github.com/metabase/metabase/issues/49189,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2439725346, 'issue_id': 2614943446, 'author': 'paoliniluis', 'body': 'Hi @psalinasy can you add this to the clickhouse driver repository?', 'created_at': datetime.datetime(2024, 10, 26, 20, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444399099, 'issue_id': 2614943446, 'author': 'psalinasy', 'body': 'Actually - it is already there. Dupe for https://github.com/ClickHouse/metabase-clickhouse-driver/issues/167', 'created_at': datetime.datetime(2024, 10, 29, 14, 15, 36, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-26 20:18:09 UTC): Hi @psalinasy can you add this to the clickhouse driver repository?

psalinasy (Issue Creator) on (2024-10-29 14:15:36 UTC): Actually - it is already there. Dupe for https://github.com/ClickHouse/metabase-clickhouse-driver/issues/167

"
2614937058,issue,closed,completed,Bug: Command Palette verification does not respect token status,"Currently, the command palette simply checks the moderated status of recent items and search results. This means that if a user verifies a question, then removes their token, Items in the command palette will continue to display as verified",npfitz,2024-10-25 19:23:33+00:00,[],2024-10-31 17:07:41+00:00,2024-10-31 15:52:53+00:00,https://github.com/metabase/metabase/issues/49188,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2614698965,issue,open,,[Epic] Field refs overhaul,"**Links**
- product doc: _link to product doc_
- eng doc: [Tech: Fixing refs](https://www.notion.so/metabase/Tech-Fixing-refs-55b26cfcf44744e5b044446400a01c27)
- feature branch: `refs-overhaul`
- issue links: #36185

**Implementation Plan**

_Details are in the eng doc, see **Approach 2** and **Approach 4, Variant 3** in particular._

Thumbnail sketch:

Introduce opaque string `:ident`s for all columns. These will be (1) globally unique and (2) portable by Serialization. Once they're available everywhere, use `:ident`s to construct unambiguous, globally indexable references, and use those instead of the current symbolic, ambiguous, expensive-to-dereference `:field`/`:expression`/`:aggregation` refs.

**Testing Plan**

See [Notion doc](https://www.notion.so/metabase/Testing-plan-15969354c9018052856bf7549c81b2a6?showMoveTo=true&saveParent=true) for details.

***Milestone 1: Backend foundation***

- [x] #49681
- [x] #49682
- [x] #49683
- [x] #49684
- [x] ~~#49685~~


***Milestone 2: Piecemeal port of MBQL lib***

*Splitting the parts of MBQL lib that deal with metadata and refs into `foo:old-refs` and `foo:new-refs`, from a central core outwards until it's complete! Each step here should be mergeable without breaking anything, since the `old-refs` flavour is the default.*

- [x] #49686
- [ ] #53048
- [ ] #52695
- [ ] #52696
- [ ] #52697
- [ ] #52698
- [ ] #52699
- [ ] #52700
- [ ] #52701
- [ ] #52702
    - We should do this eagerly, since this is a lot of duplicated code to carry for any longer than necessary.

*Expected bugfixes:*
- #27521
- #27735
- #12930
- #39155
- #19893
- #46845
- #34743
- #32499
- #35256
- #12679

***Milestone 3: Port problem spots in QP to use MBQL lib***

*Many parts of the QP still use legacy MBQL, and therefore the improvements to the lib from M2 won't help them. I've included the list of bugs I expect to be fixed by each stage; not necessarily comprehensive. The order of these is a bit uncertain.*

- [ ] #52703
    - _These are the source of most ""this works unless it's a model"" and ""SQL references a field that doesn't exist"" issues._
    - #23449
    - #33972
    - #47988
    - #48001 
    - #52465 
- [ ] #52704
    - _Actually might be able to just remove this one - there's nothing to reconcile when there's a single source of truth!_
- [ ] #52705
- [ ] #52706
- [ ] #52707


***Milestone 4: `:column` refs in FE***

*This can be done in parallel with M3.*

- [ ] #49692
- [ ] #49693
- [ ] #49694
- [ ] #49695
- [ ] #49696

*Expected fixes:*
- #11829

***Milestone 5: Cleanup***

*At this stage there should be no usage of legacy field refs that isn't also using legacy MBQL!* So we can delete a lot of the code for wrangling old refs.

- [ ] #49697
- [ ] #49698",bshepherdson,2024-10-25 17:20:41+00:00,['bshepherdson'],2025-01-31 16:02:57+00:00,,https://github.com/metabase/metabase/issues/49182,"[('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2462453841, 'issue_id': 2614698965, 'author': 'bshepherdson', 'body': ""Update on the progress, since this has been living in local branches so far.\n\n- Milestone 1 is complete, except for the last part (#49685) which is not vital.\n    - `metabase.lib.js.metadata` can reconstruct the `:ident`s for fields on the fly.\n    - We should probably still include the `:ident`s with those API calls; it might make dashboard parameter mapping etc. easier.\n- Mostly done 2.1\n\nRegarding when things will turn from local branches to PRs, or a working feature branch:\n- There were still some open questions and risks in this approach when I started writing it\n- So I wanted to get far enough along to prove the approach is sound.\n- M2 is the dividing line: at that point both models are running side by side and we can check (via the test suite and the new generative testing) that they produce the same results!\n\nRegarding feature branches vs. directly to master:\n- Everything through M2 is additive, and doesn't change any existing logic.\n- From M3 on I'm uncertain; I think it can be done in small pieces straight to master.\n\nFinally, I've realized that there's a looming M6 not accounted for here: some of the refs issues (#36185) will be fixed by doing this for `metabase.lib` and the main FE parts that consume refs - QB, viz settings, and parameter mapping. **But** some of the benefits will only be realized when several key parts of the QP are consuming the new, unambiguous refs as well. So there's some porting work that will be necessary there to fix some of the refs bugs.\n\nEarly this year that proved moderately costly of dev time, and risky in terms of introducing subtle bugs. I hope the new generative testing will help make it easier to get right. In any case, a push to eliminate use of legacy MBQL throughout the codebase still needs to happen."", 'created_at': datetime.datetime(2024, 11, 7, 14, 59, 34, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2024-11-07 14:59:34 UTC): Update on the progress, since this has been living in local branches so far.

- Milestone 1 is complete, except for the last part (#49685) which is not vital.
    - `metabase.lib.js.metadata` can reconstruct the `:ident`s for fields on the fly.
    - We should probably still include the `:ident`s with those API calls; it might make dashboard parameter mapping etc. easier.
- Mostly done 2.1

Regarding when things will turn from local branches to PRs, or a working feature branch:
- There were still some open questions and risks in this approach when I started writing it
- So I wanted to get far enough along to prove the approach is sound.
- M2 is the dividing line: at that point both models are running side by side and we can check (via the test suite and the new generative testing) that they produce the same results!

Regarding feature branches vs. directly to master:
- Everything through M2 is additive, and doesn't change any existing logic.
- From M3 on I'm uncertain; I think it can be done in small pieces straight to master.

Finally, I've realized that there's a looming M6 not accounted for here: some of the refs issues (#36185) will be fixed by doing this for `metabase.lib` and the main FE parts that consume refs - QB, viz settings, and parameter mapping. **But** some of the benefits will only be realized when several key parts of the QP are consuming the new, unambiguous refs as well. So there's some porting work that will be necessary there to fix some of the refs bugs.

Early this year that proved moderately costly of dev time, and risky in terms of introducing subtle bugs. I hope the new generative testing will help make it easier to get right. In any case, a push to eliminate use of legacy MBQL throughout the codebase still needs to happen.

"
2614659623,issue,open,,Map visualization - support currency options in settings,"**Is your feature request related to a problem? Please describe.**
The map visualization currently does not provide an option to specify or override the currency unit of the metric displayed on the page.

From customer:
> We have two different Metabase dashboards for our customers, where we use the same questions but then differentiate between Euro and CHF.
> Now I have noticed that I cannot change the € sign on this chart as I can on all other charts. Why is that?

**Describe the solution you'd like**
Allow customizing the currency unit on the visualization settings similarly to other charts.

**Describe alternatives you've considered**
To override the currency unit one could create a model based on the source table, edit the metadata of the model and set the currency unit for the column to be aggregated. Then create a question based on the model using the Map visualization. This is cumbersome and requires introducing or duplicating a model unnecessarily.

**How important is this feature to you?**
Requested by a customer.

**Additional context**
The way this is currently configurable in the Pie viz:
![Image](https://github.com/user-attachments/assets/68f5f075-c5a5-4b90-a9d7-f961e39e8230)",zbodi74,2024-10-25 17:02:12+00:00,[],2025-02-04 20:31:54+00:00,,https://github.com/metabase/metabase/issues/49181,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Maps', '')]",[],
2614658052,issue,open,,Driver: NocoDB,"**Is your feature request related to a problem? Please describe.**
I want to create a dashboard from my NocoDB data, but the connector does not exists.

**Describe the solution you'd like**
A new data source for NocoDB

**Describe alternatives you've considered**
Use another tool than Metabase that has a NocoDB data source.

**How important is this feature to you?**
7/10

**Additional context**
The NocoDB community is desperately looking for a dashboard tool in order to visualize data. If you implement it, the NocoDB community will rush to use Metabase.

https://github.com/nocodb/nocodb/issues/9223
",LucBerge,2024-10-25 17:01:13+00:00,[],2025-02-04 20:30:55+00:00,,https://github.com/metabase/metabase/issues/49180,"[('Database/', ''), ('Type:New Feature', '')]","[{'comment_id': 2439726830, 'issue_id': 2614658052, 'author': 'paoliniluis', 'body': 'we need https://github.com/metabase/metabase/issues/4831 for this', 'created_at': datetime.datetime(2024, 10, 26, 20, 24, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532666248, 'issue_id': 2614658052, 'author': 'gamersalpha', 'body': 'Hello, i need help how to add nocodb on metabase please ?\n\n<!-- Failed to upload ""image.png"" -->\n\n\ni can\'t add nocodb on metabase how do that please ?', 'created_at': datetime.datetime(2024, 12, 10, 19, 19, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532793211, 'issue_id': 2614658052, 'author': 'paoliniluis', 'body': '@gamersalpha please read my comment above', 'created_at': datetime.datetime(2024, 12, 10, 20, 23, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575108487, 'issue_id': 2614658052, 'author': 'xximj', 'body': '+1 For this', 'created_at': datetime.datetime(2025, 1, 7, 11, 59, 26, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-26 20:24:59 UTC): we need https://github.com/metabase/metabase/issues/4831 for this

gamersalpha on (2024-12-10 19:19:47 UTC): Hello, i need help how to add nocodb on metabase please ?

<!-- Failed to upload ""image.png"" -->


i can't add nocodb on metabase how do that please ?

paoliniluis on (2024-12-10 20:23:10 UTC): @gamersalpha please read my comment above

xximj on (2025-01-07 11:59:26 UTC): +1 For this

"
2614563283,issue,closed,completed,Exclude Date filters have opposite behavior than intended,"Let's say I want to exclude Saturday and Sunday from my question. I click on Exclude… > Days of the week…, and get a dropdown of days. I remember that the CTA I clicked on was ""Exclude.."", so I think that the dropdown is for the days that should be excluded, so I select Saturday and Sunday…and then Metabase create a filter that says ""excludes 5 days of week"" and I'm like, ""wut?"". Clicking on the filter, I discover that in fact, the days that I should select in ""Exclude"" dropdown are the days I want to include.

<img src=""https://github.com/user-attachments/assets/15c2b03e-5453-4693-9126-9f4de230fafc"" width=""300"" />
<img src=""https://github.com/user-attachments/assets/c52d37ac-6cdd-4519-a23d-409c674d4b45"" width=""300"" />
<img src=""https://github.com/user-attachments/assets/4e321f3a-a2c0-474d-a83d-39ea7b0a129a "" width=""300"" />


### To Reproduce

1. Go to a table with a date column
2. Filter by it
3. Exclude
4. Days of the Week, pick two

It excludes the other 5 days

### Expected behavior

To exclude rows with the date in those days

### Logs

_No response_

### Information about your Metabase installation

stats on `cca66d4`, but this has probably been there for 5 or 6 versions

### Severity

P2

### Additional context

_No response_",brunobergher,2024-10-25 16:23:43+00:00,['ranquild'],2024-10-28 14:59:06+00:00,2024-10-28 13:52:06+00:00,https://github.com/metabase/metabase/issues/49176,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2614395836,issue,closed,completed,Impersonation does not work with model caching,"### Describe the bug

If you set up impersonation then all cached models won't work, since the database engine won't allow access to the cached models schema

### To Reproduce

1) set up impersonation with guide https://www.metabase.com/learn/metabase-basics/administration/permissions/impersonation
2) enable model caching, then create a model and wait for it to be cached
3) access the model with the impersonated users, see the error 
![Image](https://github.com/user-attachments/assets/1b4ffcd9-fa46-4ca8-9acd-8a421fbb9dcd)


### Expected behavior

When impersonation is enabled we should not go to the cached model and rather send the query to the normal table

### Logs

```
2024-10-25 15:13:38,873 ERROR middleware.catch-exceptions :: Error processing query: ERROR: permission denied for schema metabase_cache_08487_4
  Position: 552
{:database_id 4,
 :started_at #t ""2024-10-25T15:13:38.787168Z[Etc/UTC]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: ERROR: permission denied for schema metabase_cache_08487_4\n  Position: 552"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__86031$fn__86032.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__85835$fn__85836.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__85835.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__85835.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__119504.invokeStatic(sql_jdbc.clj:79)""
    ""driver.sql_jdbc$fn__119504.invoke(sql_jdbc.clj:77)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:62)""
    ""query_processor.execute$run.invoke(execute.clj:56)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_76882__76883$fn__76884.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__76899.invoke(execute.clj:25)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__76905.invoke(execute.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___76855.invoke(cache.clj:241)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__73895.invoke(permissions.clj:147)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__113603$check_download_permissions__113604$fn__113605.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74603.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__115542$maybe_apply_column_level_perms_check__115543$fn__115544.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74613.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute76932__76933$fn__76934.invoke(execute.clj:94)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor.execute$execute76932__76933.invokeStatic(execute.clj:93)""
    ""query_processor.execute$execute76932__76933.invoke(execute.clj:89)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
    ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
    ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:106)""
    ""driver$do_with_driver.invoke(driver.clj:101)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
    ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
    ""api.dataset$run_streaming_query99466__99469$fn__99473.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__53224.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 2 queryType: MBQL queryHash: 7bbe42cf1e73b93a1271f1c77a9aed8a117120ac82e4f955784b20c979e37433""
     ""SELECT""
     ""  \""source\"".\""id\"" AS \""id\"",""
     ""  \""source\"".\""address\"" AS \""address\"",""
     ""  \""source\"".\""email\"" AS \""email\"",""
     ""  \""source\"".\""password\"" AS \""password\"",""
     ""  \""source\"".\""name\"" AS \""name\"",""
     ""  \""source\"".\""city\"" AS \""city\"",""
     ""  \""source\"".\""longitude\"" AS \""longitude\"",""
     ""  \""source\"".\""state\"" AS \""state\"",""
     ""  \""source\"".\""source\"" AS \""source\"",""
     ""  \""source\"".\""birth_date\"" AS \""birth_date\"",""
     ""  \""source\"".\""zip\"" AS \""zip\"",""
     ""  \""source\"".\""latitude\"" AS \""latitude\"",""
     ""  \""source\"".\""created_at\"" AS \""created_at\""""
     ""FROM""
     ""  (""
     ""    select""
     ""      *""
     ""    from""
     ""      \""metabase_cache_08487_4\"".\""model_122_people\""""
     ""  ) AS \""source\""""
     ""LIMIT""
     ""  2000""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :state ""42501"",
 :error_type :invalid-query,
 :json_query
 {:database 4,
  :type ""query"",
  :query {:source-table ""card__122""},
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""source\"".\""id\"" AS \""id\"", \""source\"".\""address\"" AS \""address\"", \""source\"".\""email\"" AS \""email\"", \""source\"".\""password\"" AS \""password\"", \""source\"".\""name\"" AS \""name\"", \""source\"".\""city\"" AS \""city\"", \""source\"".\""longitude\"" AS \""longitude\"", \""source\"".\""state\"" AS \""state\"", \""source\"".\""source\"" AS \""source\"", \""source\"".\""birth_date\"" AS \""birth_date\"", \""source\"".\""zip\"" AS \""zip\"", \""source\"".\""latitude\"" AS \""latitude\"", \""source\"".\""created_at\"" AS \""created_at\"" FROM (select * from \""metabase_cache_08487_4\"".\""model_122_people\"") AS \""source\"" LIMIT 2000"",
  :params nil},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__85961.invokeStatic(execute.clj:570)""
  ""driver.sql_jdbc.execute$fn__85961.invoke(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:578)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031$fn__86032.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__86031.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__85835$fn__85836.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection85805__85806.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__85835.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__85835.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__119504.invokeStatic(sql_jdbc.clj:79)""
  ""driver.sql_jdbc$fn__119504.invoke(sql_jdbc.clj:77)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:62)""
  ""query_processor.execute$run.invoke(execute.clj:56)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_76882__76883$fn__76884.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__76899.invoke(execute.clj:25)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__76905.invoke(execute.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___76855.invoke(cache.clj:241)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__73895.invoke(permissions.clj:147)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__113603$check_download_permissions__113604$fn__113605.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__74603.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__115542$maybe_apply_column_level_perms_check__115543$fn__115544.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__74613.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute76932__76933$fn__76934.invoke(execute.clj:94)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor.execute$execute76932__76933.invokeStatic(execute.clj:93)""
  ""query_processor.execute$execute76932__76933.invoke(execute.clj:89)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
  ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
  ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:106)""
  ""driver$do_with_driver.invoke(driver.clj:101)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
  ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
  ""api.dataset$run_streaming_query99466__99469$fn__99473.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response ....
```

### Information about your Metabase installation

- tested in v51, but this might probably come from previous versions

### Severity

P2

### Additional context

NA",paoliniluis,2024-10-25 15:14:42+00:00,['noahmoss'],2024-10-30 23:01:00+00:00,2024-10-30 21:39:52+00:00,https://github.com/metabase/metabase/issues/49172,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Cache', ''), ('Administration/Impersonation', 'Role level security'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2614327188,issue,open,,Tab titles are not displayed correctly on embedded dashboard in iOS browsers,"### Describe the bug

When accessing an embedded dashboard in Metabase on iOS devices, the tab titles appear to be covered or inactive, making them difficult to read:
![Image](https://github.com/user-attachments/assets/27b6af09-5911-46c3-937b-a02cbfc0d3d3)

This does not occur on web or Android, where the tab titles display as expected:
![Image](https://github.com/user-attachments/assets/b8621ab9-906d-4fe5-9914-5e853051a74e)


### To Reproduce

From customer:
> We were able to reproduce the issue on 3 browsers: Safari, Chrome and Firefox. 
> We have tested on two different iPhone:
> iPhone 11, iOS 16.7
> iPhone 15, iOS 17.6.1

1. Share a dashboard via static embedding and open it on an iOS device
2. Use Safari, Chrome, or Firefox to access the dashboard
3. Navigate to any tab within the embedded dashboard and observe the tab titles

### Expected behavior

The tab titles should display clearly, without any overlay, similarly as it is displayed on other platforms.








### Logs

_No response_

### Information about your Metabase installation

1.50.30

### Severity

Annoying. Reported by a customer.

### Additional context

_No response_",zbodi74,2024-10-25 14:48:58+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/49170,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]",[],
2614290896,issue,closed,completed,Error when try to search a question to add in a dashboard,"### Describe the bug

Search bar used to find a question and add them to a dashboard is not working.
Unexpected character ('2' (code 50)): was expecting comma to separate Object entries at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 179]

![Image](https://github.com/user-attachments/assets/adb77ad8-1794-43e4-810e-f08ca5f7946a)


### To Reproduce

1. Go to a dashboard
2. Click on add questions
3. Use the search box
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P3

### Additional context

_No response_",fer-batista,2024-10-25 14:35:22+00:00,[],2024-10-30 12:22:18+00:00,2024-10-30 12:22:17+00:00,https://github.com/metabase/metabase/issues/49169,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2438021378, 'issue_id': 2614290896, 'author': 'dpsutton', 'body': '@fer-batista can you provide the logs that appear in the backend when this error happens?', 'created_at': datetime.datetime(2024, 10, 25, 14, 48, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438046481, 'issue_id': 2614290896, 'author': 'fer-batista', 'body': '@dpsutton \n```\n{:via\n [{:type com.fasterxml.jackson.core.JsonParseException,\n   :message\n   ""Unexpected close marker \'}\': expected \']\' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]"",\n   :at [com.fasterxml.jackson.core.JsonParser _constructReadException ""JsonParser.java"" 2643]}],\n :trace\n [[com.fasterxml.jackson.core.JsonParser _constructReadException ""JsonParser.java"" 2643]\n  [com.fasterxml.jackson.core.base.ParserBase _reportMismatchedEndMarker ""ParserBase.java"" 1386]\n  [com.fasterxml.jackson.core.json.ReaderBasedJsonParser _closeScope ""ReaderBasedJsonParser.java"" 3040]\n  [com.fasterxml.jackson.core.json.ReaderBasedJsonParser nextToken ""ReaderBasedJsonParser.java"" 685]\n  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 66]\n  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]\n  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]\n  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]\n  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]\n  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]\n  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]\n  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]\n  [cheshire.parse$parse invokeStatic ""parse.clj"" 100]\n  [cheshire.parse$parse invoke ""parse.clj"" 88]\n  [cheshire.core$parse_string invokeStatic ""core.clj"" 208]\n  [cheshire.core$parse_string invoke ""core.clj"" 194]\n  [cheshire.core$parse_string invokeStatic ""core.clj"" 204]\n  [cheshire.core$parse_string invoke ""core.clj"" 194]\n  [metabase.search.impl$serialize$fn__106071 invoke ""impl.clj"" 177]\n  [clojure.core$update invokeStatic ""core.clj"" 6259]\n  [clojure.core$update invoke ""core.clj"" 6251]\n  [metabase.search.impl$serialize invokeStatic ""impl.clj"" 176]\n  [metabase.search.impl$serialize invoke ""impl.clj"" 147]\n  [clojure.core$map$fn__5954 invoke ""core.clj"" 2770]\n  [clojure.lang.LazySeq force ""LazySeq.java"" 50]\n  [clojure.lang.LazySeq realize ""LazySeq.java"" 89]\n  [clojure.lang.LazySeq seq ""LazySeq.java"" 106]\n  [clojure.lang.RT seq ""RT.java"" 555]\n  [clojure.lang.RT countFrom ""RT.java"" 670]\n  [clojure.lang.RT count ""RT.java"" 663]\n  [metabase.search.impl$search_results invokeStatic ""impl.clj"" 362]\n  [metabase.search.impl$search_results invoke ""impl.clj"" 344]\n  [metabase.search.impl$search106127__106128 invokeStatic ""impl.clj"" 380]\n  [metabase.search.impl$search106127__106128 invoke ""impl.clj"" 364]\n  [metabase.api.search$fn__106357 invokeStatic ""search.clj"" 137]\n  [metabase.api.search$fn__106357 invoke ""search.clj"" 94]\n  [compojure.core$wrap_response$fn__53970 invoke ""core.clj"" 160]\n  [compojure.core$wrap_route_middleware$fn__53954 invoke ""core.clj"" 132]\n  [compojure.core$wrap_route_info$fn__53959 invoke ""core.clj"" 139]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 151]\n  [clojure.lang.Var invoke ""Var.java"" 395]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 153]\n  [clojure.lang.Var invoke ""Var.java"" 395]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]\n  [clojure.lang.Var invoke ""Var.java"" 395]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [metabase.api.search$_PLUS_engine_cookie$fn__106303 invoke ""search.clj"" 38]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [metabase.server.middleware.auth$enforce_authentication$fn__102827 invoke ""auth.clj"" 18]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]\n  [clojure.lang.Var invoke ""Var.java"" 395]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [metabase.api.routes$fn__108227$fn__108228 invoke ""routes.clj"" 70]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\n  [clojure.core$apply invokeStatic ""core.clj"" 667]\n  [clojure.core$apply invoke ""core.clj"" 662]\n  [metabase.server.routes$fn__108507$fn__108508 doInvoke ""routes.clj"" 73]\n  [clojure.lang.RestFn invoke ""RestFn.java"" 439]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 153]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]\n  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]\n  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]\n  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__104947 invoke ""exceptions.clj"" 111]\n  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__104944 invoke ""exceptions.clj"" 100]\n  [metabase.server.middleware.log$log_api_call$fn__110974$fn__110975$fn__110976 invoke ""log.clj"" 233]\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 17]\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]\n  [metabase.server.middleware.log$log_api_call$fn__110974$fn__110975 invoke ""log.clj"" 224]\n  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]\n  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]\n  [metabase.server.middleware.log$log_api_call$fn__110974 invoke ""log.clj"" 223]\n  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__117653 invoke ""browser_cookie.clj"" 40]\n  [metabase.server.middleware.security$add_security_headers$fn__104903 invoke ""security.clj"" 273]\n  [ring.middleware.json$wrap_json_body$fn__117912 invoke ""json.clj"" 64]\n  [metabase.server.middleware.offset_paging$handle_paging$fn__92909 invoke ""offset_paging.clj"" 48]\n  [metabase.server.middleware.json$wrap_streamed_json_response$fn__55641 invoke ""json.clj"" 88]\n  [ring.middleware.keyword_params$wrap_keyword_params$fn__118001 invoke ""keyword_params.clj"" 55]\n  [ring.middleware.params$wrap_params$fn__118020 invoke ""params.clj"" 77]\n  [metabase.server.middleware.misc$maybe_set_site_url$fn__71662 invoke ""misc.clj"" 59]\n  [metabase.server.middleware.session$reset_session_timeout$fn__73467 invoke ""session.clj"" 565]\n  [metabase.server.middleware.session$bind_current_user$fn__73433$fn__73434 invoke ""session.clj"" 459]\n  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 438]\n  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 421]\n  [metabase.server.middleware.session$bind_current_user$fn__73433 invoke ""session.clj"" 458]\n  [metabase.server.middleware.session$wrap_current_user_info$fn__73410 invoke ""session.clj"" 383]\n  [metabase.analytics.sdk$embedding_mw$embedding_mw_fn__77611 invoke ""sdk.clj"" 51]\n  [metabase.server.middleware.session$wrap_session_id$fn__73382 invoke ""session.clj"" 261]\n  [metabase.server.middleware.auth$wrap_static_api_key$fn__102835 invoke ""auth.clj"" 32]\n  [ring.middleware.cookies$wrap_cookies$fn__117840 invoke ""cookies.clj"" 200]\n  [metabase.server.middleware.misc$add_content_type$fn__71644 invoke ""misc.clj"" 28]\n  [metabase.server.middleware.misc$disable_streaming_buffering$fn__71670 invoke ""misc.clj"" 75]\n  [ring.middleware.gzip$wrap_gzip$fn__117882 invoke ""gzip.clj"" 86]\n  [metabase.server.middleware.request_id$wrap_request_id$fn__108933 invoke ""request_id.clj"" 9]\n  [metabase.server.middleware.misc$bind_request$fn__71673 invoke ""misc.clj"" 91]\n  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__117669 invoke ""ssl.clj"" 41]\n  [metabase.server$async_proxy_handler$fn__61852 invoke ""server.clj"" 77]\n  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]\n  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]\n  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]\n  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]\n  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]\n  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]\n  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]\n  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]\n  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]\n  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]\n  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]\n  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]\n  [java.lang.Thread run nil -1]],\n :cause\n ""Unexpected close marker \'}\': expected \']\' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]"",\n :message\n ""Unexpected close marker \'}\': expected \']\' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]""}\n```', 'created_at': datetime.datetime(2024, 10, 25, 14, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438052193, 'issue_id': 2614290896, 'author': 'fer-batista', 'body': 'https://github.com/user-attachments/assets/ca8ea256-46f2-4a3a-b2c3-0ca7df04d8ec', 'created_at': datetime.datetime(2024, 10, 25, 14, 58, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438060091, 'issue_id': 2614290896, 'author': 'fer-batista', 'body': 'https://github.com/user-attachments/assets/3798a338-cb71-49c0-889d-911aec8d3ed7', 'created_at': datetime.datetime(2024, 10, 25, 15, 1, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438194236, 'issue_id': 2614290896, 'author': 'dpsutton', 'body': 'Weird. That is erroring out because there is invalid json for one of the card\'s queries.\nhttps://github.com/metabase/metabase/blob/master/src/metabase/search/impl.clj#L177\n\n```clojure\n        (update :dataset_query (fn [dataset-query]\n                                 (when-let [query (some-> dataset-query json/parse-string)] ;; <--- error is happening here\n                                   (if (get query ""type"")\n                                     (mbql.normalize/normalize query)\n                                     (not-empty (lib/normalize query))))))\n```\n\nThis should be impossible. Have you perhaps done any edits to the application database?\n\nI\'m trying to think of the easiest way to see which questions have invalid queries', 'created_at': datetime.datetime(2024, 10, 25, 15, 56, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438257745, 'issue_id': 2614290896, 'author': 'fer-batista', 'body': 'Yes, but not related to the question name/description. Can you give me a hint on what I need to look for in the database - maybe tables used in the search - to fix this?', 'created_at': datetime.datetime(2024, 10, 25, 16, 24, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438793952, 'issue_id': 2614290896, 'author': 'dpsutton', 'body': 'Sure. This is the `report_card` table. It has a text column `dataset_query` which should always be valid json. You have a row (or multiple) which match your search term which have invalid json.', 'created_at': datetime.datetime(2024, 10, 25, 20, 54, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439592336, 'issue_id': 2614290896, 'author': 'fer-batista', 'body': '@dpsutton Hey! Thank you for the hint.\nI got all the dataset_query and used BigQuery to SAFE.PARSE_JSON.\nThis returned all the queries with parsed JSON and I filtered only on error and then deleted it from the application database.\nNow the search box is working!\n\nThank you very much.\n![Image](https://github.com/user-attachments/assets/dae5739f-0c2c-4394-9cd6-cb390720cc20)', 'created_at': datetime.datetime(2024, 10, 26, 13, 57, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439693094, 'issue_id': 2614290896, 'author': 'paoliniluis', 'body': '@fer-batista can you send the wrong json so we can try to reproduce?', 'created_at': datetime.datetime(2024, 10, 26, 18, 52, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446957695, 'issue_id': 2614290896, 'author': 'dpsutton', 'body': ""I'm going to close this as it seems it arose due to you changing data in the application database. If this is not correct, we want to work on it with the highest priority. We should never have invalid json in that table. If that was our fault, please let us know. But it seems we didn't cause it so nothing left to do."", 'created_at': datetime.datetime(2024, 10, 30, 12, 22, 17, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-25 14:48:05 UTC): @fer-batista can you provide the logs that appear in the backend when this error happens?

fer-batista (Issue Creator) on (2024-10-25 14:56:32 UTC): @dpsutton 
```
{:via
 [{:type com.fasterxml.jackson.core.JsonParseException,
   :message
   ""Unexpected close marker '}': expected ']' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]"",
   :at [com.fasterxml.jackson.core.JsonParser _constructReadException ""JsonParser.java"" 2643]}],
 :trace
 [[com.fasterxml.jackson.core.JsonParser _constructReadException ""JsonParser.java"" 2643]
  [com.fasterxml.jackson.core.base.ParserBase _reportMismatchedEndMarker ""ParserBase.java"" 1386]
  [com.fasterxml.jackson.core.json.ReaderBasedJsonParser _closeScope ""ReaderBasedJsonParser.java"" 3040]
  [com.fasterxml.jackson.core.json.ReaderBasedJsonParser nextToken ""ReaderBasedJsonParser.java"" 685]
  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 66]
  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]
  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]
  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]
  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]
  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]
  [cheshire.parse$parse_STAR_ invokeStatic ""parse.clj"" 65]
  [cheshire.parse$parse_STAR_ invoke ""parse.clj"" 63]
  [cheshire.parse$parse invokeStatic ""parse.clj"" 100]
  [cheshire.parse$parse invoke ""parse.clj"" 88]
  [cheshire.core$parse_string invokeStatic ""core.clj"" 208]
  [cheshire.core$parse_string invoke ""core.clj"" 194]
  [cheshire.core$parse_string invokeStatic ""core.clj"" 204]
  [cheshire.core$parse_string invoke ""core.clj"" 194]
  [metabase.search.impl$serialize$fn__106071 invoke ""impl.clj"" 177]
  [clojure.core$update invokeStatic ""core.clj"" 6259]
  [clojure.core$update invoke ""core.clj"" 6251]
  [metabase.search.impl$serialize invokeStatic ""impl.clj"" 176]
  [metabase.search.impl$serialize invoke ""impl.clj"" 147]
  [clojure.core$map$fn__5954 invoke ""core.clj"" 2770]
  [clojure.lang.LazySeq force ""LazySeq.java"" 50]
  [clojure.lang.LazySeq realize ""LazySeq.java"" 89]
  [clojure.lang.LazySeq seq ""LazySeq.java"" 106]
  [clojure.lang.RT seq ""RT.java"" 555]
  [clojure.lang.RT countFrom ""RT.java"" 670]
  [clojure.lang.RT count ""RT.java"" 663]
  [metabase.search.impl$search_results invokeStatic ""impl.clj"" 362]
  [metabase.search.impl$search_results invoke ""impl.clj"" 344]
  [metabase.search.impl$search106127__106128 invokeStatic ""impl.clj"" 380]
  [metabase.search.impl$search106127__106128 invoke ""impl.clj"" 364]
  [metabase.api.search$fn__106357 invokeStatic ""search.clj"" 137]
  [metabase.api.search$fn__106357 invoke ""search.clj"" 94]
  [compojure.core$wrap_response$fn__53970 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__53954 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__53959 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 395]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 395]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 395]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [metabase.api.search$_PLUS_engine_cookie$fn__106303 invoke ""search.clj"" 38]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [metabase.server.middleware.auth$enforce_authentication$fn__102827 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 395]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [metabase.api.routes$fn__108227$fn__108228 invoke ""routes.clj"" 70]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 33]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__108507$fn__108508 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 439]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53963 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__54010 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982$f__53983$respond_SINGLEQUOTE___53984 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__54014 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53982$f__53983 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53982 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__104947 invoke ""exceptions.clj"" 111]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__104944 invoke ""exceptions.clj"" 100]
  [metabase.server.middleware.log$log_api_call$fn__110974$fn__110975$fn__110976 invoke ""log.clj"" 233]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 17]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__110974$fn__110975 invoke ""log.clj"" 224]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__110974 invoke ""log.clj"" 223]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__117653 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__104903 invoke ""security.clj"" 273]
  [ring.middleware.json$wrap_json_body$fn__117912 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__92909 invoke ""offset_paging.clj"" 48]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__55641 invoke ""json.clj"" 88]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__118001 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__118020 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__71662 invoke ""misc.clj"" 59]
  [metabase.server.middleware.session$reset_session_timeout$fn__73467 invoke ""session.clj"" 565]
  [metabase.server.middleware.session$bind_current_user$fn__73433$fn__73434 invoke ""session.clj"" 459]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 438]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 421]
  [metabase.server.middleware.session$bind_current_user$fn__73433 invoke ""session.clj"" 458]
  [metabase.server.middleware.session$wrap_current_user_info$fn__73410 invoke ""session.clj"" 383]
  [metabase.analytics.sdk$embedding_mw$embedding_mw_fn__77611 invoke ""sdk.clj"" 51]
  [metabase.server.middleware.session$wrap_session_id$fn__73382 invoke ""session.clj"" 261]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__102835 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__117840 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__71644 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__71670 invoke ""misc.clj"" 75]
  [ring.middleware.gzip$wrap_gzip$fn__117882 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.request_id$wrap_request_id$fn__108933 invoke ""request_id.clj"" 9]
  [metabase.server.middleware.misc$bind_request$fn__71673 invoke ""misc.clj"" 91]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__117669 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__61852 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause
 ""Unexpected close marker '}': expected ']' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]"",
 :message
 ""Unexpected close marker '}': expected ']' (for Array starting at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 676])\n at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 727]""}
```

fer-batista (Issue Creator) on (2024-10-25 14:58:14 UTC): https://github.com/user-attachments/assets/ca8ea256-46f2-4a3a-b2c3-0ca7df04d8ec

fer-batista (Issue Creator) on (2024-10-25 15:01:07 UTC): https://github.com/user-attachments/assets/3798a338-cb71-49c0-889d-911aec8d3ed7

dpsutton on (2024-10-25 15:56:39 UTC): Weird. That is erroring out because there is invalid json for one of the card's queries.
https://github.com/metabase/metabase/blob/master/src/metabase/search/impl.clj#L177

```clojure
        (update :dataset_query (fn [dataset-query]
                                 (when-let [query (some-> dataset-query json/parse-string)] ;; <--- error is happening here
                                   (if (get query ""type"")
                                     (mbql.normalize/normalize query)
                                     (not-empty (lib/normalize query))))))
```

This should be impossible. Have you perhaps done any edits to the application database?

I'm trying to think of the easiest way to see which questions have invalid queries

fer-batista (Issue Creator) on (2024-10-25 16:24:20 UTC): Yes, but not related to the question name/description. Can you give me a hint on what I need to look for in the database - maybe tables used in the search - to fix this?

dpsutton on (2024-10-25 20:54:26 UTC): Sure. This is the `report_card` table. It has a text column `dataset_query` which should always be valid json. You have a row (or multiple) which match your search term which have invalid json.

fer-batista (Issue Creator) on (2024-10-26 13:57:56 UTC): @dpsutton Hey! Thank you for the hint.
I got all the dataset_query and used BigQuery to SAFE.PARSE_JSON.
This returned all the queries with parsed JSON and I filtered only on error and then deleted it from the application database.
Now the search box is working!

Thank you very much.
![Image](https://github.com/user-attachments/assets/dae5739f-0c2c-4394-9cd6-cb390720cc20)

paoliniluis on (2024-10-26 18:52:39 UTC): @fer-batista can you send the wrong json so we can try to reproduce?

dpsutton on (2024-10-30 12:22:17 UTC): I'm going to close this as it seems it arose due to you changing data in the application database. If this is not correct, we want to work on it with the highest priority. We should never have invalid json in that table. If that was our fault, please let us know. But it seems we didn't cause it so nothing left to do.

"
2614211787,issue,closed,completed,Subscriptions - Days of week in chart don’t match visual representation within Metabase,"### Describe the bug

A subscription using a bar chart grouped by days of the week doesn't display the days in the correct order.

### To Reproduce

1. Set “First day of the week” to the default of Sunday in Admin Settings

2. Create a question like the following:
Products table, Summarized by Price, Group By Day of Week.

![Image](https://github.com/user-attachments/assets/e781aaad-acfa-4016-92aa-33696a4d31cf)

![Image](https://github.com/user-attachments/assets/2ba3c089-05bf-41e2-90c7-920fa533c4f8)


3. Set “First day of the week” to something like Wednesday and re-run the question.

![Image](https://github.com/user-attachments/assets/76d8a3c3-69b4-4a95-aa54-5783a3996714)


4. Send a subscription and notice the order and values of the chart are the same as they are in Metabase, however, days of the week are not.
![Image](https://github.com/user-attachments/assets/3b3c9bbe-4bf3-48e2-90d1-122a5245d2c5)




### Expected behavior

For the subscription to match what's in Metabase.

### Logs

No diagnostic info/file was needed in this situation due to being able to replicate the issue.

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.4-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P2 - Incorrect information sent in subscriptions

### Additional context

_No response_",FilmonK,2024-10-25 14:05:23+00:00,['tsplude'],2025-01-21 21:23:50+00:00,2025-01-15 00:23:13+00:00,https://github.com/metabase/metabase/issues/49166,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2614171175,issue,open,,Start using `plan-alias` on the frontend,"### Context
Token status includes the `plan-alias` key. See https://github.com/metabase/harbormaster/pull/4993 for details.

Frontend code in the main app is still relying on `getPlan` selector, which is our best guess to determine the current plan. We should switch to using the existing `plan-alias` instead.

```[tasklist]
- [ ] Update FE types
- [ ] Either replace `getPlan` selector or create a new `getPlanAlias` selector
```",nemanjaglumac,2024-10-25 13:50:48+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/49165,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.DX', 'Developer experience and QoL related.')]","[{'comment_id': 2466335679, 'issue_id': 2614171175, 'author': 'nemanjaglumac', 'body': 'Currently blocked by the lack of the backend schema. The backend types this only as a `string`.', 'created_at': datetime.datetime(2024, 11, 9, 17, 57, 51, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-11-09 17:57:51 UTC): Currently blocked by the lack of the backend schema. The backend types this only as a `string`.

"
2614167270,issue,closed,completed,Items in the audit collection are sometimes suggested as stale,"### Describe the bug

Original report:

>  after moving unused items to trash I'm seeing ""Sorry, you don't have permissions to see that"" screen – which is weird because I'm an instance admin. Is that a bug?


### To Reproduce

Attempt to clean up the root collection with ""include subcollections,"" making sure that an item in the audit collection has not been used since the cutoff date. When you attempt to move the discovered items to the trash, the `PUT` request to update the dashboard or card with `archived: true` will return a 403.

### Expected behavior

Do not suggest archiving items that can't actually be archived.

### Logs

_No response_

### Information about your Metabase installation

v51

### Severity

Fairly low, but this is a very annoying way to be introduced to a new feature.

### Additional context

_No response_",johnswanson,2024-10-25 13:49:09+00:00,['johnswanson'],2024-10-28 21:47:09+00:00,2024-10-28 21:01:25+00:00,https://github.com/metabase/metabase/issues/49164,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2437955283, 'issue_id': 2614167270, 'author': 'paoliniluis', 'body': 'please post the logs', 'created_at': datetime.datetime(2024, 10, 25, 14, 22, 55, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-25 14:22:55 UTC): please post the logs

"
2614165836,issue,closed,completed,Logging and observability,,perivamsi,2024-10-25 13:48:37+00:00,['johnswanson'],2024-11-13 12:44:51+00:00,2024-11-13 12:44:51+00:00,https://github.com/metabase/metabase/issues/49163,[],[],
2614151984,issue,open,,Add Metabase Accordion to the design system,"### Links
- [Slack thread 1](https://metaboat.slack.com/archives/C02H619CJ8K/p1729165005448559), [Slack thread 2](https://metaboat.slack.com/archives/C057WD5L0JG/p1728376094332229)
- [Figma](https://www.figma.com/design/svk67RHQ1oJb9T5KWO6Yeb/Accordion?node-id=2446-5226&node-type=canvas&t=SSTqpDFusM77D1tC-0)

### Description
We rely on Mantine's [Accordion component](https://v6.mantine.dev/core/accordion/) for the functionality and for some basic styling. So far we use it [in one place only](https://github.com/metabase/metabase/pull/33097), with [another usage incoming](https://github.com/metabase/metabase/pull/48898). 

All other components still rely on the old, non-mantine Accordion component(s).
The goal is to first tailor the Mantine Accordion to our liking, and then gradually replace the old components.


```[tasklist]
- [ ] Add the accordion theme overrides according to the Figma designs
- [ ] Update the existing components that already use Mantine accordion
- [ ] Add these variants to the Storybook
- [ ] Deprecate the old component(s)
```

Out of scope of this task:
- Gradually replace old custom Accordion components with the new single-source-of-truth accordion",nemanjaglumac,2024-10-25 13:43:18+00:00,['nemanjaglumac'],2025-02-04 20:23:46+00:00,,https://github.com/metabase/metabase/issues/49162,"[('.Design Needed', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.LongTerm', 'Issues we will fix in the long term, not a near term priority')]",[],
2614144088,issue,open,,Send current time with the context," (this allows time relative queries like ""orders from last week"" in the future)",perivamsi,2024-10-25 13:40:14+00:00,[],2025-02-04 20:30:53+00:00,,https://github.com/metabase/metabase/issues/49161,"[('Type:New Feature', '')]",[],
2614143563,issue,closed,completed,Pie chart is not working,"### Describe the bug

Pie chart is not working anymore. 

![Image](https://github.com/user-attachments/assets/85062608-d1e2-4d7e-8587-75cef7b15310)


### To Reproduce

1. Create a new question or SQL
2. Use pie chart visualization


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P1

### Additional context

_No response_",fer-batista,2024-10-25 13:40:04+00:00,['alxnddr'],2024-10-28 14:13:26+00:00,2024-10-28 14:13:25+00:00,https://github.com/metabase/metabase/issues/49160,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2614136615,issue,closed,completed,Document the flow through a sequence diagram,,perivamsi,2024-10-25 13:37:51+00:00,['johnswanson'],2024-11-13 12:44:41+00:00,2024-11-13 12:44:41+00:00,https://github.com/metabase/metabase/issues/49159,[],"[{'comment_id': 2447969870, 'issue_id': 2614136615, 'author': 'johnswanson', 'body': 'Where should this live?\n\n![Image](https://github.com/user-attachments/assets/cdef9e16-bbe8-4b36-ab83-e011397cf383)\n\n```\ntitle Metabot Sequence Diagram\n\nFrontend->Backend: User sends request\\n(message, context, history)\nBackend->LLM: Forward request to LLM\\n(message, tools)\n\nLLM->Backend: LLM response\\n(message or tool calls)\nnote over Backend: While tool calls are present:\nBackend->Tool: Invoke tools specified by LLM\nTool->Backend: Return tool output\\n(output string, reactions)\n\nBackend->LLM: Send tool output to LLM\n\nLLM->Backend: LLM response\\n(message or tool calls)\nnote over Backend: Loop continues until LLM\\nresponse has no tool calls\n\nBackend->Frontend: Forward response to Frontend\\n(reactions and/or message from the LLM)\n\n\nnote over Frontend:Frontend displays message and/or takes action based on reactions\n```', 'created_at': datetime.datetime(2024, 10, 30, 18, 8, 47, tzinfo=datetime.timezone.utc)}]","johnswanson (Assginee) on (2024-10-30 18:08:47 UTC): Where should this live?

![Image](https://github.com/user-attachments/assets/cdef9e16-bbe8-4b36-ab83-e011397cf383)

```
title Metabot Sequence Diagram

Frontend->Backend: User sends request\n(message, context, history)
Backend->LLM: Forward request to LLM\n(message, tools)

LLM->Backend: LLM response\n(message or tool calls)
note over Backend: While tool calls are present:
Backend->Tool: Invoke tools specified by LLM
Tool->Backend: Return tool output\n(output string, reactions)

Backend->LLM: Send tool output to LLM

LLM->Backend: LLM response\n(message or tool calls)
note over Backend: Loop continues until LLM\nresponse has no tool calls

Backend->Frontend: Forward response to Frontend\n(reactions and/or message from the LLM)


note over Frontend:Frontend displays message and/or takes action based on reactions
```

"
2614126678,issue,closed,completed,Do the roundtrip to send back tool results to the LLM for a text response,,perivamsi,2024-10-25 13:33:49+00:00,['johnswanson'],2024-10-29 21:04:45+00:00,2024-10-29 21:04:45+00:00,https://github.com/metabase/metabase/issues/49156,[],[],
2614015267,issue,closed,not_planned,Filters don't auto-populate on MongoDB on v51,"### Describe the bug

I don't know what happened but no matter what you do in the config, filters in MongoDB won't auto populate

### To Reproduce

1) start v51
2) add the sample DB
2.5) connect people and products to orders via a foreign key
3) set the source, category fields to have ""a list of all values"" and sync
4) add the orders table and then add these 2 fields as filters
5) click on the fields, see that there are no options, and api calls are not being sent as well

### Expected behavior

Should populate the filters

### Logs

_No response_

### Information about your Metabase installation

v51

### Severity

P1

### Additional context

_No response_",paoliniluis,2024-10-25 12:47:25+00:00,['bshepherdson'],2024-11-04 22:27:49+00:00,2024-10-28 17:27:34+00:00,https://github.com/metabase/metabase/issues/49151,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2442201320, 'issue_id': 2614015267, 'author': 'paoliniluis', 'body': ""can't reproduce this anymore"", 'created_at': datetime.datetime(2024, 10, 28, 17, 27, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-10-28 17:27:34 UTC): can't reproduce this anymore

"
2613973529,issue,closed,completed,"""hexString has 24 characters"" when drilling through in MongoDB","### Describe the bug

If you use the table metadata to make a link between the field in a mongo collection and the corresponding table (e.g. user_id in orders to people.id) then going to the table and clicking the ID of the user will result in 
![Image](https://github.com/user-attachments/assets/ce0a988f-fa20-47a1-ae82-e3c46aa74dec)


### To Reproduce

1) start up Metabase
2) add a MongoDB DB (sample DB)
3) go to orders and switch orders.user_id field to Foreign key -> people.id
4) go to orders table in ""browse data"", click on any user ID field and then on ""view details""

### Expected behavior

We should see the details of the user id

### Logs

```
2024-10-25 12:27:56,502 ERROR middleware.catch-exceptions :: Error processing query: state should be: hexString has 24 characters
{:database_id 3,
 :started_at #t ""2024-10-25T12:27:56.474777Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error compiling query: state should be: hexString has 24 characters"",
   :stacktrace
   [""--> query_processor.compile$compile_preprocessed75739__75740$fn__75741.invoke(compile.clj:35)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor.compile$compile_preprocessed75739__75740.invokeStatic(compile.clj:30)""
    ""query_processor.compile$compile_preprocessed75739__75740.invoke(compile.clj:26)""
    ""query_processor.compile$attach_compiled_query75751__75752.invokeStatic(compile.clj:54)""
    ""query_processor.compile$attach_compiled_query75751__75752.invoke(compile.clj:45)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
    ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
    ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:106)""
    ""driver$do_with_driver.invoke(driver.clj:101)""
    ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
    ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
    ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
    ""api.dataset$run_streaming_query99466__99469$fn__99473.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__53224.invoke(streaming_response.clj:97)""],
   :error_type :driver,
   :ex-data
   {:query
    {:database 3,
     :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
     :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x672275ab ""[B@672275ab""]},
     :constraints {:max-results 10000, :max-results-bare-rows 2000},
     :type :query,
     :query
     {:source-table 32,
      :fields
      [[:field 365 nil]
       [:field 362 nil]
       [:field 364 nil]
       [:field 357 nil]
       [:field 368 nil]
       [:field 367 nil]
       [:field 363 nil]
       [:field 358 nil]
       [:field 359 nil]
       [:field 356 nil]
       [:field 369 nil]
       [:field 361 nil]
       [:field 360 nil]
       [:field 366 nil]],
      :filter
      [:=
       [:field 365 {:base-type :type/MongoBSONID}]
       [:value
        ""3""
        {:base_type :type/MongoBSONID,
         :effective_type :type/MongoBSONID,
         :coercion_strategy nil,
         :semantic_type :type/PK,
         :database_type ""org.bson.types.ObjectId"",
         :name ""_id""}]],
      :limit 2000,
      :metabase.query-processor.middleware.limit/original-limit nil}},
    :type :driver}}],
 :action_id nil,
 :error_type :driver,
 :json_query
 {:database 3,
  :type ""query"",
  :query {:source-table 32, :filter [""="" [""field"" 365 {:base-type ""type/MongoBSONID""}] ""3""]},
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class java.lang.IllegalArgumentException,
 :stacktrace
 [""org.bson.assertions.Assertions.isTrueArgument(Assertions.java:64)""
  ""org.bson.types.ObjectId.parseHexString(ObjectId.java:420)""
  ""org.bson.types.ObjectId.<init>(ObjectId.java:205)""
  ""--> driver.mongo.query_processor$fn__123667.invokeStatic(query_processor.clj:411)""
  ""driver.mongo.query_processor$fn__123667.invoke(query_processor.clj:403)""
  ""driver.mongo.query_processor$filter_expr.invokeStatic(query_processor.clj:769)""
  ""driver.mongo.query_processor$filter_expr.invoke(query_processor.clj:767)""
  ""driver.mongo.query_processor$fn__125004.invokeStatic(query_processor.clj:786)""
  ""driver.mongo.query_processor$fn__125004.invoke(query_processor.clj:786)""
  ""driver.mongo.query_processor$handle_filter.invokeStatic(query_processor.clj:822)""
  ""driver.mongo.query_processor$handle_filter.invoke(query_processor.clj:819)""
  ""driver.mongo.query_processor$add_aggregation_pipeline$fn__126167.invoke(query_processor.clj:1350)""
  ""driver.mongo.query_processor$add_aggregation_pipeline.invokeStatic(query_processor.clj:1349)""
  ""driver.mongo.query_processor$add_aggregation_pipeline.invoke(query_processor.clj:1345)""
  ""driver.mongo.query_processor$add_aggregation_pipeline.invokeStatic(query_processor.clj:1347)""
  ""driver.mongo.query_processor$add_aggregation_pipeline.invoke(query_processor.clj:1345)""
  ""driver.mongo.query_processor$generate_aggregation_pipeline126179__126180.invokeStatic(query_processor.clj:1365)""
  ""driver.mongo.query_processor$generate_aggregation_pipeline126179__126180.invoke(query_processor.clj:1360)""
  ""driver.mongo.query_processor$simple_mbql__GT_native.invokeStatic(query_processor.clj:1386)""
  ""driver.mongo.query_processor$simple_mbql__GT_native.invoke(query_processor.clj:1383)""
  ""driver.mongo.query_processor$mbql__GT_native_rec.invokeStatic(query_processor.clj:1421)""
  ""driver.mongo.query_processor$mbql__GT_native_rec.invoke(query_processor.clj:1403)""
  ""driver.mongo.query_processor$mbql__GT_native.invokeStatic(query_processor.clj:1436)""
  ""driver.mongo.query_processor$mbql__GT_native.invoke(query_processor.clj:1427)""
  ""driver.mongo$fn__127790.invokeStatic(mongo.clj:450)""
  ""driver.mongo$fn__127790.invoke(mongo.clj:448)""
  ""query_processor.compile$compile_STAR_.invokeStatic(compile.clj:24)""
  ""query_processor.compile$compile_STAR_.invoke(compile.clj:20)""
  ""query_processor.compile$compile_preprocessed75739__75740$fn__75741.invoke(compile.clj:32)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor.compile$compile_preprocessed75739__75740.invokeStatic(compile.clj:30)""
  ""query_processor.compile$compile_preprocessed75739__75740.invoke(compile.clj:26)""
  ""query_processor.compile$attach_compiled_query75751__75752.invokeStatic(compile.clj:54)""
  ""query_processor.compile$attach_compiled_query75751__75752.invoke(compile.clj:45)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__86509$handle_audit_app_internal_queries__86510$fn__86511.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__74641.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware77788__77789$fn__77790.invoke(process_userland_query.clj:204)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions77853__77854$fn__77855.invoke(catch_exceptions.clj:132)""
  ""query_processor$process_query77894__77895$fn__77896.invoke(query_processor.clj:80)""
  ""query_processor.setup$do_with_canceled_chan75123__75124$fn__75125.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings75116__75117$fn__75118.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111$fn__75112.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:106)""
  ""driver$do_with_driver.invoke(driver.clj:101)""
  ""query_processor.setup$do_with_driver75109__75110$fn__75111.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102$fn__75105.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider58718__58719.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider75100__75101$fn__75102.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database75090__75091$fn__75092.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup75128__75129.invoke(setup.clj:216)""
  ""query_processor$process_query77894__77895.invokeStatic(query_processor.clj:78)""
  ""query_processor$process_query77894__77895.invoke(query_processor.clj:71)""
  ""api.dataset$run_streaming_query99466__99469$fn__99473.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504$fn__61505.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__61503$fn__61504.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__61503.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__53224.invoke(streaming_response.clj:97)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""state should be: hexString has 24 characters"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 3,
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
  :info {:executed-by 1, :context :ad-hoc},
  :constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :query
  {:source-table 32,
   :fields
   [[:field 365 nil]
    [:field 362 nil]
    [:field 364 nil]
    [:field 357 nil]
    [:field 368 nil]
    [:field 367 nil]
    [:field 363 nil]
    [:field 358 nil]
    [:field 359 nil]
    [:field 356 nil]
    [:field 369 nil]
    [:field 361 nil]
    [:field 360 nil]
    [:field 366 nil]],
   :filter
   [:=
    [:field 365 {:base-type :type/MongoBSONID}]
    [:value
     ""3""
     {:base_type :type/MongoBSONID,
      :effective_type :type/MongoBSONID,
      :coercion_strategy nil,
      :semantic_type :type/PK,
      :database_type ""org.bson.types.ObjectId"",
      :name ""_id""}]],
   :limit 2000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

- tested on v51, but I would guess this comes from before
EDIT: works in 49

### Severity

P2

### Additional context

_No response_",paoliniluis,2024-10-25 12:28:40+00:00,['lbrdnk'],2024-10-30 01:36:00+00:00,2024-10-30 01:36:00+00:00,https://github.com/metabase/metabase/issues/49149,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2613934798,issue,closed,completed,Redshift - CSV Upload - Value too long for type character varying(256),"### Describe the bug

When attempting to do CSV uploads against Redshift, you’ll encounter the following error.
I’ve attached a sample CSV.


```
Batch entry 0 INSERT INTO ""public"".""rs_uploadscustomer_csv_sample_20241025041936"" (""id"", ""text"") VALUES (TRUE, ('The sky was a deep, brilliant blue, with only a few wisps of white clouds drifting lazily across. Birds chirped in the distance, and the gentle rustle of leaves accompanied the soft breeze that stirred the air. The world seemed at peace, basking in the warmth of the late afternoon sun. As I walked along the path, the crunch of gravel beneath my feet was a soothing rhythm, each step taking me further into the quiet beauty of nature. The vibrant colors of the flowers lining the trail stood out vividly against the greenery, creating a breathtaking tapestry of life.')) was aborted: ERROR: Value too long for character type
  Detail: 
  -----------------------------------------------
  error:  Value too long for character type
  code:      8001
  context:   Value too long for type character varying(256)
  query:     3390[child_sequence:1]
  location:  string.cpp:219
  process:   padbmaster [pid=1073897705]
  -----------------------------------------------
  Call getNextException to see other errors in the batch.
```


<br>
<br>

It works in postgres just fine due to there being an association of the column with TEXT data type allowing significantly longer character lengths.

Not sure if it’s related to a cap we’re implementing, or Redshift automatically inferring a 256 character limit from TEXT due to not specifying something like VARCHAR(n).
https://docs.aws.amazon.com/redshift/latest/dg/r_Character_types.html


### To Reproduce

Take a CSV like the one I've attached and try to do a CSV upload against a Redshift schema.

[customer_csv_sample.csv](https://github.com/user-attachments/files/17521784/customer_csv_sample.csv)

<br>
<br>


![Image](https://github.com/user-attachments/assets/dac33514-18f1-453a-ad96-1ec16e47dab5)



### Expected behavior

For the import to work as it does in something like postgres.

### Logs

No diagnostic info/file was needed in this situation due to being able to replicate the issue.

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.4-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P2 - Affects all Redshift users

### Additional context

_No response_",FilmonK,2024-10-25 12:11:09+00:00,['crisptrutski'],2024-11-07 21:34:28+00:00,2024-11-07 20:49:19+00:00,https://github.com/metabase/metabase/issues/49147,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Redshift', None), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2613315098,issue,closed,completed,"Static embed flow opens a new tab to enable static embed, but the toggle state aren't synced between tabs","### Describe the bug

in V51 after setting up a new instance, and wanting to share a dashboard, I open the embed menu and click on the embed option. This opens a new tab which I can toggle the static embed setting, but after closing the tab and going back to the tab when I was about to embed a dashboard, the embed option still says that the embedding is still off.

### To Reproduce

1. Create a new dashboard
2. Click on the sharing button
3. Click on the embedding button
4. This opens a new tab then turn on static embedding
5. close the settings page tab
6. Now we're on the tab with a dashboard
7. Clik on the sharing button
8. The embedding option is still saying that the embedding is off.


### Expected behavior

I can embed my dashboard right away after turning on static embedding.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-24"",
      ""src_hash"": ""b35fbf2cf2dab51bfa1067a0ad66527b2b881146"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""b7e1ef6""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""15.0.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}

### Severity

p2, this is confusing, but I might try refreshing the page at some point which would fix the issue.

### Additional context

- The embedding option in the sharing menu doesn't specify which embed option is off. Since I would be directed to the embedding settings page which shows 3 embedding toggles I would be confused about which one I need to enable, I'd expect the copy to be `Static embedding is off` instead.
    ![Image](https://github.com/user-attachments/assets/a428f3e3-b81c-4770-8444-a26dfcdfeb7f)
- The above option is unclickable on 50.
- ""Compare options"" opens in the same tab, despite other links like interactive and SDK embedding open in a new tab.
    ![Image](https://github.com/user-attachments/assets/9b2b34b5-1949-4eb7-a766-2cdb33746c1d)
",WiNloSt,2024-10-25 07:26:54+00:00,[],2025-01-08 14:49:30+00:00,2025-01-08 14:49:30+00:00,https://github.com/metabase/metabase/issues/49143,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2577858410, 'issue_id': 2613315098, 'author': 'WiNloSt', 'body': 'Fixed by https://github.com/metabase/metabase/issues/50503 in v52', 'created_at': datetime.datetime(2025, 1, 8, 14, 49, 8, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2025-01-08 14:49:08 UTC): Fixed by https://github.com/metabase/metabase/issues/50503 in v52

"
2613267900,issue,closed,completed,Dashboard static embed preview doesn't work out of the box,"### Describe the bug

After setting up a new Metabase instance, enabling static embedding, and trying to embed a dashboard. I won't be able to see the dashboard preview unless I add my Metabase instance host to ""Allowed domains for iframes in dashboards"" settings under `/admin/settings/general`

![Image](https://github.com/user-attachments/assets/96625bf0-0533-4a32-bbd9-9379012fda69)
![Image](https://github.com/user-attachments/assets/05e8052f-a59f-42f4-88e4-3ab11dd62315)


### To Reproduce

1. Set up a new Metabase instance 
2. Enable static embedding
3. Create a dashboard
4. Embed > Static embedding
5. Click on 'Parameters' tab
6. Toggle from 'Code' to 'Preview'
8. See that the static embed iframe doesn't render

### Expected behavior

The static embed dashboard iframe renders.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.4-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

blocking since I don't know what's wrong with my setup

### Additional context

This doesn't happen with v50 since that setting is new in v51",WiNloSt,2024-10-25 07:00:11+00:00,['alxnddr'],2024-10-25 17:36:09+00:00,2024-10-25 16:17:30+00:00,https://github.com/metabase/metabase/issues/49142,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2612283755,issue,open,,Have the ability to smartly configure Field Filters automatically,"**Is your feature request related to a problem? Please describe.**
A user might have a question that uses a lot of field filters, that all come from the same table, and that requires many clicks to hook up the filters to the right fields in the right table - specially if there are many schemas. It can also be tedious to go find the right type of field

![Image](https://github.com/user-attachments/assets/35af0249-9dd6-4196-884b-0295e23118c1)


**Describe the solution you'd like**
Some sort button that let's the user automatically create field filters based on one already made, or based on a list of options

**Describe alternatives you've considered**
Doing manually

**How important is this feature to you?**
Requested by a customer, internal ticket: https://metabase.zendesk.com/agent/tickets/31424

**Additional context**
In the customer's words: ""Working off of a copy of a question that already has the variables set up saves a bunch of time, so that works really well while developing/building out dashboards. I have just had issues in the past where either I need to update variables (the source has changed etc) or multiple variables have needed to be added to many questions in 1 or multiple dashboards as features come out and it takes a long time to do.""
",ignacio-mb,2024-10-24 18:22:14+00:00,[],2025-02-04 20:30:50+00:00,,https://github.com/metabase/metabase/issues/49123,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor')]",[],
2612211233,issue,closed,completed,Unknown parameter when name label has accentuation - embedded data download,"### Describe the bug

Error on download data when the parameter label has accentuation.
Tested on static embedding.

[dbe7ab84-dd27-4f58-83a2-c7201c342f63] 2024-10-24T14:26:09-03:00 DEBUG metabase.server.middleware.log GET /api/embed/dashboard/eyJhbGciOiJIUxxxxxxxxxxx/dashcard/2570/card/2337/xlsx 400 6,9 ms (2 chamadas ao banco de dados) {:metabase-user-id 446} 
""Unknown parameter :nome_do_usuário.""

![Image](https://github.com/user-attachments/assets/e1db1d06-7017-48a6-825a-28bffcededf7)


### To Reproduce

1. Create a question
2. Create a dashboard
3. Insert a filter and name it using accentuation like ""usuários""
4. Embedded it
5. Try to download the data


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-10-23"",
      ""tag"": ""v1.51.1"",
      ""hash"": ""b8178a8""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P1

### Additional context

_No response_",fer-batista,2024-10-24 17:40:16+00:00,['WiNloSt'],2024-10-28 07:16:10+00:00,2024-10-25 16:27:20+00:00,https://github.com/metabase/metabase/issues/49118,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2436987308, 'issue_id': 2612211233, 'author': 'WiNloSt', 'body': 'Tested with v1.51.1 and v1.50.31.2. It only happened on v51.', 'created_at': datetime.datetime(2024, 10, 25, 6, 31, 10, tzinfo=datetime.timezone.utc)}]","WiNloSt (Assginee) on (2024-10-25 06:31:10 UTC): Tested with v1.51.1 and v1.50.31.2. It only happened on v51.

"
2612145786,issue,open,,Granular permissions for Metrics,"**Is your feature request related to a problem? Please describe.**
A metric is a very important concept in data analytics (same as a model), so we should have a permission about who should create metrics in the product

**Describe the solution you'd like**
A new table permission that sets who can create metrics for that table

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer who also requests that we should have https://github.com/metabase/metabase/issues/25335 and mostly sure https://github.com/metabase/metabase/issues/22423

**Additional context**
NA
",paoliniluis,2024-10-24 17:09:09+00:00,[],2025-02-04 20:30:52+00:00,,https://github.com/metabase/metabase/issues/49116,"[('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Querying/Metrics', 'v2'), ('Semantic Model', '')]",[],
2611937060,issue,closed,completed,Migrate existing click behavior to always include explicit target stage-number,Similar to #48734 but for click behavior in viz settings.,kamilmielnik,2024-10-24 15:27:36+00:00,['metamben'],2024-11-22 10:55:49+00:00,2024-11-22 10:55:47+00:00,https://github.com/metabase/metabase/issues/49110,"[('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2465510755, 'issue_id': 2611937060, 'author': 'metamben', 'body': '@kamilmielnik Where should these references show up?\n\nLooking at the code, I\'m assuming a path like `[""visualization_settings"" ""click_behavior"" ""parameterMapping"" [""target"" ""dimension""]]`, where `parameterMapping` contains a map from IDs to records with `target` fields.', 'created_at': datetime.datetime(2024, 11, 8, 18, 39, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470111629, 'issue_id': 2611937060, 'author': 'kamilmielnik', 'body': '> Looking at the code, I\'m assuming a path like `[""visualization_settings"" ""click_behavior"" ""parameterMapping"" [""target"" ""dimension""]]`, where `parameterMapping` contains a map from IDs to records with `target` fields.\n\n@metamben precisely. You can also run the app, create a new custom click behavior as a user would, and then inspect the network payload.', 'created_at': datetime.datetime(2024, 11, 12, 10, 7, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470691043, 'issue_id': 2611937060, 'author': 'metamben', 'body': 'I was wrong, I missed `column_settings`.\n\nSo the path should be like `[""visualization_settings"" ""column_settings"" [""click_behavior"" ""parameterMapping"" [""target"" ""dimension""]]]`, where `column_settings` is a map from column ref strings to column setting records containing `click_behavior`s, and  `parameterMapping` contains a map from IDs to records with `target` fields.', 'created_at': datetime.datetime(2024, 11, 12, 14, 30, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493476590, 'issue_id': 2611937060, 'author': 'kamilmielnik', 'body': ""Closed by #49911.\n\n@metamben please don't forget to close your issues ([1](https://github.com/metabase/metabase/issues/47304#issuecomment-2324196030), [2](https://github.com/metabase/metabase/issues/48441#issuecomment-2437481888), [3](https://github.com/metabase/metabase/issues/48884#issuecomment-2437482627), [4](https://github.com/metabase/metabase/issues/48734#issuecomment-2443425921), [5](https://github.com/metabase/metabase/issues/48613#issuecomment-2488602355)).\nGitHub won't automatically close them if a PR is not targeted against `master`."", 'created_at': datetime.datetime(2024, 11, 22, 10, 55, 48, tzinfo=datetime.timezone.utc)}]","metamben (Assginee) on (2024-11-08 18:39:05 UTC): @kamilmielnik Where should these references show up?

Looking at the code, I'm assuming a path like `[""visualization_settings"" ""click_behavior"" ""parameterMapping"" [""target"" ""dimension""]]`, where `parameterMapping` contains a map from IDs to records with `target` fields.

kamilmielnik (Issue Creator) on (2024-11-12 10:07:48 UTC): @metamben precisely. You can also run the app, create a new custom click behavior as a user would, and then inspect the network payload.

metamben (Assginee) on (2024-11-12 14:30:41 UTC): I was wrong, I missed `column_settings`.

So the path should be like `[""visualization_settings"" ""column_settings"" [""click_behavior"" ""parameterMapping"" [""target"" ""dimension""]]]`, where `column_settings` is a map from column ref strings to column setting records containing `click_behavior`s, and  `parameterMapping` contains a map from IDs to records with `target` fields.

kamilmielnik (Issue Creator) on (2024-11-22 10:55:48 UTC): Closed by #49911.

@metamben please don't forget to close your issues ([1](https://github.com/metabase/metabase/issues/47304#issuecomment-2324196030), [2](https://github.com/metabase/metabase/issues/48441#issuecomment-2437481888), [3](https://github.com/metabase/metabase/issues/48884#issuecomment-2437482627), [4](https://github.com/metabase/metabase/issues/48734#issuecomment-2443425921), [5](https://github.com/metabase/metabase/issues/48613#issuecomment-2488602355)).
GitHub won't automatically close them if a PR is not targeted against `master`.

"
