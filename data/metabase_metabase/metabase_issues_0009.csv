id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2316028456,issue,open,,Push down optimizations in the query at the subquery level,"**Is your feature request related to a problem? Please describe.**
The way we do nested questions keeps the fields of the subqueries static, but on columnar databases we should be only picking the columns we're using in the top level query

**Describe the solution you'd like**
If we're using columnar DB's, instead of
```
SELECT
  ""source"".""id"" AS ""id"",
  ""source"".""rating"" AS ""rating"",
  ""source"".""rating_mapped"" AS ""rating_mapped"",
  ""source"".""body"" AS ""body""
FROM
  (
    SELECT
      ""public"".""feedback"".""id"" AS ""id"",
      ""public"".""feedback"".""account_id"" AS ""account_id"",
      ""public"".""feedback"".""email"" AS ""email"",
      ""public"".""feedback"".""date_received"" AS ""date_received"",
      ""public"".""feedback"".""rating"" AS ""rating"",
      ""public"".""feedback"".""rating_mapped"" AS ""rating_mapped"",
      ""public"".""feedback"".""body"" AS ""body""
    FROM
      ""public"".""feedback""
  ) AS ""source""
LIMIT
  1048575
```

the query should be
```
SELECT
  ""source"".""id"" AS ""id"",
  ""source"".""rating"" AS ""rating"",
  ""source"".""rating_mapped"" AS ""rating_mapped"",
  ""source"".""body"" AS ""body""
FROM
  (
    SELECT
      ""public"".""feedback"".""id"" AS ""id"",
      ""public"".""feedback"".""rating"" AS ""rating"",
      ""public"".""feedback"".""rating_mapped"" AS ""rating_mapped"",
      ""public"".""feedback"".""body"" AS ""body""
    FROM
      ""public"".""feedback""
  ) AS ""source""
LIMIT
  1048575
```

**Describe alternatives you've considered**
None

**How important is this feature to you?**
NA

**Additional context**
NA
",paoliniluis,2024-05-24 18:38:24+00:00,[],2024-05-24 18:38:25+00:00,,https://github.com/metabase/metabase/issues/43137,"[('.Performance', ''), ('Type:New Feature', ''), ('Querying/Nested Queries', 'Questions based on other saved questions')]",[],
2315914198,issue,closed,completed,[FE] The Delete permanently button on Trash multi-select toast has a low contrast,"### Describe the bug

[FE] On Trash page, when you select multiple items, a toast shows up. On the toast the Delete permanently button was discovered as having a low contrast, making it hard to read.
Design updated in [Figma](https://www.figma.com/design/HRopvhNDlPOsBUQR8UMuOh/Make-Archive-actually-usable?node-id=226-9339&t=LeI6RPvNxJDL4iGX-1).

### To Reproduce

1. Go to v50 RC, 'Trash'
2. Select multiple items. A toast should show up.
3. See ""Delete permanently"" button with red text on a dary background button. This button contrast ratio is too low to read.


### Expected behavior

Design updated in [Figma](https://www.figma.com/design/HRopvhNDlPOsBUQR8UMuOh/Make-Archive-actually-usable?node-id=226-9339&t=LeI6RPvNxJDL4iGX-1).

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50 rc
```


### Severity

High

### Additional context

_No response_",dhuniverse,2024-05-24 17:43:41+00:00,['sloansparger'],2024-10-08 17:09:28+00:00,2024-06-03 18:19:33+00:00,https://github.com/metabase/metabase/issues/43136,"[('Type:Bug', 'Product defects'), ('Type:UX', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2315864146,issue,closed,completed,[FE] UI for enabling SCIM and displaying the API key,"[figma](https://www.figma.com/design/E42ezp6P3kY4PJj0r5tIOM/Support-SCIM-for-user-provisioning-and-deprovisioning?node-id=2095-1152)

Branch: `nm-scim-be`

The relevant bits are:
- `scim-enabled` and `scim-base-url` settings
- `GET /api/ee/scim/api_key` for fetching an existing (masked) SCIM API key
- `POST /api/ee/scim/api_key` for creating or recreating the key",dpsutton,2024-05-24 17:11:48+00:00,['sloansparger'],2024-07-19 22:37:46+00:00,2024-07-19 22:37:46+00:00,https://github.com/metabase/metabase/issues/43132,"[('.Frontend', '')]",[],
2315859167,issue,closed,completed,Remove :metadata/legacy-metric,,snoe,2024-05-24 17:08:28+00:00,[],2024-10-08 17:10:34+00:00,2024-05-27 18:04:15+00:00,https://github.com/metabase/metabase/issues/43131,[],[],
2315833861,issue,closed,completed,BE flake: metabase.pulse-test/multiple-recipients-test,"example failure [here](https://github.com/metabase/metabase/actions/runs/9179973284/job/25243349924#step:6:1180)

logs:

```
FAIL in metabase.pulse-test/multiple-recipients-test (pulse_test.clj:397)
Pulse should be sent to two recipients sent to :email channel 
with temporary :model/Card with attributes
{:creator_id 1,
 :database_id 1,
 :dataset_query
 {:database 1,
  :type :query,
  :query {:source-table 8, :aggregation [[""count""]], :breakout [[:field 49 {:temporal-unit :day}]]}},
 :display :line,
 :name ""Test card"",
 :visualization_settings {:graph.dimensions [""DATE""], :graph.metrics [""count""]},
 :created_at #t ""2024-05-21T19:11:19.102324Z[UTC]"",
 :updated_at #t ""2024-05-21T19:11:19.102325Z[UTC]""}

 
with temporary :model/Pulse with attributes
{:creator_id 1,
 :name ""Pulse Name"",
 :created_at #t ""2024-05-21T19:11:19.122568Z[UTC]"",
 :updated_at #t ""2024-05-21T19:11:19.122569Z[UTC]""}

 
with temporary :model/PulseCard with attributes
{:position 0, :include_csv false, :include_xls false, :pulse_id 267, :card_id 1800}

 
with temporary :model/PulseChannel with attributes
{:channel_type :email,
 :details {},
 :schedule_type :daily,
 :schedule_hour 15,
 :created_at #t ""2024-05-21T19:11:19.127194Z[UTC]"",
 :updated_at #t ""2024-05-21T19:11:19.127195Z[UTC]"",
 :pulse_id 267}

 
with temporary :model/PulseChannelRecipient with attributes
{:user_id 1, :pulse_channel_id 167}

 
Setting :email-smtp-host = ""fake_smtp_host""
 
Setting :email-smtp-port = 587
 
Setting :site-url = ""https://metabase.com/testmb""
 
with temporary :model/PulseChannelRecipient with attributes
{:user_id 3, :pulse_channel_id 167}


expected: {""crowberto@metabase.com"" [{:bcc #{""crowberto@metabase.com""
                                             ""rasta@metabase.com""},
                                      :body [{""Pulse Name"" true}
                                             {:content #<Class@1a6c5a9e java.net.URL>,
                                              :content-id true,
                                              :content-type ""image/png"",
                                              :type :inline}
                                             {:content #<Class@1a6c5a9e java.net.URL>,
                                              :content-id true,
                                              :content-type ""image/png"",
                                              :type :inline}],
                                      :from ""notifications@metabase.com"",
                                      :subject ""Pulse: Pulse Name""}],
           ""rasta@metabase.com"" [{:bcc #{""crowberto@metabase.com""
                                         ""rasta@metabase.com""},
                                  :body [{""Pulse Name"" true}
                                         {:content #<Class@1a6c5a9e java.net.URL>,
                                          :content-id true,
                                          :content-type ""image/png"",
                                          :type :inline}
                                         {:content #<Class@1a6c5a9e java.net.URL>,
                                          :content-id true,
                                          :content-type ""image/png"",
                                          :type :inline}],
                                  :from ""notifications@metabase.com"",
                                  :subject ""Pulse: Pulse Name""}]}
  actual: {}
```

The test fails because there is no matching email in the inbox.

The first flake happened on May 17. It has flaked at least 6 times since then (writing this on 24 May). [Source here](https://stats.metabase.com/question#eyJuYW1lIjoiVGVzdCBmbGFrZXMgYnkgc3VpdGUgbmFtZSBhbmQgdGVzdCBuYW1lIChub3QgUVApIiwiZGVzY3JpcHRpb24iOiJodHRwczovL3N0YXRzLm1ldGFiYXNlLmNvbS9tb2RlbC8xNDgyOC10ZXN0LWZsYWtpbmVzcyIsImRhdGFzZXRfcXVlcnkiOnsiZGF0YWJhc2UiOjI2LCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJhZ2dyZWdhdGlvbiI6W1siY291bnQiXSxbIm1pbiIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl91cmwiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dXV0sImJyZWFrb3V0IjpbWyJmaWVsZCIsInN1aXRlX25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dLFsiZmllbGQiLCJ0ZXN0X25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dLFsiZmllbGQiLCJ3b3JrZmxvd19ydW5fc3RhcnRlZF9hdCIseyJiYXNlLXR5cGUiOiJ0eXBlL0RhdGVUaW1lV2l0aExvY2FsVFoiLCJ0ZW1wb3JhbC11bml0IjoiZGF5In1dXSwic291cmNlLXRhYmxlIjoiY2FyZF9fMTQ4MjgiLCJmaWx0ZXIiOlsiYW5kIixbImRvZXMtbm90LWNvbnRhaW4iLFsiZmllbGQiLCJzdWl0ZV9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSwicXVlcnktcHJvY2Vzc29yIix7ImNhc2Utc2Vuc2l0aXZlIjpmYWxzZX1dLFsiY29udGFpbnMiLFsiZmllbGQiLCJ3b3JrZmxvd19qb2JfbmFtZSIseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV0sImJlLXRlc3RzLSIseyJjYXNlLXNlbnNpdGl2ZSI6ZmFsc2V9XSxbIj0iLFsiZmllbGQiLCJ0ZXN0X25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dLCJtdWx0aXBsZS1yZWNpcGllbnRzLXRlc3QiXV19fSwiZGlzcGxheSI6InRhYmxlIiwiZGlzcGxheUlzTG9ja2VkIjp0cnVlLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6eyJ0YWJsZS5waXZvdF9jb2x1bW4iOiJzdWl0ZV9uYW1lIiwidGFibGUuY2VsbF9jb2x1bW4iOiJjb3VudCIsInRhYmxlLnBpdm90IjpmYWxzZSwidGFibGUuY29sdW1ucyI6W3sibmFtZSI6InN1aXRlX25hbWUiLCJrZXkiOiJbXCJuYW1lXCIsXCJzdWl0ZV9uYW1lXCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiZmllbGQiLCJzdWl0ZV9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XX0seyJuYW1lIjoidGVzdF9uYW1lIiwia2V5IjoiW1wibmFtZVwiLFwidGVzdF9uYW1lXCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiZmllbGQiLCJ0ZXN0X25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dfSx7Im5hbWUiOiJjb3VudCIsImtleSI6IltcIm5hbWVcIixcImNvdW50XCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiYWdncmVnYXRpb24iLDBdfSx7Im5hbWUiOiJ3b3JrZmxvd19ydW5fc3RhcnRlZF9hdCIsImtleSI6IltcIm5hbWVcIixcIndvcmtmbG93X3J1bl9zdGFydGVkX2F0XCJdIiwiZmllbGRSZWYiOlsiZmllbGQiLCJ3b3JrZmxvd19ydW5fc3RhcnRlZF9hdCIseyJiYXNlLXR5cGUiOiJ0eXBlL0RhdGVUaW1lV2l0aExvY2FsVFoiLCJ0ZW1wb3JhbC11bml0IjoiZGF5In1dLCJlbmFibGVkIjp0cnVlfSx7Im5hbWUiOiJtaW4iLCJrZXkiOiJbXCJuYW1lXCIsXCJtaW5cIl0iLCJmaWVsZFJlZiI6WyJhZ2dyZWdhdGlvbiIsMV0sImVuYWJsZWQiOnRydWV9XSwiY29sdW1uX3NldHRpbmdzIjp7IltcIm5hbWVcIixcImNvdW50XCJdIjp7ImNvbHVtbl90aXRsZSI6IkNvdW50In0sIltcIm5hbWVcIixcIm1heFwiXSI6eyJjb2x1bW5fdGl0bGUiOiJMYXN0IGZhaWxlZCBydW4ifSwiW1wibmFtZVwiLFwibWF4XzJcIl0iOnsiY29sdW1uX3RpdGxlIjoiTGFzdCBmYWlsZWQgZGF0ZSIsImRhdGVfc3R5bGUiOiJNTU1NIEQsIFlZWVkiLCJ0aW1lX2VuYWJsZWQiOm51bGx9fX0sIm9yaWdpbmFsX2NhcmRfaWQiOjE1MjEyfQ==). It's interesting that the failures appear clustered on certain days, and not evenly distributed.

@Ngoc because this might have something to do with the pulse changes you merged to master on May 7

This flake is very similar and likely related: https://github.com/metabase/metabase/issues/43321",calherries,2024-05-24 16:50:58+00:00,['qnkhuat'],2024-06-21 03:28:55+00:00,2024-06-21 03:28:54+00:00,https://github.com/metabase/metabase/issues/43130,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2138622416, 'issue_id': 2315833861, 'author': 'qnkhuat', 'body': ""Tried to reproduce this today without any luck so far.\r\n\r\nI don't think it relates to the recent change I made with pulse because those changes are purely about how pulses are scheduled. These tests are about pulse behavior.\r\n\r\nIt's interesting that both flaky tests are related to email tho."", 'created_at': datetime.datetime(2024, 5, 30, 3, 48, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181934117, 'issue_id': 2315833861, 'author': 'qnkhuat', 'body': 'Fixed by reworking how test setup works in https://github.com/metabase/metabase/pull/43924', 'created_at': datetime.datetime(2024, 6, 21, 3, 28, 54, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-05-30 03:48:05 UTC): Tried to reproduce this today without any luck so far.

I don't think it relates to the recent change I made with pulse because those changes are purely about how pulses are scheduled. These tests are about pulse behavior.

It's interesting that both flaky tests are related to email tho.

qnkhuat (Assginee) on (2024-06-21 03:28:54 UTC): Fixed by reworking how test setup works in https://github.com/metabase/metabase/pull/43924

"
2315771005,issue,closed,not_planned,Pivot table dissapears when going to the notebook editor and return to the viz,"### Describe the bug

The FE will clean the rendering when going to the notebook editor and return to the viz

### To Reproduce

1) make a question like
![image](https://github.com/metabase/metabase/assets/1711649/ae98ebb4-f626-46af-bcaf-824791fdbd59)

2) use a pivot table to visualize it
3) then go to the notebook editor again
4) then click again on the same place to go back to the viz

the table is empty

### Expected behavior

It should show you the viz

### Logs

NA

### Information about your Metabase installation

```JSON
v50
brave
```


### Severity

P2

### Additional context

![Peek 2024-05-24 13-13](https://github.com/metabase/metabase/assets/1711649/da557b36-d1c7-41a6-bcaf-47d0855fd3e8)
",paoliniluis,2024-05-24 16:15:38+00:00,[],2024-07-03 13:32:57+00:00,2024-07-03 13:32:50+00:00,https://github.com/metabase/metabase/issues/43129,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2206090186, 'issue_id': 2315771005, 'author': 'nemanjaglumac', 'body': 'Duplicate of #39504', 'created_at': datetime.datetime(2024, 7, 3, 13, 32, 50, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-03 13:32:50 UTC): Duplicate of #39504

"
2315610434,issue,open,,"""You cannot save this Question because you do not have permissions to run its query"" in api/card.clj not translated","### Describe the bug

This line will always be in the base language, no matter the language you pick

### To Reproduce

I'm not able to repro the issue fully, but a customer is hitting this issue

### Expected behavior

Metabase should be translating that line as well

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-05-24 14:56:25+00:00,[],2025-02-04 20:25:02+00:00,,https://github.com/metabase/metabase/issues/43124,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/i18n', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2315556293,issue,closed,completed,"[Cache] Only show ""Adaptive"" and ""Don't cache"" options on OSS page",Discussion: https://metaboat.slack.com/archives/C06KX7QECN4/p1716511149510839,rafpaf,2024-05-24 14:32:20+00:00,['rafpaf'],2024-05-24 17:44:05+00:00,2024-05-24 17:44:04+00:00,https://github.com/metabase/metabase/issues/43121,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2315473680,issue,open,,Source field checkboxes don't work on models on GUI questions,"### Describe the bug

Selectors don't work when selecting fields from a model, although the SQL is updated (so the API call works)

### To Reproduce

1) create a question (orders join people)
2) save it, now turn it into a model
3) in the model field selector, deselect everything and start selecting and deselecting fields, see that the fields in one table will work, while the ones in the joined table won't

### Expected behavior

I should see fields getting selected

### Logs

NA

### Information about your Metabase installation

```JSON
v50-RC1
brave
```


### Severity

P3

### Additional context

![Peek 2024-05-24 10-52](https://github.com/metabase/metabase/assets/1711649/811713e4-8547-46a5-9a39-bedf31282565)
",paoliniluis,2024-05-24 13:52:58+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/43120,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]",[],
2315362022,issue,closed,completed,Make plus button less prominent,"We've implemented a [new right sidebar with column actions](https://github.com/metabase/metabase/issues/42150) like extract and combine to open which you have to click on the floating plus button. This button was designed as blue but it's [too prominent](https://metaboat.slack.com/archives/C01LQQ2UW03/p1716489446763749).
We decided to update styles a bit: https://www.figma.com/design/Rh7vrNTZX4TPAGC1fDtS55/Extract-and-combine---QB-expressivity-and-column-actions?node-id=2671-3025&t=5AVtVDnjcTXiLRAS-4",mngr,2024-05-24 13:01:53+00:00,[],2024-05-29 09:02:55+00:00,2024-05-29 09:02:55+00:00,https://github.com/metabase/metabase/issues/43118,"[('.Designs', ''), ('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2133524014, 'issue_id': 2315362022, 'author': 'crisptrutski', 'body': '@mngr does this need to go out in RC2, and if so can you provide an ETA?', 'created_at': datetime.datetime(2024, 5, 27, 13, 47, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133844387, 'issue_id': 2315362022, 'author': 'mngr', 'body': 'We can postpone this to RC3 if it happens', 'created_at': datetime.datetime(2024, 5, 27, 17, 8, 48, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-05-27 13:47:35 UTC): @mngr does this need to go out in RC2, and if so can you provide an ETA?

mngr (Issue Creator) on (2024-05-27 17:08:48 UTC): We can postpone this to RC3 if it happens

"
2315360195,issue,open,,Try connecting with fixed and dynamic ports always,"**Is your feature request related to a problem? Please describe.**
Users don't know if they connect via static or dynamic ports to their SQL server, so it would be nice if we try first with the port that the user entered (if any) and then with dynamic ports. The opposite is also fine, let's try with dynamic ports and if it doesn't connect we try with the default static port

**Describe the solution you'd like**
Try always connecting to SQL server with both connection types

**Describe alternatives you've considered**
None

**How important is this feature to you?**
It might save a few tickets when it comes about connecting to SQL server

**Additional context**
NA
",paoliniluis,2024-05-24 13:01:22+00:00,[],2024-05-24 13:23:40+00:00,,https://github.com/metabase/metabase/issues/43117,"[('Database/SQLServer', None), ('Type:New Feature', ''), ('.Backend', '')]",[],
2315334471,issue,closed,completed,Update Copy and Flow for Cloud Migration,"Cloud Migration V3.
Figma file: [link](https://www.figma.com/design/gDjo1m8C8aEHFtBNvhjp1p/Cloud-Migration?node-id=295-3089&t=qpFqmltQ1Y86z0Cr-4)


",npfitz,2024-05-24 12:49:40+00:00,['npfitz'],2024-05-29 23:26:04+00:00,2024-05-29 23:26:03+00:00,https://github.com/metabase/metabase/issues/43116,"[('.Design Needed', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2315326207,issue,open,,Allow users to recover archived subscriptions,"**Is your feature request related to a problem? Please describe.**
When a subscription is deleted, there's no way to recover it unless you edit the app db manually and set is_archived to false

**Describe the solution you'd like**
A way to recover the subscriptions from the UI

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-05-24 12:45:27+00:00,[],2024-05-24 12:45:27+00:00,,https://github.com/metabase/metabase/issues/43115,"[('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', '')]",[],
2315024101,issue,open,,Updating the query definition of a model may reset the metadata of custom columns,"### Describe the bug

Metadata set for the custom column may disappear after editing the query definition of a model is updated.

### To Reproduce

1. Create a model: Products, add a custom column, for example `concat([Vendor], "" - "", [Title])`; Save
2. Edit metadata: update the custom column, set Type to Category, and set a description; Save Changes
3. Edit query definition: join Orders; Save changes
4.(!) Open the metadata editor, and see the type of the custom column reverted to 'No Type'

### Expected behavior

The metadata should be preserved.

### Logs

_No response_

### Information about your Metabase installation

```JSON
v1.49.10
```


### Severity

P2

### Additional context

I reproduced this several times, however I could not do it consistently. Sometimes the column type was not reverted.",zbodi74,2024-05-24 10:16:39+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/43112,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2129286188, 'issue_id': 2315024101, 'author': 'kamilmielnik', 'body': 'Cannot reproduce in `master` at 14a42893a8.\r\nCannot reproduce in 0.49.11.\r\n\r\n@zbodi74 A recording would be useful :pray:', 'created_at': datetime.datetime(2024, 5, 24, 11, 20, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2129654396, 'issue_id': 2315024101, 'author': 'zbodi74', 'body': '@kamilmielnik - I had a hard time reproducing it again, but captured one finally: https://jam.dev/c/ef574dbe-8789-4558-9db6-f848ba703d73', 'created_at': datetime.datetime(2024, 5, 24, 14, 22, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2139528703, 'issue_id': 2315024101, 'author': 'denics', 'body': 'and you are not alone. I can confirm that I am facing the same issue in my 1.49.08, I am upgrading now to .13 . It happens to me every time with latitude and longitude in a model (quite annoying as the pin map disappear from the dashboard...)', 'created_at': datetime.datetime(2024, 5, 30, 13, 12, 45, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-05-24 11:20:02 UTC): Cannot reproduce in `master` at 14a42893a8.
Cannot reproduce in 0.49.11.

@zbodi74 A recording would be useful :pray:

zbodi74 (Issue Creator) on (2024-05-24 14:22:58 UTC): @kamilmielnik - I had a hard time reproducing it again, but captured one finally: https://jam.dev/c/ef574dbe-8789-4558-9db6-f848ba703d73

denics on (2024-05-30 13:12:45 UTC): and you are not alone. I can confirm that I am facing the same issue in my 1.49.08, I am upgrading now to .13 . It happens to me every time with latitude and longitude in a model (quite annoying as the pin map disappear from the dashboard...)

"
2314607762,issue,open,,"Date filter ""last 7 days including today"" does not include today","### Describe the bug

Since 0.49.2 we see a change in the behaviour of date filters. We draw bar charts of the throughput of events occured per day. The query uses a filter of ""last 7 days"" and the option ""including today"" is activated.

With 0.49.2 and higher we see 7 bars for the last 7 days. With 0.49.1 we saw 8 bars, the current day was shown as bar no 8.

When looking at the SQL statements that MB generates (Oracle database is used in our case) there is a difference in the date comparison.

0.49.1 generated
```AND (
    ...CREATED >= TRUNC(
      (CURRENT_TIMESTAMP + NUMTODSINTERVAL(-7, 'day')),
      'dd'
    )
  )
  AND (
    ...CREATED < TRUNC(
      (CURRENT_TIMESTAMP + NUMTODSINTERVAL(1, 'day')),
      'dd'
    )
  )
```

In 0.49.2 generates
```AND ...CREATED BETWEEN TRUNC(
    (CURRENT_TIMESTAMP + NUMTODSINTERVAL(-7, 'day')),
    'dd'
  )
  AND TRUNC(CURRENT_TIMESTAMP, 'dd')

```

Maybe caused by changes for #40332?

### To Reproduce

1. Create a new question
2. use a table that holds recent data containing a timestamp
3. add filter by date ""last 7 days""
4. activate ""including today"" in that filter
5. aggregate/count per day


### Expected behavior

The result should include data for the current day

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""de-DE"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.15+10"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.15"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.15+10"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-182-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Berlin""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""sqlserver"",
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.5.25-MariaDB-ubu2004""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v0.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",simonwes,2024-05-24 07:14:58+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/43106,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Oracle', None), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2237267262, 'issue_id': 2314607762, 'author': 'pepegc', 'body': '+1 This is really counter intuitive', 'created_at': datetime.datetime(2024, 7, 18, 18, 42, 12, tzinfo=datetime.timezone.utc)}]","pepegc on (2024-07-18 18:42:12 UTC): +1 This is really counter intuitive

"
2314208107,issue,closed,not_planned,[Cache] Remove invalidate button from OSS screen,,rafpaf,2024-05-24 02:32:47+00:00,[],2024-05-24 02:34:37+00:00,2024-05-24 02:34:37+00:00,https://github.com/metabase/metabase/issues/43103,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2313866645,issue,closed,completed,Provide Macaw with driver-based formatting options,"In order to [correctly handle case and quoting during SQL rewrites](https://github.com/metabase/macaw/issues/34), we need to be driver-aware.

As a first version we'll expect Metabase to pass in some relevant config, and keep Macaw itself driver agnostic.
```clojure
{:case-insensitive? true
 :quotes            ""[]"" ;; MSSQL
```

Perhaps we're able to leverage existing driver methods used by the query processor, especially for the quotes. Otherwise, new multimethods with sensible defaults (thinking case sensitive, with double quotes for quotes).

In future we might find the need to have dialect specific grammars, in which case this will seem a bit redundant. We'll probably keep a fairly agnostic superset grammar as fallback for newfangled 3rd party drivers, which will still take these options though.",crisptrutski,2024-05-23 21:22:53+00:00,['crisptrutski'],2024-06-10 20:41:56+00:00,2024-06-03 14:06:18+00:00,https://github.com/metabase/metabase/issues/43096,"[('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2130010691, 'issue_id': 2313866645, 'author': 'crisptrutski', 'body': 'It turns out that:\r\n\r\n1. Macaw as it stands can\'t support `[]` quoting. Hacking around that can happen just as well in Metabase as in Macaw, so I\'d prefer to keep the library ""clean"" for now.\r\n2. Most common dialect support the same two quotes, so just handle them for everything.\r\n3. Whether quotes affect case sensitivity differs by dialect, so I added an extra option for that.\r\n\r\nSo the options we need are now the following:\r\n\r\n```clojure\r\n{\r\n  :case-insensitive? true ;; ignore case when comparing identifiers\r\n  :quotes-preserve-case? true ;; ignore :case-insensitive? for quoted references?\r\n}\r\n```', 'created_at': datetime.datetime(2024, 5, 24, 17, 7, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142195837, 'issue_id': 2313866645, 'author': 'crisptrutski', 'body': ""It turns out that MySQL's behavior doesn't quite fix any of the patterns we expected. There was a bit of a crossed wire when discussing this with Sanya in the related issue as well, where it turns out he was actually talking about case sensitivity when comparing the values of string typed columns.\r\n\r\nTo summarize [MySQL behavior](https://dev.mysql.com/doc/refman/8.0/en/identifier-case-sensitivity.html):\r\n\r\n - Databases and tables are case sensitive depending on the the file systems it's using, and the `lower_case_table-names` system variable. The default value of this variable comes from the OS the DB was created on. \r\n - The semantics of that system variable are quite complex, but as far as we care if the value is `0` then we know that it's running on a case insensitive FS and case is not being normalized. If it is any other value then these identifiers are not treated as case sensitive.\r\n - We can check this system variable by querying the connection, and its value can never change, so it's safe to cache.\r\n - Column names and aliases are never case sensitive, even if you quote them.\r\n\r\nFor a v1 I think we can just treat MySQL as never being case sensitive, since in practice it's a strongly discouraged practice to use non lowercase names in the database and table names.\r\n\r\nFor a v2 we could change the Macaw API to allow case sensitivity to be set on a per-identifier-type basis, and to get some of these values from the database. We could keep this per-database configuration in a in-memory cache to avoid database hits every time we analyze a query, and we could save this as a property of the database when we first connect to it. \r\n\r\nThat's quite a few moving parts for something customers are unlikely ever to run into, so I think it's fair to kick it down the road."", 'created_at': datetime.datetime(2024, 5, 31, 13, 43, 54, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-05-24 17:07:19 UTC): It turns out that:

1. Macaw as it stands can't support `[]` quoting. Hacking around that can happen just as well in Metabase as in Macaw, so I'd prefer to keep the library ""clean"" for now.
2. Most common dialect support the same two quotes, so just handle them for everything.
3. Whether quotes affect case sensitivity differs by dialect, so I added an extra option for that.

So the options we need are now the following:

```clojure
{
  :case-insensitive? true ;; ignore case when comparing identifiers
  :quotes-preserve-case? true ;; ignore :case-insensitive? for quoted references?
}
```

crisptrutski (Issue Creator) on (2024-05-31 13:43:54 UTC): It turns out that MySQL's behavior doesn't quite fix any of the patterns we expected. There was a bit of a crossed wire when discussing this with Sanya in the related issue as well, where it turns out he was actually talking about case sensitivity when comparing the values of string typed columns.

To summarize [MySQL behavior](https://dev.mysql.com/doc/refman/8.0/en/identifier-case-sensitivity.html):

 - Databases and tables are case sensitive depending on the the file systems it's using, and the `lower_case_table-names` system variable. The default value of this variable comes from the OS the DB was created on. 
 - The semantics of that system variable are quite complex, but as far as we care if the value is `0` then we know that it's running on a case insensitive FS and case is not being normalized. If it is any other value then these identifiers are not treated as case sensitive.
 - We can check this system variable by querying the connection, and its value can never change, so it's safe to cache.
 - Column names and aliases are never case sensitive, even if you quote them.

For a v1 I think we can just treat MySQL as never being case sensitive, since in practice it's a strongly discouraged practice to use non lowercase names in the database and table names.

For a v2 we could change the Macaw API to allow case sensitivity to be set on a per-identifier-type basis, and to get some of these values from the database. We could keep this per-database configuration in a in-memory cache to avoid database hits every time we analyze a query, and we could save this as a property of the database when we first connect to it. 

That's quite a few moving parts for something customers are unlikely ever to run into, so I think it's fair to kick it down the road.

"
2313744081,issue,closed,completed,Remove Query Processor legacy metric expansion and port legacy metric tests,,snoe,2024-05-23 20:10:24+00:00,[],2024-10-08 17:10:48+00:00,2024-05-23 22:39:58+00:00,https://github.com/metabase/metabase/issues/43093,"[('Querying/Processor', ''), ('.Backend', '')]",[],
2313709101,issue,open,,Improve api/activity/recent_items performance,"On stats, it is ~500ms but hopefully should be ~200ms.

e.g.: `/api/activity/recent_views 200 452.1 ms (6 DB calls)`

We should profile this endpoint to see what is actually taking so long, but there are some possible avenues that we suspect:

1. The 4 entity queries (`:card`, `:dataset`, `:collection`, and `:table`) are done sequentially, but could be done in parallel

2. Removing runtime checks (costs: could return incorrect data in certain situations).

3. Allow filtering via params (either count of items, or count per model, or just specify which models to grab)

-----

- [ ] profile endpoint and figure out what is expensive",escherize,2024-05-23 19:50:10+00:00,[],2024-07-15 16:52:31+00:00,,https://github.com/metabase/metabase/issues/43092,"[('.Performance', ''), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2128024061, 'issue_id': 2313709101, 'author': 'escherize', 'body': 'Before any optimization, this is where we are on my m1 macbook pro:\r\n\r\non master:\r\n```\r\nEvaluation count : 4440 in 60 samples of 74 calls.\r\n             Execution time mean : 15.107747 ms\r\n    Execution time std-deviation : 1.086454 ms\r\n   Execution time lower quantile : 13.752945 ms ( 2.5%)\r\n   Execution time upper quantile : 17.359551 ms (97.5%)\r\n                   Overhead used : 2.389407 ns\r\n\r\nFound 1 outliers in 60 samples (1.6667 %)\r\n\tlow-severe\t 1 (1.6667 %)\r\n Variance from outliers : 53.4768 % Variance is severely inflated by outliers\r\n```\r\n\r\n------\r\n\r\n\r\n<img width=""1666"" alt=""Screenshot 2024-05-23 at 4 34 13\u202fPM"" src=""https://github.com/metabase/metabase/assets/343288/2eb1274f-7a56-4651-91ce-6f740ba2a8ee"">\r\n\r\n\r\nHere\'s a flamegraph with recent-views highlighted. Seems like the time is indeed dominated by the big 4 (or 5) queries. I will see if parallelizing them makes a dent now.', 'created_at': datetime.datetime(2024, 5, 23, 21, 9, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2147906551, 'issue_id': 2313709101, 'author': 'escherize', 'body': 'I suspect parallelizing the 4 big queries on the left would speed this up. On my small test data size, however, the overhead made it 10% slower.', 'created_at': datetime.datetime(2024, 6, 4, 16, 7, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2147956770, 'issue_id': 2313709101, 'author': 'paoliniluis', 'body': 'I have a strong belief that a massive improvement might come if we go with https://github.com/metabase/metabase/issues/16909', 'created_at': datetime.datetime(2024, 6, 4, 16, 32, 51, tzinfo=datetime.timezone.utc)}]","escherize (Issue Creator) on (2024-05-23 21:09:56 UTC): Before any optimization, this is where we are on my m1 macbook pro:

on master:
```
Evaluation count : 4440 in 60 samples of 74 calls.
             Execution time mean : 15.107747 ms
    Execution time std-deviation : 1.086454 ms
   Execution time lower quantile : 13.752945 ms ( 2.5%)
   Execution time upper quantile : 17.359551 ms (97.5%)
                   Overhead used : 2.389407 ns

Found 1 outliers in 60 samples (1.6667 %)
	low-severe	 1 (1.6667 %)
 Variance from outliers : 53.4768 % Variance is severely inflated by outliers
```

------


<img width=""1666"" alt=""Screenshot 2024-05-23 at 4 34 13 PM"" src=""https://github.com/metabase/metabase/assets/343288/2eb1274f-7a56-4651-91ce-6f740ba2a8ee"">


Here's a flamegraph with recent-views highlighted. Seems like the time is indeed dominated by the big 4 (or 5) queries. I will see if parallelizing them makes a dent now.

escherize (Issue Creator) on (2024-06-04 16:07:07 UTC): I suspect parallelizing the 4 big queries on the left would speed this up. On my small test data size, however, the overhead made it 10% slower.

paoliniluis on (2024-06-04 16:32:51 UTC): I have a strong belief that a massive improvement might come if we go with https://github.com/metabase/metabase/issues/16909

"
2313506157,issue,closed,completed,"Normalizer interprets ""expression"" as a MBQL :expression, but it is just a column name","### Describe the bug

Customer is getting this exception:
```
{
  ""via"": [
    {
      ""type"": ""clojure.lang.ExceptionInfo"",
      ""message"": ""Error normalizing query: Error normalizing form: null"",
      ""data"": {
        ""query"": [
          ""expression"",
          null,
          ""sum"",
          ""sum_3"",
          ""sum_2""
        ],
...
```

When trying to GET /api/cards
with this card
```
{""table.pivot_column"" ""created_month"",
 ""table.cell_column"" ""sum"",
 ""card.title"" ""Funnel view by month"",
 ""table.column_formatting""
 [{""columns"" [""expression"" nil ""sum"" ""sum_3"" ""sum_2""],
...
```

https://metaboat.slack.com/archives/C04DN5VRQM6/p1716477256872509

### To Reproduce

See logs above


### Expected behavior

1. It shouldn't try to normalize columns
2. The GET request shouldn't completely fail. It should remove the erroring question and warn the user

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Cloud instance, latest v49
```


### Severity

P1

### Additional context

https://metaboat.slack.com/archives/C04DN5VRQM6/p1716477256872509",luizarakaki,2024-05-23 17:38:36+00:00,['metamben'],2024-08-28 02:09:50+00:00,2024-05-30 13:46:05+00:00,https://github.com/metabase/metabase/issues/43089,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2313496737,issue,closed,completed,Admins can't create queries on Metabase Analytics models,"### Describe the bug

Following a specific path, admins can't create questions on Metabase Analytics models.

The reproduction is inconsistent, but we have a customer that can't create questions at all.

### To Reproduce

1. New
2. Select a Metabase Analytics model
3. See a locked notebook editor

Repro Loom: https://metaboat.slack.com/archives/C064EB1UE5P/p1716475760677229

### Expected behavior

Admins (and any user with view access to the model) should be able to create questions

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Stats
```


### Severity

A high priority P2

### Additional context

_No response_",luizarakaki,2024-05-23 17:33:00+00:00,['ranquild'],2024-07-15 20:59:58+00:00,2024-07-15 13:15:20+00:00,https://github.com/metabase/metabase/issues/43088,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2140830245, 'issue_id': 2313496737, 'author': 'noahmoss', 'body': ""Root cause: because we don't return the audit DB by default in `GET /api/databases`, the metadata provider on the FE doesn't have knowledge of it. This results in the MLv2 query having a `null` database ID, which breaks the logic for displaying the notebook editor.\r\n\r\nReturning the audit DB in `GET /api/databases` fixes this issue, but leads to audit content showing up elsewhere (i.e. it allows the raw audit views to be selected as data sources). We'll probably need some magic to add the audit DB metadata in the right spot on the FE.\r\n\r\nDebugging thread for context: https://metaboat.slack.com/archives/C064EB1UE5P/p1717094345309169"", 'created_at': datetime.datetime(2024, 5, 30, 20, 40, 58, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-05-30 20:40:58 UTC): Root cause: because we don't return the audit DB by default in `GET /api/databases`, the metadata provider on the FE doesn't have knowledge of it. This results in the MLv2 query having a `null` database ID, which breaks the logic for displaying the notebook editor.

Returning the audit DB in `GET /api/databases` fixes this issue, but leads to audit content showing up elsewhere (i.e. it allows the raw audit views to be selected as data sources). We'll probably need some magic to add the audit DB metadata in the right spot on the FE.

Debugging thread for context: https://metaboat.slack.com/archives/C064EB1UE5P/p1717094345309169

"
2313313595,issue,closed,completed,New Search button does not shrink on mobile,"### Describe the bug

Search button in app bar is too wide on mobile

![image](https://github.com/metabase/metabase/assets/1328979/da86690e-2c72-462b-942a-cd0aeb3bf356)


### To Reproduce

1. Go to homepage
2. See App bar


### Expected behavior

Should not be so large

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current Master
```


### Severity

p3

### Additional context

_No response_",npfitz,2024-05-23 16:08:08+00:00,['npfitz'],2024-05-24 19:48:04+00:00,2024-05-24 19:48:04+00:00,https://github.com/metabase/metabase/issues/43083,"[('Type:Bug', 'Product defects'), ('Client:Mobile Web', 'and tablets and smaller screens'), ('.Frontend', ''), ('.Needs Triage', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2313100219,issue,closed,completed,Time-over-time comparison aggregation helpers,,kamilmielnik,2024-05-23 14:37:57+00:00,['kamilmielnik'],2024-10-08 17:10:15+00:00,2024-05-29 14:41:43+00:00,https://github.com/metabase/metabase/issues/43079,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2313061456,issue,open,,Joining two models create the error card id 119 doesn't exist,"### Describe the bug

Hi,
When I join two models (""revenues et charges par dossier"" and ""somme des commandes par dossier"") in my question ""Marge par dossier"" I have the error : ""Card id 119 doesn't exist"". 
![Screenshot 2024-05-23 at 16 14 27](https://github.com/metabase/metabase/assets/117378776/bf1675f2-73bd-45f6-a7ed-9ca900f35ea5)


### To Reproduce

1. Go to my metabase account
2. Create a question by joining models ""revenues et charges par dossier"" and ""somme des commandes par dossier"" on tag_label = dossier_id
3. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-13"",
      ""tag"": ""v1.49.10"",
      ""hash"": ""9e8fc83""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking usage of metabase

### Additional context

_No response_",NoaTim,2024-05-23 14:22:00+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/43078,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Unable to Reproduce', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2129869590, 'issue_id': 2313061456, 'author': 'zbodi74', 'body': '@NoaTim - can you confirm if these models use data from the same database or from different ones? \r\nIf they use different databases, joining them is not supported and currently leads to the misleading message mentioned above (https://github.com/metabase/metabase/issues/38989).', 'created_at': datetime.datetime(2024, 5, 24, 15, 49, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2130409077, 'issue_id': 2313061456, 'author': 'paoliniluis', 'body': '@NoaTim please give us some details about card 119: is it a model? how is it defined?', 'created_at': datetime.datetime(2024, 5, 24, 21, 45, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182799606, 'issue_id': 2313061456, 'author': 'bshepherdson', 'body': '@NoaTim bump for the above questions. Can you give us some details on the models in question?\r\n\r\nIn particular:\r\n- Do they use the same database?\r\n- Are they native models or GUI models?\r\n\r\nOtherwise, this issue is likely to be closed as a dupe of #38989 .', 'created_at': datetime.datetime(2024, 6, 21, 13, 52, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230874281, 'issue_id': 2313061456, 'author': 'perivamsi', 'body': 'Downgrading this to a P2 and changing the ask to make the error message better.', 'created_at': datetime.datetime(2024, 7, 16, 13, 19, 56, tzinfo=datetime.timezone.utc)}]","zbodi74 on (2024-05-24 15:49:04 UTC): @NoaTim - can you confirm if these models use data from the same database or from different ones? 
If they use different databases, joining them is not supported and currently leads to the misleading message mentioned above (https://github.com/metabase/metabase/issues/38989).

paoliniluis on (2024-05-24 21:45:41 UTC): @NoaTim please give us some details about card 119: is it a model? how is it defined?

bshepherdson on (2024-06-21 13:52:35 UTC): @NoaTim bump for the above questions. Can you give us some details on the models in question?

In particular:
- Do they use the same database?
- Are they native models or GUI models?

Otherwise, this issue is likely to be closed as a dupe of #38989 .

perivamsi on (2024-07-16 13:19:56 UTC): Downgrading this to a P2 and changing the ask to make the error message better.

"
2313043465,issue,closed,completed,Invalid API request fired when clicking chart legend item,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/19c5a257-b2f4-4e13-a87f-7f7c214d6d6d



### To Reproduce

1. Create a new question based on Orders table
2. Add Count aggregation
3. Add Sum of Total aggregation
4. Breakout by Created At: Month
5. Visualize
6. Observe network tab in developer tools
7. Click any item in chart legend

GET `/api/card/undefined` request is fired

### Expected behavior

No API request should be fired


### Information about your Metabase installation

master, c9f2ffe99e

### Severity

P2
",kamilmielnik,2024-05-23 14:14:30+00:00,['JesseSDevaney'],2024-06-26 20:02:18+00:00,2024-06-26 15:12:25+00:00,https://github.com/metabase/metabase/issues/43077,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2313036438,issue,open,,Dates before 1906-01-01 break the formatting.,"### Describe the bug

Dates older than Jan 1, 1906 are displayed as `yyyy-mm-ddT00:00:00+05:21:10` for some reason. 
<img width=""917"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/cb59dca2-588b-4f63-8207-18bfcd9d9fb7"">


### To Reproduce

1. Go to `+ New`
2. Click on `SQL Query` & select database
3. `SELECT * FROM UNNEST (GENERATE_DATE_ARRAY(""1905-12-01"", ""1906-01-31"")) AS dt ORDER BY dt`
4. Scroll down from December 1905 to January 1906


### Expected behavior

All dates should be displayed as `mmm dd, yyyy`

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1058-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.39-MariaDB-0ubuntu0.20.04.2""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-13"",
      ""tag"": ""v0.49.10"",
      ""hash"": ""9e8fc83""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Calcutta""
    }
  }
}
```


### Severity

Low, just poor UX

### Additional context

_No response_",abhishek-superk,2024-05-23 14:11:33+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/43076,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2127273502, 'issue_id': 2313036438, 'author': 'kamilmielnik', 'body': ""I wasn't able to reproduce it with MariaDB and given reproduction steps.\r\nI managed to reproduce it in PostgreSQL with this query:\r\n```sql\r\nSELECT t.day::date \r\nFROM   generate_series(timestamp '1900-01-01'\r\n                     , timestamp '1901-01-01'\r\n                     , interval  '1 day') AS t(day);\r\n```\r\n\r\nThe data returned from POST `/api/dataset` cannot be parsed by JavaScript, because it looks like this:\r\n```\r\n1900-01-01T00:00:00+06:42:04\r\n```\r\n\r\nNotice the last extra `:04`. I'm not sure why it does not give me a round hour either. I'm sending it to QP team.\r\n\r\n----\r\n\r\nLooks similar to #33923"", 'created_at': datetime.datetime(2024, 5, 23, 14, 30, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2127371358, 'issue_id': 2313036438, 'author': 'abhishek-superk', 'body': 'My bad, generate array would have different syntax across different DBs. For easier replication, you can also try:\r\n `SELECT DATE(""1905-12-01"")`', 'created_at': datetime.datetime(2024, 5, 23, 15, 3, 37, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-05-23 14:30:14 UTC): I wasn't able to reproduce it with MariaDB and given reproduction steps.
I managed to reproduce it in PostgreSQL with this query:
```sql
SELECT t.day::date 
FROM   generate_series(timestamp '1900-01-01'
                     , timestamp '1901-01-01'
                     , interval  '1 day') AS t(day);
```

The data returned from POST `/api/dataset` cannot be parsed by JavaScript, because it looks like this:
```
1900-01-01T00:00:00+06:42:04
```

Notice the last extra `:04`. I'm not sure why it does not give me a round hour either. I'm sending it to QP team.

----

Looks similar to #33923

abhishek-superk (Issue Creator) on (2024-05-23 15:03:37 UTC): My bad, generate array would have different syntax across different DBs. For easier replication, you can also try:
 `SELECT DATE(""1905-12-01"")`

"
2313032079,issue,closed,completed,Break out popover overflows the screen,"### Describe the bug

The break out popover in the visualization was placed with overflow on the window.

### To Reproduce

1. New question -> Sample database -> People
2. Add an aggregation -> Count of rows -> Source
3. Visualize
4. Click on one of the visualization columns
5. Break out by
6. Time

### Expected behavior

The popover should be scrollable and not overflow the screen.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:126.0) Gecko/20100101 Firefox/126.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.20.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.20.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.20.1+1"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.2.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Amsterdam""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-05-23"",
      ""src_hash"": ""3408dbf541bb1904a57dcb2cf7022f8e76d2b1ba"",
      ""tag"": ""v0.1.6-SNAPSHOT"",
      ""hash"": ""40074bd""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

_No response_",romeovs,2024-05-23 14:09:47+00:00,['romeovs'],2024-07-02 11:16:38+00:00,2024-05-24 12:01:59+00:00,https://github.com/metabase/metabase/issues/43075,"[('Type:Bug', 'Product defects'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2199458741, 'issue_id': 2313032079, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.9](https://github.com/metabase/metabase/milestone/247)', 'created_at': datetime.datetime(2024, 7, 1, 7, 42, 13, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-01 07:42:13 UTC): 🚀 This should also be released by [v0.50.9](https://github.com/metabase/metabase/milestone/247)

"
2313027042,issue,open,,Embedding SDK for Vue.js,"**Is your feature request related to a problem? Please describe.**
Self-explanatory

**Describe the solution you'd like**
Self-explanatory
",ignacio-mb,2024-05-23 14:07:33+00:00,[],2024-06-04 14:51:00+00:00,,https://github.com/metabase/metabase/issues/43074,"[('Type:New Feature', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2313010923,issue,closed,completed,[Testing plan] Time-over-time comparison,"Testing plan for https://www.notion.so/metabase/Time-over-time-comparison-UI-for-aggregated-columns-032bb9b47d124731baa9c3c7f954727f

# Unit tests

- [x] For each of `offsetClause`, `diffOffsetClause`, `percentDiffOffsetClause` helpers:
  - [x] returns correct expression clause
  - [x] sets correct name
    - [x] singular `offset` (=-1)
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
    - [x] plural `offset` (<-1)
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
- [x] `AggregationPicker`
  - [x] does not display the option if there are no aggregations
  - [x] correct label
    - [x] single aggregation
    - [x] multiple aggregations
  - [x] calls `onAdd` when submitted
  - [x] does not call `onSelect` when submitted
- [x] `CompareAggregations`
  - [x] period input
    - [x] does not allow negative values
    - [x] does not allow non-integer values
  - [x] 1 aggregation
    - [x] does not display extra step
    - [x] cannot go back to extra step
  - [x] multiple aggregations
    - [x] displays extra step
    - [x] can go back to extra step
  - [x] submit button is disabled when no columns are selected
  - [x] submit button is disabled when offset value is empty
  - [x] calls `onSubmit`
    - [x] 1 column
    - [x] multiple columns

# e2e tests

- [x] Via aggregation picker in notebook editor
  - [x] is not displayed when there is no aggregation
  - [x] correct label
    - [x] 1 aggregation
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
    - [x] multiple aggregations
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
  - [x] adds new column(s)
    - [x] assert analytic event dispatched
    - [x] assert column name
    - [x] assert valid expression in the notebook editor widget
- [x] Via aggregation picker in chill mode (summarize)
  - [x] is not displayed when there is no aggregation
  - [x] correct label
    - [x] 1 aggregation
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
    - [x] multiple aggregations
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
  - [x] adds new column(s)
    - [x] assert analytic event dispatched
    - [x] assert column name
    - [x] assert valid expression in the notebook editor widget
- [x] Via plus button in table visualization
  - [x] is not displayed when there is no aggregation
  - [x] correct label
    - [x] 1 aggregation
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
    - [x] multiple aggregations
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
  - [x] adds new column(s)
    - [x] assert analytic event dispatched
    - [x] assert column name
    - [x] assert valid expression in the notebook editor widget
- [x] Via column header drill in table visualization
  - [x] is displayed only in columns created by aggregations
  - [x] is not displayed for data columns
  - [x] ~is not displayed for custom columns~
  - [x] is not displayed for breakout columns
    - [x] 1 aggregation
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
    - [x] multiple aggregations
      - [x] no breakout
      - [x] breakout on binned datetime column
      - [x] breakout on non-binned datetime column
      - [x] breakout on non-datetime column
  - [x] adds new column(s)
    - [x] assert analytic event dispatched
    - [x] assert column name
    - [x] assert valid expression in the notebook editor widget
",kamilmielnik,2024-05-23 14:00:41+00:00,['kamilmielnik'],2024-06-10 11:56:48+00:00,2024-06-10 11:56:48+00:00,https://github.com/metabase/metabase/issues/43073,"[('.CI & Tests', ''), ('.TestingStrategy/FE', ''), ('.Team/Querying', '')]",[],
2313010781,issue,closed,completed,Analytic events,,kamilmielnik,2024-05-23 14:00:38+00:00,['kamilmielnik'],2024-10-08 17:09:00+00:00,2024-06-06 11:03:33+00:00,https://github.com/metabase/metabase/issues/43072,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2313010673,issue,closed,completed,Previous period comparison shortcut in chill mode - column headers,,kamilmielnik,2024-05-23 14:00:35+00:00,['kamilmielnik'],2024-10-08 17:09:06+00:00,2024-06-05 15:53:52+00:00,https://github.com/metabase/metabase/issues/43071,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2313010502,issue,closed,completed,Previous period comparison shortcut in notebook mode,"- [x] show new option in aggregation picker
- [x] case with multiple aggregations
  - [x] step to select a column 
  - [x] handle option name
- [x] number input label bottom padding
- [x] number input width
- [x] number input info text
- [x] custom autocomplete items
- [x] validate plural/singular period form in the menu",kamilmielnik,2024-05-23 14:00:31+00:00,['kamilmielnik'],2024-10-08 17:09:26+00:00,2024-06-04 08:15:49+00:00,https://github.com/metabase/metabase/issues/43070,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2312962887,issue,closed,completed,Serialized models should declare fields to serialize,"And a test making sure that every new column added with migration should be handled by a developer.

[Context](https://metaboat.slack.com/archives/C0641E4PB9B/p1715913839189749)
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/45209
- [ ] #45455
- [ ] https://github.com/metabase/metabase/pull/46481
- [ ] https://github.com/metabase/metabase/pull/46147
- [ ] https://github.com/metabase/metabase/pull/46912
- [ ] https://github.com/metabase/metabase/pull/46966
- [ ] https://github.com/metabase/metabase/pull/46973
- [ ] https://github.com/metabase/metabase/pull/47121
- [ ] https://github.com/metabase/metabase/pull/47136
- [ ] https://github.com/metabase/metabase/pull/47220
- [ ] https://github.com/metabase/metabase/issues/47226
- [ ] https://github.com/metabase/metabase/pull/47268
```
",piranha,2024-05-23 13:40:44+00:00,['piranha'],2024-09-02 12:01:28+00:00,2024-08-27 10:39:36+00:00,https://github.com/metabase/metabase/issues/43068,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]",[],
2312793564,issue,closed,completed,Update the design for custom expression shortcuts,"We've implemented [shortcuts](https://github.com/metabase/metabase/issues/41177) and popular custom expressions [suggestions](https://github.com/metabase/metabase/issues/41187) for which the designers want to make small adjustments:
- Change text case for headers from upper case to sentence case
- Increase spacing before headers
",mngr,2024-05-23 12:27:29+00:00,['romeovs'],2024-05-29 11:00:56+00:00,2024-05-29 11:00:56+00:00,https://github.com/metabase/metabase/issues/43064,"[('.Design Needed', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2127042159, 'issue_id': 2312793564, 'author': 'AlessioLaiso', 'body': 'The design below flips the order of shortcuts and common functions (with revised text label), tweaks spacing, changes title case to sentence case, removes dividers, and changes the color of the icons. Please hold off any changes to the bottom documentation/""view all function"" till we get clarity on how to move forward here.\r\nhttps://www.figma.com/design/Rh7vrNTZX4TPAGC1fDtS55/Extract-and-combine---QB-expressivity-and-column-actions?node-id=2546%3A26471&t=XyRCHf2NrZYuPPMr-1', 'created_at': datetime.datetime(2024, 5, 23, 12, 57, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133529571, 'issue_id': 2312793564, 'author': 'crisptrutski', 'body': '@mngr is this something we want to include in RC2 this week?', 'created_at': datetime.datetime(2024, 5, 27, 13, 50, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133843648, 'issue_id': 2312793564, 'author': 'mngr', 'body': 'We can postpone this to RC3 if it happens', 'created_at': datetime.datetime(2024, 5, 27, 17, 8, 5, tzinfo=datetime.timezone.utc)}]","AlessioLaiso on (2024-05-23 12:57:13 UTC): The design below flips the order of shortcuts and common functions (with revised text label), tweaks spacing, changes title case to sentence case, removes dividers, and changes the color of the icons. Please hold off any changes to the bottom documentation/""view all function"" till we get clarity on how to move forward here.
https://www.figma.com/design/Rh7vrNTZX4TPAGC1fDtS55/Extract-and-combine---QB-expressivity-and-column-actions?node-id=2546%3A26471&t=XyRCHf2NrZYuPPMr-1

crisptrutski on (2024-05-27 13:50:47 UTC): @mngr is this something we want to include in RC2 this week?

mngr (Issue Creator) on (2024-05-27 17:08:05 UTC): We can postpone this to RC3 if it happens

"
2312529149,issue,closed,not_planned,0.49.11:The data retrieved using a date picker is different from the data retrieved by directly entering the date.,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/101546352/37024c5e-bb0c-483c-a015-a62e2cf08eb9)
 this is right
![image](https://github.com/metabase/metabase/assets/101546352/0d0e4246-0189-4898-8de7-34e5154ab7f3)
this wrong
The data retrieved using a date picker is different from the data retrieved by directly entering the date.
use oracle database
please helpme


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-58-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Shanghai""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""oracle"",
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.2.0""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v0.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Shanghai""
    }
  }
}
```


### Severity

Severity

### Additional context

_No response_",congzhouliang,2024-05-23 10:22:17+00:00,[],2024-10-22 20:14:54+00:00,2024-10-22 20:14:54+00:00,https://github.com/metabase/metabase/issues/43059,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Oracle', None), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2229057096, 'issue_id': 2312529149, 'author': 'ranquild', 'body': '@congzhouliang could it be the case that you accidentally added time to the date? There is an issue that the filter widgets do not display time until you open the popover. If you specify your filter value via the URL it can happen as well.\n\n![Image](https://github.com/user-attachments/assets/42915e92-b00f-4ed9-8b32-e54891fa1340)', 'created_at': datetime.datetime(2024, 7, 15, 17, 46, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323105000, 'issue_id': 2312529149, 'author': 'paoliniluis', 'body': ""@congzhouliang do you still hit this? otherwise we'll be closing the issue due to non-response"", 'created_at': datetime.datetime(2024, 9, 1, 1, 29, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2430172157, 'issue_id': 2312529149, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/39627', 'created_at': datetime.datetime(2024, 10, 22, 20, 14, 38, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-15 17:46:03 UTC): @congzhouliang could it be the case that you accidentally added time to the date? There is an issue that the filter widgets do not display time until you open the popover. If you specify your filter value via the URL it can happen as well.

![Image](https://github.com/user-attachments/assets/42915e92-b00f-4ed9-8b32-e54891fa1340)

paoliniluis on (2024-09-01 01:29:48 UTC): @congzhouliang do you still hit this? otherwise we'll be closing the issue due to non-response

ranquild on (2024-10-22 20:14:38 UTC): Duplicate of https://github.com/metabase/metabase/issues/39627

"
2312407695,issue,closed,completed,Filtering by exact date and time works incorrectly if midnight is chosen,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/4d908413-df4a-4882-bcd5-0ba5013d43df



### To Reproduce

1. Start new question based on Orders table
2. Add a filter Created At > Specific dates > On > Pick a date (e.g. May 23, 2024) > Add time > Midnight (12:00 AM)

""Created At is on May 23, 2024"" filter is added

### Expected behavior

""Created At is on May 23, 2024, 12:00 AM"" filter is added

### Information about your Metabase installation

master, 41f6d17519


### Severity

P2
",kamilmielnik,2024-05-23 09:22:39+00:00,['ranquild'],2024-07-01 17:46:38+00:00,2024-07-01 13:50:59+00:00,https://github.com/metabase/metabase/issues/43057,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2312309687,issue,closed,completed,Cloud Migration RC1 issues,"MB:
- [x] (at least) version errors should bubble up so the FE can display them
- [x] docker version fails on dump
- [x] find a mechanism for BE and FE to agree to use staging (BE is using `config/is-dev?` atm)
- [x] MB should use current version for migration if it has a non-dev one
- [x] key rotation should surface errors
- [x] h2 dumps should never be read-only

HM:
- [x] debug why operator is failing on key rotation
- [x] store should use newer version than default if provided in a migration
- [x] migration valid check should return false for claimed migrations",filipesilva,2024-05-23 08:36:43+00:00,['filipesilva'],2024-05-29 17:12:00+00:00,2024-05-29 17:11:59+00:00,https://github.com/metabase/metabase/issues/43056,"[('Operation/Docker', ''), ('.Frontend', ''), ('.Backend', ''), ('Deployment/MetabaseCloud', 'Issue only affects users of Metabase Cloud')]",[],
2311475597,issue,closed,completed,CSV Export Doesn't Respect Formatting for Financial Type Fields,"### Describe the bug

CSV Export Doesn't Respect Formatting for Financial Type Fields

### To Reproduce

- Use ""orders"" table from sample database
- In Table Metadata set ""Discount"" to a financial type and ""Total"" to either ""Quantity"" or ""No Semantic Type""
- Create a question
- Display these two fields in a table
- Add custom formatting in the viz settings to add currency formatting to every cell in the table
- Export as CSV
- Note that formatting is not retained in the export for the financial type fields

### Expected behavior

The formatting in the export should match the table visualization

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v1.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

Here is a quick Loom recording running through repro:
https://www.loom.com/share/d591d06d48e2425a833b9f09672d5145",ixipixi,2024-05-22 21:01:06+00:00,[],2024-08-13 17:57:25+00:00,2024-08-09 19:50:14+00:00,https://github.com/metabase/metabase/issues/43040,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('Customization/Formatting', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2311452898,issue,closed,completed,Custom Formatting in Table Visualization is not Respected on Export to Excel for Aggregated Fields,"### Describe the bug

Exporting formatted data from a table visualization to Excel fails to retain the custom formatting if the fields were summarized in the underlying Question.



### To Reproduce

- Create a question
- Group by some field
- In the summarize box take a sum or max of a numeric field
- Save it to a table visualization
- Format the aggregated field as currency type, percent or any other visual customization
- Export to Excel
- Note the formatting is missing

If the formatting is applied to un-summarized fields the format in the export is correct. 

### Expected behavior

The format in the export should match the table viz.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v1.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

Loom recording illustrating export of un-summarized and summarized results to Excel: 

https://www.loom.com/share/98c4d4374e62488e9c68283599442529",ixipixi,2024-05-22 20:47:17+00:00,[],2024-08-13 17:57:23+00:00,2024-08-09 19:50:14+00:00,https://github.com/metabase/metabase/issues/43039,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('Customization/Formatting', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2311363783,issue,open,,Bump shadow-cljs (2.28.7),"A new clojure compiler has been included in the latest versions, so it might give us a performance bump",paoliniluis,2024-05-22 19:53:10+00:00,[],2025-02-04 20:25:32+00:00,,https://github.com/metabase/metabase/issues/43030,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('.Backend', ''), ('dependencies', None), ('backend-deps', ''), ('.Team/Querying', '')]",[],
2311347063,issue,closed,not_planned,The 3 lines to toggle the menu in the admin settings transform to a white box on small viewports,"### Describe the bug

Just simply:
![image](https://github.com/metabase/metabase/assets/1711649/1bac2945-750d-48eb-b7d5-a0648d859af1)


### To Reproduce

1) spin up v50
2) go to the admin
3) reduce the width of the browser
4) see the white box appearing

### Expected behavior

it should show 3 lines

### Logs

NA

### Information about your Metabase installation

```JSON
v50
brave browser
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-05-22 19:42:31+00:00,[],2025-01-23 20:49:45+00:00,2025-01-23 20:49:45+00:00,https://github.com/metabase/metabase/issues/43029,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Unable to Reproduce', ''), ('Client:Mobile Web', 'and tablets and smaller screens'), ('.Frontend', ''), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2311339631,issue,closed,completed,Document MB_USER_VISIBILITY,Seems that we enabled the feature at some point in the past but we never documented the env var,paoliniluis,2024-05-22 19:37:50+00:00,[],2024-06-06 10:47:20+00:00,2024-06-06 10:47:20+00:00,https://github.com/metabase/metabase/issues/43027,"[('Type:Documentation', ''), ('Type:New Feature', '')]","[{'comment_id': 2150865550, 'issue_id': 2311339631, 'author': 'jeff-bruemmer', 'body': 'Documented in this PR: https://github.com/metabase/metabase/pull/43612 (from the new env var docs generation). Docs will go live when 50 is released.', 'created_at': datetime.datetime(2024, 6, 5, 20, 6, 49, tzinfo=datetime.timezone.utc)}]","jeff-bruemmer on (2024-06-05 20:06:49 UTC): Documented in this PR: https://github.com/metabase/metabase/pull/43612 (from the new env var docs generation). Docs will go live when 50 is released.

"
2311239195,issue,open,,If you want to edit a question on a mobile browser you see the SQL view by default,"### Describe the bug

If you're on your mobile and you want to edit a question, you'll end up in the native SQL view of the question

### To Reproduce

1) create a question on your laptop
2) then use the mobile view of the browser, go to the notebook editor and click on the icon
3) see the SQL view popping up first, when it should be the notebook view

### Expected behavior

We should show the notebook by default on mobile

### Logs

NA

### Information about your Metabase installation

```JSON
v50
brave mobile
```


### Severity

P3

### Additional context

NA
![sql-by-default](https://github.com/metabase/metabase/assets/1711649/4866f9de-f4d4-4394-a464-6199de4394f9)
",paoliniluis,2024-05-22 18:37:53+00:00,[],2024-07-04 12:03:47+00:00,,https://github.com/metabase/metabase/issues/43025,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Client:Mobile Web', 'and tablets and smaller screens'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2188875975, 'issue_id': 2311239195, 'author': 'nemanjaglumac', 'body': ""@paoliniluis This is not a bug.\r\nMetabase remembers your setting when it comes to - do you prefer the notebook SQL preview to be open or not. You've had it opened and that's what you see on mobile as well."", 'created_at': datetime.datetime(2024, 6, 25, 13, 0, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192766185, 'issue_id': 2311239195, 'author': 'calherries', 'body': ""Seems like a bug to me. I came across this as well and was about to file another bug issue for it. \r\n\r\nIf my screen is wide, I like having the notebook SQL preview open alongside the main editor. If I make the window smaller or use mobile, I definitely don't just want to see the SQL preview. I can't do anything with it."", 'created_at': datetime.datetime(2024, 6, 26, 23, 9, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2193873885, 'issue_id': 2311239195, 'author': 'nemanjaglumac', 'body': 'I guess it is a question for a product in that case.', 'created_at': datetime.datetime(2024, 6, 27, 6, 6, 32, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-06-25 13:00:16 UTC): @paoliniluis This is not a bug.
Metabase remembers your setting when it comes to - do you prefer the notebook SQL preview to be open or not. You've had it opened and that's what you see on mobile as well.

calherries on (2024-06-26 23:09:39 UTC): Seems like a bug to me. I came across this as well and was about to file another bug issue for it. 

If my screen is wide, I like having the notebook SQL preview open alongside the main editor. If I make the window smaller or use mobile, I definitely don't just want to see the SQL preview. I can't do anything with it.

nemanjaglumac on (2024-06-27 06:06:32 UTC): I guess it is a question for a product in that case.

"
2311224751,issue,closed,not_planned,"There's no ""new"" button on mobile","### Describe the bug

When using Metabase on mobile, there's no ""new"" button

### To Reproduce

Just open Metabase on your mobile

### Expected behavior

Probably this is the expected behavior?

### Logs

NA

### Information about your Metabase installation

```JSON
- v50
- brave mobile
```


### Severity

P3

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/6b6d28a2-6ba7-4eab-b180-b65344792c6b)
",paoliniluis,2024-05-22 18:31:33+00:00,[],2024-06-19 11:57:50+00:00,2024-06-19 11:57:50+00:00,https://github.com/metabase/metabase/issues/43024,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Client:Mobile Web', 'and tablets and smaller screens'), ('.Frontend', '')]","[{'comment_id': 2126847583, 'issue_id': 2311224751, 'author': 'darksciencebase', 'body': ""@kdoh @mazameli wasn't this by design? i vaguely recall reading something like that, might've been a dream though"", 'created_at': datetime.datetime(2024, 5, 23, 11, 12, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176371659, 'issue_id': 2311224751, 'author': 'kdoh', 'body': 'Yeah this is intentional as of now.', 'created_at': datetime.datetime(2024, 6, 18, 15, 21, 52, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-05-23 11:12:56 UTC): @kdoh @mazameli wasn't this by design? i vaguely recall reading something like that, might've been a dream though

kdoh on (2024-06-18 15:21:52 UTC): Yeah this is intentional as of now.

"
2311210678,issue,closed,not_planned,Metabase icon is aligned with the search bar on mobile,"### Describe the bug

When it should be aligned to the right

### To Reproduce

1) open Metabase in your mobile or check it on the mobile view of the browser

### Expected behavior

Should be aligned to the left?

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P3

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/7ce4fbef-1a7f-423f-9caa-2ec9f19607c7)
",paoliniluis,2024-05-22 18:26:57+00:00,[],2025-01-23 20:51:02+00:00,2025-01-23 20:51:02+00:00,https://github.com/metabase/metabase/issues/43023,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Unable to Reproduce', ''), ('Client:Mobile Web', 'and tablets and smaller screens'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Design System', 'Overall UI patterns and components, not specific to a single part of the product')]","[{'comment_id': 2610990891, 'issue_id': 2311210678, 'author': 'luizarakaki', 'body': 'The logo is centralized, and unable to repro on 52 because the search bar collapses into a button now', 'created_at': datetime.datetime(2025, 1, 23, 20, 50, 57, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-23 20:50:57 UTC): The logo is centralized, and unable to repro on 52 because the search bar collapses into a button now

"
2311047475,issue,closed,completed,[Cache] Move model caching UI to Admin / Performance,https://www.figma.com/design/x87hHuf4RabjMBuyV2Lq7c/caching-arc-low-fi-explorations?node-id=693-1861&t=uTI06qZm3EKx3RlH-4,rafpaf,2024-05-22 16:57:59+00:00,['rafpaf'],2024-05-29 03:15:26+00:00,2024-05-29 03:15:25+00:00,https://github.com/metabase/metabase/issues/43019,[],[],
2310889929,issue,closed,completed,Measure search performance,"Project Doc: [Notion Doc](https://www.notion.so/metabase/Measure-search-performance-958a28ef144a4b94be8b3b1f0ce4ab34)


```[tasklist]
### Tasks
- [x] Remove Snowplow Events from BE Search Endpoint
- [x] Add onQueryStarted handler to `metabase/api/search.ts` to emit snowplow events
- [x] Add snowplow events to command palette
- [x] Add snowplow events to search app
- [x] Add snowplow events to entity picker
- [x] Update snowplow event schemas
```

",npfitz,2024-05-22 15:51:46+00:00,['npfitz'],2024-06-07 19:55:52+00:00,2024-06-06 20:40:28+00:00,https://github.com/metabase/metabase/issues/43017,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2310810034,issue,closed,not_planned,MB_DB_CONNECTION_TIMEOUT_MS not used properly,"### Describe the bug

When not setting the env variable `MB_DB_CONNECTION_TIMEOUT_MS`, the BigQuery database connection timeout after 60 seconds on our client. However when setting MB_DB_CONNECTION_TIMEOUT_MS to any given value the delay of a query can exceed the value of MB_DB_CONNECTION_TIMEOUT_MS.
As an example, I ran a _chunky_ query by full-outter joining twice a table on itself on a categorical column (lot of identical values across rows). The table has nearly 300.000 rows. The variable MB_DB_CONNECTION_TIMEOUT_MS was set to 300000 i.e. 5 minutes, but the query only got timed out after roughly 10 minutes.
As I only have a BigQuery database, I cannot infer if the bug is present for other drivers.

### To Reproduce

1. Set the env variable MB_DB_CONNECTION_TIMEOUT_MS to any value greater than 60000
2. Launch Metabase and open the web UI
3. Create a question using a BigQuery (can also try other sources) table which contains several 100.000s of rows. Full-outter join it on itself once or twice on a column which is not unique per row (a category for example)
4. See the query exceeding the MB_DB_CONNECTION_TIMEOUT_MS delay by a few 10s or minutes (depending on query size) and eventually got timed out but too late


### Expected behavior

The query should be cancelled after MB_DB_CONNECTION_TIMEOUT_MS milliseconds (+/- few seconds but not much more). In any case it should not take twice the amount of time to be cancelled or several minutes.

### Logs

```
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:44:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 167.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (4 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:44:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 223.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (4 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:44:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 119.4 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (4 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:44:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 199.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (4 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:44:46+02:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 4.3 ms (1 DB calls) App DB connections: 1/15 Jetty threads: 3/50 (5 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:02+02:00 DEBUG metabase.server.middleware.log GET /api/user/ 200 9.6 ms (4 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (4 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 124.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (93 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 138.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (93 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 177.4 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (93 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 177.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (93 total active threads) Queries in flight: 0 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 139.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:45:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 151.4 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 136.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 141.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 144.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 144.2 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 151.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:46:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 178.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 159.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 180.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 146.2 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 144.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 105.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:47:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 106.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 160.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 181.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 145.2 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 148.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 108.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:48:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 93.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:49:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 130.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:49:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 139.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:49:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 132.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:49:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 155.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:49:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 132.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:03+02:00 DEBUG metabase.server.middleware.log GET /api/user/ 200 7.8 ms (4 DB calls) App DB connections: 1/15 Jetty threads: 3/50 (4 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 110.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 110.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 103.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 255.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (96 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 157.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:50:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 129.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 134.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 136.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 154.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 177.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 136.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:51:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 143.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 168.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 226.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 129.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 132.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 145.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:52:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 444.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 136.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 155.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 138.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 176.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 159.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:53:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 164.2 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:54:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 133.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:54:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 141.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:54:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 109.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:54:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 109.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:01+02:00 DEBUG metabase.server.middleware.log GET /api/user/ 200 8.4 ms (4 DB calls) App DB connections: 1/15 Jetty threads: 3/50 (4 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 137.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 86.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 3/50 (4 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 153.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 158.1 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:55:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 138.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:02+02:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 19.0 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:02+02:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 25.2 ms (11 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:02+02:00 DEBUG metabase.server.middleware.log GET /api/database 200 7.7 ms (3 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 108.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 108.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 166.4 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 185.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 145.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:56:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 189.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (97 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 117.9 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 122.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 154.7 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 241.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 138.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:57:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 138.2 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:58:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 117.0 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:58:06+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 145.8 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:58:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 108.5 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:58:26+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 108.6 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:58:46+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 158.3 µs (0 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (95 total active threads) Queries in flight: 1 (0 queued)
[c0f01a80-d642-470f-95d2-3cc1af646970] 2024-05-22T16:59:22+02:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Query cancelled
{:database_id 2,
 :started_at #t ""2024-05-22T14:45:44.549202271Z[Etc/UTC]"",
 :action_id nil,
 :json_query
 {:database 2,
  :type ""query"",
  :query
  {:source-table 168,
   :joins
   [{:fields ""all"",
     :alias ""Audits"",
     :strategy ""full-join"",
     :condition
     [""="" [""field"" 2997 {:base-type ""type/Text""}] [""field"" 2997 {:base-type ""type/Text"", :join-alias ""Audits""}]],
     :source-table 168}
    {:fields ""all"",
     :alias ""Audits - Method"",
     :condition
     [""=""
      [""field"" 2997 {:base-type ""type/Text""}]
      [""field"" 2997 {:base-type ""type/Text"", :join-alias ""Audits - Method""}]],
     :source-table 168}],
   :filter
   [""and""
    [""time-interval"" [""field"" 2998 {:base-type ""type/Date""}] -12 ""month""]
    [""time-interval"" [""field"" 2998 {:base-type ""type/Date"", :join-alias ""Audits""}] -12 ""month""]
    [""time-interval"" [""field"" 2998 {:base-type ""type/Date"", :join-alias ""Audits - Method""}] -12 ""month""]]},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT `datalake.audits`.`id` AS `id`, `datalake.audits`.`method` AS `method`, [...] `Audits___Method`.`dt` AS `Audits___Method__dt` FROM `datalake.audits` FULL JOIN `datalake.audits` AS `Audits` ON `datalake.audits`.`method` = `Audits`.`method` LEFT JOIN `datalake.audits` AS `Audits___Method` ON `datalake.audits`.`method` = `Audits___Method`.`method` WHERE (`datalake.audits`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`datalake.audits`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) AND (`Audits`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`Audits`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) AND (`Audits___Method`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`Audits___Method`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) LIMIT 1048575"",
  :params nil,
  :table-name ""audits"",
  :mbql? true},
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:359)""
  ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:327)""
  ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:371)""
  ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:369)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__116482.invoke(bigquery_cloud_sdk.clj:419)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:427)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:412)""
  ""driver.bigquery_cloud_sdk$fn__116489.invokeStatic(bigquery_cloud_sdk.clj:448)""
  ""driver.bigquery_cloud_sdk$fn__116489.invoke(bigquery_cloud_sdk.clj:440)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72237.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66594.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72058.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72068.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71500.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73405$combined_post_process__73410$combined_post_process_STAR___73411.invoke(query_processor.clj:262)""
  ""query_processor$fn__73405$combined_pre_process__73406$combined_pre_process_STAR___73407.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66691.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148$fn__72152.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67318$fn__67319.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67318.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72145.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72450.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72085$handle_audit_app_internal_queries__72086$fn__72088.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72096.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71211.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72381.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72982.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62832$thunk__62834.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62832.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62844.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93918.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53261$fn__53263.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53261.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43756.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""Query cancelled"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 2,
  :type :query,
  :query
  {:source-table 168,
   :filter
   [:and
    [:>= [:field 2998 {:base-type :type/Date, :temporal-unit :default}] [:relative-datetime -12 :month]]
    [:< [:field 2998 {:base-type :type/Date, :temporal-unit :default}] [:relative-datetime 0 :month]]
    [:>=
     [:field 2998 {:base-type :type/Date, :join-alias ""Audits"", :temporal-unit :default}]
     [:relative-datetime -12 :month]]
    [:<
     [:field 2998 {:base-type :type/Date, :join-alias ""Audits"", :temporal-unit :default}]
     [:relative-datetime 0 :month]]
    [:>=
     [:field 2998 {:base-type :type/Date, :join-alias ""Audits___Method"", :temporal-unit :default}]
     [:relative-datetime -12 :month]]
    [:<
     [:field 2998 {:base-type :type/Date, :join-alias ""Audits___Method"", :temporal-unit :default}]
     [:relative-datetime 0 :month]]],
   :fields
   [[:field 2995 nil]
    [:field 2999 nil]
    [:field 3000 nil]
    [:field 2997 nil]
    [:field 2991 nil]
    [:field 2993 nil]
    [:field 2994 nil]
    [:field 2992 nil]
    [:field 3001 nil]
    [:field 2996 {:temporal-unit :default}]
    [:field 2998 {:temporal-unit :default}]
    [:field 2995 {:join-alias ""Audits""}]
    [:field 2999 {:join-alias ""Audits""}]
    [:field 3000 {:join-alias ""Audits""}]
    [:field 2997 {:join-alias ""Audits""}]
    [:field 2991 {:join-alias ""Audits""}]
    [:field 2993 {:join-alias ""Audits""}]
    [:field 2994 {:join-alias ""Audits""}]
    [:field 2992 {:join-alias ""Audits""}]
    [:field 3001 {:join-alias ""Audits""}]
    [:field 2996 {:temporal-unit :default, :join-alias ""Audits""}]
    [:field 2998 {:temporal-unit :default, :join-alias ""Audits""}]
    [:field 2995 {:join-alias ""Audits___Method""}]
    [:field 2999 {:join-alias ""Audits___Method""}]
    [:field 3000 {:join-alias ""Audits___Method""}]
    [:field 2997 {:join-alias ""Audits___Method""}]
    [:field 2991 {:join-alias ""Audits___Method""}]
    [:field 2993 {:join-alias ""Audits___Method""}]
    [:field 2994 {:join-alias ""Audits___Method""}]
    [:field 2992 {:join-alias ""Audits___Method""}]
    [:field 3001 {:join-alias ""Audits___Method""}]
    [:field 2996 {:temporal-unit :default, :join-alias ""Audits___Method""}]
    [:field 2998 {:temporal-unit :default, :join-alias ""Audits___Method""}]],
   :joins
   [{:alias ""Audits"",
     :strategy :full-join,
     :fields
     [[:field 2995 {:join-alias ""Audits""}]
      [:field 2999 {:join-alias ""Audits""}]
      [:field 3000 {:join-alias ""Audits""}]
      [:field 2997 {:join-alias ""Audits""}]
      [:field 2991 {:join-alias ""Audits""}]
      [:field 2993 {:join-alias ""Audits""}]
      [:field 2994 {:join-alias ""Audits""}]
      [:field 2992 {:join-alias ""Audits""}]
      [:field 3001 {:join-alias ""Audits""}]
      [:field 2996 {:temporal-unit :default, :join-alias ""Audits""}]
      [:field 2998 {:temporal-unit :default, :join-alias ""Audits""}]],
     :condition [:= [:field 2997 {:base-type :type/Text}] [:field 2997 {:base-type :type/Text, :join-alias ""Audits""}]],
     :source-table 168}
    {:alias ""Audits___Method"",
     :strategy :left-join,
     :fields
     [[:field 2995 {:join-alias ""Audits___Method""}]
      [:field 2999 {:join-alias ""Audits___Method""}]
      [:field 3000 {:join-alias ""Audits___Method""}]
      [:field 2997 {:join-alias ""Audits___Method""}]
      [:field 2991 {:join-alias ""Audits___Method""}]
      [:field 2993 {:join-alias ""Audits___Method""}]
      [:field 2994 {:join-alias ""Audits___Method""}]
      [:field 2992 {:join-alias ""Audits___Method""}]
      [:field 3001 {:join-alias ""Audits___Method""}]
      [:field 2996 {:temporal-unit :default, :join-alias ""Audits___Method""}]
      [:field 2998 {:temporal-unit :default, :join-alias ""Audits___Method""}]],
     :condition
     [:= [:field 2997 {:base-type :type/Text}] [:field 2997 {:base-type :type/Text, :join-alias ""Audits___Method""}]],
     :source-table 168}],
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 5, :context :ad-hoc, :alias/escaped->original {""Audits___Method"" ""Audits - Method""}}},
 :ex-data
 {:sql
  ""-- Metabase:: userID: 5 queryType: MBQL queryHash: f04d32a27958a21486a91f18cd5bf10eaeeebed16911989cb1e79d438924d1e4\nSELECT `datalake.audits`.`id` AS `id`, `datalake.audits`.`method` AS `method`, [...] `Audits___Method`.`dt` AS `Audits___Method__dt` FROM `datalake.audits` FULL JOIN `datalake.audits` AS `Audits` ON `datalake.audits`.`method` = `Audits`.`method` LEFT JOIN `datalake.audits` AS `Audits___Method` ON `datalake.audits`.`method` = `Audits___Method`.`method` WHERE (`datalake.audits`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`datalake.audits`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) AND (`Audits`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`Audits`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) AND (`Audits___Method`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -12 month), month)) AND (`Audits___Method`.`dt` < DATE_TRUNC(CURRENT_DATE(), month)) LIMIT 2000"",
  :parameters nil,
  :metabase.driver.bigquery-cloud-sdk/cancelled? true},
 :data {:rows [], :cols []}}

```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.11+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.11"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.11+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.58+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-22"",
      ""tag"": ""v0.49.7"",
      ""hash"": ""f0ff786""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying but non-blocking

### Additional context

Metabase version: 0.49.7 (I cannot update to see of the bug persists)

I looked into the source code of Metabase but can only find one occurrence of `MB_DB_CONNECTION_TIMEOUT_MS` in the Mango driver (as a comment) & in the doc file. I don't know much about Clojure or how Metabase gets env variables values, but I cannot see any reference to a timeout value in `modules/drivers/bigquery-cloud-sdk` so is this env variable even used ?",Timelessprod,2024-05-22 15:12:55+00:00,[],2024-05-23 09:38:44+00:00,2024-05-22 16:15:36+00:00,https://github.com/metabase/metabase/issues/43015,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2125172901, 'issue_id': 2310810034, 'author': 'paoliniluis', 'body': 'Do you have any reverse proxy cutting the conn after 60 secs?', 'created_at': datetime.datetime(2024, 5, 22, 16, 8, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2125177454, 'issue_id': 2310810034, 'author': 'likeshumidity', 'body': '@Timelessprod `MB_DB_CONNECTION_TIMEOUT_MS` is a timeout for the connection attempt to the database (how long to wait when attempting to connect to a database). It does not affect queries sent to the database when the connection has already been established. Does that make sense?\r\n\r\nI think what you are trying to do is cancel queries if they run more than X amount of time. Is that correct?', 'created_at': datetime.datetime(2024, 5, 22, 16, 10, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2125189610, 'issue_id': 2310810034, 'author': 'likeshumidity', 'body': '@Timelessprod I think you want https://github.com/metabase/metabase/issues/41685\r\n\r\nClosing this issue for now, but please update to re-open if I misunderstood you.', 'created_at': datetime.datetime(2024, 5, 22, 16, 15, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2126434882, 'issue_id': 2310810034, 'author': 'Timelessprod', 'body': ""> @Timelessprod `MB_DB_CONNECTION_TIMEOUT_MS` is a timeout for the connection attempt to the database (how long to wait when attempting to connect to a database). It does not affect queries sent to the database when the connection has already been established. Does that make sense?\r\n> \r\n> I think what you are trying to do is cancel queries if they run more than X amount of time. Is that correct?\r\n\r\nYes that's what I'm looking for and I thought this variable would also handle this as when I increased its value the query are running for longer time before cancellation (thus the variable seems to have an effect somehow). If not what should I use ?"", 'created_at': datetime.datetime(2024, 5, 23, 7, 39, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2126668428, 'issue_id': 2310810034, 'author': 'Timelessprod', 'body': ""> Contributor\r\n\r\nThere's no reverse proxy set up between Metabase and our database (BigQuery)."", 'created_at': datetime.datetime(2024, 5, 23, 9, 38, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-22 16:08:45 UTC): Do you have any reverse proxy cutting the conn after 60 secs?

likeshumidity on (2024-05-22 16:10:53 UTC): @Timelessprod `MB_DB_CONNECTION_TIMEOUT_MS` is a timeout for the connection attempt to the database (how long to wait when attempting to connect to a database). It does not affect queries sent to the database when the connection has already been established. Does that make sense?

I think what you are trying to do is cancel queries if they run more than X amount of time. Is that correct?

likeshumidity on (2024-05-22 16:15:36 UTC): @Timelessprod I think you want https://github.com/metabase/metabase/issues/41685

Closing this issue for now, but please update to re-open if I misunderstood you.

Timelessprod (Issue Creator) on (2024-05-23 07:39:05 UTC): Yes that's what I'm looking for and I thought this variable would also handle this as when I increased its value the query are running for longer time before cancellation (thus the variable seems to have an effect somehow). If not what should I use ?

Timelessprod (Issue Creator) on (2024-05-23 09:38:25 UTC): There's no reverse proxy set up between Metabase and our database (BigQuery).

"
2310802514,issue,closed,completed,Improve browse models table render performance,"Currently, on an instance with 1000 models (which is admittedly greater than 99% of current metabase users), rendering this table takes 10+ seconds and completely locks up the UI. Also sometimes causes chrome to go OOM and the tab to crash.

3 possible approaches (or some combination)
- virtualize the table
- paginate the table
- use a different table component with less render overhead",iethree,2024-05-22 15:09:41+00:00,"['rafpaf', 'iethree']",2024-05-28 22:53:31+00:00,2024-05-28 22:53:31+00:00,https://github.com/metabase/metabase/issues/43014,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness')]",[],
2310734855,issue,closed,completed,The UI will keep calling /logs after you leave the troubleshooting->logs page,"### Describe the bug

If you go to the logs page and then leave, the browser will keep calling the logs endpoint
![image](https://github.com/metabase/metabase/assets/1711649/6aa65b44-2c8a-48c9-b313-1bcab31af6a5)


### To Reproduce

1) go to troubleshooting->logs
2) leave
3) see in the network tab that it's still calling the logs endpoint

### Expected behavior

It should not keep calling the endpoint once you leave

### Logs

NA

### Information about your Metabase installation

```JSON
- v50
- brave
```


### Severity

P2-3

### Additional context

_No response_",paoliniluis,2024-05-22 14:41:15+00:00,[],2024-07-05 07:30:42+00:00,2024-07-04 21:44:55+00:00,https://github.com/metabase/metabase/issues/43010,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2310622707,issue,closed,completed,[Epic] Time-over-time comparison UI for aggregated columns,"**Links**
- product doc: [Time-over-time comparison UI for aggregated columns](https://www.notion.so/metabase/Time-over-time-comparison-UI-for-aggregated-columns-032bb9b47d124731baa9c3c7f954727f)
- eng doc: [[Tech] Time-over-time comparison UI for aggregated columns](https://www.notion.so/metabase/Time-over-time-comparison-UI-for-aggregated-columns-d06c46884d924bb99b814ec9d8f9b114)
- feature branch: ~`time-over-time-comparison`~ PRs can go straight to `master`
- issue links:
    - #40313

## Implementation Plan

### Milestone 1

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/43079
- [ ] https://github.com/metabase/metabase/issues/43070
- [ ] https://github.com/metabase/metabase/issues/43178
- [ ] https://github.com/metabase/metabase/issues/43071
- [ ] https://github.com/metabase/metabase/issues/43072
- [ ] https://github.com/metabase/metabase/issues/43073
```


",kamilmielnik,2024-05-22 14:00:50+00:00,['kamilmielnik'],2024-06-10 12:18:00+00:00,2024-06-10 11:56:49+00:00,https://github.com/metabase/metabase/issues/43006,"[('.Epic', 'Feature Implementation or Project')]",[],
2310436474,issue,closed,completed,"""Duplicate Dashboard"" messes up last used filter values - one dashboard overrides another","**Context**

We're facing wrong logic for duplicated dashboards. it turned out, when we make a deep clone of the dashboard (duplicate), all filters are cloned with the same ids so currently if I change a main dashboard's filter, duplicated dashboard will be affected as well

logic related to dashboard copy ignores `parameters` and `dashcards` sent from FE, so we can't override it on our side
https://github.com/metabase/metabase/blob/master/src/metabase/api/dashboard.clj#L364-L412

Current logic of setting `last_used_param_values` presumes we have unique filter ids, so some of those places should be fixed
https://github.com/metabase/metabase/pull/40415/files#diff-4191aab4baca759a3e1663cbe6c28268c326d418f224f12717f00be32dd47583R38-R50



https://github.com/metabase/metabase/assets/125459446/e29ffdba-c080-4c1e-b1d8-55778d30c202


caught by CI https://github.com/metabase/metabase/actions/runs/9163281195/job/25192372653?pr=42777
",uladzimirdev,2024-05-22 12:41:33+00:00,['adam-james-v'],2024-07-03 22:06:32+00:00,2024-07-03 22:06:31+00:00,https://github.com/metabase/metabase/issues/43001,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2310322427,issue,closed,completed,Cannot drill to a question via title when dashboard has a filter with multiple values applied,"### Describe the bug

```
core.cljs:328 Uncaught (in promise) Error: No protocol method IAssociative.-assoc defined for type number: 16
    at Object.cljs$core$missing_protocol [as missing_protocol] (core.cljs:328:1)
    at cljs$core$IAssociative$_assoc$dyn_117294 (core.cljs:644:1)
    at Object.cljs$core$_assoc [as _assoc] (core.cljs:644:1)
    at Function.cljs$core$IFn$_invoke$arity$3 (core.cljs:2042:1)
    at common.cljc:137:1
    at core.cljc:183:1
    at core.cljc:1630:1
    at core.cljc:195:1
    at malli$core$_update (core.cljc:195:1)
    at core.cljs:7117:1
```

### To Reproduce

e2e repro: #43000

----

1. Create a question based on Orders table with limit 5
2. Add the question to a dashboard
3. Add ""Text or Category"" > ""Contains"" filter
    - can be reproduced with ""Contains"", ""Does not contain"", ""Starts with"" and ""Ends with"" filters
5. Enable multiple values on it (important)
6. Connect the filter to ""User"" > ""Source"" column
7. Set filter value to `oo` and `aa` ([image](https://github.com/metabase/metabase/assets/6830683/b84dcc15-a92d-4d22-9455-52257f322a41))
8. Apply the filter
9. Click title of the dashcard

You should be navigated to an ad-hoc question in the query builder, but there's an error in JS console instead, nothing happens in UI.

### Information about your Metabase installation

master, 9dbfae2e17


### Severity

P2
",kamilmielnik,2024-05-22 11:45:22+00:00,['bshepherdson'],2024-08-28 02:09:50+00:00,2024-06-12 07:14:45+00:00,https://github.com/metabase/metabase/issues/42999,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2124648050, 'issue_id': 2310322427, 'author': 'kamilmielnik', 'body': 'Please revert this commit when fixing the issue: d7ff869173684a9f86ee61a5b8fb8d5ae893ab5b', 'created_at': datetime.datetime(2024, 5, 22, 12, 15, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2162280420, 'issue_id': 2310322427, 'author': 'kamilmielnik', 'body': 'Closing as duplicate of #43990', 'created_at': datetime.datetime(2024, 6, 12, 7, 14, 45, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-22 12:15:49 UTC): Please revert this commit when fixing the issue: d7ff869173684a9f86ee61a5b8fb8d5ae893ab5b

kamilmielnik (Issue Creator) on (2024-06-12 07:14:45 UTC): Closing as duplicate of #43990

"
2309929928,issue,closed,not_planned,[Epic] Modularized Search,"**Links**
- product doc: https://www.notion.so/metabase/Modularize-and-improve-search-e5b7ecb42cc642dabc374a1b5705a2c6
- eng docs:
  - https://www.notion.so/metabase/Search-Modularization-part-1-7f3ed9b914a5455fbe311d25af565daa
  - https://www.notion.so/metabase/Search-Modularization-part-2-d9cd42174d6d4be785833599771441d6
- feature branch: none yet
- issue links: _related issues if any_

**Implementation Plan**


***Milestone 1***

- [ ] Rewrite model scoring to be a registry of only outliers
- [ ] Combine ""model registration"" as a single multimethod
- [ ] Move model registration code to respectful model files
- [ ] Push out all model-specific clauses to a multimethod

***Milestone 2***
",darksciencebase,2024-05-22 08:39:26+00:00,[],2024-09-03 08:29:50+00:00,2024-09-03 08:29:37+00:00,https://github.com/metabase/metabase/issues/42997,"[('Organization/Search', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2296697668, 'issue_id': 2309929928, 'author': 'calherries', 'body': 'most recently, we decided to start on getting all searchable data into one table. see the first milestone plan [here](https://www.notion.so/metabase/Search-Modularization-d9cd42174d6d4be785833599771441d6?pvs=4#84e898b77752454e8549bbf9e907b440).\r\n\r\na prototype/POC for this was started in this PR: https://github.com/metabase/metabase/pull/43986', 'created_at': datetime.datetime(2024, 8, 19, 14, 19, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325910520, 'issue_id': 2309929928, 'author': 'crisptrutski', 'body': 'Superseded by https://github.com/metabase/metabase/issues/40964', 'created_at': datetime.datetime(2024, 9, 3, 8, 29, 38, tzinfo=datetime.timezone.utc)}]","calherries on (2024-08-19 14:19:32 UTC): most recently, we decided to start on getting all searchable data into one table. see the first milestone plan [here](https://www.notion.so/metabase/Search-Modularization-d9cd42174d6d4be785833599771441d6?pvs=4#84e898b77752454e8549bbf9e907b440).

a prototype/POC for this was started in this PR: https://github.com/metabase/metabase/pull/43986

crisptrutski on (2024-09-03 08:29:38 UTC): Superseded by https://github.com/metabase/metabase/issues/40964

"
2309916420,issue,closed,completed,[Epic] Notifications,"**Links**
- product doc: https://www.notion.so/metabase/Notifications-and-data-delivery-c74c10e1fb2a418980a4c5e82ac91961
- eng doc: [_link to technical design doc, if any_](https://www.notion.so/metabase/Notification-high-level-design-9620a4a69db0494f806a146cc9174964)
- feature branch: none yet
- issue links: 

**Implementation Plan**


***Milestone 1***
_insert tasklist here_

***Milestone 2***

",darksciencebase,2024-05-22 08:32:36+00:00,"['piranha', 'crisptrutski', 'qnkhuat']",2024-06-10 08:24:07+00:00,2024-06-10 08:24:07+00:00,https://github.com/metabase/metabase/issues/42996,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2157685760, 'issue_id': 2309916420, 'author': 'darksciencebase', 'body': ""closing in favor of the actual projects (this was for the arc planning, and we've done what we wanted)"", 'created_at': datetime.datetime(2024, 6, 10, 8, 24, 7, tzinfo=datetime.timezone.utc)}]","darksciencebase (Issue Creator) on (2024-06-10 08:24:07 UTC): closing in favor of the actual projects (this was for the arc planning, and we've done what we wanted)

"
2309661976,issue,open,,Dashboard filters fail to perform fuzzy queries and a query failure error occurs.,"### Describe the bug

The global filter in the dashboard is not indexing the data properly and the containing pattern is not queried and displayed properly, and the filter is not working properly.

### To Reproduce

1. Go to 'Dashboard'
2. Click on 'Add Filters'
3. choose the 'contain' mode filters
4. enter keyword


### Expected behavior

I think the filter here should be able to query the relevant values normally through fuzzy matching and give me the selection without errors.

### Logs

[42a4e49e-5d6c-4ee9-87cd-582ac696119c] 2024-05-22T12:22:31+08:00 ERROR metabase.server.middleware.log GET /api/dashboard/6/params/eaeaf252/search/%E9%87%91%E5%B1%B1 500 20.7 ms（14个数据库调用） 
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message ""执行链式筛选器查询时出错"",
   :data
   {:field-id 10512,
    :constraints [{:field-id 10512, :op :contains, :value ""金山"", :options {:case-sensitive false}}],
    :mbql-query
    {:database 3,
     :type :query,
     :query
     {:source-table 389,
      :breakout [[:field 10512 nil]],
      :limit 1000,
      :filter [:contains [:field 10512 nil] ""金山"" {:case-sensitive false}]},
     :middleware {:disable-remaps? true}}},
   :at [metabase.models.params.chain_filter$unremapped_chain_filter invokeStatic ""chain_filter.clj"" 453]}
  {:type java.lang.RuntimeException,
   :message
   ""[:ref :metabase.mbql.schema/value] is not a valid sequence schema; a valid sequence schema consists of zero or more `one` elements, followed by zero or more `optional` elements, followed by an optional schema that will match the remaining elements."",
   :at [schema.core$parse_sequence_schema invokeStatic ""core.cljc"" 940]}],
 :trace
 [[schema.core$parse_sequence_schema invokeStatic ""core.cljc"" 940]
  [schema.core$parse_sequence_schema invoke ""core.cljc"" 932]
  [schema.core$fn__5625 invokeStatic ""core.cljc"" 958]
  [schema.core$fn__5625 invoke ""core.cljc"" 948]
  [schema.core$fn__4702$G__4684__4707 invoke ""core.cljc"" 96]
  [schema.core$checker$fn__4726 invoke ""core.cljc"" 128]
  [schema.spec.core$sub_checker$fn__4514 invoke ""core.cljc"" 95]
  [schema.spec.core$with_cache invokeStatic ""core.cljc"" 83]
  [schema.spec.core$with_cache invoke ""core.cljc"" 74]
  [schema.spec.core$sub_checker invokeStatic ""core.cljc"" 93]
  [schema.spec.core$sub_checker invoke ""core.cljc"" 88]
  [schema.spec.variant$option_step invokeStatic ""variant.cljc"" 14]
  [schema.spec.variant$option_step invoke ""variant.cljc"" 12]
  [schema.spec.variant.VariantSpec$fn__4578 invoke ""variant.cljc"" 47]
  [clojure.lang.PersistentList reduce ""PersistentList.java"" 141]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [schema.spec.variant.VariantSpec checker ""variant.cljc"" 45]
  [schema.core$checker$fn__4726 invoke ""core.cljc"" 128]
  [schema.spec.core$sub_checker$fn__4514 invoke ""core.cljc"" 95]
  [schema.spec.core$with_cache invokeStatic ""core.cljc"" 83]
  [schema.spec.core$with_cache invoke ""core.cljc"" 74]
  [schema.spec.core$sub_checker invokeStatic ""core.cljc"" 93]
  [schema.spec.core$sub_checker invoke ""core.cljc"" 88]
  [schema.spec.variant$option_step invokeStatic ""variant.cljc"" 14]
  [schema.spec.variant$option_step invoke ""variant.cljc"" 12]
  [schema.spec.variant.VariantSpec$fn__4578 invoke ""variant.cljc"" 47]
  [clojure.lang.PersistentList reduce ""PersistentList.java"" 141]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [schema.spec.variant.VariantSpec checker ""variant.cljc"" 45]
  [schema.core$checker$fn__4726 invoke ""core.cljc"" 128]
  [schema.spec.core$sub_checker$fn__4514 invoke ""core.cljc"" 95]
  [schema.spec.core$with_cache invokeStatic ""core.cljc"" 83]
  [schema.spec.core$with_cache invoke ""core.cljc"" 74]
  [schema.spec.core$sub_checker invokeStatic ""core.cljc"" 93]
  [schema.spec.core$sub_checker invoke ""core.cljc"" 88]
  [schema.spec.collection$element_transformer invokeStatic ""collection.cljc"" 34]
  [schema.spec.collection$element_transformer invoke ""collection.cljc"" 16]
  [schema.spec.collection$sequence_transformer$fn__4631 invoke ""collection.cljc"" 45]
  [clojure.lang.PersistentList reduce ""PersistentList.java"" 144]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [schema.spec.collection$sequence_transformer invokeStatic ""collection.cljc"" 43]
  [schema.spec.collection$sequence_transformer invoke ""collection.cljc"" 40]
  [schema.spec.collection.CollectionSpec checker ""collection.cljc"" 75]
  [schema.core$checker$fn__4726 invoke ""core.cljc"" 128]
  [schema.spec.core$run_checker invokeStatic ""core.cljc"" 68]
  [schema.spec.core$run_checker invoke ""core.cljc"" 64]
  [schema.core$checker invokeStatic ""core.cljc"" 127]
  [schema.core$checker invoke ""core.cljc"" 122]
  [metabase.driver.clickhouse_qp$fn__90901$fn__90904 invoke ""clickhouse_qp.clj"" 293]
  [clojure.lang.Delay deref ""Delay.java"" 42]
  [clojure.core$deref invokeStatic ""core.clj"" 2337]
  [clojure.core$deref invoke ""core.clj"" 2323]
  [metabase.driver.clickhouse_qp$fn__90901$update_string_value__90908 invoke ""clickhouse_qp.clj"" 293]
  [metabase.driver.clickhouse_qp$fn__90923 invokeStatic ""clickhouse_qp.clj"" 301]
  [metabase.driver.clickhouse_qp$fn__90923 invoke ""clickhouse_qp.clj"" 297]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
  [metabase.driver.sql.query_processor$fn__66125 invokeStatic ""query_processor.clj"" 1168]
  [metabase.driver.sql.query_processor$fn__66125 invoke ""query_processor.clj"" 1166]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 244]
  [metabase.driver.sql.query_processor$apply_top_level_clauses$fn__66231 invoke ""query_processor.clj"" 1407]
  [clojure.lang.ArraySeq reduce ""ArraySeq.java"" 119]
  [clojure.core$transduce invokeStatic ""core.clj"" 6947]
  [clojure.core$transduce invoke ""core.clj"" 6934]
  [metabase.driver.sql.query_processor$apply_top_level_clauses invokeStatic ""query_processor.clj"" 1401]
  [metabase.driver.sql.query_processor$apply_top_level_clauses invoke ""query_processor.clj"" 1394]
  [metabase.driver.sql.query_processor$apply_top_level_clauses invokeStatic ""query_processor.clj"" 1398]
  [metabase.driver.sql.query_processor$apply_top_level_clauses invoke ""query_processor.clj"" 1394]
  [metabase.driver.sql.query_processor$apply_clauses invokeStatic ""query_processor.clj"" 1464]
  [metabase.driver.sql.query_processor$apply_clauses invoke ""query_processor.clj"" 1452]
  [metabase.driver.sql.query_processor$mbql__GT_honeysql invokeStatic ""query_processor.clj"" 1484]
  [metabase.driver.sql.query_processor$mbql__GT_honeysql invoke ""query_processor.clj"" 1478]
  [metabase.driver.sql.query_processor$mbql__GT_native invokeStatic ""query_processor.clj"" 1493]
  [metabase.driver.sql.query_processor$mbql__GT_native invoke ""query_processor.clj"" 1489]
  [metabase.driver.sql$fn__83259 invokeStatic ""sql.clj"" 49]
  [metabase.driver.sql$fn__83259 invoke ""sql.clj"" 47]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
  [metabase.query_processor.middleware.mbql_to_native$query__GT_native_form invokeStatic ""mbql_to_native.clj"" 14]
  [metabase.query_processor.middleware.mbql_to_native$query__GT_native_form invoke ""mbql_to_native.clj"" 9]
  [metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71426 invoke ""mbql_to_native.clj"" 21]
  [metabase.query_processor$fn__73331$combined_post_process__73336$combined_post_process_STAR___73337
   invoke
   ""query_processor.clj""
   262]
  [metabase.query_processor$fn__73331$combined_pre_process__73332$combined_pre_process_STAR___73333
   invoke
   ""query_processor.clj""
   259]
  [metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66617
   invoke
   ""fetch_source_query.clj""
   303]
  [metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72074$fn__72078
   invoke
   ""resolve_database_and_driver.clj""
   77]
  [metabase.driver$do_with_driver invokeStatic ""driver.clj"" 97]
  [metabase.driver$do_with_driver invoke ""driver.clj"" 92]
  [metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72074
   invoke
   ""resolve_database_and_driver.clj""
   76]
  [metabase.query_processor.middleware.store$initialize_store$fn__67244$fn__67245 invoke ""store.clj"" 14]
  [metabase.query_processor.store$do_with_metadata_provider invokeStatic ""store.clj"" 169]
  [metabase.query_processor.store$do_with_metadata_provider invoke ""store.clj"" 150]
  [metabase.query_processor.store$do_with_metadata_provider invokeStatic ""store.clj"" 158]
  [metabase.query_processor.store$do_with_metadata_provider invoke ""store.clj"" 150]
  [metabase.query_processor.middleware.store$initialize_store$fn__67244 invoke ""store.clj"" 13]
  [metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72071
   invoke
   ""resolve_database_and_driver.clj""
   60]
  [metabase.query_processor.middleware.normalize_query$normalize$fn__72376 invoke ""normalize_query.clj"" 38]
  [metabase.query_processor.middleware.enterprise$fn__72011$handle_audit_app_internal_queries__72012$fn__72014
   invoke
   ""enterprise.clj""
   96]
  [metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72022
   invoke
   ""enterprise.clj""
   103]
  [metabase.query_processor.reducible$async_qp$qp_STAR___62758$thunk__62760 invoke ""reducible.clj"" 126]
  [metabase.query_processor.reducible$async_qp$qp_STAR___62758 invoke ""reducible.clj"" 132]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.query_processor.reducible$sync_qp$qp_STAR___62770 doInvoke ""reducible.clj"" 153]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.query_processor$process_query invokeStatic ""query_processor.clj"" 311]
  [metabase.query_processor$process_query invoke ""query_processor.clj"" 291]
  [metabase.query_processor$process_query invokeStatic ""query_processor.clj"" 299]
  [metabase.query_processor$process_query invoke ""query_processor.clj"" 291]
  [metabase.query_processor$process_query invokeStatic ""query_processor.clj"" 296]
  [metabase.query_processor$process_query invoke ""query_processor.clj"" 291]
  [metabase.db.metadata_queries$qp_query$fn__80831 invoke ""metadata_queries.clj"" 22]
  [metabase.db.metadata_queries$qp_query invokeStatic ""metadata_queries.clj"" 21]
  [metabase.db.metadata_queries$qp_query invoke ""metadata_queries.clj"" 19]
  [metabase.db.metadata_queries$field_query invokeStatic ""metadata_queries.clj"" 78]
  [metabase.db.metadata_queries$field_query invoke ""metadata_queries.clj"" 75]
  [metabase.db.metadata_queries$search_values_query invokeStatic ""metadata_queries.clj"" 126]
  [metabase.db.metadata_queries$search_values_query invoke ""metadata_queries.clj"" 120]
  [metabase.api.field$search_values invokeStatic ""field.clj"" 398]
  [metabase.api.field$search_values invoke ""field.clj"" 370]
  [metabase.api.field$fn__93834 invokeStatic ""field.clj"" 414]
  [metabase.api.field$fn__93834 invoke ""field.clj"" 403]
  [compojure.core$wrap_response$fn__44649 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__44633 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__44638 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661 invoke ""core.clj"" 200]
  [metabase.server.middleware.auth$enforce_authentication$fn__93977 invoke ""auth.clj"" 17]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__44689 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [metabase.api.routes$fn__101970$fn__101973 invoke ""routes.clj"" 67]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__102135$fn__102136 doInvoke ""routes.clj"" 72]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__44689 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__44693 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__44642 invoke ""core.clj"" 152]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661$f__44662$respond_SINGLEQUOTE___44663 invoke ""core.clj"" 197]
  [metabase.server.routes$fn__102120$fn__102122 invoke ""routes.clj"" 49]
  [compojure.core$routes$fn__44661$f__44662 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__44661 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98743 invoke ""exceptions.clj"" 108]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__98740 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__102404$fn__102405$fn__102406 invoke ""log.clj"" 216]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__102404$fn__102405 invoke ""log.clj"" 208]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__102404 invoke ""log.clj"" 207]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104439 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__84865 invoke ""security.clj"" 182]
  [metabase.server.middleware.json$wrap_json_body$fn__46006 invoke ""json.clj"" 67]
  [metabase.server.middleware.offset_paging$handle_paging$fn__84889 invoke ""offset_paging.clj"" 62]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__46024 invoke ""json.clj"" 103]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__104706 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__104725 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__67159 invoke ""misc.clj"" 61]
  [metabase.server.middleware.session$reset_session_timeout$fn__72582 invoke ""session.clj"" 543]
  [metabase.server.middleware.session$bind_current_user$fn__72548$fn__72549 invoke ""session.clj"" 438]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 417]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 401]
  [metabase.server.middleware.session$bind_current_user$fn__72548 invoke ""session.clj"" 437]
  [metabase.server.middleware.session$wrap_current_user_info$fn__72531 invoke ""session.clj"" 376]
  [metabase.server.middleware.session$wrap_session_id$fn__72503 invoke ""session.clj"" 255]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__93985 invoke ""auth.clj"" 30]
  [ring.middleware.cookies$wrap_cookies$fn__104626 invoke ""cookies.clj"" 194]
  [metabase.server.middleware.misc$add_content_type$fn__67141 invoke ""misc.clj"" 29]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__67167 invoke ""misc.clj"" 78]
  [ring.middleware.gzip$wrap_gzip$fn__104668 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__67170 invoke ""misc.clj"" 95]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104455 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__67581 invoke ""server.clj"" 78]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause
 ""[:ref :metabase.mbql.schema/value] is not a valid sequence schema; a valid sequence schema consists of zero or more `one` elements, followed by zero or more `optional` elements, followed by an optional schema that will match the remaining elements."",
 :message ""执行链式筛选器查询时出错"",
 :field-id 10512,
 :constraints [{:field-id 10512, :op :contains, :value ""金山"", :options {:case-sensitive false}}],
 :mbql-query
 {:database 3,
  :type :query,
  :query
  {:source-table 389,
   :breakout [[:field 10512 nil]],
   :limit 1000,
   :filter [:contains [:field 10512 nil] ""金山"" {:case-sensitive false}]},
  :middleware {:disable-remaps? true}}}

### Information about your Metabase installation

```JSON
- System: MacOS Sonoma
- Browser：Google Chrome 124.0.6367.208 (arm64)
- Metabase: 0.49.4
```


### Severity

Affects experience, but not urgent

### Additional context
![image](https://github.com/metabase/metabase/assets/89243554/29d0d4d7-d602-4d63-9670-02f809023ab4)
![image](https://github.com/metabase/metabase/assets/89243554/5efcde89-9404-4c38-9a9d-c10e526f7aaf)
![image](https://github.com/metabase/metabase/assets/89243554/470088aa-4c39-49fe-8cea-f44a99a8d7cb)
![image](https://github.com/metabase/metabase/assets/89243554/dcc4efcc-7183-48d4-805d-affd4ca00222)
",ONES-ZHUJIAQI,2024-05-22 06:17:45+00:00,[],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/42995,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', ''), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2124024866, 'issue_id': 2309661976, 'author': 'ONES-ZHUJIAQI', 'body': 'I found that this error is mainly related to the contains query.\r\n\r\n[:ref :metabase.mbql.schema/value] is not a valid sequence schema; a valid sequence schema consists of zero or more `one` elements, followed by zero or more `optional` elements, followed by an optional schema that will match the remaining elements.', 'created_at': datetime.datetime(2024, 5, 22, 7, 5, 52, tzinfo=datetime.timezone.utc)}]","ONES-ZHUJIAQI (Issue Creator) on (2024-05-22 07:05:52 UTC): I found that this error is mainly related to the contains query.

[:ref :metabase.mbql.schema/value] is not a valid sequence schema; a valid sequence schema consists of zero or more `one` elements, followed by zero or more `optional` elements, followed by an optional schema that will match the remaining elements.

"
2309116230,issue,closed,completed,disable invalid move targets in the recents tab (needs recents API update: effective_location),"the collection/id/items endpoint populates each item's full `effective_path` and the frontend uses this information to provide a nice collection-moving experience by disabling any item that is a child of the moving collection (you can't move something into itself).  The recents api lacks this information, so we have to rely on a backend API error, instead of filtering/disabling invalid choices at the outset.

![Screen Shot 2024-05-21 at 3 13 36 PM](https://github.com/metabase/metabase/assets/30528226/4250a610-e0dd-4534-aba9-2be01774c542)


It's not awful, but we can do better.


If we can get effective paths populated on the recents endpoint, we can do the same nice UI magic that we do with the collection items endpoint

",iethree,2024-05-21 21:07:26+00:00,['escherize'],2024-06-25 18:37:27+00:00,2024-05-28 17:09:31+00:00,https://github.com/metabase/metabase/issues/42980,[],"[{'comment_id': 2123556750, 'issue_id': 2309116230, 'author': 'escherize', 'body': ""As of https://github.com/metabase/metabase/pull/42813 we only send back `effective_parent`s in the recents api. **Would it be helpful to send you the effective_path on recent items with model=`collection`?** (We need to calculate that to get the effective_parent, to show a collection's parent collection correctly, so it would be very easy to do)."", 'created_at': datetime.datetime(2024, 5, 21, 22, 48, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2135741457, 'issue_id': 2309116230, 'author': 'escherize', 'body': 'Closed by #43018', 'created_at': datetime.datetime(2024, 5, 28, 17, 9, 31, tzinfo=datetime.timezone.utc)}]","escherize (Assginee) on (2024-05-21 22:48:55 UTC): As of https://github.com/metabase/metabase/pull/42813 we only send back `effective_parent`s in the recents api. **Would it be helpful to send you the effective_path on recent items with model=`collection`?** (We need to calculate that to get the effective_parent, to show a collection's parent collection correctly, so it would be very easy to do).

escherize (Assginee) on (2024-05-28 17:09:31 UTC): Closed by #43018

"
2309116163,issue,closed,completed,show parent collections for collection search items (needs search API update),"Currently, collection search results populate .... themselves ... as their parent collection, so we ignore this on the frontend, but it would be nice to have an actual parent collection hydrated so that we can show it in the entity picker search ui like we do for other entities

collections | questions
---|---
![Screen Shot 2024-05-21 at 3 09 45 PM](https://github.com/metabase/metabase/assets/30528226/843f7c70-4c0c-4203-936b-b00aee24efe8) | ![Screen Shot 2024-05-21 at 3 09 56 PM](https://github.com/metabase/metabase/assets/30528226/f49d5f6c-b426-495d-b3eb-40ec22044da0)

",iethree,2024-05-21 21:07:23+00:00,['noahmoss'],2024-06-14 18:11:31+00:00,2024-06-14 18:11:31+00:00,https://github.com/metabase/metabase/issues/42979,[],[],
2309076126,issue,closed,completed,"Data picker search shows tables in ""our analytics"" instead of in db/schema","I think we need some special logic to show the containing metadata for tables, and probably metrics too.

(all the pictures search results are tables, and work properly, but look like questions in the our analytics collection)


![Screen Shot 2024-05-21 at 2 37 05 PM](https://github.com/metabase/metabase/assets/30528226/3fcc27a7-644e-4d14-b629-366eeb5199cb)
",iethree,2024-05-21 20:38:57+00:00,['iethree'],2024-05-23 11:32:04+00:00,2024-05-23 11:32:03+00:00,https://github.com/metabase/metabase/issues/42978,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Correctness', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2309066504,issue,closed,completed,disable creating new items from the recents screen, (no way to know where they're going),iethree,2024-05-21 20:32:09+00:00,['iethree'],2024-05-24 19:03:39+00:00,2024-05-24 19:03:39+00:00,https://github.com/metabase/metabase/issues/42976,[],[],
2308968104,issue,closed,completed,"In Admin / Performance, form is still considered dirty after a certain kind of change is saved","### Describe the bug

On Admin / Performance, after deleting the multiplier from the Adaptive strategy and then saving changes, the form is still considered dirty and asks to abandon changes when I click a different database




### To Reproduce

   https://jam.dev/c/66517dcb-5030-4aaa-a630-2474d6507f7b

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""druid"",
      ""postgres"",
      ""redshift"",
      ""mysql"",
      ""bigquery-cloud-sdk"",
      ""mongo"",
      ""h2"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-21"",
      ""tag"": ""vUNKNOWN"",
      ""hash"": ""9771eaa""
    },
    ""settings"": {
      ""report-timezone"": ""US/Pacific""
    }
  }
}
```


### Severity

P4

### Additional context

_No response_",rafpaf,2024-05-21 19:32:00+00:00,['rafpaf'],2024-09-10 15:34:07+00:00,2024-08-28 14:10:04+00:00,https://github.com/metabase/metabase/issues/42974,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2308690576,issue,closed,completed,[Browse] Add blue dot to verified filter,,rafpaf,2024-05-21 16:36:20+00:00,[],2024-10-08 17:09:21+00:00,2024-06-04 14:33:43+00:00,https://github.com/metabase/metabase/issues/42964,[],[],
2308673807,issue,closed,completed,Make migrated archived items more metabasey,"Items that are migrated feel a bit hard to use. In the previous version, there was some mysterious action at hand, but it would still unarchive a tree.

```
OurAnalytics
└── A
    └── B
        └── C
            └── card
```
Example suppose collections `A > B > C` and in `C` is a `card`. In the archive, each of these would appear as top level in the archive, but if you unarchived `B`, it would unarchive `C` and `card`.

In the trash, you cannot unarchive `B`. If you _move_ `B`, it will only move that collection and not any of it's children. Also, if you were to restore `A`, it would not restore any of its children.

This feels a bit more understandable. Certainly the old way was quite wild in honoring the hierarchy without showing it, i'm just worried it might be a bit too tedious.",dpsutton,2024-05-21 16:25:44+00:00,['johnswanson'],2024-06-14 12:29:26+00:00,2024-06-14 12:29:26+00:00,https://github.com/metabase/metabase/issues/42963,[],[],
2308559754,issue,closed,completed,Tweak appearance of cache page and form,,rafpaf,2024-05-21 15:23:57+00:00,['rafpaf'],2024-06-10 20:43:00+00:00,2024-05-28 21:30:51+00:00,https://github.com/metabase/metabase/issues/42958,[],[],
2308535988,issue,closed,completed,Empty collections shown in Data Picker,"### Describe the bug

[Slack thread](https://metaboat.slack.com/archives/C02H619CJ8K/p1716303539629889?thread_ts=1716303478.270139&cid=C02H619CJ8K)

### To Reproduce

1. Create a model 
2. Create a collection and add a question to it (but not the model from step 1)
3. Start a new question
4. Open Models tab

Collection created in step 2 should not be visible

### Information about your Metabase installation

master, c09ec3ddeb


### Severity

P2
",kamilmielnik,2024-05-21 15:11:35+00:00,['kamilmielnik'],2024-05-23 06:57:28+00:00,2024-05-23 06:57:28+00:00,https://github.com/metabase/metabase/issues/42957,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2122988064, 'issue_id': 2308535988, 'author': 'iethree', 'body': ""@kamilmielnik , I see you added the v50 milestone. I thought metrics weren't in 50?"", 'created_at': datetime.datetime(2024, 5, 21, 16, 18, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2124098893, 'issue_id': 2308535988, 'author': 'kamilmielnik', 'body': ""@iethree The issue is not metrics-specific, repro steps just happened to be. I changed it to models so it's clear."", 'created_at': datetime.datetime(2024, 5, 22, 7, 47, 17, tzinfo=datetime.timezone.utc)}]","iethree on (2024-05-21 16:18:45 UTC): @kamilmielnik , I see you added the v50 milestone. I thought metrics weren't in 50?

kamilmielnik (Issue Creator) on (2024-05-22 07:47:17 UTC): @iethree The issue is not metrics-specific, repro steps just happened to be. I changed it to models so it's clear.

"
2308477929,issue,open,,Don't cancel queries when you switch in between tabs,"**Is your feature request related to a problem? Please describe.**
You might be switching tabs because some queries take some time to load, and you expect that when you come back to the tab where you left a query loading, to have it loaded and not to wait for it again.

Here's a video with this demonstration: 
https://www.loom.com/share/422b2bb05e5e4625b9f46c8b63995368?sid=f0fc9d72-c4bf-4a8c-8144-be1989c1bb99

If you see carefully, the queries from Tab 2 get canceled when I return to Tab 1 and don't run in the background.

**Describe the solution you'd like**
Keep running queries in the background while switching in between tabs.

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket: [25488](https://metabase.zendesk.com/agent/tickets/25488)

**Additional context**
This is related to this issue: https://github.com/metabase/metabase/issues/39863
",ignacio-mb,2024-05-21 14:43:23+00:00,[],2024-05-21 14:43:24+00:00,,https://github.com/metabase/metabase/issues/42956,"[('Reporting/Dashboards', ''), ('Querying/Processor', ''), ('Type:New Feature', ''), ('Querying/', '')]",[],
2308303593,issue,closed,not_planned,[Browse] Preserve sort on page reload,,rafpaf,2024-05-21 13:22:15+00:00,[],2024-08-06 15:26:04+00:00,2024-08-06 15:26:02+00:00,https://github.com/metabase/metabase/issues/42952,[],"[{'comment_id': 2271566085, 'issue_id': 2308303593, 'author': 'rafpaf', 'body': 'Closed for now. We may return to this later', 'created_at': datetime.datetime(2024, 8, 6, 15, 26, 3, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-08-06 15:26:03 UTC): Closed for now. We may return to this later

"
2308303306,issue,closed,completed,[Browse] Combine breadcrumbs into one link,,rafpaf,2024-05-21 13:22:07+00:00,['rafpaf'],2024-06-10 20:34:54+00:00,2024-06-04 02:08:49+00:00,https://github.com/metabase/metabase/issues/42951,[],[],
2308182275,issue,closed,completed,Create column actions always visible,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/a82178b4-8bba-41d6-9c7a-6c6caae6a6e6



### To Reproduce

### Case 1

1. Create a native question for Sample DB:
    ```sql
    SELECT DATE '2024-05-21' AS created_at, null as v
    UNION ALL SELECT DATE '2024-05-20' , 1
    UNION ALL SELECT DATE '2024-05-19' , 2
    ORDER BY created_at
    ```
3. Save it
4. Explore results

Plus button is visible but it should not.
Extract and combine shortcuts are shown after clicking it.


-----

### Case 2

1. Create a native question for Sample DB: `select 1`
2. Save it
3. Explore results

Plus button is visible but it should not.
Nothing happens when clicking it.



### Information about your Metabase installation

master, c09ec3ddeb


### Severity

P3
",kamilmielnik,2024-05-21 12:25:20+00:00,['kamilmielnik'],2024-07-15 21:00:21+00:00,2024-07-15 08:12:54+00:00,https://github.com/metabase/metabase/issues/42949,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Completeness', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2210346145, 'issue_id': 2308182275, 'author': 'nemanjaglumac', 'body': 'This might be a desirable behavior now when we added ""combine columns"".\r\n\r\ncc @romeovs @mngr', 'created_at': datetime.datetime(2024, 7, 5, 7, 28, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210387180, 'issue_id': 2308182275, 'author': 'kamilmielnik', 'body': '> This might be a desirable behavior now when we added ""combine columns"".\r\n\r\nNotice that in the video user cannot submit ""Extract part of column"" or ""Combine columns"" forms (because there are no columns to select from), so it does not make sense to show these options. And if there are no options to show, the plus menu also should not be shown.', 'created_at': datetime.datetime(2024, 7, 5, 7, 57, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210624981, 'issue_id': 2308182275, 'author': 'mngr', 'body': ""@kamilmielnik Why can't we extract from the created_at column here?"", 'created_at': datetime.datetime(2024, 7, 5, 10, 27, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210658518, 'issue_id': 2308182275, 'author': 'kamilmielnik', 'body': ""> @kamilmielnik Why can't we extract from the created_at column here?\r\n\r\nRight, it should be possible. There must have been a bug in QP.\r\nI just checked in `master` at b78222eac1 and it's possible to extract from created_at column."", 'created_at': datetime.datetime(2024, 7, 5, 10, 51, 18, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-05 07:28:38 UTC): This might be a desirable behavior now when we added ""combine columns"".

cc @romeovs @mngr

kamilmielnik (Issue Creator) on (2024-07-05 07:57:28 UTC): Notice that in the video user cannot submit ""Extract part of column"" or ""Combine columns"" forms (because there are no columns to select from), so it does not make sense to show these options. And if there are no options to show, the plus menu also should not be shown.

mngr on (2024-07-05 10:27:09 UTC): @kamilmielnik Why can't we extract from the created_at column here?

kamilmielnik (Issue Creator) on (2024-07-05 10:51:18 UTC): Right, it should be possible. There must have been a bug in QP.
I just checked in `master` at b78222eac1 and it's possible to extract from created_at column.

"
2308150550,issue,closed,completed,Trend charts should break down gracefully on missing data,"### Describe the bug

Trend visualization breaks down in an unhelpful way when data is incomplete.


### To Reproduce

1. Create a native question returning a time series where the latest value is null:
```
    SELECT DATE '2024-05-21' AS created_at, null as v
    UNION ALL SELECT DATE '2024-05-20' , 1
    UNION ALL SELECT DATE '2024-05-19' , 2
    ORDER BY created_at
```
2. Save it, and explore results
3. Summarize: Sum of V, Group by Day:created_at
4. Visualize: Trend
5. (!)The following error is logged on the console: `Error: The latest data point contains a null value` and the visualization breaks with the triangle
<img width=""78"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/e1f437e0-ec21-4667-ae55-e6466209140a"">.
6. (!) Switching to the table view (still using trend viz) didn't resolve the issue, the triangle remains, and the data is not displayed even in table format.
7. (!) Switching to another viz and clicking the refresh button does not clear the error. Only a full page reload resolves it.

### Expected behavior

1. The trend viz should handle incomplete data gracefully. The user should be notified if the data unavailable. (Alternatively, following the behavior of previous versions, earlier data should be displayed when possible - perhaps this could be a configurable option.)
4. Users should be able to switch to table view even if the trend is not displayable.
5. Switching to another visualization should clear any errors.

### Logs

Console
```
react-dom.production.min.js:209 Error: The latest data point contains a null value
    at s.series (compute.js:182:11)
    at compute.js:234:1
[...]
```

### Information about your Metabase installation

```JSON
1.49.10
```


### Severity

P2 - confusing

### Additional context
The same data resulted in a different outcome in v1.48 - the change was computed based on the last two available values, though the dates were incorrect:
<img width=""192"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/530921df-0b47-4b27-b211-7daaefc2905f"">

_No response_",zbodi74,2024-05-21 12:09:23+00:00,['JesseSDevaney'],2024-05-29 00:27:09+00:00,2024-05-29 00:27:09+00:00,https://github.com/metabase/metabase/issues/42948,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2122513941, 'issue_id': 2308150550, 'author': 'zbodi74', 'body': 'Adding the regression flag as this case was sort-of handled in v48.', 'created_at': datetime.datetime(2024, 5, 21, 12, 22, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2135574493, 'issue_id': 2308150550, 'author': 'JesseSDevaney', 'body': 'Re-opening until 49 backport is merged', 'created_at': datetime.datetime(2024, 5, 28, 15, 43, 20, tzinfo=datetime.timezone.utc)}]","zbodi74 (Issue Creator) on (2024-05-21 12:22:21 UTC): Adding the regression flag as this case was sort-of handled in v48.

JesseSDevaney (Assginee) on (2024-05-28 15:43:20 UTC): Re-opening until 49 backport is merged

"
2308141091,issue,closed,completed,Pivot table color customization for embedding SDK,Add basic color customization options for pivot tables.,heypoom,2024-05-21 12:04:36+00:00,['heypoom'],2024-10-08 17:10:09+00:00,2024-05-30 11:24:45+00:00,https://github.com/metabase/metabase/issues/42947,"[('.Team/Embedding', '')]",[],
2308005902,issue,open,,Tracking nested task history,"Task history records execution status for things like sync, send-pulse, and persist tasks.

Task history could be nested; for example, these are the task histories we create after syncing a database.

```
metabase=# select * from task_history order by started_at desc;
 id  |                 task                 | db_id |         started_at         |          ended_at          | duration |                                              task_details                                              | status
-----+--------------------------------------+-------+----------------------------+----------------------------+----------+--------------------------------------------------------------------------------------------------------+---------
 199 | update-field-values                  |     1 | 2024-05-14 15:12:50.566+07 | 2024-05-14 15:12:50.899+07 |      333 | {""errors"":0,""created"":0,""updated"":0,""deleted"":0}                                                       | success
 198 | delete-expired-advanced-field-values |     1 | 2024-05-14 15:12:50.459+07 | 2024-05-14 15:12:50.564+07 |      105 | {""deleted"":0}                                                                                          | success
 197 | field values scanning                |     1 | 2024-05-14 15:12:50.457+07 | 2024-05-14 15:12:50.901+07 |      444 |                                                                                                        | success
 196 | classify-tables                      |     1 | 2024-05-14 15:12:50.448+07 | 2024-05-14 15:12:50.45+07  |        2 | {""total-tables"":8,""tables-classified"":0}                                                               | success
 195 | classify-fields                      |     1 | 2024-05-14 15:12:50.441+07 | 2024-05-14 15:12:50.447+07 |        6 | {""fields-classified"":0,""fields-failed"":0}                                                              | success
 194 | fingerprint-fields                   |     1 | 2024-05-14 15:12:50.427+07 | 2024-05-14 15:12:50.439+07 |       12 | {""no-data-fingerprints"":0,""failed-fingerprints"":0,""updated-fingerprints"":0,""fingerprints-attempted"":0} | success
 193 | analyze                              |     1 | 2024-05-14 15:12:50.426+07 | 2024-05-14 15:12:50.451+07 |       25 |                                                                                                        | success
 192 | sync-table-privileges                |     1 | 2024-05-14 15:12:50.421+07 | 2024-05-14 15:12:50.422+07 |        1 |                                                                                                        | success
 191 | sync-metabase-metadata               |     1 | 2024-05-14 15:12:50.256+07 | 2024-05-14 15:12:50.42+07  |      164 | {}                                                                                                     | success
 190 | sync-indexes                         |     1 | 2024-05-14 15:12:50.227+07 | 2024-05-14 15:12:50.254+07 |       27 | {""total-indexes"":0,""added-indexes"":0,""removed-indexes"":0}                                              | success
 189 | sync-fks                             |     1 | 2024-05-14 15:12:50.21+07  | 2024-05-14 15:12:50.226+07 |       16 | {""total-fks"":6,""updated-fks"":0,""total-failed"":0}                                                       | success
 188 | sync-fields                          |     1 | 2024-05-14 15:12:50.129+07 | 2024-05-14 15:12:50.207+07 |       78 | {""total-fields"":71,""updated-fields"":0}                                                                 | success
 187 | sync-tables                          |     1 | 2024-05-14 15:12:50.116+07 | 2024-05-14 15:12:50.126+07 |       10 | {""updated-tables"":0,""total-tables"":8}                                                                  | success
 186 | sync-timezone                        |     1 | 2024-05-14 15:12:50.111+07 | 2024-05-14 15:12:50.113+07 |        2 | {""timezone-id"":""UTC""}                                                                                  | success
 185 | sync-dbms-version                    |     1 | 2024-05-14 15:12:50.106+07 | 2024-05-14 15:12:50.108+07 |        2 | {""flavor"":""H2"",""version"":""2.1.214 (2022-06-13)"",""semantic-version"":[2,1]}                              | success
 184 | sync                                 |     1 | 2024-05-14 15:12:50.096+07 | 2024-05-14 15:12:50.424+07 |      328 |                                                                                                        | success
(16 rows)
```

The last row with the task `sync` is the top-level task that triggers all other tasks.

This is an implicit parent-child relation ship between tasks, but it's currently impossible to trace.

It's useful if we want to debug what went wrong, e.g., debug a failed sync task and check to see which step it fails.

Proposal: add a `task_history.parent_task_history_id` and update `task-history/with-task-history` to record it if they are nested.",qnkhuat,2024-05-21 10:54:35+00:00,[],2024-05-30 07:29:19+00:00,,https://github.com/metabase/metabase/issues/42943,"[('Type:New Feature', ''), ('.Backend', ''), ('Administration/Troubleshooting', ''), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2307921234,issue,open,,Filters for Histogram Bin Values Don't Update with Bin Size Changes After Applying Filters,"### Describe the bug


The filters for histogram bin values when drilling through don't reflect the updated bin size after applying a filters
I **CAN'T** reproduce this in master.

### To Reproduce

1. Use Orders table
Summarize using Count and bin the Total column
<img width=""1018"" alt=""1"" src=""https://github.com/metabase/metabase/assets/17398657/8ad67c14-d0a5-409d-b2a4-8413a5b91e02"">


<br>
<br>

2. There are bins with increments of 2

<img width=""684"" alt=""2"" src=""https://github.com/metabase/metabase/assets/17398657/d5a7bbcf-0391-44bc-b4c1-f165b46b08e8"">

<br>
<br>

Drilling through to values also reflects this
<img width=""578"" alt=""3"" src=""https://github.com/metabase/metabase/assets/17398657/49ed5b8b-ccef-48ef-80fe-60908c6084e1"">


<br>
<br>


3. Add a filter with a high enough value that will alter the bin size
<img width=""938"" alt=""4"" src=""https://github.com/metabase/metabase/assets/17398657/365f9ac8-a5cb-475f-ac50-539e80b3d94e"">


<br>
<br>


Bin increments are .75 at this time

<img width=""544"" alt=""5"" src=""https://github.com/metabase/metabase/assets/17398657/e324cc37-787c-4b5f-95db-8c2be8e5802e"">


<br>
<br>


However when drilling through to see the values, we have the original bin size of 2 for the filters
<img width=""684"" alt=""6"" src=""https://github.com/metabase/metabase/assets/17398657/7857cdde-6ab5-4bd7-9019-0663224feea7"">


### Expected behavior

For the filter values to correctly reflect the expected bin size.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""13.5.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Chicago""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""snowflake"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-13"",
      ""tag"": ""v1.49.10"",
      ""hash"": ""9e8fc83""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2 - Not able to reproduce in master

### Additional context

_No response_",FilmonK,2024-05-21 10:15:28+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/42942,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2122375034, 'issue_id': 2307921234, 'author': 'kamilmielnik', 'body': 'I can reproduce in 0.49.11.\r\nCannot reproduce in `master` at c09ec3ddeb.\r\nCannot reproduce in `release-x.50.x` at 242315dcfd.', 'created_at': datetime.datetime(2024, 5, 21, 11, 2, 19, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-05-21 11:02:19 UTC): I can reproduce in 0.49.11.
Cannot reproduce in `master` at c09ec3ddeb.
Cannot reproduce in `release-x.50.x` at 242315dcfd.

"
2307810717,issue,closed,completed,Static embedding: Include domain of parent website in the Powered by Metabase link,"This is a follow-up task for https://github.com/metabase/metabase/issues/42889

If it's possible to track the domain of the website in which the iframe is embedded, we would include the domain name in the UTM params. The domain name is concated to the `utm_content` param

`utm_content=embedded_banner_<Instance_Domain>`

Context: https://metaboat.slack.com/archives/C021BPRNNBT/p1716209117457889









**Context**

* 

",albertoperdomo,2024-05-21 09:23:46+00:00,['deniskaber'],2024-05-21 21:40:11+00:00,2024-05-21 21:40:11+00:00,https://github.com/metabase/metabase/issues/42940,"[('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', '')]",[],
2307726209,issue,open,,Correctly attribute columns which shadow others,"We currently do the wrong thing with something like the below query. Chris has written at length on ways to deal with this; check Notion.


```sql
-- s/towns.name/towns.new_name

SELECT d.name, article FROM (SELECT code, name from departments) AS d JOIN towns on d.code = towns.department;


/*
\d departments
                                    Table ""public.departments""
 Column  |         Type          | Collation | Nullable |                 Default                 
---------+-----------------------+-----------+----------+-----------------------------------------
 id      | integer               |           | not null | nextval('departments_id_seq'::regclass)
 code    | character varying(4)  |           | not null | 
 capital | character varying(10) |           | not null | 
 region  | character varying(4)  |           | not null | 
 name    | text                  |           | not null | 
Indexes:
    ""departments_pkey"" PRIMARY KEY, btree (id)
    ""departments_capital_key"" UNIQUE CONSTRAINT, btree (capital)
    ""departments_code_key"" UNIQUE CONSTRAINT, btree (code)
    ""departments_id_key"" UNIQUE CONSTRAINT, btree (id)
    ""departments_name_key"" UNIQUE CONSTRAINT, btree (name)
Foreign-key constraints:
    ""departments_region_fkey"" FOREIGN KEY (region) REFERENCES regions(code)
Referenced by:
    TABLE ""towns"" CONSTRAINT ""towns_department_fkey"" FOREIGN KEY (department) REFERENCES departments(code)

\d towns
                                      Table ""public.towns""
   Column    |         Type          | Collation | Nullable |              Default              
-------------+-----------------------+-----------+----------+-----------------------------------
 id          | integer               |           | not null | nextval('towns_id_seq'::regclass)
 code        | character varying(10) |           | not null | 
 article     | text                  |           |          | 
 name        | text                  |           | not null | 
 department  | character varying(4)  |           | not null | 
 unnecessary | character varying     |           |          | 
Indexes:
    ""towns_code_department_key"" UNIQUE CONSTRAINT, btree (code, department)
    ""towns_id_key"" UNIQUE CONSTRAINT, btree (id)
Foreign-key constraints:
    ""towns_department_fkey"" FOREIGN KEY (department) REFERENCES departments(code)
*/

```",tsmacdonald,2024-05-21 08:44:28+00:00,[],2024-07-01 16:05:46+00:00,,https://github.com/metabase/metabase/issues/42938,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2200542655, 'issue_id': 2307726209, 'author': 'crisptrutski', 'body': ""We're not working on this at the moment as we're prioritizing work on robustness."", 'created_at': datetime.datetime(2024, 7, 1, 16, 5, 44, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-07-01 16:05:44 UTC): We're not working on this at the moment as we're prioritizing work on robustness.

"
2306956366,issue,closed,completed,Creating a new collection in the root collection from the entity picker errors,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6377293/92d60bcb-c21d-40e3-95e3-8b26fdb5222d)

```
2024-05-20 17:40:50,369 DEBUG middleware.log :: POST /api/collection 400 16.1 ms (0 DB calls) {:metabase-user-id 1}
{:errors {:parent_id ""nullable value must be an integer greater than zero.""},
 :specific-errors {:parent_id [""value must be an integer greater than zero., received: \""root\""""]}}
```

Values sent over the wire:

```
{""name"":""restore point"",""parent_id"":""root""}
```

Values sent when creating a new collection from the regular ""New"" button in the root collection:

```
{parent_id: null, authority_level: null, color: ""#509EE3"", description: null, name: ""collection""}
```

(note null parent_id, also the color option there is completely removed i think)

### To Reproduce

use the new collection entity picker. Easiest way is to move an item, create a new collection, navigate away from recents to the collection picker, select Our Analytics root collection and then click ""create collection""

<img width=""1005"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/fca453d4-3492-4d26-9f7f-89fe2b94d93f"">


### Expected behavior

should not error

### Logs

_No response_

### Information about your Metabase installation

```JSON
latest
```


### Severity

p1-p2

### Additional context

_No response_",dpsutton,2024-05-20 23:17:58+00:00,['npfitz'],2024-10-08 17:11:01+00:00,2024-05-22 20:28:09+00:00,https://github.com/metabase/metabase/issues/42934,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Collections', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2122562192, 'issue_id': 2306956366, 'author': 'iethree', 'body': 'we should also verify that creating a dashboard in the root collection works correctly from the entity picker', 'created_at': datetime.datetime(2024, 5, 21, 12, 48, 52, tzinfo=datetime.timezone.utc)}]","iethree on (2024-05-21 12:48:52 UTC): we should also verify that creating a dashboard in the root collection works correctly from the entity picker

"
2306832493,issue,closed,completed,When Filtering with Dates Coerced from Numeric Fields in a Table Visualization - Filter Sometimes Disappears,"### Describe the bug

When a numeric value is coerced to a date there is some unexpected behavior when you use the date as a filter on a table visualization. the filter works, but under certain conditions it will disappear while you're interacting with other filters.

### To Reproduce

1. Coerce a numeric field to a date (you can test this with the ID field on any of the sample DB tables)
2. Create a simple question and display results in a table viz
3. Filter any field on the table
4. Filter by the coerced date field
5. Edit the first field filter
6. Then one of two things may happen:
- If there were records that matched the date filter, the filter does not disappear
- If there were not records that matched the coerced date filter then it vanishes

### Expected behavior

It should mirror the behavior of a date filter that uses a non coerced date field. The field filter shouldn't vanish when the other fields are edited.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-09"",
      ""tag"": ""v1.49.9"",
      ""hash"": ""c0913c7""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",ixipixi,2024-05-20 21:32:59+00:00,['lbrdnk'],2024-08-28 02:09:49+00:00,2024-05-30 07:31:02+00:00,https://github.com/metabase/metabase/issues/42931,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Escalation', ''), ('.Team/Querying', '')]",[],
2306798618,issue,closed,completed,Admin Email does not Display on Question Timeout Page,"### Describe the bug

When a question times out you're presented with the messaging ""Your Question Took Too Long"". Below that the admin email address is included. The admin email is not displaying.

### To Reproduce

1. I just made a big test table in Postgres:

CREATE TABLE large_table (
    id SERIAL PRIMARY KEY,
    data1 INT,
    data2 INT,
    data3 TEXT
);

-- Insert a large number of rows into the table
INSERT INTO large_table (data1, data2, data3)
SELECT
    (random() * 1000000)::int,
    (random() * 1000000)::int,
    md5(random()::text)
FROM generate_series(1, 10000000);


2. Executed this SQL Query on the DB a few times and then added it to Metabase as a native SQL question:

SELECT
    t1.id,
    t1.data1,
    t1.data2,
    AVG(t2.data1) AS avg_data1,
    COUNT(t2.id) AS count_data2
FROM
    large_table t1
JOIN
    large_table t2 ON t1.data1 = t2.data2
GROUP BY
    t1.id, t1.data1, t1.data2
HAVING
    COUNT(t2.id) > 10
ORDER BY
    avg_data1 DESC;
    
    
    3. Eventually it times out and we get:
    
![admin_email](https://github.com/metabase/metabase/assets/13661163/b0480dd9-7a81-4b57-b38b-5cb3bf389653)




### Expected behavior

We should see the admin email address

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-09"",
      ""tag"": ""v1.49.9"",
      ""hash"": ""c0913c7""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",ixipixi,2024-05-20 21:06:50+00:00,['kamilmielnik'],2024-06-03 07:11:35+00:00,2024-05-21 17:26:16+00:00,https://github.com/metabase/metabase/issues/42929,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2121304529, 'issue_id': 2306798618, 'author': 'mohamed-montaser91', 'body': 'I have the same issue', 'created_at': datetime.datetime(2024, 5, 20, 22, 13, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2143852554, 'issue_id': 2306798618, 'author': 'mohamed-montaser91', 'body': ""@kamilmielnik @ixipixi \r\nwhen this bug fix coming out? it's not in the last 2 updates"", 'created_at': datetime.datetime(2024, 6, 2, 13, 21, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2144440528, 'issue_id': 2306798618, 'author': 'kamilmielnik', 'body': ""@mohamed-montaser91 It's coming out in Metabase 0.50.\r\nRC2 is scheduled to be out this week and it will include this bugfix."", 'created_at': datetime.datetime(2024, 6, 3, 7, 11, 34, tzinfo=datetime.timezone.utc)}]","mohamed-montaser91 on (2024-05-20 22:13:21 UTC): I have the same issue

mohamed-montaser91 on (2024-06-02 13:21:51 UTC): @kamilmielnik @ixipixi 
when this bug fix coming out? it's not in the last 2 updates

kamilmielnik (Assginee) on (2024-06-03 07:11:34 UTC): @mohamed-montaser91 It's coming out in Metabase 0.50.
RC2 is scheduled to be out this week and it will include this bugfix.

"
2306567686,issue,closed,completed,Fix flaky question archive test,"Failing tests

[Slack Message](https://metaboat.slack.com/archives/C5XHN8GLW/p1716225378151339)",iethree,2024-05-20 18:49:27+00:00,[],2024-10-08 17:11:30+00:00,2024-05-20 20:19:06+00:00,https://github.com/metabase/metabase/issues/42917,"[('.CI & Tests', ''), ('flaky-test-fix', '')]",[],
2306464046,issue,closed,completed,Add recent views for Cards,"**Context**

We should write a row to Recent Views for these card events:

- [x] :event/card-create
- [x] :event/card-read
- [x] :event/card-update
- [x] :event/card-query",escherize,2024-05-20 17:45:59+00:00,['escherize'],2024-10-08 17:10:01+00:00,2024-05-30 17:05:31+00:00,https://github.com/metabase/metabase/issues/42913,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2306405091,issue,open,,Can we make `Offset()` work for MySQL/MariaDB?,,camsaul,2024-05-20 17:08:36+00:00,[],2025-02-04 20:28:52+00:00,,https://github.com/metabase/metabase/issues/42908,"[('Querying/Processor', ''), ('.Backend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2250311725, 'issue_id': 2306405091, 'author': 'DieudonneCesar', 'body': 'Does anyone have information on when the Offset() function support for MySQL/MariaDB is expected to be in production? I do not see any milestone associated with it.', 'created_at': datetime.datetime(2024, 7, 25, 13, 21, 56, tzinfo=datetime.timezone.utc)}]","DieudonneCesar on (2024-07-25 13:21:56 UTC): Does anyone have information on when the Offset() function support for MySQL/MariaDB is expected to be in production? I do not see any milestone associated with it.

"
2306273825,issue,open,,Add map marker click behavior to drill-through on row data,"**Is your feature request related to a problem? Please describe.**
I have a map that shows 500 locations with markers.  Each marker has data associated with it (marker id, user id, ...). I sometimes need to dig into one of these locations. For instance I'll need to look at the user associated with the marker.
Metabase will show the data associated with the marker in a hover bubble (first screenshot), but I can't copy it because as soon as I move my cursor the bubble disappears. For instance if it's an UUID I want, I have to type it manually, or try to find the exact row in the data table view.

**Describe the solution you'd like**
Clicking on a marker should select the row in some way. Ideally it would open the ""Detail visualization"" (second screenshot) popup that's in the data table view.

**Describe alternatives you've considered**
Alternatively the code could be changed so that clicking a marker could force the hover bubble to stay open. 

A (painful) trick today is to create a dashboard, add the map, then configure the ""Click behavior"" of the map to update a dashboard filter. Then... the data can be copied from the value in the filter.

**Additional context**
The dashboard trick described above is a sign that the Metabase code can already handle clicks on markers and use the associated data. Maybe the suggested feature (open the ""Detail vizualization"" popup) will be very easy to code.

![image](https://github.com/metabase/metabase/assets/242172/393869ae-9c00-4f92-9647-73dcd42caa97)

![image](https://github.com/metabase/metabase/assets/242172/207e212a-ef53-4c5b-b380-bd73660dd2a4)
",Caerbannog,2024-05-20 15:46:39+00:00,[],2025-02-04 20:31:53+00:00,,https://github.com/metabase/metabase/issues/42902,"[('Type:New Feature', ''), ('Visualization/Maps', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus')]",[],
2306129595,issue,closed,not_planned,can't connect to oracle,"**Describe the bug**
when i try to connect to oracle i get this error
i'm running metabase on docker using wsl ubuntu distro
and my oracle is local no docker
PLEASE I NEED YOUR HELP

**Logs**
Caused by: oracle.net.ns.NetException: ORA-12541: Cannot connect. No listener at host localhost port 1521. (CONNECTION_ID=caCJrUBpRWWWAXoM5cmg9w==)
https://docs.oracle.com/error-help/db/ora-12541/
        at oracle.net.nt.TcpNTAdapter.handleEstablishSocketException(TcpNTAdapter.java:414)
        at oracle.net.nt.TcpNTAdapter.establishSocket(TcpNTAdapter.java:346)
        at oracle.net.nt.TcpNTAdapter.connect(TcpNTAdapter.java:224)
        at oracle.net.nt.ConnOption.connect(ConnOption.java:332)
        at oracle.net.nt.ConnStrategy.executeConnOption(ConnStrategy.java:1199)
        at oracle.net.nt.ConnStrategy.execute(ConnStrategy.java:742)
        at oracle.net.resolver.AddrResolution.resolveAndExecute(AddrResolution.java:708)
        at oracle.net.ns.NSProtocol.establishConnection(NSProtocol.java:959)
        at oracle.net.ns.NSProtocol.connect(NSProtocol.java:328)
        at oracle.jdbc.driver.T4CConnection.connectNetworkSessionProtocol(T4CConnection.java:3173)
        at oracle.jdbc.driver.T4CConnection.logon(T4CConnection.java:1000)
        ... 27 more
Caused by: java.net.ConnectException: Connection refused
        at java.base/sun.nio.ch.Net.connect0(Native Method)
        at java.base/sun.nio.ch.Net.connect(Unknown Source)
        at java.base/sun.nio.ch.Net.connect(Unknown Source)
        at java.base/sun.nio.ch.SocketChannelImpl.connect(Unknown Source)
        at java.base/sun.nio.ch.SocketAdaptor.connect(Unknown Source)
        at oracle.net.nt.TimeoutSocketChannel.doConnect(TimeoutSocketChannel.java:288)
        at oracle.net.nt.TimeoutSocketChannel.initializeSocketChannel(TimeoutSocketChannel.java:268)
        at oracle.net.nt.TimeoutSocketChannel.connect(TimeoutSocketChannel.java:235)
        at oracle.net.nt.TimeoutSocketChannel.<init>(TimeoutSocketChannel.java:202)
        at oracle.net.nt.TcpNTAdapter.establishSocket(TcpNTAdapter.java:335)
        ... 36 more
2024-05-20 14:23:34,100 DEBUG middleware.log :: POST /api/database 400 13.3 ms (0 DB calls) 
{:message ""Hmm, we couldn't connect to the database. Make sure your Host and Port settings are correct"",
 :errors {:host ""check your host settings"", :port ""check your port settings""}}

**Screenshots**
![image](https://github.com/metabase/metabase/assets/145304304/89c2a26f-aa01-4033-b17f-7b3d5e0a535e)


**Severity**
this is very urgent, our productions db is on oracle.

**Additional context**
this is the java version on container:
java -version
openjdk version ""11.0.23"" 2024-04-16
OpenJDK Runtime Environment Temurin-11.0.23+9 (build 11.0.23+9)
OpenJDK 64-Bit Server VM Temurin-11.0.23+9 (build 11.0.23+9, mixed mode)

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v0.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",mohamed-montaser91,2024-05-20 14:30:26+00:00,[],2025-01-16 20:33:57+00:00,2025-01-16 20:33:55+00:00,https://github.com/metabase/metabase/issues/42895,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Oracle', None), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2150881252, 'issue_id': 2306129595, 'author': 'ignacio-mb', 'body': 'hi @mohamed-montaser91 can you connect to the db using a db viewer like dbeaver with the same credentials?', 'created_at': datetime.datetime(2024, 6, 5, 20, 12, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2155102493, 'issue_id': 2306129595, 'author': 'mohamed-montaser91', 'body': '@ignacio-mb yes I can,  with dbeaver it works but on metabase no', 'created_at': datetime.datetime(2024, 6, 7, 15, 48, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189602648, 'issue_id': 2306129595, 'author': 'calherries', 'body': ""@mohamed-montaser91 can you confirm you're still having this issue? And what version of the Oracle driver and database are you using?"", 'created_at': datetime.datetime(2024, 6, 25, 17, 45, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596838495, 'issue_id': 2306129595, 'author': 'paoliniluis', 'body': 'Closing as there was no response from the user', 'created_at': datetime.datetime(2025, 1, 16, 20, 33, 55, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-06-05 20:12:28 UTC): hi @mohamed-montaser91 can you connect to the db using a db viewer like dbeaver with the same credentials?

mohamed-montaser91 (Issue Creator) on (2024-06-07 15:48:55 UTC): @ignacio-mb yes I can,  with dbeaver it works but on metabase no

calherries on (2024-06-25 17:45:54 UTC): @mohamed-montaser91 can you confirm you're still having this issue? And what version of the Oracle driver and database are you using?

paoliniluis on (2025-01-16 20:33:55 UTC): Closing as there was no response from the user

"
2306124914,issue,closed,completed,[BE] [Bug] query_metadata returns archived metrics,"Repro
- Create new single-stage metrics based on a table
- Archive them
- New -> Question -> Select the table that was used for metrics
- Summarize
- There should be no archived metrics

<img width=""491"" alt=""Screenshot 2024-05-20 at 10 27 26"" src=""https://github.com/metabase/metabase/assets/8542534/4df757fe-f0e2-48e8-9ef0-8ef902a67436"">
",ranquild,2024-05-20 14:28:18+00:00,['metamben'],2024-10-08 17:10:49+00:00,2024-05-23 21:29:58+00:00,https://github.com/metabase/metabase/issues/42893,[],[],
2306104040,issue,open,,"For a dashboard-level filter, be able to set default value for different tabs","**Is your feature request related to a problem? Please describe.**
- For a dashboard-level filter, be able to set default value for different tabs
- E.g. i have a dashboard level filter called ""transaction count threshold"". FOr tab 1, i want to set threshold = 1000 txns, tab 2 threshold = 200 txns

**Describe the solution you'd like**
- E.g. i have a dashboard level filter called ""transaction count threshold"". FOr tab 1, i want to set threshold = 1000 txns, tab 2 threshold = 200 txns

**Describe alternatives you've considered**
Just not having defaults

**How important is this feature to you?**
Currently, dashboard-level filters are not too helpful when you have multiple tabs on dashbaord so some more enhancements on dashboard-level filter on dashes with multiple tabs would be helpful

**Additional context**
Add any other context or screenshots about the feature request here.
",aarthi-subramanian,2024-05-20 14:17:53+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/42891,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2306084344,issue,closed,completed,"Static embedding: Update link in ""Powered by Metabase footer""","<img width=""776"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24216/0b47698b-4b26-43f4-b8be-237b9ce818ba"">

In static embedding and public links on OSS and EE not on Pro/EE, there is a footer with the copy ""Powered by Metabase"" and a link to the Metabase website.

We want to update the URL and add some UTM codes. 

Destination URL: https://www.metabase.com/powered-by-metabase

UTM codes:
`utm_source=product`
`utm_medium=referral`
`utm_campaign=powered_by_metabase`
`utm_content=embedded_banner`

**Context**
https://metaboat.slack.com/archives/C021BPRNNBT/p1716209117457889",albertoperdomo,2024-05-20 14:07:58+00:00,['deniskaber'],2024-05-21 21:34:29+00:00,2024-05-21 21:34:29+00:00,https://github.com/metabase/metabase/issues/42889,"[('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('backport', 'Automatically create PR on current release branch on merge'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Sharing/Public', '')]",[],
2305951974,issue,closed,completed,Optimize rendering of DashboardHeader,"<img width=""1247"" alt=""Screenshot 2024-05-20 at 15 56 37"" src=""https://github.com/metabase/metabase/assets/125459446/3dca8a7a-7a84-4fab-b5f0-aeee7a339ad1"">
",uladzimirdev,2024-05-20 13:00:56+00:00,['uladzimirdev'],2024-10-08 17:10:03+00:00,2024-05-30 15:14:54+00:00,https://github.com/metabase/metabase/issues/42885,[],[],
2305951485,issue,closed,completed,drop props spreading to DashboardSidebars,,uladzimirdev,2024-05-20 13:00:39+00:00,['uladzimirdev'],2024-10-08 17:11:27+00:00,2024-05-21 09:48:04+00:00,https://github.com/metabase/metabase/issues/42884,[],[],
2305951385,issue,closed,completed,drop props spreading to DashboardHeader,,uladzimirdev,2024-05-20 13:00:35+00:00,['uladzimirdev'],2024-10-08 17:10:58+00:00,2024-05-23 06:52:18+00:00,https://github.com/metabase/metabase/issues/42883,[],[],
2305950838,issue,closed,completed,drop props spreading to DashboardGrid,,uladzimirdev,2024-05-20 13:00:17+00:00,['uladzimirdev'],2024-10-08 17:11:34+00:00,2024-05-20 17:43:59+00:00,https://github.com/metabase/metabase/issues/42882,[],[],
2305950320,issue,closed,completed,[Epic] Optimize dashboard rendering,"Dashboard rendering is slow and not optimal, but it's close to impossible to make any change there, so let's prepare it

<img width=""1242"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/3c48fb44-37d4-4e63-b1f0-07832bffb7cd"">
starting point - 105 renderings in a simple dashboard with 2 cards

<img width=""615"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/2ea2c35a-3108-401d-b0ca-ade771c41ee2"">


TBA
**Implementation Plan**
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42882
- [ ] https://github.com/metabase/metabase/issues/42883
- [ ] https://github.com/metabase/metabase/issues/42884
- [ ] https://github.com/metabase/metabase/issues/42885
- [ ] https://github.com/metabase/metabase/pull/43431
- [ ] https://github.com/metabase/metabase/pull/43340
- [ ] https://github.com/metabase/metabase/pull/43323
- [ ] https://github.com/metabase/metabase/pull/43169
```

",uladzimirdev,2024-05-20 13:00:01+00:00,['uladzimirdev'],2024-06-03 08:09:42+00:00,2024-06-03 08:09:20+00:00,https://github.com/metabase/metabase/issues/42881,"[('.Epic', 'Feature Implementation or Project')]",[],
2305828745,issue,open,,CLS due to recent items reloading every time the command palette is opened,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/1689011e-33fd-40b0-8cb6-343e624b90b4



### To Reproduce

1. Open up the command palette
2. Notice recent items are loading and appear after a while
3. Close the command palette
4. Open up the command palette again

Recent items are not immediately shown (even though they're already cached) resulting in an disrupting Content Layout Shift

### Information about your Metabase installation

master, 5d795be

### Severity

P2

### Additional context

I'm giving it P2 because it's annoying and disrupts my workflow",kamilmielnik,2024-05-20 11:54:16+00:00,[],2025-02-04 20:27:23+00:00,,https://github.com/metabase/metabase/issues/42880,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2305782754,issue,closed,completed,Entity Picker difficult to use on mobile,"![image](https://github.com/metabase/metabase/assets/6830683/1df58db6-e7f4-440f-a02f-eddbfab45d39)

### Description

On mobile:
- when search is available, the search input will take most of the horizontal space resulting in wrapped modal title and ""x"" being off-screen (it should probably go into a separate row - to confirm with product)
- when tabs don't horizontally fit in the viewport, they wrap into multiple lines instead of becoming scrollable (to confirm with product)
- the entity picker modal is horizontally scrollable (only the `nested-item-picker` should be horizontally scrollable)

### How to reproduce

On mobile:
- start a new question
- try to move existing question to a different collection

### Information about your Metabase installation

master, 5d795be

### Severity

P3
",kamilmielnik,2024-05-20 11:31:14+00:00,[],2024-05-20 13:46:55+00:00,2024-05-20 13:46:48+00:00,https://github.com/metabase/metabase/issues/42879,[],"[{'comment_id': 2120492147, 'issue_id': 2305782754, 'author': 'iethree', 'body': ""note: we have some [really great mobile designs](https://www.notion.so/metabase/Make-picking-an-item-a-nice-experience-with-an-EntityPicker-component-05e457c1b84f413f84ab9756e0c68b57?pvs=4#3d63f32dc2994226ac8353a507371e70), they just haven't been implemented yet"", 'created_at': datetime.datetime(2024, 5, 20, 13, 43, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120498183, 'issue_id': 2305782754, 'author': 'kamilmielnik', 'body': ""I'll close this for now then, thanks!"", 'created_at': datetime.datetime(2024, 5, 20, 13, 46, 48, tzinfo=datetime.timezone.utc)}]","iethree on (2024-05-20 13:43:35 UTC): note: we have some [really great mobile designs](https://www.notion.so/metabase/Make-picking-an-item-a-nice-experience-with-an-EntityPicker-component-05e457c1b84f413f84ab9756e0c68b57?pvs=4#3d63f32dc2994226ac8353a507371e70), they just haven't been implemented yet

kamilmielnik (Issue Creator) on (2024-05-20 13:46:48 UTC): I'll close this for now then, thanks!

"
2305769253,issue,open,,Home/End keys do 2 things in the command palette input,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/3a63d91a-f1b4-456a-a292-14124ad6a3e0



### To Reproduce

1. Hit <kbd>Ctrl</kbd> + <kbd>K</kbd> to open up the command palette
2. Type `hello` in the input
3. Hit <kbd>Home</kbd> key
    - :heavy_check_mark:  Cursor goes to the beginning of the input
    - :x: First result gets selected
4. Hit <kbd>End</kbd> key
    - :heavy_check_mark:  Cursor goes to the end of the input
    - :x: Last result gets selected

### Expected behavior

<kbd>Home</kbd> & <kbd>End</kbd> keys **do not affect** which result is selected.
<kbd>Home</kbd> & <kbd>End</kbd> keys **affect** cursor position in the input

### Information about your Metabase installation

master, 5d795be

### Severity

P3",kamilmielnik,2024-05-20 11:26:13+00:00,[],2024-06-04 19:24:03+00:00,,https://github.com/metabase/metabase/issues/42878,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2147709101, 'issue_id': 2305769253, 'author': 'npfitz', 'body': '@luizarakaki Any thoughts on this?', 'created_at': datetime.datetime(2024, 6, 4, 14, 39, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2148241792, 'issue_id': 2305769253, 'author': 'luizarakaki', 'body': ""Idk, isn't the current behavior good? I think it will always do what you want."", 'created_at': datetime.datetime(2024, 6, 4, 19, 24, 2, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-06-04 14:39:11 UTC): @luizarakaki Any thoughts on this?

luizarakaki on (2024-06-04 19:24:02 UTC): Idk, isn't the current behavior good? I think it will always do what you want.

"
2305744969,issue,closed,completed,Sidebar items vary in height,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/efcff993-985d-4b5a-a8da-5fad9dfc8aed)


### To Reproduce

1. Create a question visualized as a table and bookmark it
2. Create a question visualized as a bar chart and bookmark it
3. Inspect height of bookmark elements in the sidebar

Item representing 1st question is 33px high.
Item representing 2nd question is 29px high.

### Expected behavior

Sidebar items should be of the same height

### Information about your Metabase installation

master, 5d795be

### Severity

P3
",kamilmielnik,2024-05-20 11:14:05+00:00,['npfitz'],2024-06-05 12:01:05+00:00,2024-06-04 20:21:29+00:00,https://github.com/metabase/metabase/issues/42877,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2304055019,issue,open,,Parallelize frontend and drivers build,"When we build using `./bin/buld.sh`, we're executing a series of steps in sequential order. However, drivers and frontend don't have common dependencies, so they can easily be built in parallel. The frontend is the slowest part of the build. Drivers take a few minutes, and those few minutes is what we can save if we implement this.

Related to https://github.com/metabase/metabase/issues/37576.",nemanjaglumac,2024-05-18 11:57:47+00:00,['camsaul'],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/42874,"[('.Building & Releasing', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.DX', 'Developer experience and QoL related.'), ('.Team/DevEx', '')]","[{'comment_id': 2241199172, 'issue_id': 2304055019, 'author': 'paoliniluis', 'body': 'PR for driver build is here https://github.com/metabase/metabase/pull/45897', 'created_at': datetime.datetime(2024, 7, 20, 16, 28, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242482242, 'issue_id': 2304055019, 'author': 'uladzimirdev', 'body': ""I've played with parallel builds during last week and we easily reach max resources on the machine, so FE and drivers parallel build doesn't bring a significant improvement. At the same time if we use a more performance machine, we can cut ~30s from the build.\r\n\r\nFirstly I plan to [build static-viz and main app in parallel](https://github.com/metabase/metabase/pull/45864) to save ~10-15s"", 'created_at': datetime.datetime(2024, 7, 22, 9, 17, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324772891, 'issue_id': 2304055019, 'author': 'uladzimirdev', 'body': ""> I've played with parallel builds during last week and we easily reach max resources on the machine, so FE and drivers parallel build doesn't bring a significant improvement. At the same time if we use a more performance machine, we can cut ~30s from the build.\r\n> \r\n> Firstly I plan to [build static-viz and main app in parallel](https://github.com/metabase/metabase/pull/45864) to save ~10-15s\r\n\r\nUpdate:\r\n\r\nafter migration to rspack we can save ~15-20s running FE builds in parallel"", 'created_at': datetime.datetime(2024, 9, 2, 13, 32, 12, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-20 16:28:42 UTC): PR for driver build is here https://github.com/metabase/metabase/pull/45897

uladzimirdev on (2024-07-22 09:17:21 UTC): I've played with parallel builds during last week and we easily reach max resources on the machine, so FE and drivers parallel build doesn't bring a significant improvement. At the same time if we use a more performance machine, we can cut ~30s from the build.

Firstly I plan to [build static-viz and main app in parallel](https://github.com/metabase/metabase/pull/45864) to save ~10-15s

uladzimirdev on (2024-09-02 13:32:12 UTC): Update:

after migration to rspack we can save ~15-20s running FE builds in parallel

"
2304018370,issue,open,,Support for the feature “Filter by column equal/not equal to value in cell” for columns with links,"**Is your feature request related to a problem? Please describe.**
I configured 'Display as Link' for the column in the Table. The values in the column are displayed as a link, this is ok.
But for such columns, it is no longer possible to use the feature “Filter by column is equal/not equal to the value in the cell”.

**Describe the solution you'd like**
I would like to be able to quickly filter by value.
As an example of implementation, for Table or Table in Dashboard:
- When clicking on a cell value, open the link configured in Link URL (as it works now).
- When clicking in a cell, not on the cell value (link), show the menu “Filter by” (as now, for columns without links).

**How important is this feature to you?**
Now, to filter, you have to copy the value in a cell, add a filter by cell and paste the value there.
It would be more convenient to use a quick filter setup like for columns without links.",alyakh-gegi-llc,2024-05-18 10:49:00+00:00,[],2024-06-04 14:50:41+00:00,,https://github.com/metabase/metabase/issues/42873,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus')]",[],
2303611270,issue,closed,completed,"Pivot Table: If a value in a cell is NULL and has a Suffix it will display in the table as ""null Suffix""","### Describe the bug

If a pivot table has a cell with a NULL value it displays an empty cell in the visualization unless a suffix has been configured. In that case it displays ""null"" with the suffix appended on the end.

**Without suffix:**
![one](https://github.com/metabase/metabase/assets/13661163/d399381f-313a-41c7-98b0-81fb4b92a4b5)

**With Suffix:**
![two](https://github.com/metabase/metabase/assets/13661163/ed8a00ec-6aea-493c-b46c-660165464bff)


### To Reproduce

1. Create a Model using this query from the Sample Database:

(SELECT
  ""PUBLIC"".""PRODUCTS"".""ID"" AS ""ID"",
  ""PUBLIC"".""PRODUCTS"".""EAN"" AS ""EAN"",
  ""PUBLIC"".""PRODUCTS"".""TITLE"" AS ""TITLE"",
  ""PUBLIC"".""PRODUCTS"".""CATEGORY"" AS ""CATEGORY"",
  ""PUBLIC"".""PRODUCTS"".""VENDOR"" AS ""VENDOR"",
  ""PUBLIC"".""PRODUCTS"".""PRICE"" AS ""PRICE"",
  ""PUBLIC"".""PRODUCTS"".""RATING"" AS ""RATING"",
  ""PUBLIC"".""PRODUCTS"".""CREATED_AT"" AS ""CREATED_AT""
FROM
  ""PUBLIC"".""PRODUCTS""
  where ""PUBLIC"".""PRODUCTS"".""CATEGORY"" <> 'Gizmo'
LIMIT 50)
  
  union all
  
 ( SELECT
  ""PUBLIC"".""PRODUCTS"".""ID"" AS ""ID"",
  ""PUBLIC"".""PRODUCTS"".""EAN"" AS ""EAN"",
  ""PUBLIC"".""PRODUCTS"".""TITLE"" AS ""TITLE"",
  ""PUBLIC"".""PRODUCTS"".""CATEGORY"" AS ""CATEGORY"",
  ""PUBLIC"".""PRODUCTS"".""VENDOR"" AS ""VENDOR"",
  null AS ""PRICE"",
  ""PUBLIC"".""PRODUCTS"".""RATING"" AS ""RATING"",
  ""PUBLIC"".""PRODUCTS"".""CREATED_AT"" AS ""CREATED_AT""
FROM
  ""PUBLIC"".""PRODUCTS""
LIMIT 50)

2. In the GUI Builder take a minimum of price grouped by Category and Vendor
3. View as a Pivot and observe all of the empty price results for the ""Gizmo"" category
4. Add "" dollars"" as a suffix for the price measure
5. Observe the cells now display ""null dollars"" 


### Expected behavior

The cell should still be empty

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-09"",
      ""tag"": ""v1.49.9"",
      ""hash"": ""c0913c7""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

It's not pretty

### Additional context

_No response_",ixipixi,2024-05-17 21:40:39+00:00,['alxnddr'],2024-08-30 03:55:19+00:00,2024-08-30 03:21:36+00:00,https://github.com/metabase/metabase/issues/42867,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2303570760,issue,open,,"""SET SEARCH_PATH"" Transaction Hangs in Idle State in Postgres","### Describe the bug

When Metabase launches a query is executed against the app db to set the ""search_path"" variable in Postgres. The transaction never leaves the ""idle in transaction"" state.

### To Reproduce

1. Start Metabase v48.5 or higher
2. On the application database run:

SELECT pid ,datname ,usename ,application_name ,client_hostname ,client_port ,backend_start ,query_start ,query ,state
FROM pg_stat_activity
WHERE state = 'idle in transaction';

Note that the pid with the ""set search_path"" query in it never resolves.



### Expected behavior

The transaction should complete.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-09"",
      ""tag"": ""v1.49.9"",
      ""hash"": ""c0913c7""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Unclear on if this impacts anything other than leaving a single process hanging since this is already the default setting for this value in Postgres

### Additional context

_No response_",ixipixi,2024-05-17 20:59:38+00:00,[],2025-02-04 20:27:38+00:00,,https://github.com/metabase/metabase/issues/42862,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/', ''), ('.Team/Querying', '')]","[{'comment_id': 2120564609, 'issue_id': 2303570760, 'author': 'darksciencebase', 'body': '@ixipixi is this a neatness issue or was there some particular fallout from this? thinking about the priority here and would like to understand the whole picture', 'created_at': datetime.datetime(2024, 5, 20, 14, 21, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120624925, 'issue_id': 2303570760, 'author': 'ixipixi', 'body': ""@darksciencebase it's not impacting performance afaik but it creates an inconvenience for customers/sys admins/dbas that are monitoring for hanging transactions. They see a transaction stuck in idle for a long time and go research it to discover it's this every time. They know to ignore it but it's not ideal."", 'created_at': datetime.datetime(2024, 5, 20, 14, 53, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620902966, 'issue_id': 2303570760, 'author': 'WiNloSt', 'body': ""I'm trying to assign a team to issues without one. I feels free to forward to a different team where appropriate 🙏"", 'created_at': datetime.datetime(2025, 1, 29, 7, 40, 5, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-05-20 14:21:59 UTC): @ixipixi is this a neatness issue or was there some particular fallout from this? thinking about the priority here and would like to understand the whole picture

ixipixi (Issue Creator) on (2024-05-20 14:53:22 UTC): @darksciencebase it's not impacting performance afaik but it creates an inconvenience for customers/sys admins/dbas that are monitoring for hanging transactions. They see a transaction stuck in idle for a long time and go research it to discover it's this every time. They know to ignore it but it's not ideal.

WiNloSt on (2025-01-29 07:40:05 UTC): I'm trying to assign a team to issues without one. I feels free to forward to a different team where appropriate 🙏

"
2303509087,issue,open,,Global option in settings to set global unformatted for all exports including apis,"**Is your feature request related to a problem? Please describe.**
Global option in settings to set global unformatted for all exports including apis

**Describe the solution you'd like**
I would like an option in the settings to turn the unformat location for all exports (csv or xlsx) as the integers are now showing as ""123,123"" and dates are showing as formatted ""January 1, 2024"" so you can export for a file manually, however, we are using hightouch and this has broken a bunch of our integrations. 


**Describe alternatives you've considered**
Rolling back to Metabase 0.48, however the java -jar metabase.jat migrate down does not work.

**How important is this feature to you?**
considering this has broken around 50 saved questions in metabase that are connected to Hightouch syncs, and these are all sent to various partners, and they are alllll incorrect now.
",todd-gallant,2024-05-17 20:13:55+00:00,[],2024-06-06 23:05:31+00:00,,https://github.com/metabase/metabase/issues/42859,"[('Misc/API', ''), ('Type:New Feature', '')]",[],
2303458736,issue,closed,completed,Choosing the fields to Join On Resets Join Type in the GUI Editor,"### Describe the bug

If you join  two tables in the GUI editor and set the join type to anything other than the default join, choosing the fields to join on causes the join type to revert to default.

### To Reproduce

1. In the Sample Database start a Question with ""Accounts""
2. Add a join to ""People""
3. Change the join type to ""Inner Join""
4. Choose columns to join on (like email)
5. Join type from initial step reverts to ""left outer""


### Expected behavior

If the user changes the join type it should remain unless they change it.


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-09"",
      ""tag"": ""v1.49.9"",
      ""hash"": ""c0913c7""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying and inobvious

### Additional context

_No response_",ixipixi,2024-05-17 19:41:50+00:00,['ranquild'],2024-06-24 13:56:01+00:00,2024-06-24 13:07:14+00:00,https://github.com/metabase/metabase/issues/42858,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2180973924, 'issue_id': 2303458736, 'author': 'ranquild', 'body': ""Unclear if it's FE or MBQL lib, setting FE for now"", 'created_at': datetime.datetime(2024, 6, 20, 15, 24, 31, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-06-20 15:24:31 UTC): Unclear if it's FE or MBQL lib, setting FE for now

"
2303315801,issue,open,,[Epic] Command palette v1.1,"Some potential epics:
- [Command palette: contextualized default state
](https://www.notion.so/metabase/Command-palette-contextualized-default-state-93ad8d696eff46a2bfe893992050496e)
- [Command palette: filters](https://www.notion.so/metabase/Command-palette-filters-0f83e3ced2614d2cb3e04eb5608c966c)
- [Command palette: display metadata](https://www.notion.so/metabase/Command-palette-display-metadata-5813e123645e4b0a883f1a0aeb2ae2b6)
- Add table schema https://metaboat.slack.com/archives/C02H619CJ8K/p1718975157010509
    - #44460",luizarakaki,2024-05-17 18:01:31+00:00,[],2025-02-04 20:27:24+00:00,,https://github.com/metabase/metabase/issues/42849,"[('Organization/Search', ''), ('.Epic', 'Feature Implementation or Project')]",[],
2303285382,issue,open,,[Epic] Upsell system (part 2),[Product doc](https://www.notion.so/metabase/Implement-the-upsell-system-part-2-2a8fff4ad016482e83494f5148ab7997),luizarakaki,2024-05-17 17:42:39+00:00,[],2025-02-04 20:23:55+00:00,,https://github.com/metabase/metabase/issues/42846,"[('Administration/', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2303187596,issue,closed,not_planned,Field filter dropdown is not showing all of the expected options,"### Describe the bug

I have a field filter linked to all of the charts on my [dashboard](https://loop.metabaseapp.com/dashboard/234-parcel-rate-errors?tenant_qid=qid%3A%3Atenant%3Ac468614d-6ad3-4312-bb54-61073e526114&invoiced_after=&invoiced_before=&carrier=&invoice_numbers=&tracking_number=&charge_type=) and there should be 3 options showing up in the dropdown, but only 2 are showing up. I triple checked that the data contains all 3 values, and for whatever reason the third will not show up. The only way I can get it to show up is if I make all 3 the default value (see screenshot). But as soon as I unselect the missing value ""UPS,"" it disappears from the dropdown.
<img width=""1492"" alt=""Screenshot 2024-05-17 at 11 38 06 AM"" src=""https://github.com/metabase/metabase/assets/147414454/a2f1843f-d93e-46b5-bc89-f1e1110ae890"">
<img width=""338"" alt=""Screenshot 2024-05-17 at 11 38 26 AM"" src=""https://github.com/metabase/metabase/assets/147414454/95d10470-9d60-4e5f-9d51-0a45e0ef8273"">
<img width=""337"" alt=""Screenshot 2024-05-17 at 11 38 43 AM"" src=""https://github.com/metabase/metabase/assets/147414454/574a504a-14b9-4a36-b6dc-74ad2b9d8566"">
I'm confident that ""UPS"" data is in the charts on the dashboard, because when I set it to ONLY use UPS using the hack I figured out, the dashboard is populated with data (see screenshot).
<img width=""1489"" alt=""Screenshot 2024-05-17 at 11 40 23 AM"" src=""https://github.com/metabase/metabase/assets/147414454/53db78b3-549b-47df-860d-67100a17a703"">


### To Reproduce

1. Go to this [dashboard](https://loop.metabaseapp.com/dashboard/234-parcel-rate-errors?tenant_qid=qid%3A%3Atenant%3Ac468614d-6ad3-4312-bb54-61073e526114&invoiced_after=&invoiced_before=&carrier=DHL&carrier=FedEx&invoice_numbers=&tracking_number=&charge_type=)
2. Click on the Carrier filter
3. See error - the options should be ""UPS"" ""FedEx"" and ""DHL,"" but only ""FedEx"" and ""DHL"" are showing up. If you remove the filter all together, you will see that UPS data does indeed exist in the reports that this filter is attached to.


### Expected behavior

This dropdown filter should be showing 3 options, not 2: ""UPS"" ""FedEx"" and ""DHL""

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-13"",
      ""tag"": ""v1.49.10"",
      ""hash"": ""9e8fc83""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

[metabase-bug.webm](https://github.com/metabase/metabase/assets/147414454/956fe059-bb27-4fbc-95ac-ed48afc1dc9e)
",carolineloop,2024-05-17 16:45:56+00:00,[],2024-09-13 23:46:29+00:00,2024-09-13 23:46:29+00:00,https://github.com/metabase/metabase/issues/42841,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Product Input Needed', ''), ('.Team/Querying', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2118102554, 'issue_id': 2303187596, 'author': 'paoliniluis', 'body': 'Are the filters linked_', 'created_at': datetime.datetime(2024, 5, 17, 17, 41, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2118129075, 'issue_id': 2303187596, 'author': 'carolineloop', 'body': 'Yes the filter is linked to all of the other field filters on the dashboard. However, the one that removes ""UPS"" is the tenant_qid filter. Except when I run a ""distinct"" query with the table that the field filter is derived from WITH the tenant_qid field filter applied, it returns all 3 expected values. So I think it must be bug that\'s causing only 2 to show up in the dropdown.', 'created_at': datetime.datetime(2024, 5, 17, 17, 59, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204972960, 'issue_id': 2303187596, 'author': 'ranquild', 'body': ""Reassigned to DashViz because it's Linked filters. My take - this is probably working as intended because linked filters do not take connected cards into account."", 'created_at': datetime.datetime(2024, 7, 3, 2, 58, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323105994, 'issue_id': 2303187596, 'author': 'paoliniluis', 'body': '@carolineloop are you still hitting this? if so, please send us an email to help at metabase dot com', 'created_at': datetime.datetime(2024, 9, 1, 1, 32, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325573560, 'issue_id': 2303187596, 'author': 'carolineloop', 'body': ""I don't believe it's come up again, no - I will reach out at the email if\r\nneeded! Thanks!\r\n\r\nOn Sat, Aug 31, 2024 at 8:32\u202fPM Luis Paolini ***@***.***>\r\nwrote:\r\n\r\n> @carolineloop <https://github.com/carolineloop> are you still hitting\r\n> this? if so, please send us an email to help at metabase dot com\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/42841#issuecomment-2323105994>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BDEV3NRLGEP6CAUJGG2NFTDZUJVEPAVCNFSM6AAAAABH4OXR72VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMRTGEYDKOJZGQ>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 9, 3, 4, 17, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-17 17:41:05 UTC): Are the filters linked_

carolineloop (Issue Creator) on (2024-05-17 17:59:44 UTC): Yes the filter is linked to all of the other field filters on the dashboard. However, the one that removes ""UPS"" is the tenant_qid filter. Except when I run a ""distinct"" query with the table that the field filter is derived from WITH the tenant_qid field filter applied, it returns all 3 expected values. So I think it must be bug that's causing only 2 to show up in the dropdown.

ranquild on (2024-07-03 02:58:41 UTC): Reassigned to DashViz because it's Linked filters. My take - this is probably working as intended because linked filters do not take connected cards into account.

paoliniluis on (2024-09-01 01:32:33 UTC): @carolineloop are you still hitting this? if so, please send us an email to help at metabase dot com

carolineloop (Issue Creator) on (2024-09-03 04:17:46 UTC): I don't believe it's come up again, no - I will reach out at the email if
needed! Thanks!

On Sat, Aug 31, 2024 at 8:32 PM Luis Paolini ***@***.***>
wrote:

"
2302997682,issue,closed,completed,Milestone Reminder GH Action doesn't always work,"### Describe the bug

We have a very useful milestone reminder GH action, but it doesn't always work as expected.
There are two scenarios we need to fix:
1. The action sometimes literally fails because of an exception ([example](https://github.com/metabase/metabase/actions/runs/9129775294))
2. The action posting a comment on PRs that don't even have the closing keyword ([example](https://github.com/metabase/metabase/pull/42624#issuecomment-2110361435))

### To Reproduce

1. Close a PR that contains this body: `Closes #12345 and #23456`

or 

2. Close a PR that doesn't have a closing keyword at all.


### Expected behavior

1. Action should never fail
2. Action should not post comments on PRs that didn't have the closing keyword and a linked issue to begin with

### Logs

_No response_

### Information about your Metabase installation

```JSON
.
```


### Severity

p3

### Additional context

Internal.",nemanjaglumac,2024-05-17 15:14:04+00:00,['nemanjaglumac'],2024-10-08 17:08:43+00:00,2024-06-06 22:44:56+00:00,https://github.com/metabase/metabase/issues/42835,"[('.CI & Tests', ''), ('.DX', 'Developer experience and QoL related.')]","[{'comment_id': 2118258625, 'issue_id': 2302997682, 'author': 'darksciencebase', 'body': ""I'm probably missing something, but if a PR doesn't have a closing keyword, that means it's not connected to an issue, which in turn means the PR itself should have a milestone, so I'm lost about the #2 in the description."", 'created_at': datetime.datetime(2024, 5, 17, 19, 37, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2118323128, 'issue_id': 2302997682, 'author': 'nemanjaglumac', 'body': ""> which in turn means the PR itself should have a milestone\r\n\r\nNot always. There are a ton of tech debt PRs that don't really need a milestone. I'm not aware that we're enforcing a milestone in 100% of cases?"", 'created_at': datetime.datetime(2024, 5, 17, 20, 17, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119899421, 'issue_id': 2302997682, 'author': 'darksciencebase', 'body': ""> Not always. There are a ton of tech debt PRs that don't really need a milestone. I'm not aware that we're enforcing a milestone in 100% of cases?\r\n\r\nnot 100% but (1) better too many PRs than too few, (2) many tech debt PRs should have a milestons, (3) the reminder doesn't know a difference. let's continue this discussion on the notion doc explaining our usage of milestones"", 'created_at': datetime.datetime(2024, 5, 20, 8, 4, 49, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-05-17 19:37:32 UTC): I'm probably missing something, but if a PR doesn't have a closing keyword, that means it's not connected to an issue, which in turn means the PR itself should have a milestone, so I'm lost about the #2 in the description.

nemanjaglumac (Issue Creator) on (2024-05-17 20:17:13 UTC): Not always. There are a ton of tech debt PRs that don't really need a milestone. I'm not aware that we're enforcing a milestone in 100% of cases?

darksciencebase on (2024-05-20 08:04:49 UTC): not 100% but (1) better too many PRs than too few, (2) many tech debt PRs should have a milestons, (3) the reminder doesn't know a difference. let's continue this discussion on the notion doc explaining our usage of milestones

"
2302853687,issue,closed,completed,Optimize creating preview queries on the FE,"Currently the FE constructs preview queries by dropping clauses from the main query https://github.com/metabase/metabase/blob/76a473a786f128e7b70e23f5d63606eeacbed178/frontend/src/metabase/query_builder/components/notebook/lib/steps.ts#L313 This is very inefficient and caused significant performance issues in the fast. We added a workaround by computing the preview query for each step only when the user clicks the preview button. It's no longer the case now because we need to compute preview queries upfront to calculate whether the query is valid for previewing. So now performance issues are back. 

We need a performant way to construct preview queries. It should be straightforward to add a MBQL lib function for this:

```
type ClauseType = 
  | ""data""
  | ""joins""
  | ""expressions""
  | ""filter""
  | ""aggregation""
  | ""breakout""
  | ""order-by""
  | ""limit"";

function previewQuery(query: Query, stageIndex: number, clauseType: ClauseType, clauseIndex: number | null): Query
```

The function should return a query with all the stages after `stageIndex` dropped, and all the clauses after `clauseType` dropped. Also `clauseIndex` can be optionally provided; in this case only clauses of this type in the range `[0, clauseIndex]` should remain. 

Examples:

```
const query = {
  ""source-table"": 1,
  ""joins"": [join1, join2],
  ""expressions: { ... },
  ""filter"": [""and, filter1, filter],
  ""aggregation"": [aggregation1, aggregation2],
  ""breakout"": [breakout1, breakout2],
  ...
}

previewQuery(query, 0, ""data"") =>
{
  ""source-table"": 1,
}

previewQuery(query, 0, ""joins"") =>
{
  ""source-table"": 1,
  ""joins"": [join1, join2]
}

previewQuery(query, 0, ""joins"", 0) =>
{
  ""source-table"": 1,
  ""joins"": [join1]
}

previewQuery(query, 0, ""expressions"") =>
{
  ""source-table"": 1,
  ""joins"": [join1, join2],
  ""expressions"": { ... }
}
```

",ranquild,2024-05-17 14:07:01+00:00,['bshepherdson'],2024-05-29 19:24:24+00:00,2024-05-29 19:24:23+00:00,https://github.com/metabase/metabase/issues/42831,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2302802067,issue,closed,completed,Field values do not work properly in public dashboards when models are used,"### Describe the bug

When you have a dashboard filter, which is linked to a question that aggregates results, the request to get possible filtering options fails with a 500 error. The query it generates references a column that does not exist, as it is structure in a way that attempts to get possible values **after** aggregating, instead of prior.

### To Reproduce

1. Standup a MB instance with sample data (H2) and default configuration
1. Create an SQL model against the sample data, with the following query: `select * from people`
1. Create a UI builder question that uses the model
1. Add a ""Distinct values of State"" under ""Summarize"", then save the question
1. Add the question to a new dashboard
1. Add a new ""Text or Category"" filter
1. Select ""Is"" for filter type
1. Select ""State"" on the question's ""Column to filter on"" -- this should configure the filter to pull values from connected fields
1. Save the dashboard
1. Open the browser developer tools, then the network tab
1. Click the filter field, and inspect the failed request 

### Expected behavior

The request should not fail, and should return values that can be selected for filtering.

### Logs

JS logs:

![Screenshot 2024-05-17 at 9 26 17 AM](https://github.com/metabase/metabase/assets/634835/73ce7508-3436-46a5-a53c-c56c2143ee19)

Error response:

```json
{
  ""via"": [
    {
      ""type"": ""clojure.lang.ExceptionInfo"",
      ""message"": ""Error executing query: Column \""source.STATE\"" not found; SQL statement:\nSELECT \""source\"".\""STATE\"" AS \""STATE\"" FROM (SELECT count(distinct \""source\"".\""STATE\"") AS \""count\"" FROM (select * from people) AS \""source\"") AS \""source\"" WHERE \""source\"".\""STATE\"" IS NOT NULL GROUP BY \""source\"".\""STATE\"" ORDER BY \""source\"".\""STATE\"" ASC LIMIT 1000 [42122-214]"",
      ""data"": {
        ""driver"": ""h2"",
        ""sql"": [
          ""-- Metabase"",
          ""SELECT"",
          ""  \""source\"".\""STATE\"" AS \""STATE\"""",
          ""FROM"",
          ""  ("",
          ""    SELECT"",
          ""      count(distinct \""source\"".\""STATE\"") AS \""count\"""",
          ""    FROM"",
          ""      ("",
          ""        select"",
          ""          *"",
          ""        from"",
          ""          people"",
          ""      ) AS \""source\"""",
          ""  ) AS \""source\"""",
          ""WHERE"",
          ""  \""source\"".\""STATE\"" IS NOT NULL"",
          ""GROUP BY"",
          ""  \""source\"".\""STATE\"""",
          ""ORDER BY"",
          ""  \""source\"".\""STATE\"" ASC"",
          ""LIMIT"",
          ""  1000""
        ],
        ""params"": null,
        ""type"": ""invalid-query""
      },
      ""at"": [
        ""metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__79490$fn__79491"",
        ""invoke"",
        ""execute.clj"",
        702
      ]
    },
    {
      ""type"": ""org.h2.jdbc.JdbcSQLSyntaxErrorException"",
      ""message"": ""Column \""source.STATE\"" not found; SQL statement:\nSELECT \""source\"".\""STATE\"" AS \""STATE\"" FROM (SELECT count(distinct \""source\"".\""STATE\"") AS \""count\"" FROM (select * from people) AS \""source\"") AS \""source\"" WHERE \""source\"".\""STATE\"" IS NOT NULL GROUP BY \""source\"".\""STATE\"" ORDER BY \""source\"".\""STATE\"" ASC LIMIT 1000 [42122-214]"",
      ""at"": [
        ""org.h2.message.DbException"",
        ""getJdbcSQLException"",
        ""DbException.java"",
        502
      ]
    }
  ],
  ""trace"": [
    [
      ""org.h2.message.DbException"",
      ""getJdbcSQLException"",
      ""DbException.java"",
      502
    ],
    [
      ""org.h2.message.DbException"",
      ""getJdbcSQLException"",
      ""DbException.java"",
      477
    ],
    [
      ""org.h2.message.DbException"",
      ""get"",
      ""DbException.java"",
      223
    ],
    [
      ""org.h2.message.DbException"",
      ""get"",
      ""DbException.java"",
      199
    ],
    [
      ""org.h2.expression.ExpressionColumn"",
      ""getColumnException"",
      ""ExpressionColumn.java"",
      244
    ],
    [
      ""org.h2.expression.ExpressionColumn"",
      ""optimizeOther"",
      ""ExpressionColumn.java"",
      226
    ],
    [
      ""org.h2.expression.ExpressionColumn"",
      ""optimize"",
      ""ExpressionColumn.java"",
      213
    ],
    [
      ""org.h2.expression.Alias"",
      ""optimize"",
      ""Alias.java"",
      52
    ],
    [
      ""org.h2.command.query.Select"",
      ""prepareExpressions"",
      ""Select.java"",
      1170
    ],
    [
      ""org.h2.command.query.Query"",
      ""prepare"",
      ""Query.java"",
      218
    ],
    [
      ""org.h2.command.Parser"",
      ""prepareCommand"",
      ""Parser.java"",
      575
    ],
    [
      ""org.h2.engine.SessionLocal"",
      ""prepareLocal"",
      ""SessionLocal.java"",
      631
    ],
    [
      ""org.h2.engine.SessionLocal"",
      ""prepareCommand"",
      ""SessionLocal.java"",
      554
    ],
    [
      ""org.h2.jdbc.JdbcConnection"",
      ""prepareCommand"",
      ""JdbcConnection.java"",
      1116
    ],
    [
      ""org.h2.jdbc.JdbcStatement"",
      ""executeInternal"",
      ""JdbcStatement.java"",
      237
    ],
    [
      ""org.h2.jdbc.JdbcStatement"",
      ""execute"",
      ""JdbcStatement.java"",
      223
    ],
    [
      ""com.mchange.v2.c3p0.impl.NewProxyStatement"",
      ""execute"",
      ""NewProxyStatement.java"",
      75
    ],
    [
      ""metabase.driver.sql_jdbc.execute$fn__79409"",
      ""invokeStatic"",
      ""execute.clj"",
      561
    ],
    [
      ""metabase.driver.sql_jdbc.execute$fn__79409"",
      ""invoke"",
      ""execute.clj"",
      559
    ],
    [
      ""clojure.lang.MultiFn"",
      ""invoke"",
      ""MultiFn.java"",
      239
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_"",
      ""invokeStatic"",
      ""execute.clj"",
      569
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_"",
      ""invoke"",
      ""execute.clj"",
      566
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__79490$fn__79491"",
      ""invoke"",
      ""execute.clj"",
      700
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__79490"",
      ""invoke"",
      ""execute.clj"",
      699
    ],
    [
      ""metabase.driver.h2$fn__81730$fn__81732"",
      ""invoke"",
      ""h2.clj"",
      535
    ],
    [
      ""metabase.driver.sql_jdbc.execute$do_with_resolved_connection"",
      ""invokeStatic"",
      ""execute.clj"",
      335
    ],
    [
      ""metabase.driver.sql_jdbc.execute$do_with_resolved_connection"",
      ""invoke"",
      ""execute.clj"",
      318
    ],
    [
      ""metabase.driver.h2$fn__81730"",
      ""invokeStatic"",
      ""h2.clj"",
      526
    ],
    [
      ""metabase.driver.h2$fn__81730"",
      ""invoke"",
      ""h2.clj"",
      522
    ],
    [
      ""clojure.lang.MultiFn"",
      ""invoke"",
      ""MultiFn.java"",
      244
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query"",
      ""invokeStatic"",
      ""execute.clj"",
      693
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query"",
      ""invoke"",
      ""execute.clj"",
      679
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query"",
      ""invokeStatic"",
      ""execute.clj"",
      690
    ],
    [
      ""metabase.driver.sql_jdbc.execute$execute_reducible_query"",
      ""invoke"",
      ""execute.clj"",
      679
    ],
    [
      ""metabase.driver.sql_jdbc$fn__106839"",
      ""invokeStatic"",
      ""sql_jdbc.clj"",
      78
    ],
    [
      ""metabase.driver.sql_jdbc$fn__106839"",
      ""invoke"",
      ""sql_jdbc.clj"",
      76
    ],
    [
      ""metabase.driver.h2$fn__81571"",
      ""invokeStatic"",
      ""h2.clj"",
      272
    ],
    [
      ""metabase.driver.h2$fn__81571"",
      ""invoke"",
      ""h2.clj"",
      268
    ],
    [
      ""clojure.lang.MultiFn"",
      ""invoke"",
      ""MultiFn.java"",
      244
    ],
    [
      ""metabase.query_processor.context$executef"",
      ""invokeStatic"",
      ""context.clj"",
      60
    ],
    [
      ""metabase.query_processor.context$executef"",
      ""invoke"",
      ""context.clj"",
      49
    ],
    [
      ""metabase.query_processor.context.default$default_runf"",
      ""invokeStatic"",
      ""default.clj"",
      44
    ],
    [
      ""metabase.query_processor.context.default$default_runf"",
      ""invoke"",
      ""default.clj"",
      42
    ],
    [
      ""metabase.query_processor.context$runf"",
      ""invokeStatic"",
      ""context.clj"",
      46
    ],
    [
      ""metabase.query_processor.context$runf"",
      ""invoke"",
      ""context.clj"",
      40
    ],
    [
      ""metabase.query_processor.reducible$identity_qp"",
      ""invokeStatic"",
      ""reducible.clj"",
      39
    ],
    [
      ""metabase.query_processor.reducible$identity_qp"",
      ""invoke"",
      ""reducible.clj"",
      36
    ],
    [
      ""metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72307"",
      ""invoke"",
      ""cache.clj"",
      229
    ],
    [
      ""metabase.query_processor.middleware.permissions$check_query_permissions$fn__66656"",
      ""invoke"",
      ""permissions.clj"",
      140
    ],
    [
      ""metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72128"",
      ""invoke"",
      ""enterprise.clj"",
      51
    ],
    [
      ""metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72138"",
      ""invoke"",
      ""enterprise.clj"",
      64
    ],
    [
      ""metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71570"",
      ""invoke"",
      ""mbql_to_native.clj"",
      24
    ],
    [
      ""metabase.query_processor$fn__73475$combined_post_process__73480$combined_post_process_STAR___73481"",
      ""invoke"",
      ""query_processor.clj"",
      262
    ],
    [
      ""metabase.query_processor$fn__73475$combined_pre_process__73476$combined_pre_process_STAR___73477"",
      ""invoke"",
      ""query_processor.clj"",
      259
    ],
    [
      ""metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66753"",
      ""invoke"",
      ""fetch_source_query.clj"",
      299
    ],
    [
      ""metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72218$fn__72222"",
      ""invoke"",
      ""resolve_database_and_driver.clj"",
      77
    ],
    [
      ""metabase.driver$do_with_driver"",
      ""invokeStatic"",
      ""driver.clj"",
      97
    ],
    [
      ""metabase.driver$do_with_driver"",
      ""invoke"",
      ""driver.clj"",
      92
    ],
    [
      ""metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72218"",
      ""invoke"",
      ""resolve_database_and_driver.clj"",
      76
    ],
    [
      ""metabase.query_processor.middleware.store$initialize_store$fn__67380$fn__67381"",
      ""invoke"",
      ""store.clj"",
      14
    ],
    [
      ""metabase.query_processor.store$do_with_metadata_provider"",
      ""invokeStatic"",
      ""store.clj"",
      169
    ],
    [
      ""metabase.query_processor.store$do_with_metadata_provider"",
      ""invoke"",
      ""store.clj"",
      150
    ],
    [
      ""metabase.query_processor.store$do_with_metadata_provider"",
      ""invokeStatic"",
      ""store.clj"",
      158
    ],
    [
      ""metabase.query_processor.store$do_with_metadata_provider"",
      ""invoke"",
      ""store.clj"",
      150
    ],
    [
      ""metabase.query_processor.middleware.store$initialize_store$fn__67380"",
      ""invoke"",
      ""store.clj"",
      13
    ],
    [
      ""metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72215"",
      ""invoke"",
      ""resolve_database_and_driver.clj"",
      60
    ],
    [
      ""metabase.query_processor.middleware.normalize_query$normalize$fn__72520"",
      ""invoke"",
      ""normalize_query.clj"",
      38
    ],
    [
      ""metabase.query_processor.middleware.enterprise$fn__72155$handle_audit_app_internal_queries__72156$fn__72158"",
      ""invoke"",
      ""enterprise.clj"",
      96
    ],
    [
      ""metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72166"",
      ""invoke"",
      ""enterprise.clj"",
      103
    ],
    [
      ""metabase.query_processor.reducible$async_qp$qp_STAR___62893$thunk__62895"",
      ""invoke"",
      ""reducible.clj"",
      126
    ],
    [
      ""metabase.query_processor.reducible$async_qp$qp_STAR___62893"",
      ""invoke"",
      ""reducible.clj"",
      132
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      667
    ],
    [
      ""clojure.core$apply"",
      ""invoke"",
      ""core.clj"",
      662
    ],
    [
      ""metabase.query_processor.reducible$sync_qp$qp_STAR___62905"",
      ""doInvoke"",
      ""reducible.clj"",
      153
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invokeStatic"",
      ""query_processor.clj"",
      311
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invoke"",
      ""query_processor.clj"",
      291
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invokeStatic"",
      ""query_processor.clj"",
      299
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invoke"",
      ""query_processor.clj"",
      291
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invokeStatic"",
      ""query_processor.clj"",
      296
    ],
    [
      ""metabase.query_processor$process_query"",
      ""invoke"",
      ""query_processor.clj"",
      291
    ],
    [
      ""metabase.models.params.custom_values$values_from_card"",
      ""invokeStatic"",
      ""custom_values.clj"",
      97
    ],
    [
      ""metabase.models.params.custom_values$values_from_card"",
      ""invoke"",
      ""custom_values.clj"",
      76
    ],
    [
      ""metabase.models.params.custom_values$values_from_card"",
      ""invokeStatic"",
      ""custom_values.clj"",
      91
    ],
    [
      ""metabase.models.params.custom_values$values_from_card"",
      ""invoke"",
      ""custom_values.clj"",
      76
    ],
    [
      ""metabase.api.dashboard$filter_values_from_field_refs$iter__95151__95155$fn__95156"",
      ""invoke"",
      ""dashboard.clj"",
      973
    ],
    [
      ""clojure.lang.LazySeq"",
      ""sval"",
      ""LazySeq.java"",
      42
    ],
    [
      ""clojure.lang.LazySeq"",
      ""seq"",
      ""LazySeq.java"",
      51
    ],
    [
      ""clojure.lang.RT"",
      ""seq"",
      ""RT.java"",
      535
    ],
    [
      ""clojure.core$seq__5467"",
      ""invokeStatic"",
      ""core.clj"",
      139
    ],
    [
      ""clojure.core$map$fn__5935"",
      ""invoke"",
      ""core.clj"",
      2763
    ],
    [
      ""clojure.lang.LazySeq"",
      ""sval"",
      ""LazySeq.java"",
      42
    ],
    [
      ""clojure.lang.LazySeq"",
      ""seq"",
      ""LazySeq.java"",
      51
    ],
    [
      ""clojure.lang.RT"",
      ""seq"",
      ""RT.java"",
      535
    ],
    [
      ""clojure.core$seq__5467"",
      ""invokeStatic"",
      ""core.clj"",
      139
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      662
    ],
    [
      ""clojure.core$mapcat"",
      ""invokeStatic"",
      ""core.clj"",
      2800
    ],
    [
      ""clojure.core$mapcat"",
      ""doInvoke"",
      ""core.clj"",
      2800
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      423
    ],
    [
      ""metabase.api.dashboard$filter_values_from_field_refs"",
      ""invokeStatic"",
      ""dashboard.clj"",
      974
    ],
    [
      ""metabase.api.dashboard$filter_values_from_field_refs"",
      ""invoke"",
      ""dashboard.clj"",
      963
    ],
    [
      ""metabase.api.dashboard$chain_filter"",
      ""invokeStatic"",
      ""dashboard.clj"",
      999
    ],
    [
      ""metabase.api.dashboard$chain_filter"",
      ""invoke"",
      ""dashboard.clj"",
      983
    ],
    [
      ""metabase.api.dashboard$param_values$fn__95189"",
      ""invoke"",
      ""dashboard.clj"",
      1045
    ],
    [
      ""metabase.models.params.custom_values$parameter__GT_values"",
      ""invokeStatic"",
      ""custom_values.clj"",
      134
    ],
    [
      ""metabase.models.params.custom_values$parameter__GT_values"",
      ""invoke"",
      ""custom_values.clj"",
      119
    ],
    [
      ""metabase.api.dashboard$param_values"",
      ""invokeStatic"",
      ""dashboard.clj"",
      1042
    ],
    [
      ""metabase.api.dashboard$param_values"",
      ""invoke"",
      ""dashboard.clj"",
      1022
    ],
    [
      ""metabase.api.dashboard$param_values"",
      ""invokeStatic"",
      ""dashboard.clj"",
      1030
    ],
    [
      ""metabase.api.dashboard$param_values"",
      ""invoke"",
      ""dashboard.clj"",
      1022
    ],
    [
      ""metabase.api.dashboard$fn__95192$fn__95194"",
      ""invoke"",
      ""dashboard.clj"",
      1058
    ],
    [
      ""metabase.api.dashboard$fn__95192"",
      ""invokeStatic"",
      ""dashboard.clj"",
      1057
    ],
    [
      ""metabase.api.dashboard$fn__95192"",
      ""invoke"",
      ""dashboard.clj"",
      1047
    ],
    [
      ""compojure.core$wrap_response$fn__44694"",
      ""invoke"",
      ""core.clj"",
      160
    ],
    [
      ""compojure.core$wrap_route_middleware$fn__44678"",
      ""invoke"",
      ""core.clj"",
      132
    ],
    [
      ""compojure.core$wrap_route_info$fn__44683"",
      ""invoke"",
      ""core.clj"",
      139
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      151
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""metabase.server.middleware.auth$enforce_authentication$fn__94049"",
      ""invoke"",
      ""auth.clj"",
      17
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$make_context$handler__44734"",
      ""invoke"",
      ""core.clj"",
      290
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      300
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""metabase.api.routes$fn__102082$fn__102085"",
      ""invoke"",
      ""routes.clj"",
      67
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      667
    ],
    [
      ""clojure.core$apply"",
      ""invoke"",
      ""core.clj"",
      662
    ],
    [
      ""metabase.server.routes$fn__102247$fn__102248"",
      ""doInvoke"",
      ""routes.clj"",
      72
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$make_context$handler__44734"",
      ""invoke"",
      ""core.clj"",
      290
    ],
    [
      ""compojure.core$make_context$fn__44738"",
      ""invoke"",
      ""core.clj"",
      300
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__44687"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707$respond_SINGLEQUOTE___44708"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""metabase.server.routes$fn__102232$fn__102234"",
      ""invoke"",
      ""routes.clj"",
      49
    ],
    [
      ""compojure.core$routes$fn__44706$f__44707"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__44706"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98793"",
      ""invoke"",
      ""exceptions.clj"",
      108
    ],
    [
      ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__98790"",
      ""invoke"",
      ""exceptions.clj"",
      96
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__102524$fn__102525$fn__102526"",
      ""invoke"",
      ""log.clj"",
      230
    ],
    [
      ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
      ""invokeStatic"",
      ""diagnostic.clj"",
      18
    ],
    [
      ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
      ""invoke"",
      ""diagnostic.clj"",
      12
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__102524$fn__102525"",
      ""invoke"",
      ""log.clj"",
      222
    ],
    [
      ""toucan2.execute$do_with_call_counts"",
      ""invokeStatic"",
      ""execute.clj"",
      112
    ],
    [
      ""toucan2.execute$do_with_call_counts"",
      ""invoke"",
      ""execute.clj"",
      103
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__102524"",
      ""invoke"",
      ""log.clj"",
      221
    ],
    [
      ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104589"",
      ""invoke"",
      ""browser_cookie.clj"",
      40
    ],
    [
      ""metabase.server.middleware.security$add_security_headers$fn__98749"",
      ""invoke"",
      ""security.clj"",
      182
    ],
    [
      ""metabase.server.middleware.json$wrap_json_body$fn__46051"",
      ""invoke"",
      ""json.clj"",
      67
    ],
    [
      ""metabase.server.middleware.offset_paging$handle_paging$fn__84947"",
      ""invoke"",
      ""offset_paging.clj"",
      43
    ],
    [
      ""metabase.server.middleware.json$wrap_streamed_json_response$fn__46069"",
      ""invoke"",
      ""json.clj"",
      103
    ],
    [
      ""ring.middleware.keyword_params$wrap_keyword_params$fn__104856"",
      ""invoke"",
      ""keyword_params.clj"",
      55
    ],
    [
      ""ring.middleware.params$wrap_params$fn__104875"",
      ""invoke"",
      ""params.clj"",
      77
    ],
    [
      ""metabase.server.middleware.misc$maybe_set_site_url$fn__67295"",
      ""invoke"",
      ""misc.clj"",
      61
    ],
    [
      ""metabase.server.middleware.session$reset_session_timeout$fn__72726"",
      ""invoke"",
      ""session.clj"",
      546
    ],
    [
      ""metabase.server.middleware.session$bind_current_user$fn__72692$fn__72693"",
      ""invoke"",
      ""session.clj"",
      440
    ],
    [
      ""metabase.server.middleware.session$do_with_current_user"",
      ""invokeStatic"",
      ""session.clj"",
      419
    ],
    [
      ""metabase.server.middleware.session$do_with_current_user"",
      ""invoke"",
      ""session.clj"",
      403
    ],
    [
      ""metabase.server.middleware.session$bind_current_user$fn__72692"",
      ""invoke"",
      ""session.clj"",
      439
    ],
    [
      ""metabase.server.middleware.session$wrap_current_user_info$fn__72675"",
      ""invoke"",
      ""session.clj"",
      378
    ],
    [
      ""metabase.server.middleware.session$wrap_session_id$fn__72647"",
      ""invoke"",
      ""session.clj"",
      257
    ],
    [
      ""metabase.server.middleware.auth$wrap_static_api_key$fn__94057"",
      ""invoke"",
      ""auth.clj"",
      30
    ],
    [
      ""ring.middleware.cookies$wrap_cookies$fn__104776"",
      ""invoke"",
      ""cookies.clj"",
      194
    ],
    [
      ""metabase.server.middleware.misc$add_content_type$fn__67277"",
      ""invoke"",
      ""misc.clj"",
      29
    ],
    [
      ""metabase.server.middleware.misc$disable_streaming_buffering$fn__67303"",
      ""invoke"",
      ""misc.clj"",
      78
    ],
    [
      ""ring.middleware.gzip$wrap_gzip$fn__104818"",
      ""invoke"",
      ""gzip.clj"",
      86
    ],
    [
      ""metabase.server.middleware.misc$bind_request$fn__67306"",
      ""invoke"",
      ""misc.clj"",
      95
    ],
    [
      ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104605"",
      ""invoke"",
      ""ssl.clj"",
      41
    ],
    [
      ""metabase.server$async_proxy_handler$fn__67717"",
      ""invoke"",
      ""server.clj"",
      78
    ],
    [
      ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
      ""handle"",
      null,
      -1
    ],
    [
      ""org.eclipse.jetty.server.handler.StatisticsHandler"",
      ""handle"",
      ""StatisticsHandler.java"",
      173
    ],
    [
      ""org.eclipse.jetty.server.handler.HandlerWrapper"",
      ""handle"",
      ""HandlerWrapper.java"",
      122
    ],
    [
      ""org.eclipse.jetty.server.Server"",
      ""handle"",
      ""Server.java"",
      563
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
      ""dispatch"",
      ""HttpChannel.java"",
      1598
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel"",
      ""dispatch"",
      ""HttpChannel.java"",
      753
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel"",
      ""handle"",
      ""HttpChannel.java"",
      501
    ],
    [
      ""org.eclipse.jetty.server.HttpConnection"",
      ""onFillable"",
      ""HttpConnection.java"",
      287
    ],
    [
      ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
      ""succeeded"",
      ""AbstractConnection.java"",
      314
    ],
    [
      ""org.eclipse.jetty.io.FillInterest"",
      ""fillable"",
      ""FillInterest.java"",
      100
    ],
    [
      ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
      ""run"",
      ""SelectableChannelEndPoint.java"",
      53
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""runTask"",
      ""AdaptiveExecutionStrategy.java"",
      421
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""consumeTask"",
      ""AdaptiveExecutionStrategy.java"",
      390
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""tryProduce"",
      ""AdaptiveExecutionStrategy.java"",
      277
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""run"",
      ""AdaptiveExecutionStrategy.java"",
      199
    ],
    [
      ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
      ""run"",
      ""ReservedThreadExecutor.java"",
      411
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
      ""runJob"",
      ""QueuedThreadPool.java"",
      969
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
      ""doRunJob"",
      ""QueuedThreadPool.java"",
      1194
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
      ""run"",
      ""QueuedThreadPool.java"",
      1149
    ],
    [
      ""java.lang.Thread"",
      ""run"",
      null,
      -1
    ]
  ],
  ""cause"": ""Column \""source.STATE\"" not found; SQL statement:\nSELECT \""source\"".\""STATE\"" AS \""STATE\"" FROM (SELECT count(distinct \""source\"".\""STATE\"") AS \""count\"" FROM (select * from people) AS \""source\"") AS \""source\"" WHERE \""source\"".\""STATE\"" IS NOT NULL GROUP BY \""source\"".\""STATE\"" ORDER BY \""source\"".\""STATE\"" ASC LIMIT 1000 [42122-214]"",
  ""message"": ""Error executing query: Column \""source.STATE\"" not found; SQL statement:\nSELECT \""source\"".\""STATE\"" AS \""STATE\"" FROM (SELECT count(distinct \""source\"".\""STATE\"") AS \""count\"" FROM (select * from people) AS \""source\"") AS \""source\"" WHERE \""source\"".\""STATE\"" IS NOT NULL GROUP BY \""source\"".\""STATE\"" ORDER BY \""source\"".\""STATE\"" ASC LIMIT 1000 [42122-214]"",
  ""driver"": ""h2"",
  ""sql"": [
    ""-- Metabase"",
    ""SELECT"",
    ""  \""source\"".\""STATE\"" AS \""STATE\"""",
    ""FROM"",
    ""  ("",
    ""    SELECT"",
    ""      count(distinct \""source\"".\""STATE\"") AS \""count\"""",
    ""    FROM"",
    ""      ("",
    ""        select"",
    ""          *"",
    ""        from"",
    ""          people"",
    ""      ) AS \""source\"""",
    ""  ) AS \""source\"""",
    ""WHERE"",
    ""  \""source\"".\""STATE\"" IS NOT NULL"",
    ""GROUP BY"",
    ""  \""source\"".\""STATE\"""",
    ""ORDER BY"",
    ""  \""source\"".\""STATE\"" ASC"",
    ""LIMIT"",
    ""  1000""
  ],
  ""params"": null
}
```

### Information about your Metabase installation

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.26-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.2 (Debian 15.2-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v0.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking usage of Metabase (almost) entirely

### Additional context

This bug is not specific to version 0.49.11, and has been seen on other versions, including prior to the 0.49.x branch.

Attempted to aggregate using both ""distinct values of"" and ""average of"" summarization. Did not test others.

Tested with both the sample database, as well as a Postgres database.

Also attempted with a UI builder model (essentially the same query) with similar, but slightly different behavior. The options endpoint still fails, but when selecting a question field to link, I had to select a field other than `STATE`, as it was not in the selectable list (not sure if this is expected behavior, or a bug).",kfriend,2024-05-17 13:46:27+00:00,['lbrdnk'],2024-10-07 09:47:47+00:00,2024-10-03 18:49:30+00:00,https://github.com/metabase/metabase/issues/42829,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2203218945, 'issue_id': 2302802067, 'author': 'ranquild', 'body': '@case this is a QPD-only bug now. `param_fields` should be fixed and the FE should just work. Please unskip these 2 e2e tests when the BE issue is fixed https://github.com/metabase/metabase/blob/e048976f2ee67e16e1252ec2968f8c3c47f41908/e2e/test/scenarios/filters-reproductions/dashboard-filters-reproductions.cy.spec.js#L2592', 'created_at': datetime.datetime(2024, 7, 2, 13, 47, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249157586, 'issue_id': 2302802067, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.16](https://github.com/metabase/metabase/milestone/257)', 'created_at': datetime.datetime(2024, 7, 25, 1, 10, 20, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-02 13:47:21 UTC): @case this is a QPD-only bug now. `param_fields` should be fixed and the FE should just work. Please unskip these 2 e2e tests when the BE issue is fixed https://github.com/metabase/metabase/blob/e048976f2ee67e16e1252ec2968f8c3c47f41908/e2e/test/scenarios/filters-reproductions/dashboard-filters-reproductions.cy.spec.js#L2592

github-actions[bot] on (2024-07-25 01:10:20 UTC): 🚀 This should also be released by [v0.50.16](https://github.com/metabase/metabase/milestone/257)

"
2302749752,issue,closed,completed,Include plan alias in token information,"We want to include plan alias in the token information so that we can use it in the upsell badging.

See 
https://github.com/metabase/harbormaster/pull/4993/commits/462da5a91c33f2a7662ed15de1ac83b99da2c859 for the shape. Just a string on the key `:plan-alias`.

This is already the case. The `token-status` setting is visible to admins. We only show the upsell information to admins, so that information is already on the FE.
```
❯ http get ""localhost:3000/api/session/properties"" Cookie:$SESSION -pb | jq '.""token-status"".""plan-alias""'
""internal""
```

If you don't see it yet, add 

```diff
modified   deps.edn
@@ -262,6 +262,7 @@
                  ""-Dfile.encoding=UTF-8""
                  ""-Duser.language=en""
                  ""-Duser.country=US""
+                 ""-Dmetastore.dev.server.url=https://token-check.staging.metabase.com/""
                  ;; Allow clojure goes fast tooling to work
                  ""-Djdk.attach.allowAttachSelf""
                  ;; This will suppress the warning about dynamically loaded agents (like clj-memory-meter)
```

To your deps.edn file under the `:dev` alias. 

And perhaps we should also document it in the malli schema

```diff
modified   src/metabase/public_settings/premium_features.clj
@@ -102,6 +102,7 @@
   [:map
    [:valid                          :boolean]
    [:status                         [:string {:min 1}]]
+   [:plan-alias    {:optional true} :string]
    [:error-details {:optional true} [:maybe [:string {:min 1}]]]
    [:features      {:optional true} [:sequential [:string {:min 1}]]]
    [:trial         {:optional true} :boolean]
@@ -118,6 +119,15 @@

```",dpsutton,2024-05-17 13:24:18+00:00,['escherize'],2024-10-08 17:05:18+00:00,2024-07-03 19:46:03+00:00,https://github.com/metabase/metabase/issues/42828,[],"[{'comment_id': 2203611599, 'issue_id': 2302749752, 'author': 'escherize', 'body': 'Besides the PR to metabase, we should update [the other repo too](https://github.com/metabase/token_airgap_gen/issues/5). [PR here](https://github.com/metabase/token_airgap_gen/pull/5).', 'created_at': datetime.datetime(2024, 7, 2, 15, 47, 51, tzinfo=datetime.timezone.utc)}]","escherize (Assginee) on (2024-07-02 15:47:51 UTC): Besides the PR to metabase, we should update [the other repo too](https://github.com/metabase/token_airgap_gen/issues/5). [PR here](https://github.com/metabase/token_airgap_gen/pull/5).

"
2302027375,issue,open,,Invalid query error when trying to zoom in Bar visualization,"### Describe the bug

When trying to zoom Bar visualisation based on joined MySQL tables I get an error:
Invalid query: {:query {:breakout [nil nil nil nil nil [nil nil [""Invalid :temporal-unit for the specified :base-type.""]]]}}

### To Reproduce

- I have a MySQL table `orders` with a list of orders, date format linux time stamp.
- I created an `Orders with date` Question based on the orders table - SELECT `order`.`order` AS `order`, FROM_UNIXTIME(`order`.`open_milli` / 1000) AS `timestamp` FROM `order`;
Then I joined `orders` and `Orders with date` by order number.
- I created a visualization in which I added several fields with order information from the `orders` table and `timestamp` from `Orders with date`
- Visualization format Bar, view previous 30 days by day
- When trying to zoom I get an error (group by hours):
Invalid query: {:query {:breakout [nil nil nil nil nil [nil nil [""Invalid :temporal-unit for the specified :base-type.""]]]}}
![Screenshot 2024-05-17 111434](https://github.com/metabase/metabase/assets/49691003/5d2e60e7-2de3-4f97-939c-061f3570e6a7)
![Screenshot 2024-05-17 111450](https://github.com/metabase/metabase/assets/49691003/810903af-3524-4e23-b3fd-2f96811c145e)
- Then if I change group by minute and return group by hour. Everything is fine
![Screenshot 2024-05-17 113248](https://github.com/metabase/metabase/assets/49691003/5d23aa4e-626b-4b48-b44b-11c544ac6e1a)



### Expected behavior

The visualization should group by hours without error.

### Logs

[183bf2df-5196-4ed0-a1eb-94885de9a6e7] 2024-05-17T11:25:52+04:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Invalid query: {:query {:breakout [nil nil nil nil nil [nil nil [""Invalid :temporal-unit for the specified :base-type.""]]]}}
{:database_id 3,
 :started_at #t ""2024-05-17T07:25:52.140083702Z[Etc/UTC]"",
 :action_id nil,
 :json_query
 {:database 3,
  :type ""query"",
  :query
  {:source-table 20,
   :joins
   [{:alias ""Deal - Order"",
     :condition
     [""=""
      [""field"" 252 {:base-type ""type/Integer""}]
      [""field"" 217 {:base-type ""type/Integer"", :join-alias ""Deal - Order""}]],
     :source-table 18}
    {:alias ""Order DB with Date - Order"",
     :condition
     [""=""
      [""field"" 252 {:base-type ""type/Integer""}]
      [""field"" ""order"" {:base-type ""type/Integer"", :join-alias ""Order DB with Date - Order""}]],
     :source-table ""card__15""}],
   :expressions
   {:Volume
    [""*"" [""field"" 239 {:base-type ""type/Float""}] [""field"" 218 {:base-type ""type/Float"", :join-alias ""Deal - Order""}]]},
   :aggregation [[""sum"" [""expression"" ""Volume"" {:base-type ""type/Float""}]]],
   :breakout
   [[""field"" 242 {:base-type ""type/Text""}]
    [""field"" 232 {:base-type ""type/Text""}]
    [""field"" 229 {:base-type ""type/Text""}]
    [""field"" 231 {:base-type ""type/Text""}]
    [""field"" 243 {:base-type ""type/Text""}]
    [""field"" ""timestamp"" {:base-type ""type/Date"", :join-alias ""Order DB with Date - Order"", :temporal-unit ""hour""}]],
   :filter
   [""between""
    [""field"" ""timestamp"" {:base-type ""type/Date"", :join-alias ""Order DB with Date - Order"", :temporal-unit ""day""}]
    ""2024-05-09T00:00Z""
    ""2024-05-10T00:00Z""]},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> mbql.schema$fn__29379$fn__29380.invoke(schema.cljc:1874)""
  ""query_processor.middleware.validate$validate_query.invokeStatic(validate.clj:9)""
  ""query_processor.middleware.validate$validate_query.invoke(validate.clj:6)""
  ""query_processor$preprocess_STAR_$fn__73445.invoke(query_processor.clj:164)""
  ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)""
  ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)""
  ""query_processor$fn__73453$combined_pre_process__73454$combined_pre_process_STAR___73455.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66731.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72196$fn__72200.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72196.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67358$fn__67359.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67358.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72193.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72498.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72133$handle_audit_app_internal_queries__72134$fn__72136.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72144.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71259.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72429.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73030.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62871$thunk__62873.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62871.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62883.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93999.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53297$fn__53299.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53297.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43762.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""Invalid query: {:query {:breakout [nil nil nil nil nil [nil nil [\""Invalid :temporal-unit for the specified :base-type.\""]]]}}"",
 :row_count 0,
 :running_time 0,
 :preprocessed nil,
 :ex-data
 {:error {:query {:breakout [nil nil nil nil nil [nil nil [""Invalid :temporal-unit for the specified :base-type.""]]]}},
  :original
  {:schema [:ref :metabase.mbql.schema/Query],
   :value
   {:database 3,
    :type :query,
    :query
    {:source-table 20,
     :joins
     [{:alias ""Deal - Order"",
       :condition
       [:= [:field 252 {:base-type :type/Integer}] [:field 217 {:base-type :type/Integer, :join-alias ""Deal - Order""}]],
       :source-table 18}
      {:alias ""Order DB with Date - Order"",
       :condition
       [:=
        [:field 252 {:base-type :type/Integer}]
        [:field ""order"" {:base-type :type/Integer, :join-alias ""Order DB with Date - Order""}]],
       :source-card-id 15,
       :source-query
       {:collection ""order"",
        :native
        ""SELECT\n  `order`.`order` AS `order`,\n  `order`.`open_milli` AS `open_milli`,\n  FROM_UNIXTIME(`order`.`open_milli` / 1000) AS `timestamp`\nFROM\n  `order`;""},
       :source-metadata
       [{:display_name ""order"",
         :field_ref [:field ""order"" {:base-type :type/Integer}],
         :name ""order"",
         :base_type :type/Integer,
         :effective_type :type/Integer,
         :semantic_type nil,
         :fingerprint
         {:global {:distinct-count 2000, :nil% 0.0},
          :type
          {:type/Number
           {:min 1.0, :q1 500.9768035073571, :q3 1500.5, :max 2000.0, :sd 577.4160643813981, :avg 1000.5}}}}
        {:display_name ""open_milli"",
         :field_ref [:field ""open_milli"" {:base-type :type/BigInteger}],
         :name ""open_milli"",
         :base_type :type/BigInteger,
         :effective_type :type/BigInteger,
         :semantic_type nil,
         :fingerprint
         {:global {:distinct-count 1531, :nil% 0.0},
          :type
          {:type/Number
           {:min 1.667905697787E12,
            :q1 1.6772687549379685E12,
            :q3 1.687731282289729E12,
            :max 1.68937138035E12,
            :sd 6.950498492473033E9,
            :avg 1.682831989752517E12}}}}
        {:display_name ""timestamp"",
         :field_ref [:field ""timestamp"" {:base-type :type/DateTime}],
         :name ""timestamp"",
         :base_type :type/DateTime,
         :effective_type :type/DateTime,
         :semantic_type nil,
         :fingerprint
         {:global {:distinct-count 1531, :nil% 0.0},
          :type {:type/DateTime {:earliest ""2022-11-08T11:08:17.787Z"", :latest ""2023-07-14T21:49:40.35Z""}}}}]}],
     :expressions
     {""Volume""
      [:* [:field 239 {:base-type :type/Float}] [:field 218 {:base-type :type/Float, :join-alias ""Deal - Order""}]]},
     :aggregation [[:sum [:expression ""Volume"" {:base-type :type/Float}]]],
     :breakout
     [[:field 242 {:base-type :type/Text}]
      [:field 232 {:base-type :type/Text}]
      [:field 229 {:base-type :type/Text}]
      [:field 231 {:base-type :type/Text}]
      [:field 243 {:base-type :type/Text}]
      [:field ""timestamp"" {:base-type :type/Date, :join-alias ""Order DB with Date - Order"", :temporal-unit :hour}]],
     :filter
     [:between
      [:field ""timestamp"" {:base-type :type/Date, :join-alias ""Order DB with Date - Order"", :temporal-unit :day}]
      ""2024-05-09T00:00Z""
      ""2024-05-10T00:00Z""]},
    :middleware
    {:js-int-to-string? true,
     :add-default-userland-constraints? true,
     :metabase.query-processor.middleware.constraints/add-userland-constraints? true},
    :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x33359799 ""[B@33359799""]}},
   :errors
   ({:path [0 0 0 :query 0 0 :breakout 0 0 :field 0 0 1 ""options"" 0 0 0 1],
     :in [:query :breakout 5 2],
     :schema
     [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x3d36b3a ""metabase.mbql.schema$valid_temporal_unit_for_base_type_QMARK_@3d36b3a""]],
     :value {:base-type :type/Date, :join-alias ""Order DB with Date - Order"", :temporal-unit :hour}})}},
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
- Browsers: Chrome 125.0.6422.61, Firefox 125.0.3
- OS: Windows 10-11
- Databases: MariaDB
- Metabase Version: 0.49.10
- Metabase Hosting Env: Jar-File on Ubuntu 22.04.4 LTS
- Metabase internal database: H2
```


### Severity

Low

### Additional context

_No response_",adronkin,2024-05-17 07:33:52+00:00,[],2025-02-04 20:31:14+00:00,,https://github.com/metabase/metabase/issues/42817,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]",[],
2301928056,issue,closed,not_planned,Error encountered during deployment of version 0.49.x,"### Describe the bug

When attempting to redeploy version 0.49.x, the following error is encountered.
However, no issues are encountered when deploying version 0.48.x.
I suspect the issue might be related to the JDBC driver version.

""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }

-----
2024-05-17 14:00:45,047 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=68058) SAVEPOINT fb25173f-9ae2-47a7-8d43-791be297d400 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
	at metabase.db.setup$migrate_BANG_$fn__51159.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___48835.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
	at clojure.lang.RestFn.invoke(RestFn.java:445)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
	at metabase.db.setup$setup_db_BANG_$fn__51187$fn__51188.invoke(setup.clj:165)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__51187.invoke(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__51207.invoke(db.clj:69)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
	at metabase.core$init_BANG_.invoke(core.clj:154)
	at metabase.core$start_normally.invokeStatic(core.clj:171)
	at metabase.core$start_normally.invoke(core.clj:165)
	at metabase.core$entrypoint.invokeStatic(core.clj:204)
	at metabase.core$entrypoint.doInvoke(core.clj:198)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=68058) SAVEPOINT fb25173f-9ae2-47a7-8d43-791be297d400 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 49 more

### To Reproduce

1. download jar
2. configurate database
3. start  jar



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-LTS"",
    ""java.vendor"": ""Red Hat, Inc."",
    ""java.vendor.url"": ""https://www.redhat.com/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""3.10.0-957.21.3.el7.x86_64"",
    ""user.language"": ""zh"",
    ""user.timezone"": ""Asia/Shanghai""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.34""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-12-19"",
      ""tag"": ""v0.48.1"",
      ""hash"": ""a8302d4""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

p1

### Additional context

_No response_",WangDanpeng,2024-05-17 06:30:09+00:00,[],2025-01-08 15:46:06+00:00,2024-05-17 07:26:33+00:00,https://github.com/metabase/metabase/issues/42816,"[('Type:Bug', 'Product defects'), ('Database/MySQL', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase')]","[{'comment_id': 2116921768, 'issue_id': 2301928056, 'author': 'zbodi74', 'body': 'Duplicate of [40546](https://github.com/metabase/metabase/issues/40546).\r\n@WangDanpeng, there is ongoing troubleshooting on the other issue, please follow up there.', 'created_at': datetime.datetime(2024, 5, 17, 7, 26, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2116951209, 'issue_id': 2301928056, 'author': 'zbodi74', 'body': ""@WangDanpeng - could you confirm which v49 version you were attempting to upgrade to - we think this issue might have been fixed by v0.49.2.\r\nPlease ensure you're trying to migrate to the latest v49 release (currently[v0.49.11](https://github.com/metabase/metabase/releases/tag/v0.49.11)."", 'created_at': datetime.datetime(2024, 5, 17, 7, 46, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578002174, 'issue_id': 2301928056, 'author': 'paoliniluis', 'body': '@WangDanpeng can you check 52.5?', 'created_at': datetime.datetime(2025, 1, 8, 15, 46, 5, tzinfo=datetime.timezone.utc)}]","zbodi74 on (2024-05-17 07:26:33 UTC): Duplicate of [40546](https://github.com/metabase/metabase/issues/40546).
@WangDanpeng, there is ongoing troubleshooting on the other issue, please follow up there.

zbodi74 on (2024-05-17 07:46:11 UTC): @WangDanpeng - could you confirm which v49 version you were attempting to upgrade to - we think this issue might have been fixed by v0.49.2.
Please ensure you're trying to migrate to the latest v49 release (currently[v0.49.11](https://github.com/metabase/metabase/releases/tag/v0.49.11).

paoliniluis on (2025-01-08 15:46:05 UTC): @WangDanpeng can you check 52.5?

"
2301604037,issue,closed,not_planned,"On a dashboard with multiple tabs, allow filters for just the specific tab","**Is your feature request related to a problem? Please describe.**
Me and my team are high users of the metabase dashboard with tabs. However, one big problem is that when we add a dashboard-level filter, we only want this filter to apply to ONE tab. It apples to all tabs :(

**Describe the solution you'd like**
If you add a dashboard-level filter to a dash with multiple tabs, have an option to apply this filter to ALL tabs or just the one tab.

**Describe alternatives you've considered**
I can add individual filters for the charts but this isnt helpful here

**How important is this feature to you?**
Very important for usability, self-service for stakeholders

**Additional context**

",aarthi-subramanian,2024-05-17 00:44:16+00:00,[],2024-06-04 14:55:46+00:00,2024-06-04 14:55:46+00:00,https://github.com/metabase/metabase/issues/42809,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2117948428, 'issue_id': 2301604037, 'author': 'paoliniluis', 'body': ""If you don't connect the filter to any card on the tab, then the filter will dissapear from there, have you checked this?"", 'created_at': datetime.datetime(2024, 5, 17, 16, 22, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2118199152, 'issue_id': 2301604037, 'author': 'aarthi-subramanian', 'body': 'Ya. I want different filters for different tabs. E.g. `transaction_count_threshold` filter where default is 1000 for tab1, default is 100 for tab 2, default is 100000 for tab3', 'created_at': datetime.datetime(2024, 5, 17, 18, 51, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2123163643, 'issue_id': 2301604037, 'author': 'likeshumidity', 'body': 'In version 49, you should be able to add two filters--one attached to the content in Tab A, another attached to the content in Tab B. When you are on Tab A, only the Tab A filter will be visible. When you are on Tab B, only the Tab B filter will be visible. Will this work for you?', 'created_at': datetime.datetime(2024, 5, 21, 18, 4, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2123165736, 'issue_id': 2301604037, 'author': 'aarthi-subramanian', 'body': ""Oh wow yes that's what i want! Sorry how can i see which version im on?"", 'created_at': datetime.datetime(2024, 5, 21, 18, 6, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2123358359, 'issue_id': 2301604037, 'author': 'aarthi-subramanian', 'body': 'Ah this is my version. Ill ask my data eng team if we can upgrade to 49 🙏 \r\n<img width=""487"" alt=""image"" src=""https://github.com/metabase/metabase/assets/47357846/7ab55250-c6da-4349-9ad7-9a0a65ed87b6"">', 'created_at': datetime.datetime(2024, 5, 21, 20, 7, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2147747623, 'issue_id': 2301604037, 'author': 'ignacio-mb', 'body': 'Closing as this is possible from version 49, and dupe of https://github.com/metabase/metabase/issues/31621', 'created_at': datetime.datetime(2024, 6, 4, 14, 55, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-17 16:22:19 UTC): If you don't connect the filter to any card on the tab, then the filter will dissapear from there, have you checked this?

aarthi-subramanian (Issue Creator) on (2024-05-17 18:51:05 UTC): Ya. I want different filters for different tabs. E.g. `transaction_count_threshold` filter where default is 1000 for tab1, default is 100 for tab 2, default is 100000 for tab3

likeshumidity on (2024-05-21 18:04:55 UTC): In version 49, you should be able to add two filters--one attached to the content in Tab A, another attached to the content in Tab B. When you are on Tab A, only the Tab A filter will be visible. When you are on Tab B, only the Tab B filter will be visible. Will this work for you?

aarthi-subramanian (Issue Creator) on (2024-05-21 18:06:13 UTC): Oh wow yes that's what i want! Sorry how can i see which version im on?

aarthi-subramanian (Issue Creator) on (2024-05-21 20:07:24 UTC): Ah this is my version. Ill ask my data eng team if we can upgrade to 49 🙏 
<img width=""487"" alt=""image"" src=""https://github.com/metabase/metabase/assets/47357846/7ab55250-c6da-4349-9ad7-9a0a65ed87b6"">

ignacio-mb on (2024-06-04 14:55:09 UTC): Closing as this is possible from version 49, and dupe of https://github.com/metabase/metabase/issues/31621

"
2301387068,issue,closed,completed,add snowplow tracking to upsells system,"see [product doc](https://www.notion.so/metabase/Upsell-System-Guidelines-72ce6f7402fb4c93a165e904dcf7a93c?pvs=4#f5919f74d11c40538cc0a6e71c235e85)

- viewed: probably can hook into the wrapper HoC
- clicked: can probably do in the `components/` level from the props passed in",iethree,2024-05-16 21:33:44+00:00,['iethree'],2024-10-08 17:11:13+00:00,2024-05-21 22:49:11+00:00,https://github.com/metabase/metabase/issues/42802,[],[],
2301338136,issue,open,,Light/dark map tile variants,"#### Is your feature request related to a problem? Please describe.

Metabase does not offer a dark/night theme (see #9203), though browser extensions like Dark Reader work well enough to customise the styles for a dark mode.  Where this falls short is with map tiles, which remain unchanged and are rather blinding alongside the rest of the site in a dark theme.

#### Describe the solution you'd like

If and when a site-wide dark mode is available, the option to configure light and dark tiles independently, and for them to be used with the corresponding theme.  Ideally, a default dark tile set would be available as with the current light tiles, though I don't know if OSM provides their own for this or if a third-party tile provider would be needed.

#### Describe alternatives you've considered

I could just equip a dark tile set all the time, though I find them less legible during the day, and a dark map against an otherwise white website also looks a bit jarring.

Switching between light and dark map tiles manually is also a bit painful as there's nowhere to ""store"" the dark tile URL when not in use (i.e. I'd need to dig it out from somewhere else and paste into the settings field each time).

#### How important is this feature to you?

A fair few of my regular visualisations are map-based, and I refer to them at various hours of the day, so I do frequently notice this.

#### Additional context

Here's how it looks currently (default map tiles with Dark Reader's ""dynamic"" theme):

![image](https://github.com/metabase/metabase/assets/4025899/d6723849-a12a-4e05-93a0-b344d7fcebb5)

And using e.g. Dark Matter tiles (`https://{s}.basemaps.cartocdn.com/dark_all/{z}/{x}/{y}.png`):

![image](https://github.com/metabase/metabase/assets/4025899/ae36cbee-1695-43d6-ad63-2506ff873949)",Terrance,2024-05-16 21:02:59+00:00,[],2024-05-17 14:20:53+00:00,,https://github.com/metabase/metabase/issues/42798,"[('Type:New Feature', ''), ('Customization/i18n', ''), ('Visualization/Maps', '')]",[],
2301238065,issue,closed,completed,Remove Google Analytics driver and related special case stuff,"We made the decision to deprecate it about a year ago because of https://github.com/metabase/metabase/issues/12905#issuecomment-1611804549, now because it's blocking Metrics v2 we are finally going to drop it entirely. ([We announced this in 47.](https://www.metabase.com/releases/Metabase-47)) This needs to be done before we ship 50. See https://metaboat.slack.com/archives/C04DN5VRQM6/p1715888743074829 for more info.

We need to delete all the code related to GA in the repo including the CI job and any mentions of `:googleanalytics` in the codebase. We have a lot of special edge case stuff in the codebase for GA's hardcoded `:metric`s and `:segment`s (which use string IDs instead of integers), we should remove that stuff from the MBQL schemas and all of the special case code. Examples of stuff to remove:

- `modules/drivers/googleanalytics`
- https://github.com/metabase/metabase/blob/d142da9984b0485c56c224b79116031973226399/src/metabase/legacy_mbql/schema.cljc#L987-L996
- https://github.com/metabase/metabase/blob/59e7b3d1cb2f22a9574cad9aef1a2bea3a72fc80/deps.edn#L388
- https://github.com/metabase/metabase/blob/cd007ba6ac34dc3ab2769c5333718eef41c15d69/src/metabase/xrays/automagic_dashboards/names.clj#L31
- GitHub Actions related to Google Analytics

**Please be thorough and remove all the dead GA-related code!!! Please 🙇‍♂️**",camsaul,2024-05-16 20:01:24+00:00,['camsaul'],2024-05-30 18:22:14+00:00,2024-05-30 18:22:13+00:00,https://github.com/metabase/metabase/issues/42792,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/Processor', ''), ('Database/Google Analytics', None), ('.Backend', '')]","[{'comment_id': 2116088805, 'issue_id': 2301238065, 'author': 'camsaul', 'body': ""We should also double-check that things like the Database REST API endpoints don't blow up if we have a `Database` with a driver that no longer exists. The `after-select` method for `:model/Database` only calls `metabase.driver.util/features` if the driver is registered, so that should be good at least, but we should check other things as well just to be safe."", 'created_at': datetime.datetime(2024, 5, 16, 20, 6, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2132905176, 'issue_id': 2301238065, 'author': 'crisptrutski', 'body': '@camsaul do you have an ETA for landing the remaining work here?', 'created_at': datetime.datetime(2024, 5, 27, 8, 12, 53, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-05-16 20:06:14 UTC): We should also double-check that things like the Database REST API endpoints don't blow up if we have a `Database` with a driver that no longer exists. The `after-select` method for `:model/Database` only calls `metabase.driver.util/features` if the driver is registered, so that should be good at least, but we should check other things as well just to be safe.

crisptrutski on (2024-05-27 08:12:53 UTC): @camsaul do you have an ETA for landing the remaining work here?

"
2301027253,issue,open,,"Expanding long content via ""View more"" on ObjectDetail viz should not trigger drill popover","### Describe the bug

Expanding long content via ""View more"" on ObjectDetail viz should not trigger drill popover:

<img width=""1712"" alt=""Screenshot 2024-05-16 at 3 03 35 PM"" src=""https://github.com/metabase/metabase/assets/14301985/0685c859-e53e-4005-af8b-63e739ab8095"">


### To Reproduce

1. Sample Dataset -> Reviews table -> Detail viz
2. Click on ""View more""
3. It opens the drill popover


### Expected behavior

Should not trigger drill popover

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest master
```


### Severity

Although it should not block users, the behavior looks very annoying

### Additional context

_No response_",alxnddr,2024-05-16 18:05:11+00:00,[],2024-07-18 04:31:54+00:00,,https://github.com/metabase/metabase/issues/42790,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Detail', 'ObjectDetail'), ('.Team/DashViz', 'Dashboard and Viz team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2116348276, 'issue_id': 2301027253, 'author': 'H0onnn', 'body': 'Hello, @alxnddr ! I am interested in this issue. Can you explain what action should occur when that button is pressed?', 'created_at': datetime.datetime(2024, 5, 16, 23, 10, 24, tzinfo=datetime.timezone.utc)}]","H0onnn on (2024-05-16 23:10:24 UTC): Hello, @alxnddr ! I am interested in this issue. Can you explain what action should occur when that button is pressed?

"
2301003984,issue,closed,completed,Remove cache timestamp from question info sidebar,,rafpaf,2024-05-16 17:53:11+00:00,['rafpaf'],2024-06-03 16:38:11+00:00,2024-05-17 04:22:39+00:00,https://github.com/metabase/metabase/issues/42789,[],[],
2300775248,issue,closed,completed,Press comma to enter a value (this was previously only possible with Tab),"- Entering comma in the filter input should create a new value.
- Pasting a comma, tab or newline-delimited value should create the corresponding values.
Eg. pasting `foo, bar, baz` should create the values: `foo`, `bar`, `baz`.
- Allow to use quotes to enter values with comma like ""Clothes, shoes and accessories"".
- Add new UI element - icon `i` with a tooltip that explains the new behavior

![Untitled](https://github.com/metabase/metabase/assets/1250185/72226b9b-c51c-430f-b789-2615d9da975a)
",romeovs,2024-05-16 15:55:32+00:00,['romeovs'],2024-05-28 11:57:38+00:00,2024-05-28 11:43:11+00:00,https://github.com/metabase/metabase/issues/42783,"[('.Team/Querying', '')]",[],
2300741842,issue,closed,completed,[BE] [QP] Ensure custom expressions are handled without name clashes,,snoe,2024-05-16 15:39:44+00:00,['snoe'],2024-10-08 17:11:04+00:00,2024-05-22 17:51:33+00:00,https://github.com/metabase/metabase/issues/42782,[],[],
2300709354,issue,closed,completed,Browse-related heading changes,"Browse data -> Browse databases
Browsing models -> Models
https://metaboat.slack.com/archives/C06REDHM6BV/p1715872086595549",rafpaf,2024-05-16 15:23:41+00:00,['rafpaf'],2024-05-16 21:56:47+00:00,2024-05-16 21:56:47+00:00,https://github.com/metabase/metabase/issues/42781,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2300676119,issue,closed,completed,"Questions always say ""Updated a few seconds ago""","There's a discrepancy between the timestamp in the sidebar and the one in the footer. In the sidebar it says this question was last cached 44 minutes ago. In the footer it says ""Updated a few seconds ago.""

<img width=""911"" alt=""image"" src=""https://github.com/metabase/metabase/assets/130925/243f9ea2-cf26-4ee6-b640-f7a72861b2f1"">


### To Reproduce

View a question that was cached more than a minute ago, and look at the ""Updated"" timestamp in the footer.

I think this happens because `QuestionLastUpdated` has:

```
t`Updated ${moment(result.updated_at).fromNow()}`
```

But `result.updated_at` is `undefined`. I think the field might be obsolete.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.11 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-05-14"",
      ""src_hash"": ""b71361ac052039d559b195106d7a46710ce08931"",
      ""tag"": ""v1.1.3-SNAPSHOT"",
      ""hash"": ""6284aeb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

_No response_",rafpaf,2024-05-16 15:09:34+00:00,['rafpaf'],2024-06-26 09:38:29+00:00,2024-06-26 08:10:20+00:00,https://github.com/metabase/metabase/issues/42778,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2118348543, 'issue_id': 2300676119, 'author': 'rafpaf', 'body': 'Heads up that we may just be getting rid of this message https://metaboat.slack.com/archives/C06KX7QECN4/p1715972915986779?thread_ts=1715850000.658139&channel=C06KX7QECN4&message_ts=1715972915.986779', 'created_at': datetime.datetime(2024, 5, 17, 20, 33, 52, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-05-17 20:33:52 UTC): Heads up that we may just be getting rid of this message https://metaboat.slack.com/archives/C06KX7QECN4/p1715972915986779?thread_ts=1715850000.658139&channel=C06KX7QECN4&message_ts=1715972915.986779

"
2300650770,issue,open,,Network errors for collection items misleadingly show empty collection UI,"### Describe the bug

If the endpoints powering collections have an error for whatever reason, we show an empty collection UI instead of something indicating an error. This is quite confusing and we should just be a bit more honest and say we had an error

<img width=""456"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/ae9aae51-ca01-416b-a5a5-2bf1737644fd"">


### To Reproduce

probably easiest to add an error to the collection items endpoints and then see an empty UI

### Expected behavior

some indication that an error happened. The current behavior made people worry about data loss instead of hiccups.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p2

### Additional context

_No response_",dpsutton,2024-05-16 14:58:37+00:00,[],2024-05-16 14:59:11+00:00,,https://github.com/metabase/metabase/issues/42775,"[('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2300603990,issue,closed,completed,Open currently selected item's tab by default,"See [Slack thread](https://metaboat.slack.com/archives/C0645JP1W81/p1715868069360229).

----

**Case 1**: (query builder) editing source table of an existing question based on Orders table
- ""Tables"" tab should be opened first

**Case 2**: (dashboard) replacing question in a dashboard card
- ""Saved questions"" tab should be opened first
",kamilmielnik,2024-05-16 14:41:00+00:00,['npfitz'],2024-05-17 08:06:40+00:00,2024-05-17 08:06:40+00:00,https://github.com/metabase/metabase/issues/42774,"[('.Frontend', '')]",[],
2300578953,issue,closed,completed,"""-modified"" suffix briefly shown in a model's name input during creation","### Describe the bug


https://github.com/metabase/metabase/assets/6830683/1bba1142-2652-4ed0-adf8-9834a56457ef



### To Reproduce

1. Start a new notebook model based on Orders table
2. Click ""Save""
3. Observe name input in the modal from now
4. Click ""Save"" in the modal

Observe that the name input will briefly show `- modified` suffix

### Expected behavior

`- modified` suffix is not shown

### Information about your Metabase installation

master, 44cb385c40

### Severity

P3
",kamilmielnik,2024-05-16 14:30:45+00:00,['nemanjaglumac'],2024-08-22 07:00:25+00:00,2024-08-22 07:00:24+00:00,https://github.com/metabase/metabase/issues/42773,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2209435601, 'issue_id': 2300578953, 'author': 'paoliniluis', 'body': 'happens on questions as well', 'created_at': datetime.datetime(2024, 7, 4, 18, 24, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233467534, 'issue_id': 2300578953, 'author': 'nemanjaglumac', 'body': 'Still present in 50.13.', 'created_at': datetime.datetime(2024, 7, 17, 14, 29, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299710286, 'issue_id': 2300578953, 'author': 'nemanjaglumac', 'body': ""Fixed in `master` by https://github.com/metabase/metabase/pull/38457, which wasn't backported.\r\n\r\nThe diff is huge, but the line to look for is:\r\n`const [originalQuestion] = useState(latestOriginalQuestion); // originalQuestion from props changes during saving`"", 'created_at': datetime.datetime(2024, 8, 20, 20, 30, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303927610, 'issue_id': 2300578953, 'author': 'nemanjaglumac', 'body': 'Fixed by https://github.com/metabase/metabase/pull/47086', 'created_at': datetime.datetime(2024, 8, 22, 7, 0, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-04 18:24:04 UTC): happens on questions as well

nemanjaglumac (Assginee) on (2024-07-17 14:29:02 UTC): Still present in 50.13.

nemanjaglumac (Assginee) on (2024-08-20 20:30:01 UTC): Fixed in `master` by https://github.com/metabase/metabase/pull/38457, which wasn't backported.

The diff is huge, but the line to look for is:
`const [originalQuestion] = useState(latestOriginalQuestion); // originalQuestion from props changes during saving`

nemanjaglumac (Assginee) on (2024-08-22 07:00:24 UTC): Fixed by https://github.com/metabase/metabase/pull/47086

"
2300558760,issue,open,,"When saving queries in a metabase folder and ordering by name, 1-9 is respected but 10+ is not ordered correctly","### Describe the bug

* When saving queries in a metabase folder and ordering the files by name (the default sort order), 1-9 is respected but 10+ is not ordered correctly.
* E.g. if i name 10 files as `1. something`, `2. something`, `3. something` ... `10. something`. 
     * The expected order of files is: `1. something`, `2. something`, `3. something` ... `10. something`
     * However the actual order is showing as: `10. something`, `1. something`, `2. something`, `3. something` ... 
* This is wrong and confusing for users. I want the the sort order to be respected, especially if the sort order default is name ascending! 

### To Reproduce

See above

### Expected behavior

See above

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",aarthi-subramanian,2024-05-16 14:22:51+00:00,[],2024-06-03 19:51:13+00:00,,https://github.com/metabase/metabase/issues/42772,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2145996336, 'issue_id': 2300558760, 'author': 'npfitz', 'body': ""@luizarakaki How do you think we should approach this? On the one hand, we sort by string value and I don't think treating names that start with numbers differently is a great option, but we also don't allow people to sort things manually within collections either"", 'created_at': datetime.datetime(2024, 6, 3, 19, 51, 13, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-06-03 19:51:13 UTC): @luizarakaki How do you think we should approach this? On the one hand, we sort by string value and I don't think treating names that start with numbers differently is a great option, but we also don't allow people to sort things manually within collections either

"
2300430308,issue,closed,completed,Don't use relative link for geojson maps,"From @oisincoveney 

Hey backend team! I have a quick question for y'all. Right now we're trying to embed a static dashboard using the Embedding SDK, but one snag that we found was that the geojson maps that we use for the visualizations aren't loading, since the links to the map are using a relative URL. That means that if a client has a map visualization on, for example, localhost:420420/admin/whatever, the SDK tried to fetch the map from localhost:420420/admin/whatever/app/assets/geojson/us-states.json .
I see that it's initialized to this relative url within the geojson.clj  file as a setting. Do you think we could do something to explicitly specify the backend URL so it looks like [MB_BACKEND_URL]/app/assets/geojson/us-states.json? Or is there something else that we should do?",dpsutton,2024-05-16 13:33:56+00:00,['noahmoss'],2024-10-08 17:09:23+00:00,2024-06-04 10:43:27+00:00,https://github.com/metabase/metabase/issues/42767,"[('Misc/API', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('Visualization/Maps', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2127063895, 'issue_id': 2300430308, 'author': 'NevRA', 'body': '@dpsutton any updates on this?', 'created_at': datetime.datetime(2024, 5, 23, 13, 7, 5, tzinfo=datetime.timezone.utc)}]","NevRA on (2024-05-23 13:07:05 UTC): @dpsutton any updates on this?

"
2300385868,issue,closed,not_planned,Custom columns don't work after aggregation unless the user has native query permissions,"### Describe the bug

In questions based on native models, post aggregation custom columns no longer work, unless the user is given **native query permissions**.

### To Reproduce

1. Create a native model (`select * from products`), save it

Log in with a user that does not have native query permissions:
2. Create a GUI question, based on the model created in step 1
3. Add an aggregation(summarize: Count of Rows, by Category)
4. Add a custom column (`[Count] + 1`)
5.(!) Visualize, and see the error
<img width=""524"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/b27adcb4-8acb-46a7-a993-113b5a857448"">

Assigning native query permissions to the user makes the question runnabl.

### Expected behavior

The question should work without native query permissions.

### Logs

n/a

### Information about your Metabase installation

```JSON
1.49.10
```


### Severity

P1 - affects a common function

### Additional context

Reproduced it in `49.10` but I suspect the issue might have existed in earlier versions (`49.8`).",zbodi74,2024-05-16 13:18:55+00:00,['bshepherdson'],2024-08-28 02:09:49+00:00,2024-06-21 14:05:15+00:00,https://github.com/metabase/metabase/issues/42765,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2182822278, 'issue_id': 2300385868, 'author': 'bshepherdson', 'body': ""No repro on 50.x.\r\n\r\n- I defined a SQL model with my admin user: `SELECT * FROM products;` and saved it.\r\n- I created a new user with QB but no native query perms (see screenshot; I can't make a new native question)\r\n- That user can write a `[Count] + 1` expression and it works fine.\r\n\r\nI'm closing this one; reopen if there's still an issue here.\r\n\r\n![2024-06-21-100206_1604x1096_scrot](https://github.com/metabase/metabase/assets/157812/1a7ec126-9b42-467b-af13-6385ccf13c44)\r\n![2024-06-21-100229_1292x537_scrot](https://github.com/metabase/metabase/assets/157812/b4a2008f-6876-46b0-8a95-8a63031562c7)"", 'created_at': datetime.datetime(2024, 6, 21, 14, 5, 16, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-06-21 14:05:16 UTC): No repro on 50.x.

- I defined a SQL model with my admin user: `SELECT * FROM products;` and saved it.
- I created a new user with QB but no native query perms (see screenshot; I can't make a new native question)
- That user can write a `[Count] + 1` expression and it works fine.

I'm closing this one; reopen if there's still an issue here.

![2024-06-21-100206_1604x1096_scrot](https://github.com/metabase/metabase/assets/157812/1a7ec126-9b42-467b-af13-6385ccf13c44)
![2024-06-21-100229_1292x537_scrot](https://github.com/metabase/metabase/assets/157812/b4a2008f-6876-46b0-8a95-8a63031562c7)

"
2300368662,issue,closed,completed,[Bug] Cannot use offsetted column as a base for another offsetted column,"e2e repro (skipped for now) here: #42756

----

Repro steps:
1. Create a new question based on Orders table
2. Add sort clause, e.g. order by ID ascending
3. Add a custom column called `Total-1` with this expression: `Offset([Total], -1)`
4. Add a custom column called `Total-2` with this expression: `Offset([Total-1], -1)`
5. Visualize the query

![image](https://github.com/metabase/metabase/assets/6830683/aa51ca7a-2c02-47ec-ad2c-5ddeb357c8c1)
",kamilmielnik,2024-05-16 13:11:13+00:00,[],2024-08-28 02:09:48+00:00,2024-05-17 13:45:05+00:00,https://github.com/metabase/metabase/issues/42764,"[('Type:Bug', 'Product defects'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2117644716, 'issue_id': 2300368662, 'author': 'kamilmielnik', 'body': 'This has been addressed by #42736. Now offset-based columns are not visible (or filterable, or expressionable, etc.)', 'created_at': datetime.datetime(2024, 5, 17, 13, 45, 5, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-17 13:45:05 UTC): This has been addressed by #42736. Now offset-based columns are not visible (or filterable, or expressionable, etc.)

"
2300333548,issue,closed,not_planned,Border showing on night theme with bordered=false,"### Describe the bug

Hey,

It looks as though the bordered=false property is not being respected when an embedded dashboard has theme=night set. 

I noticed that your team recently released a fix aimed at addressing this issue, but it doesn't seem to have quite worked: https://github.com/metabase/metabase/pull/41514.

From what I can see, it looks as though the issue is within `EmbedFrame.module.css`, which contains the following CSS:

```
.ThemeNight.EmbedFrame .DashCard .Card {
  background-color: var(--color-bg-black);
  border: 1px solid var(--color-bg-dark);
}
```

I've confirmed in-browser that this is the style being applied to my dashboard.


### To Reproduce

1. Embed a dashboard with theme=night and bordered=false applied

### Expected behavior

No border is shown when theme=night and bordered=false are set.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest Chrome (v124)
Macbook Pro (Sonoma 14.2.1)
```


### Severity

Medium - it's complicating convincing our designers to use Metabase dashboards

### Additional context

_No response_",lokalise-mark,2024-05-16 12:55:53+00:00,[],2024-05-17 10:08:52+00:00,2024-05-16 13:24:17+00:00,https://github.com/metabase/metabase/issues/42763,"[('Type:Bug', 'Product defects'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2115238777, 'issue_id': 2300333548, 'author': 'npretto', 'body': 'Hey @lokalise-mark, the fix in the PR you linked has not been released yet, it will come out with v50, the RC should come out in a few days', 'created_at': datetime.datetime(2024, 5, 16, 13, 24, 17, tzinfo=datetime.timezone.utc)}]","npretto on (2024-05-16 13:24:17 UTC): Hey @lokalise-mark, the fix in the PR you linked has not been released yet, it will come out with v50, the RC should come out in a few days

"
2300200226,issue,closed,completed,The new time granularity option is too intense and overflows,"### Describe the bug

Link to the [Slack thread](https://metaboat.slack.com/archives/C02H619CJ8K/p1715773636987059).

> This time granularity option list feels really intense to me and I don’t know why I need to see all of these without disclosing more.

![image](https://github.com/metabase/metabase/assets/1250185/66d75f1e-a6fd-4d01-b165-bde27d7ff15d)


### To Reproduce

1. Browse data -> Accounts
2. Add an aggregation on a time column and pick a bucket
3. Open the View ... by ... dropdown underneath the visualization

The dropdown overflows and is quite overwhelming.


### Expected behavior

Make it no overflow and hide some options behind a `More...` button.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:125.0) Gecko/20100101 Firefox/125.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.20.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.20.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.20.1+1"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.2.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Amsterdam""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-05-14"",
      ""src_hash"": ""0a5efccbcd6508a403492a46be0b5eb713a22d6b"",
      ""tag"": ""v0.1.3-SNAPSHOT"",
      ""hash"": ""f352fe0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

_No response_",romeovs,2024-05-16 11:54:15+00:00,['romeovs'],2024-10-08 17:09:58+00:00,2024-05-30 19:23:56+00:00,https://github.com/metabase/metabase/issues/42760,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2299819121,issue,closed,completed,Chips + authorized origins investigation,"Fill https://www.notion.so/metabase/CHIPS-x-Authorized-origins-1788f86663404aac9a3b94e738806757 for the most common scenarios.
The idea is to understand how and if we can bundle some options, for example a toggle to enable local (as in localhost) development",npretto,2024-05-16 09:14:16+00:00,['npretto'],2024-05-28 09:37:55+00:00,2024-05-28 09:37:54+00:00,https://github.com/metabase/metabase/issues/42754,[],[],
2299783595,issue,closed,completed,Do not suggest `Offset` in filters,"We [don't plan to support `Offset` in filters](https://github.com/metabase/metabase/assets/6830683/6c6e7cd2-b3b3-452f-a088-67fe039907bc) in v50 so we need to disable suggesting it

![image](https://github.com/metabase/metabase/assets/6830683/6842267d-5a1a-4b1b-a85e-7bd5a3fddd19)
",kamilmielnik,2024-05-16 08:58:12+00:00,['kamilmielnik'],2024-05-16 11:21:00+00:00,2024-05-16 11:20:59+00:00,https://github.com/metabase/metabase/issues/42753,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2114960285, 'issue_id': 2299783595, 'author': 'kamilmielnik', 'body': 'Closed by #42755', 'created_at': datetime.datetime(2024, 5, 16, 11, 20, 59, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-16 11:20:59 UTC): Closed by #42755

"
2299779544,issue,closed,completed,Cover `Offset()` in filters with e2e tests,"Similar to #42452 and #42511

This **is not** going to v50, see [Slack thread](https://metaboat.slack.com/archives/C06P22KS4JH/p1715687283946849).",kamilmielnik,2024-05-16 08:56:33+00:00,[],2024-05-17 10:15:30+00:00,2024-05-17 10:15:29+00:00,https://github.com/metabase/metabase/issues/42752,[],"[{'comment_id': 2117228212, 'issue_id': 2299779544, 'author': 'kamilmielnik', 'body': ""Closing for now as we don't know if we're going to support `Offset()` in filters, see [Slack thread](https://metaboat.slack.com/archives/C06P22KS4JH/p1715940859886719?thread_ts=1715940684.914479&cid=C06P22KS4JH)."", 'created_at': datetime.datetime(2024, 5, 17, 10, 15, 29, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-17 10:15:29 UTC): Closing for now as we don't know if we're going to support `Offset()` in filters, see [Slack thread](https://metaboat.slack.com/archives/C06P22KS4JH/p1715940859886719?thread_ts=1715940684.914479&cid=C06P22KS4JH).

"
2299478868,issue,closed,completed,Implement changelog generation as a part of SDK release process,"This requires https://github.com/metabase/metabase/pull/42516 to be merged first.

We can hook this up as a part of the PR (for version bump) creation process for simplicity.",WiNloSt,2024-05-16 06:33:56+00:00,['WiNloSt'],2024-10-08 17:09:45+00:00,2024-05-31 15:03:07+00:00,https://github.com/metabase/metabase/issues/42750,"[('.CI & Tests', '')]",[],
2299478753,issue,closed,completed,Spike tools for changelog generation,"Starting with https://github.com/absolute-version/commit-and-tag-version. If that works then we don't have to try other tools. Otherwise, there are 2 more tools to try:
- https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog
- https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli",WiNloSt,2024-05-16 06:33:53+00:00,['WiNloSt'],2024-06-07 15:55:27+00:00,2024-05-30 07:17:06+00:00,https://github.com/metabase/metabase/issues/42749,"[('.CI & Tests', ''), ('.Team/Embedding', '')]","[{'comment_id': 2137767536, 'issue_id': 2299478753, 'author': 'WiNloSt', 'body': '# Spike summary\r\n\r\n## Constraints\r\n1. We need to put the conventional commit in the merge commit message. I initially said that we could try to put the conventional commit message [in each commit](https://metaboat.slack.com/archives/C063Q3F1HPF/p1715787524818449?thread_ts=1715784742.767949&cid=C063Q3F1HPF), but after trying out [`conventional-changelog`](https://github.com/conventional-changelog/conventional-changelog). It would only read the type e.g. `feat`, `fix`, `chore` etc. from the commit message (the first line of the commit). Since we squash merge, all the commit messages will be bundled in the main merge commit body, and those conventional commit messages _won\'t_ be picked up by `conventional-changelog`. So it\'s best to name the PR with a conventional commit style.\r\n2. A PR should only contain one change according to conventional commits. Because of 1), we can only have one item in the merge commit message, it\'s impossible to have a PR that contains multiple changes e.g. 2 fixes or 2 features, or a fix and a feature and have those multiple changes recognized by `conventional-changelog`. I think this is a good constraint, since it forces us to be deliberate about what should be included in the PR anyway. \r\n\r\n## Recommended workflow (modified from [conventional-changelog-cli](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli#recommended-workflow))\r\nWe can modify our [SDK release workflow](https://github.com/metabase/metabase/blob/87896eac8cc8fee4cb943d4ba2b3745c6866bac2/.github/workflows/release-embedding-sdk.yml) as follows:\r\n- Since we should tag after creating a changelog we should move the `git-tag` step later after `publish-npm` then we need to add a replacement job that ensures the tag would be available, so we run the workflow for the same tag for unknown reasons.\r\n- In `publish-npm` step (we could extract this to another step if it\'s getting too long), we add the steps to generate the changelog before committing that along side the readme and SDK package.json template\r\n\r\n## How to generate a changelog\r\n1. Ensure the merged commit has a conventional commit message in the header (the first line) and only contain 1 change. See constraints\r\n2. install `conventional-changelog-cli`\r\n    ```sh\r\n    yarn add --dev conventional-changelog-cli\r\n    ```\r\n3. For the first run that will generate the first changelog file run:\r\n    ```sh\r\n    yarn conventional-changelog -p angular --pkg resources/embedding-sdk/package.json --config embedding/config.js --tagPrefix embedding-sdk- -i CHANGELOG.MD -s -r 0\r\n    ```\r\n4. For the subsequent run that will append new change to the existing chaneglog file run:\r\n    ```sh\r\n    yarn conventional-changelog -p angular --pkg resources/embedding-sdk/package.json --config embedding/config.js --tagPrefix embedding-sdk- -i CHANGELOG.MD -s\r\n    ```\r\n    This drops `-r 0` at the end of the first command.\r\n\r\n## Useful details about generating the changelog\r\n- The reason we need to generate the changelog before starting tagging is because `conventional-changelog` will look for all the existing tags with the specified prefix, in our case, `embedding-sdk-` e.g. `embedding-sdk-0.1.5` and use it to populate a diff link in the changelog. [For example](https://github.com/metabase/metabase/compare/embedding-sdk-0.1.4...embedding-sdk-0.1.5). Sidenote: This might not make sense since not all the commits are related to the SDK change. I\'m not sure how to remove this yet, but I think it has something to do with the handlebar template, so it shouldn\'t be too hard to remove if we want to.\r\n- When generating the changelog it will use the `version` in the specified package.json to create the link, for example, if the latest tag is `embedding-sdk-0.1.5` and we have version `0.1.6` in the package.json it will create [this link](https://github.com/metabase/metabase/compare/embedding-sdk-0.1.5...embedding-sdk-0.1.6). Depends whether or not we want to have this link, we can drop this step entirely.\r\n- `--config embedding/config.js` specify a config file and the file should look something like this\r\n    ```js\r\n    module.exports = {\r\n      gitRawCommitsOpts: { grep: ""(sdk)"" },\r\n    };\r\n    ```\r\n    This will grep the commit that contains the scope `(sdk)` since `conventional-change` doesn\'t have a way to filter commits. We need to supply git arguments that would produce the desire changelog ourselves.\r\n- We could customize the extra type we want by supplying a `writerOpts`. [For example.](https://github.com/conventional-changelog/conventional-changelog/blob/d3b8aaa16337993bbad4d91db1ffac5a7568756b/packages/conventional-changelog-angular/src/writer.js#L42-L43)', 'created_at': datetime.datetime(2024, 5, 29, 16, 2, 41, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-05-29 16:02:41 UTC): # Spike summary

## Constraints
1. We need to put the conventional commit in the merge commit message. I initially said that we could try to put the conventional commit message [in each commit](https://metaboat.slack.com/archives/C063Q3F1HPF/p1715787524818449?thread_ts=1715784742.767949&cid=C063Q3F1HPF), but after trying out [`conventional-changelog`](https://github.com/conventional-changelog/conventional-changelog). It would only read the type e.g. `feat`, `fix`, `chore` etc. from the commit message (the first line of the commit). Since we squash merge, all the commit messages will be bundled in the main merge commit body, and those conventional commit messages _won't_ be picked up by `conventional-changelog`. So it's best to name the PR with a conventional commit style.
2. A PR should only contain one change according to conventional commits. Because of 1), we can only have one item in the merge commit message, it's impossible to have a PR that contains multiple changes e.g. 2 fixes or 2 features, or a fix and a feature and have those multiple changes recognized by `conventional-changelog`. I think this is a good constraint, since it forces us to be deliberate about what should be included in the PR anyway. 

## Recommended workflow (modified from [conventional-changelog-cli](https://github.com/conventional-changelog/conventional-changelog/tree/master/packages/conventional-changelog-cli#recommended-workflow))
We can modify our [SDK release workflow](https://github.com/metabase/metabase/blob/87896eac8cc8fee4cb943d4ba2b3745c6866bac2/.github/workflows/release-embedding-sdk.yml) as follows:
- Since we should tag after creating a changelog we should move the `git-tag` step later after `publish-npm` then we need to add a replacement job that ensures the tag would be available, so we run the workflow for the same tag for unknown reasons.
- In `publish-npm` step (we could extract this to another step if it's getting too long), we add the steps to generate the changelog before committing that along side the readme and SDK package.json template

## How to generate a changelog
1. Ensure the merged commit has a conventional commit message in the header (the first line) and only contain 1 change. See constraints
2. install `conventional-changelog-cli`
    ```sh
    yarn add --dev conventional-changelog-cli
    ```
3. For the first run that will generate the first changelog file run:
    ```sh
    yarn conventional-changelog -p angular --pkg resources/embedding-sdk/package.json --config embedding/config.js --tagPrefix embedding-sdk- -i CHANGELOG.MD -s -r 0
    ```
4. For the subsequent run that will append new change to the existing chaneglog file run:
    ```sh
    yarn conventional-changelog -p angular --pkg resources/embedding-sdk/package.json --config embedding/config.js --tagPrefix embedding-sdk- -i CHANGELOG.MD -s
    ```
    This drops `-r 0` at the end of the first command.

## Useful details about generating the changelog
- The reason we need to generate the changelog before starting tagging is because `conventional-changelog` will look for all the existing tags with the specified prefix, in our case, `embedding-sdk-` e.g. `embedding-sdk-0.1.5` and use it to populate a diff link in the changelog. [For example](https://github.com/metabase/metabase/compare/embedding-sdk-0.1.4...embedding-sdk-0.1.5). Sidenote: This might not make sense since not all the commits are related to the SDK change. I'm not sure how to remove this yet, but I think it has something to do with the handlebar template, so it shouldn't be too hard to remove if we want to.
- When generating the changelog it will use the `version` in the specified package.json to create the link, for example, if the latest tag is `embedding-sdk-0.1.5` and we have version `0.1.6` in the package.json it will create [this link](https://github.com/metabase/metabase/compare/embedding-sdk-0.1.5...embedding-sdk-0.1.6). Depends whether or not we want to have this link, we can drop this step entirely.
- `--config embedding/config.js` specify a config file and the file should look something like this
    ```js
    module.exports = {
      gitRawCommitsOpts: { grep: ""(sdk)"" },
    };
    ```
    This will grep the commit that contains the scope `(sdk)` since `conventional-change` doesn't have a way to filter commits. We need to supply git arguments that would produce the desire changelog ourselves.
- We could customize the extra type we want by supplying a `writerOpts`. [For example.](https://github.com/conventional-changelog/conventional-changelog/blob/d3b8aaa16337993bbad4d91db1ffac5a7568756b/packages/conventional-changelog-angular/src/writer.js#L42-L43)

"
2299478549,issue,closed,completed,[Epic] Automate SDK changelog,"### Description
We want a way to generate SDK changelog easily, and possibly automate it. We ended up choosing [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/) as a format to help streamline changelog generation process.

Here's the current shape of [the convention](https://metaboat.slack.com/archives/C063Q3F1HPF/p1715787524818449?thread_ts=1715784742.767949&cid=C063Q3F1HPF)
- We allow 2 type `fix` and `feat`
- Always add the scope, and the only supported scope now is `sdk`
- Breaking change notation `!` has been discussed yet. So there's no enforcing it now.
- Add a conventional commit message in either
  - PR title: This will be included as the squash commit message to master
  - Each commit message: normally when squash merging GH will combine all commit message, so I could grab message from that

### Milestone 1

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42749
- [ ] https://github.com/metabase/metabase/issues/42750
- [ ] https://github.com/metabase/metabase/issues/43582
- [ ] https://github.com/metabase/metabase/issues/43583
- [ ] https://github.com/metabase/metabase/issues/43746
```
",WiNloSt,2024-05-16 06:33:48+00:00,['WiNloSt'],2024-06-07 16:32:14+00:00,2024-06-07 16:32:13+00:00,https://github.com/metabase/metabase/issues/42748,"[('.CI & Tests', ''), ('.Epic', 'Feature Implementation or Project'), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2299217147,issue,closed,not_planned,Metabase Initialization Failure due to JSON Parsing Error in Database Migration Script,"### Describe the bug

When using the latest version of Metabase (metabase/metabase:latest from Docker) in an ECS task, logs depict migration errors that cause the service initialization to fail. Currently there are not successful tasks in operation and Metabase in inaccessible (Application Load Balancer returns a 503 to the user). 

### To Reproduce

In AWS ECS (Elastic Container Service):
- Created a new task definition. In the task definition, you set the Docker image to metabase/metabase:latest
- Ensured database connection settings, application settings, etc. were all correctly configured
- Created a new ECS service to use the task definition created
- Started the service.
-  Monitored the logs in CloudWatch. During Metabase initialization process, observed that it failed with a JsonParseException error.
- The error logs indicated that the failure occurred during a database migration (Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat), and the error was due to an unexpected character in a JSON string (Unexpected character ('T' (code 84)): Expected space separating root-level values).

### Expected behavior

_No response_

### Logs

```
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,177 WARN db.liquibase :: ()
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,177 INFO metabase.core :: Metabase Shutdown COMPLETE
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,167 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,159 INFO metabase.core :: Metabase Shutting Down ...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,142 ERROR metabase.core :: Metabase Initialization FAILED
May 15, 2024 at 21:56 (UTC-4:00)	liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
May 15, 2024 at 21:56 (UTC-4:00)	Reason: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values
May 15, 2024 at 21:56 (UTC-4:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.command.CommandScope.execute(CommandScope.java:253)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.lambda$child$0(Scope.java:186)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:195)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:185)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:164)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Liquibase.update(Liquibase.java:234)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Liquibase.update(Liquibase.java:212)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Liquibase.update(Liquibase.java:194)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$migrate_BANG_$fn__51146.invoke(setup.clj:80)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.liquibase$do_with_liquibase$f_STAR___48822.invoke(liquibase.clj:139)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:445)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$setup_db_BANG_$fn__51174$fn__51175.invoke(setup.clj:165)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$setup_db_BANG_$fn__51174.invoke(setup.clj:160)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db$setup_db_BANG_$fn__51194.invoke(db.clj:69)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$init_BANG_.invoke(core.clj:154)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$start_normally.invokeStatic(core.clj:171)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$start_normally.invoke(core.clj:165)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$entrypoint.invokeStatic(core.clj:204)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.core$entrypoint.doInvoke(core.clj:198)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:397)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:152)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.Var.applyTo(Var.java:705)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$apply.invokeStatic(core.clj:667)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$apply.invoke(core.clj:662)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:397)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:152)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.bootstrap.main(Unknown Source)
May 15, 2024 at 21:56 (UTC-4:00)	Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
May 15, 2024 at 21:56 (UTC-4:00)	Reason: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values
May 15, 2024 at 21:56 (UTC-4:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.lambda$child$0(Scope.java:186)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:195)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:185)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:164)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.command.CommandScope.execute(CommandScope.java:217)
May 15, 2024 at 21:56 (UTC-4:00)	... 49 more
May 15, 2024 at 21:56 (UTC-4:00)	Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
May 15, 2024 at 21:56 (UTC-4:00)	Reason: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values
May 15, 2024 at 21:56 (UTC-4:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.lambda$child$0(Scope.java:186)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:195)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:185)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:164)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.lambda$child$0(Scope.java:186)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:195)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:185)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:164)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:252)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.Scope.child(Scope.java:256)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
May 15, 2024 at 21:56 (UTC-4:00)	... 57 more
May 15, 2024 at 21:56 (UTC-4:00)	Caused by: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values
May 15, 2024 at 21:56 (UTC-4:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:676)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportMissingRootWS(ParserMinimalBase.java:724)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._verifyRootSpace(ReaderBasedJsonParser.java:1834)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._parseUnsignedNumber(ReaderBasedJsonParser.java:1429)
May 15, 2024 at 21:56 (UTC-4:00)	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:809)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.parse$parse.invokeStatic(parse.clj:90)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.parse$parse.invoke(parse.clj:88)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.core$parse_string.invokeStatic(core.clj:208)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.core$parse_string.invoke(core.clj:194)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.core$parse_string.invokeStatic(core.clj:205)
May 15, 2024 at 21:56 (UTC-4:00)	at cheshire.core$parse_string.invoke(core.clj:194)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606$fn__48607.invoke(custom_migrations.clj:1079)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$filter$fn__5962.invoke(core.clj:2834)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.LazySeq.sval(LazySeq.java:42)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.LazySeq.seq(LazySeq.java:51)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RT.seq(RT.java:535)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$seq__5467.invokeStatic(core.clj:139)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$seq__5467.invoke(core.clj:139)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606.invoke(custom_migrations.clj:1079)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.connection$do_transaction$thunk__32323.invoke(connection.clj:150)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.connection$do_transaction.invoke(connection.clj:146)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:165)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:457)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18237.invoke(threaded.clj:71)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invokeStatic(core.clj:6887)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invoke(core.clj:6869)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$comp$fn__5876.invoke(core.clj:2588)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:44)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:165)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:457)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605.invoke(custom_migrations.clj:1073)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invokeStatic(core.clj:6887)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invoke(core.clj:6869)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invokeStatic(core.clj:6887)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$reduce.invoke(core.clj:6869)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
May 15, 2024 at 21:56 (UTC-4:00)	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:160)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyTo(AFn.java:144)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:436)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFn.applyToHelper(AFn.java:156)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.applyTo(RestFn.java:132)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
May 15, 2024 at 21:56 (UTC-4:00)	at clojure.lang.RestFn.invoke(RestFn.java:421)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
May 15, 2024 at 21:56 (UTC-4:00)	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
May 15, 2024 at 21:56 (UTC-4:00)	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff.execute(custom_migrations.clj:1073)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
May 15, 2024 at 21:56 (UTC-4:00)	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
May 15, 2024 at 21:56 (UTC-4:00)	... 72 more
May 15, 2024 at 21:56 (UTC-4:00)	Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('T' (code 84)): Expected space separating root-level values
May 15, 2024 at 21:56 (UTC-4:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
May 15, 2024 at 21:56 (UTC-4:00)	... 236 more
May 15, 2024 at 21:56 (UTC-4:00)	UPDATE SUMMARY
May 15, 2024 at 21:56 (UTC-4:00)	Run: 2
May 15, 2024 at 21:56 (UTC-4:00)	Previously run: 268
May 15, 2024 at 21:56 (UTC-4:00)	Filtered out: 17
May 15, 2024 at 21:56 (UTC-4:00)	-------------------------------
May 15, 2024 at 21:56 (UTC-4:00)	Total change sets: 287
May 15, 2024 at 21:56 (UTC-4:00)	FILTERED CHANGE SETS SUMMARY
May 15, 2024 at 21:56 (UTC-4:00)	DBMS mismatch: 17
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:59,086 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat encountered an exception.
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:58,543 INFO db.liquibase :: Running 2 migrations ...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:57,945 INFO db.liquibase :: No migration lock found.
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:57,933 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:57,016 INFO db.liquibase :: Checking if Database has unrun migrations...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:57,015 INFO db.setup :: Liquibase is ready.
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:56,669 INFO db.setup :: Running Database Migrations...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:56,670 INFO db.setup :: Setting up Liquibase...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,832 INFO db.setup :: [36mChecking if a database downgrade is required...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,831 INFO db.setup :: Successfully verified PostgreSQL 15.5 application database connection. ✅
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,390 INFO db.setup :: [36mVerifying postgres Database Connection ...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,388 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,379 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlite...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,379 INFO driver.impl :: [34mRegistered driver :sqlite[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,376 INFO driver.impl :: [34mRegistered driver :bigquery-cloud-sdk[0m (parents: [:sql]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,376 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :bigquery-cloud-sdk...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,362 INFO driver.impl :: [34mRegistered driver :sparksql[0m (parents: [:hive-like]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,361 INFO driver.impl :: [34mRegistered abstract driver :hive-like[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,361 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sparksql...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,360 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :hive-like...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,351 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :oracle...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,352 INFO driver.impl :: [34mRegistered driver :oracle[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,345 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :vertica...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,345 INFO driver.impl :: [34mRegistered driver :vertica[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,341 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :googleanalytics...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,341 INFO driver.impl :: [34mRegistered driver :googleanalytics[0m 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,336 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :athena...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,337 INFO driver.impl :: [34mRegistered driver :athena[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,324 INFO driver.impl :: [34mRegistered driver :mongo[0m 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,323 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :mongo...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,315 INFO driver.impl :: [34mRegistered driver :redshift[0m (parents: [:postgres]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,312 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :redshift...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,307 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,308 INFO driver.impl :: [34mRegistered driver :druid[0m 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,302 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :snowflake...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,303 INFO driver.impl :: [34mRegistered driver :snowflake[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,263 INFO driver.impl :: [34mRegistered driver :sqlserver[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,263 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlserver...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,256 INFO driver.impl :: [34mRegistered driver :presto-jdbc[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:55,244 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto-jdbc...[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,730 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,726 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,671 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,663 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,640 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,633 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,617 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,608 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,592 INFO util.files :: Extract file /modules/googleanalytics.metabase-driver.jar -> /plugins/googleanalytics.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,555 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:54,074 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,956 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,765 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,410 INFO metabase.plugins :: Loading plugins in /plugins...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,404 INFO metabase.core :: System info:
May 15, 2024 at 21:56 (UTC-4:00)	{""file.encoding"" ""UTF-8"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.runtime.name"" ""OpenJDK Runtime Environment"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.runtime.version"" ""11.0.23+9"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.vendor"" ""Eclipse Adoptium"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.vendor.url"" ""https://adoptium.net/"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.version"" ""11.0.23"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
May 15, 2024 at 21:56 (UTC-4:00)	""java.vm.version"" ""11.0.23+9"",
May 15, 2024 at 21:56 (UTC-4:00)	""os.name"" ""Linux"",
May 15, 2024 at 21:56 (UTC-4:00)	""os.version"" ""5.10.215-203.850.amzn2.x86_64"",
May 15, 2024 at 21:56 (UTC-4:00)	""user.language"" ""en"",
May 15, 2024 at 21:56 (UTC-4:00)	""user.timezone"" ""GMT""}
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,394 INFO metabase.core :: Starting Metabase version v1.49.10 (9e8fc83) ...
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,315 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
May 15, 2024 at 21:56 (UTC-4:00)	{:port 3000, :host ""0.0.0.0""}
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,269 INFO metabase.core :: Starting Metabase in STANDALONE mode
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:53,259 INFO metabase.core ::
May 15, 2024 at 21:56 (UTC-4:00) v1.49.10 (9e8fc83)
May 15, 2024 at 21:56 (UTC-4:00)	Copyright © 2024 Metabase, Inc.
May 15, 2024 at 21:56 (UTC-4:00) Enterprise Edition extensions are PRESENT.
May 15, 2024 at 21:56 (UTC-4:00)	Usage of Metabase Enterprise Edition features are subject to the Metabase Commercial License. See https://www.metabase.com/license/commercial/ for details.
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,596 INFO driver.impl :: [34mRegistered driver :postgres[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,558 INFO driver.impl :: [34mRegistered driver :mysql[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,316 INFO metabase.util :: [32mLoad driver :sql-jdbc took 114.3 ms[0m
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,317 INFO driver.impl :: [34mRegistered driver :h2[0m (parents: [:sql-jdbc]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,307 INFO driver.impl :: [34mRegistered abstract driver :sql-jdbc[0m (parents: [:sql]) 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:49,292 INFO driver.impl :: [34mRegistered abstract driver :sql[0m 🚚
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:41,093 INFO util.encryption :: Saved credentials encryption is ENABLED for this Metabase instance. 🔐
May 15, 2024 at 21:56 (UTC-4:00)	For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
May 15, 2024 at 21:56 (UTC-4:00)	2024-05-16 01:56:37,983 INFO metabase.util :: Maximum memory available to JVM: 512.0 MB
May 15, 2024 at 21:56 (UTC-4:00)	Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
```

### Information about your Metabase installation

```JSON
Unfortunately I can't access the Admin panel as the task is not running. Here's the information I can provide:
- Browser: Chrome Version 124.0.6367.208
- ECS configuration: Linux { ""cpu"": ""2048"", ""memory"": ""4096"" }
- Database Postgres (Metabase) and MariaDB (Application)
- Hosting Environment: ECS
- Metabase Version: metabase/metabase:latest (v1.49.10 in this case)
```


### Severity

blocking usage of Metabase entirely

### Additional context

Issue may be similar to https://github.com/metabase/metabase/issues/42711 and https://github.com/metabase/metabase/issues/41924#issuecomment-2113431939",ZencareJake,2024-05-16 02:45:49+00:00,[],2024-05-16 13:27:48+00:00,2024-05-16 02:55:24+00:00,https://github.com/metabase/metabase/issues/42743,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2113920413, 'issue_id': 2299217147, 'author': 'qnkhuat', 'body': 'Dup of https://github.com/metabase/metabase/issues/42611, the fix is coming in 49.11', 'created_at': datetime.datetime(2024, 5, 16, 2, 55, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2115248032, 'issue_id': 2299217147, 'author': 'ZencareJake', 'body': '49.11 initialized successfully.', 'created_at': datetime.datetime(2024, 5, 16, 13, 27, 46, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-05-16 02:55:24 UTC): Dup of https://github.com/metabase/metabase/issues/42611, the fix is coming in 49.11

ZencareJake (Issue Creator) on (2024-05-16 13:27:46 UTC): 49.11 initialized successfully.

"
2299209651,issue,closed,completed,[FE] [Bug] Properly pass compatible metrics to MBQL lib,,ranquild,2024-05-16 02:37:13+00:00,['ranquild'],2024-05-16 14:30:16+00:00,2024-05-16 14:30:16+00:00,https://github.com/metabase/metabase/issues/42742,[],[],
2299208986,issue,closed,completed,The Admin / Performance page ignores the cache duration specified when creating a database,"### Describe the bug

When you create a database, you're asked to set a cache invalidation policy. But the Admin / Performance page ignores this.

[Loom](https://www.loom.com/share/48d6459861054c58a48578e4e580e54c?sid=b7e7aacd-222b-4cd2-a4ab-fa480b1da6cb)

### To Reproduce

In Admin / Databases, create a new database and under advanced options specify a cache duration. Then go to Admin / Performance and look at the database.

Expected behavior: The database's cache invalidation policy in Admin / Performance should be set to Duration, with the specified number of hours.

Actual behavior: The database's cache invalidation policy in Admin / Performance is still ""Use default"".

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  }
}
```

### Severity

P1",rafpaf,2024-05-16 02:36:30+00:00,['rafpaf'],2024-06-03 16:38:31+00:00,2024-05-17 12:30:48+00:00,https://github.com/metabase/metabase/issues/42741,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2113926737, 'issue_id': 2299208986, 'author': 'rafpaf', 'body': 'The database creation form stores a duration in `metabase_database.cache_ttl`. This duration is ignored by Admin / Performance page, which uses the `cache_config` table.\r\n\r\nInvalidation policies that were previously stored in `metabase_database` are copied into `cache_config` via a migration. However, we still let users insert data into `metabase_database`.\r\n\r\nRelated matters:\r\n* Cards have a `cache_ttl` field which is ignored by Admin / Performance.\r\n* Dead code in the FE: `QuestionCacheTTLField`, `CacheTTLField`, `PLUGIN_FORM_WIDGETS`\r\n* `src/metabase/query_processor/middleware/cache.clj` refers in a comment to a `query-caching-default-ttl` setting, but this is defunct.', 'created_at': datetime.datetime(2024, 5, 16, 3, 3, 22, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-05-16 03:03:22 UTC): The database creation form stores a duration in `metabase_database.cache_ttl`. This duration is ignored by Admin / Performance page, which uses the `cache_config` table.

Invalidation policies that were previously stored in `metabase_database` are copied into `cache_config` via a migration. However, we still let users insert data into `metabase_database`.

Related matters:
* Cards have a `cache_ttl` field which is ignored by Admin / Performance.
* Dead code in the FE: `QuestionCacheTTLField`, `CacheTTLField`, `PLUGIN_FORM_WIDGETS`
* `src/metabase/query_processor/middleware/cache.clj` refers in a comment to a `query-caching-default-ttl` setting, but this is defunct.

"
2299139471,issue,closed,completed,Preview does not work for custom columns with `Offset` function,"1. New Question > Orders (from sample db)
2. Sort by ID
3. Custom column Prev Total = `Offset([Total], -1)`
4. Click on preview for custom column and it fails saying `Window function requires either breakouts or order by in the query`

We should hide the preview button in such cases

<img width=""1282"" alt=""Screenshot 2024-05-15 at 9 42 33 PM"" src=""https://github.com/metabase/metabase/assets/127636/5481bfc1-329c-4a35-b1e8-f86aec798fb0"">
",perivamsi,2024-05-16 01:44:03+00:00,[],2024-06-11 12:29:06+00:00,2024-05-17 09:48:43+00:00,https://github.com/metabase/metabase/issues/42739,[],[],
2299131819,issue,closed,not_planned,Users should be able to wipe all cached filter values from the GUI,"**Is your feature request related to a problem? Please describe.**
Many times the cached values from linked filters should be discarded before the expiration and users need to access the app db. We should give them the possibility to do that from the GUI

**Describe the solution you'd like**
A button on the settings to discard all cached values from linked filters

**Describe alternatives you've considered**
Go to the app db

**How important is this feature to you?**
We can't go to the app db for each one of these

**Additional context**
NA
",paoliniluis,2024-05-16 01:39:22+00:00,[],2024-09-01 01:36:22+00:00,2024-09-01 01:36:22+00:00,https://github.com/metabase/metabase/issues/42738,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]","[{'comment_id': 2323107165, 'issue_id': 2299131819, 'author': 'paoliniluis', 'body': 'This is currently working if you go to the field settings, my bad', 'created_at': datetime.datetime(2024, 9, 1, 1, 36, 18, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-09-01 01:36:18 UTC): This is currently working if you go to the field settings, my bad

"
2299010385,issue,closed,not_planned,MariaDB 10.11.7 is classified as too old (RocksDB),"**Describe the bug**
A connection is established, I can select 1 from dual, but all queries against tables fail, no tables are shown.

**Logs**
********************************************************************************
WARNING: Metabase only officially supports MySQL 5.7/MariaDB 10.2 and above.
All Metabase features may not work properly when using an unsupported version.
********************************************************************************

""MyRocks supports only READ COMMITTED and REPEATABLE READ isolation levels. Please change from current isolation level READ-UNCOMMITTED"",

**To Reproduce**
Install Ubuntu 24.04, apt update; apt install mariadb; ( Server version: 10.11.7-MariaDB-2ubuntu2 Ubuntu 24.04 )
I'm using SSL to connect. JDBC options I've used:

disableSslHostnameVerification=true

disableSslHostnameVerification=true&trustServerCertificate=true

disableSslHostnameVerification=true&trustServerCertificate=true&sessionVariables=tx_isolation='READ-COMMITTED'

I've set MariaDB to run globally with READ-COMMITTED and also tried REPEATABLE-READ


**Expected behavior**
Tables should show on the Browse page for the DB. Queries should run against tables.

**Severity**
I'm trying to use Rocks for analytics purposes. The data isn't getting any smaller. I suppose I could try to start over on an older OS release.

**Additional context**
I think the message about isolation level is a red herring. It looks more like this MariaDB version is unrecognized and classified as too old, when it's probably too new.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:126.0) Gecko/20100101 Firefox/126.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",Charlie-MPC,2024-05-15 23:19:38+00:00,[],2024-08-28 02:09:48+00:00,2024-07-03 18:03:11+00:00,https://github.com/metabase/metabase/issues/42734,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2118269687, 'issue_id': 2299010385, 'author': 'Charlie-MPC', 'body': 'After adding an InnoDB table to the DB as a test, it has become visible in Metabase. So the RocksDB tables are ignored. Is that intentional?', 'created_at': datetime.datetime(2024, 5, 17, 19, 44, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2175572923, 'issue_id': 2299010385, 'author': 'SBK79', 'body': 'tables that use Rocksdb engine are not visible for me, is this issue fixed ? is there a way to see rocksdb tables on metabase for now ?', 'created_at': datetime.datetime(2024, 6, 18, 8, 57, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2175925301, 'issue_id': 2299010385, 'author': 'paoliniluis', 'body': 'There’s not. We don’t support rocks db', 'created_at': datetime.datetime(2024, 6, 18, 11, 57, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2175960876, 'issue_id': 2299010385, 'author': 'SBK79', 'body': '> There’s not. We don’t support rocks db\r\n\r\nwill you support it in near future?', 'created_at': datetime.datetime(2024, 6, 18, 12, 17, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176186659, 'issue_id': 2299010385, 'author': 'paoliniluis', 'body': 'It depends on how many people ask for it, currently only 2 people did', 'created_at': datetime.datetime(2024, 6, 18, 14, 2, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197779773, 'issue_id': 2299010385, 'author': 'paoliniluis', 'body': 'if someone can test 50.7 or 50.8, we now use read commited @Charlie-MPC @SBK79', 'created_at': datetime.datetime(2024, 6, 28, 23, 54, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2198042529, 'issue_id': 2299010385, 'author': 'SBK79', 'body': ""@paoliniluis I tested metabase version 50.8 and unfortunately it didn't  find rocksdb tables again"", 'created_at': datetime.datetime(2024, 6, 29, 8, 11, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206913516, 'issue_id': 2299010385, 'author': 'perivamsi', 'body': ""This is not a bug and should not be a P1 since we don't support rocksdb."", 'created_at': datetime.datetime(2024, 7, 3, 18, 3, 9, tzinfo=datetime.timezone.utc)}]","Charlie-MPC (Issue Creator) on (2024-05-17 19:44:55 UTC): After adding an InnoDB table to the DB as a test, it has become visible in Metabase. So the RocksDB tables are ignored. Is that intentional?

SBK79 on (2024-06-18 08:57:58 UTC): tables that use Rocksdb engine are not visible for me, is this issue fixed ? is there a way to see rocksdb tables on metabase for now ?

paoliniluis on (2024-06-18 11:57:44 UTC): There’s not. We don’t support rocks db

SBK79 on (2024-06-18 12:17:17 UTC): will you support it in near future?

paoliniluis on (2024-06-18 14:02:48 UTC): It depends on how many people ask for it, currently only 2 people did

paoliniluis on (2024-06-28 23:54:43 UTC): if someone can test 50.7 or 50.8, we now use read commited @Charlie-MPC @SBK79

SBK79 on (2024-06-29 08:11:04 UTC): @paoliniluis I tested metabase version 50.8 and unfortunately it didn't  find rocksdb tables again

perivamsi on (2024-07-03 18:03:09 UTC): This is not a bug and should not be a P1 since we don't support rocksdb.

"
2298962555,issue,closed,completed,Add caching policy form to question info sidebar,,rafpaf,2024-05-15 22:33:55+00:00,['rafpaf'],2024-05-17 03:33:08+00:00,2024-05-17 03:33:08+00:00,https://github.com/metabase/metabase/issues/42731,[],[],
2298736446,issue,open,,[Bug] Sorting on implicit columns leads to incorrect offset calculation,"1. New question > Orders (from the sample data)
2. Select Product -> ID as the sort column
3. Add a custom column with prev total = `Offset([Total] ,-1)`

The results do not make sense - the prev total does not correspond to the total column from the previous row.




<img width=""644"" alt=""Screenshot 2024-05-15 at 3 58 31 PM"" src=""https://github.com/metabase/metabase/assets/127636/e60722b1-e448-418d-86cc-4e6dfc74ffc9"">
",perivamsi,2024-05-15 19:58:13+00:00,[],2024-05-30 20:34:27+00:00,,https://github.com/metabase/metabase/issues/42726,"[('.Limitation', '')]","[{'comment_id': 2128354035, 'issue_id': 2298736446, 'author': 'camsaul', 'body': 'order is indeterminate because sort order is indeterminate. See https://metaboat.slack.com/archives/C06P22KS4JH/p1716516438513129?thread_ts=1715803145.456429&cid=C06P22KS4JH for more info\r\n\r\n![image](https://github.com/metabase/metabase/assets/1455846/749bfd42-58e9-49cc-a312-d02a1af7db7b)', 'created_at': datetime.datetime(2024, 5, 24, 2, 5, 40, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-05-24 02:05:40 UTC): order is indeterminate because sort order is indeterminate. See https://metaboat.slack.com/archives/C06P22KS4JH/p1716516438513129?thread_ts=1715803145.456429&cid=C06P22KS4JH for more info

![image](https://github.com/metabase/metabase/assets/1455846/749bfd42-58e9-49cc-a312-d02a1af7db7b)

"
2298733292,issue,closed,completed,[Bug] Do not allow custom expression with offset function in a sort clause,"<img width=""1193"" alt=""Screenshot 2024-05-15 at 3 56 09 PM"" src=""https://github.com/metabase/metabase/assets/127636/7027db8c-7ff2-4924-a947-a0d6b905b90f"">
<img width=""734"" alt=""Screenshot 2024-05-15 at 3 56 20 PM"" src=""https://github.com/metabase/metabase/assets/127636/c86f9692-7c6e-4f0a-94d8-a14d0c337da6"">
",perivamsi,2024-05-15 19:56:00+00:00,[],2024-06-11 12:29:01+00:00,2024-05-17 09:49:26+00:00,https://github.com/metabase/metabase/issues/42725,[],[],
2298671061,issue,open,,Sorting tabular data view loses my work on viz,"[Loom](https://www.loom.com/share/4cf5f1b6b8774a838e30304440fc43bb?sid=7eab2403-0666-42e7-835f-85f8c07cffff)

Expected behavior: This shouldn't replace the existing viz with a table",cdeweyx,2024-05-15 19:19:40+00:00,[],2024-05-15 19:20:13+00:00,,https://github.com/metabase/metabase/issues/42723,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/', ''), ('Querying/', ''), ('.Team/Querying', '')]",[],
2298631800,issue,open,,"Styling for ""No change"" in trend charts is weird","Bold and grey style for ""No change"" is odd here. Should just read as ""No change vs. previous week"" all in one style.

[Slack discussion](https://metaboat.slack.com/archives/C01LQQ2UW03/p1715770696561769).

![Image](https://github.com/metabase/metabase/assets/16455495/09612954-1f14-431c-8886-9ad85df53e0a)

",cdeweyx,2024-05-15 19:01:10+00:00,[],2024-05-20 22:26:50+00:00,,https://github.com/metabase/metabase/issues/42721,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2121318942, 'issue_id': 2298631800, 'author': 'cdeweyx', 'body': 'Related discussion re null state: [Slack discussion](https://metaboat.slack.com/archives/C064QMXEV9N/p1716243140208849)', 'created_at': datetime.datetime(2024, 5, 20, 22, 26, 49, tzinfo=datetime.timezone.utc)}]","cdeweyx (Issue Creator) on (2024-05-20 22:26:49 UTC): Related discussion re null state: [Slack discussion](https://metaboat.slack.com/archives/C064QMXEV9N/p1716243140208849)

"
2298620957,issue,closed,not_planned,Widen question sidebar to match dashboard sidebar,,rafpaf,2024-05-15 18:56:19+00:00,[],2024-07-26 13:15:58+00:00,2024-07-26 13:15:56+00:00,https://github.com/metabase/metabase/issues/42719,[],"[{'comment_id': 2252744704, 'issue_id': 2298620957, 'author': 'rafpaf', 'body': ""We'll address this in the Sidesheets epic"", 'created_at': datetime.datetime(2024, 7, 26, 13, 15, 56, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-07-26 13:15:56 UTC): We'll address this in the Sidesheets epic

"
2298620058,issue,open,,[Cache] Follow ups (up next: Improve clear cache button and refresh button tooltip),"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/43019
- [ ] https://github.com/metabase/metabase/issues/43103
- [ ] https://github.com/metabase/metabase/issues/42741
- [ ] https://github.com/metabase/metabase/pull/42808
- [ ] https://github.com/metabase/metabase/pull/42788
- [ ] https://github.com/metabase/metabase/issues/42958
- [ ] https://github.com/metabase/metabase/issues/42719
- [x] Should it be ""invalidate cache now"" or ""clear cache""?
- [x] there’s too much distance between the DB icon and the name of the DB. It should the same distance as we have between the icons and DB titles within the list of DBs on the left.
- [x] constrain max width of strategy editor
- [x] Remove ""Question last cached"" and ""Dashboard last cached"" from the sidebar (they are showing imprecise timestamps) and it also should be moved elsewhere
- [x] Remove the Database advanced caching setting (required for v50 gold)
- [x] make the whole div be a hover/click target to display the policy form
- [x] In the bottom of the question UI, there is the execution time with a ""Updated a few seconds ago"" label. This label should show when the results were retrieved. If the question is cached, it should show something like ""retrived from cache: updated X ago""
- [ ] https://github.com/metabase/metabase/issues/44268
- [ ] https://github.com/metabase/metabase/pull/44263
- [ ] https://github.com/metabase/metabase/issues/45127
- [ ] https://github.com/metabase/metabase/pull/44280
- [ ] https://github.com/metabase/metabase/pull/46072
- [x] Require curate permission to change a question/dashboard caching policy
- [x] Change the button text from ""Clear cache"" to – depending on the context – ""Clear this question's cache"", ""Clear this dashboard's cache"", or ""Clear this database's cache"" (#46791)
- [x] Change the refresh button's tooltip to ""Clear cache and refresh"" (#46791)
- [ ] Use a broom icon for the clear cache button
```

```[tasklist]
### After Sidesheets
- [ ] Make the question cache footer element open the cache sidebar on click (if the user has access)
```
",rafpaf,2024-05-15 18:55:54+00:00,[],2024-08-27 18:25:59+00:00,,https://github.com/metabase/metabase/issues/42718,[],[],
2298594082,issue,open,,Dashboard with a large number of slow cards locks up the entire app temporarily by exhausting the browser's concurrent request limit,"### Describe the bug

If a dashboard has a certain number of cards which each take a long time to load, it locks up the entire app (i.e. API calls won't respond) until results start to come in.

Strangely, it only happens for the user who opened the dashboard. Other users can still use the site fine.

### To Reproduce

1. Connect a postgres DB (probably repros with other DBs but haven't tried)
2. Save a native query as `select pg_sleep(25);`
3. Create a dashboard and add at least 8 copies of the card. I can reliably repro with 8 but if it doesn't work try adding more.
4. Save the dashboard. You'll probably see it hang while trying to save for a while.
5. Refresh the dashboard and then open the homepage in another tab. You should see loading icons for the content on the page. Once results come back on the dashboard, the homepage should load.

<img width=""1575"" alt=""image"" src=""https://github.com/metabase/metabase/assets/32746338/9abed3de-0aaa-4a0c-b855-a59f4174757a"">

### Expected behavior

A single dashboard shouldn't be able to lock up the entire rest of the site.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master (`50a03a1956`)
```


### Severity

P1?

### Additional context

_No response_",noahmoss,2024-05-15 18:44:14+00:00,[],2024-07-16 17:05:35+00:00,,https://github.com/metabase/metabase/issues/42717,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2113355465, 'issue_id': 2298594082, 'author': 'noahmoss', 'body': ""Update: I've discovered that this is due to browser limits on the number of concurrent HTTP requests that can be made to the same server. Firing off more than 6 (for Chrome and FF) concurrent, long-running queries will block any other API requests made by the app. But if you log in as the same user in a different browser, the app will work fine while the dashboard is loading."", 'created_at': datetime.datetime(2024, 5, 15, 19, 59, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231313144, 'issue_id': 2298594082, 'author': 'paoliniluis', 'body': '@noahmoss this is http 1.1, on http 2 you can make as many concurrent requests as you wish. Should we close this issue?', 'created_at': datetime.datetime(2024, 7, 16, 16, 6, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231415387, 'issue_id': 2298594082, 'author': 'noahmoss', 'body': ""@paoliniluis I repro'd this in May based on this loom from Dan: https://metaboat.slack.com/archives/CKZEMT1MJ/p1715359546533919\r\n\r\nAre you able to repro with my steps? Maybe I got the root cause slightly wrong but I assume it's still an observable issue."", 'created_at': datetime.datetime(2024, 7, 16, 17, 5, 32, tzinfo=datetime.timezone.utc)}]","noahmoss (Issue Creator) on (2024-05-15 19:59:16 UTC): Update: I've discovered that this is due to browser limits on the number of concurrent HTTP requests that can be made to the same server. Firing off more than 6 (for Chrome and FF) concurrent, long-running queries will block any other API requests made by the app. But if you log in as the same user in a different browser, the app will work fine while the dashboard is loading.

paoliniluis on (2024-07-16 16:06:34 UTC): @noahmoss this is http 1.1, on http 2 you can make as many concurrent requests as you wish. Should we close this issue?

noahmoss (Issue Creator) on (2024-07-16 17:05:32 UTC): @paoliniluis I repro'd this in May based on this loom from Dan: https://metaboat.slack.com/archives/CKZEMT1MJ/p1715359546533919

Are you able to repro with my steps? Maybe I got the root cause slightly wrong but I assume it's still an observable issue.

"
2298479487,issue,closed,completed,cljs files are built twice at CI during build,,uladzimirdev,2024-05-15 17:42:00+00:00,[],2024-10-08 16:20:32+00:00,2024-07-17 16:13:48+00:00,https://github.com/metabase/metabase/issues/42714,[],[],
2298424911,issue,closed,not_planned,Appearance Upsell,"tricky because 
- our menu doesn't support icons
- the appearance menu item gets added by EE plugin",iethree,2024-05-15 17:10:09+00:00,[],2024-06-13 16:35:32+00:00,2024-06-13 16:35:32+00:00,https://github.com/metabase/metabase/issues/42713,[],[],
2298397028,issue,closed,completed,Migration Error from 0.49.8 to 0.49.9 or 0.49.10,"**Describe the bug**
I am currently using Metabase version 0.49.8. When attempting to update to version 0.49.10, I encountered an error during the migration process. The error message is as follows:

**Logs**
2024-05-15 15:03:53,695 ERROR metabase.core :: Metabase Initialization FAILED
java.sql.BatchUpdateException: Batch entry 0 UPDATE databasechangelog SET FILENAME = CASE WHEN ID = ('v00.00-000') THEN ('migrations/001_update_migrations.yaml') WHEN ID < ('v45.00-001') THEN ('migrations/000_legacy_migrations.yaml') ELSE ('migrations/001_update_migrations.yaml') END was aborted: ERROR: duplicate key value violates unique constraint ""idx_databasechangelog_id_author_filename""
  Detail: Key (id, author, filename)=(v00.00-000, qnkhuat, migrations/001_update_migrations.yaml) already exists.  Call getNextException to see other errors in the batch.
        at org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2413)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:579)
        at org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:912)
        at org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:936)
        at org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1733)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeBatch(NewProxyPreparedStatement.java:2544)
        at clojure.java.jdbc$execute_batch.invokeStatic(jdbc.clj:598)
        at clojure.java.jdbc$execute_batch.invoke(jdbc.clj:591)
        at clojure.java.jdbc$db_do_execute_prepared_statement$fn__28513.invoke(jdbc.clj:1057)
        at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:807)
        at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776)
        at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789)
        at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776)
        at clojure.java.jdbc$db_do_execute_prepared_statement.invokeStatic(jdbc.clj:1056)
        at clojure.java.jdbc$db_do_execute_prepared_statement.invoke(jdbc.clj:1042)
        at clojure.java.jdbc$db_do_prepared.invokeStatic(jdbc.clj:1080)
        at clojure.java.jdbc$db_do_prepared.invoke(jdbc.clj:1060)
        at clojure.java.jdbc$execute_BANG_$execute_helper__28581.invoke(jdbc.clj:1464)
        at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1466)
        at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435)
        at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1456)
        at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435)
        at metabase.db.liquibase$consolidate_liquibase_changesets_BANG_.invokeStatic(liquibase.clj:413)
        at metabase.db.liquibase$consolidate_liquibase_changesets_BANG_.invoke(liquibase.clj:400)
        at metabase.db.setup$migrate_BANG_$fn__51137.invoke(setup.clj:77)
        at metabase.db.liquibase$do_with_liquibase$f_STAR___48813.invoke(liquibase.clj:139)
        at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
        at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
        at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
        at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
        at clojure.lang.RestFn.invoke(RestFn.java:445)
        at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
        at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
        at metabase.db.setup$setup_db_BANG_$fn__51165$fn__51166.invoke(setup.clj:165)
        at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
        at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
        at metabase.db.setup$setup_db_BANG_$fn__51165.invoke(setup.clj:160)
        at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
        at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
        at metabase.db$setup_db_BANG_$fn__51185.invoke(db.clj:69)
        at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
        at metabase.db$setup_db_BANG_.invoke(db.clj:55)
        at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
        at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
        at metabase.core$init_BANG_.invokeStatic(core.clj:159)
        at metabase.core$init_BANG_.invoke(core.clj:154)
        at metabase.core$start_normally.invokeStatic(core.clj:171)
        at metabase.core$start_normally.invoke(core.clj:165)
        at metabase.core$entrypoint.invokeStatic(core.clj:204)
        at metabase.core$entrypoint.doInvoke(core.clj:198)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""idx_databasechangelog_id_author_filename""
  Detail: Key (id, author, filename)=(v00.00-000, qnkhuat, migrations/001_update_migrations.yaml) already exists.
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
        ... 61 more
2024-05-15 15:03:53,715 INFO metabase.core :: Metabase Shutting Down ...

**To Reproduce**
Steps to reproduce the behavior:
1. Dowload last version (0.49.10)
2. Run 'java -jar ./metabase.jar'

**Expected behavior**
This error prevents the successful completion of the update. Could you please assist in resolving this issue?

**Severity**
As a result, it is critically impacting our ability to use the latest version and benefit from its improvements and bug fixes. Given the severity, a prompt resolution would be greatly appreciated.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.75+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```",jeromedumas-peekin,2024-05-15 16:52:26+00:00,[],2024-05-20 08:33:44+00:00,2024-05-20 07:43:49+00:00,https://github.com/metabase/metabase/issues/42711,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase')]","[{'comment_id': 2113443092, 'issue_id': 2298397028, 'author': 'ZencareJake', 'body': ""Similar failure here:\r\n\r\n```\r\nReason: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values\r\nliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:\r\n2024-05-15 20:22:22,225 ERROR metabase.core :: Metabase Initialization FAILED\r\n... 236 more\r\nat [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]\r\nCaused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('T' (code 84)): Expected space separating root-level values\r\n```\r\nIt looks like @ppavlov39 is having similar issues [here](https://github.com/metabase/metabase/issues/41924) \r\n\r\nIn the logs I've listed above, the commit in question can be seen [here](https://github.com/metabase/metabase/commit/fe1f5950fb0ac03560b720b8cebeaf68b39a3eab)"", 'created_at': datetime.datetime(2024, 5, 15, 20, 56, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113451494, 'issue_id': 2298397028, 'author': 'ZencareJake', 'body': 'Looks like this has been addressed in some closed issues and will be resolved in 49.11\r\n\r\nhttps://github.com/metabase/metabase/issues/42659#issuecomment-2112657115', 'created_at': datetime.datetime(2024, 5, 15, 21, 3, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113657543, 'issue_id': 2298397028, 'author': 'paoliniluis', 'body': 'no, this is another thing, not the one that we already fixed', 'created_at': datetime.datetime(2024, 5, 15, 23, 42, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113915785, 'issue_id': 2298397028, 'author': 'ZencareJake', 'body': '> no, this is another thing, not the one that we already fixed\r\n\r\nGotcha, my apologies.', 'created_at': datetime.datetime(2024, 5, 16, 2, 49, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113923406, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': 'An old thread on this: https://metaboat.slack.com/archives/C064EB1UE5P/p1704840138989869', 'created_at': datetime.datetime(2024, 5, 16, 2, 59, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113926462, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': '@jeromedumas-peekin I need some info to debug this.\r\n\r\nCould you give us a dump of your `databasechangelog` table?\r\n\r\n```sql\r\nselect * from databasechangelog;\r\n```', 'created_at': datetime.datetime(2024, 5, 16, 3, 3, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2114091645, 'issue_id': 2298397028, 'author': 'dauntlessnomad', 'body': ""got this error after new update. \r\n\r\n```2024-05-16 05:51:13,979 ERROR metabase.core :: Metabase Initialization FAILED\t[78c11c62d9c145849baa3ee103273639](https://ap-south-1.console.aws.amazon.com/ecs/v2/clusters/eximpe-production-ap-south-1/services/metabase/tasks/78c11c62d9c145849baa3ee103273639?region=ap-south-1)\tmetabase\r\nMay 16, 2024 at 11:21 (UTC+5:30)\tliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:\t[78c11c62d9c145849baa3ee103273639](https://ap-south-1.console.aws.amazon.com/ecs/v2/clusters/eximpe-production-ap-south-1/services/metabase/tasks/78c11c62d9c145849baa3ee103273639?region=ap-south-1)\tmetabase\r\nMay 16, 2024 at 11:21 (UTC+5:30)\tReason: clojure.lang.ExceptionInfo: Unrecognized token 'nTmBnuuIywXxYSR': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')```\r\n\r\n\r\ni had to take a db snapshot and downgrade to v0.49.7 for the metabase to come back up."", 'created_at': datetime.datetime(2024, 5, 16, 5, 56, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2115593950, 'issue_id': 2298397028, 'author': 'jeromedumas-peekin', 'body': '> @jeromedumas-peekin I need some info to debug this.\r\n> \r\n> Could you give us a dump of your `databasechangelog` table?\r\n> \r\n> ```sql\r\n> select * from databasechangelog;\r\n> ```\r\n\r\nYes, please find dump of `databasechangelog` table. \r\n[databasechangelog.csv](https://github.com/metabase/metabase/files/15337683/databasechangelog.csv)', 'created_at': datetime.datetime(2024, 5, 16, 15, 45, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2117492608, 'issue_id': 2298397028, 'author': 'jeromedumas-peekin', 'body': 'Same error with version 0.49.11', 'created_at': datetime.datetime(2024, 5, 17, 12, 29, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119657202, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': '@jeromedumas-peekin, I am looking at your database change log, and it seems like there was a weird migration sequence. 2 problems:\r\n1) There are 2 migrations with IDs `v00.00-000`, and we should only have one.\r\n\r\n2) all `databasechangelog.filename` are `migrations/000_migrations.yaml` except for one entry.\r\n\r\nThis filename only existed in the pre-48 versions; from 48, we changed it to either `migrations/000_legacy_migrations.yaml` or `migrations/001_update_migrations.yaml`.\r\n\r\nThis suggests that there was some attempt to run a pre48 version recently without a proper downgrade.', 'created_at': datetime.datetime(2024, 5, 20, 4, 44, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119663042, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': ""The problem we're having here is not with migration, but it's trying to run this query on startup\r\n\r\n```\r\nUPDATE databasechangelog\r\nSET FILENAME = CASE\r\n                   WHEN ID = v00.00-000 THEN migrations/001_update_migrations.yaml\r\n                   WHEN ID < v45.00-001 THEN migrations/000_legacy_migrations.yaml\r\n                   ELSE migrations/001_update_migrations.yaml\r\n               END\r\n```\r\nand it fails because your database change log has 2 migrations with id `v00.00-000`"", 'created_at': datetime.datetime(2024, 5, 20, 4, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119666525, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': 'Try [this](https://github.com/metabase/metabase/issues/37344#issuecomment-1903146315) and see if it resolves your issue.', 'created_at': datetime.datetime(2024, 5, 20, 4, 55, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119865575, 'issue_id': 2298397028, 'author': 'jeromedumas-peekin', 'body': ""Solved with `delete from databasechangelog where id = 'v00.00-000' and author = 'qnkhuat' and filename = '001_update_migrations.yaml';`"", 'created_at': datetime.datetime(2024, 5, 20, 7, 43, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119890254, 'issue_id': 2298397028, 'author': 'qnkhuat', 'body': '@jeromedumas-peekin for our information, did something weird happen with your migration sequence?\r\n\r\nI want to know why you have 2 such migrations in the first place.', 'created_at': datetime.datetime(2024, 5, 20, 7, 59, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119950746, 'issue_id': 2298397028, 'author': 'jeromedumas-peekin', 'body': ""@qnkhuat No, nothing unusual happened with the migration sequence. I don't understand why i have 2 such migrations."", 'created_at': datetime.datetime(2024, 5, 20, 8, 33, 42, tzinfo=datetime.timezone.utc)}]","ZencareJake on (2024-05-15 20:56:45 UTC): Similar failure here:

```
Reason: clojure.lang.ExceptionInfo: Unexpected character ('T' (code 84)): Expected space separating root-level values
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
2024-05-15 20:22:22,225 ERROR metabase.core :: Metabase Initialization FAILED
... 236 more
at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('T' (code 84)): Expected space separating root-level values
```
It looks like @ppavlov39 is having similar issues [here](https://github.com/metabase/metabase/issues/41924) 

In the logs I've listed above, the commit in question can be seen [here](https://github.com/metabase/metabase/commit/fe1f5950fb0ac03560b720b8cebeaf68b39a3eab)

ZencareJake on (2024-05-15 21:03:01 UTC): Looks like this has been addressed in some closed issues and will be resolved in 49.11

https://github.com/metabase/metabase/issues/42659#issuecomment-2112657115

paoliniluis on (2024-05-15 23:42:09 UTC): no, this is another thing, not the one that we already fixed

ZencareJake on (2024-05-16 02:49:35 UTC): Gotcha, my apologies.

qnkhuat on (2024-05-16 02:59:20 UTC): An old thread on this: https://metaboat.slack.com/archives/C064EB1UE5P/p1704840138989869

qnkhuat on (2024-05-16 03:03:01 UTC): @jeromedumas-peekin I need some info to debug this.

Could you give us a dump of your `databasechangelog` table?

```sql
select * from databasechangelog;
```

dauntlessnomad on (2024-05-16 05:56:01 UTC): got this error after new update. 

```2024-05-16 05:51:13,979 ERROR metabase.core :: Metabase Initialization FAILED	[78c11c62d9c145849baa3ee103273639](https://ap-south-1.console.aws.amazon.com/ecs/v2/clusters/eximpe-production-ap-south-1/services/metabase/tasks/78c11c62d9c145849baa3ee103273639?region=ap-south-1)	metabase
May 16, 2024 at 11:21 (UTC+5:30)	liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:	[78c11c62d9c145849baa3ee103273639](https://ap-south-1.console.aws.amazon.com/ecs/v2/clusters/eximpe-production-ap-south-1/services/metabase/tasks/78c11c62d9c145849baa3ee103273639?region=ap-south-1)	metabase
May 16, 2024 at 11:21 (UTC+5:30)	Reason: clojure.lang.ExceptionInfo: Unrecognized token 'nTmBnuuIywXxYSR': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')```


i had to take a db snapshot and downgrade to v0.49.7 for the metabase to come back up.

jeromedumas-peekin (Issue Creator) on (2024-05-16 15:45:27 UTC): Yes, please find dump of `databasechangelog` table. 
[databasechangelog.csv](https://github.com/metabase/metabase/files/15337683/databasechangelog.csv)

jeromedumas-peekin (Issue Creator) on (2024-05-17 12:29:36 UTC): Same error with version 0.49.11

qnkhuat on (2024-05-20 04:44:30 UTC): @jeromedumas-peekin, I am looking at your database change log, and it seems like there was a weird migration sequence. 2 problems:
1) There are 2 migrations with IDs `v00.00-000`, and we should only have one.

2) all `databasechangelog.filename` are `migrations/000_migrations.yaml` except for one entry.

This filename only existed in the pre-48 versions; from 48, we changed it to either `migrations/000_legacy_migrations.yaml` or `migrations/001_update_migrations.yaml`.

This suggests that there was some attempt to run a pre48 version recently without a proper downgrade.

qnkhuat on (2024-05-20 04:51:45 UTC): The problem we're having here is not with migration, but it's trying to run this query on startup

```
UPDATE databasechangelog
SET FILENAME = CASE
                   WHEN ID = v00.00-000 THEN migrations/001_update_migrations.yaml
                   WHEN ID < v45.00-001 THEN migrations/000_legacy_migrations.yaml
                   ELSE migrations/001_update_migrations.yaml
               END
```
and it fails because your database change log has 2 migrations with id `v00.00-000`

qnkhuat on (2024-05-20 04:55:42 UTC): Try [this](https://github.com/metabase/metabase/issues/37344#issuecomment-1903146315) and see if it resolves your issue.

jeromedumas-peekin (Issue Creator) on (2024-05-20 07:43:50 UTC): Solved with `delete from databasechangelog where id = 'v00.00-000' and author = 'qnkhuat' and filename = '001_update_migrations.yaml';`

qnkhuat on (2024-05-20 07:59:23 UTC): @jeromedumas-peekin for our information, did something weird happen with your migration sequence?

I want to know why you have 2 such migrations in the first place.

jeromedumas-peekin (Issue Creator) on (2024-05-20 08:33:42 UTC): @qnkhuat No, nothing unusual happened with the migration sequence. I don't understand why i have 2 such migrations.

"
2298311923,issue,closed,not_planned,SSO (badge for each enterprise SSO method) Upsell,- tricky because all the components for SSO methods lives in the EE code,iethree,2024-05-15 16:04:07+00:00,[],2024-06-13 16:35:18+00:00,2024-06-13 16:35:18+00:00,https://github.com/metabase/metabase/issues/42708,[],[],
2298311832,issue,closed,not_planned,Metabase Analytics Upsell,,iethree,2024-05-15 16:04:04+00:00,[],2024-06-13 16:35:25+00:00,2024-06-13 16:35:25+00:00,https://github.com/metabase/metabase/issues/42707,[],[],
2298311688,issue,closed,completed,Migrate to cloud Upsell,"- upsell directory setup
- initial upsell components + wrappers
- first upsell: hosting",iethree,2024-05-15 16:04:00+00:00,['iethree'],2024-05-17 08:10:37+00:00,2024-05-16 22:12:29+00:00,https://github.com/metabase/metabase/issues/42706,[],[],
2298303072,issue,closed,completed,Custom user interface colors does not get applied on SDK,"Custom user interface colors does not get applied to the SDK. In addition, the SDK always throws a runtime error regarding `MetabaseSettings.get(""application-colors"")` being undefined at runtime, therefore the `updateColors` method in `whitelabel.js` is returning an error in the SDK. The value is not properly loaded.

See reproduction on https://github.com/metabase/metabase/pull/42663#discussion_r1603104382
",heypoom,2024-05-15 15:59:48+00:00,['heypoom'],2024-10-08 17:11:21+00:00,2024-05-21 17:29:26+00:00,https://github.com/metabase/metabase/issues/42705,[],[],
2298243512,issue,closed,completed,Upgrade Typescript to v5.4.5,"We're on Typescript v4.7.2, latest is v5.4.5.

New versions have cool stuff like https://devblogs.microsoft.com/typescript/announcing-typescript-5-2/#easier-method-usage-for-unions-of-arrays",iethree,2024-05-15 15:32:06+00:00,[],2025-01-03 16:53:43+00:00,2025-01-03 16:53:42+00:00,https://github.com/metabase/metabase/issues/42704,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2569534134, 'issue_id': 2298243512, 'author': 'iethree', 'body': 'done in #43736', 'created_at': datetime.datetime(2025, 1, 3, 16, 53, 42, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2025-01-03 16:53:42 UTC): done in #43736

"
2298185511,issue,closed,completed,Respect search-type-ahead setting in command palette,,npfitz,2024-05-15 15:05:50+00:00,['npfitz'],2024-05-15 21:48:16+00:00,2024-05-15 21:48:16+00:00,https://github.com/metabase/metabase/issues/42701,[],[],
2298105045,issue,closed,completed,add `can_restore` to help migrated archive items make sense,,dpsutton,2024-05-15 14:31:15+00:00,['johnswanson'],2024-05-16 23:16:53+00:00,2024-05-16 23:16:53+00:00,https://github.com/metabase/metabase/issues/42700,[],[],
2298063008,issue,closed,completed,Pivot table becomes broken if a breakout clause is added without visualizing the question,"### Describe the bug

When a saved question was visualized as a pivot table and its column widths were changed, then adding another breakout clause without visualizing the question will break it without the ability to recover.

### To Reproduce

- New -> Question -> Select Orders
- Summarize by “Count”, “Sum of (Total)“, Breakout by “User.State”, “Orders.Created At”
- Visualize
- Change the viz type to “Pivot table”
- Change the title (left) column width via the resize handle in the column header
- **Save the question now**
- Open the notebook editor
- Add another breakout “Product.Category”
- **Save the question now without visualizing**
- Visualize now

<img width=""1098"" alt=""Screenshot 2024-05-15 at 14 04 43"" src=""https://github.com/metabase/metabase/assets/8542534/b4b69124-6211-43c1-b852-73487354feaa"">

### Expected behavior

The table should render without errors

### Logs

FE logs:
```
querying.js:203 Error: Invalid metadata returned for cell 1:
        x:262, y:0, width:NaN, height:30
    at t.cellCount (calculateSizeAndPositionData.js:17:13)
    at t.value (calculateSizeAndPositionData.js:35:1)
    at t.value (CollectionView.js:315:27)
    at ij (react-dom.production.min.js:182:192)
    at iI (react-dom.production.min.js:181:224)
    at l (react-dom.production.min.js:263:490)
    at aH (react-dom.production.min.js:246:265)
    at react-dom.production.min.js:246:194
    at aW (react-dom.production.min.js:246:199)
    at react-dom.production.min.js:123:115
```

### Information about your Metabase installation

```
0.49
```

### Severity

Breaks questions without being able to recover from the UI.

### Additional context

_No response_",ranquild,2024-05-15 14:13:06+00:00,['ranquild'],2024-05-16 13:53:25+00:00,2024-05-16 13:53:15+00:00,https://github.com/metabase/metabase/issues/42697,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]",[],
2298056493,issue,closed,completed,[Browse] Milestone 2: Recents,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42632
```
",rafpaf,2024-05-15 14:10:16+00:00,[],2024-06-13 16:36:58+00:00,2024-06-13 16:36:57+00:00,https://github.com/metabase/metabase/issues/42696,[],"[{'comment_id': 2112742758, 'issue_id': 2298056493, 'author': 'rafpaf', 'body': 'Currently paused', 'created_at': datetime.datetime(2024, 5, 15, 14, 44, 26, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-05-15 14:44:26 UTC): Currently paused

"
2298048851,issue,closed,completed,Metabase doesn't automatically center-align labels in horizontal axis when removing columns,"### Describe the bug

When a combo visualization is used to display information with columns removed, the texts appear to be off-center. See following:

![Uploading image.png…](https://p23.zdusercontent.com/attachment/9175259/uQuHYm3D0H4xa9m6exjYuDeLX?token=eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..-0hfLX0XIHMEHloizFgjMw.YwXZnk8QZLJkmXAVUbQ-fhxa3h-Wg7RUJc-4YUiQOrBrSSTg9WsbuBl16Ddt1fHVcp1q47jAkEMfPWIXQ4cVg6Fdgr19w-4EpBwLivs-beLBLom3B3Mg_2K1n6XI69OsjRS5z0n1B11juV3s0Y2aDhma0yGxjSFdHfHAQNHQalr0lZwH9BDDuWn1ssvp6zj_81er8jcN0admQoNKdaU0BOOEV4T1ELwXhflxijNLuPlggItL8h-BM7lqO1U-_OMK3wTmkJ5pQ_paJVAHbSIUsyj38MGnaoHUbmK9mXJG3FKYVqpDxDp0y3Bi7Rk6zuvA.rajQgv3UD1naEarCfwOSmQ)


### To Reproduce

1. Create a new question using SQL editor. For example:

`with orders_table as (
SELECT
  extract(YEAR from created_at) AS year_,
  extract(MONTH from created_at) AS month_,
  COUNT(id),
  SUM(total)
FROM orders
WHERE extract(YEAR from created_at) = 2024
GROUP BY
  extract(YEAR from created_at),
  extract(MONTH from created_at)
ORDER BY
  extract(MONTH from created_at)
)
SELECT
    orders_table.*,
    CASE month_
        when 1 then 'Jan'
        when 2 then 'Feb'
        when 3 then 'Mar'
        when 4 then 'Apr'
        when 5 then 'May'
        when 6 then 'Jun'
        when 7 then 'Jul'
        when 8 then 'Aug'
        when 9 then 'Sep'
        when 10 then 'Oct'
        when 11 then 'Nov'
        when 12 then 'Dec'
    else null
  END case_status_date_cdt_month_txt,
FROM orders_table
WHERE month_ <= 5`

2. Change visualization to Combo

3. Remove columns YEAR_ and MONTH_


### Expected behavior

The texts should be centered across the current bars being displayed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase Cloud v1.49.8
```


### Severity

minor

### Additional context

_No response_",taqattack,2024-05-15 14:07:10+00:00,[],2024-05-15 18:18:42+00:00,2024-05-15 18:16:36+00:00,https://github.com/metabase/metabase/issues/42695,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2113162643, 'issue_id': 2298048851, 'author': 'alxnddr', 'body': 'Hi @taqattack, we\'ve revamped our cartesian charts in the upcoming Metabase 50 release and this particular case will work as expected:\r\n\r\n<img width=""1724"" alt=""Screenshot 2024-05-15 at 3 16 58\u202fPM"" src=""https://github.com/metabase/metabase/assets/14301985/7f7fc663-3a41-42ce-aef2-28a232bf9453"">', 'created_at': datetime.datetime(2024, 5, 15, 18, 17, 46, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-05-15 18:17:46 UTC): Hi @taqattack, we've revamped our cartesian charts in the upcoming Metabase 50 release and this particular case will work as expected:

<img width=""1724"" alt=""Screenshot 2024-05-15 at 3 16 58 PM"" src=""https://github.com/metabase/metabase/assets/14301985/7f7fc663-3a41-42ce-aef2-28a232bf9453"">

"
2298032061,issue,closed,completed,[Epic] Improve theming consistency for React embedding SDK,"**Goals**
1. Focus on ensuring that changes are cascaded.
2. Theming should not feel inconsistent or broken
3. Granularity comes later.

**Links**
- [product doc](https://www.notion.so/metabase/SDK-Coarse-Theming-6fedde5eb0404778b86a2a4006d377f7?pvs=4)
- [eng doc](https://www.notion.so/metabase/Next-Theming-Milestones-4e82017c97844adb983add93fed2c6d1?pvs=4)

**Implementation Plan**

***Milestone 1: Expose color settings and improve font consistency***

```[tasklist]
### Tasks
- [ ] #42680
- [ ] #42684
- [ ] #42676
- [ ] https://github.com/metabase/metabase/pull/42855
- [ ] https://github.com/metabase/metabase/issues/42705
- [ ] #42563
```

***Milestone 1.5: Migrate hardcoded colors in main app styles***

```[tasklist]
### Tasks
- [ ] #43413
- [ ] #43512
- [ ] #43598
- [ ] #43608
- [ ] #43676
- [ ] #43687
```

***Milestone 2: Chart colors, color contrast and font scaling***

```[tasklist]
### Tasks
- [ ] #42686
- [ ] #42685
- [ ] https://github.com/metabase/metabase/issues/42947
- [ ] #42692
```

***Milestone 3: Fix styling issues in static dashboards and add to demo app***

```[tasklist]
### Tasks
- [ ] #43665
- [ ] #42678
- [ ] https://github.com/metabase/shoppy/issues/26
- [ ] https://github.com/metabase/metabase/issues/43820
- [ ] https://github.com/metabase/metabase/issues/43918
- [ ] https://github.com/metabase/metabase/issues/43819
- [ ] #42693
- [ ] #43672
```

***Milestone 4: Address theming in more visualizations and cleanup theming migration***

```[tasklist]
### Tasks
- [ ] #43265
- [ ] https://github.com/metabase/metabase/issues/44115
- [ ] #43674
- [ ] https://github.com/metabase/metabase/issues/44222
- [ ] https://github.com/metabase/metabase/issues/44226
```",heypoom,2024-05-15 14:01:35+00:00,[],2024-06-27 11:25:13+00:00,2024-06-27 11:25:12+00:00,https://github.com/metabase/metabase/issues/42694,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', '')]",[],
2298010293,issue,closed,completed,Theming for tables in dashboards in embedding SDK,Currently #42411 only supports table in embedded questions (i.e. TableInteractive). We want to add the same theming support to TableSimple (for embedded dashboards). The same theming options for TableInteractive should also apply to TableSimple.,heypoom,2024-05-15 13:54:31+00:00,['heypoom'],2024-10-08 17:07:46+00:00,2024-06-13 14:34:27+00:00,https://github.com/metabase/metabase/issues/42693,[],"[{'comment_id': 2129865177, 'issue_id': 2298010293, 'author': 'heypoom', 'body': '@deniskaber Just a heads-up, `TableSimple` will only be rendered in static dashboards (not questions), so if we were to test this with the SDK we can use the static dashboard PR to test', 'created_at': datetime.datetime(2024, 5, 24, 15, 46, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150599192, 'issue_id': 2298010293, 'author': 'heypoom', 'body': ""@deniskaber fyi, feel free to unassign yourself if you're not working on this yet (so Kelvin and I can help tackle this 🙏🏻)"", 'created_at': datetime.datetime(2024, 6, 5, 17, 33, 54, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-24 15:46:36 UTC): @deniskaber Just a heads-up, `TableSimple` will only be rendered in static dashboards (not questions), so if we were to test this with the SDK we can use the static dashboard PR to test

heypoom (Issue Creator) on (2024-06-05 17:33:54 UTC): @deniskaber fyi, feel free to unassign yourself if you're not working on this yet (so Kelvin and I can help tackle this 🙏🏻)

"
2297985110,issue,closed,completed,Font size scaling should apply to visible SDK components proportionally,"The base font size settings should apply to all visible elements in SDK components proportionally, such as for cartesian chart's axis labels. Some elements are currently hard-coded with px, instead of using relative units such as `em` and `rem`.",heypoom,2024-05-15 13:46:47+00:00,['heypoom'],2024-10-08 17:09:19+00:00,2024-06-04 20:36:50+00:00,https://github.com/metabase/metabase/issues/42692,[],[],
2297779733,issue,closed,completed,Empty collections handling,"Currently root collections and personal collections are always displayed in the picker, see:

https://github.com/metabase/metabase/blob/1c5e5998bbe7ea6ebd6d59bb23fbfbe2d81a9068/frontend/src/metabase/common/components/QuestionPicker/utils.ts#L94-L105

https://github.com/metabase/metabase/blob/4cbae2ee70c64738695db8705b172efbb4524a0f/frontend/src/metabase/common/components/CollectionPicker/components/PersonalCollectionItemList.tsx#L51

https://github.com/metabase/metabase/blob/1163109d9e38ec322129f67daf2c336788f4d616/frontend/src/metabase/common/components/DataPicker/utils.ts#L188-L190

This can sometimes lead users to dead ends.

Ideally we'd

> update the API to correctly populate personal collections. I think the right way to do this is probably not via search, but should be a special case like `collection/personal/items` to list all other personal collections with the same shape as `collection/:id/items`

See [Slack thread](https://metaboat.slack.com/archives/C010L1Z4F9S/p1715776154458989?thread_ts=1715177121.332039&cid=C010L1Z4F9S).

----

This should be covered with tests.

----

We [had to remove](https://github.com/metabase/metabase/pull/42565) this assertion in the Data Picker epic because of it: https://github.com/metabase/metabase/blob/14e66a08dbb51104f1ece7e84920ecdb1002723e/e2e/test/scenarios/question/new.cy.spec.js#L198-L200

We should bring it back.",kamilmielnik,2024-05-15 12:29:50+00:00,[],2024-05-16 06:56:37+00:00,2024-05-16 06:56:37+00:00,https://github.com/metabase/metabase/issues/42687,"[('Type:Bug', 'Product defects'), ('.Frontend', ''), ('.Backend', '')]","[{'comment_id': 2114203960, 'issue_id': 2297779733, 'author': 'kamilmielnik', 'body': 'Duplicate of #40924', 'created_at': datetime.datetime(2024, 5, 16, 6, 56, 37, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-16 06:56:37 UTC): Duplicate of #40924

"
2297572962,issue,closed,completed,Text colors should follow the background based on color contrast in embedding SDK,We should provide support for both light-theme and dark-theme users of the sdk by providing automatic contrast detection. The idea is that foreground color should follow the background color defined in https://github.com/metabase/metabase/issues/42678 by detecting whether the background is dark or light mode.,heypoom,2024-05-15 11:04:22+00:00,['heypoom'],2024-06-05 17:18:41+00:00,2024-05-27 11:31:08+00:00,https://github.com/metabase/metabase/issues/42686,[],"[{'comment_id': 2133280369, 'issue_id': 2297572962, 'author': 'heypoom', 'body': 'Closing this issue as we already provide `text-primary`, `text-secondary` and `text-tertiary` settings that the user can control. [Refer to the discussion here.](https://metaboat.slack.com/archives/C063Q3F1HPF/p1716801970416769?thread_ts=1716547771.731429&cid=C063Q3F1HPF)', 'created_at': datetime.datetime(2024, 5, 27, 11, 31, 8, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-27 11:31:08 UTC): Closing this issue as we already provide `text-primary`, `text-secondary` and `text-tertiary` settings that the user can control. [Refer to the discussion here.](https://metaboat.slack.com/archives/C063Q3F1HPF/p1716801970416769?thread_ts=1716547771.731429&cid=C063Q3F1HPF)

"
2297544787,issue,closed,completed,Override chart colors with support for auto-generating colors in embedding SDK,"Provide theme options to override chart colors that were defined in the dashboard.

- When no overrides are provided in the SDK, existing chart colors should apply as before.
- When one chart color override is provided, attempt to auto-generate the rest of the colors.

<img src=""https://github.com/metabase/metabase/assets/4714175/f36f0959-7c4f-4786-a2d9-1dd077921403"" width=""600"">

",heypoom,2024-05-15 10:54:29+00:00,['heypoom'],2024-10-08 17:10:30+00:00,2024-05-28 09:56:02+00:00,https://github.com/metabase/metabase/issues/42685,[],[],
2297535114,issue,closed,completed,Override user interface colors in embedding SDK,"Expose colors to override the 3 user interface colors as part of the theme configuration.

- Primary color - already exposed as `brand` ✅ 
- Aggregation and breakouts in query builder (`colors.summarize`)
- Color used in filter components (`colors.filter`)

![Image](https://github.com/metabase/metabase/assets/4714175/5b28e6a0-9c8a-471c-b6cd-e2180baa2fdf)

",heypoom,2024-05-15 10:49:16+00:00,['heypoom'],2024-06-05 17:18:37+00:00,2024-05-20 16:03:58+00:00,https://github.com/metabase/metabase/issues/42684,[],"[{'comment_id': 2120751223, 'issue_id': 2297535114, 'author': 'heypoom', 'body': 'This is implemented by Denis on #42663, we support `brand`, `summarize` and `filter` now.\n\n<img src=""https://github.com/metabase/metabase/assets/4714175/a9044857-3639-4d4c-a205-c01ab965585b"" width=""300"">', 'created_at': datetime.datetime(2024, 5, 20, 16, 3, 58, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-20 16:03:58 UTC): This is implemented by Denis on #42663, we support `brand`, `summarize` and `filter` now.

<img src=""https://github.com/metabase/metabase/assets/4714175/a9044857-3639-4d4c-a205-c01ab965585b"" width=""300"">

"
2297355305,issue,closed,completed,"Can't reset binning on join columns to ""Don't bin""","### Describe the bug

When adding a join to a question and choosing a date field, it will by default bin the date field by month. You can change the binning, but trying to change to the ""Don't bin"" option doesn't work - the current binning sticks.

### To Reproduce

1. Go to 'New' > 'Question'
2. Choose the Sample Database and any table with a date field, such as Accounts
3. Add a join to the same table and choose the 'Created At' date field on both sides of the criteria
4. Change the 'Created At' grouping to 'Day'; this works
5. Change the 'Created At' grouping to 'Day of month' (from the More menu); this works
6. Change the 'Created At' grouping to 'Don't bin'; this is ignored and 'Day of month' remains


### Expected behavior

Changing the binning to ""Don't bin"" should work.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-15"",
      ""tag"": ""v0.49.10"",
      ""hash"": ""9e8fc83""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Auckland""
    }
  }
}
```


### Severity

Moderate

### Additional context

_No response_",willbryant,2024-05-15 09:31:24+00:00,['ranquild'],2024-06-24 13:50:48+00:00,2024-06-24 13:06:35+00:00,https://github.com/metabase/metabase/issues/42681,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2297347704,issue,closed,completed,Remap color scheme names to be theme-agnostic in embedding SDK,"Currently we expose the exact colors we are using in the codebase to the SDK: `brand`, `text-dark`, `text-light` and `text-medium`. The `text-*` colors currently represent the different tints, where `text-dark` is darker than `text-light`.

This is problematic for dark-themed SDK users, as for dark themes those names could have the opposite semantic. We could remap these colors in the publicly-exposed theme configuration so that they're theme agnostic - so they have good meaning in both dark and light themes.

- `text-dark` to `text-primary`
- `text-medium` to `text-secondary`
- `text-light` to `text-tertiary`",heypoom,2024-05-15 09:27:49+00:00,['deniskaber'],2024-05-17 13:57:44+00:00,2024-05-17 13:57:44+00:00,https://github.com/metabase/metabase/issues/42680,[],[],
2297328617,issue,closed,completed,Update the docs on theming configuration in embedding SDK,,heypoom,2024-05-15 09:18:50+00:00,['heypoom'],2024-05-17 10:16:43+00:00,2024-05-17 10:16:43+00:00,https://github.com/metabase/metabase/issues/42679,[],[],
2297326053,issue,closed,completed,Dashboard and question color customization in embedding SDK,"Implement background color settings for the embedding SDK.


```[tasklist]
### Blockers
- [x] #41973 needed to implement the ""dashboard background settings"" and ""dashcard background settings""
```

## Theme Options
- ✅ Popover background settings
   - Popovers are used in filters, click action context menu, column header menu, etc.
   - Implemented in #42663
- Visualization & dashcard background settings
   - Apply background color to dashcard container in embedded dashboards
   - Apply background color to question/visualization container in embedded questions
- Dashboard background settings
   - Default to unset/transparent

## Considerations
- We can either use the `theme.colors` field (e.g. `bg-visualization`), or we can make this a theme option (e.g. `theme.visualization.backgroundColor`)",heypoom,2024-05-15 09:18:01+00:00,['heypoom'],2024-10-08 17:08:38+00:00,2024-06-07 15:07:29+00:00,https://github.com/metabase/metabase/issues/42678,[],"[{'comment_id': 2120829518, 'issue_id': 2297326053, 'author': 'heypoom', 'body': '@albertoperdomo @NevRA FYI, I moved this to Milestone 3 because of a hard dependency on Static Dashboard. Denis already implemented background for popovers in the drills PR, but the other 2 (dashcard background, embedded dashboard background) all requires Static Dashboard.', 'created_at': datetime.datetime(2024, 5, 20, 16, 52, 31, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-20 16:52:31 UTC): @albertoperdomo @NevRA FYI, I moved this to Milestone 3 because of a hard dependency on Static Dashboard. Denis already implemented background for popovers in the drills PR, but the other 2 (dashcard background, embedded dashboard background) all requires Static Dashboard.

"
2297296192,issue,open,,Configurable session timeout based on group membership,"**Is your feature request related to a problem? Please describe.**
Larger organizations may want to set up different session timeouts for different groups of people (for instance, internal vs external users, creators vs data consumers, ...).

An actual request:
> We have multiple groups of users, some whom we would like to have shorter session timeouts after inactivity vs others e.g. purely data consumers would have their session timeout after 30 minutes of inactivity vs data developers who might have their session timeout after 2 hours of inactivity.

**Describe the solution you'd like**
Ability to configure session timeouts based on group membership (in addition to the configurable global default). When a timeout value is associated with a group the user is a member of, the session timeout will be set to the group specific value for the user.

**Describe alternatives you've considered**
n/a

**How important is this feature to you?**
A customer has requested it.

**Additional context**
n/a",zbodi74,2024-05-15 09:07:33+00:00,[],2024-05-30 10:04:53+00:00,,https://github.com/metabase/metabase/issues/42677,"[('Type:New Feature', ''), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('Administration/People', 'and Groups. Also user Account Settings')]",[],
2297265067,issue,closed,completed,Ensure font family are applied to all visualizations using echarts in SDK,"We should double-check that echarts-based visualizations in embedding SDK are applying font family settings correctly.

```[tasklist]
### Blockers
- [x] #42341 Needed for Font Families to work.
```


## Cases to check
- Metabase font families. Set `theme.fontFamily` to one of our supported fonts (e.g. `Inter`) 
- Custom font family. Set `theme.fontFamily` in the SDK to `""Custom"". Upload a custom font in the admin settings, and apply the custom font.

## Visualizations to check
- **Cartesian Charts**
    - **Line Chart**
    - **Area Chart**
    - **Bar Chart**
    - Funnel
    - Waterfall Chart
    - Scatter Plot
- Combo Charts

## Example elements to check
- Axis Labels
- Axis Values
- Values on Data Points (value above or within each bars in bar charts)
- Goal Line Label

## Out of scope visualizations (not echarts)
- Pie Chart (using D3.js)",heypoom,2024-05-15 08:53:43+00:00,['heypoom'],2024-05-21 11:48:50+00:00,2024-05-21 11:48:50+00:00,https://github.com/metabase/metabase/issues/42676,[],"[{'comment_id': 2122454739, 'issue_id': 2297265067, 'author': 'heypoom', 'body': '@albertoperdomo @NevRA Here are the test results. I think font family is applied to all vis already including Visx and D3 ones, so we are good to close this.\r\n\r\n✅ Cartesian Charts: Line, Area and Bar charts\r\n\r\n![CleanShot 2567-05-21 at 18 38 27@2x](https://github.com/metabase/metabase/assets/4714175/07311a3c-993e-430b-aefd-72bb3ea2a8c8)\r\n\r\n✅ Row Chart\r\n\r\n![CleanShot 2567-05-21 at 18 48 19@2x](https://github.com/metabase/metabase/assets/4714175/489b4f7f-dc18-4aaf-bb93-66a39dc48363)\r\n\r\n✅ Pie Chart\r\n\r\n![CleanShot 2567-05-21 at 18 42 16@2x](https://github.com/metabase/metabase/assets/4714175/63f3677a-42de-4280-9b13-c9aff9818239)\r\n\r\n✅ Scalar & Smart Scalar\r\n\r\n![CleanShot 2567-05-21 at 18 45 30@2x](https://github.com/metabase/metabase/assets/4714175/e2a35043-ac53-45b0-9a11-f281c7054b08)\r\n\r\n✅ Funnel\r\n\r\n![CleanShot 2567-05-21 at 18 46 18@2x](https://github.com/metabase/metabase/assets/4714175/d86165fe-5392-4412-a5bc-16c8109372da)\r\n\r\n✅ Waterfall\r\n\r\n![CleanShot 2567-05-21 at 18 47 17@2x](https://github.com/metabase/metabase/assets/4714175/625f7445-e62f-4b9a-9f55-e1424d5a3646)\r\n\r\n⛔ Pivot table does not render at all, cannot test. Will have to fix that.', 'created_at': datetime.datetime(2024, 5, 21, 11, 48, 50, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-21 11:48:50 UTC): @albertoperdomo @NevRA Here are the test results. I think font family is applied to all vis already including Visx and D3 ones, so we are good to close this.

✅ Cartesian Charts: Line, Area and Bar charts

![CleanShot 2567-05-21 at 18 38 27@2x](https://github.com/metabase/metabase/assets/4714175/07311a3c-993e-430b-aefd-72bb3ea2a8c8)

✅ Row Chart

![CleanShot 2567-05-21 at 18 48 19@2x](https://github.com/metabase/metabase/assets/4714175/489b4f7f-dc18-4aaf-bb93-66a39dc48363)

✅ Pie Chart

![CleanShot 2567-05-21 at 18 42 16@2x](https://github.com/metabase/metabase/assets/4714175/63f3677a-42de-4280-9b13-c9aff9818239)

✅ Scalar & Smart Scalar

![CleanShot 2567-05-21 at 18 45 30@2x](https://github.com/metabase/metabase/assets/4714175/e2a35043-ac53-45b0-9a11-f281c7054b08)

✅ Funnel

![CleanShot 2567-05-21 at 18 46 18@2x](https://github.com/metabase/metabase/assets/4714175/d86165fe-5392-4412-a5bc-16c8109372da)

✅ Waterfall

![CleanShot 2567-05-21 at 18 47 17@2x](https://github.com/metabase/metabase/assets/4714175/625f7445-e62f-4b9a-9f55-e1424d5a3646)

⛔ Pivot table does not render at all, cannot test. Will have to fix that.

"
2297171904,issue,closed,completed,Integrate Recents tab,"- [x] enable recents tab in the Data Picker
- [x] update existing e2e tests to account for the new Recents tab (which will now be the default tab)
- [x] add new e2e tests to account for the new Recents tab",kamilmielnik,2024-05-15 08:09:51+00:00,['kamilmielnik'],2024-05-17 10:23:16+00:00,2024-05-17 10:23:16+00:00,https://github.com/metabase/metabase/issues/42675,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2117246794, 'issue_id': 2297171904, 'author': 'kamilmielnik', 'body': 'Closed by #42821', 'created_at': datetime.datetime(2024, 5, 17, 10, 23, 16, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-17 10:23:16 UTC): Closed by #42821

"
2297080892,issue,closed,completed,Add the created column to the end of the table and scroll to it,"[Product doc](https://www.notion.so/metabase/Scroll-to-the-created-column-96e13721bc4f44e0a8da9be1349e64a0)

Currently, when creating new columns through the Extract/Combine column drillthroughs, or through the Extract/Combine column shortcuts in viz mode, the column gets added inconsistently:

- the shortcuts add the column to the end
- the extract drillthrough adds the column after the column it's extracted from, while the combine column drillthrough adds the column to the end.

## Goals
- Make this more consistent by adding the new column at the end always.
- Scroll to the newly added column",romeovs,2024-05-15 07:22:21+00:00,['romeovs'],2024-10-08 17:11:47+00:00,2024-05-17 14:23:04+00:00,https://github.com/metabase/metabase/issues/42674,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2296702803,issue,open,,"Monthly revenue and other cards in ""customer-360"" dashboard breaks on subscriptions","### Describe the bug

Sending a test subscription makes these cards to error
![image](https://github.com/metabase/metabase/assets/1711649/015f15ce-576a-4c3d-b9d4-5a43c032fd5f)
![image](https://github.com/metabase/metabase/assets/1711649/e9cf1506-3c30-49c0-a3c4-7bb9f84c5a06)


### To Reproduce

- Go to customer 360 dashboard
- send yourself a subscription

### Expected behavior

It should render

### Logs

NA

### Information about your Metabase installation

```JSON
master
```


### Severity

P2

### Additional context

There are other cards that have some little visual glitches like
![image](https://github.com/metabase/metabase/assets/1711649/6f6cbbc8-aa2c-441f-861f-43ce8b638ee3)
![image](https://github.com/metabase/metabase/assets/1711649/b55274a7-32de-404b-948e-7997661324f3)
![image](https://github.com/metabase/metabase/assets/1711649/ac663eda-1b9b-47f9-85c9-305023338856)
![image](https://github.com/metabase/metabase/assets/1711649/c0565a67-6750-4ebd-816e-729d99de8d9f)
",paoliniluis,2024-05-15 02:08:57+00:00,[],2024-05-16 21:02:27+00:00,,https://github.com/metabase/metabase/issues/42673,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2296668471,issue,open,,Connecting to Athena gives a NullPointerException with a null message when not filling up the region section,"### Describe the bug

If you don't fill the region, it will throw an error immediately with a null pointer exception and a null value

### To Reproduce

1) set up an Athena and then try to connect Metabase to it (without filling up the region section)
2) see the error

### Expected behavior

It should show the error, and also we should respect the defaults

### Logs

```
2024-05-15 01:20:47,085 ERROR driver.util :: Failed to connect to Database
java.lang.NullPointerException
	at clojure.string$starts_with_QMARK_.invokeStatic(string.clj:365)
	at clojure.string$starts_with_QMARK_.invoke(string.clj:361)
	at metabase.driver.athena$endpoint_for_region.invokeStatic(athena.clj:52)
	at metabase.driver.athena$endpoint_for_region.invoke(athena.clj:48)
	at metabase.driver.athena$fn__112981.invokeStatic(athena.clj:60)
	at metabase.driver.athena$fn__112981.invoke(athena.clj:55)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__51120.invoke(connection.clj:315)
	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:314)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:310)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:339)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:335)
	at metabase.driver.sql_jdbc$fn__112862.invokeStatic(sql_jdbc.clj:49)
	at metabase.driver.sql_jdbc$fn__112862.invoke(sql_jdbc.clj:47)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__60055.invoke(util.clj:148)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-05-15 01:20:47,088 ERROR api.database :: Cannot connect to Database
java.lang.NullPointerException
	at clojure.string$starts_with_QMARK_.invokeStatic(string.clj:365)
	at clojure.string$starts_with_QMARK_.invoke(string.clj:361)
	at metabase.driver.athena$endpoint_for_region.invokeStatic(athena.clj:52)
	at metabase.driver.athena$endpoint_for_region.invoke(athena.clj:48)
	at metabase.driver.athena$fn__112981.invokeStatic(athena.clj:60)
	at metabase.driver.athena$fn__112981.invoke(athena.clj:55)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__51120.invoke(connection.clj:315)
	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:314)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:310)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:339)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:335)
	at metabase.driver.sql_jdbc$fn__112862.invokeStatic(sql_jdbc.clj:49)
	at metabase.driver.sql_jdbc$fn__112862.invoke(sql_jdbc.clj:47)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__60055.invoke(util.clj:148)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-05-15 01:20:47,092 DEBUG middleware.log :: POST /api/database 400 8.4 ms (0 DB calls) 
{:message nil}
```

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-05-15 01:24:40+00:00,[],2025-02-04 20:27:54+00:00,,https://github.com/metabase/metabase/issues/42671,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Database/Athena', ''), ('.Team/Drivers', '')]",[],
2296511441,issue,closed,completed,[BE] [API] Return compatible metrics in /api/table/:id/query_metadata as before,,snoe,2024-05-14 22:25:39+00:00,['snoe'],2024-05-16 14:49:56+00:00,2024-05-16 14:49:56+00:00,https://github.com/metabase/metabase/issues/42668,[],[],
2296510698,issue,closed,completed,[BE] [QP] Allow referencing compatible metrics in queries without joins (previous behavior),,snoe,2024-05-14 22:25:05+00:00,['snoe'],2024-05-17 16:33:42+00:00,2024-05-17 16:33:42+00:00,https://github.com/metabase/metabase/issues/42667,[],[],
2296419931,issue,closed,completed,Reduce number of queries. We have an N+1 situation,,dpsutton,2024-05-14 21:09:56+00:00,['escherize'],2024-05-16 23:20:01+00:00,2024-05-16 23:20:01+00:00,https://github.com/metabase/metabase/issues/42665,[],[],
2296308278,issue,closed,not_planned,Token error on upgrade to 49.9,"### Describe the bug

I am attempting to upgrade our instance from v0.47.7 -> v0.49.9 and hitting a migration error.

We are not changing anything with our encryption key, but under 47.7 we are getting this error in the logs:

```
Cannot decrypt encrypted String. Have you changed or forgot to set MB_ENCRYPTION_SECRET_KEY?
```

Everything is working in 47.7 however as far as we can tell.

When attempting to upgrade to 49.9:

```
May 14, 2024 at 14:05 (UTC+12:00)	2024-05-14 12:05:15,281 ERROR metabase.core :: Metabase Initialization FAILED	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	Reason: clojure.lang.ExceptionInfo: Unrecognized token '<omitted>': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 43] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
```

I have also attempted a two step migration (47.7 -> 48 -> 49) and hit the same error.

### To Reproduce

1. Have an instance of 0.47.7
2. Attempt to upgrade to 0.49.9
3. Migration fails


### Expected behavior

_No response_

### Logs

Migration error: 

https://gist.github.com/kbrownlees/4f390db9460e59cea7a81ed5e831b992

Start-up logs for 48.13:

https://gist.github.com/kbrownlees/b62de3366b1c06db8143281876eab816

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:125.0) Gecko/20100101 Firefox/125.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Australia/Sydney""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-30"",
      ""tag"": ""v0.48.13"",
      ""hash"": ""7a5ccd8""
    },
    ""settings"": {
      ""report-timezone"": ""Australia/Sydney""
    }
  }
}
```


### Severity

Blocking upgrade to 49

### Additional context

_No response_",kbrownlees,2024-05-14 19:54:00+00:00,[],2024-05-15 14:09:35+00:00,2024-05-14 20:11:08+00:00,https://github.com/metabase/metabase/issues/42659,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2111058956, 'issue_id': 2296308278, 'author': 'paoliniluis', 'body': 'we just fixed this today, expect it for 49.11', 'created_at': datetime.datetime(2024, 5, 14, 20, 11, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2112432646, 'issue_id': 2296308278, 'author': 'vinceve', 'body': 'Upgraded from 1.49.3 to 1.49.9 and got the same issue (although the error is slightly different)\r\n\r\n```\r\ntabase\r\n2024-05-15 12:34:30,408 ERROR metabase.core :: Metabase Initialization FAILED\r\nmetabase\r\nliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:\r\nmetabase\r\nReason: clojure.lang.ExceptionInfo: Unexpected character (\'Z\' (code 90)): Expected space separating root-level values\r\nmetabase\r\nat [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\nmetabase\r\n    at liquibase.command.CommandScope.execute(CommandScope.java:253)\r\nmetabase\r\n    at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)\r\nmetabase\r\n    at liquibase.Scope.lambda$child$0(Scope.java:186)\r\n```\r\n\r\nWhen will this issue be resolved and released? It\'s important for us as we are in the middle of a release and that this blocks our upgrade.', 'created_at': datetime.datetime(2024, 5, 15, 12, 48, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2112657115, 'issue_id': 2296308278, 'author': 'paoliniluis', 'body': 'We’re releasing the fix in 49.11', 'created_at': datetime.datetime(2024, 5, 15, 14, 9, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-14 20:11:08 UTC): we just fixed this today, expect it for 49.11

vinceve on (2024-05-15 12:48:45 UTC): Upgraded from 1.49.3 to 1.49.9 and got the same issue (although the error is slightly different)

```
tabase
2024-05-15 12:34:30,408 ERROR metabase.core :: Metabase Initialization FAILED
metabase
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
metabase
Reason: clojure.lang.ExceptionInfo: Unexpected character ('Z' (code 90)): Expected space separating root-level values
metabase
at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
metabase
    at liquibase.command.CommandScope.execute(CommandScope.java:253)
metabase
    at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
metabase
    at liquibase.Scope.lambda$child$0(Scope.java:186)
```

When will this issue be resolved and released? It's important for us as we are in the middle of a release and that this blocks our upgrade.

paoliniluis on (2024-05-15 14:09:33 UTC): We’re releasing the fix in 49.11

"
2296145489,issue,closed,completed,"[FE] [Bug] Cannot use ""underlying records"" drill for metrics on a dashboard",,ranquild,2024-05-14 18:45:46+00:00,['ranquild'],2024-05-16 12:13:01+00:00,2024-05-16 12:13:01+00:00,https://github.com/metabase/metabase/issues/42656,[],[],
2295939601,issue,open,,Feature flags on visualizations/tabs to show/hide content to different users,"**Is your feature request related to a problem? Please describe.**
Customer: We are considering placing some of the new visualizations, or the entire tab, inside a dashboard behind a feature flag. This way, we can display them to certain users before fully rolling them out.

**Describe the solution you'd like**
TBD

**Describe alternatives you've considered**
Create multiple dashboards and conditionally display them based on the corresponding feature flag

**How important is this feature to you?**

**Additional context**
Slack: https://metaboat.slack.com/archives/C07166YL2UU/p1715639493912399",albertoperdomo,2024-05-14 16:47:48+00:00,[],2025-02-04 20:30:24+00:00,,https://github.com/metabase/metabase/issues/42652,"[('Type:New Feature', ''), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2465129843, 'issue_id': 2295939601, 'author': 'albertoperdomo', 'body': 'Possible options:\n* use groups to grant access to a subset of users to these dashboards\n* use the SDK to conditionally render specific dashboards based on a user attribute, or group membership - not possible if the collections that contains these dashboards are accessible to everyone and accessed via the collection browser component.', 'created_at': datetime.datetime(2024, 11, 8, 16, 7, 7, tzinfo=datetime.timezone.utc)}]","albertoperdomo (Issue Creator) on (2024-11-08 16:07:07 UTC): Possible options:
* use groups to grant access to a subset of users to these dashboards
* use the SDK to conditionally render specific dashboards based on a user attribute, or group membership - not possible if the collections that contains these dashboards are accessible to everyone and accessed via the collection browser component.

"
2295902366,issue,closed,completed,Remove settings encryption of `analytics-uuid` and `anon-tracking-enabled`,"We encrypt some settings settings and not others when encryption is enabled.

Ex:

```sql
select * 
from setting 
where key in ('show-homepage-data', 'persisted-model-refresh-cron-schedule')
```

<img width=""965"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/ece83ddf-005b-4d3a-8481-795e830ef5dc"">


We should not encrypt `analytics-uuid` and `anon-tracking-enabled`.

Marked as P2 but perhaps is a P1 and we want to do this with some speed.",dpsutton,2024-05-14 16:27:36+00:00,['johnswanson'],2024-08-15 12:15:59+00:00,2024-05-29 15:41:52+00:00,https://github.com/metabase/metabase/issues/42651,"[('Priority:P2', 'Average run of the mill bug'), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2112549210, 'issue_id': 2295902366, 'author': 'dpsutton', 'body': 'Question from slack:\r\n> When we get this in, will this make the analytics-uuid unencrypted as soon as someone migrates to the new version then? Or will it stay encrypted for migrating old instances and only entirely new ones will have it unencrypted?', 'created_at': datetime.datetime(2024, 5, 15, 13, 33, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120791905, 'issue_id': 2295902366, 'author': 'trinya', 'body': 'Can we up the priority for this one a bit? We need this to build the report of feature usage by customer, that would help us understand e.g. bumps in [contraction](https://www.notion.so/BizOps-Monthly-Update-15f55f856c82478f861b9985680992b3?d=f030e436fc6042edafe42a110f27a245&pvs=4#379c8351c1774720942091f48d1d32fb) and make decisions about pricing / plans.', 'created_at': datetime.datetime(2024, 5, 20, 16, 28, 31, tzinfo=datetime.timezone.utc)}]","dpsutton (Issue Creator) on (2024-05-15 13:33:43 UTC): Question from slack:

trinya on (2024-05-20 16:28:31 UTC): Can we up the priority for this one a bit? We need this to build the report of feature usage by customer, that would help us understand e.g. bumps in [contraction](https://www.notion.so/BizOps-Monthly-Update-15f55f856c82478f861b9985680992b3?d=f030e436fc6042edafe42a110f27a245&pvs=4#379c8351c1774720942091f48d1d32fb) and make decisions about pricing / plans.

"
2295779981,issue,closed,completed,Implement F&R for cards with snippets,,tsmacdonald,2024-05-14 15:24:33+00:00,['tsmacdonald'],2024-05-23 09:25:45+00:00,2024-05-23 08:47:19+00:00,https://github.com/metabase/metabase/issues/42648,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2295737753,issue,open,,Editing filter clears out all filters,"### Describe the bug


https://github.com/metabase/metabase/assets/965260/4afe0837-eb8f-4949-aea1-b28e04e3e7a0



### To Reproduce

1. Create a custom column
2. Filter by it
3. Edit the filter and click away

Video shows this

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.49.10
```


### Severity

Annoying

### Additional context

_No response_",k2xl,2024-05-14 15:04:59+00:00,[],2025-02-04 20:27:14+00:00,,https://github.com/metabase/metabase/issues/42647,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2110790362, 'issue_id': 2295737753, 'author': 'snoe', 'body': '@k2xl \r\n\r\nCan you share the expression definition of `deltaRegister`?\r\n\r\nIn the browser console, do you see any warnings that look like `""Removing bad clause....""` ? If you do, could you share them with us?', 'created_at': datetime.datetime(2024, 5, 14, 17, 45, 11, tzinfo=datetime.timezone.utc)}]","snoe on (2024-05-14 17:45:11 UTC): @k2xl 

Can you share the expression definition of `deltaRegister`?

In the browser console, do you see any warnings that look like `""Removing bad clause....""` ? If you do, could you share them with us?

"
2295590806,issue,closed,completed,Instance Analytics content appears in add series modal without EE token,"Hey! I can see instance analytics questions in “Add series” modal even without a EE token. Bug? The same should happen if my token becomes invalid etc

[Slack Message](https://metaboat.slack.com/archives/C064EB1UE5P/p1715608378800339?thread_ts=1715608378.800339&cid=C064EB1UE5P)",iethree,2024-05-14 14:13:26+00:00,['noahmoss'],2024-06-10 20:48:42+00:00,2024-06-07 19:52:47+00:00,https://github.com/metabase/metabase/issues/42645,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2295467460,issue,closed,not_planned,Dashboard empty after POST/PUT api request without logs to investigate,"### Describe the bug

Sometimes, when I upload a new dashboard through the API, the created dashboard appears without any cards on it. Both creation/update (POST and PUT) requests return a 200 status code, and there are no server-side logs.

It's entirely possible that I've made mistakes in the dashboard definitions. However, I would appreciate receiving some information to help identify what I'm doing wrong, **as there's clearly an issue**.

### To Reproduce

This my personnal test, with just one card to test it. Lot of useless data, it come from a GET : 
```
################################################################
Request:
URL: http://127.0.0.1:9844/api/dashboard
Headers:
{
    ""Accept"": ""application/json"",
    ""Content-Type"": ""application/json""
}
Json:
{
    ""description"": ""Tableau de bord aliment\u00e9 par Thom avec les chiffres cl\u00e9s standards."",
    ""archived"": false,
    ""collection_position"": null,
    ""dashcards"": [
        {
            ""size_x"": 4,
            ""dashboard_tab_id"": 4,
            ""series"": [],
            ""action_id"": null,
            ""collection_authority_level"": null,
            ""card"": {
                ""description"": null,
                ""archived"": false,
                ""collection_position"": null,
                ""table_id"": 28,
                ""result_metadata"": [
                    {
                        ""base_type"": ""type/Integer"",
                        ""name"": ""count"",
                        ""display_name"": ""Nombre de lignes"",
                        ""semantic_type"": ""type/Quantity"",
                        ""source"": ""aggregation"",
                        ""field_ref"": [
                            ""aggregation"",
                            0
                        ],
                        ""aggregation_index"": 0
                    }
                ],
                ""initially_published_at"": null,
                ""can_write"": true,
                ""database_id"": 2,
                ""enable_embedding"": false,
                ""collection_id"": 6,
                ""query_type"": ""query"",
                ""name"": ""Nombre de users"",
                ""type"": ""question"",
                ""query_average_duration"": 58,
                ""creator_id"": 1,
                ""moderation_reviews"": [],
                ""updated_at"": null,
                ""made_public_by_id"": null,
                ""embedding_params"": null,
                ""cache_ttl"": null,
                ""dataset_query"": {
                    ""database"": 2,
                    ""type"": ""query"",
                    ""query"": {
                        ""aggregation"": [
                            [
                                ""count""
                            ]
                        ],
                        ""source-table"": ""card__6""
                    }
                },
                ""id"": 146,
                ""parameter_mappings"": [],
                ""display"": ""scalar"",
                ""entity_id"": ""_h0l-OD8cOr5_bKUm7_8S"",
                ""collection_preview"": true,
                ""visualization_settings"": {
                    ""column_settings"": {
                        ""[\""name\"",\""count\""]"": {
                            ""suffix"": "" \ud83d\udc69\u200d\ud83d\udcbb""
                        }
                    }
                },
                ""metabase_version"": ""v0.48.8 (a900c85)"",
                ""parameters"": [],
                ""dataset"": false,
                ""created_at"": null,
                ""public_uuid"": null
            },
            ""updated_at"": null,
            ""col"": 0,
            ""id"": 80,
            ""parameter_mappings"": [
                {
                    ""parameter_id"": ""a5b8515e"",
                    ""card_id"": 14,
                    ""target"": [
                        ""dimension"",
                        [
                            ""field"",
                            ""Pscge"",
                            {
                                ""base-type"": ""type/Text""
                            }
                        ]
                    ]
                }
            ],
            ""card_id"": 14,
            ""entity_id"": ""nAL1qLpmneE9M5EgGj_W4"",
            ""visualization_settings"": {
                ""card.title"": ""users"",
                ""column_settings"": {
                    ""[\""name\"",\""count\""]"": {
                        ""suffix"": "" \ud83d\udc69\u200d\ud83d\udcbb""
                    }
                }
            },
            ""size_y"": 2,
            ""dashboard_id"": 35,
            ""created_at"": null,
            ""row"": 6
        }
    ],
    ""param_values"": null,
    ""initially_published_at"": null,
    ""can_write"": true,
    ""tabs"": [
        {
            ""id"": 1,
            ""dashboard_id"": 35,
            ""name"": ""G\u00e9n\u00e9ral"",
            ""position"": 0,
            ""entity_id"": ""y3K8jvKd2z81My9C8zVQR"",
            ""created_at"": null,
            ""updated_at"": null
        },
        {
            ""id"": 2,
            ""dashboard_id"": 35,
            ""name"": ""Par tags et modalit\u00e9s"",
            ""position"": 1,
            ""entity_id"": ""ErSmF6oKFYYOPlGgbU_Kk"",
            ""created_at"": null,
            ""updated_at"": null
        },
        {
            ""id"": 4,
            ""dashboard_id"": 35,
            ""name"": ""D\u00e9partement"",
            ""position"": 2,
            ""entity_id"": ""RvbuWJ55MWIBoKrNlXJtD"",
            ""created_at"": null,
            ""updated_at"": null
        },
        {
            ""id"": 6,
            ""dashboard_id"": 35,
            ""name"": ""Motifs et preco"",
            ""position"": 3,
            ""entity_id"": ""3OEnBkhEXjFb31gu13jX_"",
            ""created_at"": null,
            ""updated_at"": null
        },
        {
            ""id"": 3,
            ""dashboard_id"": 35,
            ""name"": ""Gestion de PYCJ"",
            ""position"": 4,
            ""entity_id"": ""ChngoQsbniYv2g4bJ9GbB"",
            ""created_at"": null,
            ""updated_at"": null
        },
        {
            ""id"": 5,
            ""dashboard_id"": 35,
            ""name"": ""Incoh\u00e9rences"",
            ""position"": 5,
            ""entity_id"": ""ca6c6sINPlZJM_ZM5S_rN"",
            ""created_at"": null,
            ""updated_at"": null
        }
    ],
    ""enable_embedding"": false,
    ""collection_id"": 2,
    ""show_in_getting_started"": false,
    ""name"": ""PYCJ - Statistiques"",
    ""width"": ""full"",
    ""caveats"": null,
    ""collection_authority_level"": null,
    ""creator_id"": 1,
    ""updated_at"": null,
    ""made_public_by_id"": null,
    ""embedding_params"": null,
    ""cache_ttl"": null,
    ""id"": null,
    ""position"": null,
    ""entity_id"": ""Id1t7GVfyha-bth0Hpi_H"",
    ""param_fields"": {
        ""471"": {
            ""id"": 471,
            ""table_id"": 9,
            ""display_name"": ""Date Schoolyear"",
            ""base_type"": ""type/Text"",
            ""semantic_type"": ""type/Category"",
            ""has_field_values"": ""list"",
            ""name_field"": null,
            ""dimensions"": []
        },
        ""499"": {
            ""id"": 499,
            ""table_id"": 14,
            ""display_name"": ""Name"",
            ""base_type"": ""type/Text"",
            ""semantic_type"": ""type/Name"",
            ""has_field_values"": ""list"",
            ""name_field"": null,
            ""dimensions"": []
        },
        ""582"": {
            ""id"": 582,
            ""table_id"": 27,
            ""display_name"": ""Category"",
            ""base_type"": ""type/Text"",
            ""semantic_type"": ""type/Category"",
            ""has_field_values"": ""list"",
            ""name_field"": null,
            ""dimensions"": []
        },
        ""583"": {
            ""id"": 583,
            ""table_id"": 27,
            ""display_name"": ""Cycle"",
            ""base_type"": ""type/Text"",
            ""semantic_type"": ""type/Category"",
            ""has_field_values"": ""list"",
            ""name_field"": null,
            ""dimensions"": []
        },
        ""584"": {
            ""id"": 584,
            ""table_id"": 27,
            ""display_name"": ""Degre"",
            ""base_type"": ""type/Text"",
            ""semantic_type"": ""type/Category"",
            ""has_field_values"": ""list"",
            ""name_field"": null,
            ""dimensions"": []
        }
    },
    ""last-edit-info"": {
        ""id"": 1,
        ""email"": ""Thom.aaaa@gmail.com"",
        ""first_name"": ""Thom"",
        ""last_name"": ""aaaa"",
        ""timestamp"": ""2024-05-08T13:43:38.493222Z""
    },
    ""collection"": {
        ""authority_level"": null,
        ""description"": ""Collections de base cr\u00e9\u00e9es par Thom pour vous aider \u00e0 mieux utiliser vos statistiques."",
        ""archived"": false,
        ""slug"": ""collections_de_Thom_%3F%3F"",
        ""name"": ""Collections de Thom \ud83d\udd12"",
        ""personal_owner_id"": null,
        ""type"": null,
        ""id"": 70,
        ""entity_id"": ""Zv5yVkuSEXkeAANiUUc7z"",
        ""location"": ""/"",
        ""namespace"": null,
        ""is_personal"": false,
        ""created_at"": null
    },
    ""parameters"": [
        {
            ""name"": ""Ann\u00e9e Scolaire"",
            ""slug"": ""ann%C3%A9e_scolaire"",
            ""id"": ""aa86138c"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 12,
                ""value_field"": [
                    ""field"",
                    73,
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""Pscge"",
            ""slug"": ""Pscge"",
            ""id"": ""a5b8515e"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 6,
                ""value_field"": [
                    ""field"",
                    ""Pscge"",
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""\u00c9tablissement"",
            ""slug"": ""%C3%A9tablissement"",
            ""id"": ""22ad2af9"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 7,
                ""value_field"": [
                    ""field"",
                    ""\u00c9tablissement"",
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""Parcours"",
            ""slug"": ""parcours"",
            ""id"": ""a82f67fd"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Degr\u00e9"",
            ""slug"": ""degr%C3%A9"",
            ""id"": ""83c85cfc"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Cycle"",
            ""slug"": ""cycle"",
            ""id"": ""d8909a3a"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Categorie"",
            ""slug"": ""categorie"",
            ""id"": ""45b4af03"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Tag"",
            ""slug"": ""tag"",
            ""id"": ""7f968232"",
            ""type"": ""string/contains"",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 3,
                ""value_field"": [
                    ""field"",
                    378,
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        }
    ],
    ""auto_apply_filters"": true,
    ""created_at"": null,
    ""public_uuid"": null,
    ""points_of_interest"": null,
    ""old_id"": 35
}

Response:
Status Code: 200
Response JSON:
{
    ""description"": ""Tableau de bord aliment\u00e9 par Thom avec les chiffres cl\u00e9s standards."",
    ""archived"": false,
    ""collection_position"": null,
    ""enable_embedding"": false,
    ""collection_id"": 2,
    ""show_in_getting_started"": false,
    ""name"": ""PYCJ - Statistiques"",
    ""caveats"": null,
    ""creator_id"": 1,
    ""updated_at"": ""2024-05-14T13:20:52.409778"",
    ""made_public_by_id"": null,
    ""embedding_params"": null,
    ""cache_ttl"": null,
    ""id"": 2,
    ""position"": null,
    ""entity_id"": ""7hMQeMe13p7I8-TNkYQxL"",
    ""last-edit-info"": {
        ""timestamp"": ""2024-05-14T13:20:52.422Z"",
        ""id"": 1,
        ""first_name"": ""Thom"",
        ""last_name"": ""aaaa"",
        ""email"": ""Thom.aaaa@gmail.com""
    },
    ""parameters"": [
        {
            ""name"": ""Ann\u00e9e Scolaire"",
            ""slug"": ""ann%C3%A9e_scolaire"",
            ""id"": ""aa86138c"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 12,
                ""value_field"": [
                    ""field"",
                    73,
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""Pscge"",
            ""slug"": ""Pscge"",
            ""id"": ""a5b8515e"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 6,
                ""value_field"": [
                    ""field"",
                    ""Pscge"",
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""\u00c9tablissement"",
            ""slug"": ""%C3%A9tablissement"",
            ""id"": ""22ad2af9"",
            ""type"": ""string/="",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 7,
                ""value_field"": [
                    ""field"",
                    ""\u00c9tablissement"",
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        },
        {
            ""name"": ""Parcours"",
            ""slug"": ""parcours"",
            ""id"": ""a82f67fd"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Degr\u00e9"",
            ""slug"": ""degr%C3%A9"",
            ""id"": ""83c85cfc"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Cycle"",
            ""slug"": ""cycle"",
            ""id"": ""d8909a3a"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Categorie"",
            ""slug"": ""categorie"",
            ""id"": ""45b4af03"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
        },
        {
            ""name"": ""Tag"",
            ""slug"": ""tag"",
            ""id"": ""7f968232"",
            ""type"": ""string/contains"",
            ""sectionId"": ""string"",
            ""values_query_type"": ""list"",
            ""values_source_type"": ""card"",
            ""values_source_config"": {
                ""card_id"": 3,
                ""value_field"": [
                    ""field"",
                    378,
                    {
                        ""base-type"": ""type/Text""
                    }
                ]
            }
        }
    ],
    ""created_at"": ""2024-05-14T13:20:52.409778"",
    ""public_uuid"": null,
    ""points_of_interest"": null
}
################################################################
```

### Expected behavior

I would like the software to provide feedback indicating what is causing the issue, to assist me in troubleshooting and correcting it.

### Logs

DEBUG middleware.log :: POST /api/dashboard 200 24.3 ms (24 appels de DB) Connexions App DB : 2/13 Threads Jetty : 3/50 (4 inactif, 0 en file d'attente) (69 total de threads actifs) Requêtes en cours : 0 (0 en file d'attente)

### Information about your Metabase installation

```JSON
Metabase v0.48.8 on Docker metabase/metabase
Python requests
```


### Severity

annoying

### Additional context

_No response_",tomy137,2024-05-14 13:27:35+00:00,[],2024-05-14 14:40:50+00:00,2024-05-14 14:18:52+00:00,https://github.com/metabase/metabase/issues/42642,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2110371354, 'issue_id': 2295467460, 'author': 'tomy137', 'body': ""Sorry. My bad. Wrong version between GET and POST. \r\n\r\nSeems that I can't remove my topic. Don't hesitate to do so."", 'created_at': datetime.datetime(2024, 5, 14, 14, 19, 27, tzinfo=datetime.timezone.utc)}]","tomy137 (Issue Creator) on (2024-05-14 14:19:27 UTC): Sorry. My bad. Wrong version between GET and POST. 

Seems that I can't remove my topic. Don't hesitate to do so.

"
2295359954,issue,open,,Add an indication of deprecation to product and to docs for deprecated features,"**Is your feature request related to a problem? Please describe.**
Customers are sometimes surprised by our deprecations, and new customers may have no idea that we are deprecating a feature and start building based on it. Some examples:
- Data Reference - we tried to deprecate but got a lot of pushback from users, so we kept it
- Segments & Metrics - planned for deprecation more than a year, does not work very well/not fully implemented, no indication in product or docs of this, frustrating experience for customers
- Pulse reports in Collections - had a customer surprised by this deprecation

(Let me know if you need more examples or links to relevant tickets.)

**Describe the solution you'd like**
- Add a `deprecated` label to any create/modify/configure screens in product with hover on label modal showing:
  - Link to a Github issue mentioning the deprecation
  - Link to the help page (same as clicking the Gear then Help)
- Add a `deprecated` label to top of relevant section in docs with
  - Link to a Github issue mentioning the deprecation
  - Suggestion to ask forums if OSS and contact support if paid customer with any questions/concerns.
  - If applicable, link to Github issue for replacement/improvement functionality (e.g. for Segments & Metrics, link to the Metrics v2 epic)

**Describe alternatives you've considered**
- no change, customers frustrated
- deprecated label with no CTA (minimum requirement, but dead end, and we lose the feedback)

**How important is this feature to you?**
- Improves customer experience by better informing them of our roadmap that might affect their usage of some features

**Additional context**
- https://github.com/metabase/metabase/issues/37335
- https://github.com/metabase/metabase/issues/33696 (unsure if planned)
- https://github.com/metabase/metabase/issues/31410
- https://github.com/metabase/metabase/issues/30574",likeshumidity,2024-05-14 12:49:44+00:00,[],2025-02-04 20:31:09+00:00,,https://github.com/metabase/metabase/issues/42640,"[('Type:Tech Debt', 'or Refactoring'), ('Type:Documentation', ''), ('Type:New Feature', '')]",[],
2295116112,issue,open,,Migrate CacheConfigApi to RTK,,rafpaf,2024-05-14 10:58:14+00:00,[],2024-05-14 10:58:14+00:00,,https://github.com/metabase/metabase/issues/42635,[],[],
2295008309,issue,closed,completed,Metrics (v1) revisions API is broken,"### Describe the bug

When trying to view revisions for a metric, the spinner keeps loading forever. The console warns that the endpoint doesn't exist.

![image](https://github.com/metabase/metabase/assets/31325167/aeb8a2ec-0ba4-4630-ad7e-5cbe9a967c69)


### To Reproduce

1. Go to `/admin/datamodel/metric/1/revisions`
2. See the loading spinner
3. Check the console and notice 404 for the `/api/metric/1/revisions`


### Expected behavior

One should be able to load metric revisions, just like it's currently possible for segments.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, f52e02f, H2, Sample Database
```


### Severity

P1

### Additional context

This became broken when we renamed the legacy metrics in https://github.com/metabase/metabase/pull/39232.

The code is calling `fetchRevisions` action, which invokes `RevisionsApi` under the hood.
We missed this because `/revisions` wasn't a part of Metrics entity or the metrics api.",nemanjaglumac,2024-05-14 10:03:06+00:00,['nemanjaglumac'],2024-05-16 08:45:17+00:00,2024-05-14 16:27:22+00:00,https://github.com/metabase/metabase/issues/42633,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metrics & Segments', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature')]",[],
2295000636,issue,closed,completed,Add recents to Browse models table,,rafpaf,2024-05-14 09:59:20+00:00,[],2024-10-08 17:08:34+00:00,2024-06-07 20:28:11+00:00,https://github.com/metabase/metabase/issues/42632,[],[],
2294946218,issue,closed,completed,Embedding app origin setting should allow multiple origins for the `Access-Control-Allow-Origin` header,"**Context**


We're started using `embedding-app-origin` to make the embedding sdk work on other domains via `Access-Control-Allow-Origin`. This has a small issue as `Access-Control-Allow-Origin` should only return one origin (or ""*"") while we tell the users to give us a list of origins separated by a space:
![image](https://github.com/metabase/metabase/assets/1914270/b767fa6a-5798-4c22-a4da-b638bc8d9f79)

A solution could be to change the following line https://github.com/metabase/metabase/blob/ef15d0e32b0fe9d72cfd57ed6163f1c00cff7af0/src/metabase/server/middleware/security.clj#L131
to return the referrer if it's present in the list of allowed origins. We'll need to normalize the origins before doing the check.

We use the same setting for multiple headers, we should also double check if the formats are compatible.",npretto,2024-05-14 09:37:58+00:00,['npretto'],2024-05-29 05:59:35+00:00,2024-05-29 05:59:34+00:00,https://github.com/metabase/metabase/issues/42631,"[('backport', 'Automatically create PR on current release branch on merge'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', '')]","[{'comment_id': 2129929215, 'issue_id': 2294946218, 'author': 'npretto', 'body': 'For context, the PR closing this issue was reverted with this https://github.com/metabase/metabase/pull/43125 because it broke staging', 'created_at': datetime.datetime(2024, 5, 24, 16, 18, 45, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-05-24 16:18:45 UTC): For context, the PR closing this issue was reverted with this https://github.com/metabase/metabase/pull/43125 because it broke staging

"
2294771069,issue,closed,completed,[Epic] Add download PDF to static embedded dashboards and make knobs for downloads consistent between public links and static embeds,"**Links**
- product doc: https://www.notion.so/metabase/Add-download-PDF-to-static-embedded-dashboards-a155ebfce35346178e657a440723b2a1

**Implementation Plan**



```[tasklist]
### Milestone 1 - refactors and preparation tasks
- [ ] https://github.com/metabase/metabase/issues/43289
- [x] ~move all embed params to redux~ (decided not to do this)
- [ ] https://github.com/metabase/metabase/pull/43495
```

```[tasklist]
### Milestone 2 - functionality
- [ ] https://github.com/metabase/metabase/issues/43605
- [ ] https://github.com/metabase/metabase/issues/44067
- [ ] https://github.com/metabase/metabase/issues/44285
- [ ] https://github.com/metabase/metabase/pull/45178
- [ ] https://github.com/metabase/metabase/pull/45240
```

```[tasklist]
### Milestone 3
- [ ] https://github.com/metabase/metabase/issues/45932
- [ ] https://github.com/metabase/metabase/issues/46007
- [ ] https://github.com/metabase/metabase/pull/46132
- [ ] https://github.com/metabase/metabase/issues/46422
```



This would solve https://github.com/metabase/metabase/issues/34384



",npretto,2024-05-14 08:22:23+00:00,['npretto'],2024-08-02 15:01:36+00:00,2024-08-02 15:01:35+00:00,https://github.com/metabase/metabase/issues/42628,"[('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Epic', 'Feature Implementation or Project')]",[],
2294755608,issue,open,,Percentage formatting is ignored when adding a series from a saved question,"### Describe the bug

 When displaying values for multiple series, then formatting style (e.g. ""percentage"") of the second series is not applied.

### To Reproduce

1. Create two line charts from separate data sources, one with a ""Sum"" summary, the other with a ""Avg"" summary
2. On the ""Avg"" line chart, set the visualization settings for the summary to Style = Percentage
3. Add the first chart to a dashboard
4. Edit the dashboard in order to add the second chart as a series to the first chart


### Expected behavior

The Y-axis value should carry on the setting of the 2nd line chart (as fixed in #13095)

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:125.0) Gecko/20100101 Firefox/125.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-153-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10 (Debian 14.10-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-11"",
      ""tag"": ""v0.48.3"",
      ""hash"": ""80d8323""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

Mild

### Additional context

![330336801-436fe2ca-18a3-46c9-aa6a-d59a4b707cab](https://github.com/metabase/metabase/assets/1238320/81cfa938-3232-4b48-b115-244db36d6d1a)
![330337227-bb409b9f-2ef9-4aaa-b7ff-6a2a3e10bc61](https://github.com/metabase/metabase/assets/1238320/c675aaff-bb88-4ee4-bd76-dccaa7b19e1e)",hellpe,2024-05-14 08:17:51+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/42626,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Reporting/Dashboards/Combined charts', 'Combining charts'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2553426048, 'issue_id': 2294755608, 'author': 'Tony-metabase', 'body': 'To add with this, the issue seems to be specific when axis are getting split:\n\n<img width=""1422"" alt=""Image"" src=""https://github.com/user-attachments/assets/b4cb7de7-208b-45bb-b7dc-367ea9f1a24e"" />\n\nDue to [this](https://github.com/metabase/metabase/issues/17943) the formatting is applied based on the first chart but when a % number is used as the first chart and there is a split axis the other chart doesn\'t carry the same format ... Which is different form the right section where the question without % was started first', 'created_at': datetime.datetime(2024, 12, 19, 11, 2, 3, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-12-19 11:02:03 UTC): To add with this, the issue seems to be specific when axis are getting split:

<img width=""1422"" alt=""Image"" src=""https://github.com/user-attachments/assets/b4cb7de7-208b-45bb-b7dc-367ea9f1a24e"" />

Due to [this](https://github.com/metabase/metabase/issues/17943) the formatting is applied based on the first chart but when a % number is used as the first chart and there is a split axis the other chart doesn't carry the same format ... Which is different form the right section where the question without % was started first

"
2294650369,issue,closed,completed,"Anchor the suggestion popover, always under and never above the editor","Anchor the suggestion popover to always be under the suggestion editor.

<img width=""564"" alt=""Screenshot 2024-05-14 at 09 32 37"" src=""https://github.com/metabase/metabase/assets/1250185/4c9d995a-b799-4e28-bb4f-7349bf2a9223"">
",romeovs,2024-05-14 07:30:25+00:00,['romeovs'],2024-05-14 08:35:25+00:00,2024-05-14 08:35:25+00:00,https://github.com/metabase/metabase/issues/42623,[],[],
2294571638,issue,open,,An option for subscription emails that provides a link for users to log in to the Metabase portal,"**Is your feature request related to a problem? Please describe.**
An option for a subscription email to be a link for a user to login to Metabase portal to view data rather than having the data displayed in the email.


**Describe the solution you'd like**
When creating email subscriptions for certain data dashboards, instead of just sending what's in the dashboard, they would like the option of sending an email that new data is available. They would also like for the ability within the subscription area to have a section to compose the email or have a template.

> Dear xxx, 
> 
> Your Data portal has new data, click here to access and download it today.
> 
> Best wishes

The end users could then click on the link to access their dashboard to access the data. 
That way data isn't sent within the email which isn't secure enough. 





",FilmonK,2024-05-14 06:46:38+00:00,[],2025-02-04 20:30:51+00:00,,https://github.com/metabase/metabase/issues/42622,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2153538669, 'issue_id': 2294571638, 'author': 'paoliniluis', 'body': ""@FilmonK why don't they just fork the project and adapt the email template? https://github.com/metabase/metabase/blob/master/src/metabase/email/pulse.mustache"", 'created_at': datetime.datetime(2024, 6, 6, 23, 9, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2159392310, 'issue_id': 2294571638, 'author': 'FilmonK', 'body': ""@paoliniluis \r\nThat was explained to them, however, they'd like an option within Metabase interface.\r\nAs well having this capability for cloud customers."", 'created_at': datetime.datetime(2024, 6, 10, 22, 9, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567907104, 'issue_id': 2294571638, 'author': 'brunobergher', 'body': 'Likely to be handled by #51710', 'created_at': datetime.datetime(2025, 1, 2, 15, 1, 6, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-06 23:09:25 UTC): @FilmonK why don't they just fork the project and adapt the email template? https://github.com/metabase/metabase/blob/master/src/metabase/email/pulse.mustache

FilmonK (Issue Creator) on (2024-06-10 22:09:51 UTC): @paoliniluis 
That was explained to them, however, they'd like an option within Metabase interface.
As well having this capability for cloud customers.

brunobergher on (2025-01-02 15:01:06 UTC): Likely to be handled by #51710

"
2294302592,issue,closed,not_planned,Model Permession,"### Describe the bug

Users can Edit a Model Query using Native Query editor Without Having PermessionPermission

### To Reproduce

a. Create a Group with preview-only access and add a user to this group only.
b. Disable Native Query Editor for this Group.
c. Create a user with model creation access.
d. Create a model with native query enabled and add it to the analytics collection.
e. Log in as the user from the newly created group.
f. Navigate to the newly created model.
g. Attempt to edit the model query.

### Expected behavior

The user from the group with preview-only access, and with the Native Query Editor restricted, should not be able to edit the model query. The system should enforce the read-only access level set for the group, preventing any modifications to the model's query.


### Logs

the log will be no use case for this.

### Information about your Metabase installation

```JSON
Version 124.0.6367.201 (Official Build) (64-bit)
Windows 11
MySql 
0.49.8
Jar File on Ubuntu
MySql
```


### Severity

Altering Security and access rights

### Additional context

_No response_",MQinna,2024-05-14 03:40:28+00:00,[],2024-05-14 15:50:47+00:00,2024-05-14 15:50:47+00:00,https://github.com/metabase/metabase/issues/42620,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2110515325, 'issue_id': 2294302592, 'author': 'paoliniluis', 'body': ""Hi, please check the repro steps, although the user can SEE the SQL, it doesn't mean that they can EDIT it.\r\n\r\nI wasn´t able to reproduce"", 'created_at': datetime.datetime(2024, 5, 14, 15, 20, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2110529763, 'issue_id': 2294302592, 'author': 'Tony-metabase', 'body': 'The moment you press on `edit` you are not able to write anything in the editor and not even save\r\n\r\n<img width=""1503"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/3f8de118-6d81-4a12-92ab-588470e31644"">', 'created_at': datetime.datetime(2024, 5, 14, 15, 27, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-14 15:20:12 UTC): Hi, please check the repro steps, although the user can SEE the SQL, it doesn't mean that they can EDIT it.

I wasn´t able to reproduce

Tony-metabase on (2024-05-14 15:27:00 UTC): The moment you press on `edit` you are not able to write anything in the editor and not even save

<img width=""1503"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/3f8de118-6d81-4a12-92ab-588470e31644"">

"
2294279164,issue,closed,completed,[FE] [Bug] cannot turn off metric visualization in collections,,ranquild,2024-05-14 03:19:29+00:00,['ranquild'],2024-05-16 12:13:19+00:00,2024-05-16 12:13:19+00:00,https://github.com/metabase/metabase/issues/42618,[],[],
2293906482,issue,closed,completed,Metabase can't decrypt the data when adding an encryption key after a failed migration ,"### Describe the bug

If you start a migration without an encryption key and you add it afterwards, it seems that Metabase isn't using it

### To Reproduce

1) Start v48.9 with an encryption key, initialize it
2) Remove encryption key and start 49.10, it won't work, as it doesn't have the encryption key
3) Now add the key and start 49.10 again, it won't work

### Expected behavior

It should work

### Logs

```

2024-05-13 21:46:53,652 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat encountered an exception.

UPDATE SUMMARY
Run:                          2
Previously run:             268
Filtered out:                17
-------------------------------
Total change sets:          287


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               17

2024-05-13 21:46:53,682 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unrecognized token 'KglemLU5XpyL': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 13] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
	at metabase.db.setup$migrate_BANG_$fn__51146.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___48822.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
	at clojure.lang.RestFn.invoke(RestFn.java:445)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
	at metabase.db.setup$setup_db_BANG_$fn__51174$fn__51175.invoke(setup.clj:165)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__51174.invoke(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__51194.invoke(db.clj:69)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
	at metabase.core$init_BANG_.invoke(core.clj:154)
	at metabase.core$start_normally.invokeStatic(core.clj:171)
	at metabase.core$start_normally.invoke(core.clj:165)
	at metabase.core$entrypoint.invokeStatic(core.clj:204)
	at metabase.core$entrypoint.doInvoke(core.clj:198)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unrecognized token 'KglemLU5XpyL': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 13] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 49 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unrecognized token 'KglemLU5XpyL': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 13] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 57 more
Caused by: clojure.lang.ExceptionInfo: Unrecognized token 'KglemLU5XpyL': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 13] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:762)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._reportInvalidToken(ReaderBasedJsonParser.java:3042)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._handleOddValue(ReaderBasedJsonParser.java:2085)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:812)
	at cheshire.parse$parse.invokeStatic(parse.clj:90)
	at cheshire.parse$parse.invoke(parse.clj:88)
	at cheshire.core$parse_string.invokeStatic(core.clj:208)
	at cheshire.core$parse_string.invoke(core.clj:194)
	at cheshire.core$parse_string.invokeStatic(core.clj:205)
	at cheshire.core$parse_string.invoke(core.clj:194)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606$fn__48607.invoke(custom_migrations.clj:1079)
	at clojure.core$filter$fn__5962.invoke(core.clj:2834)
	at clojure.lang.LazySeq.sval(LazySeq.java:42)
	at clojure.lang.LazySeq.seq(LazySeq.java:51)
	at clojure.lang.RT.seq(RT.java:535)
	at clojure.core$seq__5467.invokeStatic(core.clj:139)
	at clojure.core$seq__5467.invoke(core.clj:139)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606.invoke(custom_migrations.clj:1079)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at metabase.db.connection$do_transaction$thunk__32323.invoke(connection.clj:150)
	at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
	at metabase.db.connection$do_transaction.invoke(connection.clj:146)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18237.invoke(threaded.clj:71)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2588)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605.invoke(custom_migrations.clj:1073)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff.execute(custom_migrations.clj:1073)
	at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 72 more
Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'KglemLU5XpyL': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 13]
	... 234 more
2024-05-13 21:46:53,901 INFO metabase.core :: Metabase Shutting Down ...
```

### Information about your Metabase installation

```JSON
v48 migrating to v49
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-05-13 21:50:07+00:00,['qnkhuat'],2024-05-14 14:11:56+00:00,2024-05-14 14:09:16+00:00,https://github.com/metabase/metabase/issues/42612,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2109143151, 'issue_id': 2293906482, 'author': 'kbrownlees', 'body': 'We are hitting a very similar error trying to upgrade from v0.47.7 -> v0.49.9.\r\n\r\nWe are not changing anything with our encryption key, but under 47.7 we are getting this error in the logs:\r\n\r\n```\r\nCannot decrypt encrypted String. Have you changed or forgot to set MB_ENCRYPTION_SECRET_KEY?\r\n```\r\n\r\nEverything is working in 47.7 however as far as we can tell.\r\n\r\nWhen attempting to upgrade to 49.9:\r\n\r\n```\r\nMay 14, 2024 at 14:05 (UTC+12:00)\t2024-05-14 12:05:15,281 ERROR metabase.core :: Metabase Initialization FAILED\tmetabase-test\r\nMay 14, 2024 at 14:05 (UTC+12:00)\tliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:\tmetabase-test\r\nMay 14, 2024 at 14:05 (UTC+12:00)\tReason: clojure.lang.ExceptionInfo: Unrecognized token \'<omitted>\': was expecting (JSON String, Number, Array, Object or token \'null\', \'true\' or \'false\')\tmetabase-test\r\nMay 14, 2024 at 14:05 (UTC+12:00)\tat [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 43] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n```', 'created_at': datetime.datetime(2024, 5, 14, 2, 10, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2110350424, 'issue_id': 2293906482, 'author': 'qnkhuat', 'body': '@kbrownlees, your issue might not be related to this. This issue is from a change we made in 49.10.\r\n\r\nCould you open a new issue for it?', 'created_at': datetime.datetime(2024, 5, 14, 14, 11, 55, tzinfo=datetime.timezone.utc)}]","kbrownlees on (2024-05-14 02:10:21 UTC): We are hitting a very similar error trying to upgrade from v0.47.7 -> v0.49.9.

We are not changing anything with our encryption key, but under 47.7 we are getting this error in the logs:

```
Cannot decrypt encrypted String. Have you changed or forgot to set MB_ENCRYPTION_SECRET_KEY?
```

Everything is working in 47.7 however as far as we can tell.

When attempting to upgrade to 49.9:

```
May 14, 2024 at 14:05 (UTC+12:00)	2024-05-14 12:05:15,281 ERROR metabase.core :: Metabase Initialization FAILED	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	Reason: clojure.lang.ExceptionInfo: Unrecognized token '<omitted>': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')	metabase-test
May 14, 2024 at 14:05 (UTC+12:00)	at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 43] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
```

qnkhuat (Assginee) on (2024-05-14 14:11:55 UTC): @kbrownlees, your issue might not be related to this. This issue is from a change we made in 49.10.

Could you open a new issue for it?

"
2293884429,issue,closed,completed,Error in migration on upgrade between 48-49 due to encryption key,"### Describe the bug

A migration is complicating the upgrade to 49, with a weird error

### To Reproduce

1) Start a v48.9 with an MB_ENCRYPTION_SECRET_KEY and initialize it
2) the move to 49.10

### Expected behavior

It should migrate

### Logs

```
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unexpected character ('H' (code 72)): Expected space separating root-level values
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
	at metabase.db.setup$migrate_BANG_$fn__51146.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___48822.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
	at clojure.lang.RestFn.invoke(RestFn.java:445)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
	at metabase.db.setup$setup_db_BANG_$fn__51174$fn__51175.invoke(setup.clj:165)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__51174.invoke(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__51194.invoke(db.clj:69)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
	at metabase.core$init_BANG_.invoke(core.clj:154)
	at metabase.core$start_normally.invokeStatic(core.clj:171)
	at metabase.core$start_normally.invoke(core.clj:165)
	at metabase.core$entrypoint.invokeStatic(core.clj:204)
	at metabase.core$entrypoint.doInvoke(core.clj:198)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unexpected character ('H' (code 72)): Expected space separating root-level values
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 49 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: Unexpected character ('H' (code 72)): Expected space separating root-level values
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 57 more
Caused by: clojure.lang.ExceptionInfo: Unexpected character ('H' (code 72)): Expected space separating root-level values
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3] {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:2481)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:752)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:676)
	at com.fasterxml.jackson.core.base.ParserMinimalBase._reportMissingRootWS(ParserMinimalBase.java:724)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._verifyRootSpace(ReaderBasedJsonParser.java:1834)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._parseUnsignedNumber(ReaderBasedJsonParser.java:1429)
	at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:809)
	at cheshire.parse$parse.invokeStatic(parse.clj:90)
	at cheshire.parse$parse.invoke(parse.clj:88)
	at cheshire.core$parse_string.invokeStatic(core.clj:208)
	at cheshire.core$parse_string.invoke(core.clj:194)
	at cheshire.core$parse_string.invokeStatic(core.clj:205)
	at cheshire.core$parse_string.invoke(core.clj:194)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606$fn__48607.invoke(custom_migrations.clj:1079)
	at clojure.core$filter$fn__5962.invoke(core.clj:2834)
	at clojure.lang.LazySeq.sval(LazySeq.java:42)
	at clojure.lang.LazySeq.seq(LazySeq.java:51)
	at clojure.lang.RT.seq(RT.java:535)
	at clojure.core$seq__5467.invokeStatic(core.clj:139)
	at clojure.core$seq__5467.invoke(core.clj:139)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605$with_transaction_STAR___48606.invoke(custom_migrations.clj:1079)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at metabase.db.connection$do_transaction$thunk__32323.invoke(connection.clj:150)
	at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
	at metabase.db.connection$do_transaction.invoke(connection.clj:146)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18237.invoke(threaded.clj:71)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2588)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff$with_connection_STAR___48605.invoke(custom_migrations.clj:1073)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at toucan2.connection$bind_current_connectable_fn$fn__21143.invoke(connection.clj:104)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18233$fn__18234$fn__18235.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203$fn__18207.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18203.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18213.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at metabase.db.custom_migrations.DeleteScanFieldValuesTriggerForDBThatTurnItOff.execute(custom_migrations.clj:1073)
	at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 72 more
Caused by: com.fasterxml.jackson.core.JsonParseException: Unexpected character ('H' (code 72)): Expected space separating root-level values
 at [Source: REDACTED (`StreamReadFeature.INCLUDE_SOURCE_IN_LOCATION` disabled); line: 1, column: 3]
	... 236 more

```

### Information about your Metabase installation

```JSON
v49.10
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-05-13 21:33:53+00:00,['qnkhuat'],2024-05-14 14:10:17+00:00,2024-05-14 14:10:17+00:00,https://github.com/metabase/metabase/issues/42611,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2110346667, 'issue_id': 2293884429, 'author': 'qnkhuat', 'body': 'Fixed in https://github.com/metabase/metabase/pull/42617', 'created_at': datetime.datetime(2024, 5, 14, 14, 10, 17, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-05-14 14:10:17 UTC): Fixed in https://github.com/metabase/metabase/pull/42617

"
2293876596,issue,closed,not_planned,"[FE] [Bug] Cannot use ""underlying records"" drill from a dashboard for metrics",QB breaks,ranquild,2024-05-13 21:27:52+00:00,[],2024-05-14 18:46:50+00:00,2024-05-14 18:46:50+00:00,https://github.com/metabase/metabase/issues/42610,[],[],
2293859813,issue,closed,completed,"Cannot use ""underlying records"" drill from a dashboard for metrics",,ranquild,2024-05-13 21:15:25+00:00,[],2025-01-06 14:53:55+00:00,2025-01-06 14:53:55+00:00,https://github.com/metabase/metabase/issues/42609,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Metrics & Segments', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', ''), ('Semantic Model', '')]","[{'comment_id': 2161452821, 'issue_id': 2293859813, 'author': 'bshepherdson', 'body': ""@ranquild is this still relevant? If so, can you update the description and title? I don't have any context for what the issue is here. Feel free to assign it back to me if you think I'm the right person to work on this, or to someone else on BE who's working more closely on Metrics."", 'created_at': datetime.datetime(2024, 6, 11, 19, 20, 42, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-06-11 19:20:42 UTC): @ranquild is this still relevant? If so, can you update the description and title? I don't have any context for what the issue is here. Feel free to assign it back to me if you think I'm the right person to work on this, or to someone else on BE who's working more closely on Metrics.

"
2293784239,issue,closed,not_planned,[BE] [Bug] Metrics are not returned by `/api/activity/popular_items`,"E2E repro https://github.com/metabase/metabase/blob/44d530b560da058de09ddf576ea8b404e596dff3/e2e/test/scenarios/metrics/metrics-search.cy.spec.js#L70

Steps:
- Run EE
- Log in as user A.
- Create a metric and run its query
- Log out and log in as user B.
- Open homepage
- There are no ""popular items"" and x-rays are displayed.

When doing the same with a question, the question is returned by the endpoint correctly.",ranquild,2024-05-13 20:28:33+00:00,['metamben'],2024-05-16 19:47:00+00:00,2024-05-16 19:47:00+00:00,https://github.com/metabase/metabase/issues/42607,[],"[{'comment_id': 2111262941, 'issue_id': 2293784239, 'author': 'metamben', 'body': ""@ranquild, how exactly should the metric's query be run? If I just open it it gets executed via the `POST /dataset` endpoint in `ad-hoc` context, so the execution is not returned in `popular_items`. I also managed to execute it in `collection` context, but those executions don't count either. Do we need a new type of context? It's probably not a good idea to allow those context to be considered by `popular_items`."", 'created_at': datetime.datetime(2024, 5, 14, 22, 44, 45, tzinfo=datetime.timezone.utc)}]","metamben (Assginee) on (2024-05-14 22:44:45 UTC): @ranquild, how exactly should the metric's query be run? If I just open it it gets executed via the `POST /dataset` endpoint in `ad-hoc` context, so the execution is not returned in `popular_items`. I also managed to execute it in `collection` context, but those executions don't count either. Do we need a new type of context? It's probably not a good idea to allow those context to be considered by `popular_items`.

"
2293697657,issue,closed,completed,[FE] [Bug] Cannot replace a card with a metric on a dashboard,,ranquild,2024-05-13 19:43:08+00:00,['ranquild'],2024-05-16 14:12:34+00:00,2024-05-16 14:12:34+00:00,https://github.com/metabase/metabase/issues/42598,[],[],
2293656577,issue,open,,Collections - Add Visual Indicators for Access Levels and Option to View Permissions for Non-Admin Creators,"**Is your feature request related to a problem? Please describe.**
Provide content creators with a way to see if a collection is accessible to all users or only a select group. This would help simplify the process of sharing content appropriately across a larger organization.

Non-admin content creators currently cannot  view the access permissions of a collection, thus they don't have a way to know whether a question they save into that collection will be accessible to the general public or only to a restricted group of users.

**Describe the solution you'd like**
Use distinct icons to differentiate between common access levels by the general public (All Users group). For example, use specific icons to indicate whether a collections contents are
- editable by All Users
- readable (but not editable) by All Users
- neither editable nor readable by All Users (access is provided via membership in other groups)

Additionally, provide a way to view the permissions of a specific collection for all users with at least view access to the collection. At the same place where admins are able to edit the permissions, they would see: ... / View Permissions

**Describe alternatives you've considered**
Using official collections to change the icon of the collection - however this is not the intended use, and it is also not autoatmically tied to permissions.

**How important is this feature to you?**
Important - it would streamline the process of sharing content with correct permissions, particularly in larger organizations.",zbodi74,2024-05-13 19:28:05+00:00,[],2024-05-15 12:14:23+00:00,,https://github.com/metabase/metabase/issues/42596,"[('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Organization/Collections', '')]",[],
2293379054,issue,open,,Ability to Customize Tooltip Contents and Formatting,"**Is your feature request related to a problem? Please describe.**
If you have a lot of fields in the underlying data source for a visualization - every field shows up in the tooltip. Sometimes these aren't relevant or useful to the end user and it would make sense to be able to choose what to display, customize formatting and customize labelling.

For example:

- A max() or aggregate calculation that's used for a JOIN in the dataset but doesn't need to be displayed in the tooltip
- An aggregate field that has a really long name makes the label really long
- Latitude and Longitude in a map might be necessary for the visualization but not for the end user
- There may already be data labelled ""other"" in the underlying result sets so the existing label becomes redundant and confusing

**Describe the solution you'd like**
It would make sense to allow customization of the tooltip either in the question builder or in the Card visualization settings from the Dashboard.

**Describe alternatives you've considered**
Editing the underlying data to change how the tooltip is displayed (sometimes this is straightforward but sometimes, especially with multi-level aggregated queries) it's not so easy to remove fields required for JOINS, etc. If you want to change the name you either have to write native SQL or use a custom expression to duplicate a column in a hacky way.

",ixipixi,2024-05-13 17:12:34+00:00,[],2024-06-06 21:34:52+00:00,,https://github.com/metabase/metabase/issues/42594,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Visualization/Maps', '')]","[{'comment_id': 2108288353, 'issue_id': 2293379054, 'author': 'ixipixi', 'body': 'Related issues:\r\n\r\n- https://github.com/metabase/metabase/issues/42178\r\n- https://github.com/metabase/metabase/issues/5176\r\n- https://github.com/metabase/metabase/issues/34010', 'created_at': datetime.datetime(2024, 5, 13, 17, 13, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2149605696, 'issue_id': 2293379054, 'author': 'Tony-metabase', 'body': 'I would also like to add to this. Currently you cannot change the background color of the tooltip, having it as an option would also be ideal so in interactive embedding it can be more in line with the white-labelling of the customer  \r\n\r\n<img width=""1507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/5185e4e1-d006-4e1c-9baf-d37264e9fec9"">', 'created_at': datetime.datetime(2024, 6, 5, 11, 32, 55, tzinfo=datetime.timezone.utc)}]","ixipixi (Issue Creator) on (2024-05-13 17:13:46 UTC): Related issues:

- https://github.com/metabase/metabase/issues/42178
- https://github.com/metabase/metabase/issues/5176
- https://github.com/metabase/metabase/issues/34010

Tony-metabase on (2024-06-05 11:32:55 UTC): I would also like to add to this. Currently you cannot change the background color of the tooltip, having it as an option would also be ideal so in interactive embedding it can be more in line with the white-labelling of the customer  

<img width=""1507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/5185e4e1-d006-4e1c-9baf-d37264e9fec9"">

"
2293279819,issue,closed,completed,[FE] New modal after adding a database,,dpsutton,2024-05-13 16:24:56+00:00,['npfitz'],2024-05-23 16:05:04+00:00,2024-05-23 14:40:38+00:00,https://github.com/metabase/metabase/issues/42592,[],[],
2293272273,issue,closed,completed,[Cache] Milestone 5: Questions,"add new question cache configuration form to question sidebar, similar to https://github.com/metabase/metabase/issues/42566
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42731
- [ ] https://github.com/metabase/metabase/issues/42789
```
",iethree,2024-05-13 16:20:44+00:00,['rafpaf'],2024-06-03 16:38:43+00:00,2024-05-17 15:42:15+00:00,https://github.com/metabase/metabase/issues/42591,[],[],
2293118281,issue,closed,completed,Design update for column info,"[Product doc](https://www.notion.so/metabase/Design-update-for-column-info-aefdb5dbff3b45a6a9e64e14f0bd0a13)

Update the column and table info icons to avoid them from being so intrusive.


<img width=""313"" alt=""Screenshot 2024-05-13 at 17 14 14"" src=""https://github.com/metabase/metabase/assets/1250185/05c66469-7b5d-4e49-838b-45457e5946f0"">
",romeovs,2024-05-13 15:14:35+00:00,['romeovs'],2024-05-15 07:23:08+00:00,2024-05-15 06:48:19+00:00,https://github.com/metabase/metabase/issues/42589,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2293071052,issue,closed,not_planned,datasource add csv,"**Is your feature request related to a problem? Please describe.**

Since CSV does not have a data format, there is currently no range filtering for the number format in CSV, which may be necessary.


 For non-software practitioners, it is still a bit troublesome to build a MySQL or PG data source, if you can add a pre-set data type change transformation or the like to the CSV data source, so that the number column can support range queries, 

this may be a good extension for Metabase users, because the barrier to entry is lower. 


I need this feature as well


**Describe the solution you'd like**

**Describe alternatives you've considered**

https://github.com/Markenson/csv-metabase-driver/issues/38

![image](https://github.com/Markenson/csv-metabase-driver/assets/37619525/7d127787-abf5-4eb1-bd75-a7486f15a74a)

![image](https://github.com/Markenson/csv-metabase-driver/assets/37619525/8f85b023-1760-44e0-8201-981f75aa0134)


---


![image](https://github.com/Markenson/csv-metabase-driver/assets/37619525/70396f6d-7af4-4bbc-b525-b0aadbf9930a)


![image](https://github.com/Markenson/csv-metabase-driver/assets/37619525/8e96b8eb-c45a-4f37-9af8-c61328245c82)

---

what can id do???

 less than or grather than


**How important is this feature to you?**



**Additional context**


https://github.com/Markenson/csv-metabase-driver/issues/38
",nogeek-cn,2024-05-13 14:54:09+00:00,[],2024-05-24 13:13:03+00:00,2024-05-24 13:13:03+00:00,https://github.com/metabase/metabase/issues/42587,"[('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2117738010, 'issue_id': 2293071052, 'author': 'ignacio-mb', 'body': ""Hi @nogeek-cn Metabase will try to match the type based on several factors (field values and field name, for example).\r\n\r\nCan you share an example of the data in which it's not converted to the type you want? Thanks"", 'created_at': datetime.datetime(2024, 5, 17, 14, 29, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2117925210, 'issue_id': 2293071052, 'author': 'nogeek-cn', 'body': 'Thanks ，this is file\r\n\r\n[test.csv](https://github.com/metabase/metabase/files/15354102/test.csv)\r\n\r\n\r\n\r\nalse can see this data\r\n\r\n```csv\r\n姓名,总分,语文,数学,外语,物理,化学,道德与法治\r\nmic,428.5,82,70,38.5,32,30,43\r\ntom,557,98,94,71.5,61,43.5,56\r\njames,472,88,71,56,41,32,50\r\nhhh,44,2,45,66,77,88,99\r\naaaa,566,74,32,74,36,42,22\r\n```\r\n\r\ni use this driver\r\n\r\nhttps://github.com/Markenson/csv-metabase-driver\r\n\r\n---\r\n\r\nOK\r\n\r\ni input this file.\r\n\r\nin metabase change clumn to Scope .\r\n![image](https://github.com/metabase/metabase/assets/37619525/2d3f7c63-d772-4ea1-bc05-97dcaa0eab0a)\r\n\r\n\r\n<img width=""707"" alt=""image"" src=""https://github.com/metabase/metabase/assets/37619525/69240466-f375-4934-874c-611cd7f6da04"">\r\n\r\n<img width=""651"" alt=""image"" src=""https://github.com/metabase/metabase/assets/37619525/4f8c16f7-42f0-4d6f-9427-b2ae263a3121"">\r\n\r\nthanks\r\n\r\nok, \r\n\r\nexcept to can filter user ""less than"" or ""greate than""\r\n\r\n\r\n@ignacio-mb', 'created_at': datetime.datetime(2024, 5, 17, 16, 8, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2117943752, 'issue_id': 2293071052, 'author': 'paoliniluis', 'body': 'I think that the problem is on the custom driver', 'created_at': datetime.datetime(2024, 5, 17, 16, 18, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2118062153, 'issue_id': 2293071052, 'author': 'ignacio-mb', 'body': 'It is indeed the driver, because using our new CSV upload feature I can use the proper Score (number) filters. Why are you using the driver and not the [our CSV feature](https://www.metabase.com/product/csv-uploads)?', 'created_at': datetime.datetime(2024, 5, 17, 17, 24, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2129505927, 'issue_id': 2293071052, 'author': 'paoliniluis', 'body': '@nogeek-cn please contact the builder of the custom driver for this', 'created_at': datetime.datetime(2024, 5, 24, 13, 12, 57, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-05-17 14:29:34 UTC): Hi @nogeek-cn Metabase will try to match the type based on several factors (field values and field name, for example).

Can you share an example of the data in which it's not converted to the type you want? Thanks

nogeek-cn (Issue Creator) on (2024-05-17 16:08:10 UTC): Thanks ，this is file

[test.csv](https://github.com/metabase/metabase/files/15354102/test.csv)



alse can see this data

```csv
姓名,总分,语文,数学,外语,物理,化学,道德与法治
mic,428.5,82,70,38.5,32,30,43
tom,557,98,94,71.5,61,43.5,56
james,472,88,71,56,41,32,50
hhh,44,2,45,66,77,88,99
aaaa,566,74,32,74,36,42,22
```

i use this driver

https://github.com/Markenson/csv-metabase-driver

---

OK

i input this file.

in metabase change clumn to Scope .
![image](https://github.com/metabase/metabase/assets/37619525/2d3f7c63-d772-4ea1-bc05-97dcaa0eab0a)


<img width=""707"" alt=""image"" src=""https://github.com/metabase/metabase/assets/37619525/69240466-f375-4934-874c-611cd7f6da04"">

<img width=""651"" alt=""image"" src=""https://github.com/metabase/metabase/assets/37619525/4f8c16f7-42f0-4d6f-9427-b2ae263a3121"">

thanks

ok, 

except to can filter user ""less than"" or ""greate than""


@ignacio-mb

paoliniluis on (2024-05-17 16:18:50 UTC): I think that the problem is on the custom driver

ignacio-mb on (2024-05-17 17:24:08 UTC): It is indeed the driver, because using our new CSV upload feature I can use the proper Score (number) filters. Why are you using the driver and not the [our CSV feature](https://www.metabase.com/product/csv-uploads)?

paoliniluis on (2024-05-24 13:12:57 UTC): @nogeek-cn please contact the builder of the custom driver for this

"
2293047496,issue,open,,Correctly attribute columns in compound queries,"The intention here is to get all the tests added in #42585 passing, i.e. correctly track the provenance of fields coming from sub-selects, CTEs, unions, etc.",tsmacdonald,2024-05-13 14:44:06+00:00,[],2025-02-04 20:28:25+00:00,,https://github.com/metabase/metabase/issues/42586,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2200544689, 'issue_id': 2293047496, 'author': 'crisptrutski', 'body': ""We're not working on this right now as flat scopes are deemed sufficient for v1."", 'created_at': datetime.datetime(2024, 7, 1, 16, 6, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293380534, 'issue_id': 2293047496, 'author': 'crisptrutski', 'body': 'Have started adding acceptance tests showing the gaps here in Macaw, with comments linking back here.\r\n\r\ne.g. this [query](https://github.com/metabase/macaw/blob/1c4ea0b136de88336916fe6a3542598d931bb97a/test/resources/acceptance/cycle__cte.sql), with override [here](https://github.com/metabase/macaw/blob/1c4ea0b136de88336916fe6a3542598d931bb97a/test/resources/acceptance/cycle__cte.analysis.edn)', 'created_at': datetime.datetime(2024, 8, 16, 12, 1, 21, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-07-01 16:06:46 UTC): We're not working on this right now as flat scopes are deemed sufficient for v1.

crisptrutski on (2024-08-16 12:01:21 UTC): Have started adding acceptance tests showing the gaps here in Macaw, with comments linking back here.

e.g. this [query](https://github.com/metabase/macaw/blob/1c4ea0b136de88336916fe6a3542598d931bb97a/test/resources/acceptance/cycle__cte.sql), with override [here](https://github.com/metabase/macaw/blob/1c4ea0b136de88336916fe6a3542598d931bb97a/test/resources/acceptance/cycle__cte.analysis.edn)

"
2293047325,issue,closed,completed,Test column attribution for compound queries,"Compound constructions include sub-selects, WITH, UNION, etc.

Really good real-world example [here](https://metabase.zendesk.com/agent/tickets/27376).",tsmacdonald,2024-05-13 14:44:03+00:00,['crisptrutski'],2024-06-17 07:43:06+00:00,2024-06-17 07:43:06+00:00,https://github.com/metabase/metabase/issues/42585,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2126354025, 'issue_id': 2293047325, 'author': 'crisptrutski', 'body': ""It's worth starting with small helper for mangling all the schema, table, alias, column, etc names in the queries, as I'm sure we'll be adding more tests from user queries in the future. doing it manually for this first example would be madness as well."", 'created_at': datetime.datetime(2024, 5, 23, 6, 47, 33, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-05-23 06:47:33 UTC): It's worth starting with small helper for mangling all the schema, table, alias, column, etc names in the queries, as I'm sure we'll be adding more tests from user queries in the future. doing it manually for this first example would be madness as well.

"
2293047150,issue,closed,completed,Correctly track aliased columns,,tsmacdonald,2024-05-13 14:44:00+00:00,['piranha'],2024-05-22 09:41:17+00:00,2024-05-22 09:41:17+00:00,https://github.com/metabase/metabase/issues/42584,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2107830128, 'issue_id': 2293047150, 'author': 'tsmacdonald', 'body': 'Fixed by https://github.com/metabase/macaw/pull/31', 'created_at': datetime.datetime(2024, 5, 13, 14, 46, 57, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-05-13 14:46:57 UTC): Fixed by https://github.com/metabase/macaw/pull/31

"
2293046986,issue,closed,completed,Implement F&R for native queries with optional tags (`[[`s and  `]]`s),,tsmacdonald,2024-05-13 14:43:56+00:00,[],2024-05-23 09:55:42+00:00,2024-05-23 09:55:30+00:00,https://github.com/metabase/metabase/issues/42583,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2293046905,issue,closed,completed,Implement F&R for native queries with references to other cards,,tsmacdonald,2024-05-13 14:43:54+00:00,['tsmacdonald'],2024-05-22 10:52:31+00:00,2024-05-22 10:44:20+00:00,https://github.com/metabase/metabase/issues/42582,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2112370428, 'issue_id': 2293046905, 'author': 'tsmacdonald', 'body': 'This is a little tricky:\r\n\r\n```\r\nt> (println (:query (:native (:dataset_query cr))))\r\nSELECT * from {{#129-just-plain-orders}}\r\nnil\r\nmetabase.native-query-analyzer.replacement> (println (replace-names cr {:columns {""source""     ""referral""\r\n                                                                                  ""birth_date"" ""birthday""}\r\n                                                                        :tables {""people"" ""folk""}}))\r\n{:t SELECT * from }\r\n{:t (params/->Param #129-just-plain-orders)}\r\n{:t nil}\r\nExecution error (ParseException) at net.sf.jsqlparser.parser.CCJSqlParser/generateParseException (CCJSqlParser.java:39603).\r\nEncountered unexpected token: ""from"" ""FROM""\r\n    at line 1, column 10.\r\n\r\nWas expecting one of:\r\n\r\n    <EOF>\r\n    <ST_SEMICOLON>\r\n\r\nmetabase.native-query-analyzer.replacement> (params/ReferencedCardQuery? xt)\r\nfalse\r\nmetabase.native-query-analyzer.replacement> xt\r\n(params/->Param ""#129-just-plain-orders"")\r\n```\r\n\r\nI would\'ve expected the token to be a `ReferencedCardQuery`, but it\'s not. I think this might require bringing in the `param->value` stuff?', 'created_at': datetime.datetime(2024, 5, 15, 12, 15, 43, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-05-15 12:15:43 UTC): This is a little tricky:

```
t> (println (:query (:native (:dataset_query cr))))
SELECT * from {{#129-just-plain-orders}}
nil
metabase.native-query-analyzer.replacement> (println (replace-names cr {:columns {""source""     ""referral""
                                                                                  ""birth_date"" ""birthday""}
                                                                        :tables {""people"" ""folk""}}))
{:t SELECT * from }
{:t (params/->Param #129-just-plain-orders)}
{:t nil}
Execution error (ParseException) at net.sf.jsqlparser.parser.CCJSqlParser/generateParseException (CCJSqlParser.java:39603).
Encountered unexpected token: ""from"" ""FROM""
    at line 1, column 10.

Was expecting one of:

    <EOF>
    <ST_SEMICOLON>

metabase.native-query-analyzer.replacement> (params/ReferencedCardQuery? xt)
false
metabase.native-query-analyzer.replacement> xt
(params/->Param ""#129-just-plain-orders"")
```

I would've expected the token to be a `ReferencedCardQuery`, but it's not. I think this might require bringing in the `param->value` stuff?

"
2293046800,issue,closed,completed,Implement F&R for native queries with field filters.,,tsmacdonald,2024-05-13 14:43:51+00:00,[],2024-05-16 12:14:01+00:00,2024-05-16 12:14:01+00:00,https://github.com/metabase/metabase/issues/42581,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2293046572,issue,closed,completed,"Implement F&R for native queries with variables. This includes the setup work of setting up the parser, handling the parse tree, etc.",,tsmacdonald,2024-05-13 14:43:48+00:00,['tsmacdonald'],2024-05-22 10:52:35+00:00,2024-05-16 12:14:01+00:00,https://github.com/metabase/metabase/issues/42580,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2292979332,issue,open,,Not allow these groupby columns to be mapped to click behavior in pivot tables,"**Is your feature request related to a problem? Please describe.**
Strictly related to https://github.com/metabase/metabase/issues/42350, users get confused that they can't drill down on group by when they set up Click behavior for those columns.

**Describe the solution you'd like**
Prevent this from happening by blocking this mapping.

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Internal ticket [27166](https://metabase.zendesk.com/agent/tickets/27166) and [convo](https://metaboat.slack.com/archives/C05MPF0TM3L/p1715103432944979)

**Additional context**
N/A
",ignacio-mb,2024-05-13 14:18:19+00:00,[],2024-05-20 16:55:16+00:00,,https://github.com/metabase/metabase/issues/42576,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Reporting/Dashboards/Click Behavior', '')]",[],
2292902235,issue,closed,completed,[BE] [Bug] Cannot combine compatible timeseries metrics in dashboards,"Reproduce:
- New -> Question -> Orders, Sum by Count, Group by Created At -> Save as ""Orders over time question""
- Create the same metric -> ""Orders over time metric""
- Create a similar question and a metric but based on Products
- Create a new dashboard and add ""Orders over time question"" and ""Orders over time metric"".
- Click Edit -> Add series.
- It's possible to add ""Products over time question"" to ""Orders over time question"", but not with metrics

Expected result:
- It should be possible to combine metrics just as saved questions in dashboards. Please note that combining scalar metrics works.

Bug:
- `/api/card/:id/series` does not return metrics. It relies on the `visualization_settings` present, which is not the case for metrics. This is currently by design.
- The BE should rely on the query when there is no corresponding viz setting. If there is no `graph.metrics` setting, assume that all last-stage aggregations are used. No `graph.dimensions` -> use breakouts.

<img width=""1127"" alt=""Screenshot 2024-05-13 at 09 54 03"" src=""https://github.com/metabase/metabase/assets/8542534/b2b6696b-ab5d-4955-a8fa-68c69c438445"">

Question:
<img width=""1696"" alt=""Screenshot 2024-05-13 at 09 53 59"" src=""https://github.com/metabase/metabase/assets/8542534/0e5845fa-7eb5-47e9-bdf7-934b490eb3cc"">

Metric:
<img width=""1130"" alt=""Screenshot 2024-05-13 at 09 54 11"" src=""https://github.com/metabase/metabase/assets/8542534/0341e1a4-69f4-43ca-95cd-2a6d7cb714d8"">
",ranquild,2024-05-13 13:55:36+00:00,['snoe'],2024-10-08 17:11:16+00:00,2024-05-21 21:20:33+00:00,https://github.com/metabase/metabase/issues/42575,[],[],
2292888567,issue,closed,completed,Align reset view button with the left of visualization in embedding SDK,"Currently, the reset view button is slightly offset and not aligned with the visualization, e.g. the interactive table.

<img src=""https://github.com/metabase/metabase/assets/4714175/ba47eceb-4fa1-4112-89f8-5a7760807ead"" width=""300"">

The design indicates that it should align to the left.

<img src=""https://github.com/metabase/metabase/assets/4714175/603410be-1039-4a14-be53-b6960034a379"" width=""300"">

",heypoom,2024-05-13 13:49:55+00:00,[],2024-09-05 07:46:41+00:00,2024-09-05 07:46:40+00:00,https://github.com/metabase/metabase/issues/42573,[],"[{'comment_id': 2330838516, 'issue_id': 2292888567, 'author': 'heypoom', 'body': 'Closed as the design has been updated.', 'created_at': datetime.datetime(2024, 9, 5, 7, 46, 40, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-09-05 07:46:40 UTC): Closed as the design has been updated.

"
2292856236,issue,closed,completed,[Epic] [Placeholder] Support for partitioned cookies,"**This is just a placeholder so that we can link to it until we figure out all the implementation details**


**Links**
- product doc: _link to product doc_
- eng doc: _link to technical design doc, if any_
- feature branch: `branch-name` _this should be the feature branch where this work will be done in. PRs will be delivered against this branch_
- issue links: _related issues if any_

**Implementation Plan**


***Milestone 1***
_insert tasklist here_

***Milestone 2***

",npretto,2024-05-13 13:35:57+00:00,[],2025-01-07 10:20:52+00:00,2025-01-07 10:20:51+00:00,https://github.com/metabase/metabase/issues/42571,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', '')]","[{'comment_id': 2569575973, 'issue_id': 2292856236, 'author': 'brunobergher', 'body': 'Should we close this?', 'created_at': datetime.datetime(2025, 1, 3, 17, 26, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574916265, 'issue_id': 2292856236, 'author': 'npretto', 'body': '> Should we close this?\n\nLooks like so, as the [related project](https://www.notion.so/metabase/Deal-with-Chrome-dropping-third-party-cookies-58aa096281e9463f97de97921c723328) was cancelled', 'created_at': datetime.datetime(2025, 1, 7, 10, 20, 51, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 17:26:31 UTC): Should we close this?

npretto (Issue Creator) on (2025-01-07 10:20:51 UTC): Looks like so, as the [related project](https://www.notion.so/metabase/Deal-with-Chrome-dropping-third-party-cookies-58aa096281e9463f97de97921c723328) was cancelled

"
2292825690,issue,closed,not_planned,Race condition in Browse models filter,[Loom](https://www.loom.com/share/3f6f23dda86b43349b8c2b61508d61bf?sid=5eb10a27-0a54-4b0b-81cb-193547d7bd09),rafpaf,2024-05-13 13:26:26+00:00,[],2024-08-06 15:25:48+00:00,2024-08-06 15:25:47+00:00,https://github.com/metabase/metabase/issues/42570,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Browse Data', '')]","[{'comment_id': 2271565584, 'issue_id': 2292825690, 'author': 'rafpaf', 'body': 'closed for now, may return to this later', 'created_at': datetime.datetime(2024, 8, 6, 15, 25, 47, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-08-06 15:25:47 UTC): closed for now, may return to this later

"
2292820209,issue,open,,Pin maps may remain visible on dashboards even when 'Hide this card if there are no results' is set and there is no data to display,"### Describe the bug

Pin maps do not display records if the coordinates are incomplete. However, a card on a dashboard can only be hidden if the underlying question returns an empty result set. 

This opens an edge case - when results exist but the coordinates are incomplete, and the card remains visible. 
We should consider displaying a warning in this case to clarify why the card does not disappear, as users might expect it to if there are perceived to be no results.

### To Reproduce

1. Create a data set with coordinates where each record has an incomplete coordinate (one of the values or both are null)
2. Display it on a pin map, save it, and add it to a dashboard
3. Set 'Hide this card if there are no results' for this card on the dashboard
4.(!) The card remains to be visible, in a blank state, showing 'No results!'.


### Expected behavior

The current behavior is confusing. 
We should consider displaying a message on a blank card that reads, 'No displayable records. N records are hidden due to incomplete coordinates.' This would clarify why results are not being shown, despite their presence.

A possible workaround is to filter out records with empty coordinates from the dataset. However, it might be more beneficial to display a warning to keep the user informed about the presence of such records, which could be valuable information that would otherwise remain unknown.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.49.8
```


### Severity

P3

### Additional context

_No response_",zbodi74,2024-05-13 13:24:54+00:00,[],2025-02-04 20:31:54+00:00,,https://github.com/metabase/metabase/issues/42569,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2292814148,issue,closed,completed,[Cache] Milestone 7: Overrides table,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42567
```
",rafpaf,2024-05-13 13:23:06+00:00,[],2024-08-23 19:56:55+00:00,2024-08-23 19:56:55+00:00,https://github.com/metabase/metabase/issues/42568,[],[],
2292805247,issue,closed,completed,[Cache] Add table of overrides to Admin / Performance page,[Spec](https://www.figma.com/file/x87hHuf4RabjMBuyV2Lq7c/caching-arc-low-fi-explorations?type=design&node-id=996-8125&mode=design&t=O5ydA46BcaQX3WDS-4),rafpaf,2024-05-13 13:19:32+00:00,['rafpaf'],2024-08-23 18:57:56+00:00,2024-08-23 18:57:55+00:00,https://github.com/metabase/metabase/issues/42567,[],[],
2292800543,issue,closed,completed,Add cache configuration form to dashboard sidebar,,rafpaf,2024-05-13 13:17:54+00:00,['rafpaf'],2024-05-15 16:42:47+00:00,2024-05-15 16:42:47+00:00,https://github.com/metabase/metabase/issues/42566,[],[],
2292636068,issue,closed,completed,Customize background color for visualizations,Superseded by https://github.com/metabase/metabase/issues/42678,heypoom,2024-05-13 12:06:53+00:00,[],2024-05-15 09:38:54+00:00,2024-05-15 09:38:47+00:00,https://github.com/metabase/metabase/issues/42564,[],"[{'comment_id': 2112042057, 'issue_id': 2292636068, 'author': 'heypoom', 'body': 'Superseded by #42678', 'created_at': datetime.datetime(2024, 5, 15, 9, 38, 47, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-15 09:38:47 UTC): Superseded by #42678

"
2292632037,issue,closed,completed,Expose color and font size options for smart scalar in embedding SDK,"Expose the following theme options for smart scalar:

- Customize the positive and negative colors in comparison
   - Expose two color palettes, `colors.positive` and `colors.negative`, which remaps to `success` and `error` colors respectively.
   - Ensure that smart scalar's change color follows the provided Mantine themes
- Customize the value's font size (`231` from the screenshot), could be an option like `smartScalar.value.fontSize`

<img src=""https://github.com/metabase/metabase/assets/4714175/640f5738-7530-410d-acd3-6ca6264069f2"" width=""200"">
",heypoom,2024-05-13 12:04:48+00:00,['heypoom'],2024-10-08 17:10:27+00:00,2024-05-28 14:18:00+00:00,https://github.com/metabase/metabase/issues/42563,[],[],
2292537932,issue,closed,completed,Interactive question popovers and filters should follow the embedding theme,"Components in interactive questions, such as popovers and filters, do not yet follow the brand and theme's text color.

The popover does not follow the user's brand color.

<img src=""https://github.com/metabase/metabase/assets/4714175/89ff89a3-b415-4eb5-b38f-3c5ee17b32f5"" width=""200"">

Similarly, the table column header's popover does not follow the brand color.

<img src=""https://github.com/metabase/metabase/assets/4714175/4fd64bb5-1963-4ac9-a272-ea0ad208385d"" width=""200"">

The filter header doesn't follow the brand color (it's currently purple). The filter panel doesn't show the proper text color. In this screenshot, the brand color is set to light blue.

<img src=""https://github.com/metabase/metabase/assets/4714175/85747f94-e4a8-4bfa-ac85-c46c81dad561"" width=""300"">

## Issues

- When users are using light-themed colors as their brand color, it's almost completely unreadable. Should we also change the background of those popovers when we are using light-themed brand colors for legibility?
- We should also verify if the font family and base font size is also applied accordingly to the filter header and the filter popovers.

## Notes

- Feel free to split this issue into smaller issues if the scope turns out to be bigger than expected.",heypoom,2024-05-13 11:24:44+00:00,['deniskaber'],2024-05-17 13:40:29+00:00,2024-05-17 13:40:29+00:00,https://github.com/metabase/metabase/issues/42560,[],[],
2292463241,issue,closed,completed,Remove `QuestionDataSelector`,,kamilmielnik,2024-05-13 10:46:50+00:00,['kamilmielnik'],2024-05-14 14:40:24+00:00,2024-05-14 14:40:24+00:00,https://github.com/metabase/metabase/issues/42559,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2110424975, 'issue_id': 2292463241, 'author': 'kamilmielnik', 'body': 'Closed by #42562', 'created_at': datetime.datetime(2024, 5, 14, 14, 40, 24, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-14 14:40:24 UTC): Closed by #42562

"
2292163880,issue,closed,completed,deduplicate duplicated packages,,uladzimirdev,2024-05-13 08:28:24+00:00,['uladzimirdev'],2025-01-21 13:29:07+00:00,2025-01-21 13:29:06+00:00,https://github.com/metabase/metabase/issues/42555,[],"[{'comment_id': 2604740687, 'issue_id': 2292163880, 'author': 'uladzimirdev', 'body': ""it's not the biggest problem"", 'created_at': datetime.datetime(2025, 1, 21, 13, 29, 6, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2025-01-21 13:29:06 UTC): it's not the biggest problem

"
2292149164,issue,closed,completed,[Bug] Cannot sort by aggregation that uses `Offset()`,"e2e repro in this PR: #42455 (test is skipped for now)

:warning: Please [update the assertion](https://github.com/metabase/metabase/pull/42455/files#r1598210494) in relevant test after fixing the issue :warning: 

----

Repro steps:
1. Create a question based on orders table
2. Add custom expression aggregation: `Offset(Sum([Total]), -1)`
3. Add a breakout by Orders > Created At: Month
4. Add sorting by aggregation clause created in step 2
5. Visualize the query

```
Expected :aggregation-options, got [:offset {:lib/uuid ""d88bdc68-b7d4-416e-8781-8d940a483d20"", :name ""offset"", :display-name ""offset"", :effective-type :type/Float} [:sum [:field ""TOTAL"" {:base-type :type/Float}]] -1]. (Query must be fully preprocessed.)
```

![image](https://github.com/metabase/metabase/assets/6830683/05038ab1-5cdd-4c04-80de-5552026b25d1)
",kamilmielnik,2024-05-13 08:20:54+00:00,['camsaul'],2024-08-28 02:09:47+00:00,2024-05-17 02:56:24+00:00,https://github.com/metabase/metabase/issues/42554,"[('Type:Bug', 'Product defects'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2291978707,issue,closed,completed,cut unused moment locales,75% (160 minified KBs)¹ of [Moment.js’](https://github.com/moment/moment) size are files used for localization. [They are always included](https://iamakulov.com/notes/webpack-front-end-size-caching/#moment-js) when you build your app with webpack.,uladzimirdev,2024-05-13 06:55:00+00:00,['uladzimirdev'],2025-02-03 08:51:23+00:00,2025-02-03 08:51:23+00:00,https://github.com/metabase/metabase/issues/42552,[],[],
2291978488,issue,closed,completed,separate jspdf and html2canvas from the vendors chunk,"Even if `html2canvas` and `jspdf` dependencies are marked to be loaded lazily, webpack doesn't automatically create separate chunks for them in current configuration

e.g.
https://github.com/metabase/metabase/blob/6cc0f2bc9c7ae31f1ba4d63d683c7b7e7ed755de/frontend/src/metabase/visualizations/lib/save-chart-image.ts#L24

<img width=""692"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/52eb43fa-9dd8-41e0-94c4-b8c9a1156cf6"">
<img width=""743"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/ef460d1d-d2ec-4ee9-a916-fddaf94b8e2a"">
",uladzimirdev,2024-05-13 06:54:55+00:00,['uladzimirdev'],2024-10-08 17:11:39+00:00,2024-05-18 10:03:30+00:00,https://github.com/metabase/metabase/issues/42551,[],[],
2291977016,issue,open,,[Epic] Optimize bundle size,"Adding new UI library or migrating to another charts lib leads to bundle bloating, which affects cypress or local development.


```[tasklist]
### **Implementation Plan**
- [ ] https://github.com/metabase/metabase/issues/42551
- [ ] https://github.com/metabase/metabase/issues/42555
- [ ] https://github.com/metabase/metabase/issues/42552
- [ ] upgrade RTK to deduplicate reselect
- [ ] lazy load `jsrsasign`
- [ ] lazy load `ace`
- [ ] cut unused moment-timezone data in dev mode
- [ ] exclude cljs dev tools during local cypress run by default
```",uladzimirdev,2024-05-13 06:54:23+00:00,[],2025-01-29 09:01:26+00:00,,https://github.com/metabase/metabase/issues/42550,"[('.Epic', 'Feature Implementation or Project')]",[],
2291750223,issue,closed,not_planned,"SQLITE Error ""no such column""","### Describe the bug

Somewhere between v45 and current version this error started to appear. It was working fine in v0.45.2.1.

When I select a filter value it gives the error: `[SQLITE_ERROR] SQL error or missing database (no such column: test_table2.col1)`. 
The `test_table2.col1` exists and is selected on the right column:

![Screenshot 2024-05-12 at 20-48-14 test_card_2 · Metabase](https://github.com/metabase/metabase/assets/15974735/c5525727-67e6-4e9d-8c0c-36010ae3aefa)



### To Reproduce

- Connect a SQLITE DB.
- Create a sql card: 
```
select *
from test_table
where 1 = 1 
[[ and {{test_filter}} ]]
```
- connect the filter to a string column
- select a filter value and run the code

### Expected behavior

The shouldn't be an error

### Logs

no relevant logs

### Information about your Metabase installation

```JSON
v49.9
```


### Severity

blocking some unittests

### Additional context

_No response_",vvaezian,2024-05-13 03:57:04+00:00,[],2024-05-14 06:03:08+00:00,2024-05-13 15:08:16+00:00,https://github.com/metabase/metabase/issues/42547,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2107795193, 'issue_id': 2291750223, 'author': 'Tony-metabase', 'body': '@vvaezian You are mapping the column to a different table than the one you are filtering from .. So off course there will be no column `Col1` in table test_table\r\n\r\n<img width=""847"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/ae289fca-22e6-4eb3-aac0-44a7dea10dd0"">\r\n\r\nOr am i missing something?', 'created_at': datetime.datetime(2024, 5, 13, 14, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2107920075, 'issue_id': 2291750223, 'author': 'vvaezian', 'body': ""@Tony-metabase This card was created automatically as part of unittests. It seems the order of tables has changed. Anyways it's not related to the issue raised. Don't know how I missed that naming difference."", 'created_at': datetime.datetime(2024, 5, 13, 15, 8, 16, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-05-13 14:39:00 UTC): @vvaezian You are mapping the column to a different table than the one you are filtering from .. So off course there will be no column `Col1` in table test_table

<img width=""847"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/ae289fca-22e6-4eb3-aac0-44a7dea10dd0"">

Or am i missing something?

vvaezian (Issue Creator) on (2024-05-13 15:08:16 UTC): @Tony-metabase This card was created automatically as part of unittests. It seems the order of tables has changed. Anyways it's not related to the issue raised. Don't know how I missed that naming difference.

"
2291070053,issue,open,,"Deep clone dashboards, including upstream models","**Is your feature request related to a problem? Please describe.**
When you clone dashboards based on models the source models are not cloned as well, which might be an interesting use case when a user wants to take the entire lineage of objects to make it's own version of the dashboard (from the data to the viz)

**Describe the solution you'd like**
An option on dashboard cloning to make a deep deep copy (that includes the models as well)

**Describe alternatives you've considered**
Via serialization

**How important is this feature to you?**
Requested by a customer that has a lot of tenants and each tenant has a default data model that they might want to extend

**Additional context**
This should be defaulted to false
",paoliniluis,2024-05-11 21:22:35+00:00,[],2025-02-04 20:30:17+00:00,,https://github.com/metabase/metabase/issues/42546,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Querying/Models', 'aka Datasets')]","[{'comment_id': 2129228868, 'issue_id': 2291070053, 'author': 'mrsaikumar-7', 'body': 'Hey, I had developed a python package using serialisation, that can solve this issue\r\nit can perform following things:\r\n\r\n1. can deep copy the collection including questions, models, dashboards\r\n2. we can change the database reference, so that single dashboard design will be cloned with a different database.\r\n3. we can perform version controlling \r\n\r\nthank you', 'created_at': datetime.datetime(2024, 5, 24, 10, 48, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298714311, 'issue_id': 2291070053, 'author': 'albertoperdomo', 'body': '@paoliniluis In this case, are the source and target artifacts on the same instance? Just thinking this overlaps nicely with deep cloning of collections.', 'created_at': datetime.datetime(2024, 8, 20, 12, 15, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298992026, 'issue_id': 2291070053, 'author': 'paoliniluis', 'body': ""@albertoperdomo yes, it's all done in the same instance"", 'created_at': datetime.datetime(2024, 8, 20, 14, 23, 35, tzinfo=datetime.timezone.utc)}]","mrsaikumar-7 on (2024-05-24 10:48:27 UTC): Hey, I had developed a python package using serialisation, that can solve this issue
it can perform following things:

1. can deep copy the collection including questions, models, dashboards
2. we can change the database reference, so that single dashboard design will be cloned with a different database.
3. we can perform version controlling 

thank you

albertoperdomo on (2024-08-20 12:15:34 UTC): @paoliniluis In this case, are the source and target artifacts on the same instance? Just thinking this overlaps nicely with deep cloning of collections.

paoliniluis (Issue Creator) on (2024-08-20 14:23:35 UTC): @albertoperdomo yes, it's all done in the same instance

"
2290502186,issue,open,,Coherence in filter values on lots of data,"### Describe the bug

There's an interesting case on filters: let's say that you have a lot of unique values in the data that exceed the limit we have. If that happens we'll show a search box or an input box as the default behavior of the filter.

But you can currently override that: do a question (SQL or GUI), then add the filter and tell the filter to use the values of the query (yes, you'll lose cascading filters in this way), but you made your filter now to use tons of values

### To Reproduce

see above

### Expected behavior

We should make this behavior coherent, or just put the documentation together to make this a supported use case for big filters

### Logs

NA

### Information about your Metabase installation

```JSON
since... forever
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-05-10 22:54:18+00:00,[],2025-02-04 20:27:31+00:00,,https://github.com/metabase/metabase/issues/42544,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Completeness', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2121003154, 'issue_id': 2290502186, 'author': 'mazameli', 'body': 'What would ""make this behavior coherent"" look like in your mind, @paoliniluis? Tell the user ""woah, this is gonna be a _ton_ of options in this filter""?', 'created_at': datetime.datetime(2024, 5, 20, 18, 42, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2121310599, 'issue_id': 2290502186, 'author': 'paoliniluis', 'body': '@mazameli I know that this one is tricky, but one of our customers has been hammering on this one for a while. I believe we should chat with them to see what’s their suggestion since:\r\n1) there are a lot of unique filter values and that’s why we show a search box\r\n2) they seem to need all those filter values and that will clog their browser, but that’s why they get all those values via a query', 'created_at': datetime.datetime(2024, 5, 20, 22, 18, 32, tzinfo=datetime.timezone.utc)}]","mazameli on (2024-05-20 18:42:50 UTC): What would ""make this behavior coherent"" look like in your mind, @paoliniluis? Tell the user ""woah, this is gonna be a _ton_ of options in this filter""?

paoliniluis (Issue Creator) on (2024-05-20 22:18:32 UTC): @mazameli I know that this one is tricky, but one of our customers has been hammering on this one for a while. I believe we should chat with them to see what’s their suggestion since:
1) there are a lot of unique filter values and that’s why we show a search box
2) they seem to need all those filter values and that will clog their browser, but that’s why they get all those values via a query

"
2290478809,issue,open,,Metrics visibility is reset after changing group or adding filter for aggregated metrics,"### Describe the bug

I have a question that groups by Industry with a 5 metrics where only 2 of them are displayed in a stacked bar chart.
When I change the group to another field in the editor, all 5 metrics are displayed instead of just the 2. 

If you add a filter for one of the metrics (count) to be greater than 10, then it will remove all the metrics and nothing is shown in the chart and you are forced to re-select the metrics. 

### To Reproduce

1. Create  question with 5 metrics grouped by one field and show only 2 of the metrics in a stacked bar chart
2. Change grouping to another field
3. Observe all 5 metrics are shown
4. Open the editor again and add a filter for one of the metrics (like count > 10) and all metrics are removed. You will need to select the metrics in the viz settings. 


### Expected behavior

Changing group field or adding filter for aggregated metrics should not change visualization behavior. Doing so makes Metabase feel like a beta quality product. 

### Logs

n/a

### Information about your Metabase installation

```JSON
Master on Postgres
```


### Severity

There is a workaround but it makes Metabase look bad / poor quality, so sooner we fix the better to improve user experience & impression

### Additional context

_No response_",maxzheng,2024-05-10 22:18:09+00:00,['alxnddr'],2024-07-01 23:39:07+00:00,,https://github.com/metabase/metabase/issues/42540,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2120486817, 'issue_id': 2290478809, 'author': 'ranquild', 'body': 'Adding QC because this is cased by field references used in the viz settings; should be fixed by migrating them to aliases.', 'created_at': datetime.datetime(2024, 5, 20, 13, 40, 43, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-05-20 13:40:43 UTC): Adding QC because this is cased by field references used in the viz settings; should be fixed by migrating them to aliases.

"
2290320076,issue,closed,not_planned,"Cannot Link to Dashboard with ""Custom Click"" Behavior even if you have ""View"" Access to the Collection it's in","### Describe the bug

When you set a custom destination with ""On Click"" behavior you can set a URL, saved question or dashboard as the target. When you click ""Dashboard"" you're presented with a list of dashboards you can target.

- If you have ""View"" access to a Collection a dashboard is in then you cannot select it from the menu
- If you have ""Curate"" access the Collection the target dashboard is in then you can



### To Reproduce

1. Create a test collection (or use ""Our Analytics"")
2. In the test collection create ""Target Dashboard""
3. Set collection access for the ""All Users"" group to ""View"" for the test collection
4. Log in as a non admin user
5. From any dashboard this user can edit add ""custom click"" behavior to one of the cards
6. Select ""Dashboard"" as the destination
7. Note that the dashboard in the test collection is not selectable as a destination


### Expected behavior

You should be able to link to a dashboard if you can otherwise view it.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying - you can partially work around it with the ""URL"" option but you miss out on fitler customization options that are available if you choose the dashboard from a list

### Additional context

_No response_",ixipixi,2024-05-10 19:50:04+00:00,[],2024-07-22 16:12:51+00:00,2024-07-22 16:12:51+00:00,https://github.com/metabase/metabase/issues/42534,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2243330739, 'issue_id': 2290320076, 'author': 'kulyk', 'body': 'Can no longer reproduce, think it was fixed with the new entity picker', 'created_at': datetime.datetime(2024, 7, 22, 16, 12, 51, tzinfo=datetime.timezone.utc)}]","kulyk on (2024-07-22 16:12:51 UTC): Can no longer reproduce, think it was fixed with the new entity picker

"
2290175183,issue,open,,[Epic] Support entity-id in URLs,[Product doc](https://www.notion.so/metabase/Stable-IDs-across-environments-a22f44c02f02452aa28a3ad0c172c543?pvs=4),luizarakaki,2024-05-10 18:00:54+00:00,[],2024-10-03 01:28:58+00:00,,https://github.com/metabase/metabase/issues/42528,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2290174572,issue,closed,completed,[Epic] Improve Info Sidebars + Introduce Sidesheets,"Docs
- [Product Doc](https://www.notion.so/metabase/Rework-the-info-sidebar-and-entity-actions-9df9b242aef24c9babe3f27b45f61056)
- [Technical Design](https://www.notion.so/metabase/Sidesheets-for-Questions-Dashboards-and-Collections-c26fe9183d074356808fad00de27c58a)
- [Figma Designs](https://www.figma.com/design/NOCVfjRaqkVhNqNq8jL9mX/Rework-the-info-sidebar-and-entity-actions?node-id=917-6517&t=7giObEhGrQ7hOcok-0)


```[tasklist]
### Milestone 0: Design + Planning
- [x] Investigate Existing Sidebar code
- [x] Tech Design Document
- [x] Testing Plan
```

```[tasklist]
### Milestone 1: Actions Menu Changes
- [ ] https://github.com/metabase/metabase/pull/46106
- [ ] https://github.com/metabase/metabase/issues/46252
- [ ] https://github.com/metabase/metabase/issues/46096
- [ ] https://github.com/metabase/metabase/issues/46191
- [ ] https://github.com/metabase/metabase/issues/46192
```

```[tasklist]
### Milestone 2: Side Sheets
- [ ] https://github.com/metabase/metabase/issues/46639
- [ ] https://github.com/metabase/metabase/issues/47132
- [ ] https://github.com/metabase/metabase/issues/47130
- [ ] https://github.com/metabase/metabase/issues/47131
- [ ] https://github.com/metabase/metabase/issues/47133
- [ ] https://github.com/metabase/metabase/issues/47673
- [ ] https://github.com/metabase/metabase/issues/47674
- [ ] https://github.com/metabase/metabase/issues/47919
- [ ] https://github.com/metabase/metabase/issues/47904
- [ ] https://github.com/metabase/metabase/issues/48099
- [ ] https://github.com/metabase/metabase/issues/48100
- [ ] https://github.com/metabase/metabase/issues/48174
- [ ] https://github.com/metabase/metabase/pull/47871
```",luizarakaki,2024-05-10 18:00:25+00:00,"['rafpaf', 'iethree']",2024-11-05 13:47:28+00:00,2024-11-05 13:47:28+00:00,https://github.com/metabase/metabase/issues/42527,"[('.Epic', 'Feature Implementation or Project')]",[],
2290087038,issue,closed,not_planned,Metabase is deleting the information uploaded by csv,"**Describe the bug**
2 days ago I uploaded several csv files and generated 3 different tables in my manuable-cross-table database
* zips
* labels
* tracking_info

but today the information disappeared, and the same thing happened to me before

**Logs**
```sql
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:00-06:00 INFO metabase.sync.util STARTING: Sync metadata for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-dbms-version'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-dbms-version'' for postgres Database 166 ''manuable-cross-table'' (178,7 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-timezone'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-timezone'' for postgres Database 166 ''manuable-cross-table'' (236,6 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-tables'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.sync-metadata.sync-timezone :postgres database 166 default timezone is ""GMT""
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-tables'' for postgres Database 166 ''manuable-cross-table'' (3,3 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-fields'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-fields'' for postgres Database 166 ''manuable-cross-table'' (1,2 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-fks'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-fks'' for postgres Database 166 ''manuable-cross-table'' (3,9 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-indexes'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-indexes'' for postgres Database 166 ''manuable-cross-table'' (1,9 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-metabase-metadata'' for postgres Database 166 ''manuable-cross-table'' (37,0 µs)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-metabase-metadata'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''sync-table-privileges'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''sync-table-privileges'' for postgres Database 166 ''manuable-cross-table'' (123,8 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: Sync metadata for postgres Database 166 ''manuable-cross-table'' (958,1 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: Analyze data for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''fingerprint-fields'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''classify-fields'' for postgres Database 166 ''manuable-cross-table'' (27,3 µs)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''classify-tables'' for postgres Database 166 ''manuable-cross-table'' (30,5 µs)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: step ''fingerprint-fields'' for postgres Database 166 ''manuable-cross-table'' (1,9 ms)
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''classify-fields'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util STARTING: step ''classify-tables'' for postgres Database 166 ''manuable-cross-table''
[26e84b0b-4caa-436c-a8ce-017136b1bc4f] 2024-05-10T08:04:01-06:00 INFO metabase.sync.util FINISHED: Analyze data for postgres Database 166 ''manuable-cross-table'' (21,1 ms)
```

**To Reproduce**
Steps to reproduce the behavior:
1. have csv uploads enabled
2. upload a csv correctly
3. wait 2 days

**Expected behavior**
You should no longer have any tables in your database.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
We are about to begin a process to analyze external information that is not in our databases, to audit whether our margins are correct in real time. It would be very useful for me if you could support me as soon as possible.

**Additional context**
A new database was created on Amazon, only for csv uploads in metabase. This was the selected instance db.t3.micro

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",ingluisandres,2024-05-10 16:55:29+00:00,[],2024-05-20 18:15:45+00:00,2024-05-20 18:15:45+00:00,https://github.com/metabase/metabase/issues/42524,"[('Type:Bug', 'Product defects'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2105289618, 'issue_id': 2290087038, 'author': 'paoliniluis', 'body': 'Hi, Metabase does not issue a drop table, can you search for those tables with a database gui?', 'created_at': datetime.datetime(2024, 5, 10, 21, 24, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120514797, 'issue_id': 2290087038, 'author': 'darksciencebase', 'body': '@ingluisandres was it by any chance the Sample Database that was set as the destination for uploads?', 'created_at': datetime.datetime(2024, 5, 20, 13, 55, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120957773, 'issue_id': 2290087038, 'author': 'calherries', 'body': ""This isn't the sample database, based on the diagnostic info this is a postgres DB. \r\n\r\nSomething else must be causing the tables to be dropped from the database other than Metabase. The only `DROP TABLE` calls in Metabase 49.8 are used on persisted model tables, or to clean up new upload tables immediately after a failed upload. I'm removing the P1 and closing the issue for this reason."", 'created_at': datetime.datetime(2024, 5, 20, 18, 13, 55, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-10 21:24:58 UTC): Hi, Metabase does not issue a drop table, can you search for those tables with a database gui?

darksciencebase on (2024-05-20 13:55:40 UTC): @ingluisandres was it by any chance the Sample Database that was set as the destination for uploads?

calherries on (2024-05-20 18:13:55 UTC): This isn't the sample database, based on the diagnostic info this is a postgres DB. 

Something else must be causing the tables to be dropped from the database other than Metabase. The only `DROP TABLE` calls in Metabase 49.8 are used on persisted model tables, or to clean up new upload tables immediately after a failed upload. I'm removing the P1 and closing the issue for this reason.

"
2290064739,issue,open,,Consolidate the query execution REST API endpoints,"We have way to many different endpoints for running queries, the problem is every time we want to change one thing we have to change like 6 or 12 endpoints instead of just one. Example: PR #41668, made more difficult because we have so many endpoints that need to change

See my tech design doc for more information https://www.notion.so/metabase/Query-Processor-API-Simplification-480e2c46dcf94232b3ece5b9b89449c4 ",camsaul,2024-05-10 16:43:00+00:00,[],2025-02-04 20:29:48+00:00,,https://github.com/metabase/metabase/issues/42523,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/Processor', ''), ('Misc/API', ''), ('.Backend', ''), ('.DX', 'Developer experience and QoL related.'), ('.Team/DevEx', '')]",[],
2289876431,issue,closed,completed,Cover `Offset()` in custom expressions with e2e tests,"Similar to #42452

This is going to v50, see [Slack thread](https://metaboat.slack.com/archives/C06P22KS4JH/p1715687283946849).

We should also make sure `Offset` is not available in filters",kamilmielnik,2024-05-10 14:44:54+00:00,['kamilmielnik'],2024-06-11 12:30:25+00:00,2024-05-21 06:37:46+00:00,https://github.com/metabase/metabase/issues/42511,"[('.CI & Tests', ''), ('.Team/Querying', '')]",[],
2289783610,issue,closed,not_planned,Limit clause breaks query results,"e2e repro in this PR: #42455 (test is skipped for now)

-----

Repro steps:
1. Create a question based on orders table
2. Add custom expression aggregation: `Offset(Sum([Total]), -1)`
3. Add a breakout by Orders > Created At: Month
4. Add a breakout by Products > Category
5. Visualize the query as a table - [it works as expected (5 columns, 193 rows)](https://github.com/metabase/metabase/assets/6830683/db383048-07e5-4245-9424-220a30da5b58)
6. Go back to notebook editor
7. Add row limit 5
8. Visualize the query

The [results have only 4 rows and 3 columns](https://github.com/metabase/metabase/assets/6830683/879f53a0-b109-4611-a2c0-f53a8db6a182) and the table has been transposed compared to results in step 5.

It's expected that the results will look the same as in step 5, but limited to 5 first rows.


",kamilmielnik,2024-05-10 13:53:59+00:00,['camsaul'],2024-08-28 02:09:47+00:00,2024-05-16 00:50:43+00:00,https://github.com/metabase/metabase/issues/42509,"[('Type:Bug', 'Product defects'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2113707564, 'issue_id': 2289783610, 'author': 'camsaul', 'body': 'Turns out query results are actually just fine, but the FE is visualizing things as a pivot table by default. Disabling pivot visualization shows you 5 rows\r\n\r\n![image](https://github.com/metabase/metabase/assets/1455846/0d63ba94-04ad-4af2-b83c-63f08ad7a4ab)', 'created_at': datetime.datetime(2024, 5, 16, 0, 46, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113707967, 'issue_id': 2289783610, 'author': 'camsaul', 'body': 'Note: you can easily verify that the QP returned 5 rows by looking at the response in the Network inspector', 'created_at': datetime.datetime(2024, 5, 16, 0, 47, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2113710154, 'issue_id': 2289783610, 'author': 'camsaul', 'body': 'Closing as not a bug\r\n\r\nSee Slack discussion for more info https://metaboat.slack.com/archives/C06P22KS4JH/p1715820619367019', 'created_at': datetime.datetime(2024, 5, 16, 0, 50, 43, tzinfo=datetime.timezone.utc)}]","camsaul (Assginee) on (2024-05-16 00:46:58 UTC): Turns out query results are actually just fine, but the FE is visualizing things as a pivot table by default. Disabling pivot visualization shows you 5 rows

![image](https://github.com/metabase/metabase/assets/1455846/0d63ba94-04ad-4af2-b83c-63f08ad7a4ab)

camsaul (Assginee) on (2024-05-16 00:47:34 UTC): Note: you can easily verify that the QP returned 5 rows by looking at the response in the Network inspector

camsaul (Assginee) on (2024-05-16 00:50:43 UTC): Closing as not a bug

See Slack discussion for more info https://metaboat.slack.com/archives/C06P22KS4JH/p1715820619367019

"
2289658670,issue,closed,completed,"Localize the name ""Trash""",,johnswanson,2024-05-10 12:40:06+00:00,['johnswanson'],2024-05-13 22:35:26+00:00,2024-05-13 22:35:26+00:00,https://github.com/metabase/metabase/issues/42505,[],[],
2289575861,issue,closed,completed,[Epic] Improve navigation and behavior for multi-select text filters,"**Links**
- [Product doc](https://www.notion.so/Offer-the-ability-to-select-multiple-values-for-all-text-filters-e41ed1d75702473683967ba57dd3a331?pvs=24)
- [Eng doc](https://www.notion.so/metabase/Tech-Selecting-multiple-values-for-all-text-filters-83aa3b8a803741e2b2e94e242cec85f3)
- Feature branch: None needed. We should be able to merge any of the tasks below independently to `master`.

**Implementation Plan**
Introduce new behavior, and improve the existing UX. These changes should apply to ""is"", ""is not"", ""contains"", ""starts with"" and ""ends with"" filters.
```[tasklist]
### Notebook and Chill mode editor
- [ ] https://github.com/metabase/metabase/issues/42783
```

```[tasklist]
### Dashboard filter input
- [ ] https://github.com/metabase/metabase/issues/43290
```

",nemanjaglumac,2024-05-10 11:45:31+00:00,['romeovs'],2024-06-17 06:38:55+00:00,2024-06-14 10:38:10+00:00,https://github.com/metabase/metabase/issues/42504,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2289574291,issue,closed,completed,use RTK Query for model-indexes API,,ranquild,2024-05-10 11:44:23+00:00,['npfitz'],2024-07-10 20:12:20+00:00,2024-07-10 20:12:07+00:00,https://github.com/metabase/metabase/issues/42503,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2289447548,issue,closed,completed,Columns are excluded from the unformatted option when downloading,"### Describe the bug

Columns are excluded form the formatted/unformatted option when downloading ... External systems are expecting an unformatted column which used to be downloaded before 48 differently when it does now in 49

### To Reproduce

1. Go to New -> Question -> Orders -> Save
2. Go to Total Column -> Rename it to ->  ""This is a formatted column""

<img width=""1492"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/336d8596-0207-4e98-81a3-f0dd65465652"">

3. Download the question using unformatted option, notice the name remains the same even though results themself change:

<img width=""1497"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/003e9e9c-72a3-4a13-9589-9d788deced17"">


### Expected behavior

If you download unformatted results then nothing should keep the formatting. Applies for Question, Dashboards and anywhere else we offer the unformatted option

### Logs

Nothing that is relevant

### Information about your Metabase installation

```JSON
1.49.9 and master
```


### Severity

Blocker since external systems are expecting an unformatted column which used to be downloaded before 48 differently when it does now in 49

### Additional context

_No response_",Tony-metabase,2024-05-10 10:21:53+00:00,['adam-james-v'],2024-05-10 23:42:22+00:00,2024-05-10 23:39:05+00:00,https://github.com/metabase/metabase/issues/42500,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('.Escalation', '')]",[],
2289392862,issue,closed,completed,Automate releasing Metabase Embedding SDK for React,"### References
- Here's the [Slack discussion](https://metaboat.slack.com/archives/C063Q3F1HPF/p1715336732339349?thread_ts=1715336587.301399&cid=C063Q3F1HPF) about this workflow
- [Notion doc](https://www.notion.so/metabase/WIP-Embedding-SDK-8103306366be4f0786b489ad2324235c#a30196689237423f95856f0a802e9379)

### Here are the steps to release the SDK:
1. Create [embedding-sdk-0.1.x](https://github.com/metabase/metabase/releases/tag/embedding-sdk-0.1.0) tag
2. Build uberjar from the tag https://github.com/metabase/metabase/actions/workflows/uberjar.yml
3. Unzip uberjar and upload it to the S3 [https://downloads.metabase.com/sdk/v0.1.x/metabase.jar](https://downloads.metabase.com/sdk/v0.1.0/metabase.jar)
4. Update readme https://github.com/metabase/metabase/blob/master/enterprise/frontend/src/embedding-sdk/README.md
5. [Publishing to NPM](https://www.notion.so/metabase/WIP-Embedding-SDK-8103306366be4f0786b489ad2324235c?pvs=4#fc907bb1beb74c21b27a3c041140420f)

",WiNloSt,2024-05-10 09:47:47+00:00,['WiNloSt'],2024-05-16 13:21:11+00:00,2024-05-16 13:21:11+00:00,https://github.com/metabase/metabase/issues/42498,"[('.CI & Tests', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2289320882,issue,open,,Multi threaded for static viz,"GraalVM can only be multithreaded if each thread creates its own context. Currently, we initialized context once and reuse it across threads([1](https://github.com/metabase/metabase/blob/3db3f29c1f5775adc19099ec9da5cf15c6981c9f/src/metabase/pulse/render/js_svg.clj#L37)), ([2](https://github.com/metabase/metabase/blob/3db3f29c1f5775adc19099ec9da5cf15c6981c9f/src/metabase/pulse/render/color.clj#L18)).

This is not thread-safe, and since we made pulses sent in parallel in #41772, this problem started to surface ([thread](https://metaboat.slack.com/archives/C05MPF0TM3L/p1715247921215309)).

To work around that, we put a lock to`context` whenever we execute a JS function([ref](https://github.com/metabase/metabase/blob/thread-safe-static-viz/src/metabase/pulse/render/js_engine.clj#L54)). This fixes the issue, but it creates a bottleneck when rendering static viz as everything become synchronized.

Having a context for a thread does not work well because the `static-viz-context` eats 120MiB and takes 1.3 seconds to load. If we have multiple threads, each spawning a context, we'll start seeing a bunch of OOM.

Ideally, we should have a resource pool for context, and it'd be even better if this resource pool will auto clean up after some time and only keep one context around.",qnkhuat,2024-05-10 09:03:38+00:00,[],2024-05-10 09:46:26+00:00,,https://github.com/metabase/metabase/issues/42496,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('.Backend', ''), ('Visualization/Static', 'Subscriptions/pulse generated image')]",[],
2288319009,issue,closed,completed,[Epic] Small JWT improvements,"~Maybe we should fix https://github.com/metabase/metabase-private/issues/51 too~ this actually works

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/28646
- [ ] https://github.com/metabase/metabase/issues/43971
```
",luizarakaki,2024-05-09 19:30:10+00:00,['noahmoss'],2024-11-19 18:34:21+00:00,2024-11-19 18:34:20+00:00,https://github.com/metabase/metabase/issues/42479,"[('.Epic', 'Feature Implementation or Project'), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT')]","[{'comment_id': 2486461226, 'issue_id': 2288319009, 'author': 'luizarakaki', 'body': 'Closing this. We might work on #28646 another time', 'created_at': datetime.datetime(2024, 11, 19, 18, 34, 20, tzinfo=datetime.timezone.utc)}]","luizarakaki (Issue Creator) on (2024-11-19 18:34:20 UTC): Closing this. We might work on #28646 another time

"
2288273909,issue,closed,completed,[BE] [QP] Check which drivers lose metric support because of nested queries,"- [x] Athena via sql-jdbc
- [x] BigQueryCloudSDK via sql
- [ ] Druid
- [x] Druid-JDBC via sql-jdbc 
- [x] H2 via sql-jdbc
- [x] Mongo
- [x] MySQL via sql-jdbc
- [x] Oracle via sql-jdbc
- [x] Postgres via sql-jdbc
- [x] Presto-JDBC via sql-jdbc
- [x] Redshift via postgresql
- [x] Snowflake via sql-jdbc 
- [x] SparkSQL
- [x] SQLite via sql-jdbc
- [x] SQLServer via sql-jdbc
- [x] Vertica via sql-jdbc",metamben,2024-05-09 18:57:54+00:00,['metamben'],2024-05-16 18:14:17+00:00,2024-05-16 18:14:17+00:00,https://github.com/metabase/metabase/issues/42474,[],"[{'comment_id': 2115904588, 'issue_id': 2288273909, 'author': 'perivamsi', 'body': 'Only old druid does not support this (out of all the drivers we own)', 'created_at': datetime.datetime(2024, 5, 16, 18, 14, 17, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-05-16 18:14:17 UTC): Only old druid does not support this (out of all the drivers we own)

"
2288210676,issue,closed,completed,"[BE] [MBQL lib] Disallow joining metrics, cleanup","Remove suggested join conditions, automatically added aggregation clauses for metrics",ranquild,2024-05-09 18:13:18+00:00,['bshepherdson'],2024-05-13 13:57:52+00:00,2024-05-13 13:57:52+00:00,https://github.com/metabase/metabase/issues/42471,[],[],
2288203816,issue,closed,completed,[BE] [MBQL lib] Allow using compatible metrics for the source table,"Depends on https://github.com/metabase/metabase/issues/42462

Modify `availableMetrics`
- If `source-card` is a metric, return only it
- If `source-table` is a table, return all metrics compatible with this table (metrics v1 behavior). These metrics are passed in `table.metrics` as before 
	- Compatible means:
		- single stage metric
		- source table of question is the same source table of metric
		- only allowed on stage 0",ranquild,2024-05-09 18:08:53+00:00,['snoe'],2024-05-16 16:08:34+00:00,2024-05-16 16:08:34+00:00,https://github.com/metabase/metabase/issues/42470,[],[],
2288116571,issue,open,,[BE] [QP] Legacy metric cleanup,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/43093
- [ ] https://github.com/metabase/metabase/issues/43131
```
",ranquild,2024-05-09 17:14:53+00:00,['snoe'],2024-05-24 17:08:29+00:00,,https://github.com/metabase/metabase/issues/42464,[],[],
2288116369,issue,closed,completed,[FE] Disallow joining metrics,"1. Cannot join to a metric - always
2. If data source is a metric, then disallow joins completely on the first stage of the query
",ranquild,2024-05-09 17:14:45+00:00,['ranquild'],2024-05-13 13:30:51+00:00,2024-05-13 13:30:51+00:00,https://github.com/metabase/metabase/issues/42463,[],[],
2288113111,issue,closed,completed,[BE] [QP] Allow using compatible metrics for the source table,"Support v1 behavior:

- Return compatible metrics in /api/table/:id/query_metadata as before
- Allow referencing compatible metrics in queries without joins (previous behavior)
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/42667
- [ ] https://github.com/metabase/metabase/issues/42668
```
",ranquild,2024-05-09 17:12:42+00:00,['snoe'],2024-05-17 16:33:49+00:00,2024-05-17 16:33:48+00:00,https://github.com/metabase/metabase/issues/42462,[],[],
2288013841,issue,closed,not_planned,Email Reports showing incorrect data,"**Is your feature request related to a problem? Please describe.**
the email reports are not great quality.

I have seen emails where a graph is displayed fine then next week it is grayed out with that image silhouette.

The trials and repeats chart is just a normal line chart by quarter but it looks so bad and confusing with incorrect values in the email report.

**Describe the solution you'd like**
Fix the email to correctly display what is on the dashboard

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
11 /10 
We need to have proper automated emails

**Additional context**
This is so unbelievably vital for my organization and I believe very important for your platform to perfect to be a top data analysis platform imho, having automated reports with no error. This is a very important part of data reporting so this truly needs to be improved.

ty very much this is very important to me

<img width=""418"" alt=""Screenshot 2024-05-09 at 12 00 38 PM"" src=""https://github.com/metabase/metabase/assets/121153315/f8f62d33-186a-4adf-8637-7a5af1632de1"">


<img width=""56"" alt=""Screenshot 2024-05-09 at 12 05 39 PM"" src=""https://github.com/metabase/metabase/assets/121153315/e74adae3-151d-464f-b10f-e95b6a94930e"">
",OdinTallBeard,2024-05-09 16:08:55+00:00,[],2024-05-13 14:43:11+00:00,2024-05-13 14:43:11+00:00,https://github.com/metabase/metabase/issues/42460,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2107812034, 'issue_id': 2288013841, 'author': 'Tony-metabase', 'body': ""Yeah there are a lot of issues around Static Viz and line charts but most of those should be closed with release 50 since the StaticVic will convert to eCharts so we shouldn't have these kind of inconsistencies anymore. \r\n\r\nClosing as duplicate https://github.com/metabase/metabase/issues/30315"", 'created_at': datetime.datetime(2024, 5, 13, 14, 43, 5, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-05-13 14:43:05 UTC): Yeah there are a lot of issues around Static Viz and line charts but most of those should be closed with release 50 since the StaticVic will convert to eCharts so we shouldn't have these kind of inconsistencies anymore. 

Closing as duplicate https://github.com/metabase/metabase/issues/30315

"
2287832022,issue,closed,completed,"Pie chart tooltip ""Other"" group produces NaN%","### Describe the bug

Pie chart tooltip ""Other"" group produces NaN% and does not show values. Caused by https://github.com/metabase/metabase/pull/39180

<img width=""1017"" alt=""Screenshot 2024-05-09 at 11 35 42 AM"" src=""https://github.com/metabase/metabase/assets/14301985/ff2032e7-f15a-4a85-90b1-63aa9947aff7"">


### To Reproduce

1. New -> Orders -> Summarize by Total: 50 bins
2. Hover the ""Other"" slice
3. The tooltip shows NaN


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest master
```


### Severity

Makes it really hard to see what is grouped in the ""Other"" slice

",alxnddr,2024-05-09 14:37:26+00:00,['EmmadUsmani'],2024-05-13 15:55:29+00:00,2024-05-10 16:01:36+00:00,https://github.com/metabase/metabase/issues/42458,"[('Type:Bug', 'Product defects'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2287562962,issue,closed,completed,Cover `Offset()` in aggregations with e2e tests,See [Slack thread](https://metaboat.slack.com/archives/C06P22KS4JH/p1715082193980109?thread_ts=1715072591.646449&cid=C06P22KS4JH),kamilmielnik,2024-05-09 12:13:24+00:00,['kamilmielnik'],2024-05-13 11:04:22+00:00,2024-05-13 11:04:22+00:00,https://github.com/metabase/metabase/issues/42452,"[('.CI & Tests', ''), ('.Team/Querying', '')]",[],
2287431612,issue,open,,Duplicated series in chart after filter is removed,"### Describe the bug

Removing a post-aggregation filter causes duplication of data on a single series chart.

### To Reproduce

1. Create a GUI question: Orders, Summarize: Count of rows, Group by: Product --> Category
2. Add filter post aggregation: Product --> Category is not empty
3. Visualize: select Bar (or Row)
4. Save it
5. Edit the question and remove the filter
6. The series is now duplicated, and the error persists if the question is saved.
<img width=""757"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/f9b1aa20-4aad-4e3a-a46a-d94d8c0fd239"">


### Expected behavior

The duplication should not happen.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.49.8
```


### Severity

P1 or P2 - Reported by a customer. It seems to affect a common feature.

### Additional context

I couldn't reproduce this on stats as of 2024-05-08 / 1c5e599 .",zbodi74,2024-05-09 10:52:26+00:00,[],2024-05-29 20:55:53+00:00,,https://github.com/metabase/metabase/issues/42447,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2102821604, 'issue_id': 2287431612, 'author': 'calherries', 'body': 'This is an FE issue. \r\n\r\nFollowing the steps above, at step 4 these are the `visualization_settings` of the card:\r\n```\r\n    ""visualization_settings"": {\r\n        ""graph.dimensions"": [\r\n            ""CATEGORY""\r\n        ],\r\n        ""graph.metrics"": [\r\n            ""count""\r\n        ]\r\n    },\r\n```\r\nAfter saving at step 6, the `visualization_settings` have a duplicated count metric:\r\n```\r\n    ""visualization_settings"": {\r\n        ""graph.dimensions"": [\r\n            ""CATEGORY""\r\n        ],\r\n        ""graph.metrics"": [\r\n            ""count"",\r\n            ""count""\r\n        ]\r\n    },\r\n```', 'created_at': datetime.datetime(2024, 5, 9, 14, 53, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2138248013, 'issue_id': 2287431612, 'author': 'alxnddr', 'body': 'This has become slightly better after ECharts, however there is still two ""Count"" items in the sidebar:\n\n![Image](https://github.com/metabase/metabase/assets/14301985/95bcdf91-35d8-4bb4-be65-359a47321b65)', 'created_at': datetime.datetime(2024, 5, 29, 20, 55, 46, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-09 14:53:25 UTC): This is an FE issue. 

Following the steps above, at step 4 these are the `visualization_settings` of the card:
```
    ""visualization_settings"": {
        ""graph.dimensions"": [
            ""CATEGORY""
        ],
        ""graph.metrics"": [
            ""count""
        ]
    },
```
After saving at step 6, the `visualization_settings` have a duplicated count metric:
```
    ""visualization_settings"": {
        ""graph.dimensions"": [
            ""CATEGORY""
        ],
        ""graph.metrics"": [
            ""count"",
            ""count""
        ]
    },
```

alxnddr on (2024-05-29 20:55:46 UTC): This has become slightly better after ECharts, however there is still two ""Count"" items in the sidebar:

![Image](https://github.com/metabase/metabase/assets/14301985/95bcdf91-35d8-4bb4-be65-359a47321b65)

"
2287412186,issue,closed,completed,Resolve probable false positive with code scanning re: Druid driver ,"This looks like a false positive:

1. It refers to a pom file that doesn't exist in the repo.
2. It refers to a different version of the vertica driver to the one we package.
3. Printing out the dependency tree[^1] with the drivers on the class path doesn't show the old version of the affected package.

[^1]: `clj -A:dev:ee:ee-dev:drivers:drivers-dev:build  -Stree`

<!-- Warning: The suggested title contains the alert rule name. This can expose security information. -->

Tracking issue for:
- [ ] https://github.com/metabase/metabase/security/code-scanning/245
",crisptrutski,2024-05-09 10:41:06+00:00,[],2024-05-16 06:10:47+00:00,2024-05-16 06:10:47+00:00,https://github.com/metabase/metabase/issues/42446,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2102416971, 'issue_id': 2287412186, 'author': 'crisptrutski', 'body': ""Created this to avoid wasting other people's time on investigating. Hopefully the scanner auto-resolves this shortly."", 'created_at': datetime.datetime(2024, 5, 9, 10, 42, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2114108427, 'issue_id': 2287412186, 'author': 'piranha', 'body': ""Pom files do not exist since they are created by a `.github/script/write-poms.sh` specifically to track deps with Snyk. :) But `pom.xml` in question refers `org.clojure/clojure 1.11.2` explicitly, so it doesn't really make any sense to me - I'm going to dismiss the alert."", 'created_at': datetime.datetime(2024, 5, 16, 6, 10, 47, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-05-09 10:42:06 UTC): Created this to avoid wasting other people's time on investigating. Hopefully the scanner auto-resolves this shortly.

piranha on (2024-05-16 06:10:47 UTC): Pom files do not exist since they are created by a `.github/script/write-poms.sh` specifically to track deps with Snyk. :) But `pom.xml` in question refers `org.clojure/clojure 1.11.2` explicitly, so it doesn't really make any sense to me - I'm going to dismiss the alert.

"
2287257870,issue,closed,completed,Add analytics events for combine and extract shortcuts,Add analytics events for combine and extract shortcut usage via viz table header.,romeovs,2024-05-09 09:13:11+00:00,['romeovs'],2024-05-13 13:52:55+00:00,2024-05-13 13:52:55+00:00,https://github.com/metabase/metabase/issues/42443,[],[],
2286627306,issue,closed,completed,"MB_JETTY_SKIP_SNI evaluating env variable as string instead of bool, always evaluating to truthy if set","### Describe the bug

Setting `MB_JETTY_SKIP_SNI` always evaluates to `false` if unset and always evaluates to `true` if set because `config/config-str` being used instead of `config/config-bool` for `:mb-jetty-skip-sni`.

- https://github.com/metabase/metabase/blob/master/src/metabase/server.clj#L21-L34

### To Reproduce

1. Generate a self-signed cert replacing `YOUR.HOSTNAME` with your hostname (can't be localhost and requires at least one `.` in the hostname. (May need to add a line to your `/etc/hosts` when using 127.0.0.1.)
```bash
# leave all prompted values for CN, CO, ST, etc. blank
$ keytool -keystore selfsigned-ip-cn-and-san-nohost.jks -storepass storepass -genkeypair -keyalg RSA -validity 365
```

2. Set Jetty to run with SSL like below:
```.env
MB_SITE_URL=https://YOUR.HOSTNAME:8443
MB_JETTY_SSL=true
MB_JETTY_SSL_PORT=8443
MB_JETTY_SSL_KEYSTORE=/app/selfsigned.jks
MB_JETTY_SSL_KEYSTORE_PASSWORD=storepass
MB_JETTY_SKIP_SNI=false
```

3. Set `MB_JETTY_SKIP_SNI` to any value (e.g. `false`, `""false""`, `true`, `""true""`, `abc123`)
4. Run Metabase
5. Metabase runs JETTY with SNI disabled
6. To verify behavior with SNI enabled, comment out `MB_JETTY_SKIP_SNI=false` in the .env file which defaults to false and should see an SNI error since the hostname won't match the certificate

### Expected behavior

- Expect these to set `:mb-jetty-skip-sni` to `false` and enable SNI:
  - `MB_JETTY_SKIP_SNI=false`
  - `MB_JETTY_SKIP_SNI=""false""`
  - not setting `MB_JETTY_SKIP_SNI` in the .env
- Expect these to set `:mb-jetty-skip-sni` to true and disable SNI:
  - `MB_JETTY_SKIP_SNI=true`
  - `MB_JETTY_SKIP_SNI=""true""`


### Logs

If SNI enabled and hostname doesn't match certificate, then expect to see below in logs:
<img width=""857"" alt=""image"" src=""https://github.com/metabase/metabase/assets/8808703/3a086989-623d-4fdc-9bb0-02234303ea92"">

If SNI disabled, expect to see nothing unusual in the logs

### Information about your Metabase installation

```JSON
- `master` as of `0468c9a7f5946c9a9d3b91ced5cee9a68d81533e`
- v1.49.8
```


### Severity

P1: Users unable to explicitly set MB_JETTY_SKIP_SNI to false
- Metabase could be deployed with `MB_JETTY_SKIP_SNI=false` explicitly requiring SNI to address a risk and SNI would be disabled, and there may be no indication to administrator that it was not working unless they tried to verify it which would be unusual.

### Additional context

https://metaboat.slack.com/archives/C052ZBWRG3W/p1715096284142429",likeshumidity,2024-05-08 23:14:53+00:00,['noahmoss'],2024-06-25 19:19:51+00:00,2024-06-25 14:00:25+00:00,https://github.com/metabase/metabase/issues/42435,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Operation/Environment variables', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2101932910, 'issue_id': 2286627306, 'author': 'likeshumidity', 'body': 'On the fence re: P1 vs P2, so can downgrade if needed. It seems most modern browsers warn users if SNI not enabled with a ""your connection is not private"" message or similar. But seems like an easy fix as well re: one line change.', 'created_at': datetime.datetime(2024, 5, 9, 4, 56, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189398314, 'issue_id': 2286627306, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.7](https://github.com/metabase/metabase/milestone/243)', 'created_at': datetime.datetime(2024, 6, 25, 16, 22, 56, tzinfo=datetime.timezone.utc)}]","likeshumidity (Issue Creator) on (2024-05-09 04:56:03 UTC): On the fence re: P1 vs P2, so can downgrade if needed. It seems most modern browsers warn users if SNI not enabled with a ""your connection is not private"" message or similar. But seems like an easy fix as well re: one line change.

github-actions[bot] on (2024-06-25 16:22:56 UTC): 🚀 This should also be released by [v0.50.7](https://github.com/metabase/metabase/milestone/243)

"
2286555589,issue,closed,not_planned,[Epic] Modular Backend,"[https://www.notion.so/metabase/Backend-Modularization-2025-Plan-17669354c90180b98bd4eb9c8ccf2395](https://www.notion.so/metabase/Backend-Modularization-2025-Plan-17669354c90180b98bd4eb9c8ccf2395)

```[tasklist]
- [ ] #42250
- [ ] #42433
- [ ] https://github.com/metabase/metabase/pull/42436
- [ ] https://github.com/metabase/metabase/pull/42437
- [ ] https://github.com/metabase/metabase/pull/42468
- [ ] https://github.com/metabase/metabase/pull/42469
- [ ] https://github.com/metabase/metabase/pull/42487
- [ ] https://github.com/metabase/metabase/pull/42491
- [ ] https://github.com/metabase/metabase/pull/48640
- [ ] https://github.com/metabase/metabase/pull/50839
- [ ] [Backend modularization] `enterprise/advanced-config`
- [ ] [Backend modularization] `enterprise/advanced-permissions`
- [ ] [Backend modularization] `enterprise/airgap`
- [ ] [Backend modularization] `enterprise/advanced-config`
- [ ] [Backend modularization] `enterprise/advanced-permissions`
- [ ] [Backend modularization] `enterprise/airgap`
- [ ] [Backend modularization] `enterprise/api`
- [ ] [Backend modularization] `enterprise/audit-app`
- [ ] [Backend modularization] `enterprise/auth-provider`
- [ ] [Backend modularization] `enterprise/billing`
- [ ] [Backend modularization] `enterprise/cache`
- [ ] [Backend modularization] `enterprise/content-verification`
- [ ] [Backend modularization] `enterprise/core`
- [ ] [Backend modularization] `enterprise/dashboard-subscription-filters`
- [ ] [Backend modularization] `enterprise/enhancements`
- [ ] [Backend modularization] `enterprise/llm`
- [ ] https://github.com/metabase/metabase/issues/52183
- [ ] [Backend modularization] `enterprise/query-reference-validation`
- [ ] [Backend modularization] `enterprise/sandbox`
- [ ] [Backend modularization] `enterprise/scim`
- [ ] [Backend modularization] `enterprise/search`
- [ ] [Backend modularization] `enterprise/serialization`
- [ ] [Backend modularization] `enterprise/snippet-collections`
- [ ] [Backend modularization] `enterprise/sso`
- [ ] [Backend modularization] `enterprise/stale`
- [ ] [Backend modularization] `enterprise/stats`
- [ ] [Backend modularization] `enterprise/task`
- [ ] [Backend modularization] `enterprise/upload-management`
- [ ] https://github.com/metabase/metabase/issues/52169
- [ ] [Backend modularization] `analytics`
- [ ] https://github.com/metabase/metabase/issues/52178
- [ ] [Backend modularization] `api`
- [ ] https://github.com/metabase/metabase/issues/52224
- [ ] [Backend modularization] `audit`
- [ ] [Backend modularization] `auth-provider`
- [ ] https://github.com/metabase/metabase/issues/52154
- [ ] https://github.com/metabase/metabase/issues/52238
- [ ] [Backend modularization] `cmd`
- [ ] https://github.com/metabase/metabase/issues/52176
- [ ] [Backend modularization] `config`
- [ ] https://github.com/metabase/metabase/issues/52153
- [ ] https://github.com/metabase/metabase/issues/52174
- [ ] [Backend modularization] `driver`
- [ ] [Backend modularization] `eid-translation`
- [ ] https://github.com/metabase/metabase/issues/52237
- [ ] [Backend modularization] `embed`
- [ ] [Backend modularization] `events`
- [ ] [Backend modularization] `formatter`
- [ ] [Backend modularization] `integrations`
- [ ] https://github.com/metabase/metabase/issues/53281
- [x] [Backend modularization] `lib`
- [ ] [Backend modularization] `logger`
- [ ] https://github.com/metabase/metabase/issues/52166
- [ ] [Backend modularization] `models`
- [ ] [Backend modularization] `moderation`
- [ ] [Backend modularization] `notification`
- [ ] https://github.com/metabase/metabase/issues/52926
- [ ] [Backend modularization] `plugins`
- [x] [Backend modularization] `premium-features`
- [ ] [Backend modularization] `public-settings`
- [ ] [Backend modularization] `pulse`
- [ ] https://github.com/metabase/metabase/issues/52164
- [ ] [Backend modularization] `query-processor`
- [ ] https://github.com/metabase/metabase/issues/52142
- [x] [Backend modularization] `request`
- [ ] https://github.com/metabase/metabase/issues/52152
- [x] [Backend modularization] `search`
- [x] [Backend modularization] `server`
- [ ] https://github.com/metabase/metabase/issues/52232
- [ ] https://github.com/metabase/metabase/issues/52250
- [ ] [Backend modularization] `task`
- [ ] https://github.com/metabase/metabase/issues/52172
- [ ] [Backend modularization] `types`
- [ ] [Backend modularization] `upload`
- [ ] [Backend modularization] `util`
- [ ] https://github.com/metabase/metabase/issues/52146
```",camsaul,2024-05-08 22:01:58+00:00,['camsaul'],2025-02-07 22:19:12+00:00,2025-02-07 22:19:10+00:00,https://github.com/metabase/metabase/issues/42434,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Epic', 'Feature Implementation or Project'), ('.DX', 'Developer experience and QoL related.'), ('.Team/DevEx', '')]","[{'comment_id': 2644231847, 'issue_id': 2286555589, 'author': 'camsaul', 'body': 'Closing this in favor of https://linear.app/metabase/project/backend-modularization-c89167255eb3', 'created_at': datetime.datetime(2025, 2, 7, 22, 19, 10, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2025-02-07 22:19:10 UTC): Closing this in favor of https://linear.app/metabase/project/backend-modularization-c89167255eb3

"
2286457922,issue,closed,completed,[dc.js migration] Inability to configure x-axis for a chart,https://metaboat.slack.com/archives/C05MPF0TM3L/p1715200193398569,alxnddr,2024-05-08 20:59:18+00:00,[],2024-05-09 23:00:33+00:00,2024-05-09 23:00:32+00:00,https://github.com/metabase/metabase/issues/42429,"[('Type:Bug', 'Product defects'), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2103574860, 'issue_id': 2286457922, 'author': 'alxnddr', 'body': 'Intentional behavior', 'created_at': datetime.datetime(2024, 5, 9, 23, 0, 32, tzinfo=datetime.timezone.utc)}]","alxnddr (Issue Creator) on (2024-05-09 23:00:32 UTC): Intentional behavior

"
2286404309,issue,closed,not_planned,[FE] [Bug] Cannot reference aggregation columns in custom aggregation expressions in metric queries,"Repro https://github.com/metabase/metabase/blob/0ec58b90218f06d3ab8fbec60068b4393885bc47/e2e/test/scenarios/metrics/metrics-editing.cy.spec.ts#L182

<img width=""914"" alt=""Screenshot 2024-05-08 at 16 35 50"" src=""https://github.com/metabase/metabase/assets/8542534/94ef2b30-bab0-4e84-bcd5-bd4e58502f06"">
",ranquild,2024-05-08 20:36:30+00:00,['ranquild'],2024-05-09 19:03:11+00:00,2024-05-09 19:03:10+00:00,https://github.com/metabase/metabase/issues/42425,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Notebook/Custom Expression', '')]","[{'comment_id': 2103249150, 'issue_id': 2286404309, 'author': 'ranquild', 'body': 'This is actually existing and intended behavior.', 'created_at': datetime.datetime(2024, 5, 9, 19, 3, 10, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-05-09 19:03:10 UTC): This is actually existing and intended behavior.

"
2286177856,issue,closed,not_planned,[FE] [Bug] Order by and Limit clauses from metric queries are ignored,"Repro 
https://github.com/metabase/metabase/blob/9be6e6e31922c59b6e7484d6c366a169acbd6551/e2e/test/scenarios/metrics/metrics-creation.cy.spec.ts#L251
https://github.com/metabase/metabase/blob/7b4f8ad8af39b6f651d2cd715464a016abdac877/e2e/test/scenarios/metrics/metrics-creation.cy.spec.ts#L251

Currently when adding an order by or limit clause to the last stage of the metric query they are silently ignored. I see the following options:
1. Do nothing. In this case adding an order by or limit clause is pointless and only confuses the user.
2. **Copy it as a default value when creating a query based on the metric.** It would follow our existing approach (we copy breakout clauses). This would be an MBQL lib change.
3. Do not copy it but silently apply as the default value for `limit` on the first stage of the query that uses the metric, and copy all order by clauses to the preprocessed query. This can be done in the QP. 
4. Hide order by and limit steps from the notebook for the last stage of metric queries. This results in weird UX for multi-stage metrics as you need to add something on the second stage of the query first to be able to sort and limit data.

",ranquild,2024-05-08 18:19:03+00:00,[],2024-05-09 18:16:47+00:00,2024-05-09 18:16:47+00:00,https://github.com/metabase/metabase/issues/42416,"[('Type:Bug', 'Product defects'), ('Querying/Processor', '')]",[],
2286008326,issue,closed,completed,Fix very flaky questionpicker test,"https://github.com/metabase/metabase/actions/runs/9003645519/job/24734765476#step:5:934

[Slack Message](https://metaboat.slack.com/archives/C5XHN8GLW/p1715186240363589?thread_ts=1715181680.408789&cid=C5XHN8GLW)",iethree,2024-05-08 16:39:38+00:00,['iethree'],2024-05-08 17:46:58+00:00,2024-05-08 17:46:57+00:00,https://github.com/metabase/metabase/issues/42410,"[('Type:Bug', 'Product defects'), ('.CI & Tests', ''), ('flaky-test-fix', '')]",[],
2285945892,issue,open,,Default or Parameterized Filters on Questions,"I'm super excited to see more date filtering options coming to dashboard filters, and I love that I can set a default filter on a dashboard, but sometimes, I want a default filter on a question. Right now, the only way to do this is with a SQL parameter, but I'd really like to be able to do this in the GUI. This [issue](https://github.com/metabase/metabase/issues/1543) is related and a possible solution, but I'm opening a new issue because I don't think it's the only solution to this problem.

Use case:
I have a dashboard where most often, I want to view the current quarter's data. Sometimes, I want to view a past quarter. I can set my dashboard filters to default to the current quarter, but to make the functionality work so that I can also filter to last quarter, the questions on that dashboard have to show all data--they can't be filtered to the current quarter, or I'll end up with a combination of filters that shows no data. 

Now, I have a bunch of questions that can be filtered to current quarter, but they default to displaying all quarters (pretty ugly for a bunch of WoW trends that are designed to show 1 quarter at a time). 

Ideally, these questions would have a filter that defaults to the current quarter (or whatever default I want to set) without that filter cascading into the dashboards that question is on--so when users go to view each individual questions (from search or nav in Our Analytics), they default to Current Quarter, and could easily adjust to past quarters, and they could do the same separately on a dashboard containing that question. This might be through parameterization on GUI questions, but could also be its own functionality more like dashboard filters.

One other nice to have here: some sort of visual distinction between filters/parameters that are meant to be changed, and the ones I've put in place to ensure data quality. I think the parameter boxes on SQL questions are good for this (and my users aren't going in to edit SQL), but on GUI questions, I'll often have filters for test data, etc that aren't really meant to be edited, and in the same display, filters for dates or customer categories. This makes it hard for my end users to figure out what's ""safe"" for them to self-serve.",megansmcguire,2024-05-08 16:04:14+00:00,[],2025-02-04 20:30:35+00:00,,https://github.com/metabase/metabase/issues/42409,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/GUI', 'Query builder catch-all, including simple mode')]","[{'comment_id': 2103466644, 'issue_id': 2285945892, 'author': 'notrom', 'body': ""> One other nice to have here: some sort of visual distinction between filters/parameters that are meant to be changed, and the ones I've put in place to ensure data quality.\r\n\r\nI like this suggestion. I often build that sort of question as a model with the static filters applied at that level, then the user can add their filters on top of that without touching my intentional filters. That does make me add more models which I have to manage going forward but it generally works quite well."", 'created_at': datetime.datetime(2024, 5, 9, 21, 45, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2155283392, 'issue_id': 2285945892, 'author': 'ignacio-mb', 'body': 'Related to https://github.com/metabase/metabase/issues/2763', 'created_at': datetime.datetime(2024, 6, 7, 17, 59, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316296664, 'issue_id': 2285945892, 'author': 'paoliniluis', 'body': ""isn't this the definition of a metric or a segment in Metabase?"", 'created_at': datetime.datetime(2024, 8, 28, 21, 40, 2, tzinfo=datetime.timezone.utc)}]","notrom on (2024-05-09 21:45:43 UTC): I like this suggestion. I often build that sort of question as a model with the static filters applied at that level, then the user can add their filters on top of that without touching my intentional filters. That does make me add more models which I have to manage going forward but it generally works quite well.

ignacio-mb on (2024-06-07 17:59:44 UTC): Related to https://github.com/metabase/metabase/issues/2763

paoliniluis on (2024-08-28 21:40:02 UTC): isn't this the definition of a metric or a segment in Metabase?

"
2285941262,issue,closed,not_planned,Feature request: visible entity IDs for every entity created in the system ,"Hi guys,

Hope it's okay to drop in with another feature request. As I roll out Metabase, these are coming to me organically from time to time.

Something that strikes me is that as the system begins to scale, it quickly becomes hard to retrieve visualisations through the ""quick"" mechanisms of searching in the search bar and choosing from one of the dropdown populations.

Something I think that would be very valuable: every ""entity"" that you create (whether that's a dashboard, a question, a model) has an entity ID (I imagine this already exists in the backend).

Here are a couple of ideas for how this could be useful:

1: Permalink masking: visit yourmetabase.com/[entityid] to jump to the target URL 

2: To expedite retrieval of the right visuals between colleagues. For example, I could tell a colleague to search for 12345. If this retrieved the desired entity there would be no chance of ambiguity if objects with similar names were stored in the system. 

- Daniel
",danielrosehill,2024-05-08 16:01:34+00:00,[],2024-05-13 14:47:21+00:00,2024-05-13 14:47:21+00:00,https://github.com/metabase/metabase/issues/42408,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Needs Triage', '')]","[{'comment_id': 2107831820, 'issue_id': 2285941262, 'author': 'Tony-metabase', 'body': 'That\'s what happens actually. If you look at the URL when you try to edit a person, go to a dashbaord or even a collection:\r\n\r\n<img width=""1439"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/50b49c5e-98c7-4b96-b19b-e7701975a175"">\r\n\r\nYou will notice that each collection and so on will carry an ID that if placed in the proper URL it will render that object for that context.\r\n\r\nTo add with that there is also an entityID in the Table but that ID is used for Serialization purposes', 'created_at': datetime.datetime(2024, 5, 13, 14, 47, 21, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-05-13 14:47:21 UTC): That's what happens actually. If you look at the URL when you try to edit a person, go to a dashbaord or even a collection:

<img width=""1439"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/50b49c5e-98c7-4b96-b19b-e7701975a175"">

You will notice that each collection and so on will carry an ID that if placed in the proper URL it will render that object for that context.

To add with that there is also an entityID in the Table but that ID is used for Serialization purposes

"
2285928160,issue,open,,Impersonation - implement a feature to the control visibility of schemas and tables,"**Is your feature request related to a problem? Please describe.**
Schemas and table metadata is synchronized using the main connection credentials. However, with impersonation enabled, query access varies based on the database role assigned by impersonation to the user. Ideally, users should only see the schemas and tables they are entitled to query. 

**Describe the solution you'd like**
Provide a mechanism for admins to control the visibility of database resources (schemas, tables, columns(?)) for specific groups of users with impersonated access, so that this is in alignment with the effective data access of the user.

**Describe alternatives you've considered**
n/a

**How important is this feature to you?**
This is important for customers who need strict controls on the visibility of database resources, in addition to implementing row-level security.",zbodi74,2024-05-08 15:54:24+00:00,[],2025-02-04 20:30:27+00:00,,https://github.com/metabase/metabase/issues/42407,"[('Type:New Feature', ''), ('Administration/Impersonation', 'Role level security')]","[{'comment_id': 2101024207, 'issue_id': 2285928160, 'author': 'andresrecalde', 'body': ""Our ideal solution here is that when using impersonation, the permissions are all pushed down to the database. This would include RLS but also which schemas/tables the role has access to: if the group's role doesn't have select access to a table or view, it wouldn't be visible via the UI and attempting to query it directly would appear the same as if they attempted to query a non-existent object."", 'created_at': datetime.datetime(2024, 5, 8, 17, 3, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101274934, 'issue_id': 2285928160, 'author': 'paoliniluis', 'body': ""This is tricky, as when you enable impersonation Metabase doesn't know what the DB has access to..."", 'created_at': datetime.datetime(2024, 5, 8, 19, 24, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271740837, 'issue_id': 2285928160, 'author': 'ixipixi', 'body': 'Perhaps some option to hide the table in data permissions would work. Then admins could make the GUI mirror whatever they set up for impersonation?', 'created_at': datetime.datetime(2024, 8, 6, 17, 0, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598365229, 'issue_id': 2285928160, 'author': 'paoliniluis', 'body': 'Have a feeling that this is a FE thing (an admin should be able to select which schemas/tables to show to each group) cc @luizarakaki', 'created_at': datetime.datetime(2025, 1, 17, 13, 25, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598854372, 'issue_id': 2285928160, 'author': 'ixipixi', 'body': 'In some cases the inability to do this renders the Impersonation feature unusable.', 'created_at': datetime.datetime(2025, 1, 17, 17, 30, 28, tzinfo=datetime.timezone.utc)}]","andresrecalde on (2024-05-08 17:03:19 UTC): Our ideal solution here is that when using impersonation, the permissions are all pushed down to the database. This would include RLS but also which schemas/tables the role has access to: if the group's role doesn't have select access to a table or view, it wouldn't be visible via the UI and attempting to query it directly would appear the same as if they attempted to query a non-existent object.

paoliniluis on (2024-05-08 19:24:44 UTC): This is tricky, as when you enable impersonation Metabase doesn't know what the DB has access to...

ixipixi on (2024-08-06 17:00:04 UTC): Perhaps some option to hide the table in data permissions would work. Then admins could make the GUI mirror whatever they set up for impersonation?

paoliniluis on (2025-01-17 13:25:42 UTC): Have a feeling that this is a FE thing (an admin should be able to select which schemas/tables to show to each group) cc @luizarakaki

ixipixi on (2025-01-17 17:30:28 UTC): In some cases the inability to do this renders the Impersonation feature unusable.

"
2285903761,issue,open,,date_trunc in SQL returning last day of month with Snowflake,"### Describe the bug

When querying `timestamp_TZ` fields from Snowflake with Metabase's SQL query editor, the `date_trunc` feature returns the wrong truncated date. For example, `date_trunc('month',[date field])` will return 5pm the last day of the month. Similarly,`date_trunc('day',[date field])` returns the PRECEDING day at 5pm. This issue does NOT occur with `timestamp_NTZ` fields.

### To Reproduce

1. Go to the SQL query editor
2. Query the below in our database, or in any other database database query any timestamp_TZ field.
select  date_trunc('day',CREATED_DATE) as day,
            date_trunc('month',CREATED_DATE) as month,
            created_date
from salesforce.sf_opps
3. See the incorrect truncation of the created_date field.

### Expected behavior

Date_trunc should truncate the timestamp to the appropriate specified date part.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.214-202.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Moderate

### Additional context

_No response_",samgroner1,2024-05-08 15:41:15+00:00,[],2025-02-04 20:28:37+00:00,,https://github.com/metabase/metabase/issues/42406,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Browser:Chrome', ''), ('Querying/Native', 'The SQL/native query editor'), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2101120360, 'issue_id': 2285903761, 'author': 'calherries', 'body': ""This looks similar to [this](https://discourse.metabase.com/t/different-result-for-date-trunc-for-table-and-view-with-snowflake/23462/4) bug report.\r\n\r\nI have a theory the problem is related to the `TIMEZONE` parameter of snowflake ([docs](https://docs.snowflake.net/manuals/sql-reference/parameters.html#timezone)), since 5pm PST midnight GMT and the default value of this parameter is `America/Los_Angeles`.\r\n\r\n@samgroner1 can you check the result of this query in your database?\r\n```\r\nshow parameters like '%timezone%';\r\n```"", 'created_at': datetime.datetime(2024, 5, 8, 18, 2, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101151077, 'issue_id': 2285903761, 'author': 'samgroner1', 'body': 'Sure: \r\n<img width=""1162"" alt=""Screenshot 2024-05-08 at 2 12 03 PM"" src=""https://github.com/metabase/metabase/assets/169276251/8039f083-3fc9-4124-be07-f1c9624997c7""> \r\n<img width=""1072"" alt=""image"" src=""https://github.com/metabase/metabase/assets/169276251/8fdb915b-8d55-4500-a797-2e3c284bd768"">', 'created_at': datetime.datetime(2024, 5, 8, 18, 14, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101183958, 'issue_id': 2285903761, 'author': 'calherries', 'body': ""Thanks, that rules out my theory.\r\n\r\nCan you also try reproducing the issue reported [previously](https://discourse.metabase.com/t/different-result-for-date-trunc-for-table-and-view-with-snowflake/23462/4)? That would help confirm this is the same issue.\r\n\r\nSpecifically what is the result of:\r\n```\r\nCREATE OR REPLACE TABLE TEST_TABLE (DATE) AS (SELECT to_timestamp_tz(1673630797));\r\nSELECT date_trunc('week', date) FROM TEST_TABLE;\r\n```"", 'created_at': datetime.datetime(2024, 5, 8, 18, 30, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101279974, 'issue_id': 2285903761, 'author': 'samgroner1', 'body': 'See below, seems like the same issue (incorrect date_trunc of timestamp_tz)\r\n![image](https://github.com/metabase/metabase/assets/169276251/14a0a1ea-7ba9-4c49-8be1-8968cfe6b8e9)', 'created_at': datetime.datetime(2024, 5, 8, 19, 28, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101320424, 'issue_id': 2285903761, 'author': 'calherries', 'body': 'And does executing the same select statement in metabase yield ""January 8, 2023, 4:00 PM""?', 'created_at': datetime.datetime(2024, 5, 8, 19, 54, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2107705928, 'issue_id': 2285903761, 'author': 'samgroner1', 'body': ""@calherries Sorry, not sure if your previous question was asking to run in Metabase or Snowflake. I can't run that exact query in Metabase because it contains two statements, however I believe the below should be the same and it outputs January 7, 2023 4:00pm.\r\n![image](https://github.com/metabase/metabase/assets/169276251/374b20fd-c02e-4006-a950-d23d14e853e1)"", 'created_at': datetime.datetime(2024, 5, 13, 14, 18, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221234641, 'issue_id': 2285903761, 'author': 'tjfaust', 'body': 'I am having the same issue. Was any progress made? I do not have this issue when I run `date_trunc(\'month\',current_date())`\r\n\r\nThe raw value of the date field looks like `2023-08-18 23:32:41.000 +0000\'\r\n\r\n @samgroner1 @calherries \r\n<img width=""618"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1253854/8944021f-c276-4294-ad20-9cda5294adf9"">', 'created_at': datetime.datetime(2024, 7, 10, 19, 5, 38, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-08 18:02:31 UTC): This looks similar to [this](https://discourse.metabase.com/t/different-result-for-date-trunc-for-table-and-view-with-snowflake/23462/4) bug report.

I have a theory the problem is related to the `TIMEZONE` parameter of snowflake ([docs](https://docs.snowflake.net/manuals/sql-reference/parameters.html#timezone)), since 5pm PST midnight GMT and the default value of this parameter is `America/Los_Angeles`.

@samgroner1 can you check the result of this query in your database?
```
show parameters like '%timezone%';
```

samgroner1 (Issue Creator) on (2024-05-08 18:14:27 UTC): Sure: 
<img width=""1162"" alt=""Screenshot 2024-05-08 at 2 12 03 PM"" src=""https://github.com/metabase/metabase/assets/169276251/8039f083-3fc9-4124-be07-f1c9624997c7""> 
<img width=""1072"" alt=""image"" src=""https://github.com/metabase/metabase/assets/169276251/8fdb915b-8d55-4500-a797-2e3c284bd768"">

calherries on (2024-05-08 18:30:23 UTC): Thanks, that rules out my theory.

Can you also try reproducing the issue reported [previously](https://discourse.metabase.com/t/different-result-for-date-trunc-for-table-and-view-with-snowflake/23462/4)? That would help confirm this is the same issue.

Specifically what is the result of:
```
CREATE OR REPLACE TABLE TEST_TABLE (DATE) AS (SELECT to_timestamp_tz(1673630797));
SELECT date_trunc('week', date) FROM TEST_TABLE;
```

samgroner1 (Issue Creator) on (2024-05-08 19:28:07 UTC): See below, seems like the same issue (incorrect date_trunc of timestamp_tz)
![image](https://github.com/metabase/metabase/assets/169276251/14a0a1ea-7ba9-4c49-8be1-8968cfe6b8e9)

calherries on (2024-05-08 19:54:21 UTC): And does executing the same select statement in metabase yield ""January 8, 2023, 4:00 PM""?

samgroner1 (Issue Creator) on (2024-05-13 14:18:12 UTC): @calherries Sorry, not sure if your previous question was asking to run in Metabase or Snowflake. I can't run that exact query in Metabase because it contains two statements, however I believe the below should be the same and it outputs January 7, 2023 4:00pm.
![image](https://github.com/metabase/metabase/assets/169276251/374b20fd-c02e-4006-a950-d23d14e853e1)

tjfaust on (2024-07-10 19:05:38 UTC): I am having the same issue. Was any progress made? I do not have this issue when I run `date_trunc('month',current_date())`

The raw value of the date field looks like `2023-08-18 23:32:41.000 +0000'

 @samgroner1 @calherries 
<img width=""618"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1253854/8944021f-c276-4294-ad20-9cda5294adf9"">

"
2285863053,issue,open,,Allow customization of dashboard filter sort order when values come from connected fields or another question,"
When I set up a dashboard filter, I rarely want to maintain a manual list of options. Most recently, I've been configuring a dashboard filter based on our fiscal quarter name (displayed as a category from our DB--does not play well with date functions as it's offset by a month and calendar year (we just started Q2 FY25). When I set this up using the connected fields or using a question to generate the list (basically `select distinct FY-FQ from dates order by 1 desc), the sort order is automatically alphabetical, ascending. The only workaround I've found is to manually maintain the list. Ideally, I'd like to be able to customize the sort order for the dashboard filter drop down list--just an option on whether to sort Asc or Desc would make my dashboard user experience better.

",megansmcguire,2024-05-08 15:20:22+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/42403,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2356976674, 'issue_id': 2285863053, 'author': 'mattmattbci', 'body': 'Additionally, when using a saved question or model as the basis of a drop-down filter on a dashboard, the values sort alphabetically instead of just running the query in the saved question or model and respecting the sort order (ORDER BY clause) of that question/model.  That would be ideal to allow the results from the question to populate the filter without being re-ordered.', 'created_at': datetime.datetime(2024, 9, 17, 21, 34, 32, tzinfo=datetime.timezone.utc)}]","mattmattbci on (2024-09-17 21:34:32 UTC): Additionally, when using a saved question or model as the basis of a drop-down filter on a dashboard, the values sort alphabetically instead of just running the query in the saved question or model and respecting the sort order (ORDER BY clause) of that question/model.  That would be ideal to allow the results from the question to populate the filter without being re-ordered.

"
2285836793,issue,closed,completed,FE: give user option to include searching for items in the trash on search page,,sloansparger,2024-05-08 15:07:01+00:00,['sloansparger'],2024-05-11 04:02:15+00:00,2024-05-11 04:02:14+00:00,https://github.com/metabase/metabase/issues/42401,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Frontend', '')]",[],
2285795839,issue,open,,Return the blue banner to nudge people to connect your database,"**Is your feature request related to a problem? Please describe.**
We are observing [lower activation rates](https://stats.metabase.com/question/17636-activation-conversion-retention-monthly-cloud) in April after the banner was removed.
We would like to still get calls with PAs with people who are looking for a solution to have an internal DB offered with Metabase (capability we're building right now with [Baby's First DWH](https://www.notion.so/metabase/Baby-s-First-Data-Warehouse-e823f13025e44c11afa97e8d6473a090)) 

**Describe the solution you'd like**
1. Please revert the change made here:
https://github.com/metabase/metabase/issues/40644
and get the database banner back as it was.
2. Please check that the calendly link under the ""Get help connecting"" points at https://calendly.com/pierinasalinas/connect-to-metabase

**How important is this feature to you?**
Very important - we should get the activation rates back as less people would convert and retain with our product. Additionally we need customer insights for Baby's First DWH to make decisions on how to price the new piece of product we're building and what kind of features should we include.",trinya,2024-05-08 14:48:56+00:00,[],2025-02-04 20:30:22+00:00,,https://github.com/metabase/metabase/issues/42398,"[('Type:New Feature', ''), ('First Experience/Setup', '')]",[],
2285729137,issue,open,,[BE] [QP] [Bug] Wrong column names for columns for metric aggregation clauses,"Failed e2e test `should be possible to sort by metric (metabase#8283)` 
CI run https://app.replay.io/team/dzoyNTM4ZjRmOC05YmFlLTRiYjYtYjljYi1jOGYzOWUyMjRhZWY=/runs?testRunId=8064b50f-fb16-4a56-a93e-672f382001f1

How to reproduce:
- New -> Metric
- Select Products from the Sample DB
- Aggregate -> Count of rows
- Save
- New -> Question
- Select the metric from the previous step
- Click ""Preview"" after the summarize step (or visualize the question)
- The name of the aggregation column is incorrect. It should be the name of the metric

Metric:
<img width=""1296"" alt=""Screenshot 2024-05-08 at 10 18 42"" src=""https://github.com/metabase/metabase/assets/8542534/a7f942e7-0cb5-42ea-8a97-f35218da689c"">

Question based on the metric:
<img width=""1293"" alt=""Screenshot 2024-05-08 at 10 18 26"" src=""https://github.com/metabase/metabase/assets/8542534/4b7e3b02-fa7f-4fdf-9509-1e67f1e45e2b"">
",ranquild,2024-05-08 14:19:56+00:00,[],2025-02-04 20:29:29+00:00,,https://github.com/metabase/metabase/issues/42392,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Semantic Model', '')]",[],
2285716587,issue,closed,not_planned,[BE] [MBQL lib] [Bug] `joinLHSDisplayName` should return the name of the metric and not the underlying table,"How to reproduce:
- New -> Question -> Select a metric
- Join -> join either a table or a metric
- See that the name of the LHS table is incorrect - it should be the name of the metric and not the underlying table

<img width=""1297"" alt=""Screenshot 2024-05-08 at 10 11 38"" src=""https://github.com/metabase/metabase/assets/8542534/9b2b5add-9e96-43d0-98cf-5d75b8ff425d"">
",ranquild,2024-05-08 14:14:10+00:00,['bshepherdson'],2024-05-09 17:40:47+00:00,2024-05-09 17:40:47+00:00,https://github.com/metabase/metabase/issues/42390,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2285527294,issue,closed,completed,Invalid join clause does not disappear after changing query source to use a different database,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/555f3087-1ea4-4f63-a178-eeb0adf8c768


### To Reproduce

1. Have another database connected
2. Start a question based on Orders table from Sample DB
3. Join Accounts table but **do not specify join condition**
4. Change data source to a table from a different DB

Invalid cross-database join condition is not automatically removed.
It will be automatically removed if join condition is specified in step 3 though.

### Expected behavior

master, a91f3c0


### Severity

P2
",kamilmielnik,2024-05-08 12:52:29+00:00,['kamilmielnik'],2024-07-02 14:35:29+00:00,2024-07-02 14:03:13+00:00,https://github.com/metabase/metabase/issues/42385,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2100518714, 'issue_id': 2285527294, 'author': 'kamilmielnik', 'body': ""I think it's FE bug in `JoinDraft`"", 'created_at': datetime.datetime(2024, 5, 8, 12, 56, 50, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-08 12:56:50 UTC): I think it's FE bug in `JoinDraft`

"
2285262532,issue,closed,completed,Add Upload CSVs button for customers with feature flag,"**Context**

Customers can have a `DWH` subscription.

**Proposal**

Add a `CSV upload` button for these customers when the feature flag:

```
attached-dwh = ON
```

See [designs](https://www.figma.com/file/zzRODww44883ojSwMlUT9E/Baby-Data-Warehouse---Milestone-3---CSV-entrypoints?type=design&node-id=1520-32973&mode=design&t=m2BuyOFqyajLn9EC-4).

related to: https://github.com/metabase/harbormaster/issues/4931

```[tasklist]
### Tasks
- [x] Add new DWH plans to settings and Plan
- [x] Show the `Upload CSVs` button on the left navigation
- [x] When the button is clicked, it should launch the uploading CSVs file dialog and proceed to the CSV upload (to the attached storage that should be pre-enabled for these customers)
- [x] When the button is clicked, send a Snowplow event: `csv_upload_clicked`, source: `left_nav`
- [x] Write relevant e2e tests
```",trinya,2024-05-08 10:33:34+00:00,['losrebellos'],2024-06-19 14:03:52+00:00,2024-06-18 16:48:33+00:00,https://github.com/metabase/metabase/issues/42381,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2285192094,issue,closed,not_planned,Dashboard Filters Unmodifiable After Upgrade from v48 to v49,"### Describe the bug

After upgrading from version v0.48.8 to version v0.49.8, I've encountered a peculiar issue with the dashboard filters. 

In read mode, the filters function correctly; I can select items from the list, and the questions filter as expected. However, when I attempt to modify the filters, an error message stating ""unknown field"" appears.

Furthermore, when I try to forcefully modify the filters, no changes are displayed. Additionally, the following error message is logged in the browser console: `Uncaught (in promise) Error: No matching clause - [metabase.lib.util.js:11:115](webpack:///target/cljs_release/metabase.lib.util.js)`.

![metabase-filter-bug](https://github.com/metabase/metabase/assets/2952029/3087b062-769e-48e9-9791-eefbc7f78685)

This issue persists even when trying to add new filters.

Essentially, I am unable to modify or add any filters.

### To Reproduce

Not sure about the repeatabily but, this is what I've done : 
- Set my dashboard with filters up on v0.48.8  
- Upgrade to v0.49.8
- Try to modify existing filters

I tried to downgrade to v0.48 to selectively upgrade version to version but can't manage to succesfully downgrade...

### Expected behavior

_No response_

### Logs

No server-side logs when the error appear. Seems to be front-side specifics. 

Browser logs : 
Some of thoses before click : 
```
DashCardCardParameterMapper.tsx:84 [re-reselect] Invalid cache key ""undefined"" has been returned by keySelector function.
h @ index.js:98
(anonymous) @ DashCardCardParameterMapper.tsx:84
r @ wrapMapToProps.js:47
r.mapToProps @ wrapMapToProps.js:56
r @ wrapMapToProps.js:47
(anonymous) @ selectorFactory.js:19
(anonymous) @ connect.js:313
u @ use-sync-external-store-shim.production.min.js:10
l @ connect.js:337
o6 @ react-dom.production.min.js:153
iF @ react-dom.production.min.js:175
iN @ react-dom.production.min.js:175
iD @ react-dom.production.min.js:174
l @ react-dom.production.min.js:268
aH @ react-dom.production.min.js:246
(anonymous) @ react-dom.production.min.js:246
aW @ react-dom.production.min.js:246
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
oi @ react-dom.production.min.js:123
oo @ react-dom.production.min.js:122
Y @ react-dom.production.min.js:287
TU @ react-dom.production.min.js:68
```

After click :
```
Uncaught (in promise) Error: No matching clause: 
    BV metabase.lib.util.js:11
    71733 metabase.lib.convert.js:22
    h cljs.core.js:509
    k1 metabase.lib.card.js:7
    6242 metabase.lib.card.js:11
    v cljs.core.js:510
    e metabase.lib.metadata.calculation.js:40
    6242 metabase.lib.card.js:8
    v cljs.core.js:510
    e metabase.lib.metadata.calculation.js:43
    c metabase.lib.stage.js:17
    c metabase.lib.stage.js:22
    91877 metabase.lib.stage.js:23
    v cljs.core.js:510
    e metabase.lib.metadata.calculation.js:43
    U_ metabase.lib.metadata.calculation.js:44
    d_ metabase.lib.metadata.calculation.js:7
    e_ metabase.lib.metadata.calculation.js:8
    t metabase.lib.metadata.calculation.js:43
    e metabase.lib.filter.js:66
    e4 cljs.core.js:71
    e7 cljs.core.js:71
    g cljs.core.js:269
    t metabase.lib.core.js:80
    filterable_columns metabase.lib.js.js:48
    d_ metabase.lib.metadata.calculation.js:7
    e_ metabase.lib.metadata.calculation.js:8
    filterable_columns metabase.lib.js.js:47
    tn filter.ts:73
    f mapping-options.ts:163
    t utils.ts:69
    o utils.ts:102
    eS parameters.js:129
    Redux 2
    eS parameters.js:126
    Redux 3
    g DashCardCardParameterMapper.tsx:130
    onChange DashCardCardParameterMapper.tsx:290
    onChange ParameterTargetList.jsx:28
    handleChange AccordionList.jsx:247
    onClick AccordionListCell.jsx:149
    React 12
    unstable_runWithPriority scheduler.production.min.js:19
    React 3
metabase.lib.util.js:11:115

```

### Information about your Metabase installation

```JSON
- Firefox 122.0.1 OR Brave / Chromium 124.0.6367.118 (Same behaviour)
- Metabase v0.49.8 - Docker image metabase/metabase:v0.49.8
```


### Severity

blocking

### Additional context

I already try to : 
- Clear cache (Metabase + Browser)
- discard_values / sync_schema
- force rename colomn in model metadata",tomy137,2024-05-08 09:57:05+00:00,['bshepherdson'],2024-08-28 02:09:46+00:00,2024-06-05 21:14:19+00:00,https://github.com/metabase/metabase/issues/42379,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('.Unable to Reproduce', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2101070599, 'issue_id': 2285192094, 'author': 'calherries', 'body': 'I can\'t reproduce this using v0.49.8.\r\n\r\nBut the stack trace gives a hint as to what\'s causing it.\r\n```\r\nUncaught (in promise) Error: No matching clause: \r\n    BV metabase.lib.util.js:11\r\n    71733 metabase.lib.convert.js:22\r\n    h cljs.core.js:509\r\n    k1 metabase.lib.card.js:7\r\n```\r\n""No matching clause"" means a case statement is being executed. It must be [this one](https://github.com/metabase/metabase/blob/5ca34c17b2e99b7f0c2c1163cd751abbd21c44c2/src/metabase/lib/util.cljc#L274-L276) since it\'s the only case statement in the file.\r\n\r\n@tomy137 can you provide more information about what you see when you try to downgrade? Is there an error message? Perhaps it is related.', 'created_at': datetime.datetime(2024, 5, 8, 17, 31, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2104194395, 'issue_id': 2285192094, 'author': 'calherries', 'body': ""I've tagged both Team/QueryProcessor and Team/DashViz because it's not clear to me what code is at fault yet."", 'created_at': datetime.datetime(2024, 5, 10, 8, 38, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2110507920, 'issue_id': 2285192094, 'author': 'k2xl', 'body': 'This happens to me too on 0.49.10. Seems to happen more often on mobile but also happens on browser.', 'created_at': datetime.datetime(2024, 5, 14, 15, 16, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133987999, 'issue_id': 2285192094, 'author': 'bshepherdson', 'body': '@tomy137 @k2xl some more information would be useful for debugging this.\r\n\r\nIt would help a lot to see the network payload for the dashboard - can you use the devtools Network tab to ""Copy -> Copy response"" for the `/api/dashboard/123` request?\r\n\r\nIf you create a new dashboard and new questions (ideally based on our sample database) can you create and edit filters for it? That is, is this only an issue when upgrading a dashboard which already exists on 48 to 49?', 'created_at': datetime.datetime(2024, 5, 27, 19, 51, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142223472, 'issue_id': 2285192094, 'author': 'paoliniluis', 'body': '@tomy137 @k2xl can you please give us some information about this?', 'created_at': datetime.datetime(2024, 5, 31, 13, 54, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142422105, 'issue_id': 2285192094, 'author': 'tomy137', 'body': ""Sorry, but I can't reproduce it now. I haven't worked on filters since this issue arose, and today it's working.\r\nI did update to v0.49.10; maybe it's related?"", 'created_at': datetime.datetime(2024, 5, 31, 14, 44, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150973573, 'issue_id': 2285192094, 'author': 'bshepherdson', 'body': ""Ah, I see. Slippery issues like this are puzzling.\r\n\r\nWith no one able to reproduce this, I'm going to close this issue. Feel free to reopen it if the issue reappears!"", 'created_at': datetime.datetime(2024, 6, 5, 21, 14, 19, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-08 17:31:25 UTC): I can't reproduce this using v0.49.8.

But the stack trace gives a hint as to what's causing it.
```
Uncaught (in promise) Error: No matching clause: 
    BV metabase.lib.util.js:11
    71733 metabase.lib.convert.js:22
    h cljs.core.js:509
    k1 metabase.lib.card.js:7
```
""No matching clause"" means a case statement is being executed. It must be [this one](https://github.com/metabase/metabase/blob/5ca34c17b2e99b7f0c2c1163cd751abbd21c44c2/src/metabase/lib/util.cljc#L274-L276) since it's the only case statement in the file.

@tomy137 can you provide more information about what you see when you try to downgrade? Is there an error message? Perhaps it is related.

calherries on (2024-05-10 08:38:57 UTC): I've tagged both Team/QueryProcessor and Team/DashViz because it's not clear to me what code is at fault yet.

k2xl on (2024-05-14 15:16:39 UTC): This happens to me too on 0.49.10. Seems to happen more often on mobile but also happens on browser.

bshepherdson (Assginee) on (2024-05-27 19:51:50 UTC): @tomy137 @k2xl some more information would be useful for debugging this.

It would help a lot to see the network payload for the dashboard - can you use the devtools Network tab to ""Copy -> Copy response"" for the `/api/dashboard/123` request?

If you create a new dashboard and new questions (ideally based on our sample database) can you create and edit filters for it? That is, is this only an issue when upgrading a dashboard which already exists on 48 to 49?

paoliniluis on (2024-05-31 13:54:08 UTC): @tomy137 @k2xl can you please give us some information about this?

tomy137 (Issue Creator) on (2024-05-31 14:44:47 UTC): Sorry, but I can't reproduce it now. I haven't worked on filters since this issue arose, and today it's working.
I did update to v0.49.10; maybe it's related?

bshepherdson (Assginee) on (2024-06-05 21:14:19 UTC): Ah, I see. Slippery issues like this are puzzling.

With no one able to reproduce this, I'm going to close this issue. Feel free to reopen it if the issue reappears!

"
2285088878,issue,closed,completed,`diagnose-expression` throws when `Offset` is nested,"Repro steps:
1. `git checkout 42318-offset-custom-columns-frontend`
2. Start a new question based on Orders table
3. Try to add a custom column with custom expression: `case(Offset([Total], -1) > 5, ""abc"")`
4. Observe error in JS console

```
Error normalizing query: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Error normalizing form: Assert failed: (= (count clause) 4)
```

[Screenshot](https://github.com/metabase/metabase/assets/6830683/4c78a378-ec5b-4606-8303-32089b23a84e)
",kamilmielnik,2024-05-08 09:07:36+00:00,['kamilmielnik'],2024-05-10 13:40:35+00:00,2024-05-10 13:39:10+00:00,https://github.com/metabase/metabase/issues/42377,"[('Type:Bug', 'Product defects'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2101034743, 'issue_id': 2285088878, 'author': 'camsaul', 'body': ""I'm guessing this is a bug with the FE code that parses case from user input into an actual MBQL clause, it's probably not recursively calling the same parsing code on its arguments. `offset` needs to go thru code that adds the options map automatically"", 'created_at': datetime.datetime(2024, 5, 8, 17, 9, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2102552448, 'issue_id': 2285088878, 'author': 'kamilmielnik', 'body': ""> I'm guessing this is a bug with the FE code that parses case from user input into an actual MBQL clause, it's probably not recursively calling the same parsing code on its arguments. `offset` needs to go thru code that adds the options map automatically\r\n\r\n:100:\r\n\r\n~Will be fixed with 5ddbe34f246d1dfbe901dab0884762143cf1f74f in #42326.~\r\n~I'll close this issue for now as it is/was reproducible only in that PR.~ \r\nReopening, we should [probably](https://metaboat.slack.com/archives/C06P22KS4JH/p1715271148442289?thread_ts=1715072591.646449&cid=C06P22KS4JH) still merge it to master."", 'created_at': datetime.datetime(2024, 5, 9, 12, 16, 42, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-05-08 17:09:20 UTC): I'm guessing this is a bug with the FE code that parses case from user input into an actual MBQL clause, it's probably not recursively calling the same parsing code on its arguments. `offset` needs to go thru code that adds the options map automatically

kamilmielnik (Issue Creator) on (2024-05-09 12:16:42 UTC): :100:

~Will be fixed with 5ddbe34f246d1dfbe901dab0884762143cf1f74f in #42326.~
~I'll close this issue for now as it is/was reproducible only in that PR.~ 
Reopening, we should [probably](https://metaboat.slack.com/archives/C06P22KS4JH/p1715271148442289?thread_ts=1715072591.646449&cid=C06P22KS4JH) still merge it to master.

"
2285060750,issue,closed,not_planned,metabase support maxcomputer,"**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**How important is this feature to you?**

**Additional context**
Add any other context or screenshots about the feature request here.
",mdzz9527,2024-05-08 08:55:05+00:00,[],2024-05-08 12:32:12+00:00,2024-05-08 12:32:12+00:00,https://github.com/metabase/metabase/issues/42376,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2100473675, 'issue_id': 2285060750, 'author': 'paoliniluis', 'body': 'no info', 'created_at': datetime.datetime(2024, 5, 8, 12, 32, 7, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-08 12:32:07 UTC): no info

"
2285008008,issue,closed,completed,Design update for Extract examples,"[product doc](https://www.notion.so/metabase/Design-update-for-Extract-examples-a120d6ea1f9348bc92172b6fe92d6345)


Make Extract dropdown options more readable.
<img width=""577"" alt=""Screenshot 2024-05-08 at 10 28 43"" src=""https://github.com/metabase/metabase/assets/1250185/cbb895ae-f592-44bb-80b6-c079fd11f44c"">
",romeovs,2024-05-08 08:29:11+00:00,['romeovs'],2024-05-15 17:23:15+00:00,2024-05-15 17:23:15+00:00,https://github.com/metabase/metabase/issues/42375,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2284554701,issue,open,,A kondo linter to ban using toucan2 models in custom migration,"**Context**
Custom migration is a way for us to write migration in Clojure, and since it's a migration, it demands a high level of reliability, so any code written in this namespace should have less dependency on the rest of the application. (e.g: importing code from metabase.util is a no no)

Even though we have been following this rule, there is still a loophole that we didn't consider: toucan2 models.

Toucan2 models often have hooks associated with them, while we're not explicating importing `metabase.models`, by using these hooks to select/insert/update we're indirectly making custom migration depend on external sources. 

To enforce this, let's write a kondo linter to ban using `:model/*` for toucan2 methods in `custom-migration` namespace.

- issue links: _related issues if any_
- https://github.com/metabase/metabase/pull/42369
",qnkhuat,2024-05-08 02:43:34+00:00,[],2024-05-08 08:02:40+00:00,,https://github.com/metabase/metabase/issues/42370,"[('Type:Tech Debt', 'or Refactoring'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2284419944,issue,closed,completed,Pie chart sometimes disappears,"### Describe the bug

Pie chart sometimes disappears.


### To Reproduce

Check out the loom from https://metaboat.slack.com/archives/C05NQSWPRMK/p1715122094392309

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest master
```


### Severity

Looks annoying

### Additional context

May be related to https://github.com/metabase/metabase/pull/40840",alxnddr,2024-05-08 00:00:04+00:00,['JesseSDevaney'],2024-05-13 16:04:51+00:00,2024-05-10 21:56:07+00:00,https://github.com/metabase/metabase/issues/42367,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2284274471,issue,open,,Area series can cover other series which makes it impossible to hover them,"### Describe the bug

Area series can cover other series which makes it impossible to hover them:
<img width=""1360"" alt=""Screenshot 2024-05-07 at 6 36 32 PM"" src=""https://github.com/metabase/metabase/assets/14301985/704a458a-585f-4e71-9b3c-70e386d78d35"">

We should sort series so that all of them are generally available for hovers

### To Reproduce

1. New -> Sample dataset -> Count by Created At: Month and Product → Category
2. Make it a combo chart, make Gadget an area
3. Try hovering underlying bars to see the tooltip


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
All versions
```


### Severity

annoying

### Additional context

_No response_",alxnddr,2024-05-07 21:39:24+00:00,[],2025-02-04 20:31:22+00:00,,https://github.com/metabase/metabase/issues/42366,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2237746680, 'issue_id': 2284274471, 'author': 'EmmadUsmani', 'body': ""I think we should wait before trying to fix this. There's no perfect solution at the moment, if we render areas underneath bars, then they will not be visible in many cases, see the example below.\n\n![Image](https://github.com/user-attachments/assets/ffe2e83a-7a1e-4a8e-93f8-a021bfc3abc4)\n\nIt probably makes more sense to tackle this when we [Migrate tooltips to ECharts for more predictable behavior](https://www.notion.so/metabase/Migrate-tooltips-to-ECharts-for-more-predictable-behavior-364f2c71f3b248f1b839960af037279c). We can potentially use something like querying the specific series in the event handler to determine whether the area or the the below series is being hovered, like in Kyle's [example code](https://echarts.apache.org/examples/en/editor.html?c=multiple-y-axis&code=CYQwLiCMAEC80G0C0AWAbAGmkgrABiyUgOgCYBmUrUnTaAdjXq0nNqxVKukrtLxJoUWcuQC6AbgBQoCKTiJukAHR1yy8iI0iszMtSwl1w6CbSSZ4EOQUJl92SFIWpAWwCWAOwAiV-fABZcAALZQ9PAAp7ZUdSAEppVxAAD185BSCwUKTkqIc_BKkpAAcAUwAnAGNSzwgAc1KAJRBPBoUctKdsaHDO0mk3LwA1EAAbAFdSjJCwrzyYq0hCnJGJqcCZnPnHJYHYhViwkGKIiIA3McnuL2BS5Li4AD5oAG8paGhy0rBx8s9oc6XUryABUPRSq0mDwA9ODUn5pABfQqDTyQ4HTLKzSLRWLLCFA_zQTLZFLbAoDAD2xTA7kp_3gbw-YEplNGtOKAC5Xu8PtAwOV3HUGuVuQByFLuADOYt5iIwvLqguA3KZfMFdWCYHFxAApLKPvLeaNSg1PCqeXzoI5uQgxQBVTzuUC3GVYMUABUpVRqEAAVqUxWI5QqPskAILJaW23kfNVWsAATzK4sq4FN3sTYtDVugYyFngAKu5KgBrKXcgWTHNWm2IMUAKRa2egYoAYqUAEYtsVBco98PFfvuoJZ90N8aeHsT0YD8Z1HsAZVKxR7AHlKmAewA5SlnHveUqVIOx6CI3liHOJyPRxCn-N8pMp1sXNbZ08fTwgVylcWO50gK6765tAxSUlK7i0vS4omgAZluNZ8jk3IrECiEfOEKHDEC0AADzQHg0AAPw9NhazQNyBAfnmUZSgAMl4v6WiB0BSsElIAO6VuU1bUR8oyMYuSYmqqfF8pUbLeuKADEOAoPQeAAMJoAaLHniB6l8kaVoPsyyZMWKr6TMBuZfj-4pej6tQgAGJlWmBEFQZ44oalqdlISkKEEms6Gkc5fnonhBHEQFOGUb5kr0Yxoksax7FcfyPGlL5_GCcJTG6bmEmjFJrbSQAnJAimKfQOCqRp1HabmkV0SAnalKMMUsbB3pJGAYAVNygI-dANx3Fg7jxE8zGxRc5SgRU1TWQ00ixR87iwQCZRWfUTQtG0zzEA8mUgctU2rZioTlJSk7AN1kzQGCHR-NAsKoWshRzWe0ANVKUw7bme2-iAbTwOdUxXSkfS3XC6JxMoLJtu4ySlGduxiYaCOfN8vz_F901TI88CESR6MHQA1K2-oUa2YqzWplWnppl68m9gqlBWd46dRZkGf-LoM-5enPmKnYgMO1HXrRACS5p3OF1F1nY-QQJANMgSybIck1IFGaUbateAHWigCatYI4ou3Pcw07AgBti8kwYVVaVVxiz34GZZ-02YGvlPgZAmeK7gs3lKhvi9AkC-VLuJ-PLuaK-y7hciNuZqxr5RtdrXV69aVj-8bsDPI45Bm-nFtiNAhNivqlM2xeUiIgMriJopwT82Ayj0hEYquCdb17hULYvKxFTuAzGeUWeWCwZOm50v8ETFPz35SttvI13XDfKG9YBrjSE8RA-kfK7HzIaiK4qQaUrjlWecqPdAEmeFKbKlMoOV1C3bfjB3ZwVL39NSgRYqFMiAxuFrvXcojdm6t3bqUE6CFXif37n7C2Q95TQFHp4ce9Iloz1cHPZii9gGN1XuvJyW9Tw72jirR8B9OqtkimfTS_9eTX1viaB-lIn7gNfpA8YYBYEMx_n_FEuDl5gJfm_LuWAe50zgYPQOw9kFjychg8os954YSAcvAhG9m7b1ZFHGOmUBRCkPq2Y-p8qYX3Jowu-LC2EiMge_cakjeGQF_kiFEgCl4gKbpEdhHcuHdx4fAo23IYBIJQWgye08lFYJUT0NRniNFEO0UrMhe9EqGKoRKWitDzEMPpEw--j9n4QKgQEwOLjK4JCAA&lang=ts)."", 'created_at': datetime.datetime(2024, 7, 18, 22, 51, 8, tzinfo=datetime.timezone.utc)}]","EmmadUsmani on (2024-07-18 22:51:08 UTC): I think we should wait before trying to fix this. There's no perfect solution at the moment, if we render areas underneath bars, then they will not be visible in many cases, see the example below.

![Image](https://github.com/user-attachments/assets/ffe2e83a-7a1e-4a8e-93f8-a021bfc3abc4)

It probably makes more sense to tackle this when we [Migrate tooltips to ECharts for more predictable behavior](https://www.notion.so/metabase/Migrate-tooltips-to-ECharts-for-more-predictable-behavior-364f2c71f3b248f1b839960af037279c). We can potentially use something like querying the specific series in the event handler to determine whether the area or the the below series is being hovered, like in Kyle's [example code](https://echarts.apache.org/examples/en/editor.html?c=multiple-y-axis&code=CYQwLiCMAEC80G0C0AWAbAGmkgrABiyUgOgCYBmUrUnTaAdjXq0nNqxVKukrtLxJoUWcuQC6AbgBQoCKTiJukAHR1yy8iI0iszMtSwl1w6CbSSZ4EOQUJl92SFIWpAWwCWAOwAiV-fABZcAALZQ9PAAp7ZUdSAEppVxAAD185BSCwUKTkqIc_BKkpAAcAUwAnAGNSzwgAc1KAJRBPBoUctKdsaHDO0mk3LwA1EAAbAFdSjJCwrzyYq0hCnJGJqcCZnPnHJYHYhViwkGKIiIA3McnuL2BS5Li4AD5oAG8paGhy0rBx8s9oc6XUryABUPRSq0mDwA9ODUn5pABfQqDTyQ4HTLKzSLRWLLCFA_zQTLZFLbAoDAD2xTA7kp_3gbw-YEplNGtOKAC5Xu8PtAwOV3HUGuVuQByFLuADOYt5iIwvLqguA3KZfMFdWCYHFxAApLKPvLeaNSg1PCqeXzoI5uQgxQBVTzuUC3GVYMUABUpVRqEAAVqUxWI5QqPskAILJaW23kfNVWsAATzK4sq4FN3sTYtDVugYyFngAKu5KgBrKXcgWTHNWm2IMUAKRa2egYoAYqUAEYtsVBco98PFfvuoJZ90N8aeHsT0YD8Z1HsAZVKxR7AHlKmAewA5SlnHveUqVIOx6CI3liHOJyPRxCn-N8pMp1sXNbZ08fTwgVylcWO50gK6765tAxSUlK7i0vS4omgAZluNZ8jk3IrECiEfOEKHDEC0AADzQHg0AAPw9NhazQNyBAfnmUZSgAMl4v6WiB0BSsElIAO6VuU1bUR8oyMYuSYmqqfF8pUbLeuKADEOAoPQeAAMJoAaLHniB6l8kaVoPsyyZMWKr6TMBuZfj-4pej6tQgAGJlWmBEFQZ44oalqdlISkKEEms6Gkc5fnonhBHEQFOGUb5kr0Yxoksax7FcfyPGlL5_GCcJTG6bmEmjFJrbSQAnJAimKfQOCqRp1HabmkV0SAnalKMMUsbB3pJGAYAVNygI-dANx3Fg7jxE8zGxRc5SgRU1TWQ00ixR87iwQCZRWfUTQtG0zzEA8mUgctU2rZioTlJSk7AN1kzQGCHR-NAsKoWshRzWe0ANVKUw7bme2-iAbTwOdUxXSkfS3XC6JxMoLJtu4ySlGduxiYaCOfN8vz_F901TI88CESR6MHQA1K2-oUa2YqzWplWnppl68m9gqlBWd46dRZkGf-LoM-5enPmKnYgMO1HXrRACS5p3OF1F1nY-QQJANMgSybIck1IFGaUbateAHWigCatYI4ou3Pcw07AgBti8kwYVVaVVxiz34GZZ-02YGvlPgZAmeK7gs3lKhvi9AkC-VLuJ-PLuaK-y7hciNuZqxr5RtdrXV69aVj-8bsDPI45Bm-nFtiNAhNivqlM2xeUiIgMriJopwT82Ayj0hEYquCdb17hULYvKxFTuAzGeUWeWCwZOm50v8ETFPz35SttvI13XDfKG9YBrjSE8RA-kfK7HzIaiK4qQaUrjlWecqPdAEmeFKbKlMoOV1C3bfjB3ZwVL39NSgRYqFMiAxuFrvXcojdm6t3bqUE6CFXif37n7C2Q95TQFHp4ce9Iloz1cHPZii9gGN1XuvJyW9Tw72jirR8B9OqtkimfTS_9eTX1viaB-lIn7gNfpA8YYBYEMx_n_FEuDl5gJfm_LuWAe50zgYPQOw9kFjychg8os954YSAcvAhG9m7b1ZFHGOmUBRCkPq2Y-p8qYX3Jowu-LC2EiMge_cakjeGQF_kiFEgCl4gKbpEdhHcuHdx4fAo23IYBIJQWgye08lFYJUT0NRniNFEO0UrMhe9EqGKoRKWitDzEMPpEw--j9n4QKgQEwOLjK4JCAA&lang=ts).

"
2284255740,issue,closed,completed,BigQuery - GUI Query Builder Generates Invalid SQL for Nested Queries if the Table Name Contains a Space,"### Describe the bug

If you use the GUI query builder to create multi-level aggregation in BigQuery the outermost SELECT contains incorrect aliases for fields from the subquery if:

- The joined source table has a space in the name OR
- The field from the joined source table has a space in the name


### To Reproduce

1. Create two test tables in Big Query - one should have a space in the name, the other should not
2. Join from the table that doesn't have a space to the table that does
3. Group the results by a column on the the table with a space in the name
4. Summarize again on the grouped results - when you aggregate the second time the query fails because the main select statement doesn't include the correct alias for the field from the subquery

![Screenshot 2024-05-07 154433](https://github.com/metabase/metabase/assets/13661163/8e3003d1-3910-4193-86ea-a48452609aaf)
![Screenshot 2024-05-07 155204](https://github.com/metabase/metabase/assets/13661163/2fb6487a-fce0-43e7-9a63-3db247f9efc9)


You can also reproduce this with two tables that have no spaces in the name if you're summarizing on a field that has a space in the name:

![Screenshot 2024-05-07 161913](https://github.com/metabase/metabase/assets/13661163/a758bbca-ea99-49d1-ab12-fd5da00c18df)


### Expected behavior

The correct SQL should be generated

### Logs

BQ Error:

https://www.googleapis.com/bigquery/v2/projects/data-mb-analysis/queries { ""code"": 400, ""errors"": [ { ""domain"": ""global"", ""location"": ""q"", ""locationType"": ""parameter"", ""message"": ""Name Employee Test - EmpCode__EmpLName not found inside source at [2:21]"", ""reason"": ""invalidQuery"" } ], ""message"": ""Name Employee Test - EmpCode__EmpLName not found inside source at [2:21]"", ""status"": ""INVALID_ARGUMENT"" }

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Pretty annoying but you can technically work around it by adding an aggregate of the offending field in the ""summarize"" box of the first query and then doing your final aggregate on that aggregate

### Additional context

_No response_",ixipixi,2024-05-07 21:23:29+00:00,[],2024-08-28 02:09:46+00:00,2024-07-18 15:25:47+00:00,https://github.com/metabase/metabase/issues/42365,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2231789750, 'issue_id': 2284255740, 'author': 'snoe', 'body': 'This has been fixed on master for BigQuery by some other change, however I see that sqlite has the same issue. Adding a PR for tests across all drivers.', 'created_at': datetime.datetime(2024, 7, 16, 20, 39, 36, tzinfo=datetime.timezone.utc)}]","snoe on (2024-07-16 20:39:36 UTC): This has been fixed on master for BigQuery by some other change, however I see that sqlite has the same issue. Adding a PR for tests across all drivers.

"
2284193763,issue,closed,not_planned,Custom values in Dropdown List dashboard filter option is being used by Search List option,"### Describe the bug

In a dashboard filter, if you edit a Dropdown List to use custom values, and then switch to use the Search list, the search list will use the custom values instead of the values linked to the field filter. As Dropdown and Search lists are separate options, they should have nothing to do with each other. 

### To Reproduce

1. Add a field filter in a dashboard and map to a field
2. Select Dropdown list option and set custom values
3. Switch/select Search list
4. Save dashboard
5. Try searching in the field filter and it will only show the custom values instead of values linked to the table field.


### Expected behavior

Search list should always use values linked to the field -- and not custom values from Dropdown option as they are different options. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master on Postgres
```


### Severity

Medium as fix isn't obvious. Confusing when switching drop dropdown with custom to search list and most users won't be able to figure out what is going on / think search list is broken

### Additional context

_No response_",maxzheng,2024-05-07 20:43:21+00:00,[],2024-07-12 17:12:29+00:00,2024-07-12 11:16:37+00:00,https://github.com/metabase/metabase/issues/42364,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2180977132, 'issue_id': 2284193763, 'author': 'ranquild', 'body': ""We don't reset custom source settings when going from Dropdown -> Search, that seems to be root cause here"", 'created_at': datetime.datetime(2024, 6, 20, 15, 26, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225171175, 'issue_id': 2284193763, 'author': 'romeovs', 'body': 'AFAICT this is is the way this is suppossed to work, but maybe @mngr can weigh in?', 'created_at': datetime.datetime(2024, 7, 12, 9, 19, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225297340, 'issue_id': 2284193763, 'author': 'mngr', 'body': ""OK, so the problem here is not that we don't clear the custom values, but that we hide them behind the edit button which is linked to the option chosen (dropdown or search).\r\nThis is a UI problem, not the logic problem. This whole process of setting the filter options is so obscure that we have to redesign it completely.\r\n@romeovs I would close this particular ticket as it is intended behavior indeed, but this is a valuable input @maxzheng to highlight the UI problems we have here."", 'created_at': datetime.datetime(2024, 7, 12, 10, 35, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225975668, 'issue_id': 2284193763, 'author': 'maxzheng', 'body': ""@romeovs @mngr I don't understand how this is considered working as expected as the behavior does not make logical sense. So you have 2 filter options: Search & Custom. If you select Search, it uses the value linked to the db field (expected behavior). If you change to Custom and set a custom list of values, then it uses the custom list (expected behavior). Now if you switch back to Search, it is still using the custom list of values (and not the values linked to the db) -- this is unexpected behavior of the Search option, and therefore it's a bug. In order for a user to use the linked db value again, they would need to go back to Custom, clear the list, and then select Search again..."", 'created_at': datetime.datetime(2024, 7, 12, 17, 1, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225982312, 'issue_id': 2284193763, 'author': 'mngr', 'body': ""@maxzheng both Search and Dropdown have the same options to set, either it's a custom list of values or linked to the db field - and this is set independently regardless of what you choose as a UI element\r\nso basically what you selected from where to fetch the values is kept while you switching from Dropdown to Search and back"", 'created_at': datetime.datetime(2024, 7, 12, 17, 6, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225992636, 'issue_id': 2284193763, 'author': 'maxzheng', 'body': '@mngr Interesting. Did you guys changed how that worked? I remember they have different options but now both are the same. Since they are the same, then I guess it makes sense / it is working as expected.', 'created_at': datetime.datetime(2024, 7, 12, 17, 12, 28, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-06-20 15:26:07 UTC): We don't reset custom source settings when going from Dropdown -> Search, that seems to be root cause here

romeovs on (2024-07-12 09:19:05 UTC): AFAICT this is is the way this is suppossed to work, but maybe @mngr can weigh in?

mngr on (2024-07-12 10:35:42 UTC): OK, so the problem here is not that we don't clear the custom values, but that we hide them behind the edit button which is linked to the option chosen (dropdown or search).
This is a UI problem, not the logic problem. This whole process of setting the filter options is so obscure that we have to redesign it completely.
@romeovs I would close this particular ticket as it is intended behavior indeed, but this is a valuable input @maxzheng to highlight the UI problems we have here.

maxzheng (Issue Creator) on (2024-07-12 17:01:52 UTC): @romeovs @mngr I don't understand how this is considered working as expected as the behavior does not make logical sense. So you have 2 filter options: Search & Custom. If you select Search, it uses the value linked to the db field (expected behavior). If you change to Custom and set a custom list of values, then it uses the custom list (expected behavior). Now if you switch back to Search, it is still using the custom list of values (and not the values linked to the db) -- this is unexpected behavior of the Search option, and therefore it's a bug. In order for a user to use the linked db value again, they would need to go back to Custom, clear the list, and then select Search again...

mngr on (2024-07-12 17:06:17 UTC): @maxzheng both Search and Dropdown have the same options to set, either it's a custom list of values or linked to the db field - and this is set independently regardless of what you choose as a UI element
so basically what you selected from where to fetch the values is kept while you switching from Dropdown to Search and back

maxzheng (Issue Creator) on (2024-07-12 17:12:28 UTC): @mngr Interesting. Did you guys changed how that worked? I remember they have different options but now both are the same. Since they are the same, then I guess it makes sense / it is working as expected.

"
2284098365,issue,closed,completed,[BE] [QP] [Bug] Incorrect results when using custom columns in metric queries,"Follow this e2e test https://github.com/metabase/metabase/blob/eca73572ba39c1992350c15860ba8597287cecac/e2e/test/scenarios/metrics/metrics-creation.cy.spec.ts#L164
- New -> Metric -> Raw Data -> Orders
- Custom column -> `[Total] / 2` with name `Total2`
- Aggregation -> Sum Of ->  `Total2`
- Save the metric
- Run the query

Expected:
- `755,310.84`

Actual:
- Metric always returns `1` 
<img width=""1003"" alt=""Screenshot 2024-05-07 at 15 42 42"" src=""https://github.com/metabase/metabase/assets/8542534/304b00a4-fd7c-4af4-9511-3ab8925579a3"">
",ranquild,2024-05-07 19:44:38+00:00,['snoe'],2024-10-08 17:11:17+00:00,2024-05-21 19:49:57+00:00,https://github.com/metabase/metabase/issues/42360,[],[],
2284027114,issue,closed,not_planned,Clicking on the ellipsis next to an item in a collection doesn't close another that's already open,"### Describe the bug

If you click on the `...` icon to open additional options on an item in a collection, and then you click on one for a different item, it doesn't close the first one automatically. And one might cover up the other if they overlap.

### To Reproduce

https://www.loom.com/share/143a17cfe562405a99cb047fe0fbd8c9

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master
```


### Severity

P3

### Additional context

_No response_",noahmoss,2024-05-07 19:02:35+00:00,[],2024-05-08 16:55:14+00:00,2024-05-08 16:55:14+00:00,https://github.com/metabase/metabase/issues/42358,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Frontend', '')]","[{'comment_id': 2101010786, 'issue_id': 2284027114, 'author': 'calherries', 'body': 'Closing, dupe of https://github.com/metabase/metabase/issues/42235', 'created_at': datetime.datetime(2024, 5, 8, 16, 55, 14, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-08 16:55:14 UTC): Closing, dupe of https://github.com/metabase/metabase/issues/42235

"
2283966095,issue,closed,completed,[FE] Add metric icons to data and join steps,,ranquild,2024-05-07 18:24:28+00:00,['ranquild'],2024-05-08 14:33:50+00:00,2024-05-08 14:33:50+00:00,https://github.com/metabase/metabase/issues/42356,[],[],
2283945486,issue,closed,completed,Database mapped field in model metadata shows None after mapping/saving,"### Describe the bug

In a model's metadata, I edited a field to map the database field. It mapped, however it still shows None. 
![Screenshot 2024-05-03 at 2 52 21 PM](https://github.com/metabase/metabase/assets/9684260/172f12fd-24cf-4bb8-b49f-3c872c6e85e4)


### To Reproduce

1. Edit any model and map a field to a database field
2. Observe the mapping shows None even though it mapped and works. 


### Expected behavior

It should show the mapped field

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master on Postgres
```


### Severity

Cosmetic

### Additional context

_No response_",maxzheng,2024-05-07 18:10:57+00:00,['ranquild'],2024-06-27 15:01:12+00:00,2024-06-24 12:37:30+00:00,https://github.com/metabase/metabase/issues/42355,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2183329343, 'issue_id': 2283945486, 'author': 'maxzheng', 'body': ""Bumping priority to P2 as this is an important feature and this bug, while cosmetic, makes it looks like it's broken, which is effectively the same to users."", 'created_at': datetime.datetime(2024, 6, 21, 19, 24, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194956901, 'issue_id': 2283945486, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)', 'created_at': datetime.datetime(2024, 6, 27, 15, 1, 10, tzinfo=datetime.timezone.utc)}]","maxzheng (Issue Creator) on (2024-06-21 19:24:09 UTC): Bumping priority to P2 as this is an important feature and this bug, while cosmetic, makes it looks like it's broken, which is effectively the same to users.

github-actions[bot] on (2024-06-27 15:01:10 UTC): 🚀 This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)

"
2283938899,issue,closed,completed,Dependency issues with SDK when using React 18,"### Describe the bug

App uses React 18
SDK specifies React ^17.0.2 in its package.json

npm will complain about dependencies.
It can be still be achieved by running `npm install --force`.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

`--force` should not be necessary
The SDK should be compatible with React 17 and 18

### Logs

_No response_

### Information about your Metabase installation

```JSON
- @metabase/embedding-sdk-react 0.1.2
- React 18
```


### Severity

P2

### Additional context

_No response_",albertoperdomo,2024-05-07 18:06:55+00:00,['WiNloSt'],2024-05-09 14:44:36+00:00,2024-05-09 14:44:36+00:00,https://github.com/metabase/metabase/issues/42354,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2283915280,issue,closed,completed,Loading error when drilling down on Interactive Question with the SDK,"### Describe the bug

When using drill down ""see these <records>"", first a ""Question not found is shown"", then the question actually loads, but a runtime error is triggered.

Loom: https://www.loom.com/share/7530d33a65f145efb0e2547c2c190a1b

<img width=""1488"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24216/39090953-616d-4c16-ae54-1fd1a4eaf527"">

### To Reproduce

1. Setup Metabase Dockerhub metabase/metabase-dev:embedding-sdk-0.1.0
2. Code is here: https://github.com/albertoperdomo/metabase-sdk-testing-app/commit/f87a757b92b4221c5ccf1b179f807b73b0bda5eb

### Expected behavior

- No runtime errors

### Logs

_No response_

### Information about your Metabase installation

```JSON
- @metabase/embedding-sdk-react v0.1.1
- Metabase Dockerhub metabase/metabase-dev:embedding-sdk-0.1.0
```


### Severity

P1

### Additional context

_No response_",albertoperdomo,2024-05-07 17:51:50+00:00,['WiNloSt'],2024-05-29 12:08:26+00:00,2024-05-10 06:52:30+00:00,https://github.com/metabase/metabase/issues/42352,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2283889676,issue,open,,Click behavior doesn't work for Group bys in Pivot Tables,"### Describe the bug

If you have a pivot table with several summarizations and group bys, when setting up click-behavior, you won't get any variables passed through the click-behavior when clicking the group bys, but yes, the aggregations.

Probably related to the fix we pulled up for this issue: https://github.com/metabase/metabase/issues/25203

### To Reproduce

1. Create a Pivot Table based on Orders. Count of rows and sum of Total Grouped by Created At: Year (binned) and Product Category. Save.
2. Add this pivot table to a dashboard
3. Set up click behavior for that Table, using any field to any field (indistinct). Save.
5. See that when you click on the Year field of the Pivot table you won't get any variable passed, but when you click on the Summarizations, you get the values configured.

https://github.com/metabase/metabase/assets/132273646/85fda779-43a4-4309-a87d-c79b1e2849d4





### Expected behavior


### Logs

_No response_

### Information about your Metabase installation

```JSON
- 49.8
```


### Severity

P2

### Additional context

A couple of customers are requesting this as the expected behavior",ignacio-mb,2024-05-07 17:34:43+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/42350,"[('Priority:P2', 'Average run of the mill bug'), ('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Reporting/Dashboards/Click Behavior', '')]","[{'comment_id': 2107681623, 'issue_id': 2283889676, 'author': 'cdeweyx', 'body': 'I think the best course of action here is to:\r\n1. Not allow these groupby columns to be mapped to click behavior in pivot tables (this never worked, and we are letting people hit a dead end)\r\n2. Treat this issue as a feature request, and incorporate into other pivot table improvement plans for the future', 'created_at': datetime.datetime(2024, 5, 13, 14, 10, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2145909418, 'issue_id': 2283889676, 'author': 'ignacio-mb', 'body': 'Related to https://github.com/metabase/metabase/issues/41896', 'created_at': datetime.datetime(2024, 6, 3, 18, 57, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445629926, 'issue_id': 2283889676, 'author': 'ryutaro9434', 'body': 'By when this new feature will be released?', 'created_at': datetime.datetime(2024, 10, 30, 1, 29, 33, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-05-13 14:10:54 UTC): I think the best course of action here is to:
1. Not allow these groupby columns to be mapped to click behavior in pivot tables (this never worked, and we are letting people hit a dead end)
2. Treat this issue as a feature request, and incorporate into other pivot table improvement plans for the future

ignacio-mb (Issue Creator) on (2024-06-03 18:57:03 UTC): Related to https://github.com/metabase/metabase/issues/41896

ryutaro9434 on (2024-10-30 01:29:33 UTC): By when this new feature will be released?

"
2283882282,issue,closed,completed,Copy question info/description when duplicating.,"**Is your feature request related to a problem? Please describe.**
When creating a question from a saved one, the info/description of the previous question is lost. If you want to create a question that has a different aggregation, for example `Daily orders` and change to `Weekly orders` the description for the question will be the same, only changing the time aggregation.

**Describe the solution you'd like**
When saving a new question from a previous saved question, it would be awesome that the description for the new question is copied from the original question.
",subzet,2024-05-07 17:30:11+00:00,[],2024-08-21 16:26:47+00:00,2024-08-21 16:26:47+00:00,https://github.com/metabase/metabase/issues/42348,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Completeness', ''), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2209603619, 'issue_id': 2283882282, 'author': 'nemanjaglumac', 'body': 'Related https://github.com/metabase/metabase/issues/41196', 'created_at': datetime.datetime(2024, 7, 4, 22, 13, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302499425, 'issue_id': 2283882282, 'author': 'nemanjaglumac', 'body': 'This has been implemented already.\r\nhttps://github.com/metabase/metabase/blob/master/frontend/src/metabase/components/SaveQuestionForm/util.ts#L81-L82\r\n\r\nAnd we have a test that ensures this functionality.\r\nhttps://github.com/metabase/metabase/blob/master/frontend/src/metabase/containers/SaveQuestionModal/SaveQuestionModal.unit.spec.tsx#L404-L407', 'created_at': datetime.datetime(2024, 8, 21, 16, 26, 47, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-04 22:13:39 UTC): Related https://github.com/metabase/metabase/issues/41196

nemanjaglumac on (2024-08-21 16:26:47 UTC): This has been implemented already.
https://github.com/metabase/metabase/blob/master/frontend/src/metabase/components/SaveQuestionForm/util.ts#L81-L82

And we have a test that ensures this functionality.
https://github.com/metabase/metabase/blob/master/frontend/src/metabase/containers/SaveQuestionModal/SaveQuestionModal.unit.spec.tsx#L404-L407

"
2283829278,issue,closed,completed,Replace the search bar with a search button that opens the command palette,"- [x] Replace the search bar with the search button ([Figma](https://www.figma.com/file/hubkgafXKo4wcBeTAbJ4vh/Browsing-Models-Exploration?type=design&node-id=287-53101&mode=design&t=tB1tEpNf3nQ2w6wt-4) note that the ""view all"" results changed from this spec. We now show the view and filter in the first position and this is the desired state.)
- [x] Keep the search bar in embedding contexts",luizarakaki,2024-05-07 16:57:52+00:00,['npfitz'],2024-05-15 22:19:38+00:00,2024-05-15 20:26:46+00:00,https://github.com/metabase/metabase/issues/42346,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2283770175,issue,closed,completed,Migration: move existing `archived` items to the Trash,,johnswanson,2024-05-07 16:24:52+00:00,['johnswanson'],2024-05-09 20:39:16+00:00,2024-05-09 20:39:15+00:00,https://github.com/metabase/metabase/issues/42343,[],"[{'comment_id': 2103385800, 'issue_id': 2283770175, 'author': 'johnswanson', 'body': 'Fixed by https://github.com/metabase/metabase/pull/42241', 'created_at': datetime.datetime(2024, 5, 9, 20, 39, 15, tzinfo=datetime.timezone.utc)}]","johnswanson (Issue Creator) on (2024-05-09 20:39:15 UTC): Fixed by https://github.com/metabase/metabase/pull/42241

"
2283717079,issue,closed,completed,Allow overriding font in SDK,"Currently, the visualization is using its own font from `getFont` selector.
https://github.com/metabase/metabase/blob/1060973956b85712e55ff15465736928b01aea63/frontend/src/metabase/visualizations/components/Visualization/Visualization.jsx#L68

This breaks the customizing font from the SDK if we set it differently from the instance font.

p.s. there are other places that might need the same remedy as well.",WiNloSt,2024-05-07 15:58:36+00:00,['deniskaber'],2024-10-08 17:11:36+00:00,2024-05-20 16:57:50+00:00,https://github.com/metabase/metabase/issues/42341,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2283634124,issue,closed,completed,oracle field filter generates invalid query ,"**Describe the bug**
when creating a field filter, the generated SQL contains the schema, which creates an error on SQL.

**Error**
ORA-00904: ""schema"".""table"".""column"": invalid identifier 

**Generated SQL**
WHERE TRUNC(SCHEME.TABLE.DATE_COLUMN, 'dd') BETWEEN date '2023-05-01' AND date '2024-04-30';

**Logs**
```
 ORA-00904: ""SCHEME"".""TABLE"".""DATE_COLUMN"": invalid identifier
2024-05-07T15:09:38.932113404Z 
2024-05-07T15:09:38.932116984Z {:database_id 2,
2024-05-07T15:09:38.932119442Z  :started_at #t ""2024-05-07T15:09:38.821280Z[GMT]"",
2024-05-07T15:09:38.932121869Z  :via
2024-05-07T15:09:38.932124087Z  [{:status :failed,
```

**To Reproduce**
Steps to reproduce the behavior:
1. Create a Question with native query
2. define a variable with a field filter
3. Map the filter to an table column with a schema
4. Run the Query
5. Exception is generated

**Expected behavior**
the generated query must run, excluding the schema path from the query, this example is working
`WHERE TRUNC(TABLE.DATE_COLUMN, 'dd') BETWEEN date '2023-05-01' AND date '2024-04-30';`

**Severity**
isn't possible to use the product properly.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""it-IT"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.146.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Debian 16.2-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",jsantana3c,2024-05-07 15:17:10+00:00,['appleby'],2024-11-12 00:03:36+00:00,2024-11-12 00:03:36+00:00,https://github.com/metabase/metabase/issues/42338,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('Database/Oracle', None), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2451915203, 'issue_id': 2283634124, 'author': 'ranquild', 'body': ""Could be driver specific. I don't think it's okay to exclude the schema name in all cases like this"", 'created_at': datetime.datetime(2024, 11, 1, 13, 56, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465925068, 'issue_id': 2283634124, 'author': 'appleby', 'body': '@jsantana3c are you able to provide the complete query that is failing or ideally a minimal reproduction?\n\nSo far I can only reproduce this for queries which have table aliases, but in such cases simply dropping the schema still does not produce a working query, so I\'m worried the failure you\'re seeing might be slightly different.\n\n(these example are querying the HR schema from oracle\'s [db-sample-schemas](https://github.com/oracle-samples/db-sample-schemas)).\n\n**working example**\n\n```sql\nSELECT *\nFROM JOB_HISTORY\nWHERE {{date}}\n```\n\nThe field filter expands to the following, but including the schema here is fine.\n\n```sql\nWHERE TRUNC(""HR"".""JOB_HISTORY"".""START_DATE"", \'dd\') BETWEEN date \'2000-11-08\'\n   AND date \'2001-11-08\'\n```\n\n**failing example**\n\n```\nSELECT * FROM HR.JOB_HISTORY J\nWHERE {{date}}\n```\n\nThe field filter expands to the same, but in this case Oracle considers `""HR"".""JOB_HISTORY"".""START_DATE""` an invalid identifier and instead wants `""J"".""START_DATE""`', 'created_at': datetime.datetime(2024, 11, 9, 0, 10, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469271788, 'issue_id': 2283634124, 'author': 'appleby', 'body': 'I realized that the behavior @jsantana3c reports could be explained by picking a table alias (a.k.a. [correlation name](https://docs.oracle.com/javadb/10.6.2.1/ref/rrefcorrelationname.html)) that happens to correspond to the schema-less table name. For example, the following query works, but replacing the column reference in the `WHERE` clause with `HR.JOB_HISTORY.START_DATE` produces the same ""ORA-00904: invalid identifier"" error.\n\n```sql\nSELECT * FROM HR.JOB_HISTORY JOB_HISTORY\nWHERE JOB_HISTORY.START_DATE = date \'2001-01-13\'\n```\n\nIf this is indeed related to table aliases, then this is likely a dup of #3324.\n\nThings get more awkward in the presence of nested queries, especially if you are referencing a saved model / question like so\n\n```sql\nSELECT * FROM {{#123-saved-question}} WHERE {{my-field-filter}}\n```\n\nbut again this is a known limitation, and our [docs recommend](https://www.metabase.com/docs/latest/questions/native-editor/referencing-saved-questions-in-queries#limitations-and-tradeoffs) duplicating the saved question and adding the filter there for a [related-but-not-quite-the-same issue](https://github.com/metabase/metabase/issues/6449) of wanting to reference field filters from source queries.', 'created_at': datetime.datetime(2024, 11, 11, 23, 19, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469314844, 'issue_id': 2283634124, 'author': 'joaquinjsb', 'body': ""Yes, \nsorry for the late reply, I do confirm it's a duplicate of #3324, I guess this issue can be closed.\n\nthanks"", 'created_at': datetime.datetime(2024, 11, 12, 0, 2, 41, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-11-01 13:56:30 UTC): Could be driver specific. I don't think it's okay to exclude the schema name in all cases like this

appleby (Assginee) on (2024-11-09 00:10:33 UTC): @jsantana3c are you able to provide the complete query that is failing or ideally a minimal reproduction?

So far I can only reproduce this for queries which have table aliases, but in such cases simply dropping the schema still does not produce a working query, so I'm worried the failure you're seeing might be slightly different.

(these example are querying the HR schema from oracle's [db-sample-schemas](https://github.com/oracle-samples/db-sample-schemas)).

**working example**

```sql
SELECT *
FROM JOB_HISTORY
WHERE {{date}}
```

The field filter expands to the following, but including the schema here is fine.

```sql
WHERE TRUNC(""HR"".""JOB_HISTORY"".""START_DATE"", 'dd') BETWEEN date '2000-11-08'
   AND date '2001-11-08'
```

**failing example**

```
SELECT * FROM HR.JOB_HISTORY J
WHERE {{date}}
```

The field filter expands to the same, but in this case Oracle considers `""HR"".""JOB_HISTORY"".""START_DATE""` an invalid identifier and instead wants `""J"".""START_DATE""`

appleby (Assginee) on (2024-11-11 23:19:58 UTC): I realized that the behavior @jsantana3c reports could be explained by picking a table alias (a.k.a. [correlation name](https://docs.oracle.com/javadb/10.6.2.1/ref/rrefcorrelationname.html)) that happens to correspond to the schema-less table name. For example, the following query works, but replacing the column reference in the `WHERE` clause with `HR.JOB_HISTORY.START_DATE` produces the same ""ORA-00904: invalid identifier"" error.

```sql
SELECT * FROM HR.JOB_HISTORY JOB_HISTORY
WHERE JOB_HISTORY.START_DATE = date '2001-01-13'
```

If this is indeed related to table aliases, then this is likely a dup of #3324.

Things get more awkward in the presence of nested queries, especially if you are referencing a saved model / question like so

```sql
SELECT * FROM {{#123-saved-question}} WHERE {{my-field-filter}}
```

but again this is a known limitation, and our [docs recommend](https://www.metabase.com/docs/latest/questions/native-editor/referencing-saved-questions-in-queries#limitations-and-tradeoffs) duplicating the saved question and adding the filter there for a [related-but-not-quite-the-same issue](https://github.com/metabase/metabase/issues/6449) of wanting to reference field filters from source queries.

joaquinjsb on (2024-11-12 00:02:41 UTC): Yes, 
sorry for the late reply, I do confirm it's a duplicate of #3324, I guess this issue can be closed.

thanks

"
2283570232,issue,closed,not_planned,Allow copying data from a question result,"Quite often I need to copy the result of a table to paste in google sheets. 
It is quite easy to accomplish when the table is part of a dashboard. However, it is nearly impossible to copy table if it is in question form

To resolve my problem I either have to download results in csv or make a dashboard specifically to be able to copy data. Both options require extra time and become irritating when doing it regularly  

Making it possible to select and copy table in question form would make metabase experience much more enjoyable!   ",iamalexanderkim,2024-05-07 14:51:04+00:00,[],2024-06-05 11:49:50+00:00,2024-06-05 11:49:50+00:00,https://github.com/metabase/metabase/issues/42337,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2148061903, 'issue_id': 2283570232, 'author': 'ignacio-mb', 'body': 'Hi @iamalexanderkim thanks for your feedback. Could this be a duplicate of https://github.com/metabase/metabase/issues/4425?', 'created_at': datetime.datetime(2024, 6, 4, 17, 32, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2149077677, 'issue_id': 2283570232, 'author': 'iamalexanderkim', 'body': 'Hi @ignacio-mb \r\nYes, looks like the same problem', 'created_at': datetime.datetime(2024, 6, 5, 7, 29, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2149636313, 'issue_id': 2283570232, 'author': 'ignacio-mb', 'body': 'Ok! Closing this out then. Feel free to add any comments to that one!', 'created_at': datetime.datetime(2024, 6, 5, 11, 49, 50, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-06-04 17:32:49 UTC): Hi @iamalexanderkim thanks for your feedback. Could this be a duplicate of https://github.com/metabase/metabase/issues/4425?

iamalexanderkim (Issue Creator) on (2024-06-05 07:29:02 UTC): Hi @ignacio-mb 
Yes, looks like the same problem

ignacio-mb on (2024-06-05 11:49:50 UTC): Ok! Closing this out then. Feel free to add any comments to that one!

"
2283490443,issue,closed,completed,Table does not appear selected in single-schema dbs,"Repro steps:
1. Start a new question
2. Choose a table from a single-schema database as data source
3. Click the data source to edit it

Table selected in step 2 is not highlighted.",kamilmielnik,2024-05-07 14:16:50+00:00,['kamilmielnik'],2024-05-08 07:01:51+00:00,2024-05-08 07:01:51+00:00,https://github.com/metabase/metabase/issues/42335,"[('Type:Bug', 'Product defects'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2099881193, 'issue_id': 2283490443, 'author': 'kamilmielnik', 'body': 'Closed by #42336', 'created_at': datetime.datetime(2024, 5, 8, 7, 1, 51, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-08 07:01:51 UTC): Closed by #42336

"
2282986415,issue,closed,completed,Oracle timestamps fingerprinting error (No implementation of method: :->temporal of protocol: #'metabase.sync.analyze.fingerprint.fingerprinters/ITemporalCoerceable),"**Describe the bug**
timestamps in my Oracle instance aren't fingerprinted properly.


**Logs**

```
2024-05-07 11:04:40,565 WARN sync.util :: Error generating fingerprint for Field ''DATA_PRESTAZIONE''
2024-05-07T11:04:40.566170699Z java.lang.IllegalArgumentException: No implementation of method: :->temporal of protocol: #'metabase.sync.analyze.fingerprint.fingerprinters/ITemporalCoerceable found for class: oracle.sql.TIMESTAMPLTZ
2024-05-07T11:04:40.566205964Z 	at clojure.core$_cache_protocol_fn.invokeStatic(core_deftype.clj:584)
2024-05-07T11:04:40.566213532Z 	at clojure.core$_cache_protocol_fn.invoke(core_deftype.clj:576)
2024-05-07T11:04:40.566218136Z 	at metabase.sync.analyze.fingerprint.fingerprinters$fn__62682$G__62677__62687.invoke(fingerprinters.clj:189)
2024-05-07T11:04:40.566222491Z 	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)
2024-05-07T11:04:40.566226926Z 	at redux.core$post_complete$fn__62227.invoke(core.cljc:15)
2024-05-07T11:04:40.566231037Z 	at redux.core$juxt$fn__62233$fn__62238.invoke(core.cljc:37)
2024-05-07T11:04:40.566235060Z 	at clojure.core$map$fn__5939.invoke(core.clj:2777)
2024-05-07T11:04:40.566239174Z 	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-05-07T11:04:40.566243234Z 	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-05-07T11:04:40.566247266Z 	at clojure.lang.RT.seq(RT.java:535)
2024-05-07T11:04:40.566251263Z 	at clojure.core$seq__5467.invokeStatic(core.clj:139)
2024-05-07T11:04:40.566255289Z 	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
2024-05-07T11:04:40.566260041Z 	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-05-07T11:04:40.566264369Z 	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-05-07T11:04:40.566268996Z 	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-05-07T11:04:40.566273128Z 	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-05-07T11:04:40.566277216Z 	at clojure.core$into.invokeStatic(core.clj:6959)
2024-05-07T11:04:40.566281295Z 	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-05-07T11:04:40.566285398Z 	at clojure.core$mapv.invoke(core.clj:6971)
2024-05-07T11:04:40.566289310Z 	at redux.core$juxt$fn__62233.invoke(core.cljc:34)
2024-05-07T11:04:40.566293326Z 	at redux.core$post_complete$fn__62227.invoke(core.cljc:15)
2024-05-07T11:04:40.566297426Z 	at metabase.sync.analyze.fingerprint.fingerprinters$with_error_handling$fn__62624$fn__62629.invoke(fingerprinters.clj:84)
2024-05-07T11:04:40.566301704Z 	at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:190)
2024-05-07T11:04:40.566305906Z 	at metabase.sync.util$do_with_error_handling.invoke(util.clj:183)
2024-05-07T11:04:40.566310010Z 	at metabase.sync.analyze.fingerprint.fingerprinters$with_error_handling$fn__62624.invoke(fingerprinters.clj:84)
2024-05-07T11:04:40.566314337Z 	at metabase.sync.analyze.fingerprint.fingerprinters$col_wise$fn__62587$fn__62592.invoke(fingerprinters.clj:34)
2024-05-07T11:04:40.566320728Z 	at clojure.core$map$fn__5942.invoke(core.clj:2783)
2024-05-07T11:04:40.566324962Z 	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-05-07T11:04:40.566329001Z 	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-05-07T11:04:40.566333475Z 	at clojure.lang.Cons.next(Cons.java:39)
2024-05-07T11:04:40.566343107Z 	at clojure.lang.RT.next(RT.java:713)
2024-05-07T11:04:40.566347678Z 	at clojure.core$next__5451.invokeStatic(core.clj:64)
2024-05-07T11:04:40.566352107Z 	at clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:169)
2024-05-07T11:04:40.566356199Z 	at clojure.core.protocols$fn__8249.invoke(protocols.clj:124)
2024-05-07T11:04:40.566360228Z 	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
2024-05-07T11:04:40.566364326Z 	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
2024-05-07T11:04:40.566368409Z 	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-05-07T11:04:40.566372540Z 	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-05-07T11:04:40.566376577Z 	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-05-07T11:04:40.566380825Z 	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-05-07T11:04:40.566559440Z 	at clojure.core$into.invokeStatic(core.clj:6959)
2024-05-07T11:04:40.566711164Z 	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-05-07T11:04:40.566761711Z 	at clojure.core$mapv.invoke(core.clj:6971)
2024-05-07T11:04:40.566874297Z 	at metabase.sync.analyze.fingerprint.fingerprinters$col_wise$fn__62587.invoke(fingerprinters.clj:31)
2024-05-07T11:04:40.566982010Z 	at redux.core$juxt$fn__62233$fn__62238.invoke(core.cljc:37)
2024-05-07T11:04:40.567074877Z 	at clojure.core$map$fn__5939.invoke(core.clj:2777)
2024-05-07T11:04:40.567120787Z 	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-05-07T11:04:40.567264541Z 	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-05-07T11:04:40.567420891Z 	at clojure.lang.RT.seq(RT.java:535)
2024-05-07T11:04:40.567479195Z 	at clojure.core$seq__5467.invokeStatic(core.clj:139)
2024-05-07T11:04:40.567510533Z 	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
2024-05-07T11:04:40.567541508Z 	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-05-07T11:04:40.567725407Z 	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-05-07T11:04:40.567978299Z 	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-05-07T11:04:40.568147442Z 	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-05-07T11:04:40.568322016Z 	at clojure.core$into.invokeStatic(core.clj:6959)
2024-05-07T11:04:40.568405725Z 	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-05-07T11:04:40.568479292Z 	at clojure.core$mapv.invoke(core.clj:6971)
2024-05-07T11:04:40.568530972Z 	at redux.core$juxt$fn__62233.invoke(core.cljc:34)
2024-05-07T11:04:40.568615028Z 	at redux.core$post_complete$fn__62227.invoke(core.cljc:15)
2024-05-07T11:04:40.568748834Z 	at metabase.query_processor.reducible$combine_additional_reducing_fns$combine_additional_reducing_fns_rf_STAR___62864$fn__62867$fn__62868.invoke(reducible.clj:230)
2024-05-07T11:04:40.568829513Z 	at clojure.core$map$fn__5939.invoke(core.clj:2777)
2024-05-07T11:04:40.568965629Z 	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-05-07T11:04:40.569097954Z 	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-05-07T11:04:40.569182727Z 	at clojure.lang.RT.seq(RT.java:535)
2024-05-07T11:04:40.569366421Z 	at clojure.core$seq__5467.invokeStatic(core.clj:139)
2024-05-07T11:04:40.569433941Z 	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
2024-05-07T11:04:40.569472177Z 	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-05-07T11:04:40.569513896Z 	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-05-07T11:04:40.569688031Z 	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-05-07T11:04:40.569735494Z 	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-05-07T11:04:40.569840406Z 	at clojure.core$into.invokeStatic(core.clj:6959)
2024-05-07T11:04:40.569937343Z 	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-05-07T11:04:40.570119432Z 	at clojure.core$mapv.invoke(core.clj:6971)
2024-05-07T11:04:40.570280157Z 	at metabase.query_processor.reducible$combine_additional_reducing_fns$combine_additional_reducing_fns_rf_STAR___62864$fn__62867.invoke(reducible.clj:227)
2024-05-07T11:04:40.570373714Z 	at metabase.query_processor.reducible$combine_additional_reducing_fns$combine_additional_reducing_fns_rf_STAR___62864.invoke(reducible.clj:226)
2024-05-07T11:04:40.570446851Z 	at clojure.core$take$fn__5974$fn__5975.invoke(core.clj:2894)
2024-05-07T11:04:40.570540861Z 	at metabase.query_processor.middleware.add_rows_truncated$add_rows_truncated_xform$fn__71189.invoke(add_rows_truncated.clj:34)
2024-05-07T11:04:40.570587730Z 	at metabase.query_processor.middleware.format_rows$format_rows_xform$fn__72904.invoke(format_rows.clj:74)
2024-05-07T11:04:40.570631918Z 	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)
2024-05-07T11:04:40.570671140Z 	at metabase.query_processor.reducible$reducible_rows$reify__62856.reduce(reducible.clj:177)
2024-05-07T11:04:40.570708080Z 	at clojure.core$transduce.invokeStatic(core.clj:6947)
2024-05-07T11:04:40.570742123Z 	at clojure.core$transduce.invokeStatic(core.clj:6943)
2024-05-07T11:04:40.570786628Z 	at clojure.core$transduce.invoke(core.clj:6934)
2024-05-07T11:04:40.570943006Z 	at metabase.query_processor.context.default$default_reducef$fn__50536.invoke(default.clj:34)
2024-05-07T11:04:40.571063688Z 	at metabase.query_processor.context.default$default_reducef.invokeStatic(default.clj:33)
2024-05-07T11:04:40.571222416Z 	at metabase.query_processor.context.default$default_reducef.invoke(default.clj:25)
2024-05-07T11:04:40.571271378Z 	at metabase.query_processor.context$reducef.invokeStatic(context.clj:70)
2024-05-07T11:04:40.571365431Z 	at metabase.query_processor.context$reducef.invoke(context.clj:63)
2024-05-07T11:04:40.571446365Z 	at metabase.query_processor.context.default$default_runf$respond_STAR___50540.invoke(default.clj:45)
2024-05-07T11:04:40.571589526Z 	at metabase.driver.oracle$remove_rownum_column.invokeStatic(oracle.clj:494)
2024-05-07T11:04:40.571694671Z 	at metabase.driver.oracle$remove_rownum_column.invoke(oracle.clj:490)
2024-05-07T11:04:40.571765847Z 	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
2024-05-07T11:04:40.571938468Z 	at metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__79439.invoke(execute.clj:710)
2024-05-07T11:04:40.572212061Z 	at metabase.driver.sql_jdbc.execute$fn__79232$fn__79233.invoke(execute.clj:389)
2024-05-07T11:04:40.572321039Z 	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)
2024-05-07T11:04:40.572515981Z 	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)
2024-05-07T11:04:40.572588136Z 	at metabase.driver.sql_jdbc.execute$fn__79232.invokeStatic(execute.clj:383)
2024-05-07T11:04:40.572651493Z 	at metabase.driver.sql_jdbc.execute$fn__79232.invoke(execute.clj:381)
2024-05-07T11:04:40.572827817Z 	at clojure.lang.MultiFn.invoke(MultiFn.java:244)
2024-05-07T11:04:40.572961244Z 	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)
2024-05-07T11:04:40.573005592Z 	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)
2024-05-07T11:04:40.573090656Z 	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)
2024-05-07T11:04:40.573165498Z 	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)
2024-05-07T11:04:40.573203458Z 	at metabase.driver.sql_jdbc$fn__106810.invokeStatic(sql_jdbc.clj:78)
2024-05-07T11:04:40.573236391Z 	at metabase.driver.sql_jdbc$fn__106810.invoke(sql_jdbc.clj:76)
2024-05-07T11:04:40.573274252Z 	at metabase.driver.oracle$fn__125736.invokeStatic(oracle.clj:507)
2024-05-07T11:04:40.573526551Z 	at metabase.driver.oracle$fn__125736.invoke(oracle.clj:505)
2024-05-07T11:04:40.573700947Z 	at clojure.lang.MultiFn.invoke(MultiFn.java:244)
2024-05-07T11:04:40.573756839Z 	at metabase.query_processor.context$executef.invokeStatic(context.clj:60)
2024-05-07T11:04:40.573773398Z 	at metabase.query_processor.context$executef.invoke(context.clj:49)
2024-05-07T11:04:40.573796911Z 	at metabase.query_processor.context.default$default_runf.invokeStatic(default.clj:44)
2024-05-07T11:04:40.573855222Z 	at metabase.query_processor.context.default$default_runf.invoke(default.clj:42)
2024-05-07T11:04:40.574031521Z 	at metabase.query_processor.context$runf.invokeStatic(context.clj:46)
2024-05-07T11:04:40.574379261Z 	at metabase.query_processor.context$runf.invoke(context.clj:40)
2024-05-07T11:04:40.574444715Z 	at metabase.query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)
2024-05-07T11:04:40.574468818Z 	at metabase.query_processor.reducible$identity_qp.invoke(reducible.clj:36)
2024-05-07T11:04:40.574490616Z 	at metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72255.invoke(cache.clj:229)
2024-05-07T11:04:40.574516443Z 	at metabase.query_processor.middleware.permissions$check_query_permissions$fn__66604.invoke(permissions.clj:140)
2024-05-07T11:04:40.574620459Z 	at metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72076.invoke(enterprise.clj:51)
2024-05-07T11:04:40.574676851Z 	at metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72086.invoke(enterprise.clj:64)
2024-05-07T11:04:40.574716067Z 	at metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71518.invoke(mbql_to_native.clj:24)
2024-05-07T11:04:40.574757103Z 	at metabase.query_processor$fn__73423$combined_post_process__73428$combined_post_process_STAR___73429.invoke(query_processor.clj:262)
2024-05-07T11:04:40.574798371Z 	at metabase.query_processor$fn__73423$combined_pre_process__73424$combined_pre_process_STAR___73425.invoke(query_processor.clj:259)
2024-05-07T11:04:40.574837908Z 	at metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66701.invoke(fetch_source_query.clj:303)
2024-05-07T11:04:40.574866326Z 	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72166$fn__72170.invoke(resolve_database_and_driver.clj:77)
2024-05-07T11:04:40.574892453Z 	at metabase.driver$do_with_driver.invokeStatic(driver.clj:97)
2024-05-07T11:04:40.574996758Z 	at metabase.driver$do_with_driver.invoke(driver.clj:92)
2024-05-07T11:04:40.575154113Z 	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72166.invoke(resolve_database_and_driver.clj:76)
2024-05-07T11:04:40.575329117Z 	at metabase.query_processor.middleware.store$initialize_store$fn__67328$fn__67329.invoke(store.clj:14)
2024-05-07T11:04:40.575463185Z 	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)
2024-05-07T11:04:40.575514596Z 	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
2024-05-07T11:04:40.575656445Z 	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)
2024-05-07T11:04:40.575755185Z 	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
2024-05-07T11:04:40.575812609Z 	at metabase.query_processor.middleware.store$initialize_store$fn__67328.invoke(store.clj:13)
2024-05-07T11:04:40.575857601Z 	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72163.invoke(resolve_database_and_driver.clj:60)
2024-05-07T11:04:40.576050864Z 	at metabase.query_processor.middleware.normalize_query$normalize$fn__72468.invoke(normalize_query.clj:38)
2024-05-07T11:04:40.576260777Z 	at metabase.query_processor.middleware.enterprise$fn__72103$handle_audit_app_internal_queries__72104$fn__72106.invoke(enterprise.clj:96)
2024-05-07T11:04:40.576347461Z 	at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72114.invoke(enterprise.clj:103)
2024-05-07T11:04:40.576486303Z 	at metabase.query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71229.invoke(constraints.clj:104)
2024-05-07T11:04:40.577094352Z 	at metabase.query_processor.middleware.process_userland_query$process_userland_query$fn__72399.invoke(process_userland_query.clj:156)
2024-05-07T11:04:40.577351046Z 	at metabase.query_processor.middleware.catch_exceptions$catch_exceptions$fn__73000.invoke(catch_exceptions.clj:171)
2024-05-07T11:04:40.577609015Z 	at metabase.query_processor.reducible$async_qp$qp_STAR___62841$thunk__62843.invoke(reducible.clj:126)
2024-05-07T11:04:40.577770166Z 	at metabase.query_processor.reducible$async_qp$qp_STAR___62841.invoke(reducible.clj:132)
2024-05-07T11:04:40.577865679Z 	at clojure.lang.AFn.applyToHelper(AFn.java:160)
2024-05-07T11:04:40.577911855Z 	at clojure.lang.AFn.applyTo(AFn.java:144)
2024-05-07T11:04:40.577959892Z 	at clojure.core$apply.invokeStatic(core.clj:667)
2024-05-07T11:04:40.577997161Z 	at clojure.core$apply.invoke(core.clj:662)
2024-05-07T11:04:40.578031109Z 	at metabase.query_processor.reducible$sync_qp$qp_STAR___62853.doInvoke(reducible.clj:153)
2024-05-07T11:04:40.578158434Z 	at clojure.lang.RestFn.applyTo(RestFn.java:137)
2024-05-07T11:04:40.578254899Z 	at clojure.core$apply.invokeStatic(core.clj:669)
2024-05-07T11:04:40.578353774Z 	at clojure.core$apply.invoke(core.clj:662)
2024-05-07T11:04:40.578516573Z 	at metabase.query_processor$process_userland_query.invokeStatic(query_processor.clj:402)
2024-05-07T11:04:40.578694325Z 	at metabase.query_processor$process_userland_query.doInvoke(query_processor.clj:398)
2024-05-07T11:04:40.578823522Z 	at clojure.lang.RestFn.invoke(RestFn.java:439)
2024-05-07T11:04:40.579053354Z 	at metabase.query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)
2024-05-07T11:04:40.579141197Z 	at metabase.query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)
2024-05-07T11:04:40.579197208Z 	at metabase.query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)
2024-05-07T11:04:40.579246505Z 	at metabase.query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)
2024-05-07T11:04:40.579298697Z 	at metabase.api.dataset$run_query_async$fn__93965.invoke(dataset.clj:79)
2024-05-07T11:04:40.579379882Z 	at clojure.lang.AFn.applyToHelper(AFn.java:154)
2024-05-07T11:04:40.579729924Z 	at clojure.lang.AFn.applyTo(AFn.java:144)
2024-05-07T11:04:40.579869451Z 	at clojure.core$apply.invokeStatic(core.clj:667)
2024-05-07T11:04:40.580083247Z 	at clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990)
2024-05-07T11:04:40.580270655Z 	at clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990)
2024-05-07T11:04:40.580355650Z 	at clojure.lang.RestFn.applyTo(RestFn.java:142)
2024-05-07T11:04:40.580399461Z 	at clojure.core$apply.invokeStatic(core.clj:671)
2024-05-07T11:04:40.580433882Z 	at clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020)
2024-05-07T11:04:40.580465414Z 	at clojure.lang.RestFn.invoke(RestFn.java:408)
2024-05-07T11:04:40.580534798Z 	at metabase.query_processor.streaming$streaming_response_STAR_$fn__53270$fn__53272.invoke(streaming.clj:168)
2024-05-07T11:04:40.580695717Z 	at metabase.query_processor.streaming$streaming_response_STAR_$fn__53270.invoke(streaming.clj:167)
2024-05-07T11:04:40.580758544Z 	at clojure.lang.AFn.applyToHelper(AFn.java:156)
2024-05-07T11:04:40.580968845Z 	at clojure.lang.AFn.applyTo(AFn.java:144)
2024-05-07T11:04:40.581040990Z 	at clojure.core$apply.invokeStatic(core.clj:667)
2024-05-07T11:04:40.581215766Z 	at clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990)
2024-05-07T11:04:40.581304799Z 	at clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990)
2024-05-07T11:04:40.581359272Z 	at clojure.lang.RestFn.applyTo(RestFn.java:142)
2024-05-07T11:04:40.581408645Z 	at clojure.core$apply.invokeStatic(core.clj:671)
2024-05-07T11:04:40.581449634Z 	at clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020)
2024-05-07T11:04:40.581494986Z 	at clojure.lang.RestFn.invoke(RestFn.java:421)
2024-05-07T11:04:40.581576329Z 	at metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)
2024-05-07T11:04:40.581692305Z 	at metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)
2024-05-07T11:04:40.581843996Z 	at metabase.async.streaming_response$do_f_async$task__43762.invoke(streaming_response.clj:88)
2024-05-07T11:04:40.581901445Z 	at clojure.lang.AFn.run(AFn.java:22)
2024-05-07T11:04:40.581966943Z 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
2024-05-07T11:04:40.582076479Z 	at java.base/java.util.concurrent.FutureTask.run(Unknown Source)
2024-05-07T11:04:40.582216756Z 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
2024-05-07T11:04:40.582376188Z 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(
```

**To Reproduce**
Steps to reproduce the behavior:
1. Add a Oracle Database (ojdbc8 as per docs)
2. fingerprint database
3. visualize a table with a timestamp type

**Expected behavior**
the timestamps should be properly fingerprinted and rendered.

**Screenshots**
![image](https://github.com/metabase/metabase/assets/166711198/3e0ded62-9f34-45d5-87df-c5f48cca3fd6)

**Severity**
it's preventing my from using the product at all, when creating a model, based on  a native query, the filters on the dashboard
are not working.

**Additional context**
DBMS: Oracle (ver. Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit Production

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""it-IT"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.146.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Debian 16.2-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",jsantana3c,2024-05-07 11:10:30+00:00,['calherries'],2024-12-24 11:38:26+00:00,2024-06-25 02:16:23+00:00,https://github.com/metabase/metabase/issues/42325,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('Database/Oracle', None), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2098287899, 'issue_id': 2282986415, 'author': 'jsantana3c', 'body': ""when creating a model with native SQL, casting it as timestamp:\r\n`SELECT cast(column as timestamp) as column_a from table;`\r\n\r\nit's working properly, but using that column (and adding the metadata etc) the filter on the dashboard doesn't work either."", 'created_at': datetime.datetime(2024, 5, 7, 12, 26, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098353748, 'issue_id': 2282986415, 'author': 'paoliniluis', 'body': 'can you give us the DDL of the table?', 'created_at': datetime.datetime(2024, 5, 7, 13, 1, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2100490270, 'issue_id': 2282986415, 'author': 'jsantana3c', 'body': '```\r\ncreate table example_table\r\n(\r\n    ID         NUMBER                            not null\r\n        constraint ""pk_id_table""\r\n            primary key,\r\n    property1  NUMBER,\r\n    event_date TIMESTAMP(6) WITH LOCAL TIME ZONE not null,\r\n    property2  CHAR                              not null\r\n        constraint CHK_property2\r\n            check (property2 IN (\'T\', \'F\')),\r\n    property3  NUMBER,\r\n    property4  NUMBER,\r\n    property5  NUMBER,\r\n    property6  NUMBER,\r\n    property7  NUMBER,\r\n    property8  CHAR                              not null\r\n        constraint CHK_property8\r\n            check (property8 IN (\'T\', \'F\')),\r\n    property9  CHAR                              not null\r\n        constraint CHK_property9\r\n            check (property9 IN (\'T\', \'F\')),\r\n    property10 NUMBER,\r\n    property11 CHAR default \'F\'                  not null\r\n        constraint CHK_property11\r\n            check (property11 IN (\'T\', \'F\')),\r\n    property12 CHAR,\r\n    property13 VARCHAR2(20),\r\n    property14 CLOB,\r\n    property15 CHAR\r\n)\r\n```', 'created_at': datetime.datetime(2024, 5, 8, 12, 41, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2122584704, 'issue_id': 2282986415, 'author': 'jsantana3c', 'body': ""@paoliniluis  sorry to ping you, wanted to know if there's anyway I can help fix this, can you give me the starting points to check what can I do?"", 'created_at': datetime.datetime(2024, 5, 21, 13, 0, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2164120181, 'issue_id': 2282986415, 'author': 'paoliniluis', 'body': ""@jsantana3c another customer just hit this one as well so I'll be prioritizing this today"", 'created_at': datetime.datetime(2024, 6, 13, 0, 13, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2164124738, 'issue_id': 2282986415, 'author': 'paoliniluis', 'body': ""I wasn't able to hit the issue on the timestamp, but rather on timestamp diff's\r\n\r\nRepro:\r\n1) run this in your oracle DB:\r\n```\r\ncreate table table1 (\r\n\r\n    name_col       VARCHAR(255),\r\n\r\n    number_col     NUMBER(19,0),\r\n\r\n    timestamp1_col TIMESTAMP,\r\n\r\n    timestamp2_col TIMESTAMP\r\n\r\n);\r\n\r\ninsert into table1 values ('name1' , 1, TO_TIMESTAMP('01-01-2024 08:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('01-01-2024 07:00 PM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name2' , 2, TO_TIMESTAMP('02-01-2024 09:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('02-01-2024 08:30 PM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name3' , 3, TO_TIMESTAMP('03-01-2024 10:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('03-01-2024 09:20 PM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name11', 11, TO_TIMESTAMP('01-02-2024 08:00 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('01-02-2024 06:52 AM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name12', 12, TO_TIMESTAMP('02-02-2024 08:30 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('02-02-2024 08:22 AM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name13', 13, TO_TIMESTAMP('03-02-2024 08:45 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('03-02-2024 08:33 AM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\ninsert into table1 values ('name14', 14, TO_TIMESTAMP('04-02-2024 08:55 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('04-02-2024 06:13 AM', 'MM-DD-YYYY HH:MI AM'));\r\n\r\n\r\n\r\ncreate or replace view view1 as\r\n\r\nselect name_col\r\n\r\n    , number_col\r\n\r\n    , (timestamp1_col - timestamp2_col) as timestamp_diff\r\n\r\n    , TO_TIMESTAMP('14.01.2023 8:00 PM', 'DD.MM.YYYY HH:MI AM') - TO_TIMESTAMP('16.02.2023 10:15 PM', 'DD.MM.YYYY HH:MI AM') AS timestamp_diff2\r\n\r\nfrom table1\r\n;\r\n```\r\n\r\n2) add the db and then go to the view, hit the error"", 'created_at': datetime.datetime(2024, 6, 13, 0, 18, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2164909535, 'issue_id': 2282986415, 'author': 'joaquinjsb', 'body': 'you did just add a ""timezone"" type, the issue is reproducible with **TIMESTAMP(6) WITH LOCAL TIME ZONE**, for example\r\nthis ddl:\r\n\r\n```sql\r\n\r\ncreate table example_table\r\n(\r\n    property1  NUMBER,\r\n    property2  timestamp(6),\r\n    event_date TIMESTAMP(6) WITH LOCAL TIME ZONE not null\r\n);\r\n```\r\n\r\ni successfully managed to reproduce it, the result I get is this:\r\n\r\n![image](https://github.com/metabase/metabase/assets/2885322/c0624b45-8222-4109-924d-c29d14baf7ec)', 'created_at': datetime.datetime(2024, 6, 13, 7, 57, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2165247352, 'issue_id': 2282986415, 'author': 'darksciencebase', 'body': ""if it's easy to smash https://github.com/metabase/metabase/issues/44109 in the same go, we should"", 'created_at': datetime.datetime(2024, 6, 13, 10, 25, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2165254319, 'issue_id': 2282986415, 'author': 'joaquinjsb', 'body': ""> if it's easy to smash #44109 in the same go, we should\r\n\r\nI do also have the clob issue, so probably it's related to the whole oracle implementation"", 'created_at': datetime.datetime(2024, 6, 13, 10, 28, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2165256840, 'issue_id': 2282986415, 'author': 'joaquinjsb', 'body': 'and if you guys are squashing oracle bugs, do also check this one https://github.com/metabase/metabase/issues/42338', 'created_at': datetime.datetime(2024, 6, 13, 10, 29, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190032378, 'issue_id': 2282986415, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)', 'created_at': datetime.datetime(2024, 6, 25, 21, 52, 18, tzinfo=datetime.timezone.utc)}]","jsantana3c (Issue Creator) on (2024-05-07 12:26:11 UTC): when creating a model with native SQL, casting it as timestamp:
`SELECT cast(column as timestamp) as column_a from table;`

it's working properly, but using that column (and adding the metadata etc) the filter on the dashboard doesn't work either.

paoliniluis on (2024-05-07 13:01:16 UTC): can you give us the DDL of the table?

jsantana3c (Issue Creator) on (2024-05-08 12:41:13 UTC): ```
create table example_table
(
    ID         NUMBER                            not null
        constraint ""pk_id_table""
            primary key,
    property1  NUMBER,
    event_date TIMESTAMP(6) WITH LOCAL TIME ZONE not null,
    property2  CHAR                              not null
        constraint CHK_property2
            check (property2 IN ('T', 'F')),
    property3  NUMBER,
    property4  NUMBER,
    property5  NUMBER,
    property6  NUMBER,
    property7  NUMBER,
    property8  CHAR                              not null
        constraint CHK_property8
            check (property8 IN ('T', 'F')),
    property9  CHAR                              not null
        constraint CHK_property9
            check (property9 IN ('T', 'F')),
    property10 NUMBER,
    property11 CHAR default 'F'                  not null
        constraint CHK_property11
            check (property11 IN ('T', 'F')),
    property12 CHAR,
    property13 VARCHAR2(20),
    property14 CLOB,
    property15 CHAR
)
```

jsantana3c (Issue Creator) on (2024-05-21 13:00:48 UTC): @paoliniluis  sorry to ping you, wanted to know if there's anyway I can help fix this, can you give me the starting points to check what can I do?

paoliniluis on (2024-06-13 00:13:27 UTC): @jsantana3c another customer just hit this one as well so I'll be prioritizing this today

paoliniluis on (2024-06-13 00:18:05 UTC): I wasn't able to hit the issue on the timestamp, but rather on timestamp diff's

Repro:
1) run this in your oracle DB:
```
create table table1 (

    name_col       VARCHAR(255),

    number_col     NUMBER(19,0),

    timestamp1_col TIMESTAMP,

    timestamp2_col TIMESTAMP

);

insert into table1 values ('name1' , 1, TO_TIMESTAMP('01-01-2024 08:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('01-01-2024 07:00 PM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name2' , 2, TO_TIMESTAMP('02-01-2024 09:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('02-01-2024 08:30 PM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name3' , 3, TO_TIMESTAMP('03-01-2024 10:00 PM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('03-01-2024 09:20 PM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name11', 11, TO_TIMESTAMP('01-02-2024 08:00 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('01-02-2024 06:52 AM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name12', 12, TO_TIMESTAMP('02-02-2024 08:30 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('02-02-2024 08:22 AM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name13', 13, TO_TIMESTAMP('03-02-2024 08:45 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('03-02-2024 08:33 AM', 'MM-DD-YYYY HH:MI AM'));

insert into table1 values ('name14', 14, TO_TIMESTAMP('04-02-2024 08:55 AM', 'MM-DD-YYYY HH:MI AM'), TO_TIMESTAMP('04-02-2024 06:13 AM', 'MM-DD-YYYY HH:MI AM'));



create or replace view view1 as

select name_col

    , number_col

    , (timestamp1_col - timestamp2_col) as timestamp_diff

    , TO_TIMESTAMP('14.01.2023 8:00 PM', 'DD.MM.YYYY HH:MI AM') - TO_TIMESTAMP('16.02.2023 10:15 PM', 'DD.MM.YYYY HH:MI AM') AS timestamp_diff2

from table1
;
```

2) add the db and then go to the view, hit the error

joaquinjsb on (2024-06-13 07:57:38 UTC): you did just add a ""timezone"" type, the issue is reproducible with **TIMESTAMP(6) WITH LOCAL TIME ZONE**, for example
this ddl:

```sql

create table example_table
(
    property1  NUMBER,
    property2  timestamp(6),
    event_date TIMESTAMP(6) WITH LOCAL TIME ZONE not null
);
```

i successfully managed to reproduce it, the result I get is this:

![image](https://github.com/metabase/metabase/assets/2885322/c0624b45-8222-4109-924d-c29d14baf7ec)

darksciencebase on (2024-06-13 10:25:01 UTC): if it's easy to smash https://github.com/metabase/metabase/issues/44109 in the same go, we should

joaquinjsb on (2024-06-13 10:28:28 UTC): I do also have the clob issue, so probably it's related to the whole oracle implementation

joaquinjsb on (2024-06-13 10:29:35 UTC): and if you guys are squashing oracle bugs, do also check this one https://github.com/metabase/metabase/issues/42338

github-actions[bot] on (2024-06-25 21:52:18 UTC): 🚀 This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)

"
2282925976,issue,closed,completed,`Offset()` doesn't work after saving a question,"

https://github.com/metabase/metabase/assets/6830683/ef4c305b-fb4d-43a8-bbe2-a2275fb3429a


Repro steps:
1. `git checkout master`
2. Start a new question based on Orders table
3. Add aggregation with custom expression: `Offset(Sum([Total]), -1)`
4. Add `Created At: Month` breakout ([question should look like this now](https://github.com/metabase/metabase/assets/6830683/2f421972-0ff2-4414-9007-f7ce7daa7a35))
5. Visualize
6. It works
7. Save question
8. Refresh the page
9. See error

----

POST `/api/card/:id/query` gives error:
```
Invalid output: {:query {:aggregation [[nil {:lib/uuid [\""missing required key, got: nil\""]}]]}}
```

----

![image](https://github.com/metabase/metabase/assets/6830683/c3766062-e156-4b7e-8fc1-6d695b7b7a3b)
",kamilmielnik,2024-05-07 10:45:32+00:00,['camsaul'],2024-08-28 02:11:54+00:00,2024-05-07 20:05:29+00:00,https://github.com/metabase/metabase/issues/42323,"[('Type:Bug', 'Product defects'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2282868924,issue,closed,completed,Option to customize base font size for React embedding,,heypoom,2024-05-07 10:22:56+00:00,['heypoom'],2024-05-08 14:18:30+00:00,2024-05-08 14:18:30+00:00,https://github.com/metabase/metabase/issues/42321,[],[],
2282850435,issue,closed,completed,Metabase 0.49.8 update from 0.49.5 failed with clickhouse driver,"### Describe the bug

Updating Metabase from 0.49.5 to 0.49.8 failed, with failed db migration.

### To Reproduce

1. make sure you run 0.49.5 version
2. try to upgrade metabase.jar with 0.49.8 version and restart it

### Expected behavior

Migration should be done withour problems

### Logs

 ```
 2024-05-07 10:07:44,852 INFO db.liquibase :: Running 1 migrations ...
 2024-05-07 10:07:45,220 INFO driver.impl :: Initializing driver :sql...
 2024-05-07 10:07:45,221 INFO driver.impl :: Initializing driver :sql-jdbc...
 2024-05-07 10:07:45,221 INFO driver.impl :: Initializing driver :postgres...
 2024-05-07 10:07:45,253 INFO driver.impl :: Initializing driver :h2...
 2024-05-07 10:07:45,259 INFO driver.impl :: Initializing driver :clickhouse...
 2024-05-07 10:07:45,260 INFO plugins.classloader :: Added URL file:/var/lib/metabase/plugins/clickhouse.metabase-driver.jar to classpath
 2024-05-07 10:07:45,275 DEBUG plugins.init-steps :: Loading plugin namespace metabase.driver.clickhouse...
 2024-05-07 10:07:45,300 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat encountered an exception.
 UPDATE SUMMARY
 Run:                          1
 Previously run:             268
 Filtered out:                17
 -------------------------------
 Total change sets:          286
 FILTERED CHANGE SETS SUMMARY
 DBMS mismatch:               17
 2024-05-07 10:07:45,355 ERROR metabase.core :: Metabase Initialization FAILED
 liquibase.exception.CommandExecutionException: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader 'bootstrap')
         at liquibase.command.CommandScope.execute(CommandScope.java:253)
         at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
         at liquibase.Scope.lambda$child$0(Scope.java:186)
         at liquibase.Scope.child(Scope.java:195)
         at liquibase.Scope.child(Scope.java:185)
         at liquibase.Scope.child(Scope.java:164)
         at liquibase.Liquibase.runInScope(Liquibase.java:1419)
         at liquibase.Liquibase.update(Liquibase.java:234)
         at liquibase.Liquibase.update(Liquibase.java:212)
         at liquibase.Liquibase.update(Liquibase.java:194)
         at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
         at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
         at metabase.db.setup$migrate_BANG_$fn__51110.invoke(setup.clj:80)
         at metabase.db.liquibase$do_with_liquibase$f_STAR___48786.invoke(liquibase.clj:139)
         at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
         at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
         at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
         at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
         at clojure.lang.RestFn.invoke(RestFn.java:445)
         at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
         at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
         at metabase.db.setup$setup_db_BANG_$fn__51138$fn__51139.invoke(setup.clj:165)
         at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
         at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
         at metabase.db.setup$setup_db_BANG_$fn__51138.invoke(setup.clj:160)
         at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
         at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
         at metabase.db$setup_db_BANG_$fn__51158.invoke(db.clj:69)
         at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
         at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
         at metabase.core$init_BANG_.invokeStatic(core.clj:159)
         at metabase.core$init_BANG_.invoke(core.clj:154)
         at metabase.core$start_normally.invokeStatic(core.clj:171)
         at metabase.core$start_normally.invoke(core.clj:165)
         at metabase.core$entrypoint.invokeStatic(core.clj:204)
         at metabase.core$entrypoint.doInvoke(core.clj:198)
         at clojure.lang.RestFn.invoke(RestFn.java:397)
         at clojure.lang.AFn.applyToHelper(AFn.java:152)
         at clojure.lang.RestFn.applyTo(RestFn.java:132)
         at clojure.lang.Var.applyTo(Var.java:705)
         at clojure.core$apply.invokeStatic(core.clj:667)
         at clojure.core$apply.invoke(core.clj:662)
         at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
         at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
         at clojure.lang.RestFn.invoke(RestFn.java:397)
         at clojure.lang.AFn.applyToHelper(AFn.java:152)
         at clojure.lang.RestFn.applyTo(RestFn.java:132)
         at metabase.bootstrap.main(Unknown Source)
 Caused by: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader 'bootstrap')
         at liquibase.command.CommandScope.logPrimaryExceptionToMdc(CommandScope.java:287)
         at liquibase.command.CommandScope.execute(CommandScope.java:245)
         ... 49 more
 2024-05-07 10:07:45,364 INFO metabase.core :: Metabase Shutting Down ...
 2024-05-07 10:07:45,371 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
 2024-05-07 10:07:45,382 WARN db.liquibase :: ()
 2024-05-07 10:07:45,383 INFO metabase.core :: Metabase Shutdown COMPLETE
```

### Information about your Metabase installation

```JSON
{""file.encoding"" ""UTF-8"",
  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
  ""java.runtime.version"" ""11.0.23+9"",
  ""java.vendor"" ""Eclipse Adoptium"",
  ""java.vendor.url"" ""https://adoptium.net/"",
  ""java.version"" ""11.0.23"",
  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
  ""java.vm.version"" ""11.0.23+9"",
  ""os.name"" ""Linux"",
  ""os.version"" ""4.4.0-210-generic"",
  ""user.language"" ""en"",
  ""user.timezone"" ""UTC""}
```


### Severity

Blocking upgrade

### Additional context

_No response_",sanel,2024-05-07 10:15:56+00:00,['qnkhuat'],2024-05-14 12:53:24+00:00,2024-05-14 12:53:11+00:00,https://github.com/metabase/metabase/issues/42319,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2097984417, 'issue_id': 2282850435, 'author': 'sanel', 'body': 'Also to mention, Metabase updates until `0.49.6` worked without problems (that version update failed as well, so I just kept Metbase on `0.49.5`). It also fails on `jdk-11.0.4+11` version', 'created_at': datetime.datetime(2024, 5, 7, 10, 22, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098085282, 'issue_id': 2282850435, 'author': 'calherries', 'body': ""I haven't attempted to reproduce this. Based on the stacktrace, the problem is the migration added by  https://github.com/metabase/metabase/issues/41348 is failing.\r\n\r\nhttps://github.com/metabase/metabase/blob/43c0ce979a73a84aa03d2e7feb4eeee6e40e8614/src/metabase/db/custom_migrations.clj#L1077-L1094"", 'created_at': datetime.datetime(2024, 5, 7, 10, 53, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098186446, 'issue_id': 2282850435, 'author': 'qnkhuat', 'body': ""similiar to https://github.com/metabase/metabase/issues/41779.\r\n\r\n@sanel do you have any 3rd party plugins?\r\n\r\nUpdate: I see you have a clickhouse db.\r\n\r\nMaybe it's a general issue with instances that have 3rd party drivers."", 'created_at': datetime.datetime(2024, 5, 7, 11, 29, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098468127, 'issue_id': 2282850435, 'author': 'sanel', 'body': ""@qnkhuat yes, I have clickhouse plugin. So, after I deleted `/var/lib/metabase/plugins` folder and run upgrade again, migrations passed! Thank you @qnkhuat :)\r\n\r\nNow, I'm curious, why migrations fail when (some) plugins are present?"", 'created_at': datetime.datetime(2024, 5, 7, 13, 54, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098471742, 'issue_id': 2282850435, 'author': 'sanel', 'body': 'Also, clickhouse driver that might be the problem: https://github.com/enqueue/metabase-clickhouse-driver/releases/download/1.1.3/clickhouse.metabase-driver.jar', 'created_at': datetime.datetime(2024, 5, 7, 13, 56, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2099710953, 'issue_id': 2282850435, 'author': 'qnkhuat', 'body': ""It fails because you have an old version of Clickhouse that's no longer compatible with Metabase 49. If you use their newest version, upgrade should be fine."", 'created_at': datetime.datetime(2024, 5, 8, 4, 20, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2102843522, 'issue_id': 2282850435, 'author': 'dannyeuu', 'body': 'I have the last version of ClickHouse driver 1.4.0 on Metabase v.0.49.2 working ok, but when trying to migrate to Metabase v.0.49.2 I found this problem with the migration. Open an issue on the driver repo https://github.com/ClickHouse/metabase-clickhouse-driver/issues/235', 'created_at': datetime.datetime(2024, 5, 9, 15, 5, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2102895118, 'issue_id': 2282850435, 'author': 'calherries', 'body': '> v.0.49.2 working ok... migrate to v.0.49.2 problem\r\n\r\n@dannyeuu can you repeat what version you are migrating from and migrating to?', 'created_at': datetime.datetime(2024, 5, 9, 15, 31, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2102902339, 'issue_id': 2282850435, 'author': 'dannyeuu', 'body': '> > v.0.49.2 working ok... migrate to v.0.49.2 problem\r\n> \r\n> @dannyeuu can you repeat what version you are migrating from and migrating to?\r\n\r\nsorry @calherries my actually version is 0.49.2 and tying to upgrade to 0.49.8', 'created_at': datetime.datetime(2024, 5, 9, 15, 34, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2102920062, 'issue_id': 2282850435, 'author': 'calherries', 'body': ""@qnkhuat I'm opening this again since it's not just the old clickhouse driver"", 'created_at': datetime.datetime(2024, 5, 9, 15, 42, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2103669143, 'issue_id': 2282850435, 'author': 'qnkhuat', 'body': ""I couldn't reproduce. Here is what I did:\r\n1. Start MB with 0.49.2 with Clickhouse driver version 1.4.0\r\n2. Add a Clickhouse driver\r\n3. Stop MB and migrate to 0.49.8 without a problem\r\n\r\n@dannyeuu, is there anything different with your setup? Please share your full startup log; it'll help us investigate the issue."", 'created_at': datetime.datetime(2024, 5, 10, 1, 3, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2104653554, 'issue_id': 2282850435, 'author': 'dannyeuu', 'body': '> I couldn\'t reproduce. Here is what I did:\r\n> \r\n> 1. Start MB with 0.49.2 with Clickhouse driver version 1.4.0\r\n> 2. Add a Clickhouse driver\r\n> 3. Stop MB and migrate to 0.49.8 without a problem\r\n> \r\n> @dannyeuu, is there anything different with your setup? Please share your full startup log; it\'ll help us investigate the issue.\r\n\r\nthis is the log that I received, @qnkhuat :\r\n```\r\n2024-05-09 14:55:09,723 INFO metabase.util :: Maximum memory available to JVM: 12.0 GB\r\n2024-05-09 14:55:12,660 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.  \r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-05-09 14:55:21,005 INFO driver.impl :: \x1b[34mRegistered abstract driver :sql\x1b[0m  \r\n2024-05-09 14:55:21,018 INFO driver.impl :: \x1b[34mRegistered abstract driver :sql-jdbc\x1b[0m (parents: [:sql]) \r\n2024-05-09 14:55:21,028 INFO metabase.util :: \x1b[32mLoad driver :sql-jdbc took 101.5 ms\x1b[0m\r\n2024-05-09 14:55:21,029 INFO driver.impl :: \x1b[34mRegistered driver :h2\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:21,273 INFO driver.impl :: \x1b[34mRegistered driver :mysql\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:21,322 INFO driver.impl :: \x1b[34mRegistered driver :postgres\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:23,516 INFO metabase.core :: \r\nMetabase v0.49.8 (38cb850) \r\n\r\nCopyright © 2024 Metabase, Inc. \r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-05-09 14:55:23,530 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\n2024-05-09 14:55:23,597 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\n {:port 3000, :host ""0.0.0.0"", :max-threads 256}\r\n\r\n2024-05-09 14:55:23,660 INFO metabase.core :: Starting Metabase version v0.49.8 (38cb850) ...\r\n2024-05-09 14:55:23,669 INFO metabase.core :: System info:\r\n {""file.encoding"" ""UTF-8"",\r\n ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\n ""java.runtime.version"" ""19+36"",\r\n ""java.vendor"" ""Eclipse Adoptium"",\r\n ""java.vendor.url"" ""https://adoptium.net/"",\r\n ""java.version"" ""19"",\r\n ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\n ""java.vm.version"" ""19+36"",\r\n ""os.name"" ""Linux"",\r\n ""os.version"" ""5.10.0-28-cloud-amd64"",\r\n ""user.language"" ""en"",\r\n ""user.timezone"" ""Etc/UTC""}\r\n\r\n2024-05-09 14:55:23,672 INFO metabase.plugins :: Loading plugins in /home/metabase/metabase/plugins...\r\n2024-05-09 14:55:24,034 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /home/metabase/metabase/plugins/athena.metabase-driver.jar\r\n2024-05-09 14:55:24,186 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /home/metabase/metabase/plugins/presto-jdbc.metabase-driver.jar\r\n2024-05-09 14:55:24,276 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /home/metabase/metabase/plugins/snowflake.metabase-driver.jar\r\n2024-05-09 14:55:24,782 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /home/metabase/metabase/plugins/oracle.metabase-driver.jar\r\n2024-05-09 14:55:24,784 INFO util.files :: Extract file /modules/googleanalytics.metabase-driver.jar -> /home/metabase/metabase/plugins/googleanalytics.metabase-driver.jar\r\n2024-05-09 14:55:24,800 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /home/metabase/metabase/plugins/vertica.metabase-driver.jar\r\n2024-05-09 14:55:24,801 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /home/metabase/metabase/plugins/mongo.metabase-driver.jar\r\n2024-05-09 14:55:24,824 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /home/metabase/metabase/plugins/redshift.metabase-driver.jar\r\n2024-05-09 14:55:24,833 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /home/metabase/metabase/plugins/sqlite.metabase-driver.jar\r\n2024-05-09 14:55:24,867 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /home/metabase/metabase/plugins/sqlserver.metabase-driver.jar\r\n2024-05-09 14:55:24,879 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /home/metabase/metabase/plugins/sparksql.metabase-driver.jar\r\n2024-05-09 14:55:24,953 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /home/metabase/metabase/plugins/druid.metabase-driver.jar\r\n2024-05-09 14:55:24,958 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /home/metabase/metabase/plugins/bigquery-cloud-sdk.metabase-driver.jar\r\n2024-05-09 14:55:25,719 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/ojdbc8.jar to classpath\r\n2024-05-09 14:55:25,780 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :google...\x1b[0m\r\n2024-05-09 14:55:25,784 INFO driver.impl :: \x1b[34mRegistered abstract driver :google\x1b[0m  \r\n2024-05-09 14:55:25,810 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :bigquery-cloud-sdk...\x1b[0m\r\n2024-05-09 14:55:25,811 INFO driver.impl :: \x1b[34mRegistered driver :bigquery-cloud-sdk\x1b[0m (parents: [:sql]) \r\n2024-05-09 14:55:25,821 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :clickhouse...\x1b[0m\r\n2024-05-09 14:55:25,822 INFO driver.impl :: \x1b[34mRegistered driver :clickhouse\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,831 INFO plugins.dependencies :: Plugin \'Metabase BigQuery Driver\' depends on plugin \'Metabase Google Drivers Shared Dependencies\'\r\n2024-05-09 14:55:25,833 INFO plugins.dependencies :: Metabase BigQuery Driver dependency {:plugin Metabase Google Drivers Shared Dependencies} satisfied? true\r\n2024-05-09 14:55:25,833 WARN plugins.lazy-loaded-driver :: \x1b[31mWarning: plugin manifest for :bigquery does not include connection properties\x1b[0m\r\n2024-05-09 14:55:25,834 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :bigquery...\x1b[0m\r\n2024-05-09 14:55:25,835 INFO driver.impl :: \x1b[34mRegistered driver :bigquery\x1b[0m (parents: [:sql :google]) \r\n2024-05-09 14:55:25,846 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :hive-like...\x1b[0m\r\n2024-05-09 14:55:25,847 INFO driver.impl :: \x1b[34mRegistered abstract driver :hive-like\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,847 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :sparksql...\x1b[0m\r\n2024-05-09 14:55:25,848 INFO driver.impl :: \x1b[34mRegistered driver :sparksql\x1b[0m (parents: [:hive-like]) \r\n2024-05-09 14:55:25,853 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :cubejs...\x1b[0m\r\n2024-05-09 14:55:25,854 INFO driver.impl :: \x1b[34mRegistered driver :cubejs\x1b[0m  \r\n2024-05-09 14:55:25,858 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :sqlite...\x1b[0m\r\n2024-05-09 14:55:25,859 INFO driver.impl :: \x1b[34mRegistered driver :sqlite\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,866 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :redshift...\x1b[0m\r\n2024-05-09 14:55:25,867 INFO driver.impl :: \x1b[34mRegistered driver :redshift\x1b[0m (parents: [:postgres]) \r\n2024-05-09 14:55:25,880 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :mongo...\x1b[0m\r\n2024-05-09 14:55:25,881 INFO driver.impl :: \x1b[34mRegistered driver :mongo\x1b[0m  \r\n2024-05-09 14:55:25,887 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :sqlserver...\x1b[0m\r\n2024-05-09 14:55:25,888 INFO driver.impl :: \x1b[34mRegistered driver :sqlserver\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,897 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :starburst...\x1b[0m\r\n2024-05-09 14:55:25,898 INFO driver.impl :: \x1b[34mRegistered driver :starburst\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,913 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :athena...\x1b[0m\r\n2024-05-09 14:55:25,914 INFO driver.impl :: \x1b[34mRegistered driver :athena\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,920 INFO plugins.dependencies :: \x1b[31mMetabase cannot initialize plugin Metabase Vertica Driver due to required dependencies.\x1b[0m Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can\'t ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.\r\n\r\n2024-05-09 14:55:25,921 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false\r\n2024-05-09 14:55:25,922 INFO plugins.dependencies :: \x1b[33mPlugins with unsatisfied deps: [""Metabase Vertica Driver""]\x1b[0m\r\n2024-05-09 14:55:25,927 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :googleanalytics...\x1b[0m\r\n2024-05-09 14:55:25,927 INFO driver.impl :: \x1b[34mRegistered driver :googleanalytics\x1b[0m  \r\n2024-05-09 14:55:25,944 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :presto-jdbc...\x1b[0m\r\n2024-05-09 14:55:25,945 INFO driver.impl :: \x1b[34mRegistered driver :presto-jdbc\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:25,949 INFO plugins.dependencies :: Plugin \'Metabase Presto Driver\' depends on plugin \'Presto Common Driver\'\r\n2024-05-09 14:55:25,949 INFO plugins.dependencies :: Metabase Presto Driver dependency {:plugin Presto Common Driver} satisfied? false\r\n2024-05-09 14:55:25,950 INFO plugins.dependencies :: \x1b[33mPlugins with unsatisfied deps: [""Metabase Presto Driver"" ""Metabase Vertica Driver""]\x1b[0m\r\n2024-05-09 14:55:25,954 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :druid...\x1b[0m\r\n2024-05-09 14:55:25,955 INFO driver.impl :: \x1b[34mRegistered driver :druid\x1b[0m  \r\n2024-05-09 14:55:25,965 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true\r\n2024-05-09 14:55:25,966 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :oracle...\x1b[0m\r\n2024-05-09 14:55:25,967 INFO driver.impl :: \x1b[34mRegistered driver :oracle\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:26,008 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :snowflake...\x1b[0m\r\n2024-05-09 14:55:26,009 INFO driver.impl :: \x1b[34mRegistered driver :snowflake\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:26,014 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :presto-common...\x1b[0m\r\n2024-05-09 14:55:26,015 INFO driver.impl :: \x1b[34mRegistered abstract driver :presto-common\x1b[0m  \r\n2024-05-09 14:55:26,015 INFO plugins.dependencies :: Metabase Presto Driver dependency {:plugin Presto Common Driver} satisfied? true\r\n2024-05-09 14:55:26,019 DEBUG plugins.initialize :: \x1b[33mDependencies satisfied; these plugins will now be loaded: [""Metabase Presto Driver""]\x1b[0m\r\n2024-05-09 14:55:26,021 DEBUG plugins.lazy-loaded-driver :: \x1b[35mRegistering lazy loading driver :presto...\x1b[0m\r\n2024-05-09 14:55:26,022 INFO driver.impl :: \x1b[34mRegistered driver :presto\x1b[0m (parents: [:presto-common]) \r\n2024-05-09 14:55:26,045 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-05-09 14:55:26,048 INFO db.setup :: \x1b[36mVerifying postgres Database Connection ...\x1b[0m\r\n2024-05-09 14:55:26,638 INFO db.setup :: Successfully verified PostgreSQL 15.5 application database connection. \r\n2024-05-09 14:55:26,639 INFO db.setup :: \x1b[36mChecking if a database downgrade is required...\x1b[0m\r\n2024-05-09 14:55:27,602 INFO db.setup :: Running Database Migrations...\r\n2024-05-09 14:55:27,604 INFO db.setup :: Setting up Liquibase...\r\n2024-05-09 14:55:27,972 INFO db.setup :: Liquibase is ready.\r\n2024-05-09 14:55:27,973 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-05-09 14:55:29,152 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-05-09 14:55:29,161 INFO db.liquibase :: No migration lock found.\r\n2024-05-09 14:55:29,765 INFO db.liquibase :: Running 5 migrations ...\r\n2024-05-09 14:55:30,449 INFO driver.impl :: \x1b[33mInitializing driver :sql...\x1b[0m\r\n2024-05-09 14:55:30,449 INFO driver.impl :: \x1b[33mInitializing driver :sql-jdbc...\x1b[0m\r\n2024-05-09 14:55:30,449 INFO driver.impl :: \x1b[33mInitializing driver :clickhouse...\x1b[0m\r\n2024-05-09 14:55:30,450 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/clickhouse.metabase-driver.jar to classpath\r\n2024-05-09 14:55:30,451 DEBUG plugins.init-steps :: \x1b[34mLoading plugin namespace metabase.driver.clickhouse...\x1b[0m\r\n2024-05-09 14:55:30,535 INFO driver.impl :: \x1b[34mRegistered driver :clickhouse\x1b[0m (parents: [:sql-jdbc]) \r\n2024-05-09 14:55:30,567 DEBUG plugins.jdbc-proxy :: \x1b[34mRegistering JDBC proxy driver for com.clickhouse.jdbc.ClickHouseDriver...\x1b[0m\r\n2024-05-09 14:55:30,570 INFO metabase.util :: \x1b[36m ⮦ \x1b[35mLoad lazy loading driver :clickhouse\x1b[0m took 118.3 ms\x1b[0m\r\n2024-05-09 14:55:30,621 INFO driver.impl :: \x1b[33mInitializing driver :mysql...\x1b[0m\r\n2024-05-09 14:55:30,645 INFO driver.impl :: \x1b[33mInitializing driver :postgres...\x1b[0m\r\n2024-05-09 14:55:30,658 INFO driver.impl :: \x1b[33mInitializing driver :cubejs...\x1b[0m\r\n2024-05-09 14:55:30,659 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/cubejs.metabase-driver.jar to classpath\r\n2024-05-09 14:55:30,660 DEBUG plugins.init-steps :: \x1b[34mLoading plugin namespace metabase.driver.cubejs...\x1b[0m\r\n2024-05-09 14:55:30,677 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat encountered an exception.\r\n\r\nUPDATE SUMMARY\r\nRun:                          5\r\nPreviously run:             264\r\nFiltered out:                17\r\n-------------------------------\r\nTotal change sets:          286\r\n\r\n\r\nFILTERED CHANGE SETS SUMMARY\r\nDBMS mismatch:               17\r\n\r\n2024-05-09 14:55:30,738 ERROR metabase.core :: Metabase Initialization FAILED\r\nliquibase.exception.CommandExecutionException: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader \'bootstrap\')\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:253)\r\n\tat liquibase.Liquibase.lambda$update$0(Liquibase.java:245)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.Liquibase.runInScope(Liquibase.java:1419)\r\n\tat liquibase.Liquibase.update(Liquibase.java:234)\r\n\tat liquibase.Liquibase.update(Liquibase.java:212)\r\n\tat liquibase.Liquibase.update(Liquibase.java:194)\r\n\tat metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)\r\n\tat metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)\r\n\tat metabase.db.setup$migrate_BANG_$fn__51110.invoke(setup.clj:80)\r\n\tat metabase.db.liquibase$do_with_liquibase$f_STAR___48786.invoke(liquibase.clj:139)\r\n\tat metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)\r\n\tat metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)\r\n\tat metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)\r\n\tat metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:445)\r\n\tat metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)\r\n\tat metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)\r\n\tat metabase.db.setup$setup_db_BANG_$fn__51138$fn__51139.invoke(setup.clj:165)\r\n\tat metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)\r\n\tat metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)\r\n\tat metabase.db.setup$setup_db_BANG_$fn__51138.invoke(setup.clj:160)\r\n\tat metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)\r\n\tat metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)\r\n\tat metabase.db$setup_db_BANG_$fn__51158.invoke(db.clj:69)\r\n\tat metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)\r\n\tat metabase.db$setup_db_BANG_.invoke(db.clj:55)\r\n\tat metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)\r\n\tat metabase.core$init_BANG__STAR_.invoke(core.clj:101)\r\n\tat metabase.core$init_BANG_.invokeStatic(core.clj:159)\r\n\tat metabase.core$init_BANG_.invoke(core.clj:154)\r\n\tat metabase.core$start_normally.invokeStatic(core.clj:171)\r\n\tat metabase.core$start_normally.invoke(core.clj:165)\r\n\tat metabase.core$entrypoint.invokeStatic(core.clj:204)\r\n\tat metabase.core$entrypoint.doInvoke(core.clj:198)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:397)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.Var.applyTo(Var.java:705)\r\n\tat clojure.core$apply.invokeStatic(core.clj:667)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)\r\n\tat metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:397)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:152)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat metabase.bootstrap.main(Unknown Source)\r\nCaused by: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader \'bootstrap\')\r\n\tat liquibase.command.CommandScope.logPrimaryExceptionToMdc(CommandScope.java:287)\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:245)\r\n\t... 49 more\r\n2024-05-09 14:55:30,748 INFO metabase.core :: Metabase Shutting Down ...\r\n2024-05-09 14:55:30,749 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\n2024-05-09 14:55:30,759 WARN db.liquibase :: ()\r\n2024-05-09 14:55:30,762 INFO metabase.core :: Metabase Shutdown COMPLETE\r\n\r\n```', 'created_at': datetime.datetime(2024, 5, 10, 13, 54, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2106530125, 'issue_id': 2282850435, 'author': 'qnkhuat', 'body': ""I'm also seeing a cubejs driver. Their [repo](https://github.com/pyrooka/metabase-cubejs-driver) is archived and is 2 years old and I'm pretty sure it's not compatible with the latest version of MB\r\n\r\nSo I think cubejs is the problem, not clickhouse.\r\n\r\nEither way, when 49.9 is out, this should be fixed, or you can remove cubes and upgrade to 49.8 should work."", 'created_at': datetime.datetime(2024, 5, 13, 2, 37, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2108820809, 'issue_id': 2282850435, 'author': 'paoliniluis', 'body': 'Hi @sanel can you check the previous comment?', 'created_at': datetime.datetime(2024, 5, 13, 21, 21, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2108919191, 'issue_id': 2282850435, 'author': 'sanel', 'body': '@paoliniluis it worked for me after I removed clickhouse driver. Actually, I removed plugins folder completely, leaving metabase to extract a fresh list of plugins. Do you need anything else from my side?', 'created_at': datetime.datetime(2024, 5, 13, 22, 37, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2109214000, 'issue_id': 2282850435, 'author': 'qnkhuat', 'body': 'should be a question for @dannyeuu', 'created_at': datetime.datetime(2024, 5, 14, 3, 36, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2110077468, 'issue_id': 2282850435, 'author': 'dannyeuu', 'body': '> should be a question for @dannyeuu\r\n\r\nThanks, @sanel and @qnkhuat removing the cubejs plugin and upgrading to MB v0.49.9, and worked.\r\n\r\n![Screenshot from 2024-05-14 09-25-39](https://github.com/metabase/metabase/assets/6808348/388249b9-e904-416b-a908-6465cfbd6ed0)', 'created_at': datetime.datetime(2024, 5, 14, 12, 26, 50, tzinfo=datetime.timezone.utc)}]","sanel (Issue Creator) on (2024-05-07 10:22:33 UTC): Also to mention, Metabase updates until `0.49.6` worked without problems (that version update failed as well, so I just kept Metbase on `0.49.5`). It also fails on `jdk-11.0.4+11` version

calherries on (2024-05-07 10:53:35 UTC): I haven't attempted to reproduce this. Based on the stacktrace, the problem is the migration added by  https://github.com/metabase/metabase/issues/41348 is failing.

https://github.com/metabase/metabase/blob/43c0ce979a73a84aa03d2e7feb4eeee6e40e8614/src/metabase/db/custom_migrations.clj#L1077-L1094

qnkhuat (Assginee) on (2024-05-07 11:29:30 UTC): similiar to https://github.com/metabase/metabase/issues/41779.

@sanel do you have any 3rd party plugins?

Update: I see you have a clickhouse db.

Maybe it's a general issue with instances that have 3rd party drivers.

sanel (Issue Creator) on (2024-05-07 13:54:29 UTC): @qnkhuat yes, I have clickhouse plugin. So, after I deleted `/var/lib/metabase/plugins` folder and run upgrade again, migrations passed! Thank you @qnkhuat :)

Now, I'm curious, why migrations fail when (some) plugins are present?

sanel (Issue Creator) on (2024-05-07 13:56:03 UTC): Also, clickhouse driver that might be the problem: https://github.com/enqueue/metabase-clickhouse-driver/releases/download/1.1.3/clickhouse.metabase-driver.jar

qnkhuat (Assginee) on (2024-05-08 04:20:45 UTC): It fails because you have an old version of Clickhouse that's no longer compatible with Metabase 49. If you use their newest version, upgrade should be fine.

dannyeuu on (2024-05-09 15:05:06 UTC): I have the last version of ClickHouse driver 1.4.0 on Metabase v.0.49.2 working ok, but when trying to migrate to Metabase v.0.49.2 I found this problem with the migration. Open an issue on the driver repo https://github.com/ClickHouse/metabase-clickhouse-driver/issues/235

calherries on (2024-05-09 15:31:58 UTC): @dannyeuu can you repeat what version you are migrating from and migrating to?

dannyeuu on (2024-05-09 15:34:56 UTC): sorry @calherries my actually version is 0.49.2 and tying to upgrade to 0.49.8

calherries on (2024-05-09 15:42:58 UTC): @qnkhuat I'm opening this again since it's not just the old clickhouse driver

qnkhuat (Assginee) on (2024-05-10 01:03:42 UTC): I couldn't reproduce. Here is what I did:
1. Start MB with 0.49.2 with Clickhouse driver version 1.4.0
2. Add a Clickhouse driver
3. Stop MB and migrate to 0.49.8 without a problem

@dannyeuu, is there anything different with your setup? Please share your full startup log; it'll help us investigate the issue.

dannyeuu on (2024-05-10 13:54:07 UTC): this is the log that I received, @qnkhuat :
```
2024-05-09 14:55:09,723 INFO metabase.util :: Maximum memory available to JVM: 12.0 GB
2024-05-09 14:55:12,660 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.  
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-05-09 14:55:21,005 INFO driver.impl :: [34mRegistered abstract driver :sql[0m  
2024-05-09 14:55:21,018 INFO driver.impl :: [34mRegistered abstract driver :sql-jdbc[0m (parents: [:sql]) 
2024-05-09 14:55:21,028 INFO metabase.util :: [32mLoad driver :sql-jdbc took 101.5 ms[0m
2024-05-09 14:55:21,029 INFO driver.impl :: [34mRegistered driver :h2[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:21,273 INFO driver.impl :: [34mRegistered driver :mysql[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:21,322 INFO driver.impl :: [34mRegistered driver :postgres[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:23,516 INFO metabase.core :: 
Metabase v0.49.8 (38cb850) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-05-09 14:55:23,530 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-05-09 14:55:23,597 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0"", :max-threads 256}

2024-05-09 14:55:23,660 INFO metabase.core :: Starting Metabase version v0.49.8 (38cb850) ...
2024-05-09 14:55:23,669 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""19+36"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""19"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""19+36"",
 ""os.name"" ""Linux"",
 ""os.version"" ""5.10.0-28-cloud-amd64"",
 ""user.language"" ""en"",
 ""user.timezone"" ""Etc/UTC""}

2024-05-09 14:55:23,672 INFO metabase.plugins :: Loading plugins in /home/metabase/metabase/plugins...
2024-05-09 14:55:24,034 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /home/metabase/metabase/plugins/athena.metabase-driver.jar
2024-05-09 14:55:24,186 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /home/metabase/metabase/plugins/presto-jdbc.metabase-driver.jar
2024-05-09 14:55:24,276 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /home/metabase/metabase/plugins/snowflake.metabase-driver.jar
2024-05-09 14:55:24,782 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /home/metabase/metabase/plugins/oracle.metabase-driver.jar
2024-05-09 14:55:24,784 INFO util.files :: Extract file /modules/googleanalytics.metabase-driver.jar -> /home/metabase/metabase/plugins/googleanalytics.metabase-driver.jar
2024-05-09 14:55:24,800 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /home/metabase/metabase/plugins/vertica.metabase-driver.jar
2024-05-09 14:55:24,801 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /home/metabase/metabase/plugins/mongo.metabase-driver.jar
2024-05-09 14:55:24,824 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /home/metabase/metabase/plugins/redshift.metabase-driver.jar
2024-05-09 14:55:24,833 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /home/metabase/metabase/plugins/sqlite.metabase-driver.jar
2024-05-09 14:55:24,867 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /home/metabase/metabase/plugins/sqlserver.metabase-driver.jar
2024-05-09 14:55:24,879 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /home/metabase/metabase/plugins/sparksql.metabase-driver.jar
2024-05-09 14:55:24,953 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /home/metabase/metabase/plugins/druid.metabase-driver.jar
2024-05-09 14:55:24,958 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /home/metabase/metabase/plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-05-09 14:55:25,719 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/ojdbc8.jar to classpath
2024-05-09 14:55:25,780 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :google...[0m
2024-05-09 14:55:25,784 INFO driver.impl :: [34mRegistered abstract driver :google[0m  
2024-05-09 14:55:25,810 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :bigquery-cloud-sdk...[0m
2024-05-09 14:55:25,811 INFO driver.impl :: [34mRegistered driver :bigquery-cloud-sdk[0m (parents: [:sql]) 
2024-05-09 14:55:25,821 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :clickhouse...[0m
2024-05-09 14:55:25,822 INFO driver.impl :: [34mRegistered driver :clickhouse[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,831 INFO plugins.dependencies :: Plugin 'Metabase BigQuery Driver' depends on plugin 'Metabase Google Drivers Shared Dependencies'
2024-05-09 14:55:25,833 INFO plugins.dependencies :: Metabase BigQuery Driver dependency {:plugin Metabase Google Drivers Shared Dependencies} satisfied? true
2024-05-09 14:55:25,833 WARN plugins.lazy-loaded-driver :: [31mWarning: plugin manifest for :bigquery does not include connection properties[0m
2024-05-09 14:55:25,834 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :bigquery...[0m
2024-05-09 14:55:25,835 INFO driver.impl :: [34mRegistered driver :bigquery[0m (parents: [:sql :google]) 
2024-05-09 14:55:25,846 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :hive-like...[0m
2024-05-09 14:55:25,847 INFO driver.impl :: [34mRegistered abstract driver :hive-like[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,847 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sparksql...[0m
2024-05-09 14:55:25,848 INFO driver.impl :: [34mRegistered driver :sparksql[0m (parents: [:hive-like]) 
2024-05-09 14:55:25,853 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :cubejs...[0m
2024-05-09 14:55:25,854 INFO driver.impl :: [34mRegistered driver :cubejs[0m  
2024-05-09 14:55:25,858 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlite...[0m
2024-05-09 14:55:25,859 INFO driver.impl :: [34mRegistered driver :sqlite[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,866 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :redshift...[0m
2024-05-09 14:55:25,867 INFO driver.impl :: [34mRegistered driver :redshift[0m (parents: [:postgres]) 
2024-05-09 14:55:25,880 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :mongo...[0m
2024-05-09 14:55:25,881 INFO driver.impl :: [34mRegistered driver :mongo[0m  
2024-05-09 14:55:25,887 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlserver...[0m
2024-05-09 14:55:25,888 INFO driver.impl :: [34mRegistered driver :sqlserver[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,897 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :starburst...[0m
2024-05-09 14:55:25,898 INFO driver.impl :: [34mRegistered driver :starburst[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,913 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :athena...[0m
2024-05-09 14:55:25,914 INFO driver.impl :: [34mRegistered driver :athena[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,920 INFO plugins.dependencies :: [31mMetabase cannot initialize plugin Metabase Vertica Driver due to required dependencies.[0m Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-05-09 14:55:25,921 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-05-09 14:55:25,922 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Vertica Driver""][0m
2024-05-09 14:55:25,927 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :googleanalytics...[0m
2024-05-09 14:55:25,927 INFO driver.impl :: [34mRegistered driver :googleanalytics[0m  
2024-05-09 14:55:25,944 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto-jdbc...[0m
2024-05-09 14:55:25,945 INFO driver.impl :: [34mRegistered driver :presto-jdbc[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:25,949 INFO plugins.dependencies :: Plugin 'Metabase Presto Driver' depends on plugin 'Presto Common Driver'
2024-05-09 14:55:25,949 INFO plugins.dependencies :: Metabase Presto Driver dependency {:plugin Presto Common Driver} satisfied? false
2024-05-09 14:55:25,950 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Presto Driver"" ""Metabase Vertica Driver""][0m
2024-05-09 14:55:25,954 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid...[0m
2024-05-09 14:55:25,955 INFO driver.impl :: [34mRegistered driver :druid[0m  
2024-05-09 14:55:25,965 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true
2024-05-09 14:55:25,966 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :oracle...[0m
2024-05-09 14:55:25,967 INFO driver.impl :: [34mRegistered driver :oracle[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:26,008 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :snowflake...[0m
2024-05-09 14:55:26,009 INFO driver.impl :: [34mRegistered driver :snowflake[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:26,014 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto-common...[0m
2024-05-09 14:55:26,015 INFO driver.impl :: [34mRegistered abstract driver :presto-common[0m  
2024-05-09 14:55:26,015 INFO plugins.dependencies :: Metabase Presto Driver dependency {:plugin Presto Common Driver} satisfied? true
2024-05-09 14:55:26,019 DEBUG plugins.initialize :: [33mDependencies satisfied; these plugins will now be loaded: [""Metabase Presto Driver""][0m
2024-05-09 14:55:26,021 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto...[0m
2024-05-09 14:55:26,022 INFO driver.impl :: [34mRegistered driver :presto[0m (parents: [:presto-common]) 
2024-05-09 14:55:26,045 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-05-09 14:55:26,048 INFO db.setup :: [36mVerifying postgres Database Connection ...[0m
2024-05-09 14:55:26,638 INFO db.setup :: Successfully verified PostgreSQL 15.5 application database connection. 
2024-05-09 14:55:26,639 INFO db.setup :: [36mChecking if a database downgrade is required...[0m
2024-05-09 14:55:27,602 INFO db.setup :: Running Database Migrations...
2024-05-09 14:55:27,604 INFO db.setup :: Setting up Liquibase...
2024-05-09 14:55:27,972 INFO db.setup :: Liquibase is ready.
2024-05-09 14:55:27,973 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-05-09 14:55:29,152 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-05-09 14:55:29,161 INFO db.liquibase :: No migration lock found.
2024-05-09 14:55:29,765 INFO db.liquibase :: Running 5 migrations ...
2024-05-09 14:55:30,449 INFO driver.impl :: [33mInitializing driver :sql...[0m
2024-05-09 14:55:30,449 INFO driver.impl :: [33mInitializing driver :sql-jdbc...[0m
2024-05-09 14:55:30,449 INFO driver.impl :: [33mInitializing driver :clickhouse...[0m
2024-05-09 14:55:30,450 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/clickhouse.metabase-driver.jar to classpath
2024-05-09 14:55:30,451 DEBUG plugins.init-steps :: [34mLoading plugin namespace metabase.driver.clickhouse...[0m
2024-05-09 14:55:30,535 INFO driver.impl :: [34mRegistered driver :clickhouse[0m (parents: [:sql-jdbc]) 
2024-05-09 14:55:30,567 DEBUG plugins.jdbc-proxy :: [34mRegistering JDBC proxy driver for com.clickhouse.jdbc.ClickHouseDriver...[0m
2024-05-09 14:55:30,570 INFO metabase.util :: [36m ⮦ [35mLoad lazy loading driver :clickhouse[0m took 118.3 ms[0m
2024-05-09 14:55:30,621 INFO driver.impl :: [33mInitializing driver :mysql...[0m
2024-05-09 14:55:30,645 INFO driver.impl :: [33mInitializing driver :postgres...[0m
2024-05-09 14:55:30,658 INFO driver.impl :: [33mInitializing driver :cubejs...[0m
2024-05-09 14:55:30,659 INFO plugins.classloader :: Added URL file:/home/metabase/metabase/plugins/cubejs.metabase-driver.jar to classpath
2024-05-09 14:55:30,660 DEBUG plugins.init-steps :: [34mLoading plugin namespace metabase.driver.cubejs...[0m
2024-05-09 14:55:30,677 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-04-09T10:00:03::qnkhuat encountered an exception.

UPDATE SUMMARY
Run:                          5
Previously run:             264
Filtered out:                17
-------------------------------
Total change sets:          286


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               17

2024-05-09 14:55:30,738 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader 'bootstrap')
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:305)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:287)
	at metabase.db.setup$migrate_BANG_$fn__51110.invoke(setup.clj:80)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___48786.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
	at clojure.lang.RestFn.invoke(RestFn.java:445)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
	at metabase.db.setup$setup_db_BANG_$fn__51138$fn__51139.invoke(setup.clj:165)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__51138.invoke(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__51158.invoke(db.clj:69)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)
	at metabase.db$setup_db_BANG_.invoke(db.clj:55)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:116)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:101)
	at metabase.core$init_BANG_.invokeStatic(core.clj:159)
	at metabase.core$init_BANG_.invoke(core.clj:154)
	at metabase.core$start_normally.invokeStatic(core.clj:171)
	at metabase.core$start_normally.invoke(core.clj:165)
	at metabase.core$entrypoint.invokeStatic(core.clj:204)
	at metabase.core$entrypoint.doInvoke(core.clj:198)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: java.lang.ClassCastException: class java.lang.ExceptionInInitializerError cannot be cast to class java.lang.Exception (java.lang.ExceptionInInitializerError and java.lang.Exception are in module java.base of loader 'bootstrap')
	at liquibase.command.CommandScope.logPrimaryExceptionToMdc(CommandScope.java:287)
	at liquibase.command.CommandScope.execute(CommandScope.java:245)
	... 49 more
2024-05-09 14:55:30,748 INFO metabase.core :: Metabase Shutting Down ...
2024-05-09 14:55:30,749 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-05-09 14:55:30,759 WARN db.liquibase :: ()
2024-05-09 14:55:30,762 INFO metabase.core :: Metabase Shutdown COMPLETE

```

qnkhuat (Assginee) on (2024-05-13 02:37:40 UTC): I'm also seeing a cubejs driver. Their [repo](https://github.com/pyrooka/metabase-cubejs-driver) is archived and is 2 years old and I'm pretty sure it's not compatible with the latest version of MB

So I think cubejs is the problem, not clickhouse.

Either way, when 49.9 is out, this should be fixed, or you can remove cubes and upgrade to 49.8 should work.

paoliniluis on (2024-05-13 21:21:09 UTC): Hi @sanel can you check the previous comment?

sanel (Issue Creator) on (2024-05-13 22:37:21 UTC): @paoliniluis it worked for me after I removed clickhouse driver. Actually, I removed plugins folder completely, leaving metabase to extract a fresh list of plugins. Do you need anything else from my side?

qnkhuat (Assginee) on (2024-05-14 03:36:14 UTC): should be a question for @dannyeuu

dannyeuu on (2024-05-14 12:26:50 UTC): Thanks, @sanel and @qnkhuat removing the cubejs plugin and upgrading to MB v0.49.9, and worked.

![Screenshot from 2024-05-14 09-25-39](https://github.com/metabase/metabase/assets/6808348/388249b9-e904-416b-a908-6465cfbd6ed0)

"
2282818440,issue,closed,completed,Support `Offset()` in custom columns,"FE work for #42132
Related Slack thread: https://metaboat.slack.com/archives/C06P22KS4JH/p1715072591646449

",kamilmielnik,2024-05-07 10:02:34+00:00,['kamilmielnik'],2024-05-16 06:48:35+00:00,2024-05-16 06:48:35+00:00,https://github.com/metabase/metabase/issues/42318,"[('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2111097956, 'issue_id': 2282818440, 'author': 'bshepherdson', 'body': 'Should this be tagged for 0.50 as a blocker?', 'created_at': datetime.datetime(2024, 5, 14, 20, 36, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2114184724, 'issue_id': 2282818440, 'author': 'kamilmielnik', 'body': 'Closed by #42326', 'created_at': datetime.datetime(2024, 5, 16, 6, 48, 35, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-05-14 20:36:51 UTC): Should this be tagged for 0.50 as a blocker?

kamilmielnik (Issue Creator) on (2024-05-16 06:48:35 UTC): Closed by #42326

"
2282389122,issue,closed,not_planned,Auto-detect Latin/Arabic encoded text in an uploaded csv file,"### Describe the bug

What I did:
1- Enabled uploading csv files from settings to (PostgreSQL Database)
2- Created the attached csv file 
[test.csv](https://github.com/metabase/metabase/files/15231189/test.csv)
3- Uploaded csv 
4- ![Screenshot 2024-05-07 092331](https://github.com/metabase/metabase/assets/62171887/d83b4bb5-917e-4590-85aa-41337fc65f72)



### To Reproduce

1. create a csv file and fill it with data in arabic letters or download the attached one
[test.csv](https://github.com/metabase/metabase/files/15231236/test.csv)

2. Enable Uploading csv from settings (https://yourmetabaselink/admin/settings/uploads)

3. Upload the csv

4.Display the Uploaded csv & See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-200.131.27.1.el8uek.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""postgres"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.36-0ubuntu0.22.04.1""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-16"",
      ""tag"": ""v0.49.6"",
      ""hash"": ""5abf130""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Riyadh""
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",AbdullahOmerDev,2024-05-07 06:29:32+00:00,[],2024-09-06 15:38:14+00:00,2024-09-06 15:38:14+00:00,https://github.com/metabase/metabase/issues/42313,"[('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2098048057, 'issue_id': 2282389122, 'author': 'calherries', 'body': '@El3aber the text in the CSV appears to be encoded with Latin/Arabic encoding. https://en.wikipedia.org/wiki/ISO/IEC_8859-6. If you first convert the file to UTF-8 encoding using a text editor, the upload should work.\r\n\r\nHere\'s the test file I uploaded:\r\n[utf8_test.csv](https://github.com/metabase/metabase/files/15234303/utf8_test.csv)\r\n\r\nAnd here\'s how it is displayed in Metabase:\r\n<img width=""393"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/481f86ff-4c06-414f-98e9-eaf70533e654"">\r\n\r\nI tested uploading the original test file and uploaded it to Google Sheets, and detects the correct encoding and displays it correctly. We could do the same thing, so I\'ve relabelled this as a feature request because it has an easy workaround. You could even upload the CSV file to google sheets, download it, and re-upload it into Metabase.', 'created_at': datetime.datetime(2024, 5, 7, 10, 42, 9, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-07 10:42:09 UTC): @El3aber the text in the CSV appears to be encoded with Latin/Arabic encoding. https://en.wikipedia.org/wiki/ISO/IEC_8859-6. If you first convert the file to UTF-8 encoding using a text editor, the upload should work.

Here's the test file I uploaded:
[utf8_test.csv](https://github.com/metabase/metabase/files/15234303/utf8_test.csv)

And here's how it is displayed in Metabase:
<img width=""393"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/481f86ff-4c06-414f-98e9-eaf70533e654"">

I tested uploading the original test file and uploaded it to Google Sheets, and detects the correct encoding and displays it correctly. We could do the same thing, so I've relabelled this as a feature request because it has an easy workaround. You could even upload the CSV file to google sheets, download it, and re-upload it into Metabase.

"
2282114207,issue,open,,We should provide a better error message when removing the visibility of the field,"### Describe the bug

If you create a query with a field that is taken out of visibility later, we send an error saying that the field does not exist, but it does, we just remove the visibility of it. We should send a message like ""this question has a hidden field and cannot be processed or something""

### To Reproduce

1) create a question like sum of total group by prod->category
2) save the question
3) now set that field to ""do not include"" in table metadata
4) run the question again and see the error (""column source.total does not exist"")

### Expected behavior

We should send the correct message

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

It has always been like that for sure",paoliniluis,2024-05-07 01:53:40+00:00,[],2025-02-04 20:27:54+00:00,,https://github.com/metabase/metabase/issues/42309,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('Administration/Table Metadata', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2282071206,issue,open,,`:alias/escaped->original` should be exempt from normalization and be a key of string => string,"This is an internal key used by the QP, it's getting normalized to `keyword => string` which can break queries that call MBQL normalization in the middle of QP preprocessing, since the `annotate` middleware assumes keys here are strings. We should make sure legacy MBQL and MLv2 normalization ensure the keys are strings.",camsaul,2024-05-07 01:16:59+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/42307,"[('Type:Bug', 'Product defects'), ('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2282067387,issue,open,,MLv2 schemas for value types like `:time` are incorrect,"MLv2 schemas for stuff like `:time` don't allow `:default` as a unit, and don't allow JDBC `java.time` literals like a `java.time.LocalTime`. The legacy MBQL schema allows these.

Failing test for `metabase.lib.schema.expression.temporal-test`

```clj
(deftest ^:parallel time-test
  (are [t] (not (me/humanize (mc/explain :mbql.clause/time [:time {:lib/uuid ""00000000-0000-0000-0000-000000000000""} t :default])))
    ""08:00""
    #?@(:clj [#t ""08:00""])))
```",camsaul,2024-05-07 01:14:31+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/42306,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2281878767,issue,closed,completed,Implement minimal viable serialization for Trash,"Serialization for the Trash collection needs to be carefully considered, and I hadn't researched serialization well enough before now to know exactly what it entailed. My understanding is still a bit limited, but I think the minimum viable v1 implementation is something like this:

- if you specify `--collections` to export, we should serialize items that were trashed _from_ one of those collections, as well as the items directly in that collection
- we do not need to serialize the Trash collection itself - it should be the same across all instances. But we can serialize it if not doing so is difficult - it's a few lines of YAML, and we'll set the `entity_id` such that the serdes system recognizes that it's the same entity in the destination database
- if you don't specify `--collections`, we should serialize items that are trashed, just like we do currently.
- `trashed_from_collection_id` should be converted to an entity ID on extraction, and back on load, just like `collection_id`
- `trashed_from_location` needs a similar conversion process, modeled on `location`

I think the most difficult part of this might be ensuring that the Trash collection is exported if necessary, while _not_ exporting _every_ item in the Trash. The existing serialization machinery has logic preventing ""escaping"", where e.g. a dashboard shows a card in a non-exported collection. Currently in this case it just warns the user and does not export any of the items. We'll need a way to say ""include this Collection in the serialization set... but not everything in it, just those items that were going to be included anyway.""",johnswanson,2024-05-06 22:17:00+00:00,['johnswanson'],2024-05-09 20:39:41+00:00,2024-05-09 20:39:41+00:00,https://github.com/metabase/metabase/issues/42301,[],"[{'comment_id': 2098238672, 'issue_id': 2281878767, 'author': 'bshepherdson', 'body': 'Each model (eg. Dashboards) can customize what it ""contains"", in terms of what should be serialized, when you do selective export (eg. `--collections`). It\'s powered by the multimethod `descendants` (not to be confused with `dependencies`!).\r\n\r\nSo it won\'t be hard to achieve the first point, by adjusting the `descendants` for collections to include both items in the collection and items in the Trash which were trashed from that collection.', 'created_at': datetime.datetime(2024, 5, 7, 11, 59, 10, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-05-07 11:59:10 UTC): Each model (eg. Dashboards) can customize what it ""contains"", in terms of what should be serialized, when you do selective export (eg. `--collections`). It's powered by the multimethod `descendants` (not to be confused with `dependencies`!).

So it won't be hard to achieve the first point, by adjusting the `descendants` for collections to include both items in the collection and items in the Trash which were trashed from that collection.

"
2281761972,issue,closed,completed,[Browse] Milestone 3: Cleanup,"```[tasklist]
### Tasks
- [ ] #42964
- [ ] https://github.com/metabase/metabase/issues/43014
- [ ] https://github.com/metabase/metabase/issues/42951
- [ ] https://github.com/metabase/metabase/issues/43253
- [x] Add ellipsis to descriptions
- [ ] #43251
- [ ] https://github.com/metabase/metabase/issues/42781
- [ ] https://github.com/metabase/metabase/issues/44157
```
",iethree,2024-05-06 21:00:54+00:00,[],2024-06-16 12:24:54+00:00,2024-06-16 12:24:53+00:00,https://github.com/metabase/metabase/issues/42298,[],[],
2281559281,issue,closed,completed,[Epic] Clickhouse upload CSV support for Cloud,"CH supporting CSV uploads supports https://github.com/metabase/harbormaster/issues/4931

```[tasklist]
###
- [ ] https://github.com/metabase/metabase/pull/42359
- [x] https://github.com/metabase/metabase/pull/42531
- [ ] https://github.com/ClickHouse/metabase-clickhouse-driver/pull/236
- [ ] https://github.com/metabase/metabase/pull/42851
- [ ] https://github.com/metabase/metabase/pull/42869
- [ ] https://github.com/ClickHouse/metabase-clickhouse-driver/pull/239
```",calherries,2024-05-06 19:11:32+00:00,['calherries'],2024-06-13 05:56:33+00:00,2024-06-13 05:56:33+00:00,https://github.com/metabase/metabase/issues/42294,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2155120143, 'issue_id': 2281559281, 'author': 'calherries', 'body': 'This is currently waiting on the ClickHouse driver release for 50: https://github.com/ClickHouse/metabase-clickhouse-driver/pull/239', 'created_at': datetime.datetime(2024, 6, 7, 15, 59, 59, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-06-07 15:59:59 UTC): This is currently waiting on the ClickHouse driver release for 50: https://github.com/ClickHouse/metabase-clickhouse-driver/pull/239

"
2281478535,issue,closed,completed,Filtering on date columns by relative dates returning wrong results,"### Describe the bug

We have recently started seeing duplicate records in our weekly alerts. This started around 2-3 weeks ago.

### To Reproduce

1. Go to https://stats.metabase.com/question/4859
2. Change filter on created at from past week 16 weeks ago, to past week from 17 weeks ago 
3. Realize there are some results that show up in both when they should not



### Expected behavior

There seems to be something wrong with this filter. This was reliable up until a few weeks ago and now we consistently have the duplicates every week.



### Logs

_No response_

### Information about your Metabase installation

```JSON
- Hash 649de4f 2024-05-06
```


### Severity

P2

### Additional context

Discussion in Slack w/ Loom: https://metaboat.slack.com/archives/C01LQQ2UW03/p1714409208479349",albertoperdomo,2024-05-06 18:27:16+00:00,['snoe'],2024-08-28 02:10:46+00:00,2024-06-24 20:18:54+00:00,https://github.com/metabase/metabase/issues/42291,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Team/Querying', '')]","[{'comment_id': 2097270934, 'issue_id': 2281478535, 'author': 'camsaul', 'body': 'Is this bug present in 49? What database(s) are affected?', 'created_at': datetime.datetime(2024, 5, 7, 2, 10, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097399063, 'issue_id': 2281478535, 'author': 'camsaul', 'body': 'Duplicate of #34573', 'created_at': datetime.datetime(2024, 5, 7, 3, 58, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097421018, 'issue_id': 2281478535, 'author': 'camsaul', 'body': 'Ok while this is extremely similar to #34573 I actually have a way to work around this on the BE', 'created_at': datetime.datetime(2024, 5, 7, 4, 26, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2140819470, 'issue_id': 2281478535, 'author': 'camsaul', 'body': '@albertoperdomo is reporting this is still not working as expected here https://metaboat.slack.com/archives/C01LQQ2UW03/p1716799511920049?thread_ts=1714409208.479349&cid=C01LQQ2UW03', 'created_at': datetime.datetime(2024, 5, 30, 20, 33, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180926387, 'issue_id': 2281478535, 'author': 'albertoperdomo', 'body': 'Upgraded to P1: Correctness of results, common feature', 'created_at': datetime.datetime(2024, 6, 20, 15, 1, 32, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-05-07 02:10:30 UTC): Is this bug present in 49? What database(s) are affected?

camsaul on (2024-05-07 03:58:03 UTC): Duplicate of #34573

camsaul on (2024-05-07 04:26:17 UTC): Ok while this is extremely similar to #34573 I actually have a way to work around this on the BE

camsaul on (2024-05-30 20:33:03 UTC): @albertoperdomo is reporting this is still not working as expected here https://metaboat.slack.com/archives/C01LQQ2UW03/p1716799511920049?thread_ts=1714409208.479349&cid=C01LQQ2UW03

albertoperdomo (Issue Creator) on (2024-06-20 15:01:32 UTC): Upgraded to P1: Correctness of results, common feature

"
2281439424,issue,open,,PostgreSQL connection transaction not closed cleanly at shutdown,"### Describe the bug

When I stop or restart Metabase, I see the following in my PostgreSQL server log printed once or twice:

> unexpected EOF on client connection with an open transaction

### To Reproduce

1. Start Metabase, connected to a PostgreSQL database.
2. Stop Metabase (in this case using `systemctl restart`, which sends a `TERM` signal).

### Expected behavior

Any open transactions should be committed or rolled back as part of a clean shutdown.

### Logs

Journal context:

```
May 06 18:42:48 server sudo[689324]:     user : TTY=pts/1 ; PWD=/home/user ; USER=root ; COMMAND=/usr/bin/systemctl restart metabase.service
May 06 18:42:48 server sudo[689324]: pam_unix(sudo:session): session opened for user root(uid=0) by user(uid=1000)
May 06 18:42:48 server systemd[1]: Stopping Metabase server...
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,634 INFO metabase.core :: Metabase Shutting Down ...
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,634 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_server1715017252397 shutting down.
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,634 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_server1715017252397 paused.
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,635 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_server1715017252397 shutdown complete.
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,636 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
May 06 18:42:48 server metabase[688937]: 2024-05-06 18:42:48,641 INFO metabase.core :: Metabase Shutdown COMPLETE
May 06 18:42:48 server systemd[1]: metabase.service: Deactivated successfully.
May 06 18:42:48 server systemd[1]: Stopped Metabase server.
May 06 18:42:48 server systemd[1]: metabase.service: Consumed 54.153s CPU time.
May 06 18:42:48 server postgres[689022]: 2024-05-06 18:42:48.981 BST [689022] LOG:  unexpected EOF on client connection with an open transaction
May 06 18:42:48 server postgres[689024]: 2024-05-06 18:42:48.988 BST [689024] LOG:  unexpected EOF on client connection with an open transaction
```

Connection pool details:

```json
{
  ""connection-pools"": {
    ""metabase-postgres-app-db"": {
      ""numConnections"": 7,
      ""numIdleConnections"": 6,
      ""numBusyConnections"": 1,
      ""minPoolSize"": 1,
      ""maxPoolSize"": 15,
      ""numThreadsAwaitingCheckoutDefaultUser"": 0
    },
    ""db-2-postgres-stats"": {
      ""numConnections"": 2,
      ""numIdleConnections"": 2,
      ""numBusyConnections"": 0,
      ""minPoolSize"": 1,
      ""maxPoolSize"": 15,
      ""numThreadsAwaitingCheckoutDefaultUser"": 0
    }
  }
}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:126.0) Gecko/20100101 Firefox/126.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""22"",
    ""java.vendor"": ""N/A"",
    ""java.vendor.url"": ""https://openjdk.org/"",
    ""java.version"": ""22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""22"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.7-arch1-2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/London""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Purely informational, no known impact

### Additional context

I'm unsure if this is coming from the internal database, the main connected database, or both -- looking at running processes, it appears to be the former based on the open transaction:

```
/usr/bin/postgres ...
...
├─ postgres: metabase metabase 127.0.0.1(34436) idle
├─ postgres: metabase metabase 127.0.0.1(34444) idle
├─ postgres: metabase metabase 127.0.0.1(34446) idle
├─ postgres: metabase metabase 127.0.0.1(34450) idle in transaction
├─ postgres: metabase metabase 127.0.0.1(57584) idle
├─ postgres: metabase metabase 127.0.0.1(57590) idle
├─ postgres: metabase metabase 127.0.0.1(57594) idle
├─ postgres: metabase stats 127.0.0.1(33072) idle
└─ postgres: metabase stats 127.0.0.1(33088) idle
```

Metabase and PostgreSQL are both running bare-metal.  Installed via [AUR](https://aur.archlinux.org/packages/metabase).",Terrance,2024-05-06 18:03:59+00:00,[],2024-05-07 10:09:28+00:00,,https://github.com/metabase/metabase/issues/42288,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Operation/', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2097194417, 'issue_id': 2281439424, 'author': 'paoliniluis', 'body': 'Please downgrade Java to v11', 'created_at': datetime.datetime(2024, 5, 7, 1, 26, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097680303, 'issue_id': 2281439424, 'author': 'Terrance', 'body': 'No change running under Java 11.', 'created_at': datetime.datetime(2024, 5, 7, 7, 56, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097937391, 'issue_id': 2281439424, 'author': 'calherries', 'body': ""I reproduced on master (43c0ce979a) using Postgres as the app DB. The open transactions are on the Metabase app DB, not a connected database, because I didn't have any postgres DBs connected when I shut down Metabase."", 'created_at': datetime.datetime(2024, 5, 7, 10, 9, 27, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-07 01:26:36 UTC): Please downgrade Java to v11

Terrance (Issue Creator) on (2024-05-07 07:56:45 UTC): No change running under Java 11.

calherries on (2024-05-07 10:09:27 UTC): I reproduced on master (43c0ce979a) using Postgres as the app DB. The open transactions are on the Metabase app DB, not a connected database, because I didn't have any postgres DBs connected when I shut down Metabase.

"
2281312583,issue,closed,completed,[dc.js migration] static charts crash on stats,"https://metaboat.slack.com/archives/C010L1Z4F9S/p1715010583355849
<img width=""457"" alt=""Screenshot 2024-05-06 at 1 53 44 PM"" src=""https://github.com/metabase/metabase/assets/14301985/d4c4072c-5e32-4b6b-9549-5eb882c9a2f6"">

<img width=""405"" alt=""Screenshot 2024-05-06 at 1 56 41 PM"" src=""https://github.com/metabase/metabase/assets/14301985/6b5ef93f-fbaf-4cd3-9e9e-49a40631128e"">

<img width=""422"" alt=""Screenshot 2024-05-06 at 1 56 50 PM"" src=""https://github.com/metabase/metabase/assets/14301985/4059e727-efc9-46fe-bc20-2da21621cdf6"">

",alxnddr,2024-05-06 16:53:23+00:00,['alxnddr'],2024-05-14 23:20:32+00:00,2024-05-14 23:20:31+00:00,https://github.com/metabase/metabase/issues/42282,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2281307108,issue,closed,completed,[dc.js migration] Data labels auto-compactness should not be recomputed on hovers,"Data labels auto-compactness should not be recomputed on hovers because it causes noticeable lags.
Extend `ChartMeasurements` with a property `dataLabelsFormat: ""full"" | ""compact"" | ""default""` and set it based on the viz settings and the auto-compactness algorithm.",alxnddr,2024-05-06 16:50:57+00:00,['JesseSDevaney'],2024-05-17 18:18:25+00:00,2024-05-17 18:18:24+00:00,https://github.com/metabase/metabase/issues/42281,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2099279675, 'issue_id': 2281307108, 'author': 'alxnddr', 'body': ""@JesseSDevaney I'll take this since it is convenient to fix while implementing https://github.com/metabase/metabase/pull/42247"", 'created_at': datetime.datetime(2024, 5, 7, 20, 46, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2118155708, 'issue_id': 2281307108, 'author': 'JesseSDevaney', 'body': '- Closed by: https://github.com/metabase/metabase/pull/42616', 'created_at': datetime.datetime(2024, 5, 17, 18, 18, 25, tzinfo=datetime.timezone.utc)}]","alxnddr (Issue Creator) on (2024-05-07 20:46:42 UTC): @JesseSDevaney I'll take this since it is convenient to fix while implementing https://github.com/metabase/metabase/pull/42247

JesseSDevaney (Assginee) on (2024-05-17 18:18:25 UTC): - Closed by: https://github.com/metabase/metabase/pull/42616

"
2281046455,issue,open,,Visual alert for failing token validation,"**Is your feature request related to a problem? Please describe.**
Token expiry or intermittent network issues may cause the token check fail and result in paid features becoming unavailable.
Currently the users are not notified about this condition in any way.

**Describe the solution you'd like**
A visual alert telling that paid features are not available, and if feasible also informing the users / admins about the likely cause, and directing them to act accordingly.

**Describe alternatives you've considered**
Users may consider monitoring `/api/premium-features/token/status externally.

**How important is this feature to you?**
Was pointed out by a customer who had intermittent ticket validation problems.

**Additional context**
This relates to https://github.com/metabase/metabase/issues/38365 (alerting for licences soon-to-expire).",zbodi74,2024-05-06 14:41:17+00:00,[],2024-05-07 08:55:37+00:00,,https://github.com/metabase/metabase/issues/42280,"[('Type:New Feature', ''), ('Administration/', '')]",[],
2281015068,issue,closed,completed,[FE] E2E tests for metrics,"### metrics-editing.cy.spec.ts

location:
- [x] homepage
- [x] auto pinning

data source:
- [x] table
- [x] question single/multi stage 
- [x] model single/multi stage
- [x] metric single/multi stage

joins:
- [x] join a table/question/model in metric queries
- [x] not possible to join a metric
- [x] not possible to join on the first stage of a metric-based query
- [x] join on the second stage of a metric query

columns:
- [x] single stage
- [x] multi stage
- [x] implicit joins
- [x] expression editor when the metric is already used

filters:
- [x] single stage
- [x] multi stage
- [x] implicit joins

breakouts:
- [x] timeseries/geo metrics
- [x] multi stage

aggregations:
- [x] simple operators
- [x] custom aggregation expressions
- [x] multi stage
- [x] multiple intermediate aggregations
- [x] table metric / non-table

organization:
- [x] name
- [x] edit table/question/model/metric-based query

### metrics-question.cy.spec.ts
- [x] move
- [x] should be able to add a filter
- [x] should be able to add a breakout
- [x] should be able to change the temporal unit 
- [x] drill with aggregation
- [x] drill without aggregation
- [x] no data access
- [x] no collection access

### metrics-dashboard.cy.spec.ts

- [x] add & search for metrics
- [x] combine scalar metrics
- [x] combine timeseries metrics
- [x] filter + drill with aggregation
- [x] filter + drill without aggregation
- [x] click behavior
- [x] no data access
- [x] no collection access

### metrics-collection.cy.spec.ts

- [x] can view scalar and timeseries metrics
- [x] can pin and unpin metrics
- [x] can bookmark a metric and remove it from bookmarks
- [x] can archive and unarchive a metric (both toast and via archive page)

### metrics-search.cy.spec.ts
- [x] global search
- [x] search page
- [x] recent items
- [x] popular items
",ranquild,2024-05-06 14:27:02+00:00,['ranquild'],2024-05-14 21:25:49+00:00,2024-05-14 21:14:28+00:00,https://github.com/metabase/metabase/issues/42278,[],[],
2280949011,issue,open,,Different coloring for positive and negative values in visualisation,"I'm creating some data visualisations based upon a financial dataset.

It's particularly important to highlight when companies have positive or negative values, as in the following chart highlighting some companies which have net positive 'impact' and those with net negative 'impact'.

![productimpact](https://github.com/metabase/metabase/assets/40233203/48144492-26fe-4ecf-96b5-13a7e7285b0f)

It would be ideal to be able to set different colors for different values.

In this case:

- All positive values (to the right of the zero line) colored in green
- All negative values (to the left of the zero line) colored in red

As far as I can see, there isn't a way to configure this in visualisation options so I thought I'd drop in with it as a feature request 😊
",danielrosehill,2024-05-06 13:58:25+00:00,[],2024-05-07 09:01:30+00:00,,https://github.com/metabase/metabase/issues/42275,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Visualization/Charts/Row', '')]","[{'comment_id': 2097801486, 'issue_id': 2280949011, 'author': 'Tony-metabase', 'body': 'Related to https://github.com/metabase/metabase/issues/3168', 'created_at': datetime.datetime(2024, 5, 7, 9, 1, 28, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-05-07 09:01:28 UTC): Related to https://github.com/metabase/metabase/issues/3168

"
2280873694,issue,open,,Auto-scroll to selected Entity Picker item (vertically),"When opening the Data Picker with a pre-selected value, the column with that item should auto-scroll to that item vertically (this should affect parent columns as well).

https://github.com/metabase/metabase/assets/6830683/6d1e725d-7e49-4439-be24-f84d8f1489f3

",kamilmielnik,2024-05-06 13:21:55+00:00,[],2024-07-02 09:09:41+00:00,,https://github.com/metabase/metabase/issues/42274,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2102873256, 'issue_id': 2280873694, 'author': 'iethree', 'body': 'This functionality is actually in there, but it sometimes doesnt work due to a race condition 🫠', 'created_at': datetime.datetime(2024, 5, 9, 15, 20, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202423610, 'issue_id': 2280873694, 'author': 'kamilmielnik', 'body': '> This functionality is actually in there, but it sometimes doesnt work due to a race condition 🫠\r\n\r\nReassigning to Team AdminWebapp since this issue is not specific to the Query Builder.\r\n\r\nPossibly related to #44966 (it could potentially amplify this issue).', 'created_at': datetime.datetime(2024, 7, 2, 9, 9, 1, tzinfo=datetime.timezone.utc)}]","iethree on (2024-05-09 15:20:43 UTC): This functionality is actually in there, but it sometimes doesnt work due to a race condition 🫠

kamilmielnik (Issue Creator) on (2024-07-02 09:09:01 UTC): Reassigning to Team AdminWebapp since this issue is not specific to the Query Builder.

Possibly related to #44966 (it could potentially amplify this issue).

"
2280733583,issue,open,,Nested questions with `?` operator may fail when filtered,"### Describe the bug

Native questions using the `?` json operator fail when nested and filtered using either a text filter, or a date range filter. I've noticed this on Postgres, I haven't checked if it occurs with other db-s as well.

On Postgres, the workaround is to replace the `?` operator with its equivalent:`??`. [PostgreSQL doc on this:](https://jdbc.postgresql.org/documentation/query/#using-the-resultset-interface)
> In JDBC, the question mark (?) is the placeholder for the positional parameters of a PreparedStatement. There are, however, a number of PostgreSQL® operators that contain a question mark. To keep such question marks in an SQL statement from being interpreted as positional parameters, use two question marks ( ?? ) as escape sequence. You can also use this escape sequence in a Statement , but that is not required. Specifically only in a Statement a single ( ? ) can be used as an operator.

### To Reproduce

1. Using PostgreSQL, create an SQL question: 
```
select '{""abc"":123, ""def"":""ghi""}'::jsonb->'def' ? 'ghi' as col1, current_date as col2, 'some text' as col3
```
2. Save it
3. Explore Results
4. (!) Filter on Col2 (the date field), using 'Specific dates...', and see the error: 'No value specified for Parameter 3'
5. (!) Filter on Col3 (the text field), and see the error: 'No value specified for Parameter 2'

<img width=""422"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/fdca3ce0-5743-4856-a3c7-8a3df6314ab5"">


### Expected behavior

Appears to be a special case of https://github.com/metabase/metabase/issues/1964, which has been solved long ago, so I think this case should work too.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.75-0-virt"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3 (a workaround exists)

### Additional context

_No response_",zbodi74,2024-05-06 12:10:08+00:00,[],2025-02-06 12:26:32+00:00,,https://github.com/metabase/metabase/issues/42271,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Limitation', ''), ('Querying/Nested Queries', 'Questions based on other saved questions'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2201294410, 'issue_id': 2280733583, 'author': 'camsaul', 'body': 'This is a limitation, since `?` in JDBC is interpreted as a parameter placeholder you have to escape Postgres JSON operators and use `??` instead.\r\n\r\nDuplicate of #1964', 'created_at': datetime.datetime(2024, 7, 1, 22, 51, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639688925, 'issue_id': 2280733583, 'author': 'Caerbannog', 'body': 'I\'m not sure if this is the same bug but on Metabase 0.52.5 if you save the following question:\n\n![Image](https://github.com/user-attachments/assets/0cae3856-195b-4c61-873c-8ec2c043728b)\n\nThen when you ""Explore from a saved question"" the query builder does not allow full grouping. The ""Group by"" selector is empty:\n\n![Image](https://github.com/user-attachments/assets/14c2f6bc-260c-4fcc-b499-105e1821cc49)\n\nThis can be worked around by changing `where j ? \'b\'` in the initial query to:\n```\nwhere j @> \'""b""\'::jsonb;\n```\n\nSo... SQL parsing is messed up and this shows up in unexpected places.', 'created_at': datetime.datetime(2025, 2, 6, 12, 26, 31, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-07-01 22:51:04 UTC): This is a limitation, since `?` in JDBC is interpreted as a parameter placeholder you have to escape Postgres JSON operators and use `??` instead.

Duplicate of #1964

Caerbannog on (2025-02-06 12:26:31 UTC): I'm not sure if this is the same bug but on Metabase 0.52.5 if you save the following question:

![Image](https://github.com/user-attachments/assets/0cae3856-195b-4c61-873c-8ec2c043728b)

Then when you ""Explore from a saved question"" the query builder does not allow full grouping. The ""Group by"" selector is empty:

![Image](https://github.com/user-attachments/assets/14c2f6bc-260c-4fcc-b499-105e1821cc49)

This can be worked around by changing `where j ? 'b'` in the initial query to:
```
where j @> '""b""'::jsonb;
```

So... SQL parsing is messed up and this shows up in unexpected places.

"
2280120934,issue,open,,Postgres: unable to search uuid field,"### Describe the bug

Contains search on an uuid field throws an error

### To Reproduce

1. Create postgres database and a table with an uuid field
```sql
CREATE TABLE uuid_table (id uuid PRIMARY KEY);
INSERT INTO uuid_table (id) VALUES ('550e8400-e29b-41d4-a716-446655440000'), ('550e8400-e29b-41d4-a716-446655440001');
```
2. Connect this database to metabase
3. execute this in the repl
```clojure
(def table    (toucan2.core/select-one :model/Table :name ""uuid_table""))
(def field-id (toucan2.core/select-one-pk :model/Field :table_id (:id table) :name ""id""))

(metabase.query-processor/process-query {:database (:db_id table)
                                         :type :query
                                         :query {:source-table (:id table)
                                                 :breakout     [:field field-id nil]
                                                 :filter       [:contains [:field field-id nil] """"]}})
;; => ; (err) Execution error (IllegalArgumentException) at java.util.UUID/fromString1 (UUID.java:280).
;;    ; (err) Invalid UUID string: %%
```


### Expected behavior

Should be able to search

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

P2?

### Additional context

Context: https://metaboat.slack.com/archives/C05MPF0TM3L/p1714973576198549?thread_ts=1714616294.801369&cid=C05MPF0TM3L",qnkhuat,2024-05-06 06:21:27+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/42265,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Postgres', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2279926508,issue,closed,not_planned,The decimal columns in starrocks cannot be mapped the specific type in metabase,"### Describe the bug

The decimal columns whose 'database_type' are 'DECIMAL64' or 'DECIMAL128' in StarRocks cannot be mapped the specific types like 'Decimal' in metabase, which causes that we can't use such columns to filter.

Pic1:
![image](https://github.com/metabase/metabase/assets/25549512/0c7c1f65-87ea-4300-b386-318a5fe22187)
Pic2:
![image](https://github.com/metabase/metabase/assets/25549512/4a304b57-d5a9-4985-b38a-2474ecdcb190)
Pic3:
![image](https://github.com/metabase/metabase/assets/25549512/339c66ba-ed0b-4057-bcc8-b44e8a20b369)


### Information about your Metabase installation

- Operating system: CentOS 7
- Database: StarRocks
- Metabase version: v0.49.6
- Metabase hosting environment: Docker
- Metabase internal database: Postgres


### Severity

Medium. We can't use some decimal columns to filter when we use question editor.
",Jerrylovescoding,2024-05-06 03:03:32+00:00,[],2024-05-06 13:18:24+00:00,2024-05-06 13:17:23+00:00,https://github.com/metabase/metabase/issues/42264,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2095999665, 'issue_id': 2279926508, 'author': 'calherries', 'body': 'StarRocks does not have its own MB driver, I think it only works with the MySQL/MariaDB driver by ""coincidence"". If you\'d like Metabase to support StarRocks upvote the issue [here](https://github.com/metabase/metabase/issues/28081).', 'created_at': datetime.datetime(2024, 5, 6, 13, 17, 23, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-06 13:17:23 UTC): StarRocks does not have its own MB driver, I think it only works with the MySQL/MariaDB driver by ""coincidence"". If you'd like Metabase to support StarRocks upvote the issue [here](https://github.com/metabase/metabase/issues/28081).

"
2279728735,issue,closed,completed,[Epic] Databricks JDBC,"**Links**
- product doc: N/A
- eng doc: N/A
- feature branch: [`databricks-jdbc`](https://github.com/metabase/metabase/tree/databricks-jdbc)

**Implementation Plan**

```[tasklist]
### Impl
- [x] Implement driver base
- [x] Make sync work
- [x] Examine usability of existing tests
- [ ] https://github.com/metabase/metabase/issues/43497
- [ ] https://github.com/metabase/metabase/issues/43854
- [ ] https://github.com/metabase/metabase/issues/43857
- [ ] https://github.com/metabase/metabase/issues/43858
- [ ] https://github.com/metabase/metabase/issues/44083
```
Further tasks will be added based on results of existing.",lbrdnk,2024-05-05 20:58:08+00:00,['lbrdnk'],2024-09-26 14:22:22+00:00,2024-09-26 14:22:21+00:00,https://github.com/metabase/metabase/issues/42262,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', ''), ('Database/Databricks', '')]",[],
2279581404,issue,closed,not_planned,Feature request: the ability to add images into dashboards,"A picture speaks a thousand words!

While I'm working on getting a ""proper"" frontend in place for my idea, I'm currently using the dashboard feature to create some internal pages (I've created a 'welcome' dashboard and set that as the default screen in Metabase).

V1 looks something like this:

![2024-05-05_18-15](https://github.com/metabase/metabase/assets/40233203/1edd5550-aaf4-4460-a308-86eae43bd820)

Images really help to break up the text but aren't currently supported as an entity in Metabase (at least natively).

To work around that, I'm uploading images and then linking to them using Markdown:

![2024-05-05_18-15_1](https://github.com/metabase/metabase/assets/40233203/497a4f11-1dee-4e1f-9cf2-c86fe7e5c579)

It would be incredibly helpful if there were a way to natively upload images into the Metabase backend and serve them as embed objects! 

Preferably also with options for:

-> Display size
-> Caption (displayed)
-> Alt caption (for SEO and accessability) 
",danielrosehill,2024-05-05 15:18:49+00:00,[],2024-05-29 19:02:20+00:00,2024-05-29 19:02:19+00:00,https://github.com/metabase/metabase/issues/42260,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2117747914, 'issue_id': 2279581404, 'author': 'ignacio-mb', 'body': 'Hi @danielrosehill thanks for the feedback! We currently have this older issue for that: https://github.com/metabase/metabase/issues/27674. Would that be what you are looking for? Please feel free to add your comments to that thread.', 'created_at': datetime.datetime(2024, 5, 17, 14, 34, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2138076136, 'issue_id': 2279581404, 'author': 'ignacio-mb', 'body': 'Closing as dupe', 'created_at': datetime.datetime(2024, 5, 29, 19, 2, 20, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-05-17 14:34:55 UTC): Hi @danielrosehill thanks for the feedback! We currently have this older issue for that: https://github.com/metabase/metabase/issues/27674. Would that be what you are looking for? Please feel free to add your comments to that thread.

ignacio-mb on (2024-05-29 19:02:20 UTC): Closing as dupe

"
2279553148,issue,open,,Extend driver multimethod version testing also to test extensions,Currently we add `:added` metadata to multimethods in `metabase.driver*` namespaces and test for that. We should consider extending this practice also to test extensions multimethods and update the test accordingly. The test lives in [`impl_test.clj`](https://github.com/metabase/metabase/blob/baa9b81bd7c2a887cbdefee09d1ebe71e919f0a0/test/metabase/driver/impl_test.clj#L96).,lbrdnk,2024-05-05 14:14:30+00:00,[],2025-02-04 20:29:48+00:00,,https://github.com/metabase/metabase/issues/42259,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2279547865,issue,closed,not_planned,Can't update mongodbUri But can Add it.,"I can't update mongoDb URI. i have this error

Command failed with error 13 (Unauthorized): 'not authorized on bjqq7oc53aaafc2bu67p to execute command { dbStats: 1, $db: ""bjqq7oc53aaafc2bu67p"", $clusterTime: { clusterTime: Timestamp(1714917647, 28), signature: { hash: BinData(0, C4C01264F1C2B221B712A89B4663AA32AB400E1F), keyId: 7331493712389734408 } }, lsid: { id: UUID(""78268a7e-3376-4648-8a85-de2c1d83f135"") } }' on server n2-c2-mongodb-yaakadev-customers.services.clever-cloud.com:5617. The full response is {""operationTime"": {""$timestamp"": {""t"": 1714917647, ""i"": 28}}, ""ok"": 0.0, ""errmsg"": ""not authorized on bjqq7oc53aaafc2bu67p to execute command { dbStats: 1, $db: \""bjqq7oc53aaafc2bu67p\"", $clusterTime: { clusterTime: Timestamp(1714917647, 28), signature: { hash: BinData(0, C4C01264F1C2B221B712A89B4663AA32AB400E1F), keyId: 7331493712389734408 } }, lsid: { id: UUID(\""78268a7e-3376-4648-8a85-de2c1d83f135\"") } }"", ""code"": 13, ""codeName"": ""Unauthorized"", ""$clusterTime"": {""clusterTime"": {""$timestamp"": {""t"": 1714917647, ""i"": 28}}, ""signature"": {""hash"": {""$binary"": {""base64"": ""xMASZPHCsiG3EqibRmOqMqtADh8="", ""subType"": ""00""}}, ""keyId"": 7331493712389734408}}}

URI and manual config are différent, i don't understand, I can't update manual config to delete all.

**Screenshots**
If applicable, add screenshots to help explain your problem.

<img width=""677"" alt=""image"" src=""https://github.com/metabase/metabase/assets/12745925/2c796d60-2fb0-4069-baea-55f6522e9de5"">
<img width=""755"" alt=""image"" src=""https://github.com/metabase/metabase/assets/12745925/098b7ce3-4dbe-4319-bdbb-8251967dbdee"">


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 OPR/107.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.6-clevercloud-vm-dirty"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",charlou28,2024-05-05 14:02:28+00:00,[],2025-01-23 20:53:48+00:00,2025-01-23 20:53:48+00:00,https://github.com/metabase/metabase/issues/42258,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Unable to Reproduce', ''), ('.Backend', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2097196063, 'issue_id': 2279547865, 'author': 'paoliniluis', 'body': 'do you have any logs from the server?', 'created_at': datetime.datetime(2024, 5, 7, 1, 28, 29, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-07 01:28:29 UTC): do you have any logs from the server?

"
2279508451,issue,open,,Vertical/rotated axis title text is rendered incorrectly,"### Describe the bug

Vertical, rotated y-axis titles are rendered pixelated, without antialiasing in all charts with y-axis, as in the screenshot:
![image](https://github.com/metabase/metabase/assets/11353865/287db48a-6c15-486a-91ab-afae6ef6f74c)


### To Reproduce

1. Create a new SQL query as `select 'test' as category, 1 as ""Incorrectly rendered rotated text""`
2. Execute it
3. Switch visualization to 'Bar'


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.84-99.169.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    }
  }
}
```


### Severity

Minimal

### Additional context

_No response_",mkrauter,2024-05-05 12:31:13+00:00,[],2024-05-20 20:55:10+00:00,,https://github.com/metabase/metabase/issues/42257,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2096020671, 'issue_id': 2279508451, 'author': 'calherries', 'body': ""I can't reproduce using the steps above, although I'm using a MacBook and Chrome. But from the screenshot above all the text looks pixelated to me. @mkrauter What browser are you using, and what resolution is your display?"", 'created_at': datetime.datetime(2024, 5, 6, 13, 27, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096217158, 'issue_id': 2279508451, 'author': 'mkrauter', 'body': 'Windows 10 Home x64, version 22H2, build 19045.4291\r\nChrome 124.0.6367.119 (Official Build) (64-bit)\r\nHave two displays: 1920x1080, 1920x1200, no difference\r\nChrome console shows no related error\r\nElement style:\r\n![image](https://github.com/metabase/metabase/assets/11353865/63d362ea-76da-49da-81a6-2b2d01c2ff69)\r\n\r\nAlso a 2x enlarged image:\r\n![image](https://github.com/metabase/metabase/assets/11353865/d72cea78-23a7-43df-b6d2-82aada404ffb)', 'created_at': datetime.datetime(2024, 5, 6, 14, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097751682, 'issue_id': 2279508451, 'author': 'calherries', 'body': ""I'm struggling to reproduce this on my MacBook Pro 16-inch display. I adjusted my screen to 1280x828 and it still looks much better than that. \r\n\r\n![image](https://github.com/metabase/metabase/assets/39073188/5ae5c90c-2f00-49f5-ad9d-25546bb573a0)\r\n\r\nI'll ask someone else on the frontend team who might be able to troubleshoot."", 'created_at': datetime.datetime(2024, 5, 7, 8, 35, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097800938, 'issue_id': 2279508451, 'author': 'perivamsi', 'body': 'I expect this to be solved by echarts', 'created_at': datetime.datetime(2024, 5, 7, 9, 1, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101748626, 'issue_id': 2279508451, 'author': 'camsaul', 'body': 'Works fine for me on Windows 11 with a 4k monitor and [Brave Version 1.65.126 Chromium: 124.0.6367.118 (Official Build) (64-bit)](https://brave.com/latest/). This is on `master` tho\r\n\r\n<img width=""1403"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1455846/45677aa3-b453-4347-a34b-baad3b54398e"">', 'created_at': datetime.datetime(2024, 5, 9, 1, 13, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2121191407, 'issue_id': 2279508451, 'author': 'cdeweyx', 'body': 'Unable to repro core issue, looks fixed. Leaving open though until we clean up the spacing, since things still look hella crowded on the y-axis:\r\n<img width=""871"" alt=""Screenshot 2024-05-20 at 16 52 54"" src=""https://github.com/metabase/metabase/assets/16455495/0658ed80-ad3d-4f1a-a060-ec7e88133597"">', 'created_at': datetime.datetime(2024, 5, 20, 20, 55, 8, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-06 13:27:23 UTC): I can't reproduce using the steps above, although I'm using a MacBook and Chrome. But from the screenshot above all the text looks pixelated to me. @mkrauter What browser are you using, and what resolution is your display?

mkrauter (Issue Creator) on (2024-05-06 14:49:00 UTC): Windows 10 Home x64, version 22H2, build 19045.4291
Chrome 124.0.6367.119 (Official Build) (64-bit)
Have two displays: 1920x1080, 1920x1200, no difference
Chrome console shows no related error
Element style:
![image](https://github.com/metabase/metabase/assets/11353865/63d362ea-76da-49da-81a6-2b2d01c2ff69)

Also a 2x enlarged image:
![image](https://github.com/metabase/metabase/assets/11353865/d72cea78-23a7-43df-b6d2-82aada404ffb)

calherries on (2024-05-07 08:35:12 UTC): I'm struggling to reproduce this on my MacBook Pro 16-inch display. I adjusted my screen to 1280x828 and it still looks much better than that. 

![image](https://github.com/metabase/metabase/assets/39073188/5ae5c90c-2f00-49f5-ad9d-25546bb573a0)

I'll ask someone else on the frontend team who might be able to troubleshoot.

perivamsi on (2024-05-07 09:01:12 UTC): I expect this to be solved by echarts

camsaul on (2024-05-09 01:13:33 UTC): Works fine for me on Windows 11 with a 4k monitor and [Brave Version 1.65.126 Chromium: 124.0.6367.118 (Official Build) (64-bit)](https://brave.com/latest/). This is on `master` tho

<img width=""1403"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1455846/45677aa3-b453-4347-a34b-baad3b54398e"">

cdeweyx on (2024-05-20 20:55:08 UTC): Unable to repro core issue, looks fixed. Leaving open though until we clean up the spacing, since things still look hella crowded on the y-axis:
<img width=""871"" alt=""Screenshot 2024-05-20 at 16 52 54"" src=""https://github.com/metabase/metabase/assets/16455495/0658ed80-ad3d-4f1a-a060-ec7e88133597"">

"
2279483632,issue,open,,Removing a private key and adding a password results in connection failure on Snowflake,"### Description
While editing existing database, removing a private key and adding a password results in connection failure on Snowflake.

### Steps to reproduce
1. Add a Snowflake database using private key auth. So far all good, sync works.
2. Go to admin > databases > your shiny new database.
3. Click on `Select a file` in `RSA private key (PKCS#8/.p8)` section and click cancel -- the existing private key is removed.
4. Then add a correct password for the user and hit save.
5. Failure is shown due to attempt to use empty private key, see the _Error_ section.

### Note on cloud vs local deployment
I assume use of cloud instance. Using eg. local deployment, step 3 would contain selector for local or uploaded key. ~~I believe the error would be the same reproducing locally _with upload option selected_, removing previously used private key.~~ That is not true.

### Error
```
ERROR: null value in column ""value"" of relation ""secret"" violates not-null constraint
Detail: Failing row contains (39, 5, 39, 2024-05-05 11:19:34.01569+00, 2024-05-05 11:19:34.01569+00, RSA private key (PKCS#8/.p8) for XXX XXX XXX, pem-cert, null, null).
```

### Clues
I suspect the cause to be FE sending `{ details: { private-key-value: """"} }` in the payload, whereas if there was no private key used previously details contain following `{ details: { private-key-value: null} }`.

### Workaround
None that I'm aware of.

### Misc

I've discovered the issue while trying to address what's in https://github.com/metabase/metabase/issues/41852#issuecomment-2093287699.",lbrdnk,2024-05-05 11:36:22+00:00,[],2025-02-04 20:27:53+00:00,,https://github.com/metabase/metabase/issues/42256,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2279228057,issue,closed,not_planned,Aggregation per Week on Metabase when using it integrated to Cube,"### Describe the bug

I am using Cube to create the semantic layer on the company I work, and when I use the week aggregation it does not work. It gives the following error:

`ERROR: Execution error: Type Interval(DayTime) is not supported in response transformation from Cube`

And this is because it makes a query that does not make sense at Cube:

```
SELECT 
  ( 
    DATE_TRUNC( 
      'week', 
      ( 
        ""public"".""table_here"".""dt_created_at_week"" + INTERVAL '1 day' 
      ) 
    ) + INTERVAL '-1 day' 
  ) AS ""dt_created_at_week"", 
  COUNT(*) AS ""count"" 
FROM 
  ""public"".""table_here"" 
GROUP BY 
  ( 
    DATE_TRUNC( 
      'week', 
      ( 
        ""public"".""table_here"".""dt_created_at_week"" + INTERVAL '1 day' 
      ) 
    ) + INTERVAL '-1 day' 
  ) 
ORDER BY 
  ( 
    DATE_TRUNC( 
      'week', 
      ( 
        ""public"".""table_here"".""dt_created_at_week"" + INTERVAL '1 day' 
      ) 
    ) + INTERVAL '-1 day' 
  ) ASC 
```



### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.214-202.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v1.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking my usage of Metabase

### Additional context

_No response_",LarissaSiqueirabp,2024-05-04 22:52:11+00:00,[],2024-05-09 01:50:42+00:00,2024-05-07 09:16:23+00:00,https://github.com/metabase/metabase/issues/42255,"[('Type:Bug', 'Product defects'), ('Querying/MBQL', ''), ('.Backend', '')]","[{'comment_id': 2096673033, 'issue_id': 2279228057, 'author': 'calherries', 'body': ""@LarissaSiqueirabp this is an issue for the Cube team, not for Metabase. Cube is using the Postgres driver that we support and we don't maintain it with Cube in mind. Can you raise an issue [on their repo instead](https://github.com/cube-js/cube/issues)? If Cube isn't compatible with Postgres they could maintain their own separate driver."", 'created_at': datetime.datetime(2024, 5, 6, 18, 38, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097240737, 'issue_id': 2279228057, 'author': 'paoliniluis', 'body': 'Hi @LarissaSiqueirabp can you contact also the Cube team? we have just pinged them so we can fix this together. Thanks!', 'created_at': datetime.datetime(2024, 5, 7, 1, 54, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097685791, 'issue_id': 2279228057, 'author': 'ovr', 'body': 'There are two ways how to make it work:\r\n\r\n- Change Metabase settings to use Monday week instead of Sunday.\r\n- Enable SQL push-down feature in Cube via `CUBESQL_SQL_PUSH_DOWN=true`\r\n\r\nThanks', 'created_at': datetime.datetime(2024, 5, 7, 7, 59, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097830886, 'issue_id': 2279228057, 'author': 'Tony-metabase', 'body': 'Closing this and leaving this as reference as well https://github.com/cube-js/cube/issues/6332', 'created_at': datetime.datetime(2024, 5, 7, 9, 16, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101785951, 'issue_id': 2279228057, 'author': 'paoliniluis', 'body': '@LarissaSiqueirabp have you seen the comments?', 'created_at': datetime.datetime(2024, 5, 9, 1, 50, 41, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-06 18:38:58 UTC): @LarissaSiqueirabp this is an issue for the Cube team, not for Metabase. Cube is using the Postgres driver that we support and we don't maintain it with Cube in mind. Can you raise an issue [on their repo instead](https://github.com/cube-js/cube/issues)? If Cube isn't compatible with Postgres they could maintain their own separate driver.

paoliniluis on (2024-05-07 01:54:26 UTC): Hi @LarissaSiqueirabp can you contact also the Cube team? we have just pinged them so we can fix this together. Thanks!

ovr on (2024-05-07 07:59:47 UTC): There are two ways how to make it work:

- Change Metabase settings to use Monday week instead of Sunday.
- Enable SQL push-down feature in Cube via `CUBESQL_SQL_PUSH_DOWN=true`

Thanks

Tony-metabase on (2024-05-07 09:16:14 UTC): Closing this and leaving this as reference as well https://github.com/cube-js/cube/issues/6332

paoliniluis on (2024-05-09 01:50:41 UTC): @LarissaSiqueirabp have you seen the comments?

"
2279180877,issue,closed,not_planned,Ignored schemas are not ignored,"### Describe the bug

Bug I'm experiencing (deployment: self-hosted, Ubuntu Linux VPS):

When I manually set schemas not to show, they are still shown.

### To Reproduce

1. Connect a PostgreSQL database.

2. Provide Metabase with a comma-separated list of schemas that should be ignored in the table:

![image](https://github.com/metabase/metabase/assets/40233203/858abf21-f222-4fba-80c6-d49513549927)

3. Manually initiate a resync and scan of the table schema structure by clicking 'sync database schema now':

![image](https://github.com/metabase/metabase/assets/40233203/c61d4993-35a3-44e8-9ba5-20b0588d9a63)



### Expected behavior

Schemas should be ignored, but are still visible when inspecting table metadata.

After the above steps:

![image](https://github.com/metabase/metabase/assets/40233203/68fb6413-3b5c-4009-a9a6-7015b2a7a4c5)


### Logs

_No response_

### Information about your Metabase installation

```JSON
Browser: Google Chrome
Deployment: Linux VPS
```


### Severity

Moderate

### Additional context

_No response_",danielrosehill,2024-05-04 20:16:45+00:00,[],2024-05-06 15:15:02+00:00,2024-05-06 14:33:26+00:00,https://github.com/metabase/metabase/issues/42254,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2096077743, 'issue_id': 2279180877, 'author': 'calherries', 'body': ""I reproduced on master, but this works fine in 49. The feature to select certain schemas doesn't apply either."", 'created_at': datetime.datetime(2024, 5, 6, 13, 55, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096095513, 'issue_id': 2279180877, 'author': 'calherries', 'body': '@danielrosehill what version of metabase are you using? Can you paste the diagnostic info from `/admin/troubleshooting/help` please?', 'created_at': datetime.datetime(2024, 5, 6, 14, 3, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096123891, 'issue_id': 2279180877, 'author': 'danielrosehill', 'body': ""> @danielrosehill what version of metabase are you using? Can you paste the diagnostic info from `/admin/troubleshooting/help` please?\r\n\r\nI'm on Metabase 0.49.8 - the latest and truly the greatest! But ... the issue seems to have resolved itself (perhaps the DB was slow in propagating changes?)\r\n\r\nSorry for the time-waste on looking into this."", 'created_at': datetime.datetime(2024, 5, 6, 14, 13, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096183736, 'issue_id': 2279180877, 'author': 'calherries', 'body': ""Thanks @danielrosehill, I checked master again and I failed to reproduce this too. I probably did the same as you. After syncing the database, the Table Metadata page needs to be refreshed to reflect the updated state of the backend. That's a bit of a sharp edge and it's obviously easy to get confused by it. I'll create an issue to get this fixed, thanks for raising it."", 'created_at': datetime.datetime(2024, 5, 6, 14, 33, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096275243, 'issue_id': 2279180877, 'author': 'danielrosehill', 'body': ""> Thanks @danielrosehill, I checked master again and I failed to reproduce this too. I probably did the same as you. After syncing the database, the Table Metadata page needs to be refreshed to reflect the updated state of the backend. That's a bit of a sharp edge and it's obviously easy to get confused by it. I'll create an issue to get this fixed, thanks for raising it.\r\n\r\nNo problem at all. I'll try not to be overly zealous but will drop in if I can validate any unusual behavior. But so far for the vast majority of the time, Metabase has been very stable (certainly by comparison to Apache Superset ... or is uttering their name forbidden in these quarters!?)"", 'created_at': datetime.datetime(2024, 5, 6, 15, 14, 48, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-06 13:55:27 UTC): I reproduced on master, but this works fine in 49. The feature to select certain schemas doesn't apply either.

calherries on (2024-05-06 14:03:41 UTC): @danielrosehill what version of metabase are you using? Can you paste the diagnostic info from `/admin/troubleshooting/help` please?

danielrosehill (Issue Creator) on (2024-05-06 14:13:57 UTC): I'm on Metabase 0.49.8 - the latest and truly the greatest! But ... the issue seems to have resolved itself (perhaps the DB was slow in propagating changes?)

Sorry for the time-waste on looking into this.

calherries on (2024-05-06 14:33:26 UTC): Thanks @danielrosehill, I checked master again and I failed to reproduce this too. I probably did the same as you. After syncing the database, the Table Metadata page needs to be refreshed to reflect the updated state of the backend. That's a bit of a sharp edge and it's obviously easy to get confused by it. I'll create an issue to get this fixed, thanks for raising it.

danielrosehill (Issue Creator) on (2024-05-06 15:14:48 UTC): No problem at all. I'll try not to be overly zealous but will drop in if I can validate any unusual behavior. But so far for the vast majority of the time, Metabase has been very stable (certainly by comparison to Apache Superset ... or is uttering their name forbidden in these quarters!?)

"
2278943885,issue,closed,not_planned,[BE] [QP] [Bug] Combining metrics does not work (joining metrics and using a custom expression to combine the metrics in the aggregation clause),"`Invalid input: {:lib/type [""should be either :metadata/segment or :metadata/legacy-metric, got: :metadata/metric"" ""invalid dispatch value, got: (metabase.util.snake-hating-map/snake-hating-map {:id 329, :table-id 2, :name \""Orders Metric 4\"", :description nil, :archived false, :lib/type :metadata/metric, :definition \""{\\\""database\\\"":1,\\\""type\\\"":\\\""query\\\"",\\\""query\\\"":{\\\""source-table\\\"":2,\\\""aggregation\\\"":[[\\\""sum\\\"",[\\\""field\\\"",15,{\\\""base-type\\\"":\\\""type/Float\\\""}]]]}}\""})""]}`


<img width=""1985"" alt=""Screenshot 2024-05-05 at 7 00 03 AM"" src=""https://github.com/metabase/metabase/assets/127636/f7e669c0-abec-452a-bd54-dd4a365bc0a8"">
",perivamsi,2024-05-04 11:16:34+00:00,['snoe'],2024-05-09 17:10:42+00:00,2024-05-09 17:10:42+00:00,https://github.com/metabase/metabase/issues/42253,[],"[{'comment_id': 2096924463, 'issue_id': 2278943885, 'author': 'snoe', 'body': '@ranquild \r\nCan you show what mlv2 calls are happening here?', 'created_at': datetime.datetime(2024, 5, 6, 21, 10, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098624807, 'issue_id': 2278943885, 'author': 'ranquild', 'body': '@snoe there is no MBQL lib error I can reproduce, only QP:\r\n\r\n```\r\n{\r\n  ""status"": ""failed"",\r\n  ""class"": ""class clojure.lang.ExceptionInfo"",\r\n  ""error"": ""Error preprocessing query in metabase.query_processor.preprocess$ensure_pmbql$fn__64341@16b75197: null"",\r\n  ""stacktrace"": [\r\n    ""--> query_processor.preprocess$preprocess$fn__64345$fn__64346.invoke(preprocess.clj:133)"",\r\n    ""query_processor.preprocess$preprocess$fn__64345.invoke(preprocess.clj:119)"",\r\n    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:215)"",\r\n    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:206)"",\r\n    ""query_processor.preprocess$preprocess.invokeStatic(preprocess.clj:118)"",\r\n    ""query_processor.preprocess$preprocess.invoke(preprocess.clj:114)"",\r\n    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)"",\r\n    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)"",\r\n    ""query_processor.middleware.enterprise$fn__63449$handle_audit_app_internal_queries__63450$fn__63452.invoke(enterprise.clj:96)"",\r\n    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__63460.invoke(enterprise.clj:103)"",\r\n    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__70364.invoke(process_userland_query.clj:176)"",\r\n    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__70433.invoke(catch_exceptions.clj:128)"",\r\n    ""query_processor$process_query$fn__70470.invoke(query_processor.clj:78)"",\r\n    ""query_processor.setup$do_with_canceled_chan$fn__63864.invoke(setup.clj:178)"",\r\n    ""query_processor.setup$do_with_database_local_settings$fn__63859.invoke(setup.clj:170)"",\r\n    ""query_processor.setup$do_with_driver$fn__63849$fn__63850.invoke(setup.clj:146)"",\r\n    ""driver$do_with_driver.invokeStatic(driver.clj:97)"",\r\n    ""driver$do_with_driver.invoke(driver.clj:92)"",\r\n    ""query_processor.setup$do_with_driver$fn__63849.invoke(setup.clj:145)"",\r\n    ""query_processor.setup$do_with_escape_alias_fn$fn__63854.invoke(setup.clj:155)"",\r\n    ""query_processor.setup$do_with_metadata_provider$fn__63842$fn__63845.invoke(setup.clj:131)"",\r\n    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)"",\r\n    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",\r\n    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)"",\r\n    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",\r\n    ""query_processor.setup$do_with_metadata_provider$fn__63842.invoke(setup.clj:130)"",\r\n    ""query_processor.setup$do_with_resolved_database$fn__63836.invoke(setup.clj:108)"",\r\n    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:222)"",\r\n    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:206)"",\r\n    ""query_processor$process_query.invokeStatic(query_processor.clj:76)"",\r\n    ""query_processor$process_query.invoke(query_processor.clj:69)"",\r\n    ""api.dataset$run_streaming_query$fn__94529.invoke(dataset.clj:78)"",\r\n    ""query_processor.streaming$_streaming_response$fn__66127$fn__66128$fn__66129.invoke(streaming.clj:175)"",\r\n    ""query_processor.streaming$_streaming_response$fn__66127$fn__66128.invoke(streaming.clj:174)"",\r\n    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)"",\r\n    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)"",\r\n    ""query_processor.streaming$_streaming_response$fn__66127.invoke(streaming.clj:171)"",\r\n    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)"",\r\n    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)"",\r\n    ""async.streaming_response$do_f_async$task__51759.invoke(streaming_response.clj:87)""\r\n  ],\r\n  ""error_type"": ""qp"",\r\n  ""ex-data"": {\r\n    ""fn"": ""metabase.query_processor.preprocess$ensure_pmbql$fn__64341@16b75197"",\r\n    ""query"": {\r\n      ""constraints"": {\r\n        ""max-results"": 10000,\r\n        ""max-results-bare-rows"": 2000\r\n      },\r\n      ""lib/type"": ""mbql/query"",\r\n      ""lib/metadata"": ""metabase.lib.metadata.invocation_tracker.InvocationTracker@52c035dd"",\r\n      ""stages"": [\r\n        {\r\n          ""lib/type"": ""mbql.stage/mbql"",\r\n          ""source-table"": 5,\r\n          ""qp/stage-is-from-source-card"": 5\r\n        },\r\n        {\r\n          ""lib/type"": ""mbql.stage/mbql"",\r\n          ""joins"": [\r\n            {\r\n              ""fields"": ""all"",\r\n              ""alias"": ""Products, Count - Product"",\r\n              ""conditions"": [\r\n                [\r\n                  ""="",\r\n                  {\r\n                    ""lib/uuid"": ""862eadac-c97a-48cc-9e6c-0cdc89323022""\r\n                  },\r\n                  [\r\n                    ""field"",\r\n                    {\r\n                      ""base-type"": ""type/Integer"",\r\n                      ""lib/uuid"": ""3105224f-9214-443f-867c-1ad78713be97""\r\n                    },\r\n                    36\r\n                  ],\r\n                  [\r\n                    ""field"",\r\n                    {\r\n                      ""base-type"": ""type/BigInteger"",\r\n                      ""join-alias"": ""Products, Count - Product"",\r\n                      ""lib/uuid"": ""01e4d687-6197-4055-8925-cd13ae6c60e8""\r\n                    },\r\n                    71\r\n                  ]\r\n                ]\r\n              ],\r\n              ""lib/type"": ""mbql/join"",\r\n              ""stages"": [\r\n                {\r\n                  ""lib/type"": ""mbql.stage/mbql"",\r\n                  ""source-table"": 8,\r\n                  ""qp/stage-is-from-source-card"": 6\r\n                },\r\n                {\r\n                  ""lib/type"": ""mbql.stage/mbql"",\r\n                  ""qp/stage-had-source-card"": 6,\r\n                  ""source-query/model?"": false\r\n                }\r\n              ],\r\n              ""lib/options"": {\r\n                ""lib/uuid"": ""db32309b-8167-435e-bbca-ce6dce80e70a""\r\n              }\r\n            }\r\n          ],\r\n          ""qp/stage-is-from-source-card"": 7,\r\n          ""qp/stage-had-source-card"": 5,\r\n          ""source-query/model?"": false\r\n        },\r\n        {\r\n          ""lib/type"": ""mbql.stage/mbql"",\r\n          ""aggregation"": [\r\n            [\r\n              ""/"",\r\n              {\r\n                ""lib/uuid"": ""d6882cc8-e3bb-4cb3-96f7-70818d149632"",\r\n                ""name"": ""orders__count___products__count__orders__count"",\r\n                ""display-name"": ""Orders, Count""\r\n              },\r\n              [\r\n                ""count"",\r\n                {\r\n                  ""lib/uuid"": ""952a5230-05a5-46c0-8dd6-b18bb613860a"",\r\n                  ""name"": ""orders__count""\r\n                }\r\n              ],\r\n              [\r\n                ""metric"",\r\n                {\r\n                  ""lib/uuid"": ""eb4a7374-8c64-4072-baea-70be719a0c78""\r\n                },\r\n                6\r\n              ]\r\n            ]\r\n          ],\r\n          ""qp/stage-had-source-card"": 7,\r\n          ""source-query/model?"": false\r\n        }\r\n      ],\r\n      ""middleware"": {\r\n        ""js-int-to-string?"": true,\r\n        ""userland-query?"": true,\r\n        ""add-default-userland-constraints?"": true\r\n      },\r\n      ""lib.convert/converted?"": true,\r\n      ""qp/source-card-id"": 7,\r\n      ""info"": {\r\n        ""executed-by"": 2,\r\n        ""context"": ""ad-hoc"",\r\n        ""card-id"": 7,\r\n        ""query-hash"": ""0xBBFDC496""\r\n      },\r\n      ""database"": 1\r\n    },\r\n    ""type"": ""qp""\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 5, 7, 15, 0, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098627123, 'issue_id': 2278943885, 'author': 'ranquild', 'body': 'You can follow steps from this test https://github.com/metabase/metabase/blob/e3f0a67100aa0bc574ac671dae37af7b1ca03567/e2e/test/scenarios/metrics/metrics-creation.cy.spec.ts#L140', 'created_at': datetime.datetime(2024, 5, 7, 15, 1, 18, tzinfo=datetime.timezone.utc)}]","snoe (Assginee) on (2024-05-06 21:10:13 UTC): @ranquild 
Can you show what mlv2 calls are happening here?

ranquild on (2024-05-07 15:00:37 UTC): @snoe there is no MBQL lib error I can reproduce, only QP:

```
{
  ""status"": ""failed"",
  ""class"": ""class clojure.lang.ExceptionInfo"",
  ""error"": ""Error preprocessing query in metabase.query_processor.preprocess$ensure_pmbql$fn__64341@16b75197: null"",
  ""stacktrace"": [
    ""--> query_processor.preprocess$preprocess$fn__64345$fn__64346.invoke(preprocess.clj:133)"",
    ""query_processor.preprocess$preprocess$fn__64345.invoke(preprocess.clj:119)"",
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:215)"",
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:206)"",
    ""query_processor.preprocess$preprocess.invokeStatic(preprocess.clj:118)"",
    ""query_processor.preprocess$preprocess.invoke(preprocess.clj:114)"",
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)"",
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)"",
    ""query_processor.middleware.enterprise$fn__63449$handle_audit_app_internal_queries__63450$fn__63452.invoke(enterprise.clj:96)"",
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__63460.invoke(enterprise.clj:103)"",
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__70364.invoke(process_userland_query.clj:176)"",
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__70433.invoke(catch_exceptions.clj:128)"",
    ""query_processor$process_query$fn__70470.invoke(query_processor.clj:78)"",
    ""query_processor.setup$do_with_canceled_chan$fn__63864.invoke(setup.clj:178)"",
    ""query_processor.setup$do_with_database_local_settings$fn__63859.invoke(setup.clj:170)"",
    ""query_processor.setup$do_with_driver$fn__63849$fn__63850.invoke(setup.clj:146)"",
    ""driver$do_with_driver.invokeStatic(driver.clj:97)"",
    ""driver$do_with_driver.invoke(driver.clj:92)"",
    ""query_processor.setup$do_with_driver$fn__63849.invoke(setup.clj:145)"",
    ""query_processor.setup$do_with_escape_alias_fn$fn__63854.invoke(setup.clj:155)"",
    ""query_processor.setup$do_with_metadata_provider$fn__63842$fn__63845.invoke(setup.clj:131)"",
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)"",
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)"",
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",
    ""query_processor.setup$do_with_metadata_provider$fn__63842.invoke(setup.clj:130)"",
    ""query_processor.setup$do_with_resolved_database$fn__63836.invoke(setup.clj:108)"",
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:222)"",
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:206)"",
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)"",
    ""query_processor$process_query.invoke(query_processor.clj:69)"",
    ""api.dataset$run_streaming_query$fn__94529.invoke(dataset.clj:78)"",
    ""query_processor.streaming$_streaming_response$fn__66127$fn__66128$fn__66129.invoke(streaming.clj:175)"",
    ""query_processor.streaming$_streaming_response$fn__66127$fn__66128.invoke(streaming.clj:174)"",
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)"",
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)"",
    ""query_processor.streaming$_streaming_response$fn__66127.invoke(streaming.clj:171)"",
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)"",
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)"",
    ""async.streaming_response$do_f_async$task__51759.invoke(streaming_response.clj:87)""
  ],
  ""error_type"": ""qp"",
  ""ex-data"": {
    ""fn"": ""metabase.query_processor.preprocess$ensure_pmbql$fn__64341@16b75197"",
    ""query"": {
      ""constraints"": {
        ""max-results"": 10000,
        ""max-results-bare-rows"": 2000
      },
      ""lib/type"": ""mbql/query"",
      ""lib/metadata"": ""metabase.lib.metadata.invocation_tracker.InvocationTracker@52c035dd"",
      ""stages"": [
        {
          ""lib/type"": ""mbql.stage/mbql"",
          ""source-table"": 5,
          ""qp/stage-is-from-source-card"": 5
        },
        {
          ""lib/type"": ""mbql.stage/mbql"",
          ""joins"": [
            {
              ""fields"": ""all"",
              ""alias"": ""Products, Count - Product"",
              ""conditions"": [
                [
                  ""="",
                  {
                    ""lib/uuid"": ""862eadac-c97a-48cc-9e6c-0cdc89323022""
                  },
                  [
                    ""field"",
                    {
                      ""base-type"": ""type/Integer"",
                      ""lib/uuid"": ""3105224f-9214-443f-867c-1ad78713be97""
                    },
                    36
                  ],
                  [
                    ""field"",
                    {
                      ""base-type"": ""type/BigInteger"",
                      ""join-alias"": ""Products, Count - Product"",
                      ""lib/uuid"": ""01e4d687-6197-4055-8925-cd13ae6c60e8""
                    },
                    71
                  ]
                ]
              ],
              ""lib/type"": ""mbql/join"",
              ""stages"": [
                {
                  ""lib/type"": ""mbql.stage/mbql"",
                  ""source-table"": 8,
                  ""qp/stage-is-from-source-card"": 6
                },
                {
                  ""lib/type"": ""mbql.stage/mbql"",
                  ""qp/stage-had-source-card"": 6,
                  ""source-query/model?"": false
                }
              ],
              ""lib/options"": {
                ""lib/uuid"": ""db32309b-8167-435e-bbca-ce6dce80e70a""
              }
            }
          ],
          ""qp/stage-is-from-source-card"": 7,
          ""qp/stage-had-source-card"": 5,
          ""source-query/model?"": false
        },
        {
          ""lib/type"": ""mbql.stage/mbql"",
          ""aggregation"": [
            [
              ""/"",
              {
                ""lib/uuid"": ""d6882cc8-e3bb-4cb3-96f7-70818d149632"",
                ""name"": ""orders__count___products__count__orders__count"",
                ""display-name"": ""Orders, Count""
              },
              [
                ""count"",
                {
                  ""lib/uuid"": ""952a5230-05a5-46c0-8dd6-b18bb613860a"",
                  ""name"": ""orders__count""
                }
              ],
              [
                ""metric"",
                {
                  ""lib/uuid"": ""eb4a7374-8c64-4072-baea-70be719a0c78""
                },
                6
              ]
            ]
          ],
          ""qp/stage-had-source-card"": 7,
          ""source-query/model?"": false
        }
      ],
      ""middleware"": {
        ""js-int-to-string?"": true,
        ""userland-query?"": true,
        ""add-default-userland-constraints?"": true
      },
      ""lib.convert/converted?"": true,
      ""qp/source-card-id"": 7,
      ""info"": {
        ""executed-by"": 2,
        ""context"": ""ad-hoc"",
        ""card-id"": 7,
        ""query-hash"": ""0xBBFDC496""
      },
      ""database"": 1
    },
    ""type"": ""qp""
  }
}
```

ranquild on (2024-05-07 15:01:18 UTC): You can follow steps from this test https://github.com/metabase/metabase/blob/e3f0a67100aa0bc574ac671dae37af7b1ca03567/e2e/test/scenarios/metrics/metrics-creation.cy.spec.ts#L140

"
2278943846,issue,closed,completed,[BE] Comparing metrics is slow (joining metrics and selecting them in aggregation clause),,perivamsi,2024-05-04 11:16:26+00:00,['snoe'],2024-05-16 18:24:19+00:00,2024-05-16 18:24:19+00:00,https://github.com/metabase/metabase/issues/42252,[],[],
2278588235,issue,closed,duplicate,Ingest multiple MySQL schemas/databases from the same server,"According to the [MySQL documentation](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_schema), ""a schema is synonymous with a database."" And [vice versa](https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_database):
> Users coming from an Oracle Database background may find that the MySQL meaning of a database is closer to what Oracle Database calls a schema.

In fact, you can substitute the keywords in MySQL SQL syntax.

It is quite common in practice to have multiple databases/schemas on a single MySQL server and to join between them. However, Metabase currently only allows connecting to a single MySQL database/schema per server, which you must specify in the Metabase DB connection configuration.

This arbitrarily prevents cross-database/schema joins within Metabase, even though they are fully supported by MySQL. 

Given that ""a schema is synonymous with a database"" in MySQL, can Metabase instead ingest multiple databases from the same MySQL server, and register these as separate _schemas_ within the same Metabase DB connection, similar to what is done for schemas in PostgreSQL and other database engines?

This issue is essentially the same as https://github.com/metabase/metabase/issues/5887, but I wanted to give more context and get fresh eyes on it, since that issue is from 2017 and is still unresolved.

Thanks!",MChamberlin,2024-05-03 23:57:33+00:00,[],2024-12-18 22:59:54+00:00,2024-12-18 22:59:53+00:00,https://github.com/metabase/metabase/issues/42248,"[('Database/MySQL', None), ('Type:New Feature', '')]","[{'comment_id': 2094117335, 'issue_id': 2278588235, 'author': 'paoliniluis', 'body': 'related to https://github.com/metabase/metabase/issues/22237', 'created_at': datetime.datetime(2024, 5, 4, 10, 49, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552366234, 'issue_id': 2278588235, 'author': 'parsaap', 'body': ""> related to [#22237](https://github.com/metabase/metabase/issues/22237)\n\nIt's not quite similar to this issue. For #22237, you actually need to use something like Presto to query multiple databases, but with MySQL, a schema is just a kind of namespace for tables. I've been waiting for this feature for quite some time. It'll be very useful, and should not be hard at all to implement. The database itself handles all the joins and everything, you just have to prefix the table name with the schema name in the query generator and some UI changes to support this."", 'created_at': datetime.datetime(2024, 12, 18, 22, 11, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552428049, 'issue_id': 2278588235, 'author': 'paoliniluis', 'body': 'We should close this in favor of https://github.com/metabase/metabase/issues/5887 then', 'created_at': datetime.datetime(2024, 12, 18, 22, 59, 53, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-04 10:49:10 UTC): related to https://github.com/metabase/metabase/issues/22237

parsaap on (2024-12-18 22:11:44 UTC): It's not quite similar to this issue. For #22237, you actually need to use something like Presto to query multiple databases, but with MySQL, a schema is just a kind of namespace for tables. I've been waiting for this feature for quite some time. It'll be very useful, and should not be hard at all to implement. The database itself handles all the joins and everything, you just have to prefix the table name with the schema name in the query generator and some UI changes to support this.

paoliniluis on (2024-12-18 22:59:53 UTC): We should close this in favor of https://github.com/metabase/metabase/issues/5887 then

"
2278396097,issue,closed,completed,Cannot change the temporal unit or binning strategy for columns with long display names,"### Describe the bug

When selecting a column that has a long name, it's impossible to select additional column options.

### To Reproduce

1. Admin Settings -> Table Metadata -> Rename a column to some very very long name
2. New -> Question -> Select a table with the column - Group by
3. Make sure that the column name is trimmed and it's possible to select aggregation options

<img width=""369"" alt=""Screenshot 2024-05-03 at 16 39 27"" src=""https://github.com/metabase/metabase/assets/8542534/c4cf852f-5304-4338-a7f4-64aa80eb2ed8"">


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
`master`
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-05-03 20:42:22+00:00,['ranquild'],2024-05-06 12:32:28+00:00,2024-05-06 12:32:28+00:00,https://github.com/metabase/metabase/issues/42244,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature')]",[],
2278390276,issue,closed,completed,[dc.js migration] Tooltip shows data for a different x-value,https://metaboat.slack.com/archives/C01LQQ2UW03/p1714764194303799,alxnddr,2024-05-03 20:37:24+00:00,['alxnddr'],2024-05-06 23:48:10+00:00,2024-05-06 23:48:10+00:00,https://github.com/metabase/metabase/issues/42243,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2278373603,issue,closed,not_planned,Params search endpoint is broken in stats,"### Describe the bug

https://stats.metabase.com/api/dashboard/1880/params/85e5498e/search/Onecom returns 400 bad request with this response

### To Reproduce

1. Go to https://stats.metabase.com/dashboard/1880-customer-360?tab=347-overview&customer_name=&customer_id=&account_id=&domain_name_(success_tab_only)=&dns_alias_(prototype_tab_only)=&email_contains=
2. Search for `Onecom` in the Customer Name dropdown
3. No results show up


### Expected behavior

OneCom is a valid customer and should show up in the results""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": ""Cannot search against non-Text Field 541,278 \""id\"""",
            ""data"": {
                ""status-code"": 400,
                ""field-id"": 541278,
                ""field"": ""id"",
                ""base-type"": ""type/BigInteger""
            },
            ""at"": [
                ""metabase.models.params.chain_filter$check_valid_search_field"",
                ""invokeStatic"",
                ""chain_filter.clj"",
                607
            ]
        }
    ],

### Logs

_No response_

### Information about your Metabase installation

```JSON
stats
```


### Severity

P1

### Additional context

This is a blocker for 50",perivamsi,2024-05-03 20:26:06+00:00,[],2024-05-06 12:38:27+00:00,2024-05-03 20:29:14+00:00,https://github.com/metabase/metabase/issues/42242,"[('Type:Bug', 'Product defects'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Organization/Search', '')]","[{'comment_id': 2093719233, 'issue_id': 2278373603, 'author': 'perivamsi', 'body': 'duplicate of https://github.com/metabase/metabase/issues/42153', 'created_at': datetime.datetime(2024, 5, 3, 20, 29, 14, tzinfo=datetime.timezone.utc)}]","perivamsi (Issue Creator) on (2024-05-03 20:29:14 UTC): duplicate of https://github.com/metabase/metabase/issues/42153

"
2278344293,issue,open,,Error message is ambiguous for running native queries with required parameters and no default value,"### Describe the bug

This is a follow-up to [this issue](https://github.com/metabase/metabase/issues/40250).

The current workflow allows you to create a SQL query with required filter without adding the required value. 

Users are confused as to why they are able to create a question without a value if they are actually required in dashboards to be displayed correctly. The error message displayed in dashboard is not clear about the nature of the issue.

### To Reproduce

1. Create new native SQL question
2. Add a filter in query
3. Select **Always require a value**
4. Click Run

[Screenshot 1](https://metabase.zendesk.com/attachments/token/Pqg9eo6Wxh5E0cnOHRxhYx3Ov/?name=image.png)

5. Click Save
6. Create a new dashboard
7. Add this question to dashboard

[Screenshot 2](https://metabase.zendesk.com/attachments/token/Pqg9eo6Wxh5E0cnOHRxhYx3Ov/?name=image.png)

### Expected behavior

Needs to be workshopped as to what the exact flow should be. Embedding is also affected by this such as locked filters

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-CA"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15"",
    ""vendor"": ""Apple Computer, Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.214-202.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-02"",
      ""tag"": ""v1.49.3"",
      ""hash"": ""dba0992""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Amsterdam""
    }
  }
}
```


### Severity

annoying and semi-blocking

### Additional context

_No response_",taqattack,2024-05-03 20:03:46+00:00,[],2025-02-04 20:29:03+00:00,,https://github.com/metabase/metabase/issues/42240,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2299587559, 'issue_id': 2278344293, 'author': 'cdeweyx', 'body': 'Flipping to Querying as this is a follow-on to required params w/ no default value.', 'created_at': datetime.datetime(2024, 8, 20, 19, 17, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457668542, 'issue_id': 2278344293, 'author': 'ranquild', 'body': 'The backend could return a user-friendly error message for this case in `error` with `error_is_currated` set to `true` for us to display it in dashboards.', 'created_at': datetime.datetime(2024, 11, 5, 16, 41, 2, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-20 19:17:38 UTC): Flipping to Querying as this is a follow-on to required params w/ no default value.

ranquild on (2024-11-05 16:41:02 UTC): The backend could return a user-friendly error message for this case in `error` with `error_is_currated` set to `true` for us to display it in dashboards.

"
2278324899,issue,open,,"`PgConnection` has a `cancelQuery()` method, we should call it if the thread its running on gets killed","https://jdbc.postgresql.org/documentation/publicapi/org/postgresql/jdbc/PgConnection.html#cancelQuery--

We're already calling `java.sql.Statement.cancel()` but it wouldn't hurt to be extra safe and call this as well for Postgres, right?

Not sure if Redshift has this too or if it was introduced after the forcc",camsaul,2024-05-03 19:49:07+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/42238,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('Database/Postgres', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2278286354,issue,closed,completed,[BE] [QP] Metrics aren't working for Druid (old driver),"The test `metabase.driver.druid.query-processor-test/metrics-inside-aggregation-clauses-test` is failing because the (old) druid driver doesn't support nested queries.  This test is now commented out.

There are several ways to ""fix"" this:
1. Change QP to optimize ""v1 metric"" queries semantics to non-nested queries.
2. Migrate the test to the new JDBC druid driver and if that works, tell users to switch to it (this has to be discussed with the success team).
3. Lose metric support for druid (this has to be discussed with the success team).
",ranquild,2024-05-03 19:19:47+00:00,[],2024-10-08 17:11:19+00:00,2024-05-21 18:17:53+00:00,https://github.com/metabase/metabase/issues/42237,[],"[{'comment_id': 2123184142, 'issue_id': 2278286354, 'author': 'metamben', 'body': ""They don't work with the old driver but they do with the new (druid-jdbc) one."", 'created_at': datetime.datetime(2024, 5, 21, 18, 17, 53, tzinfo=datetime.timezone.utc)}]","metamben on (2024-05-21 18:17:53 UTC): They don't work with the old driver but they do with the new (druid-jdbc) one.

"
2278206992,issue,closed,completed,Overflow menu on collections list are not disappearing,"### Describe the bug

In stats, when browsing any collection, the overflow menus (aka . . .) are overlapping each other once you go from row to row, the second one overlaps with the first and so on sequentially. 

### To Reproduce

1. Go to any collection
2. Click on the '...' menu in any row,
3. Repeat step 2 in the row below or above and keep repeating
4. See error


### Expected behavior

The second menu you access should make the previous menu disappear so that there's only one menu on the screen at a given moment.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Browser: Version 123.0.6312.123 (Official Build) (arm64)
OS: Mac OS Ventura 13.2
Metabase version: You're on version vUNKNOWN
Built on 2024-05-03
Hash: 395c898
```


### Severity

annoying

### Additional context

https://www.loom.com/share/f8c3b1ae39664a358e67e4b3c92702ae?sid=0f462d9f-95fe-457e-b3a0-3a1d5d514fa3",vbenedetti,2024-05-03 18:25:20+00:00,[],2024-08-26 16:46:48+00:00,2024-08-26 16:46:47+00:00,https://github.com/metabase/metabase/issues/42235,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Frontend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2097798849, 'issue_id': 2278206992, 'author': 'calherries', 'body': ""I tested on the release branch (`dd71f00dd7`) and couldn't reproduce it, but I can on master (`43c0ce979a`)."", 'created_at': datetime.datetime(2024, 5, 7, 9, 0, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310634646, 'issue_id': 2278206992, 'author': 'rafpaf', 'body': 'This was fixed sometime this summer', 'created_at': datetime.datetime(2024, 8, 26, 16, 46, 47, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-07 09:00:06 UTC): I tested on the release branch (`dd71f00dd7`) and couldn't reproduce it, but I can on master (`43c0ce979a`).

rafpaf on (2024-08-26 16:46:47 UTC): This was fixed sometime this summer

"
2278205470,issue,closed,not_planned,Window function does not generate a correct inner query,"### Describe the bug

Testing the new wf feature I saw that it does not generate correctly the inner query
https://stats.metabase.com/question/17517-window-function-test/notebook

### To Reproduce

1) see the question above

### Expected behavior

it should work/generate the query correctly

### Logs

NA

### Information about your Metabase installation

```JSON
master
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-05-03 18:24:42+00:00,[],2024-08-28 02:10:45+00:00,2024-06-07 10:30:33+00:00,https://github.com/metabase/metabase/issues/42234,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2154557799, 'issue_id': 2278205470, 'author': 'perivamsi', 'body': 'this is not a bug, you are using `Offset` incorrectly\r\n\r\nthe correct expression should be something along the lines of `Offset(Sum([Total]), 1)`', 'created_at': datetime.datetime(2024, 6, 7, 10, 30, 30, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-06-07 10:30:30 UTC): this is not a bug, you are using `Offset` incorrectly

the correct expression should be something along the lines of `Offset(Sum([Total]), 1)`

"
2278026216,issue,closed,completed,"The filter by time dialogue at the bottom of the screen should include ""Include This X""","**Is your feature request related to a problem? Please describe.**
I often like to see today \ this week \ this month when filtering on time and I use the time filtering options at the bottom of the UI a lot. So it's really annoying that I have to go somewhere else to choose this week \ day \ month.

Here's a loom:  https://www.loom.com/share/29c1f6aa28be461f9095d01e04aa2a52?sid=cfbddc53-51f9-4d6e-8546-9ce4f9117d6f

**Describe the solution you'd like**
I'd like a checkbox or whatever to choose it where I'm choosing the other time things:
<img width=""1892"" alt=""image"" src=""https://github.com/metabase/metabase/assets/22856340/fcafa3f5-a85a-4428-b241-2f5c037b3971"">

**Describe alternatives you've considered**
I can go into the filter dialogue, but why do I have to do that?

**How important is this feature to you?**
It's a little thing that would make my experience more pleasant and chill and less annoying.
",cbalusek,2024-05-03 16:24:31+00:00,['nemanjaglumac'],2024-06-24 15:52:51+00:00,2024-06-24 15:51:57+00:00,https://github.com/metabase/metabase/issues/42220,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/GUI', 'Query builder catch-all, including simple mode')]","[{'comment_id': 2186893979, 'issue_id': 2278026216, 'author': 'nemanjaglumac', 'body': 'Implemented as part of https://github.com/metabase/metabase/issues/44096', 'created_at': datetime.datetime(2024, 6, 24, 15, 51, 57, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Assginee) on (2024-06-24 15:51:57 UTC): Implemented as part of https://github.com/metabase/metabase/issues/44096

"
2278008729,issue,closed,not_planned,Events do not appear for current week when filtering on previous weeks,"### Describe the bug

When filtering on ""Show previous x weeks"" and also choosing ""Include this week"" the events calendar does not include the current week.  The events sidebar nicely tells you that it's excluding your current week.  For example, I created an event occurring on May 1st (which is the week in which I'm writing this) and it's not appearing as the sidebar shows:

<img width=""236"" alt=""image"" src=""https://github.com/metabase/metabase/assets/22856340/597a546b-d8ab-4080-8f34-f63127f86830"">


### To Reproduce

1. Create a report with a time series that includes today (the Orders table seemed to do okay in the sample database)
2. Used the Created At (if using the Orders table) and do a Distribution from the column header
3. Change the filter at the bottom of the screen to ""View Previous 13 weeks by week""
4. Change the filter from the filter dialogue at the top of the chart to Include This Week
5. (Remind yourself to file another issue about how annoying it is that it's not at the bottom of the screen too)
6. Click on the Events side bar  (it's the calendar icon on the bottom right)
7. Create a new event that falls between the start of the week and today
8. Notice how it does not appear.  
9. If you are me, you'll also create the event again, thinking you did something wrong.


### Expected behavior

If an event is this week and I'm showing this week, I should see the event.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- On master
```


### Severity

It's annoying but it's not blocking

### Additional context

_No response_",cbalusek,2024-05-03 16:16:18+00:00,['kulyk'],2024-06-14 11:52:47+00:00,2024-06-13 13:13:50+00:00,https://github.com/metabase/metabase/issues/42219,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts/Events', 'Event annotation in timelines'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2097828102, 'issue_id': 2278008729, 'author': 'calherries', 'body': 'Reproduced on 49 branch (dd71f00dd7) and master (43c0ce979a). The issue on the frontend because the `GET /api/timeline?include=events` request returns the correct results and the filtering on those results by date is applied on the frontend.', 'created_at': datetime.datetime(2024, 5, 7, 9, 15, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2165637874, 'issue_id': 2278008729, 'author': 'kulyk', 'body': 'Duplicate of #23336', 'created_at': datetime.datetime(2024, 6, 13, 13, 13, 50, tzinfo=datetime.timezone.utc)}]","calherries on (2024-05-07 09:15:05 UTC): Reproduced on 49 branch (dd71f00dd7) and master (43c0ce979a). The issue on the frontend because the `GET /api/timeline?include=events` request returns the correct results and the filtering on those results by date is applied on the frontend.

kulyk (Assginee) on (2024-06-13 13:13:50 UTC): Duplicate of #23336

"
2277843612,issue,closed,completed,FE: support mixed stacking on line/bar/combo charts when series have suitable display types,,alxnddr,2024-05-03 14:50:05+00:00,[],2024-08-01 05:16:50+00:00,2024-08-01 05:16:50+00:00,https://github.com/metabase/metabase/issues/42215,[],[],
2277781673,issue,closed,completed,Support custom fonts in embedding SDK,"We don't seem to support custom font in the Embedding SDK.

This is how the main app does it.
https://github.com/metabase/metabase/blob/7e215b7e464f05a72a977cb5eac21f66321dac8c/frontend/src/metabase/styled-components/containers/GlobalStyles/GlobalStyles.tsx#L30-L40",WiNloSt,2024-05-03 14:18:28+00:00,['WiNloSt'],2024-05-08 15:31:15+00:00,2024-05-08 15:31:15+00:00,https://github.com/metabase/metabase/issues/42214,[],[],
2277358871,issue,open,,Unreferenced columns in pivot table queries,"### Describe the bug

There are unreferenced columns in the nested select statements we use for pivot tables, which seem to be causing issues with Cube. There might be some other database backends where this is not handled well by the query optimizer.

### To Reproduce

1. Create a GUI query: 
  * Sample Database / Orders
  * summarize by Count of Rows
  * group by: Product-->Category, User-->City, User --> State
2. Visualize as a pivot table
3. Add a filter for Orders.Created At
4. Run it, and check the queries sent to the database, and see the have unreferenced columns in the nested select statement.
(See an example below).

### Expected behavior

Unreferenced columns should not be selected in the inner select statement.


### Logs

SQL generated, the unreferenced columns are marked with comments:
```
SELECT ""source"".""products__via__product_id__category"" AS ""products__via__product_id__category"",
       ""source"".""people__via__user_id__city""          AS ""people__via__user_id__city"",
       ""source"".""people__via__user_id__state""         AS ""people__via__user_id__state"",
       ""source"".""pivot-grouping""                      AS ""pivot-grouping"",
       COUNT(*)                                       AS ""count""
FROM (SELECT ""public"".""orders"".""user_id""            AS ""user_id"", --!
             ""public"".""orders"".""product_id""         AS ""product_id"", --!
             ""public"".""orders"".""created_at""         AS ""created_at"", --! (added when a filter is present)
             ABS(0)                                 AS ""pivot-grouping"",
             ""products__via__product_id"".""category"" AS ""products__via__product_id__category"",
             ""people__via__user_id"".""city""          AS ""people__via__user_id__city"",
             ""people__via__user_id"".""state""         AS ""people__via__user_id__state"",
             ""products__via__product_id"".""id""       AS ""products__via__product_id__id"", --!
             ""people__via__user_id"".""id""            AS ""people__via__user_id__id"" --!
      FROM ""public"".""orders""
      LEFT JOIN ""public"".""products"" AS ""products__via__product_id"" ON ""public"".""orders"".""product_id"" = ""products__via__product_id"".""id""
      LEFT JOIN ""public"".""people"" AS ""people__via__user_id"" ON ""public"".""orders"".""user_id"" = ""people__via__user_id"".""id""
      WHERE (""public"".""orders"".""created_at"" >= $1)
        AND (""public"".""orders"".""created_at"" < $2)) AS ""source""
GROUP BY ""source"".""products__via__product_id__category"",
         ""source"".""people__via__user_id__city"",
         ""source"".""people__via__user_id__state"",
         ""source"".""pivot-grouping""
ORDER BY ""source"".""products__via__product_id__category"" ASC,
         ""source"".""people__via__user_id__city"" ASC,
         ""source"".""people__via__user_id__state"" ASC,
         ""source"".""pivot-grouping"" ASC;
         
         
SELECT ""source"".""people__via__user_id__state"" AS ""people__via__user_id__state"",
       ""source"".""pivot-grouping""              AS ""pivot-grouping"",
       COUNT(*)                               AS ""count""
FROM (SELECT ""public"".""orders"".""user_id""    AS ""user_id"", --!
             ""public"".""orders"".""created_at"" AS ""created_at"", --!
             ABS(3)                         AS ""pivot-grouping"",
             ""people__via__user_id"".""state"" AS ""people__via__user_id__state"",
             ""people__via__user_id"".""id""    AS ""people__via__user_id__id"" --!
      FROM ""public"".""orders""
               LEFT JOIN ""public"".""people"" AS ""people__via__user_id""
                         ON ""public"".""orders"".""user_id"" = ""people__via__user_id"".""id""
      WHERE (""public"".""orders"".""created_at"" >= $1)
        AND (""public"".""orders"".""created_at"" < $2)) AS ""source""
GROUP BY ""source"".""people__via__user_id__state"", ""source"".""pivot-grouping""
ORDER BY ""source"".""people__via__user_id__state"" ASC, ""source"".""pivot-grouping"" ASC;

SELECT ""source"".""products__via__product_id__category"" AS ""products__via__product_id__category"",
       ""source"".""pivot-grouping""                      AS ""pivot-grouping"",
       COUNT(*)                                       AS ""count""
FROM (SELECT ""public"".""orders"".""product_id""         AS ""product_id"", !--
             ""public"".""orders"".""created_at""         AS ""created_at"", !--
             ABS(6)                                 AS ""pivot-grouping"",
             ""products__via__product_id"".""category"" AS ""products__via__product_id__category"",
             ""products__via__product_id"".""id""       AS ""products__via__product_id__id"" !--
      FROM ""public"".""orders""
               LEFT JOIN ""public"".""products"" AS ""products__via__product_id""
                         ON ""public"".""orders"".""product_id"" = ""products__via__product_id"".""id""
      WHERE (""public"".""orders"".""created_at"" >= $1)
        AND (""public"".""orders"".""created_at"" < $2)) AS ""source""
GROUP BY ""source"".""products__via__product_id__category"", ""source"".""pivot-grouping""
ORDER BY ""source"".""products__via__product_id__category"" ASC, ""source"".""pivot-grouping"" ASC;

SELECT ""source"".""pivot-grouping"" AS ""pivot-grouping"", COUNT(*) AS ""count""
FROM (SELECT 
""public"".""orders"".""created_at"" AS ""created_at"", !--
ABS(7) AS ""pivot-grouping""
      FROM ""public"".""orders""
      WHERE (""public"".""orders"".""created_at"" >= $1)
        AND (""public"".""orders"".""created_at"" < $2)) AS ""source""
GROUP BY ""source"".""pivot-grouping""
ORDER BY ""source"".""pivot-grouping"" ASC;
```

### Information about your Metabase installation

```JSON
1.49.7
```


### Severity

P2

### Additional context

_No response_",zbodi74,2024-05-03 10:11:57+00:00,[],2025-02-04 20:27:56+00:00,,https://github.com/metabase/metabase/issues/42205,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2096681734, 'issue_id': 2277358871, 'author': 'camsaul', 'body': ""Downgrading to P3 since this doesn't affect any of our officially supported databases in terms of query correctness (only a potential performance issue), [Cube is not an officially supported database](https://www.metabase.com/data_sources/) at this time. I will still hopefully fix it tho since no one likes messy SQL."", 'created_at': datetime.datetime(2024, 5, 6, 18, 44, 30, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-05-06 18:44:30 UTC): Downgrading to P3 since this doesn't affect any of our officially supported databases in terms of query correctness (only a potential performance issue), [Cube is not an officially supported database](https://www.metabase.com/data_sources/) at this time. I will still hopefully fix it tho since no one likes messy SQL.

"
2277260916,issue,closed,completed,Unable to edit metadata of model,"### Describe the bug

In the metadata editor of a model I would like to update the name of the columns, updating a column works but navigating through the other columns does not work. This also triggers a javascript error. The error occurs on webkit based browsers as safari
![Screenshot 2024-05-03 at 11 12 38](https://github.com/metabase/metabase/assets/7110155/06757e7a-a06b-4e97-b4ae-dd8ffc4c61c8)



### To Reproduce

1. Go to 'Metadata editor of a model'
2. Click on 'A random column'
3. Scroll down to '-'
4. See error
No error but the column is not being selected and I get an error in dev-tools of the browser


### Expected behavior

Selection the clicked column

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Latest version of Chrome and Safari
- Metabase version 0.49.8 latest
```


### Severity

annoying

### Additional context

We cannot deliver metadata model production ready",dstollie,2024-05-03 09:15:17+00:00,[],2024-07-15 21:00:43+00:00,2024-07-05 19:41:39+00:00,https://github.com/metabase/metabase/issues/42203,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2092674645, 'issue_id': 2277260916, 'author': 'zbodi74', 'body': ""@dstollie - I tried to replicate this but wasn't able to. Could you record a quick video showing what's happening? \r\nAlso, are there any plugins installed on your end?"", 'created_at': datetime.datetime(2024, 5, 3, 9, 51, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097859097, 'issue_id': 2277260916, 'author': 'Tony-metabase', 'body': '@dstollie can you answer @zbodi74 questions please so we can investigate further', 'created_at': datetime.datetime(2024, 5, 7, 9, 28, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191083626, 'issue_id': 2277260916, 'author': 'darksciencebase', 'body': '@dstollie are you still experiencing this issue?', 'created_at': datetime.datetime(2024, 6, 26, 8, 10, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206942511, 'issue_id': 2277260916, 'author': 'ranquild', 'body': 'I can only repro with multiple self joins where exactly the same column is selected.', 'created_at': datetime.datetime(2024, 7, 3, 18, 21, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229426567, 'issue_id': 2277260916, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 42, tzinfo=datetime.timezone.utc)}]","zbodi74 on (2024-05-03 09:51:47 UTC): @dstollie - I tried to replicate this but wasn't able to. Could you record a quick video showing what's happening? 
Also, are there any plugins installed on your end?

Tony-metabase on (2024-05-07 09:28:55 UTC): @dstollie can you answer @zbodi74 questions please so we can investigate further

darksciencebase on (2024-06-26 08:10:18 UTC): @dstollie are you still experiencing this issue?

ranquild on (2024-07-03 18:21:23 UTC): I can only repro with multiple self joins where exactly the same column is selected.

github-actions[bot] on (2024-07-15 21:00:42 UTC): 🚀 This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2277179573,issue,closed,completed,Define a public metabase theme type and Mantine transformer for embedding SDK,"We should define a public `MetabaseTheme` type, and transform the public type to `MantineThemeOverride` under the hood. See [reference in Notion](https://www.notion.so/metabase/Milestones-Theming-for-React-Embedding-SDK-867fcecba0f74abd8158b6cd3164cac4?pvs=4#226c9f7ebdc3485a8d0b9da68ba6b5f8).",heypoom,2024-05-03 08:23:39+00:00,['heypoom'],2024-05-03 17:12:16+00:00,2024-05-03 17:12:16+00:00,https://github.com/metabase/metabase/issues/42201,[],[],
2277150950,issue,closed,completed,Questions should render without a fixed-height flexbox parent in React embedding,"The question component do not have a height by default, so the charts doesn't show up when a SDK user adds it to their page. There is also no style props to pass in height.

The component also doesn't follow the parent container's height / min-height by default, so either the parent must be a flexbox, or the user needs to add a CSS like parent > div { height: 100% } for it to work.

We should be able to render a sane height by default and allow customizing the height. It should also be able to follow the parent component's height without using CSS workarounds.

<img src=""https://github.com/metabase/metabase/assets/4714175/26ab8714-d6d8-4ed4-81e4-464bc316f06d"" height=""200"">
",heypoom,2024-05-03 08:04:16+00:00,['heypoom'],2024-05-08 18:19:00+00:00,2024-05-08 18:19:00+00:00,https://github.com/metabase/metabase/issues/42199,[],[],
2276974319,issue,closed,completed,Add Analytics,,uladzimirdev,2024-05-03 05:50:25+00:00,['uladzimirdev'],2024-05-06 11:19:10+00:00,2024-05-03 19:00:18+00:00,https://github.com/metabase/metabase/issues/42198,[],"[{'comment_id': 2093600580, 'issue_id': 2276974319, 'author': 'uladzimirdev', 'body': '[no analytics required](https://metaboat.slack.com/archives/C0645JP1W81/p1714749276138679?thread_ts=1714743407.493859&cid=C0645JP1W81)', 'created_at': datetime.datetime(2024, 5, 3, 19, 0, 18, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-05-03 19:00:18 UTC): [no analytics required](https://metaboat.slack.com/archives/C0645JP1W81/p1714749276138679?thread_ts=1714743407.493859&cid=C0645JP1W81)

"
2276974232,issue,closed,completed,"When the top tab on the setting panel has only one tab ""Filter settings"" (no linked filters), change its look to normal. (currently it's active in blue).",,uladzimirdev,2024-05-03 05:50:20+00:00,['uladzimirdev'],2024-05-03 17:51:28+00:00,2024-05-03 17:51:28+00:00,https://github.com/metabase/metabase/issues/42197,[],[],
2276974156,issue,closed,completed,Add typescript types for parameter sections,,uladzimirdev,2024-05-03 05:50:14+00:00,['uladzimirdev'],2024-05-06 18:48:46+00:00,2024-05-06 18:48:46+00:00,https://github.com/metabase/metabase/issues/42196,[],[],
2276777857,issue,closed,completed,Cleanup combo & stacking settings,Migration spec: https://www.notion.so/metabase/Migration-spec-e2732e79215a4a5fa44debb272413db9?pvs=4,alxnddr,2024-05-03 02:07:09+00:00,['adam-james-v'],2024-05-16 21:41:04+00:00,2024-05-16 21:41:03+00:00,https://github.com/metabase/metabase/issues/42195,"[('.Backend', '')]",[],
2276519236,issue,closed,completed,Implement downgrade (restoring the original questions),,metamben,2024-05-02 21:22:02+00:00,['metamben'],2024-05-20 13:56:41+00:00,2024-05-20 13:56:41+00:00,https://github.com/metabase/metabase/issues/42191,[],[],
2276518297,issue,closed,completed,Implement question migration for multiple metrics,,metamben,2024-05-02 21:21:32+00:00,['metamben'],2024-05-20 13:56:32+00:00,2024-05-20 13:56:32+00:00,https://github.com/metabase/metabase/issues/42190,[],[],
2276517657,issue,closed,completed,Implement question migration for single metric,,metamben,2024-05-02 21:21:15+00:00,['metamben'],2024-05-20 13:56:05+00:00,2024-05-20 13:56:05+00:00,https://github.com/metabase/metabase/issues/42189,[],[],
2276517240,issue,closed,completed,Implement metric migration,,metamben,2024-05-02 21:21:00+00:00,['metamben'],2024-05-20 13:55:52+00:00,2024-05-20 13:55:52+00:00,https://github.com/metabase/metabase/issues/42188,[],[],
2276516133,issue,closed,completed,Create new collection for v2 metrics,,metamben,2024-05-02 21:20:18+00:00,['metamben'],2024-05-20 13:55:35+00:00,2024-05-20 13:55:35+00:00,https://github.com/metabase/metabase/issues/42187,[],[],
2276489845,issue,closed,completed,Create test harness based on cloud customer metric usage,"- [x] Collect metric usage information from cloud customers
- [x] Create test harness based on the data",metamben,2024-05-02 21:08:34+00:00,['metamben'],2024-05-20 13:55:17+00:00,2024-05-20 13:43:53+00:00,https://github.com/metabase/metabase/issues/42186,[],[],
2276482426,issue,open,,"When duplicating a dashboard (and the subset of questions inside), create a collection with those questions","**Is your feature request related to a problem? Please describe.**
It can be hard to organize otherwise. From a customer: ""I find it hard to keep organized and we end up with many many charts/queries that we never use on a Dashboard which clutter things up"" 

**Describe the solution you'd like**
When duplicating a dashboard (and the subset of questions inside), create a collection with those questions wherever you are saving the dashboard.

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket: [26830](https://metabase.zendesk.com/agent/tickets/26830)

**Additional context**
N/A
",ignacio-mb,2024-05-02 21:04:38+00:00,[],2024-05-02 21:04:39+00:00,,https://github.com/metabase/metabase/issues/42185,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Organization/Saved Questions', ''), ('Organization/Collections', '')]",[],
2276257402,issue,open,,Ability to configure data label formatting separately from x/y axis formatting,"**Describe the solution you'd like**
Ability to configure tooltip formatting separately from x/y axis formatting

Look at the image below. The customer is trying to edit the x-axis separately from the tooltip, but currently if you change the format in the chart settings, it will be for both, tooltip and axis.
![Screenshot 2024-05-20 at 3 55 22 PM](https://github.com/metabase/metabase/assets/132273646/ce4387e7-74b7-4d7e-8739-454b242b8c89)

**Describe alternatives you've considered**
Not available

**How important is this feature to you?**
Requested by a customer, internal ticket: [26935](https://metabase.zendesk.com/agent/tickets/26935)

Their feedback: ""being able to format how the axis data is displayed vs the values over the data points. For example, have the y-axis formatted as 10M but the values over the data points spell out the full number. Right now I think changing the axis formatting will affect both the same.""

**Additional context**
N/A
",ignacio-mb,2024-05-02 18:53:41+00:00,[],2024-05-20 18:57:20+00:00,,https://github.com/metabase/metabase/issues/42178,"[('Type:New Feature', ''), ('Visualization/Chart Settings', '')]","[{'comment_id': 2121009538, 'issue_id': 2276257402, 'author': 'mazameli', 'body': ""@ignacio-mb I have access to Zendesk, but I don't know that everyone on the Design team does, and we read GH issues related to a given user pain point when beginning new projects. It would be great to get a quick synthesis of the Why behind requests like this in the GH issue descriptions themselves."", 'created_at': datetime.datetime(2024, 5, 20, 18, 47, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2121022372, 'issue_id': 2276257402, 'author': 'ignacio-mb', 'body': ""You are right @mazameli, it was very clear in my head but reading it again it's difficult to understand. Will do that for the next ones. \r\n\r\nFor this specifically, I updated the description"", 'created_at': datetime.datetime(2024, 5, 20, 18, 56, 42, tzinfo=datetime.timezone.utc)}]","mazameli on (2024-05-20 18:47:18 UTC): @ignacio-mb I have access to Zendesk, but I don't know that everyone on the Design team does, and we read GH issues related to a given user pain point when beginning new projects. It would be great to get a quick synthesis of the Why behind requests like this in the GH issue descriptions themselves.

ignacio-mb (Issue Creator) on (2024-05-20 18:56:42 UTC): You are right @mazameli, it was very clear in my head but reading it again it's difficult to understand. Will do that for the next ones. 

For this specifically, I updated the description

"
2276239242,issue,closed,completed,"[FE] Clicking ""Add aggregation"" button should open the expression editor if all source metrics are present in the aggregation clause","- If all the metrics’ measure columns are present in the Summarize box, then the + button should just immediately show a new custom  expression
- If one of the metrics’ measures is not present, the user should be able to either select the missing measure to add, or should be able to create a new expression",ranquild,2024-05-02 18:42:44+00:00,"['snoe', 'ranquild']",2024-05-06 12:33:26+00:00,2024-05-06 12:33:25+00:00,https://github.com/metabase/metabase/issues/42176,[],[],
2276162490,issue,closed,completed,Add combine column shortcut to the shortcut menu in the chill mode header,Add the combine columns shortcut to the `Add column` button in chill mode.,romeovs,2024-05-02 18:03:19+00:00,['romeovs'],2024-05-13 12:18:17+00:00,2024-05-13 12:16:07+00:00,https://github.com/metabase/metabase/issues/42172,"[('.Team/Querying', '')]",[],
2276116977,issue,closed,completed,Third party cookie investigation for embedding,"**Context**

Chrome is testing [disabling 3rd party cookies for 1% of the users](https://developers.google.com/privacy-sandbox/3pcd), we want to know what effect (if any) this will have on us, and see what solutions we could provide

Main questions:

- Will chrome disabling 3rd party cookies stop embedding from working?
- Are we already not working on some browsers?
    - if so when? (eg only when SameSite=None)",npretto,2024-05-02 17:37:49+00:00,['npretto'],2024-05-13 12:29:07+00:00,2024-05-13 12:29:07+00:00,https://github.com/metabase/metabase/issues/42170,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2092733901, 'issue_id': 2276116977, 'author': 'npretto', 'body': ""I managed to get it to break embedding:\r\n- when using different domains for metabase and the hosting app (not just different subdomains, different domains entirely)\r\n- on chrome beta (Version 125.0.6422.26 )\r\n- with the flag [#test-third-party-cookie-phaseout](chrome://flags/#test-third-party-cookie-phaseout) set to Enabled\r\n- with `MB_SESSION_COOKIE_SAMESITE=none`(otherwise, from my testing, it never works with different domains), note that as we point out, this will make it not work at all with safari\r\n\r\nDemo:\r\n(chrome without flags on the left, with the flag on the right)\r\n(some requests are slow because of the reverse proxy used for the domains)\r\n\r\nhttps://github.com/metabase/metabase/assets/1914270/fe897b21-5d74-4dc5-b58d-4af395d3cf61\r\n\r\n\r\nNote that (at least now, let's see when this feature will get rolled out) there is a UI that allows to re-enabled them for 90 days, but it's likely something users will not do, as there is no UI that warns about the cookies being blocked (it only shows up in the console, which normal users don't watch)."", 'created_at': datetime.datetime(2024, 5, 3, 10, 30, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2100617300, 'issue_id': 2276116977, 'author': 'npretto', 'body': '## Alternative solutions\r\n\r\n### Cookies Having Independent Partitioned State (CHIPS)\r\nhttps://developers.google.com/privacy-sandbox/3pcd/chips\r\n\r\nNew ""Partitioned"" attribute\r\nRequires ""Secure""\r\n\r\n> With partitioned cookies, when a user visits site A and embedded content from site C sets a cookie with the Partitioned attribute, the cookie is saved in a partitioned jar designated only for cookies that the site C sets when it\'s embedded on site A. The browser will only send that cookie when the top-level site is A.\r\n\r\n#### For metabase:\r\nProbably good. The only downside I can see is that if people are logged in on metabase-instance.com they will not be logged in automatically in the iframe on company.com/analytics\r\n\r\n### Storage Access API\r\nhttps://developers.google.com/privacy-sandbox/3pcd/storage-access-api\r\n\r\nNew set of API that can only used from iframe.\r\nIt requires the user to have interactive with something before asking the permission\r\nThe user can deny access\r\nThe user needs to have interacted with embedded resource in a top level domain -> not suitable for most interactive embedded solution.\r\n\r\n\r\n>  It\'s meant for use cases where both the following are true:\r\n> - The user will interact with the embedded content—that is, it is not a passive iframe or a hidden iframe.\r\n> - The user has visited the embedded origin in a top-level context—that is, when that origin is not embedded in another site.\r\n\r\n#### For metabase:\r\nProbably not a good solution for people whitelabeling and not providing top level access to MB.\r\nThe need of interaction to ask, and the need to ask/prompt is probably a big NO for most use cases\r\n\r\n### Related Website Sets\r\nIt requiers submitting to google the json of the related websites on github\r\nIt simplifies the Storage Access API by making some requirement looser, but it still seems more work than needed and not really pratical.\r\n\r\n### Federated Credential Management API\r\n\r\nExperimental thing, it seems it\'s implemented by all browsers but I haven\'t looked into it as it seems to require a lot of changes', 'created_at': datetime.datetime(2024, 5, 8, 13, 46, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2100790812, 'issue_id': 2276116977, 'author': 'npretto', 'body': '## CHIPS / ""Partitioned"" cookies experiment\r\n\r\nI tried to use Partitioned cookies with the following diff:\r\n```diff\r\ndiff --git a/src/metabase/server/middleware/session.clj b/src/metabase/server/middleware/session.clj\r\nindex e4c392ca8a..55dcc96d24 100644\r\n--- a/src/metabase/server/middleware/session.clj\r\n+++ b/src/metabase/server/middleware/session.clj\r\n@@ -190,6 +190,7 @@\r\n   (let [cookie-options (merge\r\n                         (default-session-cookie-attributes session-type request)\r\n                         {:http-only true}\r\n+                        {:partitioned true}\r\n                         ;; If permanent cookies should be used, set the `Max-Age` directive; cookies with no\r\n                         ;; `Max-Age` and no `Expires` directives are session cookies, and are deleted when the\r\n                         ;; browser is closed.\r\n\r\n```\r\n\r\nThe results are promising, interactive embedding is working across two top level different domains.\r\n\r\nPartitioned cookies/CHIPS means that if a resource from domain A is embedded in a page on domain B, then the cookies of the embeded resources will saved in `{top level domain}/{embedded domain}`, this means that the cookies of the iframe of domain A will be isolated from the ones from domain A accessed directly.\r\n\r\nLet\'s assume the customer is hosting their app on [customer.com](http://customer.com), and their mb instance is [mb-cloud.com](http://mb-cloud.com).\r\n\r\n*IF* they have an iframe with src=""[mb-cloud.com/dashboard/1](http://mb-cloud.com/dashboard/1)"" (instead of `ttps://company-example.com/sso?return_to=${mb_url}/dashboard/1` as we suggest) this is something that could happen:\r\n* if the user is logged in on [mb-cloud.com](http://mb-cloud.com)\r\n* if for some reason they are not logged in on [customer.com](http://customer.com)\r\nthen\r\n-> with partitioned cookies: they will not be auto logged into metabase, as they cookie for [mb-cloud.com](http://mb-cloud.com) is not accessible from `mb-cloud [embedded in] [customer.com](http://customer.com)`\r\n-> without partitioned cookies: they will be logged in into the iframe (this is assuming they\'re not in the 1% group)\r\n\r\nI initially didn\'t consider that this would only happen if they\'re not logged in into their jwt provider, so I think this is a super edge case we can probably ignore.\r\n\r\nThat said, we should probably think if we should allow the customers to opt out of the Partitioned parameter via a setting to make sure we\'re not accidentaly breaking their possibly unusual flows.', 'created_at': datetime.datetime(2024, 5, 8, 15, 1, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2104775398, 'issue_id': 2276116977, 'author': 'npretto', 'body': 'Some other updates\r\n- I checked and it\'s (as we expected) still not working on safari, as they don\'t support CHIPS\r\n- I confirmed that setting Partitioned always so true could break some unusual workflows (ie: our ""zendesk flow"")\r\n- it seems that the ""https requirement"" for samesite=none is not needed for localhost', 'created_at': datetime.datetime(2024, 5, 10, 15, 7, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2107447428, 'issue_id': 2276116977, 'author': 'npretto', 'body': 'Closing the issue as we decided to proceed with CHIPS', 'created_at': datetime.datetime(2024, 5, 13, 12, 29, 7, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-05-03 10:30:16 UTC): I managed to get it to break embedding:
- when using different domains for metabase and the hosting app (not just different subdomains, different domains entirely)
- on chrome beta (Version 125.0.6422.26 )
- with the flag [#test-third-party-cookie-phaseout](chrome://flags/#test-third-party-cookie-phaseout) set to Enabled
- with `MB_SESSION_COOKIE_SAMESITE=none`(otherwise, from my testing, it never works with different domains), note that as we point out, this will make it not work at all with safari

Demo:
(chrome without flags on the left, with the flag on the right)
(some requests are slow because of the reverse proxy used for the domains)

https://github.com/metabase/metabase/assets/1914270/fe897b21-5d74-4dc5-b58d-4af395d3cf61


Note that (at least now, let's see when this feature will get rolled out) there is a UI that allows to re-enabled them for 90 days, but it's likely something users will not do, as there is no UI that warns about the cookies being blocked (it only shows up in the console, which normal users don't watch).

npretto (Issue Creator) on (2024-05-08 13:46:10 UTC): ## Alternative solutions

### Cookies Having Independent Partitioned State (CHIPS)
https://developers.google.com/privacy-sandbox/3pcd/chips

New ""Partitioned"" attribute
Requires ""Secure""


#### For metabase:
Probably good. The only downside I can see is that if people are logged in on metabase-instance.com they will not be logged in automatically in the iframe on company.com/analytics

### Storage Access API
https://developers.google.com/privacy-sandbox/3pcd/storage-access-api

New set of API that can only used from iframe.
It requires the user to have interactive with something before asking the permission
The user can deny access
The user needs to have interacted with embedded resource in a top level domain -> not suitable for most interactive embedded solution.



#### For metabase:
Probably not a good solution for people whitelabeling and not providing top level access to MB.
The need of interaction to ask, and the need to ask/prompt is probably a big NO for most use cases

### Related Website Sets
It requiers submitting to google the json of the related websites on github
It simplifies the Storage Access API by making some requirement looser, but it still seems more work than needed and not really pratical.

### Federated Credential Management API

Experimental thing, it seems it's implemented by all browsers but I haven't looked into it as it seems to require a lot of changes

npretto (Issue Creator) on (2024-05-08 15:01:02 UTC): ## CHIPS / ""Partitioned"" cookies experiment

I tried to use Partitioned cookies with the following diff:
```diff
diff --git a/src/metabase/server/middleware/session.clj b/src/metabase/server/middleware/session.clj
index e4c392ca8a..55dcc96d24 100644
--- a/src/metabase/server/middleware/session.clj
+++ b/src/metabase/server/middleware/session.clj
@@ -190,6 +190,7 @@
   (let [cookie-options (merge
                         (default-session-cookie-attributes session-type request)
                         {:http-only true}
+                        {:partitioned true}
                         ;; If permanent cookies should be used, set the `Max-Age` directive; cookies with no
                         ;; `Max-Age` and no `Expires` directives are session cookies, and are deleted when the
                         ;; browser is closed.

```

The results are promising, interactive embedding is working across two top level different domains.

Partitioned cookies/CHIPS means that if a resource from domain A is embedded in a page on domain B, then the cookies of the embeded resources will saved in `{top level domain}/{embedded domain}`, this means that the cookies of the iframe of domain A will be isolated from the ones from domain A accessed directly.

Let's assume the customer is hosting their app on [customer.com](http://customer.com), and their mb instance is [mb-cloud.com](http://mb-cloud.com).

*IF* they have an iframe with src=""[mb-cloud.com/dashboard/1](http://mb-cloud.com/dashboard/1)"" (instead of `ttps://company-example.com/sso?return_to=${mb_url}/dashboard/1` as we suggest) this is something that could happen:
* if the user is logged in on [mb-cloud.com](http://mb-cloud.com)
* if for some reason they are not logged in on [customer.com](http://customer.com)
then
-> with partitioned cookies: they will not be auto logged into metabase, as they cookie for [mb-cloud.com](http://mb-cloud.com) is not accessible from `mb-cloud [embedded in] [customer.com](http://customer.com)`
-> without partitioned cookies: they will be logged in into the iframe (this is assuming they're not in the 1% group)

I initially didn't consider that this would only happen if they're not logged in into their jwt provider, so I think this is a super edge case we can probably ignore.

That said, we should probably think if we should allow the customers to opt out of the Partitioned parameter via a setting to make sure we're not accidentaly breaking their possibly unusual flows.

npretto (Issue Creator) on (2024-05-10 15:07:10 UTC): Some other updates
- I checked and it's (as we expected) still not working on safari, as they don't support CHIPS
- I confirmed that setting Partitioned always so true could break some unusual workflows (ie: our ""zendesk flow"")
- it seems that the ""https requirement"" for samesite=none is not needed for localhost

npretto (Issue Creator) on (2024-05-13 12:29:07 UTC): Closing the issue as we decided to proceed with CHIPS

"
2276104113,issue,closed,completed,[FE + BE] Do not show aggregation operators for the first stage of metrics-only queries,"For the first stage of the query, when the source card is a metric and all join things are metrics, we should disallow re-aggregating raw metrics data in a different way. ",ranquild,2024-05-02 17:30:50+00:00,"['bshepherdson', 'ranquild']",2024-05-06 12:33:22+00:00,2024-05-06 12:33:22+00:00,https://github.com/metabase/metabase/issues/42168,[],[],
2275924203,issue,open,,Redshift column marked as `uuid` (which doesn't exist?) [UNABLE TO REPRO],"### Describe the bug
UUID as a data type is not supported in Redshift (source: [Redshift Data Types](https://docs.aws.amazon.com/redshift/latest/dg/c_Supported_data_types.html)).
When filtering Redshift datasets defined through external schemas, Redshift maps UUID fields to a CHAR type. However, Metabase still applies the ::UUID decorator when filtering these fields in the Metabase question builder, e.g., `WHERE <fieldName> = '<string>'::uuid.`
This fails because of the `::uuid` decorator. It attempts to format a field as a UUID, which is not supported in Redshift. As a result, Redshift is unable to execute the query.

### Steps to Reproduce

1. Connect a Redshift database to Metabase.
2. Filter a UUID field in the Metabase question filter to any value.
3. Observe the error: Can't infer the SQL type to use for an instance of java.util.UUID. Use setObject() with an explicit Types value to specify the type to use.
4. Click 'Show Editor' -> 'View the SQL', and you will see ::uuid has been added to the end of the WHERE statement.
5. Note that Metabase should understand that the uuid data type is not supported in Redshift.

### Expected behavior
Metabase should not add the ::uuid decorator when it detects that the data source is Redshift. Instead, it should omit the decorator and treat the field as a CHAR type.

### Logs

```clj
{:database_id 2,
 :started_at #t ""2024-05-02T16:06:30.859385Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error preparing statement: Can't infer the SQL type to use for an instance of java.util.UUID. Use setObject() with an explicit Types value to specify the type to use."",
   :stacktrace
   [""--> driver.sql_jdbc.execute$prepared_statement_STAR_$fn__79313.invoke(execute.clj:533)""
    ""driver.sql_jdbc.execute$prepared_statement_STAR_.invokeStatic(execute.clj:530)""
    ""driver.sql_jdbc.execute$prepared_statement_STAR_.invoke(execute.clj:527)""
    ""driver.sql_jdbc.execute$statement_or_prepared_statement.invokeStatic(execute.clj:553)""
    ""driver.sql_jdbc.execute$statement_or_prepared_statement.invoke(execute.clj:548)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79404.invoke(execute.clj:698)""
    ""driver.redshift$fn__112313$fn__112315.invoke(redshift.clj:180)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
    ""driver.redshift$fn__112313.invokeStatic(redshift.clj:165)""
    ""driver.redshift$fn__112313.invoke(redshift.clj:163)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc$fn__106749.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__106749.invoke(sql_jdbc.clj:76)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72237.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66594.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72058.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72068.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71500.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73405$combined_post_process__73410$combined_post_process_STAR___73411.invoke(query_processor.clj:262)""
    ""query_processor$fn__73405$combined_pre_process__73406$combined_pre_process_STAR___73407.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66691.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148$fn__72152.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67318$fn__67319.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67318.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72145.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72450.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__72085$handle_audit_app_internal_queries__72086$fn__72088.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72096.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71211.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72381.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72982.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62832$thunk__62834.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62832.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62844.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93918.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53261$fn__53263.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53261.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43756.invoke(streaming_response.clj:88)""],
   :error_type :driver,
   :ex-data
   {:driver :redshift,
    :type :driver,
    :sql
    [""-- /* partner: \""metabase\"", {\""dashboard_id\"":null,\""chart_id\"":null,\""optional_user_id\"":3,\""optional_account_id\"":\""aa47e958-cd46-4739-a531-96ccdfe22d13\"",\""filter_values\"":{}} */ Metabase:: userID: 3 queryType: MBQL queryHash: fde78cb266312492b37bdd4be58aaa21be1908afd85a4a51a9b3df78e14fda88""
  ""SELECT \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"" FROM \""<dataset>\"".\""<schema>\"" WHERE<FIELD IN QUESTION> = ? LIMIT    ""  2000""],
    :params (#uuid ""28a85db2-00ad-4b76-bad4-98e689b650c9"")}}],
 :action_id nil,
 :state ""07006"",
 :error_type :driver,
 :json_query
 {:database 2,
  :type ""query"",
  :query
  {:source-table 349, :filter [""="" [""field"" 37800 {:base-type ""type/UUID""}] ""28a85db2-00ad-4b76-bad4-98e689b650c9""]},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
""SELECT \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"", \""<dataset>\"".\""<schema>\"".\""<field>\"" AS \""<field>\"" FROM \""<dataset>\"".\""<schema>\"" WHERE<FIELD IN QUESTION> = ? LIMIT 1048575"",
  :params (#uuid ""28a85db2-00ad-4b76-bad4-98e689b650c9"")},
 :status :failed,
 :class com.amazon.redshift.util.RedshiftException,
 :stacktrace
 [""com.amazon.redshift.jdbc.RedshiftPreparedStatement.setObject(RedshiftPreparedStatement.java:1171)""
  ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.setObject(NewProxyPreparedStatement.java:821)""
  ""--> driver.sql_jdbc.execute$set_object.invokeStatic(execute.clj:397)""
  ""driver.sql_jdbc.execute$set_object.invoke(execute.clj:394)""
  ""driver.sql_jdbc.execute$fn__79210.invokeStatic(execute.clj:406)""
  ""driver.sql_jdbc.execute$fn__79210.invoke(execute.clj:404)""
  ""driver.sql_jdbc.execute$set_parameters_BANG_$fn__79230.invoke(execute.clj:458)""
  ""driver.sql_jdbc.execute$set_parameters_BANG_.invokeStatic(execute.clj:454)""
  ""driver.sql_jdbc.execute$set_parameters_BANG_.invoke(execute.clj:442)""
  ""driver.sql_jdbc.execute$fn__79242.invokeStatic(execute.clj:485)""
  ""driver.sql_jdbc.execute$fn__79242.invoke(execute.clj:468)""
  ""driver.sql_jdbc.execute$prepared_statement_STAR_$fn__79313.invoke(execute.clj:531)""
  ""driver.sql_jdbc.execute$prepared_statement_STAR_.invokeStatic(execute.clj:530)""
  ""driver.sql_jdbc.execute$prepared_statement_STAR_.invoke(execute.clj:527)""
  ""driver.sql_jdbc.execute$statement_or_prepared_statement.invokeStatic(execute.clj:553)""
  ""driver.sql_jdbc.execute$statement_or_prepared_statement.invoke(execute.clj:548)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__79404.invoke(execute.clj:698)""
  ""driver.redshift$fn__112313$fn__112315.invoke(redshift.clj:180)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
  ""driver.redshift$fn__112313.invokeStatic(redshift.clj:165)""
  ""driver.redshift$fn__112313.invoke(redshift.clj:163)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
  ""driver.sql_jdbc$fn__106749.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__106749.invoke(sql_jdbc.clj:76)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72237.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66594.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72058.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72068.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71500.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73405$combined_post_process__73410$combined_post_process_STAR___73411.invoke(query_processor.clj:262)""
  ""query_processor$fn__73405$combined_pre_process__73406$combined_pre_process_STAR___73407.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66691.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148$fn__72152.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72148.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67318$fn__67319.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67318.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72145.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72450.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72085$handle_audit_app_internal_queries__72086$fn__72088.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72096.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71211.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72381.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72982.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62832$thunk__62834.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62832.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62844.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93918.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53261$fn__53263.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53261.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43756.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""Can't infer the SQL type to use for an instance of java.util.UUID. Use setObject() with an explicit Types value to specify the type to use."",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 2,
  :type :query,
  :query
  {:source-table 349,
   :filter
   [:=
    [:field 37800 {:base-type :type/UUID}]
    [:value
     ""28a85db2-00ad-4b76-bad4-98e689b650c9""
     {:base_type :type/UUID,
      :effective_type :type/UUID,
      :coercion_strategy nil,
      :semantic_type :type/Name,
      :database_type ""uuid"",
      :name ""verificationProviderId""}]],
   :fields
   [[:field 2959 nil]
    [:field 2964 {:temporal-unit :default}]
    [:field 2966 {:temporal-unit :default}]
    [:field 2975 nil]
    [:field 2970 nil]
    [:field 2963 nil]
    [:field 2957 nil]
    [:field 2974 nil]
    [:field 2968 nil]
    [:field 2973 nil]
    [:field 2965 nil]
    [:field 2972 nil]
    [:field 2962 {:temporal-unit :default}]
    [:field 2967 nil]
    [:field 2971 nil]
    [:field 2976 nil]
    [:field 2969 nil]
    [:field 2960 nil]
    [:field 2961 nil]
    [:field 2958 nil]
    [:field 37800 nil]
    [:field 38319 {:temporal-unit :default}]],
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 3, :context :ad-hoc}},
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.213-201.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-22"",
      ""tag"": ""v0.49.7"",
      ""hash"": ""f0ff786""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking our usage of metabase entirely 

### Additional context

_No response_",bhaveshnathwani,2024-05-02 16:10:17+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/42166,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Redshift', None), ('Querying/Processor', ''), ('.Unable to Reproduce', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2190415837, 'issue_id': 2275924203, 'author': 'camsaul', 'body': 'The reason Metabase is trying to do `uuid` column stuff here is because it thinks your column is a `uuid` column. \r\n\r\nI don\'t really understand how this is possible. From the error logs, Metabase picked up this information about your column:\r\n\r\n```clj\r\n{:base-type         :type/UUID\r\n :effective-type    :type/UUID\r\n :coercion-strategy nil\r\n :semantic-type     :type/Name\r\n :database-type     ""uuid""\r\n :name              ""verificationProviderId""}\r\n```\r\n\r\nhowever as you noted [Redshift doesn\'t have a `uuid` type](https://docs.aws.amazon.com/redshift/latest/dg/federated-data-types.html), so it doesn\'t make sense that this column was recorded as having database type `uuid`. \r\n\r\nDid you start with a Postgres database and change it to Redshift? Or manually mark the column as UUID?', 'created_at': datetime.datetime(2024, 6, 26, 2, 23, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190418070, 'issue_id': 2275924203, 'author': 'camsaul', 'body': ""I'm not following step 2 in your repro steps\r\n\r\n> Filter a UUID field in the Metabase question filter to any value.\r\n\r\nHow can you filter a UUID field if such a thing doesn't exist in Redshift?"", 'created_at': datetime.datetime(2024, 6, 26, 2, 26, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190426918, 'issue_id': 2275924203, 'author': 'camsaul', 'body': ""What's the type of your `verificationProviderId` column?"", 'created_at': datetime.datetime(2024, 6, 26, 2, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190438209, 'issue_id': 2275924203, 'author': 'camsaul', 'body': 'The original query was \r\n\r\n```clj\r\n{:source-table 349, :filter [""="" [""field"" 37800 {:base-type ""type/UUID""}] ""28a85db2-00ad-4b76-bad4-98e689b650c9""]}\r\n```\r\n\r\nSo Field 37800 is clearly marked as being a UUID column but this really doesn\'t make a ton of sense unless someone manually set it to that. The only way something gets `:type/UUID` is if it has a database type of `uuid` which as previously mentioned doesn\'t exist in Redshift', 'created_at': datetime.datetime(2024, 6, 26, 2, 47, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190459530, 'issue_id': 2275924203, 'author': 'camsaul', 'body': ""Downgrading to P2 since I can't reproduce this and it doesn't seem like it should be possible during normal usage -- since Redshift doesn't have `uuid` the column should never get marked as `:type/UUID`. The only explanations that make any sense are that someone started with a Postgres Database in Metabase and changed the type to Redshift or someone manually edited metadata in the application database. I can not figure out any way of reproducing this bug, column type is not something editable from the admin panel.\r\n\r\n@bhaveshnathwani please give me more information when you get a chance"", 'created_at': datetime.datetime(2024, 6, 26, 3, 6, 40, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-06-26 02:23:31 UTC): The reason Metabase is trying to do `uuid` column stuff here is because it thinks your column is a `uuid` column. 

I don't really understand how this is possible. From the error logs, Metabase picked up this information about your column:

```clj
{:base-type         :type/UUID
 :effective-type    :type/UUID
 :coercion-strategy nil
 :semantic-type     :type/Name
 :database-type     ""uuid""
 :name              ""verificationProviderId""}
```

however as you noted [Redshift doesn't have a `uuid` type](https://docs.aws.amazon.com/redshift/latest/dg/federated-data-types.html), so it doesn't make sense that this column was recorded as having database type `uuid`. 

Did you start with a Postgres database and change it to Redshift? Or manually mark the column as UUID?

camsaul on (2024-06-26 02:26:05 UTC): I'm not following step 2 in your repro steps


How can you filter a UUID field if such a thing doesn't exist in Redshift?

camsaul on (2024-06-26 02:35:43 UTC): What's the type of your `verificationProviderId` column?

camsaul on (2024-06-26 02:47:44 UTC): The original query was 

```clj
{:source-table 349, :filter [""="" [""field"" 37800 {:base-type ""type/UUID""}] ""28a85db2-00ad-4b76-bad4-98e689b650c9""]}
```

So Field 37800 is clearly marked as being a UUID column but this really doesn't make a ton of sense unless someone manually set it to that. The only way something gets `:type/UUID` is if it has a database type of `uuid` which as previously mentioned doesn't exist in Redshift

camsaul on (2024-06-26 03:06:40 UTC): Downgrading to P2 since I can't reproduce this and it doesn't seem like it should be possible during normal usage -- since Redshift doesn't have `uuid` the column should never get marked as `:type/UUID`. The only explanations that make any sense are that someone started with a Postgres Database in Metabase and changed the type to Redshift or someone manually edited metadata in the application database. I can not figure out any way of reproducing this bug, column type is not something editable from the admin panel.

@bhaveshnathwani please give me more information when you get a chance

"
2275840274,issue,closed,completed,When opening a multiseries line chart from dashboard the browser tab name gets the first series name,"### Describe the bug

When opening a multiseries line chart from dashboard the browser tab name gets the first series name.

### To Reproduce

Steps shown on stats: https://metaboat.slack.com/archives/C05MPF0TM3L/p1714491195406629

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest master
```


### Severity

Annoying

### Additional context

_No response_",alxnddr,2024-05-02 15:35:53+00:00,['kulyk'],2024-07-25 09:50:47+00:00,2024-07-25 09:50:25+00:00,https://github.com/metabase/metabase/issues/42165,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2275760296,issue,closed,completed,drop unused components from frontend/src/metabase/dashboard/components/ParametersPopover.jsx and convert to tsx,,uladzimirdev,2024-05-02 14:58:13+00:00,['uladzimirdev'],2024-05-02 21:23:23+00:00,2024-05-02 21:23:23+00:00,https://github.com/metabase/metabase/issues/42163,[],[],
2275534528,issue,closed,completed,Smart scalar should follow the Mantine theme with proper defaults in React embedding,"- Color of `vs. previous month: 94` should be readable
- Font size of value should be adjustable

![CleanShot 2567-05-02 at 22 00 25@2x](https://github.com/metabase/metabase/assets/4714175/459a573e-b57d-4c08-9469-99df0d7a40f9)
",heypoom,2024-05-02 13:23:03+00:00,['heypoom'],2024-05-13 08:57:18+00:00,2024-05-13 08:57:18+00:00,https://github.com/metabase/metabase/issues/42159,[],[],
2275534278,issue,closed,completed,Data tables should follow the Mantine theme with proper defaults in React embedding,"Data tables currently does not follow Mantine's global styles out of the box. It is also transparent by default, and the text can be unreadable.

<img src=""https://github.com/metabase/metabase/assets/4714175/a68bfbbc-c074-42e7-9ea1-4a57b6c22302"" width=""400"">

Table cells, rows & headers should try to follow the theme configuration. We could make all the other cell always have white background first, so the chart won’t look broken on sites using dark background. Then, we can allow for customizing these styles further:

- Header and link should follow the brand color, similar to the dashboard's current behaviour.
- Default text color (this isn’t configurable in the dashboard)
- Table's background color",heypoom,2024-05-02 13:22:56+00:00,['heypoom'],2024-05-15 17:13:05+00:00,2024-05-15 17:13:05+00:00,https://github.com/metabase/metabase/issues/42158,[],"[{'comment_id': 2092580976, 'issue_id': 2275534278, 'author': 'heypoom', 'body': 'unassigning myself for now - will work on other tasks first', 'created_at': datetime.datetime(2024, 5, 3, 8, 50, 38, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-05-03 08:50:38 UTC): unassigning myself for now - will work on other tasks first

"
2275527347,issue,closed,completed,Remove extraneous paddings from cartesian charts in React embedding,"`CartesianChartRoot` currently has a fixed padding that cannot be removed in React embedding environment. We should remove this padding.

<img src=""https://github.com/metabase/metabase/assets/4714175/60766fa0-9d13-4c3f-96ee-510b8bf784e9"" width=""200"" />
",heypoom,2024-05-02 13:19:35+00:00,['heypoom'],2024-05-03 07:35:47+00:00,2024-05-03 07:35:47+00:00,https://github.com/metabase/metabase/issues/42157,[],[],
2275478506,issue,closed,completed,[BE] Suggest a join condition based on the first breakout clause of joined metrics,"Modify `suggestedJoinConditions` for metrics. 

If:
- the source card is a metric 
- the source metric has a breakout clause (pick the first breakout clause if multiple)
- the joined thing is a metric
- the joined metric has a breakout clause (pick the first breakout clause if multiple)
- the columns used in these 2 breakout clauses have the same type

then add a join condition based on these 2 columns. Make sure to sync the temporal unit between columns like we do for other cases. ",ranquild,2024-05-02 12:56:44+00:00,['bshepherdson'],2024-05-07 15:35:00+00:00,2024-05-07 15:35:00+00:00,https://github.com/metabase/metabase/issues/42155,[],[],
2275435338,issue,closed,completed,Erroneous field referenced in parameter search for dashboard filter,"### Describe the bug

Stats is searching an unrelated field for the `Customer Name` filter on Dashboard 1880:

```
GET /api/dashboard/1880/params/85e5498e/search/Onecom

{""via"":
[
{""type"":""clojure.lang.ExceptionInfo"",
""message"":""Cannot search against non-Text Field 541,278 \""id\"""",
""data"":{""status-code"":400,""field-id"":541278,""field"":""id"",""base-type"":""type/BigInteger""},
""at"":[""metabase.models.params.chain_filter$check_valid_search_field"",""invokeStatic"",""chain_filter.clj"",607]}],
""trace"":[[""metabase.models.params.chain_filter$check_valid_search_field"",""invokeStatic"",""chain_filter.clj"",607],
...
""message"":""Cannot search against non-Text Field 541,278 \""id\"""",""field-id"":541278,""field"":""id"",""base-type"":""type/BigInteger""}
```

What's mysterious is that _no_ dashboard params (not on that one nor anywhere else) use Field 541278. Something is going wrong in the chain filtering that's pulling in the wrong field ID.

### To Reproduce

1. Go to dashboard 1880 on stats
2. Add a Customer Name filter
3. Check the network tab
4. See error

(alternatively, GET the endpoint directly)

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Built on 2024-05-02

Hash: 3db638f
```
```


### Severity

blocking some users

### Additional context

Unsure how widespread this is",tsmacdonald,2024-05-02 12:36:32+00:00,[],2024-05-06 10:35:40+00:00,2024-05-06 10:35:40+00:00,https://github.com/metabase/metabase/issues/42153,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Organization/Search', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2090657674, 'issue_id': 2275435338, 'author': 'tsmacdonald', 'body': ""Tried to repro this locally and couldn't manage"", 'created_at': datetime.datetime(2024, 5, 2, 14, 36, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2095206475, 'issue_id': 2275435338, 'author': 'qnkhuat', 'body': 'Answered in https://metaboat.slack.com/archives/C05MPF0TM3L/p1714616294801369', 'created_at': datetime.datetime(2024, 5, 6, 5, 8, 26, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-05-02 14:36:59 UTC): Tried to repro this locally and couldn't manage

qnkhuat on (2024-05-06 05:08:26 UTC): Answered in https://metaboat.slack.com/archives/C05MPF0TM3L/p1714616294801369

"
2275397509,issue,closed,completed,Add plus icon to chill mode headers with extract column popover shortcut,"Render a `Add column` button on the table header with the `Extract part of column` action in the pop over.


<img width=""481"" alt=""Screenshot 2024-05-08 at 19 19 07"" src=""https://github.com/metabase/metabase/assets/1250185/22c9df7b-6242-4d36-a28c-43e5fd72565d"">
",romeovs,2024-05-02 12:17:29+00:00,['romeovs'],2024-05-13 12:18:21+00:00,2024-05-13 06:26:53+00:00,https://github.com/metabase/metabase/issues/42151,"[('.Team/Querying', '')]",[],
2275397336,issue,closed,completed,[Epic] Add custom column in chill mode,"**Links**
- [product doc](https://www.notion.so/metabase/Add-custom-column-in-chill-mode-7c2195792b2c4fdeb43b1085c4b4dcb6)

## Goals
See and choose from all available shortcuts in one place to create a column in chill mode

## Implementation Plan

```[tasklist]
### Milestone 1
- [ ] https://github.com/metabase/metabase/issues/42151
- [ ] https://github.com/metabase/metabase/issues/42172
- [ ] https://github.com/metabase/metabase/issues/42443
```



<img width=""472"" alt=""Screenshot 2024-05-02 at 14 20 35"" src=""https://github.com/metabase/metabase/assets/1250185/c540c672-5b9f-4476-b9f2-2f07b8bd8942"">",romeovs,2024-05-02 12:17:23+00:00,['romeovs'],2024-06-06 13:50:36+00:00,2024-06-06 13:50:36+00:00,https://github.com/metabase/metabase/issues/42150,"[('.Epic', 'Feature Implementation or Project')]",[],
2275243996,issue,open,,Consider changing calls to mapv into map in mongo conversions code,"Original intent for using `mapv` was to realize the sequences and provide vectors as return in mongo util and conversion namespaces. That approach caused oom in calls of `do-find` during sync with collection that contain huge documents. It was sufficient to change `mapv` to `map` in that function to mitigate the issue (PR #42140). Use of lazy sequences should be considered also in other functions in mongo driver. Care should be taken so those sequences are not realized, after the connection to mongo is closed.",lbrdnk,2024-05-02 11:00:20+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/42147,"[('Type:Tech Debt', 'or Refactoring'), ('Database/Mongo', None), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2274655182,issue,open,,Jetty threads starvation,"### Describe the bug

Hello.

I encountered the following problem in Metabase - during operation the number of busy jetty threads gradually increases, after which at some point the application stops responding to healthcheck probes:
![Grafana](https://github.com/metabase/metabase/assets/48658286/384d7ab1-3e4b-4f98-82f3-ab5f411bae63)

At the same time, the number of **HelperThreads** in the thread dump increases. Here is an application dump with uptime for about a week:
[metabase-20240502.dmp](https://github.com/metabase/metabase/files/15184100/metabase-20240502.dmp)

Adding **maxIdleTime** and **unreturnedConnectionTimeout** parameters does not help. Updating the version from 0.45 to 0.48 also does not help.

Current configuration:
```
MB_JDBC_DATA_WAREHOUSE_MAX_CONNECTION_POOL_SIZE: 45
MB_JETTY_MAXTHREADS: 100

c3p0.idleConnectionTestPeriod=60
c3p0.maxIdleTime=300
c3p0.unreturnedConnectionTimeout=3600
```

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

The number of busy Jetty threads does not increase over time.

### Logs

2024-04-26 09:31:08,696 INFO metabase.core :: Starting Metabase version v0.48.8 (a900c85)
2024-04-27 00:00:55,212 DEBUG middleware.log :: GET /api/health 200 158.6 µs (0 DB calls) App DB connections: 0/10 Jetty threads: 9/100 (2 idle, 0 queued) (202 total active threads) Queries in flight: 1 (0 queued)
2024-04-29 00:01:35,991 DEBUG middleware.log :: GET /api/health 200 150.0 µs (0 DB calls) App DB connections: 0/8 Jetty threads: 39/100 (3 idle, 0 queued) (267 total active threads) Queries in flight: 0 (0 queued)
2024-05-02 00:02:25,991 DEBUG middleware.log :: GET /api/health 200 153.4 µs (0 DB calls) App DB connections: 0/15 Jetty threads: 44/100 (2 idle, 0 queued) (283 total active threads) Queries in flight: 0 (0 queued)

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:125.0) Gecko/20100101 Firefox/125.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-177-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""googleanalytics"",
      ""postgres"",
      ""bigquery-cloud-sdk"",
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.11 (Ubuntu 14.11-1.pgdg22.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Riga""
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",ky0uraku,2024-05-02 05:41:10+00:00,[],2025-02-04 20:26:29+00:00,,https://github.com/metabase/metabase/issues/42139,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2090155043, 'issue_id': 2274655182, 'author': 'paoliniluis', 'body': 'You need to tell us exactly what you do to use those threads so we can reproduce. Btw: why do you have that c3p0 config?', 'created_at': datetime.datetime(2024, 5, 2, 10, 37, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2090255737, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': '> You need to tell us exactly what you do to use those threads so we can reproduce. Btw: why do you have that c3p0 config?\r\n\r\nWe are not doing anything special - several datasources are connected to the Metabase (Postgres, Oracle), from which we take information for the dashboards that users work with.\r\n\r\n**idleConnectionTestPeriod** was needed because network devices between the DBMS and Metabase sometimes unexpectedly broke network connections; **maxIdleTime** and **unreturnedConnectionTimeout** were added in an attempt to help with increasing number of threads.', 'created_at': datetime.datetime(2024, 5, 2, 11, 22, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2092340702, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': 'I also have dumps for different days - you can see the dynamics of increasing number of HelperThreads ([Samurai](https://github.com/yusuke/samurai), for example, can visualize the difference between several dumps):\r\n[metabase-20240427.dmp](https://github.com/metabase/metabase/files/15196522/metabase-20240427.dmp)\r\n[metabase-20240501.dmp](https://github.com/metabase/metabase/files/15196523/metabase-20240501.dmp)\r\n[metabase-20240503.dmp](https://github.com/metabase/metabase/files/15196524/metabase-20240503.dmp)', 'created_at': datetime.datetime(2024, 5, 3, 5, 38, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2097863472, 'issue_id': 2274655182, 'author': 'Tony-metabase', 'body': 'Can you upgrade to our latest 49.8 please\r\n\r\nAlso when you say several datasources are connected to the Metabase can you quantify how many and what is the setting of the sync and scan for such Databases?', 'created_at': datetime.datetime(2024, 5, 7, 9, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098271112, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': '> Can you upgrade to our latest 49.8 please\r\n\r\nSure, will try it in a couple of days.\r\n\r\n> Also when you say several datasources are connected to the Metabase can you quantify how many and what is the setting of the sync and scan for such Databases?\r\n\r\nOnly one Oracle datasource is most actively used - hourly sync, scan disabled.\r\n\r\nOther data sources (PostgreSQL - 4, Oracle - 4) - hourly sync, daily scan.', 'created_at': datetime.datetime(2024, 5, 7, 12, 16, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098293923, 'issue_id': 2274655182, 'author': 'Tony-metabase', 'body': 'So you have 8 scans that happen every day right? Can you check how long those take? You can check the logs for FINISHED keywords and for the update-field-values\r\n\r\n<img width=""1167"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/f903cb43-886d-4718-9d0c-2e5bd7dec5d7"">', 'created_at': datetime.datetime(2024, 5, 7, 12, 29, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098503611, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': ""Looks like I forgot some datasources. Here are the logs for the last 5 days:\r\n```\r\ncat metabase.log | grep FINISHED | grep update-field-values\r\n\r\n2024-05-02 16:00:17,873 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (5.2 s)\r\n2024-05-03 10:00:00,061 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (59.4 µs)\r\n2024-05-03 11:03:12,844 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.1 mins)\r\n2024-05-03 11:03:22,379 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.0 s)\r\n2024-05-03 16:00:15,179 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.2 s)\r\n2024-05-04 10:00:00,069 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (35.0 µs)\r\n2024-05-04 11:03:35,279 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.2 mins)\r\n2024-05-04 11:03:46,370 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.6 s)\r\n2024-05-04 16:00:18,197 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.9 s)\r\n2024-05-05 10:00:00,075 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (33.8 µs)\r\n2024-05-05 11:03:29,756 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.2 mins)\r\n2024-05-05 11:03:40,463 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.4 s)\r\n2024-05-05 16:00:17,825 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.9 s)\r\n2024-05-06 03:00:01,768 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 10 'DB Oracle Production (GDPR)' (580.6 ms)\r\n2024-05-06 10:00:00,067 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (94.6 µs)\r\n2024-05-06 11:03:37,061 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.3 mins)\r\n2024-05-06 11:03:48,461 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.5 s)\r\n2024-05-06 16:00:18,003 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (5.0 s)\r\n2024-05-07 10:00:00,074 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (66.9 µs)\r\n2024-05-07 11:03:39,783 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.3 mins)\r\n2024-05-07 11:03:51,298 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.7 s)\r\n```"", 'created_at': datetime.datetime(2024, 5, 7, 14, 10, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2114118748, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': ""> Can you upgrade to our latest 49.8 please\r\n\r\nHello. Sorry for the delay - updated to 49.10 this morning. We'll take a look at Jetty in a couple of days and I'll come back with information."", 'created_at': datetime.datetime(2024, 5, 16, 6, 20, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120181445, 'issue_id': 2274655182, 'author': 'ky0uraku', 'body': ""@Tony-metabase\r\n\r\nHello.\r\n\r\nWe've been running the updated version of Metabase (0.49.10) since last Friday and unfortunately seeing the same behavior:\r\n![Screenshot 2024-05-20 - Grafana](https://github.com/metabase/metabase/assets/48658286/7bacc80f-2100-4abd-8ca2-ee182fbf19d6)\r\n\r\nThread dump:\r\n[metabase-20240520.dmp](https://github.com/metabase/metabase/files/15376037/metabase-20240520.dmp)"", 'created_at': datetime.datetime(2024, 5, 20, 10, 42, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2256234872, 'issue_id': 2274655182, 'author': 'Onlinehead', 'body': 'We have a customer in the cloud with a similar (but not exact) problem.\r\nInternal [thread](https://metaboat.slack.com/archives/C010ZSXQY87/p1721744228416829?thread_ts=1721143940.738869&cid=C010ZSXQY87).\r\nIt has no Oracle database connected (both DBs are Postgres), but also has an overrid of `unreturnedConnectionTimeout` value because the database it query is slow and frequently return results in minutes after request. \r\nAt some point it has all database connections used (but only for connected DBs):\r\n```\r\nDEBUG middleware.log :: GET /api/field/_reducted_/values null 30.4 s (11 DB calls) App DB connections: 6/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 12/12 (12 threads blocked)\r\nDEBUG middleware.log :: GET /api/field/_reducted_/values 200 30.6 s (11 DB calls) App DB connections: 3/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 12/12 (1 threads blocked)\r\nDEBUG middleware.log :: GET /api/field/_reducted_/values 200 2.6 s (12 DB calls) App DB connections: 4/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 15/15 (30 threads blocked)\r\n```\r\nApplication DB has free connections, but instance stopped to respond for a health check at that time.\r\nAlso, you can see in the logs the logged HTTP code is `null` for one of the requests.', 'created_at': datetime.datetime(2024, 7, 29, 15, 24, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326510298, 'issue_id': 2274655182, 'author': 'paoliniluis', 'body': 'Thread dumps here\r\n[embla2.txt](https://github.com/user-attachments/files/16849305/embla2.txt)\r\n\r\n[justplay.txt](https://github.com/user-attachments/files/16849304/justplay.txt)\r\n[celesdump.txt](https://github.com/user-attachments/files/16849303/celesdump.txt)\r\n\r\n[hosting-66e45078dd42498e-7c6bdcb6d6-fbj4n.txt](https://github.com/user-attachments/files/16849302/hosting-66e45078dd42498e-7c6bdcb6d6-fbj4n.txt)', 'created_at': datetime.datetime(2024, 9, 3, 13, 19, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326594771, 'issue_id': 2274655182, 'author': 'piranha', 'body': ""embla2: 50 of 141 stuck on `execute-bigquery`\r\njustplay: 50 of 160 stuck on `execute-reducible-query`\r\ncelesdump: 46 of 149 stuck on `execute-bigquery`\r\nhosting-66e4: kind of weird, threads are mostly parked, not really similar to previous three\r\n\r\nI've used jstack.review to look at those.\r\n\r\nNot sure what to make out of that, it seems like queries to the storage get stuck and are unreleased. Seems like somebody is clicking reload eagerly to see the data ASAP, but all the old queries are still there executing and so at some point Jetty just is at the limits.\r\n\r\nMy analysis could be way off."", 'created_at': datetime.datetime(2024, 9, 3, 13, 55, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329899520, 'issue_id': 2274655182, 'author': 'paoliniluis', 'body': 'ok, so I think this is a combination of an edge case of what I\'m going to describe below, https://github.com/metabase/metabase/issues/45571 + the fact that the queries take more time in v50 (still need to confirm that fact but all clues lead to that.\r\n\r\nRepro:\r\n1) set up Metabase connected to a postgres db as the DW\r\n2) create a new sql question that does simply ""select pg_sleep(30)""\r\n3) add the question to a dashboard like 30 times, save it\r\n4) now duplicate the tab like 3-4 times, reload the tabs also a few times (see that the queries in flight will increase and also be queued)\r\n5) close all tabs, see that the queries won\'t get cancelled, and also the queries in flight stay high\r\n\r\nIf you also add https://github.com/metabase/metabase/issues/8679 to the matter, then you have an explosive combo\r\n\r\n\r\nAlso, if you have queued queries in flight, then sync, scan, get field values, all get queued as well, adding to the combo\r\n\r\n+1 other interesting fact: try a select 1 on the sample database (h2), you won\'t get anything since all threads are locked', 'created_at': datetime.datetime(2024, 9, 4, 20, 20, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527836826, 'issue_id': 2274655182, 'author': 'benoittgt', 'body': 'We have the same issue with `v0.51.7.1`. It freeze completly the interface and we have to reboot if we want to fix it quickly. We can see in graph that it decrease after.\n\n![Image](https://github.com/user-attachments/assets/4b73737c-3f51-4815-b850-008779ddd065)\n\n![Image](https://github.com/user-attachments/assets/925751ae-8057-4d4c-b45b-3f14c9545b2c)\n\nEDIT: I think our issue is different and simply linked to a heavy usage of Metabase with a database that was having heavy load for another part of our system.', 'created_at': datetime.datetime(2024, 12, 9, 12, 48, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-02 10:37:45 UTC): You need to tell us exactly what you do to use those threads so we can reproduce. Btw: why do you have that c3p0 config?

ky0uraku (Issue Creator) on (2024-05-02 11:22:41 UTC): We are not doing anything special - several datasources are connected to the Metabase (Postgres, Oracle), from which we take information for the dashboards that users work with.

**idleConnectionTestPeriod** was needed because network devices between the DBMS and Metabase sometimes unexpectedly broke network connections; **maxIdleTime** and **unreturnedConnectionTimeout** were added in an attempt to help with increasing number of threads.

ky0uraku (Issue Creator) on (2024-05-03 05:38:46 UTC): I also have dumps for different days - you can see the dynamics of increasing number of HelperThreads ([Samurai](https://github.com/yusuke/samurai), for example, can visualize the difference between several dumps):
[metabase-20240427.dmp](https://github.com/metabase/metabase/files/15196522/metabase-20240427.dmp)
[metabase-20240501.dmp](https://github.com/metabase/metabase/files/15196523/metabase-20240501.dmp)
[metabase-20240503.dmp](https://github.com/metabase/metabase/files/15196524/metabase-20240503.dmp)

Tony-metabase on (2024-05-07 09:31:07 UTC): Can you upgrade to our latest 49.8 please

Also when you say several datasources are connected to the Metabase can you quantify how many and what is the setting of the sync and scan for such Databases?

ky0uraku (Issue Creator) on (2024-05-07 12:16:34 UTC): Sure, will try it in a couple of days.


Only one Oracle datasource is most actively used - hourly sync, scan disabled.

Other data sources (PostgreSQL - 4, Oracle - 4) - hourly sync, daily scan.

Tony-metabase on (2024-05-07 12:29:28 UTC): So you have 8 scans that happen every day right? Can you check how long those take? You can check the logs for FINISHED keywords and for the update-field-values

<img width=""1167"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/f903cb43-886d-4718-9d0c-2e5bd7dec5d7"">

ky0uraku (Issue Creator) on (2024-05-07 14:10:17 UTC): Looks like I forgot some datasources. Here are the logs for the last 5 days:
```
cat metabase.log | grep FINISHED | grep update-field-values

2024-05-02 16:00:17,873 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (5.2 s)
2024-05-03 10:00:00,061 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (59.4 µs)
2024-05-03 11:03:12,844 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.1 mins)
2024-05-03 11:03:22,379 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.0 s)
2024-05-03 16:00:15,179 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.2 s)
2024-05-04 10:00:00,069 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (35.0 µs)
2024-05-04 11:03:35,279 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.2 mins)
2024-05-04 11:03:46,370 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.6 s)
2024-05-04 16:00:18,197 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.9 s)
2024-05-05 10:00:00,075 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (33.8 µs)
2024-05-05 11:03:29,756 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.2 mins)
2024-05-05 11:03:40,463 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.4 s)
2024-05-05 16:00:17,825 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (4.9 s)
2024-05-06 03:00:01,768 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 10 'DB Oracle Production (GDPR)' (580.6 ms)
2024-05-06 10:00:00,067 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (94.6 µs)
2024-05-06 11:03:37,061 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.3 mins)
2024-05-06 11:03:48,461 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.5 s)
2024-05-06 16:00:18,003 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 5 'GA DB' (5.0 s)
2024-05-07 10:00:00,074 INFO sync.util :: FINISHED: step 'update-field-values' for googleanalytics Database 4 'GA DB Mobile' (66.9 µs)
2024-05-07 11:03:39,783 INFO sync.util :: FINISHED: step 'update-field-values' for bigquery-cloud-sdk Database 11 'DB BigQuery' (1.3 mins)
2024-05-07 11:03:51,298 INFO sync.util :: FINISHED: step 'update-field-values' for oracle Database 8 'DB Oracle Stage' (3.7 s)
```

ky0uraku (Issue Creator) on (2024-05-16 06:20:10 UTC): Hello. Sorry for the delay - updated to 49.10 this morning. We'll take a look at Jetty in a couple of days and I'll come back with information.

ky0uraku (Issue Creator) on (2024-05-20 10:42:37 UTC): @Tony-metabase

Hello.

We've been running the updated version of Metabase (0.49.10) since last Friday and unfortunately seeing the same behavior:
![Screenshot 2024-05-20 - Grafana](https://github.com/metabase/metabase/assets/48658286/7bacc80f-2100-4abd-8ca2-ee182fbf19d6)

Thread dump:
[metabase-20240520.dmp](https://github.com/metabase/metabase/files/15376037/metabase-20240520.dmp)

Onlinehead on (2024-07-29 15:24:39 UTC): We have a customer in the cloud with a similar (but not exact) problem.
Internal [thread](https://metaboat.slack.com/archives/C010ZSXQY87/p1721744228416829?thread_ts=1721143940.738869&cid=C010ZSXQY87).
It has no Oracle database connected (both DBs are Postgres), but also has an overrid of `unreturnedConnectionTimeout` value because the database it query is slow and frequently return results in minutes after request. 
At some point it has all database connections used (but only for connected DBs):
```
DEBUG middleware.log :: GET /api/field/_reducted_/values null 30.4 s (11 DB calls) App DB connections: 6/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 12/12 (12 threads blocked)
DEBUG middleware.log :: GET /api/field/_reducted_/values 200 30.6 s (11 DB calls) App DB connections: 3/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 12/12 (1 threads blocked)
DEBUG middleware.log :: GET /api/field/_reducted_/values 200 2.6 s (12 DB calls) App DB connections: 4/15  (143 total active threads) Queries in flight: 0 (0 queued); postgres DB 2 connections: 15/15 (30 threads blocked)
```
Application DB has free connections, but instance stopped to respond for a health check at that time.
Also, you can see in the logs the logged HTTP code is `null` for one of the requests.

paoliniluis on (2024-09-03 13:19:53 UTC): Thread dumps here
[embla2.txt](https://github.com/user-attachments/files/16849305/embla2.txt)

[justplay.txt](https://github.com/user-attachments/files/16849304/justplay.txt)
[celesdump.txt](https://github.com/user-attachments/files/16849303/celesdump.txt)

[hosting-66e45078dd42498e-7c6bdcb6d6-fbj4n.txt](https://github.com/user-attachments/files/16849302/hosting-66e45078dd42498e-7c6bdcb6d6-fbj4n.txt)

piranha on (2024-09-03 13:55:50 UTC): embla2: 50 of 141 stuck on `execute-bigquery`
justplay: 50 of 160 stuck on `execute-reducible-query`
celesdump: 46 of 149 stuck on `execute-bigquery`
hosting-66e4: kind of weird, threads are mostly parked, not really similar to previous three

I've used jstack.review to look at those.

Not sure what to make out of that, it seems like queries to the storage get stuck and are unreleased. Seems like somebody is clicking reload eagerly to see the data ASAP, but all the old queries are still there executing and so at some point Jetty just is at the limits.

My analysis could be way off.

paoliniluis on (2024-09-04 20:20:46 UTC): ok, so I think this is a combination of an edge case of what I'm going to describe below, https://github.com/metabase/metabase/issues/45571 + the fact that the queries take more time in v50 (still need to confirm that fact but all clues lead to that.

Repro:
1) set up Metabase connected to a postgres db as the DW
2) create a new sql question that does simply ""select pg_sleep(30)""
3) add the question to a dashboard like 30 times, save it
4) now duplicate the tab like 3-4 times, reload the tabs also a few times (see that the queries in flight will increase and also be queued)
5) close all tabs, see that the queries won't get cancelled, and also the queries in flight stay high

If you also add https://github.com/metabase/metabase/issues/8679 to the matter, then you have an explosive combo


Also, if you have queued queries in flight, then sync, scan, get field values, all get queued as well, adding to the combo

+1 other interesting fact: try a select 1 on the sample database (h2), you won't get anything since all threads are locked

benoittgt on (2024-12-09 12:48:23 UTC): We have the same issue with `v0.51.7.1`. It freeze completly the interface and we have to reboot if we want to fix it quickly. We can see in graph that it decrease after.

![Image](https://github.com/user-attachments/assets/4b73737c-3f51-4815-b850-008779ddd065)

![Image](https://github.com/user-attachments/assets/925751ae-8057-4d4c-b45b-3f14c9545b2c)

EDIT: I think our issue is different and simply linked to a heavy usage of Metabase with a database that was having heavy load for another part of our system.

"
2274349991,issue,closed,not_planned,Support SQLite on cloud,"**Is your feature request related to a problem? Please describe.**
I'm always frustrated when I have to set up a separate database on my own personal cloud to use Metabase's cloud option. I thought that the SQLite option might offer an easy way to pass in a file version of my database, but it is not an option on Metabase cloud. I'd like to be able to upload some files and persist them. Creating a public database on my own is a pain in the ass.

A SaaS offering that has a lot of burden to set up isn't worth it.

**Describe the solution you'd like**
Pass in a SQLite file. 

**Describe alternatives you've considered**
Maybe being able to link Google Sheets as a ""database"" or datasource?

**How important is this feature to you?**
Considering closing my Metabase Cloud account - I was hoping to use it for our public facing reports.

**Additional context**

",healthbjk,2024-05-01 23:35:44+00:00,[],2024-06-16 10:54:24+00:00,2024-06-16 10:54:24+00:00,https://github.com/metabase/metabase/issues/42135,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2090159360, 'issue_id': 2274349991, 'author': 'paoliniluis', 'body': 'Something is coming for solving this, but definitely not SQLite… we won’t spin up persistent storage for our cloud for now', 'created_at': datetime.datetime(2024, 5, 2, 10, 39, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2090957933, 'issue_id': 2274349991, 'author': 'healthbjk', 'body': '@paoliniluis thanks for the quick reply. \r\n\r\n>Something is coming for solving this\r\n\r\nMysterious haha.\r\n\r\n> definitely not SQLite\r\n\r\nNot wedded to SQLite or even persistent storage in your cloud, just an option to get something going easily without having to set up something super heavy like AWS.', 'created_at': datetime.datetime(2024, 5, 2, 16, 23, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2171431201, 'issue_id': 2274349991, 'author': 'Tony-metabase', 'body': 'Closing this https://github.com/metabase/metabase/issues/44233', 'created_at': datetime.datetime(2024, 6, 16, 10, 54, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-05-02 10:39:20 UTC): Something is coming for solving this, but definitely not SQLite… we won’t spin up persistent storage for our cloud for now

healthbjk (Issue Creator) on (2024-05-02 16:23:30 UTC): @paoliniluis thanks for the quick reply. 


Mysterious haha.


Not wedded to SQLite or even persistent storage in your cloud, just an option to get something going easily without having to set up something super heavy like AWS.

Tony-metabase on (2024-06-16 10:54:24 UTC): Closing this https://github.com/metabase/metabase/issues/44233

"
2274349642,issue,open,,Unable to Use Quoted Role Identifiers with Snowflake,"**Describe the bug**
Role identifiers are not quoted for Snowflake, which has case-sensitive object naming conventions. For example, Snowflake can have a role with the identifier ""test"" which Metabase cannot use. This is because when it runs the `use role` command in Snowflake, it will run `use role test` which does not exist since, per Snowflake docs, ""Unquoted identifiers are stored and [resolved](https://docs.snowflake.com/en/sql-reference/identifiers-syntax#label-identifier-casing) in uppercase"".

**Logs**
N/A

**To Reproduce**
Steps to reproduce the behavior:
1. Create a case-sensitive identifier in a connected snowflake instance (ex. `create role ""test"";`)
2. In Metabase, attempt to use the role ""test"". In our example, we attempted to use the role with Impersonation with `test` as a user attribute.
3. Fail to properly authenticate with the role.

**Expected behavior**
A feature flag for a Snowflake connection, similar to DB quoting behavior, that enables always-on identifier quoting for roles (either default or impersonated).

**Screenshots**
N/A

**Severity**
This is blocking our roll out of Metabase to our entire user base because it prevents RLS from working from Snowflake. Changing our permissions model is not an option due to the way we have RLS configured and working in Snowflake.

**Additional context**
N/A

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.214-202.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-22"",
      ""tag"": ""v1.49.7"",
      ""hash"": ""f0ff786""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",andresrecalde,2024-05-01 23:35:11+00:00,[],2024-05-10 22:04:16+00:00,,https://github.com/metabase/metabase/issues/42134,"[('Type:New Feature', ''), ('Database/Snowflake', ''), ('Administration/Data Sandboxes', 'Enterprise Sandboxing')]","[{'comment_id': 2089299430, 'issue_id': 2274349642, 'author': 'andresrecalde', 'body': 'Related to #27856', 'created_at': datetime.datetime(2024, 5, 1, 23, 45, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2090160800, 'issue_id': 2274349642, 'author': 'paoliniluis', 'body': 'Can you write to our support email ?', 'created_at': datetime.datetime(2024, 5, 2, 10, 39, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2099022250, 'issue_id': 2274349642, 'author': 'camsaul', 'body': 'See #34858 for context as to why it works this way', 'created_at': datetime.datetime(2024, 5, 7, 18, 9, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2105323432, 'issue_id': 2274349642, 'author': 'dpsutton', 'body': 'The thought is to add a checkbox (default to off) when entering the role to enable case sensitive role or somehow indicate that we will use quotes to pass through their value verbatim.', 'created_at': datetime.datetime(2024, 5, 10, 22, 4, 14, tzinfo=datetime.timezone.utc)}]","andresrecalde (Issue Creator) on (2024-05-01 23:45:38 UTC): Related to #27856

paoliniluis on (2024-05-02 10:39:58 UTC): Can you write to our support email ?

camsaul on (2024-05-07 18:09:45 UTC): See #34858 for context as to why it works this way

dpsutton on (2024-05-10 22:04:14 UTC): The thought is to add a checkbox (default to off) when entering the role to enable case sensitive role or somehow indicate that we will use quotes to pass through their value verbatim.

"
2274348282,issue,closed,completed,Make the sync process more efficient when reading large documents on MongoDB,"### Describe the bug

We OOM easily on big documents in MongoDB on relatively small DB's

### To Reproduce

1) spin up a MongoDB 4.4.5 (just mentioning this as the customer who hits this runs this specific MongoDB version, but it can be any). It needs to run on port 27017 with metabase as the username and metasample123 as the password
2) use this script to load a few thousand docs (like 2K docs). Run it with bun runtime for increased speed
```
const { MongoClient, ServerApiVersion } = require(""mongodb"");

const uri = ""mongodb://metabase:metasample123@localhost:27017/admin"";

const client = new MongoClient(uri);

// function to generate a random string of length n
function randomString(n) {
  const chars = ""abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"";
  let str = """";
  for (let i = 0; i < n; i++) {
    str += chars.charAt(Math.floor(Math.random() * chars.length));
  }
  return str;
}

// function to generate a very big and complex bson structure
function generateComplexBSON() {
  return {
    ""key1"": randomString(65536),
    ""key2"": randomString(65536),
    ""key3"": randomString(65536),
    ""key4"": randomString(65536),
    ""key5"": randomString(65536),
    ""key6"": randomString(65536),
    ""key7"": randomString(65536),
    ""key8"": randomString(65536),
    ""key9"": randomString(65536),
    ""key10"": randomString(65536),
    ""key11"": randomString(65536),
    ""key12"": randomString(65536),
    ""key13"": randomString(65536),
    ""key14"": randomString(65536),
    ""key15"": randomString(65536),
  };
};

async function run() {
  try {
    // Connect the client to the server (optional starting in v4.7)
    await client.connect();
    // loop a million times and create documents in the sample.people collection
    for (let i = 0; i < 1000000; i++) {
      await client.db(""sample"").collection(""people"").insertOne({
        ""id"": i + 1,
        // generate a random address key
        ""address"": ""address"" + Math.floor(Math.random() * 1000000),
        // generate a random email address key
        ""email"": ""email"" + Math.floor(Math.random() * 1000000),
        // generate a random password key
        ""password"": ""password"" + Math.floor(Math.random() * 1000000),
        // generate a random name key
        ""name"": ""name"" + Math.floor(Math.random() * 1000000),
        // generate a random phone city key
        ""phone"": ""phone"" + Math.floor(Math.random() * 1000000),
        // generate a random city key
        ""city"": ""city"" + Math.floor(Math.random() * 1000000),
        // generate a random longitude
        ""longitude"": Math.floor(Math.random() * 1000000),
        // generate a random US state
        ""state"": ""state"" + Math.floor(Math.random() * 1000000),
        // generate a random latitude
        ""latitude"": Math.floor(Math.random() * 1000000),
        // generate a random source
        ""source"": ""source"" + Math.floor(Math.random() * 1000000),
        // generate a random birth date
        ""birth_date"": new Date(),
        // generate a random zip code
        ""zip"": Math.floor(Math.random() * 1000000),
        // generate a random created at date
        ""created_at"": new Date(),
        ""description"": randomString(65536),
        // ""facts"": {
        //   ""key1"": generateComplexBSON(),
        //   ""key2"": randomString(65536),
        //   ""key3"": randomString(65536),
        //   ""key4"": randomString(65536),
        //   ""key5"": randomString(65536),
        //   ""key6"": randomString(65536),
        //   ""key7"": randomString(65536),
        //   ""key8"": randomString(65536),
        //   ""key9"": randomString(65536),
        //   ""key10"": randomString(65536),
        //   ""key11"": randomString(65536),
        //   ""key12"": randomString(65536),
        //   ""key13"": randomString(65536),
        //   ""key14"": randomString(65536),
        //   ""key15"": randomString(65536),
        // },
        ""tags"": [
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
          randomString(65536),
        ],
        ""complex"": generateComplexBSON(),
            });
      console.log(""Inserted "" + i + "" documents into the 'people' collection."");
    }
  } finally {
    // Ensures that the client will close when you finish/error
    await client.close();
  }
}
run().catch(console.dir);
```
(credits to chatgpt)

3) spin up Metabase and run it with -Xms512m -Xmx1530m, more memory is also fine, it will also blow up
4) Add the DB, it will crash with OOM

### Expected behavior

We should read documents more efficiently, I really don't know how, but there should be a way?

### Logs

```
2024-05-01 23:26:10,813 DEBUG middleware.log :: POST /api/database/4/sync_schema 200 29.1 ms (7 DB calls) App DB connections: 1/10 Jetty threads: 4/50 (6 idle, 0 queued) (70 total active threads) Queries in flight: 0 (0 queued)
2024-05-01 23:26:10,813 INFO sync.util :: STARTING: Sync metadata for mongo Database 4 ''mg''
2024-05-01 23:26:10,822 INFO sync.util :: STARTING: step ''sync-dbms-version'' for mongo Database 4 ''mg''
2024-05-01 23:26:10,823 INFO sync.util :: FINISHED: step ''sync-dbms-version'' for mongo Database 4 ''mg'' (1.1 ms)
2024-05-01 23:26:10,824 INFO sync.util :: STARTING: step ''sync-timezone'' for mongo Database 4 ''mg''
2024-05-01 23:26:10,824 INFO sync-metadata.sync-timezone :: :mongo database 4 default timezone is nil
2024-05-01 23:26:10,824 INFO sync.util :: FINISHED: step ''sync-timezone'' for mongo Database 4 ''mg'' (190.7 µs)
2024-05-01 23:26:10,824 INFO sync.util :: STARTING: step ''sync-tables'' for mongo Database 4 ''mg''
2024-05-01 23:26:10,829 INFO sync-metadata.tables :: Updating table metadata for Table 38 ''people''
2024-05-01 23:26:10,829 INFO sync.util :: FINISHED: step ''sync-tables'' for mongo Database 4 ''mg'' (5.0 ms)
2024-05-01 23:26:10,829 INFO sync.util :: STARTING: step ''sync-fields'' for mongo Database 4 ''mg''
Aborting due to java.lang.OutOfMemoryError: Java heap space
#
# A fatal error has been detected by the Java Runtime Environment:
#
#  Internal Error (debug.cpp:339), pid=1, tid=268
#  fatal error: OutOfMemory encountered: Java heap space
#
# JRE version: OpenJDK Runtime Environment Temurin-11.0.22+7 (11.0.22+7) (build 11.0.22+7)
# Java VM: OpenJDK 64-Bit Server VM Temurin-11.0.22+7 (11.0.22+7, mixed mode, tiered, compressed oops, g1 gc, linux-amd64)
# Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport -p%p -s%s -c%c -d%d -P%P -u%u -g%g -- %E"" (or dumping to //core.1)
#
# An error report file with more information is saved as:
# /tmp/hs_err_pid1.log

```

### Information about your Metabase installation

```JSON
v49.7
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-05-01 23:33:20+00:00,['qnkhuat'],2024-05-08 19:46:35+00:00,2024-05-02 12:15:54+00:00,https://github.com/metabase/metabase/issues/42133,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]",[],
2274325672,issue,closed,completed,[BE] [QP] [Bug] Incorrect metadata for a native model column overriden to a FK,"`should allow drills on FK columns from dashboards` E2E test fails because there is a mismatch between metadata in `/api/table/card__:id/query_metadata` and `/api/card/:id`. [Run link](https://app.replay.io/team/dzoyNTM4ZjRmOC05YmFlLTRiYjYtYjljYi1jOGYzOWUyMjRhZWY=/runs?testRunId=626f055a-eefb-4146-96b5-140dc39cf2ff&testId=dHJ0OjliZDEzY2U0NjhiZjU4ZTlkNDkyYmZjMWFiYWE1Y2JkMTBjMDhhN2U%3D)

<img width=""691"" alt=""Screenshot 2024-05-01 at 15 40 25"" src=""https://github.com/metabase/metabase/assets/8542534/25c741fa-96f3-483f-9d2d-3f337c9e8d7c"">
<img width=""706"" alt=""Screenshot 2024-05-01 at 15 40 36"" src=""https://github.com/metabase/metabase/assets/8542534/4541fd4d-fa6f-4f16-83c8-a57df2a4c902"">

Actual:
- `semantic_type` of the overriden field in `query_metadata` is null but `type/FK` in `/api/card/:id`

Expected:
- `semantic_type` is the same in both endpoints - `type/FK` in this case

The issue is present in `master`, but since we moved some stuff to MBQL lib it started to cause issues because of https://github.com/metabase/metabase/blob/0633cd87702d085791aa73efd4a12b3a96127673/src/metabase/lib/card.cljc#L107",ranquild,2024-05-01 23:07:20+00:00,['metamben'],2024-05-20 12:27:13+00:00,2024-05-20 12:27:13+00:00,https://github.com/metabase/metabase/issues/42130,[],[],
2274296083,issue,open,,"Add ""CPF Franc"" to currency list","My organization stands in New Caledonia and our currency is the ""CFP Franc"". Would it be possible to integrate it in your currency system ?
Thank you.",Pierre-PSUD,2024-05-01 22:31:45+00:00,[],2025-02-04 20:31:09+00:00,,https://github.com/metabase/metabase/issues/42129,"[('Type:New Feature', ''), ('Administration/Table Metadata', ''), ('Customization/i18n', ''), ('Customization/Formatting', ''), ('Semantic Model', ''), ('Semantic Model/Dimensions', ''), ('Semantic Model/Units', '')]",[],
2274190884,issue,closed,completed,[Epic] Let time granularity be parameterized for MBQL questions,"**Links**
- [product doc](https://www.notion.so/metabase/Let-time-granularity-be-parametrized-41a26d41cc414806b92929e0e4c859a6)
- [eng doc](https://www.notion.so/metabase/Tech-Let-time-granularity-be-parametrized-for-MBQL-questions-0e14410d4d90478481be6412fb473914)
- No feature branch yet; early QP features can land in master.
- issue links:
    - #6583 

**Implementation Plan**


***Milestone 1: Core functionality***

```[tasklist]
- [x] BE: Expand `:type :temporal-unit` parameters when running a query #42116
- [x] BE: Support saving and returning `:type :temporal-unit` parameters and mappings #42119
- [ ] https://github.com/metabase/metabase/pull/43212
- [ ] https://github.com/metabase/metabase/issues/43599
```

***Milestone 2: Allowlist of temporal units***

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/43967
- [ ] https://github.com/metabase/metabase/pull/44061
- [ ] https://github.com/metabase/metabase/issues/44361
```

***Bugs***
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/46069
- [ ] https://github.com/metabase/metabase/issues/44684
- [ ] https://github.com/metabase/metabase/issues/46068
- [ ] https://github.com/metabase/metabase/pull/46983
```",bshepherdson,2024-05-01 20:57:52+00:00,"['bshepherdson', 'ranquild']",2024-10-08 16:17:07+00:00,2024-08-20 11:49:11+00:00,https://github.com/metabase/metabase/issues/42118,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2274002592,issue,closed,completed,Truncate columns to 32767 chars on xlsx exports to avoid errors,"### Describe the bug

In https://support.microsoft.com/en-us/office/excel-specifications-and-limits-1672b34d-7043-467e-8e27-269d656771c3 MSFT says that ""Total number of characters that a cell can contain"" is 32,767 characters and we don´t respect that. We should truncate cells to avoid that

### To Reproduce

1) make a field with a long long long text
2) export it to xlsx
3) try to open it
4) see the error

### Expected behavior

We should truncate the cells

### Logs

```
{""database_id"":34,""started_at"":""2024-05-01T15:22:36.201995Z"",""via"":[{""status"":""failed"",""class"":""class clojure.lang.ExceptionInfo"",""error"":""Error reducing result rows: The maximum length of cell contents (text) is 32767 characters"",""stacktrace"":[""--> query_processor.context.default$default_reducef$fn__50537.invoke(default.clj:36)"",""query_processor.context.default$default_reducef.invokeStatic(default.clj:33)"",""query_processor.context.default$default_reducef.invoke(default.clj:25)"",""query_processor.context$reducef.invokeStatic(context.clj:70)"",""query_processor.context$reducef.invoke(context.clj:63)"",""query_processor.context.default$default_runf$respond_STAR___50541.invoke(default.clj:45)"",""driver.sql_jdbc.execute$execute_reducible_query$fn__79421.invoke(execute.clj:710)"",""driver.sql_jdbc.execute$fn__79214$fn__79215.invoke(execute.clj:389)"",""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)"",""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)"",""driver.sql_jdbc.execute$fn__79214.invokeStatic(execute.clj:383)"",""driver.sql_jdbc.execute$fn__79214.invoke(execute.clj:381)"",""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)"",""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)"",""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)"",""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)"",""driver.sql_jdbc$fn__112725.invokeStatic(sql_jdbc.clj:78)"",""driver.sql_jdbc$fn__112725.invoke(sql_jdbc.clj:76)"",""query_processor.context$executef.invokeStatic(context.clj:60)"",""query_processor.context$executef.invoke(context.clj:49)"",""query_processor.context.default$default_runf.invokeStatic(default.clj:44)"",""query_processor.context.default$default_runf.invoke(default.clj:42)"",""query_processor.context$runf.invokeStatic(context.clj:46)"",""query_processor.context$runf.invoke(context.clj:40)"",""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)"",""query_processor.reducible$identity_qp.invoke(reducible.clj:36)"",""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72244.invoke(cache.clj:229)"",""query_processor.middleware.permissions$check_query_permissions$fn__66601.invoke(permissions.clj:140)"",""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72065.invoke(enterprise.clj:51)"",""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72075.invoke(enterprise.clj:64)"",""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71507.invoke(mbql_to_native.clj:24)"",""query_processor$fn__73412$combined_post_process__73417$combined_post_process_STAR___73418.invoke(query_processor.clj:262)"",""query_processor$fn__73412$combined_pre_process__73413$combined_pre_process_STAR___73414.invoke(query_processor.clj:259)"",""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66698.invoke(fetch_source_query.clj:299)"",""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72155$fn__72159.invoke(resolve_database_and_driver.clj:77)"",""driver$do_with_driver.invokeStatic(driver.clj:97)"",""driver$do_with_driver.invoke(driver.clj:92)"",""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72155.invoke(resolve_database_and_driver.clj:76)"",""query_processor.middleware.store$initialize_store$fn__67325$fn__67326.invoke(store.clj:14)"",""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)"",""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"",""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)"",""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"",""query_processor.middleware.store$initialize_store$fn__67325.invoke(store.clj:13)"",""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72152.invoke(resolve_database_and_driver.clj:60)"",""query_processor.middleware.normalize_query$normalize$fn__72457.invoke(normalize_query.clj:38)"",""query_processor.middleware.enterprise$fn__72092$handle_audit_app_internal_queries__72093$fn__72095.invoke(enterprise.clj:96)"",""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72103.invoke(enterprise.clj:103)"",""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71218.invoke(constraints.clj:104)"",""query_processor.middleware.process_userland_query$process_userland_query$fn__72388.invoke(process_userland_query.clj:156)"",""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72989.invoke(catch_exceptions.clj:171)"",""query_processor.reducible$async_qp$qp_STAR___62839$thunk__62841.invoke(reducible.clj:126)"",""query_processor.reducible$async_qp$qp_STAR___62839$fn__62843.invoke(reducible.clj:131)""],""error_type"":""qp"",""ex-data"":{""type"":""qp""}}],""action_id"":null,""error_type"":""qp"",""json_query"":{""constraints"":null,""type"":""query"",""middleware"":{""js-int-to-string?"":false,""ignore-cached-results?"":true,""process-viz-settings?"":true,""skip-results-metadata?"":true,""format-rows?"":false},""viz-settings"":null,""database"":34,""query
```

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P3

### Additional context

NA",paoliniluis,2024-05-01 18:50:01+00:00,[],2025-01-24 22:58:34+00:00,2025-01-24 21:46:26+00:00,https://github.com/metabase/metabase/issues/42115,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2179708830, 'issue_id': 2274002592, 'author': 'notrom', 'body': 'Just stumbled into this one on 0.49.7. It produces an Excel file with no complaints on the front end but Excel refuses to open it. I get the same error as originally reported.\r\n\r\nIt would be great if the export error could be shown on the frontend so the user knows not to rely on the file they just exported.', 'created_at': datetime.datetime(2024, 6, 20, 2, 43, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293696034, 'issue_id': 2274002592, 'author': 'emanueloliveira23', 'body': ""I had the same issue. However, this limitation does not apply on exporting on question editor. For me, this limitation only happens inside a dashboard.\r\n\r\n@paoliniluis good to know that's is the limitation size. Thanks."", 'created_at': datetime.datetime(2024, 8, 16, 15, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567627522, 'issue_id': 2274002592, 'author': 'givemesomefaces', 'body': 'Should a text prompt saying ""Long texts will be truncated"" be added when the export button is clicked on the front-end page to tell users? Because the truncation during the back-end export has led to the inconsistent display between the front-end and the back-end.', 'created_at': datetime.datetime(2025, 1, 2, 11, 24, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567694839, 'issue_id': 2274002592, 'author': 'paoliniluis', 'body': ""I think it makes sense, but we can leave that for a second pass @givemesomefaces (don't think that everyone that uses Metabase has those massive texts on db's...)"", 'created_at': datetime.datetime(2025, 1, 2, 12, 22, 3, tzinfo=datetime.timezone.utc)}]","notrom on (2024-06-20 02:43:40 UTC): Just stumbled into this one on 0.49.7. It produces an Excel file with no complaints on the front end but Excel refuses to open it. I get the same error as originally reported.

It would be great if the export error could be shown on the frontend so the user knows not to rely on the file they just exported.

emanueloliveira23 on (2024-08-16 15:15:00 UTC): I had the same issue. However, this limitation does not apply on exporting on question editor. For me, this limitation only happens inside a dashboard.

@paoliniluis good to know that's is the limitation size. Thanks.

givemesomefaces on (2025-01-02 11:24:59 UTC): Should a text prompt saying ""Long texts will be truncated"" be added when the export button is clicked on the front-end page to tell users? Because the truncation during the back-end export has led to the inconsistent display between the front-end and the back-end.

paoliniluis (Issue Creator) on (2025-01-02 12:22:03 UTC): I think it makes sense, but we can leave that for a second pass @givemesomefaces (don't think that everyone that uses Metabase has those massive texts on db's...)

"
2273974928,issue,closed,completed,[dc.js migration] Tooltip position sometimes is not correct,"Details: [comment](https://github.com/metabase/metabase/issues/42114#issuecomment-2116433369)

---
https://metaboat.slack.com/archives/C01LQQ2UW03/p1714587141945559",alxnddr,2024-05-01 18:31:47+00:00,[],2024-10-08 16:17:15+00:00,2024-08-16 15:39:08+00:00,https://github.com/metabase/metabase/issues/42114,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2116433369, 'issue_id': 2273974928, 'author': 'JesseSDevaney', 'body': ""**Discussion of Issue**\r\n\r\nhttps://github.com/metabase/metabase/assets/22608765/b217768f-8b27-4c50-bbda-aa212f6acd1c\r\n\r\n---\r\n**Too Long, Didn't watch**\r\nInvestigated the issue and determined that the ECharts data sent by the ECharts events is correct, but that the DOM element it returns as the target, does not always correspond to the correct ECharts element.\r\n\r\nThis is occurring because some painted ECharts elements have invisible areas painted on top of those elements. When hovering those elements, it passes the invisible area as the target element instead of the corresponding ECharts element.\r\n\r\nThere are solutions to fix these individual tool-tip issues, but then it breaks other parts of the application, so those are not viable.\r\n\r\nIt appears that the only long-term, viable, and stable solution would be to switch to the native ECharts tooltip.\r\n\r\n---\r\n- For More Updates: https://metaboat.slack.com/archives/C05NQSWPRMK/p1715906639874699"", 'created_at': datetime.datetime(2024, 5, 17, 0, 43, 52, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-05-17 00:43:52 UTC): **Discussion of Issue**

https://github.com/metabase/metabase/assets/22608765/b217768f-8b27-4c50-bbda-aa212f6acd1c

---
**Too Long, Didn't watch**
Investigated the issue and determined that the ECharts data sent by the ECharts events is correct, but that the DOM element it returns as the target, does not always correspond to the correct ECharts element.

This is occurring because some painted ECharts elements have invisible areas painted on top of those elements. When hovering those elements, it passes the invisible area as the target element instead of the corresponding ECharts element.

There are solutions to fix these individual tool-tip issues, but then it breaks other parts of the application, so those are not viable.

It appears that the only long-term, viable, and stable solution would be to switch to the native ECharts tooltip.

---
- For More Updates: https://metaboat.slack.com/archives/C05NQSWPRMK/p1715906639874699

"
2273534136,issue,closed,completed,drop a function and test for `isDashboardParameterWithoutMapping` as not used,,uladzimirdev,2024-05-01 13:40:58+00:00,['uladzimirdev'],2024-05-02 14:59:17+00:00,2024-05-02 14:59:17+00:00,https://github.com/metabase/metabase/issues/42105,[],"[{'comment_id': 2090747187, 'issue_id': 2273534136, 'author': 'uladzimirdev', 'body': 'Fixed by https://github.com/metabase/metabase/pull/42103', 'created_at': datetime.datetime(2024, 5, 2, 14, 59, 17, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-05-02 14:59:17 UTC): Fixed by https://github.com/metabase/metabase/pull/42103

"
2273533753,issue,closed,completed,fix typo in RequierParamToggle,,uladzimirdev,2024-05-01 13:40:51+00:00,['uladzimirdev'],2024-05-02 14:59:00+00:00,2024-05-02 14:59:00+00:00,https://github.com/metabase/metabase/issues/42104,[],"[{'comment_id': 2090745983, 'issue_id': 2273533753, 'author': 'uladzimirdev', 'body': 'Fixed by https://github.com/metabase/metabase/pull/42102', 'created_at': datetime.datetime(2024, 5, 2, 14, 58, 58, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-05-02 14:58:58 UTC): Fixed by https://github.com/metabase/metabase/pull/42102

"
2273458436,issue,closed,not_planned,BE: Accept multiple arguments to `:contains` etc. and compile them correctly,,bshepherdson,2024-05-01 12:53:35+00:00,[],2024-05-01 12:54:38+00:00,2024-05-01 12:54:38+00:00,https://github.com/metabase/metabase/issues/42100,[],"[{'comment_id': 2088424166, 'issue_id': 2273458436, 'author': 'bshepherdson', 'body': 'Accidentally created.', 'created_at': datetime.datetime(2024, 5, 1, 12, 54, 38, tzinfo=datetime.timezone.utc)}]","bshepherdson (Issue Creator) on (2024-05-01 12:54:38 UTC): Accidentally created.

"
2273377147,issue,closed,completed,Investigate `orderd_card` typo in Automagic Dashboards,`automagic-dashboards.filters/add-filters` has had the misspelled `:orderd_cards` in it since 2018. This would presumably evaluate to `nil` and be treated as an empty sequence—investigate why it isn't causing problems,tsmacdonald,2024-05-01 11:46:10+00:00,['tsmacdonald'],2024-05-07 07:26:58+00:00,2024-05-07 07:26:58+00:00,https://github.com/metabase/metabase/issues/42099,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/X-rays', '')]",[],
2273299925,issue,closed,completed,Add test to extract column tests for URL and email columns,Add tests for URL and email columns in the extract header action in chill mode.,romeovs,2024-05-01 10:34:27+00:00,['romeovs'],2024-05-03 08:55:49+00:00,2024-05-03 06:48:29+00:00,https://github.com/metabase/metabase/issues/42096,"[('.Team/Querying', '')]",[],
2273282237,issue,closed,completed,Add analytics events for extract via column header,Add an analytics event when a column gets extracted via the expression shortcut editor.,romeovs,2024-05-01 10:18:11+00:00,['romeovs'],2024-05-03 11:41:01+00:00,2024-05-03 06:50:31+00:00,https://github.com/metabase/metabase/issues/42093,[],"[{'comment_id': 2091159160, 'issue_id': 2273282237, 'author': 'romeovs', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/41353', 'created_at': datetime.datetime(2024, 5, 2, 17, 47, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2092408313, 'issue_id': 2273282237, 'author': 'romeovs', 'body': 'Closed by https://github.com/metabase/metabase/pull/41774', 'created_at': datetime.datetime(2024, 5, 3, 6, 50, 31, tzinfo=datetime.timezone.utc)}]","romeovs (Issue Creator) on (2024-05-02 17:47:03 UTC): Duplicate of https://github.com/metabase/metabase/issues/41353

romeovs (Issue Creator) on (2024-05-03 06:50:31 UTC): Closed by https://github.com/metabase/metabase/pull/41774

"
