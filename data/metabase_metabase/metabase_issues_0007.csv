id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2405788949,issue,open,,Font doesn't get updated in the first try,"### Describe the bug

When trying to change the font type on the Appearance tab, the font is not updated unless you do the change 2 times. 

https://www.loom.com/share/22f9322395f040b59ce5691454f958bb?sid=de0b9e49-b6ce-4468-82cd-8d0f22e94e93

### To Reproduce

1. Go to Admin Settings > Settings > Appearance > Font
2. Click on the Font of your choice
3. The font won't be updated 
4. Select another font 
5. The first font you chose would be applied and the second font change would be ignored. 


### Expected behavior

The font you choose should be applied in the first attempt

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version v1.50.7
```


### Severity

P3

### Additional context

_No response_",psalinasy,2024-07-12 14:48:40+00:00,[],2024-07-15 21:24:07+00:00,,https://github.com/metabase/metabase/issues/45486,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Whitelabel', 'Enterprise white labelling'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2405669393,issue,closed,completed,Fix table crash when going from normal to pivot mode,"### Describe the bug

https://metaboat.slack.com/archives/C05MPF0TM3L/p1720460335669239

### To Reproduce

1. New -> Question -> Orders
2. Visualize
3. Notebook -> Summarize -> Count, Group by User ID, Product -> Category
4. Visualize
5. See the viz crashed

### Expected behavior

The viz should not crash

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-07-12 13:53:56+00:00,['ranquild'],2024-07-15 21:01:06+00:00,2024-07-12 19:16:24+00:00,https://github.com/metabase/metabase/issues/45481,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2229427222, 'issue_id': 2405669393, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 1, 5, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-15 21:01:05 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2405392652,issue,open,,Filter search results flicker,"### Describe the bug

https://github.com/user-attachments/assets/f24d417b-3bd8-4bac-84d4-1b131288a5bd


### To Reproduce

1. Open Table Metadata -> `Orders.Product ID` -> Click `Use original value` -> `Use foreign key` -> Select `Products.Title`.
2. Set `Filtering on this field` to `A list of all values`
3. Open `Orders` table. Click on `Product ID` -> Filter on this column. 
4. Type ""o"", wait for results to load
5. Hit backspace, type ""p"" - notice results will flicker when they load 


### Information about your Metabase installation

master, 53955c281e

### Severity

P3

### Additional context

Originally reported here: https://github.com/metabase/metabase/pull/45047#discussion_r1675419310",kamilmielnik,2024-07-12 11:47:08+00:00,[],2025-02-04 20:27:32+00:00,,https://github.com/metabase/metabase/issues/45473,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]",[],
2405380496,issue,closed,completed,Use in-memory failure map to avoid endless retries,"Add a map of `{card-id retries-remaining}` in an atom.

- In the Analyzer
  - Update with `(fnil dec max-retries)` when there's an exception analyzing a card. 
  - Dissoc this entry when we successfully parse a card.
- In the Sweeper
  - Skip enqueuing these records if there's a zero entry.
  It's OK for the reducible select to fetch them as that's cheaper than sending a potentially massive exclusion list in the query.",crisptrutski,2024-07-12 11:40:39+00:00,[],2024-10-08 16:20:22+00:00,2024-07-18 20:13:59+00:00,https://github.com/metabase/metabase/issues/45471,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2229013329, 'issue_id': 2405380496, 'author': 'crisptrutski', 'body': ""We can use a LRU cache from `clojure.core.cache` as our map to keep it bounded.\r\n\r\nI think it's something like this:\r\n\r\n```clojure\r\n(defonce ^:private cache-atom (atom (cache/lru-cache-factory {} :threshold 10000)))\r\n\r\n(defn track-failure! [card-id]\r\n  (swap! cache-atom cache/miss card-id\r\n         ((fnil dec max-retries)\r\n          (cache/lookup cache-atom card-id))))\r\n\r\n(defn track-success! [card-id]\r\n  (swap! cache-atom cache/evict card-id))\r\n```"", 'created_at': datetime.datetime(2024, 7, 15, 17, 19, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229042377, 'issue_id': 2405380496, 'author': 'crisptrutski', 'body': ""I think we actually want LIFO semantics, which aren't found in core.cached. To keep things simple, a `ConcurrentHashMap` with a `.size` check is probably good enough."", 'created_at': datetime.datetime(2024, 7, 15, 17, 37, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236262225, 'issue_id': 2405380496, 'author': 'crisptrutski', 'body': 'Decided to put the skip logic in the analyzer as well, this feels tighter.', 'created_at': datetime.datetime(2024, 7, 18, 11, 24, 42, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-15 17:19:55 UTC): We can use a LRU cache from `clojure.core.cache` as our map to keep it bounded.

I think it's something like this:

```clojure
(defonce ^:private cache-atom (atom (cache/lru-cache-factory {} :threshold 10000)))

(defn track-failure! [card-id]
  (swap! cache-atom cache/miss card-id
         ((fnil dec max-retries)
          (cache/lookup cache-atom card-id))))

(defn track-success! [card-id]
  (swap! cache-atom cache/evict card-id))
```

crisptrutski (Issue Creator) on (2024-07-15 17:37:04 UTC): I think we actually want LIFO semantics, which aren't found in core.cached. To keep things simple, a `ConcurrentHashMap` with a `.size` check is probably good enough.

crisptrutski (Issue Creator) on (2024-07-18 11:24:42 UTC): Decided to put the skip logic in the analyzer as well, this feels tighter.

"
2405355474,issue,closed,not_planned,Delete obsolete SQL backfill job code,,crisptrutski,2024-07-12 11:26:43+00:00,[],2024-07-12 11:39:41+00:00,2024-07-12 11:39:41+00:00,https://github.com/metabase/metabase/issues/45470,[],"[{'comment_id': 2225391413, 'issue_id': 2405355474, 'author': 'crisptrutski', 'body': ""Oh wow, there's so little code, and we might as well just rename the namespace and use quartz for the sweeper."", 'created_at': datetime.datetime(2024, 7, 12, 11, 39, 33, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-12 11:39:33 UTC): Oh wow, there's so little code, and we might as well just rename the namespace and use quartz for the sweeper.

"
2405352518,issue,closed,completed,Command palette covered by data picker,"### Describe the bug


https://github.com/user-attachments/assets/bc8f1de9-b0fd-4467-a378-2da58f7545a4



### To Reproduce

1. New > Question
2. Hit Ctrl + K

Command palette is opened behind the data picker

### Expected behavior

Command palette should open on top of the data picker


### Information about your Metabase installation

master, 250453b


### Severity

P3
",kamilmielnik,2024-07-12 11:24:45+00:00,['rafpaf'],2024-11-08 14:56:44+00:00,2024-11-01 16:25:20+00:00,https://github.com/metabase/metabase/issues/45469,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2225368433, 'issue_id': 2405352518, 'author': 'kamilmielnik', 'body': 'Similar to #45468', 'created_at': datetime.datetime(2024, 7, 12, 11, 25, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232650222, 'issue_id': 2405352518, 'author': 'kamilmielnik', 'body': 'Another scenario:\r\n\r\n1. New > Model > Notebook editor\r\n2. Hit browser back button\r\n\r\n""Discard your changes?"" modal is displayed behind the data picker modal', 'created_at': datetime.datetime(2024, 7, 17, 7, 45, 45, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-12 11:25:08 UTC): Similar to #45468

kamilmielnik (Issue Creator) on (2024-07-17 07:45:45 UTC): Another scenario:

1. New > Model > Notebook editor
2. Hit browser back button

""Discard your changes?"" modal is displayed behind the data picker modal

"
2405349035,issue,closed,completed,Some dropdowns appear on top of command palette modal backdrop,"### Describe the bug

![image](https://github.com/user-attachments/assets/397e74b3-1586-4514-a20a-c4042df66bba)


### To Reproduce

1. New question > Orders > Visualize
2. Click on '...' button
3. Hit Ctrl + K

Dropdown from ""..."" button is displayed on top of command palette modal backdrop

### Information about your Metabase installation

master, 250453b5e1


### Severity

P3
",kamilmielnik,2024-07-12 11:22:30+00:00,[],2025-01-27 22:13:09+00:00,2024-12-17 17:48:16+00:00,https://github.com/metabase/metabase/issues/45468,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2225368501, 'issue_id': 2405349035, 'author': 'kamilmielnik', 'body': 'Similar to #45469', 'created_at': datetime.datetime(2024, 7, 12, 11, 25, 12, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-12 11:25:12 UTC): Similar to #45469

"
2405319905,issue,closed,completed,Implement SQL Analysis Sweeper worker,"Add an always running background thread which works its way over all cards with missing or stale analysis, and synchronously offers them to the SQL Analysis queue.

There should be a feature flag controlling whether we start this worker or not.",crisptrutski,2024-07-12 11:05:07+00:00,[],2024-10-08 16:20:25+00:00,2024-07-18 11:15:11+00:00,https://github.com/metabase/metabase/issues/45464,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2225890507, 'issue_id': 2405319905, 'author': 'crisptrutski', 'body': ""Going to actually repurpose the existing job here, but make it non-concurrent and rescheduled. Then it's just a matter of replacing the reducing function and tweaking the query."", 'created_at': datetime.datetime(2024, 7, 12, 16, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231386845, 'issue_id': 2405319905, 'author': 'crisptrutski', 'body': ""This is partially done, by simply repurposed the backfill. I've left the name as is for now, but will revisit that once it covers stale records and deletes obsolete ones."", 'created_at': datetime.datetime(2024, 7, 16, 16, 48, 50, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-12 16:04:00 UTC): Going to actually repurpose the existing job here, but make it non-concurrent and rescheduled. Then it's just a matter of replacing the reducing function and tweaking the query.

crisptrutski (Issue Creator) on (2024-07-16 16:48:50 UTC): This is partially done, by simply repurposed the backfill. I've left the name as is for now, but will revisit that once it covers stale records and deletes obsolete ones.

"
2405317913,issue,closed,completed,Update Card modification hooks to use SQL Analysis queue,"Instead of directly calling `update-query-fields-for-card!` in the `after-insert` and `after-update` hooks, just enqueue it. 

This enqueue method should probably we smart and skip enqueuing if the relevant feature flag is disabled. We can probably remove checking the flag in the Analyzer then.",crisptrutski,2024-07-12 11:04:10+00:00,[],2024-10-08 17:02:07+00:00,2024-07-16 16:46:48+00:00,https://github.com/metabase/metabase/issues/45463,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2225887026, 'issue_id': 2405317913, 'author': 'crisptrutski', 'body': 'The main work here is going to be updating the tests that assume this is synchronous to manually running a step of the analyzer.', 'created_at': datetime.datetime(2024, 7, 12, 16, 2, 5, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-12 16:02:05 UTC): The main work here is going to be updating the tests that assume this is synchronous to manually running a step of the analyzer.

"
2405317599,issue,closed,completed,Implement SQL Analyzer worker,"Add an always-running background thread, which reads Card ids off a queue, and executes `query-field/update-query-fields-for-card!`.

While we are here, move this mutating method to a new namespace which can group the other kinds of models we will use for result columns and source tables.

We also want to introduce a feature flag to skip analysis for MBQL queries. Move this feature check up a level into `query-field-ids` as well, and clean up the tests.
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/45483
- [ ] https://github.com/metabase/metabase/pull/45543
- [ ] https://github.com/metabase/metabase/pull/45549
```
",crisptrutski,2024-07-12 11:04:01+00:00,['crisptrutski'],2024-07-30 20:19:42+00:00,2024-07-16 16:46:48+00:00,https://github.com/metabase/metabase/issues/45462,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2225893888, 'issue_id': 2405317599, 'author': 'crisptrutski', 'body': 'Going to use Quartz to run the consumer, that way we get supervision for free.', 'created_at': datetime.datetime(2024, 7, 12, 16, 5, 54, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-12 16:05:54 UTC): Going to use Quartz to run the consumer, that way we get supervision for free.

"
2405317461,issue,closed,completed,Add bounded transaction queue for SQL Analysis,Implement a queue that allows both synchronous and asynchronous delivery of messages. This will be used to schedule SQL analysis where it is missing or stale.,crisptrutski,2024-07-12 11:03:58+00:00,['crisptrutski'],2024-07-15 20:58:54+00:00,2024-07-12 11:09:06+00:00,https://github.com/metabase/metabase/issues/45461,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2229422787, 'issue_id': 2405317461, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 58, 53, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-15 20:58:53 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2405308984,issue,closed,completed,[ParseSQL] Rate limited Query Analysis ,"## Description

This work stream involves re-working the way that Query Analysis is scheduled, to ensure that we reach complete coverage without causing undue load on the Metabase instance(s). 

**Links**
- product doc: N/A (see [postmortem](https://www.notion.so/metabase/v50-Up-to-50k-minute-log-lines-with-SQL-Parser-errors-c699c635a4c243a8a9f298ce725c7964))
- eng docs:
  - [Robust SQL Parser Analysis](https://www.notion.so/metabase/Robust-backfill-for-the-SQL-Parser-16fd98ea45794300812c134197caef25)
  - [Reduced scope version](https://www.notion.so/metabase/Minimal-SQL-Analysis-Scheduling-ab8b5a63c1dc4fa3b820173b0cd9fe75)
- feature branch: Work will be done in master.

**Implementation Plan**

```[tasklist]
### Milestone 1 - bound realtime work
- [ ] https://github.com/metabase/metabase/issues/45461
- [ ] https://github.com/metabase/metabase/issues/45462
- [ ] https://github.com/metabase/metabase/issues/45463
```

```[tasklist]
### Milestone 2 - backfill safely
- [ ] https://github.com/metabase/metabase/issues/45464
- [ ] https://github.com/metabase/metabase/issues/45470
- [ ] https://github.com/metabase/metabase/issues/45471
- [ ] https://github.com/metabase/metabase/issues/45720
```

```[tasklist]
### Testing
- [x] Hook versus Sweeper race test
- [x] Manual Testing - hook only
- [x] Manual Testing - create, update, delete
- [x] Component tests
- [x] ~~End-to-end test~~ Will write a larger test that includes the validator tool
- [x] Cloud instance backfill
- [x] Local stress test
```
",crisptrutski,2024-07-12 10:59:02+00:00,['crisptrutski'],2024-08-08 14:52:35+00:00,2024-08-08 14:52:35+00:00,https://github.com/metabase/metabase/issues/45460,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2247815783, 'issue_id': 2405308984, 'author': 'crisptrutski', 'body': 'Moved Milestone 3 to a separate [Epic](https://github.com/metabase/metabase/issues/46051)', 'created_at': datetime.datetime(2024, 7, 24, 12, 41, 45, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-07-24 12:41:45 UTC): Moved Milestone 3 to a separate [Epic](https://github.com/metabase/metabase/issues/46051)

"
2405303746,issue,closed,completed,API Keys can access/query Dashboards/Cards of No-Access Collections,"### Describe the bug

Through the usage of the /api endpoint, an API key, created for Group X, can access card queries in collections where that group has no view permission (permission No Access)

### To Reproduce

1. Create a Group (Group X)
2. Create a collection and set the permissions for Group X to ""No Access""
3. Add a dashboard/card to this collection
4. Create an API Key for Group X
5. Query `/api/dashboard/<dashboard-id>` or `/api/card/<card-id>/query` and receive data


### Expected behavior

The api request should respect the permissions of the card/dashboard it queries and return Permission-Denied if the group for that key is not allowed to view the card/dashboard/collection

### Logs

[2c7a2cb5-aebf-4c1a-9e9c-835d2d9c5e5a] 2024-07-12T12:54:08+02:00 INFO metabase.query-processor.middleware.cache Query bf4c9284 took 433.0 ms to run; minimum for cache eligibility is 1000.0 Âµs; eligible
[2c7a2cb5-aebf-4c1a-9e9c-835d2d9c5e5a] 2024-07-12T12:54:08+02:00 INFO metabase.query-processor.middleware.cache Caching results for next time for query with hash ""bf4c9284"". ðŸ’¾
[2c7a2cb5-aebf-4c1a-9e9c-835d2d9c5e5a] 2024-07-12T12:54:08+02:00 DEBUG metabase.server.middleware.log POST /api/card/874/query 202 [ASYNC: completed] 729.7 ms (31 DB calls) App DB connections: 1/13 Jetty threads: 4/50 (2 idle, 0 queued) (108 total active threads) Queries in flight: 0 (0 queued); mysql DB 5 connections: 0/1 (0 threads blocked) {:metabase-user-id 112}

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-91-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.34""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v0.50.11"",
      ""hash"": ""e08c1fb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Medium

### Additional context

I am not sure if this is a bug/security vulnerability or feature request - please modify the tag as applicable!",Nexxurs,2024-07-12 10:55:51+00:00,[],2024-07-12 13:06:06+00:00,2024-07-12 13:06:06+00:00,https://github.com/metabase/metabase/issues/45458,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2225509319, 'issue_id': 2405303746, 'author': 'noahmoss', 'body': ""@Nexxurs I'm not able to reproduce. Are you certain that the API key is created in the correct group? And can you double check the permissions for that group, as well as the permissions for the All Users group?\r\n\r\nTo be clear, `All Users` access will override other groups if it's set to `View` or `Curate`. (See the [collection permissions](https://www.metabase.com/docs/latest/permissions/collections.html) docs)"", 'created_at': datetime.datetime(2024, 7, 12, 12, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225552318, 'issue_id': 2405303746, 'author': 'Nexxurs', 'body': 'Hey @noahmoss!\r\n\r\nSorry, this was my mistake - I accidently synced my browser cookies with Postman when sending those requests, so the queries were executed within session permission scope instead of the API one. \r\n\r\nI will close this issue again - thanks for the support!', 'created_at': datetime.datetime(2024, 7, 12, 13, 6, 6, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-07-12 12:48:50 UTC): @Nexxurs I'm not able to reproduce. Are you certain that the API key is created in the correct group? And can you double check the permissions for that group, as well as the permissions for the All Users group?

To be clear, `All Users` access will override other groups if it's set to `View` or `Curate`. (See the [collection permissions](https://www.metabase.com/docs/latest/permissions/collections.html) docs)

Nexxurs (Issue Creator) on (2024-07-12 13:06:06 UTC): Hey @noahmoss!

Sorry, this was my mistake - I accidently synced my browser cookies with Postman when sending those requests, so the queries were executed within session permission scope instead of the API one. 

I will close this issue again - thanks for the support!

"
2405159464,issue,closed,completed,Visualisation doesn't render properly. I see `ResizeObserver loop completed with undelivered notifications.` error in browser console,"### Describe the bug

I have a pretty straightforward visualisation. Like this.
<img width=""1229"" alt=""image"" src=""https://github.com/user-attachments/assets/8b35390f-daea-4b17-943e-da03f2cfeaa9"">

Below is the last part of the question (this is when things work fine)
<img width=""1398"" alt=""image"" src=""https://github.com/user-attachments/assets/47548c94-9648-41ab-9771-20eeaa06399a"">


Now, Say I further want to filter out dataset (count ) and only visualise count's which are > 10, then I get a rendering issue. Attaching the video.


https://github.com/user-attachments/assets/028c8783-ea7a-4c03-8647-45e747ab52fe

When problem happens, the question is like this:

<img width=""1413"" alt=""image"" src=""https://github.com/user-attachments/assets/28cc7074-4d10-43dc-8e8a-f07f66010c38"">


### To Reproduce

1. Create a question (say sales orders) when you plot data grouped by (say city) and then further group by dates.
2. See that visualisation is working fine. Graph comes up correctly grouped by count, cities and plotted against dates (say day wise).
3. Then Edit the question to further add a condition: Visualise the data where count > 10 and click visualise.
4. See that answer loads and then UI goes in resize loop. and graph doesn't render properly.

### Expected behavior

Graph should hold good, as it was when we rendered it at step 2.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser Safari (Version 17.5 (19618.2.12.11.6))
- Metabase hosted on Ubuntu 22.04 (running latest as of today)
- Database postgresql 14
- JDK: OpenJDK Runtime Environment Corretto-11.0.23.9.1 (build 11.0.23+9-LTS)
```


### Severity

Medium

### Additional context

_No response_",hb-akhilesh,2024-07-12 09:35:29+00:00,['alxnddr'],2024-07-24 06:40:12+00:00,2024-07-24 06:19:05+00:00,https://github.com/metabase/metabase/issues/45454,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2225705848, 'issue_id': 2405159464, 'author': 'alxnddr', 'body': '@hb-akhilesh thanks for reporting the issue. Could you please tell me what version of Metabase you are using?', 'created_at': datetime.datetime(2024, 7, 12, 14, 28, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225747383, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': '0.50.9\r\n\r\nOn Fri, 12 Jul 2024 at 7:58\u202fPM, Aleksandr Lesnenko ***@***.***>\r\nwrote:\r\n\r\n> @hb-akhilesh <https://github.com/hb-akhilesh> thanks for reporting the\r\n> issue. Could you please tell me what version of Metabase you are using?\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/45454#issuecomment-2225705848>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BCG3QEDGPKIDL36NNT3POQDZL7R2NAVCNFSM6AAAAABKYSQHJGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRVG4YDKOBUHA>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 7, 12, 14, 44, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2226730376, 'issue_id': 2405159464, 'author': 'alxnddr', 'body': '@hb-akhilesh thank you for the information about version you are using. I could not reproduce it yet so I wonder if you could provide additional information that would help identify the problem. Could you please try to reproduce it in Chrome and tell if it also weirdly resizes?', 'created_at': datetime.datetime(2024, 7, 13, 2, 43, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227288213, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': 'Alright. So Tried to reproduce this again on my system. But itâ€™s not happening now. I thought I shall debug into the code, but not able to for now. Shall keep a watch.\r\n\r\nThough when it happened, I had seen the browser console. Luckily I had searched for that error as I was intrigued.  This was the error that I had seen in the browser console. \r\n\r\nhttps://stackoverflow.com/questions/76187282/react-resizeobserver-loop-completed-with-undelivered-notificationsï¿¼\r\nReact: ResizeObserver loop completed with undelivered notifications\r\nstackoverflow.com\r\n \r\n\r\nWill try to give you exact source line if it happens with me again.\r\n\r\n> On 13 Jul 2024, at 8:14\u202fAM, Aleksandr Lesnenko ***@***.***> wrote:\r\n> \r\n> \r\n> @hb-akhilesh <https://github.com/hb-akhilesh> thank you for the information about version you are using. I could not reproduce it yet so I wonder if you could provide additional information that would help identify the problem. Could you please try to reproduce it in Chrome and tell if it also weirdly resizes?\r\n> \r\n> â€”\r\n> Reply to this email directly, view it on GitHub <https://github.com/metabase/metabase/issues/45454#issuecomment-2226730376>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BCG3QEGU3WJEY35GHBJQ5R3ZMCH7VAVCNFSM6AAAAABKYSQHJGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRWG4ZTAMZXGY>.\r\n> You are receiving this because you were mentioned.\r\n>', 'created_at': datetime.datetime(2024, 7, 14, 10, 2, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227290060, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': 'Okay. So I have that tab open where this is still happening. Let me know what you want me to look for. Or we can get on a call. I cannot see the exact js source code line since code is minimised. \r\n\r\nï¿¼\r\n\r\n> On 13 Jul 2024, at 8:14\u202fAM, Aleksandr Lesnenko ***@***.***> wrote:\r\n> \r\n> \r\n> @hb-akhilesh <https://github.com/hb-akhilesh> thank you for the information about version you are using. I could not reproduce it yet so I wonder if you could provide additional information that would help identify the problem. Could you please try to reproduce it in Chrome and tell if it also weirdly resizes?\r\n> \r\n> â€”\r\n> Reply to this email directly, view it on GitHub <https://github.com/metabase/metabase/issues/45454#issuecomment-2226730376>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BCG3QEGU3WJEY35GHBJQ5R3ZMCH7VAVCNFSM6AAAAABKYSQHJGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRWG4ZTAMZXGY>.\r\n> You are receiving this because you were mentioned.\r\n>', 'created_at': datetime.datetime(2024, 7, 14, 10, 8, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229512324, 'issue_id': 2405159464, 'author': 'alxnddr', 'body': ""@hb-akhilesh thanks for the additional information! I still could not reproduce it locally but I noticed there was unnecessary resizing updates which I've eliminated. Once PR gets released I'd appreciate if you could tell whether the issue is fixed or not. If this does not help I'd also appreciate if we could schedule a call"", 'created_at': datetime.datetime(2024, 7, 15, 22, 0, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229524389, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': ""Sure. I shall keep the tab open for next few days ðŸ˜ƒ\r\n\r\nOn Tue, 16 Jul 2024 at 3:31\u202fAM, Aleksandr Lesnenko ***@***.***>\r\nwrote:\r\n\r\n> @hb-akhilesh <https://github.com/hb-akhilesh> thanks for the additional\r\n> information! I still could not reproduce it locally but I noticed there was\r\n> unnecessary resizing updates which I've eliminated. Once PR gets released\r\n> I'd appreciate if you could tell whether the issue is fixed or not. If this\r\n> does not help I'd also appreciate if we could schedule a call\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/45454#issuecomment-2229512324>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BCG3QEEFCBKDPLEZ7EE2CBLZMRBC3AVCNFSM6AAAAABKYSQHJGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRZGUYTEMZSGQ>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 7, 15, 22, 11, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230123882, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': 'I see this has been marked to milestone v0.50.14 . Once released, I shall\r\ntest.\r\n\r\nOn Tue, Jul 16, 2024 at 7:06\u202fAM Aleksandr Lesnenko ***@***.***>\r\nwrote:\r\n\r\n> Closed #45454 <https://github.com/metabase/metabase/issues/45454> as\r\n> completed via #45612 <https://github.com/metabase/metabase/pull/45612>.\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/45454#event-13513434261>, or\r\n> unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BCG3QEG3IOACTWWP4LIOLMTZMR2INAVCNFSM6AAAAABKYSQHJGVHI2DSMVQWIX3LMV45UABCJFZXG5LFIV3GK3TUJZXXI2LGNFRWC5DJN5XDWMJTGUYTGNBTGQZDMMI>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 7, 16, 6, 31, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2246995199, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': 'Upgraded to [0.50.15](https://github.com/metabase/metabase/milestone/256), I don\'t see the behaviour.\r\n\r\nThough I see another problem:\r\n\r\nThe x axis is hidden now. \r\n\r\n<img width=""1325"" alt=""image"" src=""https://github.com/user-attachments/assets/a523c97a-613f-42fa-895b-b6e2d01ff8ab"">', 'created_at': datetime.datetime(2024, 7, 24, 6, 19, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247025345, 'issue_id': 2405159464, 'author': 'hb-akhilesh', 'body': 'Though If I open the browser console, then it shows\r\n<img width=""1311"" alt=""image"" src=""https://github.com/user-attachments/assets/462576c6-cf19-43ee-90be-e89c51e7d6ce"">', 'created_at': datetime.datetime(2024, 7, 24, 6, 40, 10, tzinfo=datetime.timezone.utc)}]","alxnddr (Assginee) on (2024-07-12 14:28:32 UTC): @hb-akhilesh thanks for reporting the issue. Could you please tell me what version of Metabase you are using?

hb-akhilesh (Issue Creator) on (2024-07-12 14:44:38 UTC): 0.50.9

On Fri, 12 Jul 2024 at 7:58â€¯PM, Aleksandr Lesnenko ***@***.***>
wrote:

alxnddr (Assginee) on (2024-07-13 02:43:49 UTC): @hb-akhilesh thank you for the information about version you are using. I could not reproduce it yet so I wonder if you could provide additional information that would help identify the problem. Could you please try to reproduce it in Chrome and tell if it also weirdly resizes?

hb-akhilesh (Issue Creator) on (2024-07-14 10:02:12 UTC): Alright. So Tried to reproduce this again on my system. But itâ€™s not happening now. I thought I shall debug into the code, but not able to for now. Shall keep a watch.

Though when it happened, I had seen the browser console. Luckily I had searched for that error as I was intrigued.  This was the error that I had seen in the browser console. 

https://stackoverflow.com/questions/76187282/react-resizeobserver-loop-completed-with-undelivered-notificationsï¿¼
React: ResizeObserver loop completed with undelivered notifications
stackoverflow.com
 

Will try to give you exact source line if it happens with me again.

hb-akhilesh (Issue Creator) on (2024-07-14 10:08:11 UTC): Okay. So I have that tab open where this is still happening. Let me know what you want me to look for. Or we can get on a call. I cannot see the exact js source code line since code is minimised. 

ï¿¼

alxnddr (Assginee) on (2024-07-15 22:00:55 UTC): @hb-akhilesh thanks for the additional information! I still could not reproduce it locally but I noticed there was unnecessary resizing updates which I've eliminated. Once PR gets released I'd appreciate if you could tell whether the issue is fixed or not. If this does not help I'd also appreciate if we could schedule a call

hb-akhilesh (Issue Creator) on (2024-07-15 22:11:07 UTC): Sure. I shall keep the tab open for next few days ðŸ˜ƒ

On Tue, 16 Jul 2024 at 3:31â€¯AM, Aleksandr Lesnenko ***@***.***>
wrote:

hb-akhilesh (Issue Creator) on (2024-07-16 06:31:18 UTC): I see this has been marked to milestone v0.50.14 . Once released, I shall
test.

On Tue, Jul 16, 2024 at 7:06â€¯AM Aleksandr Lesnenko ***@***.***>
wrote:

hb-akhilesh (Issue Creator) on (2024-07-24 06:19:05 UTC): Upgraded to [0.50.15](https://github.com/metabase/metabase/milestone/256), I don't see the behaviour.

Though I see another problem:

The x axis is hidden now. 

<img width=""1325"" alt=""image"" src=""https://github.com/user-attachments/assets/a523c97a-613f-42fa-895b-b6e2d01ff8ab"">

hb-akhilesh (Issue Creator) on (2024-07-24 06:40:10 UTC): Though If I open the browser console, then it shows
<img width=""1311"" alt=""image"" src=""https://github.com/user-attachments/assets/462576c6-cf19-43ee-90be-e89c51e7d6ce"">

"
2404997280,issue,closed,completed,Too many scrollbars in summarize sidebar,"### Describe the bug

![image](https://github.com/user-attachments/assets/ee365c74-878e-4c23-bf74-da64ed6c8e16)


### To Reproduce

1. Change viewport size to 1250x950
2. New question > Orders > join Products > visualize
3. Summarize

There are just too many scrollbars (3). This sidebar needs 1 scrollbar only.


### Information about your Metabase installation

master, 7e6adfa


### Severity

P3
",kamilmielnik,2024-07-12 08:03:32+00:00,['oisincoveney'],2024-10-08 16:19:40+00:00,2024-07-25 16:26:03+00:00,https://github.com/metabase/metabase/issues/45452,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2404987363,issue,closed,completed,Joined table column picker disables the only selected column,"### Describe the bug


https://github.com/user-attachments/assets/dfb574a3-456c-4c9b-a8bb-6630e628b389



### To Reproduce

1. New question > Orders > join Products
2. Click on ""Pick columns"" for the joined table
3. Click ""Select none"" - no column will be selected (unlike in data source step, where we need at least 1 column to be selected)
4. Select one column and then try to deselect it


### Expected behavior

It should be possible to deselect the only selected column (since it's possible to deselect it via ""Select none"")

### Information about your Metabase installation

master, 7e6adfaa3f


### Severity

P3
",kamilmielnik,2024-07-12 07:57:39+00:00,['ranquild'],2024-07-12 19:25:33+00:00,2024-07-12 18:53:55+00:00,https://github.com/metabase/metabase/issues/45451,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2404138973,issue,closed,completed,"""Send test email"" button missing via Admin Email config page when email related env vars are set","### Describe the bug

I am not able to send a test email using the Metabase admin email page when the following environment variables are specified.

MB_EMAIL_FROM_ADDRESS
MB_EMAIL_FROM_NAME
MB_EMAIL_SMTP_HOST
MB_EMAIL_SMTP_PORT
MB_EMAIL_SMTP_SECURITY
MB_EMAIL_SMTP_PASSWORD
MB_EMAIL_SMTP_USERNAME

The issue remains even after going to the Metabase admin panel > Email > Edit configuration and filling the form with values as found in the env vars above.
Entering values:
![image](https://github.com/user-attachments/assets/f8f9ff32-0c86-4bf4-8ddf-94571dab8317)

After entering and saving values, a green success button is visible, however no send test email button.
![image](https://github.com/user-attachments/assets/7c933f2a-789a-49b9-88b8-d843e5cb8481)


### To Reproduce

1. Start Metabase container with the env vars populated like so:
MB_EMAIL_FROM_ADDRESS = from@yourdomain.com
MB_EMAIL_FROM_NAME = name@yourdomain.com
MB_EMAIL_SMTP_HOST = email-smtp.us-west-2.amazonaws.com
MB_EMAIL_SMTP_PORT = 2587
MB_EMAIL_SMTP_SECURITY = starttls
MB_EMAIL_SMTP_PASSWORD = youpassword
MB_EMAIL_SMTP_USERNAME = yourusername
2. Login to your metabase instance via UI
3. Navigate to admin section > settings > email
4. Edit SMTP configuration (values will be blank despite env vars)
5. Manually enter values in the form and save changes.

Note that the email will successfully send if a scheduled alert is present, so this confirms the configuration values are correct, it just isnt possible to trigger a test email adhoc and you must wait an hour or until the next scheduled alert.

### Expected behavior

How I think it should work:
EMAIL/SMTP configuration values can be set via env vars and in the Admin page the send test email should be available due to the existence of the env vars. If that isnt desired then at minimum I think that regardless of if the env vars are present you should be able to manually add in the form and trigger a test.

### Logs

No console logs were generated
No service log lines that are relevant

### Information about your Metabase installation

```JSON
- Chrome Version 126.0.6478.127 (Official Build) (arm64)
- MacOS : Sanoma 14.12
- Metabase Version: v0.50.11
- Metabase environment docker Image: metabase/metabase:v0.50.11
- Metabase database: RDS aurora postgres 16.2
```


### Severity

annoying - low

### Additional context

If I do not set the env vars mentioned above and go to the Email form and enter the values as I would have set for the env vars, I do get the sent email button.",zherner,2024-07-11 21:15:32+00:00,['iethree'],2024-08-02 19:11:12+00:00,2024-08-02 17:21:57+00:00,https://github.com/metabase/metabase/issues/45445,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/', ''), ('Administration/Settings', ''), ('Misc/Emails', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2403862145,issue,closed,completed,Metadata % description shows up behind popup,"Mouseover the 15% here will show the description (in black) behind the other popup (in white). Metabase v1.50.7, on Safari.

![image](https://github.com/metabase/metabase/assets/4172079/24bb4075-6a6f-4dbb-9060-02a7c465024e)

Followup from https://metaboat.slack.com/archives/C505ZNNH4/p1720722799246589
",filipesilva,2024-07-11 18:42:07+00:00,['nemanjaglumac'],2024-07-15 21:00:54+00:00,2024-07-12 21:31:09+00:00,https://github.com/metabase/metabase/issues/45441,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2226265798, 'issue_id': 2403862145, 'author': 'nemanjaglumac', 'body': 'I think I know why ðŸ«£\r\nhttps://github.com/metabase/metabase/blob/master/frontend/src/metabase/ui/components/overlays/Popover/Popover.styled.tsx#L4', 'created_at': datetime.datetime(2024, 7, 12, 19, 57, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229426931, 'issue_id': 2403862145, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 53, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Assginee) on (2024-07-12 19:57:19 UTC): I think I know why ðŸ«£
https://github.com/metabase/metabase/blob/master/frontend/src/metabase/ui/components/overlays/Popover/Popover.styled.tsx#L4

github-actions[bot] on (2024-07-15 21:00:53 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2403382189,issue,open,,Assert on db calls in tests,"We should track db calls during tests. We currently get those stats.

eg

```
DEBUG middleware.log :: GET /api/search 200 202.1 ms (13 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (4 idle, 0 queued) (80 total active threads) Queries in flight: 0 (0 queued)
```

In CI we could add those stats to a header and have `mt/user-http-request` assert that the number of db access was below some global threshold the same way it asserts the response code.

Extra points if we let this be overridable per endpoint.

Motivator: some combination of sandboxing and group cardinality could cause a high number of queries during dashboard reads. We should catch these N+1s (https://github.com/metabase/metabase/issues/44786)",dpsutton,2024-07-11 14:48:55+00:00,[],2024-07-11 14:48:56+00:00,,https://github.com/metabase/metabase/issues/45431,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('Misc/API', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2403357466,issue,closed,not_planned,Metrics with joins crash when trying to edit or add the breakouts,"### Describe the bug

When I create a metric that has a join in the definition, save it, go to the notebook and click on the breakout or try to add a breakout the page crashes

### To Reproduce

1. Click on + New metric
2. Select Orders tables from Sample database
3. Join with Products, keep the automatically created condition
4. Add Sum of Total and break out by Created At: Month
5. Save the metric
6. Go to the notebook editor
7. Try to change or add a breakout
8. Page crashes


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Breaks a major use case

### Additional context

_No response_",mngr,2024-07-11 14:39:37+00:00,[],2024-07-11 15:18:25+00:00,2024-07-11 15:18:24+00:00,https://github.com/metabase/metabase/issues/45429,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Needs Triage', ''), ('.Team/Querying', '')]","[{'comment_id': 2223220544, 'issue_id': 2403357466, 'author': 'mngr', 'body': 'This wonâ€™t be relevant after we disable metrics as data sources', 'created_at': datetime.datetime(2024, 7, 11, 15, 18, 24, tzinfo=datetime.timezone.utc)}]","mngr (Issue Creator) on (2024-07-11 15:18:24 UTC): This wonâ€™t be relevant after we disable metrics as data sources

"
2403320679,issue,closed,completed,Update more UIs,"```[tasklist]
### Tasks
- [x] Update dark theme text
- [ ] https://github.com/metabase/metabase/issues/45135
```
",WiNloSt,2024-07-11 14:23:01+00:00,['WiNloSt'],2024-07-15 14:24:21+00:00,2024-07-15 14:24:21+00:00,https://github.com/metabase/metabase/issues/45427,[],[],
2403296096,issue,closed,completed,cleanup fast-loops dep from resolutions,"**Context**

we created a record in resolutions in https://github.com/metabase/metabase/pull/45415, but it should be obsolete after https://github.com/streamich/react-use/issues/2566 is fixed

drop resolution and upgrade react-use when the issue is resolved",uladzimirdev,2024-07-11 14:12:05+00:00,[],2024-10-08 16:19:20+00:00,2024-07-30 06:04:35+00:00,https://github.com/metabase/metabase/issues/45425,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2403262946,issue,closed,completed,Update all UTM tag to the new version,"https://www.notion.so/metabase/Product-UTM-Instrumentation-fc47f3584d5b48bea2e0ad02cda0376d

This issue was raised for [all links other than the upsell banner](https://metaboat.slack.com/archives/C063Q3F1HPF/p1720697648382679), so let's just update those links there to be more specific.
",WiNloSt,2024-07-11 13:57:30+00:00,[],2024-08-23 14:14:13+00:00,2024-08-23 12:31:27+00:00,https://github.com/metabase/metabase/issues/45422,[],[],
2402962091,issue,closed,completed,Weird behavior after saving questions in v1.50.11,"### Describe the bug

Bug first seen in v1.50.11

After saving a question a new dialogue pops up: ""Save new question"". It disappears after a few seconds and the question is saved as expected. This happens when you start from a saved question and either replace it or create a new question.
The behavior seems to be related to the query_metadata request. 

See screen recording below for an example

### To Reproduce

1. Upgrade to v.1.50.11
2. Go to a saved question
3. Edit something in this question
4. Save question, either by overwriting the old one or creating a new question.
5. See behavior


### Expected behavior

The second dialogue should never show.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""nb-NO"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.85+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v1.50.11"",
      ""hash"": ""e08c1fb""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Oslo""
    }
  }
}
```


### Severity

Annoying to any user creating questions

### Additional context

https://github.com/metabase/metabase/assets/55921651/a3da8813-bcea-4607-8784-a89877772f8c",vebjorre,2024-07-11 11:38:10+00:00,['uladzimirdev'],2024-07-17 06:42:09+00:00,2024-07-12 21:49:11+00:00,https://github.com/metabase/metabase/issues/45416,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2222759106, 'issue_id': 2402962091, 'author': 'nemanjaglumac', 'body': 'That ""Save dialog"" prompt looks like this one:\r\nhttps://github.com/metabase/metabase/issues/37373\r\n\r\n@vebjorre What was the version from which you upgraded?', 'created_at': datetime.datetime(2024, 7, 11, 12, 6, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222963163, 'issue_id': 2402962091, 'author': 'vebjorre', 'body': 'Yes, it does look similar. I have only tested questions I created myself (both old and new ones), so it is not exactly the same regarding permissions. See permissions below:\r\n![Skjermbilde 2024-07-11 kl  15 27 37](https://github.com/metabase/metabase/assets/55921651/6a6444de-189c-406c-81ba-3cf229b2fa51)\r\n\r\n> What was the version from which you upgraded?\r\n\r\n1.50.10\r\nWe usually upgrade for each new patch and I am positive I did not see this issue in 1.50.10 or earlier.', 'created_at': datetime.datetime(2024, 7, 11, 13, 36, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222974940, 'issue_id': 2402962091, 'author': 'nemanjaglumac', 'body': ""I was able to reproduce it on a fresh x.50.11 instance.\r\nUpgrading doesn't play a role here.\r\n\r\nInvestigating further..."", 'created_at': datetime.datetime(2024, 7, 11, 13, 41, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222984474, 'issue_id': 2402962091, 'author': 'nemanjaglumac', 'body': '@vebjorre this was present in x.50.10 as well.\r\nPlease see the attached video. It happens very briefly.\r\n\r\nEDIT:\r\nAaaaand it happens in `master` @ [e62d098](https://github.com/metabase/metabase/commit/e62d098b6d544fef2aa1d28e556767cc71be2e03)\r\n\r\nhttps://github.com/metabase/metabase/assets/31325167/994139ea-5434-48fa-8c1c-3291e113db0e', 'created_at': datetime.datetime(2024, 7, 11, 13, 45, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222999789, 'issue_id': 2402962091, 'author': 'nemanjaglumac', 'body': 'Related (and probably the same root cause) - https://github.com/metabase/metabase/issues/35150', 'created_at': datetime.datetime(2024, 7, 11, 13, 52, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2226244158, 'issue_id': 2402962091, 'author': 'paoliniluis', 'body': '@vebjorre your endpoints are extremely slow, can you send us an email?', 'created_at': datetime.datetime(2024, 7, 12, 19, 39, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229426274, 'issue_id': 2402962091, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.13](https://github.com/metabase/metabase/milestone/253)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231853328, 'issue_id': 2402962091, 'author': 'uladzimirdev', 'body': '@vebjorre 50.13 contains a fix, could you please share a video of the wrong behaviour in 50.13 if you still experience it?', 'created_at': datetime.datetime(2024, 7, 16, 21, 25, 19, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-11 12:06:27 UTC): That ""Save dialog"" prompt looks like this one:
https://github.com/metabase/metabase/issues/37373

@vebjorre What was the version from which you upgraded?

vebjorre (Issue Creator) on (2024-07-11 13:36:46 UTC): Yes, it does look similar. I have only tested questions I created myself (both old and new ones), so it is not exactly the same regarding permissions. See permissions below:
![Skjermbilde 2024-07-11 kl  15 27 37](https://github.com/metabase/metabase/assets/55921651/6a6444de-189c-406c-81ba-3cf229b2fa51)


1.50.10
We usually upgrade for each new patch and I am positive I did not see this issue in 1.50.10 or earlier.

nemanjaglumac on (2024-07-11 13:41:35 UTC): I was able to reproduce it on a fresh x.50.11 instance.
Upgrading doesn't play a role here.

Investigating further...

nemanjaglumac on (2024-07-11 13:45:48 UTC): @vebjorre this was present in x.50.10 as well.
Please see the attached video. It happens very briefly.

EDIT:
Aaaaand it happens in `master` @ [e62d098](https://github.com/metabase/metabase/commit/e62d098b6d544fef2aa1d28e556767cc71be2e03)

https://github.com/metabase/metabase/assets/31325167/994139ea-5434-48fa-8c1c-3291e113db0e

nemanjaglumac on (2024-07-11 13:52:28 UTC): Related (and probably the same root cause) - https://github.com/metabase/metabase/issues/35150

paoliniluis on (2024-07-12 19:39:40 UTC): @vebjorre your endpoints are extremely slow, can you send us an email?

github-actions[bot] on (2024-07-15 21:00:31 UTC): ðŸš€ This should also be released by [v0.50.13](https://github.com/metabase/metabase/milestone/253)

uladzimirdev (Assginee) on (2024-07-16 21:25:19 UTC): @vebjorre 50.13 contains a fix, could you please share a video of the wrong behaviour in 50.13 if you still experience it?

"
2402874684,issue,open,,Dashboard with multiple queries (33) and filters not caching results with metabase pro,"**Describe the bug**
When we load a dashboard when multiple queries (33 queries approximately) and we have cache by dashboards and subqueries of the dashboard active, the dashboard loads so slow, and it seems it doesn't use the cache never ( we have some filters on the dashboard with default values on them, but, we are not changing the filters). And when we go to logs to see if there is any error, we get the following message repeated over and over every time we launch our dashboard ( we have now the free trial pro metabase self hosted version)

**Logs**

> [b4b6db97-3cdb-4ecb-9f51-2a66bca3be80] 2024-07-11T12:38:27+02:00 ERROR metabase.query-processor.middleware.process-userland-query Error saving query execution info,clojure.lang.ExceptionInfo: Unknown type of ref {:ref [:sum {:lib/uuid ""5acb02b3-b37c-49ee-92d3-247524f20c92""} [:expression {:base-type :type/Decimal, :lib/uuid ""fc8ba6b2-0d98-43fd-a851-7bcbfb208dfa""} ""REVENUE""]], :toucan2/context-trace [[""parse args"" {:toucan2.query/query-type :toucan.query-type/insert.update-count, :toucan2.query/unparsed-args (:model/FieldUsage ({:field_id 83, :used_in :filter, :filter_op :=, :query_execution_id 1832} {:field_id 99, :used_in :filter, :filter_op :>=, :query_execution_id 1832} {:field_id 99, :used_in :filter, :filter_op :<, :query_execution_id 1832}))}]]},	at metabase.lib.equality$find_matching_column.invokeStatic(equality.cljc:293),	at metabase.lib.equality$find_matching_column.invoke(equality.cljc:249),	at metabase.lib.equality$find_matching_column.invokeStatic(equality.cljc:274),	at metabase.lib.equality$find_matching_column.invoke(equality.cljc:249),	at metabase.lib.aggregation$aggregation_column.invokeStatic(aggregation.cljc:433),	at metabase.lib.aggregation$aggregation_column.invoke(aggregation.cljc:423),	at metabase.models.field_usage$aggregation__GT_field_usage.invokeStatic(field_usage.clj:38),	at metabase.models.field_usage$aggregation__GT_field_usage.invoke(field_usage.clj:36),	at metabase.models.field_usage$stage__GT_field_usages$fn__75610.invoke(field_usage.clj:77),	at clojure.core$keep$fn__8649.invoke(core.clj:7406),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:58),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$concat$cat__5560$fn__5561.invoke(core.clj:736),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$map$fn__5935.invoke(core.clj:2763),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.ChunkedCons.chunkedNext(ChunkedCons.java:59),	at clojure.lang.ChunkedCons.next(ChunkedCons.java:43),	at clojure.lang.RT.next(RT.java:713),	at clojure.core$next__5451.invokeStatic(core.clj:64),	at clojure.core$next__5451.invoke(core.clj:64),	at clojure.spec.alpha$re_conform.invokeStatic(alpha.clj:1660),	at clojure.spec.alpha$re_conform.invoke(alpha.clj:1660),	at clojure.spec.alpha$regex_spec_impl$reify__2503.conform_STAR_(alpha.clj:1710),	at clojure.spec.alpha$conform.invokeStatic(alpha.clj:171),	at clojure.spec.alpha$conform.invoke(alpha.clj:167),	at clojure.spec.alpha$dt.invokeStatic(alpha.clj:764),	at clojure.spec.alpha$dt.invoke(alpha.clj:759),	at clojure.spec.alpha$dt.invokeStatic(alpha.clj:760),	at clojure.spec.alpha$dt.invoke(alpha.clj:759),	at clojure.spec.alpha$deriv.invokeStatic(alpha.clj:1534),	at clojure.spec.alpha$deriv.invoke(alpha.clj:1528),	at clojure.spec.alpha$deriv$fn__2419.invoke(alpha.clj:1544),	at clojure.core$map$fn__5935.invoke(core.clj:2772),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$map$fn__5942.invoke(core.clj:2780),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$filter$fn__5962.invoke(core.clj:2826),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:58),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$map$fn__5935.invoke(core.clj:2763),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$seq__5467.invoke(core.clj:139),	at clojure.spec.alpha$filter_alt.invokeStatic(alpha.clj:1431),	at clojure.spec.alpha$filter_alt.invoke(alpha.clj:1425),	at clojure.spec.alpha$alt_STAR_.invokeStatic(alpha.clj:1435),	at clojure.spec.alpha$alt_STAR_.invoke(alpha.clj:1434),	at clojure.spec.alpha$deriv.invokeStatic(alpha.clj:1544),	at clojure.spec.alpha$deriv.invoke(alpha.clj:1528),	at clojure.spec.alpha$deriv$fn__2419.invoke(alpha.clj:1544),	at clojure.core$map$fn__5935.invoke(core.clj:2772),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$map$fn__5942.invoke(core.clj:2780),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$filter$fn__5962.invoke(core.clj:2826),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$map$fn__5935.invoke(core.clj:2763),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:51),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$seq__5467.invoke(core.clj:139),	at clojure.spec.alpha$filter_alt.invokeStatic(alpha.clj:1431),	at clojure.spec.alpha$filter_alt.invoke(alpha.clj:1425),	at clojure.spec.alpha$alt_STAR_.invokeStatic(alpha.clj:1435),	at clojure.spec.alpha$alt_STAR_.invoke(alpha.clj:1434),	at clojure.spec.alpha$deriv.invokeStatic(alpha.clj:1544),	at clojure.spec.alpha$deriv.invoke(alpha.clj:1528),	at clojure.spec.alpha$deriv.invokeStatic(alpha.clj:1542),	at clojure.spec.alpha$deriv.invoke(alpha.clj:1528),	at clojure.spec.alpha$re_conform.invokeStatic(alpha.clj:1669),	at clojure.spec.alpha$re_conform.invoke(alpha.clj:1660),	at clojure.spec.alpha$regex_spec_impl$reify__2503.conform_STAR_(alpha.clj:1710),	at clojure.spec.alpha$conform.invokeStatic(alpha.clj:171),	at clojure.spec.alpha$conform.invoke(alpha.clj:167),	at toucan2.query$parse_args_with_spec.invokeStatic(query.clj:71),	at toucan2.query$parse_args_with_spec.invoke(query.clj:66),	at toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invokeStatic(insert.clj:35),	at toucan2.insert$parse_args_primary_method_toucan_query_type_insert__STAR_.invoke(insert.clj:32),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at clojure.core$partial$fn__5908.invoke(core.clj:2642),	at clojure.lang.AFn.applyToHelper(AFn.java:156),	at clojure.lang.RestFn.applyTo(RestFn.java:132),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:421),	at methodical.impl.combo.threaded$fn__18077$fn__18078$fn__18079.invoke(threaded.clj:70),	at methodical.impl.combo.threaded$reducer_fn$fn__18047$fn__18051.invoke(threaded.clj:23),	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58),	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136),	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124),	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19),	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31),	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75),	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75),	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13),	at clojure.core$reduce.invokeStatic(core.clj:6887),	at clojure.core$reduce.invoke(core.clj:6869),	at methodical.impl.combo.threaded$reducer_fn$fn__18047.invoke(threaded.clj:21),	at clojure.core$comp$fn__5876.invoke(core.clj:2587),	at methodical.impl.combo.threaded$combine_with_threader$fn__18057.invoke(threaded.clj:43),	at clojure.lang.AFn.applyToHelper(AFn.java:156),	at clojure.lang.RestFn.applyTo(RestFn.java:132),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:421),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193),	at toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:315),	at toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311),	at toucan2.pipeline$transduce_unparsed_with_default_rf.invokeStatic(pipeline.clj:374),	at toucan2.pipeline$transduce_unparsed_with_default_rf.invoke(pipeline.clj:368),	at toucan2.insert$insert_BANG_.invokeStatic(insert.clj:124),	at toucan2.insert$insert_BANG_.doInvoke(insert.clj:74),	at clojure.lang.RestFn.invoke(RestFn.java:421),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG__STAR_.invokeStatic(process_userland_query.clj:51),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG__STAR_.invoke(process_userland_query.clj:42),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG_$fn__75636.invoke(process_userland_query.clj:68),	at clojure.lang.AFn.run(AFn.java:22),	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	at java.base/java.lang.Thread.run(Unknown Source)


**To Reproduce**
Steps to reproduce the behavior:
1. Create a Dashboard with queries
2. Activate cache 24 hours duration on every query used on the dashboard and activate the cache on the dashboard itself
3. Launch dashboard
4. See logs on log console

**Expected behavior**
Dashboard should load instantly, because we use cache on dashboard and queries used on dashboard

**Screenshots**
<img width=""2983"" alt=""image"" src=""https://github.com/metabase/metabase/assets/112938617/e66d2b41-01a5-415d-a6be-96b05a9a6b76"">


**Severity**
We use it to show data quickly with this dashboard, and we create some light tables, with a few data registries, to improve performance on charging data, but we are not seeing any improvement, and we need to load this dashboard in a few seconds (2 to 3 seconds)


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.252-195.483.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.17""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v1.50.11"",
      ""hash"": ""e08c1fb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",juangc-wavyssa,2024-07-11 10:50:20+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/45412,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Backend', ''), ('Querying/Cache', ''), ('.Team/Querying', '')]","[{'comment_id': 2223403074, 'issue_id': 2402874684, 'author': 'paoliniluis', 'body': 'I think this is related, if not the same as https://github.com/metabase/metabase/issues/44359', 'created_at': datetime.datetime(2024, 7, 11, 16, 38, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224879626, 'issue_id': 2402874684, 'author': 'juangc-wavyssa', 'body': ""I don't know if this is related, but is no the same as they describe in the issue"", 'created_at': datetime.datetime(2024, 7, 12, 6, 29, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229405508, 'issue_id': 2402874684, 'author': 'bshepherdson', 'body': ""One of the performance fixes we made in the course of fixing #44359 disabled the `field-usage` logic that's causing the stack traces you highlighted. So from 50.13 that error message will not appear anymore.\r\n\r\nThat same performance fix may play a factor here, despite appearances. The issue was a lot of CPU work being done before each query in the dashboard request is done. The impact of that perf issue scales strongly with the complexity of the query (more joins, filters, aggregations, expressions, etc.) and weakly with the total number columns in view.\r\n\r\nSo I suspect what you're seeing here is that while the query results are cached, that post-processing was consuming perhaps 500ms per query, making the overall dashboard load very slow.\r\n\r\n@juangc-wavyssa Please try this dashboard again on 50.13 and see how it performs there."", 'created_at': datetime.datetime(2024, 7, 15, 20, 48, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230254653, 'issue_id': 2402874684, 'author': 'juangc-wavyssa', 'body': 'We have updated to 50.13 and we have the same performance issue.', 'created_at': datetime.datetime(2024, 7, 16, 7, 53, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233216029, 'issue_id': 2402874684, 'author': 'bshepherdson', 'body': 'This looks like there is a query caching issue, then.\r\n\r\nCan you screenshot the caching settings for this dashboard? (Question-level caching is not used when the dashboard is cached.)', 'created_at': datetime.datetime(2024, 7, 17, 12, 34, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247176676, 'issue_id': 2402874684, 'author': 'juangc-wavyssa', 'body': 'We configure Duration caching policy on dashboard and subqueries, with a 24 hours duration, since our data is updated every 24 hours for this dashboards and queries.', 'created_at': datetime.datetime(2024, 7, 24, 8, 9, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2344584584, 'issue_id': 2402874684, 'author': 'paoliniluis', 'body': 'Please upgrade to 50.26 once it ships and tell us if this keeps happening', 'created_at': datetime.datetime(2024, 9, 11, 19, 54, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2348764278, 'issue_id': 2402874684, 'author': 'juangc-wavyssa', 'body': '> Please upgrade to 50.26 once it ships and tell us if this keeps happening\r\n\r\nWhen is going to be released?', 'created_at': datetime.datetime(2024, 9, 13, 11, 46, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-11 16:38:45 UTC): I think this is related, if not the same as https://github.com/metabase/metabase/issues/44359

juangc-wavyssa (Issue Creator) on (2024-07-12 06:29:52 UTC): I don't know if this is related, but is no the same as they describe in the issue

bshepherdson on (2024-07-15 20:48:55 UTC): One of the performance fixes we made in the course of fixing #44359 disabled the `field-usage` logic that's causing the stack traces you highlighted. So from 50.13 that error message will not appear anymore.

That same performance fix may play a factor here, despite appearances. The issue was a lot of CPU work being done before each query in the dashboard request is done. The impact of that perf issue scales strongly with the complexity of the query (more joins, filters, aggregations, expressions, etc.) and weakly with the total number columns in view.

So I suspect what you're seeing here is that while the query results are cached, that post-processing was consuming perhaps 500ms per query, making the overall dashboard load very slow.

@juangc-wavyssa Please try this dashboard again on 50.13 and see how it performs there.

juangc-wavyssa (Issue Creator) on (2024-07-16 07:53:35 UTC): We have updated to 50.13 and we have the same performance issue.

bshepherdson on (2024-07-17 12:34:31 UTC): This looks like there is a query caching issue, then.

Can you screenshot the caching settings for this dashboard? (Question-level caching is not used when the dashboard is cached.)

juangc-wavyssa (Issue Creator) on (2024-07-24 08:09:48 UTC): We configure Duration caching policy on dashboard and subqueries, with a 24 hours duration, since our data is updated every 24 hours for this dashboards and queries.

paoliniluis on (2024-09-11 19:54:33 UTC): Please upgrade to 50.26 once it ships and tell us if this keeps happening

juangc-wavyssa (Issue Creator) on (2024-09-13 11:46:33 UTC): When is going to be released?

"
2402743171,issue,open,,Suggestions dropdown visually disconnected from the filter input,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/586fe017-8ba4-4839-b396-1148f7d8041a



### To Reproduce

1. New Question > Sample DB > Accounts > Visualize
2. Add filter on email
3. Change the type from ""Contains"" to ""Is""
4. Type ""a"", wait for suggestions to load
5. Keep applying suggestions until you see the overflow

### Expected behavior

- Filter popover should auto-scroll to the latest inserted option
- The suggestions popover should not be affected by scrolling in filter popover

### Logs

_No response_

### Information about your Metabase installation

```JSON
master, 359ae5804d
```


### Severity

P3

### Additional context

_No response_",kamilmielnik,2024-07-11 09:43:08+00:00,[],2024-07-11 09:55:23+00:00,,https://github.com/metabase/metabase/issues/45411,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2402719122,issue,closed,completed,"Unable to remove applied filter with the ""x"" button","### Describe the bug

https://github.com/metabase/metabase/assets/6830683/aa6e38ec-f73f-48d5-b942-16022fbb60b2


### To Reproduce

1. New question > Sample DB > Accounts > Visualize
2. Add filter by email with 2 emails: `abc@example.com`, `abc2@example.com`
3. Try to remove the 2nd email by clicking on ""x""

Nothing happens. Cursor does not change to pointer when ""x"" button is hovered over.
Looks like it's covered by the ""i"" icon which is not properly hidden when input is not focused.

### Information about your Metabase installation

master, 359ae5804d


### Severity

P3

",kamilmielnik,2024-07-11 09:31:59+00:00,['ranquild'],2024-07-19 23:59:22+00:00,2024-07-19 21:49:06+00:00,https://github.com/metabase/metabase/issues/45410,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Querying', '')]",[],
2402638848,issue,open,,Text cut off in FK target dropdown,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/57f99124-2cab-480b-bf94-2897ca6ed425)


### To Reproduce

1. Go to Admin -> Table Metadata -> Sample Database -> Orders
2. Click on ""Products -> ID"" in `PRODUCT_ID` section
3. Dropdown opens
4. Scroll down in the dropdown to see currently selected option

Notice that currently selected option covers the previous option, and last option is cut off.
note: things work fine if dropdown is opened again.

### Information about your Metabase installation


master, 359ae5804d


### Severity

P3
",kamilmielnik,2024-07-11 08:56:29+00:00,[],2025-02-04 20:29:28+00:00,,https://github.com/metabase/metabase/issues/45409,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Table Metadata', ''), ('.Frontend', ''), ('.Team/Querying', ''), ('Semantic Model', '')]",[],
2402418707,issue,closed,completed,Update the rest of the UI to match the new design (upsell banner) + test different plans,,WiNloSt,2024-07-11 07:01:23+00:00,['WiNloSt'],2024-07-12 11:16:57+00:00,2024-07-12 11:16:57+00:00,https://github.com/metabase/metabase/issues/45407,[],[],
2402137738,issue,closed,completed,filters can't be linked,"**Is your feature request related to a problem? Please describe.**
Filter A is province, filter B is city. When I select a province in filter A, the drop-down options in filter B are still all cities in all provinces.

**Describe the solution you'd like**
For example, filter A is for province, and filter B is for city. When I select a province in filter A, I want the drop-down options in filter B to be a list of cities in the selected province.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**How important is this feature to you?**
very important

**Additional context**
<img width=""664"" alt=""image"" src=""https://github.com/metabase/metabase/assets/13175108/9294669f-222a-4fb1-9a61-25659d38d147"">

",zuolixiang,2024-07-11 03:08:23+00:00,[],2024-07-16 08:43:43+00:00,2024-07-16 08:43:27+00:00,https://github.com/metabase/metabase/issues/45405,"[('Type:Question', 'Please use the forum: https://discourse.metabase.com/')]","[{'comment_id': 2221964296, 'issue_id': 2402137738, 'author': 'notrom', 'body': 'Have you looked at the documentation on linking filters? https://www.metabase.com/learn/dashboards/linking-filters', 'created_at': datetime.datetime(2024, 7, 11, 3, 48, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222204538, 'issue_id': 2402137738, 'author': 'zuolixiang', 'body': ""> Have you looked at the documentation on linking filters? https://www.metabase.com/learn/dashboards/linking-filters\r\n\r\nI've read this and tried,  but it doesn't work"", 'created_at': datetime.datetime(2024, 7, 11, 7, 13, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224818157, 'issue_id': 2402137738, 'author': 'WiNloSt', 'body': '@zuolixiang Could you give us more info \r\n- What Metabase version you are using\r\n- What database are you using\r\n- Screenshots of linked filters\r\n\r\nI tested that the link filters work with People table from Metabase sample database.\r\n\r\n![image](https://github.com/user-attachments/assets/93f1847d-66a4-4282-b116-3cb3f293b55a)\r\n![image](https://github.com/user-attachments/assets/5a880dbf-bc23-4d4a-a1dd-4f5b0a45d4f8)\r\n![image](https://github.com/user-attachments/assets/889d80af-8bde-416b-91a4-c5097ecceaa1)', 'created_at': datetime.datetime(2024, 7, 12, 6, 6, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2226531032, 'issue_id': 2402137738, 'author': 'zuolixiang', 'body': '@WiNloSt \r\nI pulled the current master branch, and builded in my Mac\r\nI just use Sample Database.  Details  as follow, thanks\r\n\r\n<img width=""490"" alt=""image"" src=""https://github.com/user-attachments/assets/8cfcc792-3259-41d5-8a43-3758bc9264a0"">\r\n\r\n<img width=""1428"" alt=""image"" src=""https://github.com/user-attachments/assets/37542006-e6f0-4412-8f21-0ddea9dad856"">\r\n\r\n<img width=""1086"" alt=""image"" src=""https://github.com/user-attachments/assets/a43f777c-42ba-45f6-990e-feeac87b6f9e"">\r\n\r\n<img width=""1681"" alt=""image"" src=""https://github.com/user-attachments/assets/0cb357a2-2eec-48f2-8040-28c0c063db7e"">\r\n\r\n<img width=""1682"" alt=""image"" src=""https://github.com/user-attachments/assets/7fd1340f-6dd1-4041-85cb-41dae19edac4"">\r\n\r\nfirstly, I chose State CA and add filter\r\n<img width=""1025"" alt=""image"" src=""https://github.com/user-attachments/assets/fbe1b325-0558-462d-a50c-4450e9a38325"">\r\n\r\nwhen I wanted to choose City, the filter is not a droplist, I had to type in some words to let the filter show city list\r\n<img width=""943"" alt=""image"" src=""https://github.com/user-attachments/assets/f2c3bef1-b1f4-45ac-89a8-dc215de8addc"">', 'created_at': datetime.datetime(2024, 7, 12, 23, 37, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227729430, 'issue_id': 2402137738, 'author': 'WiNloSt', 'body': 'Hi @zuolixiang thanks for the info!\r\n\r\nI believe in your case, even though you have to type something before the values start showing, the linked filter should work as intended by filtering the available values that only match the selected state which is not what you indicated in the bug description.\r\n\r\nIf you want City to be a dropdown list, you can ensure the column setting in table metadata is set to `A list of all values` instead of `Search box`. To see this setting go to Admin > Table Metadata > Select the db (Sample database in this case) > Select the table (People) > Select the column by clicking on the Cog icon on the column (City)\r\n\r\n![image](https://github.com/user-attachments/assets/3bd5a81a-1fee-4549-b8d9-2488f8b72aaf)\r\n\r\nThen the filter should show the dropdown immediately when you click on it without having to type anything.\r\n![image](https://github.com/user-attachments/assets/5d740f3a-083e-4431-ac10-5b94f1432a67)', 'created_at': datetime.datetime(2024, 7, 15, 5, 34, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229862901, 'issue_id': 2402137738, 'author': 'zuolixiang', 'body': 'Thanks youï¼ŒI did as you told, it worksï¼Œamazing! @WiNloSt', 'created_at': datetime.datetime(2024, 7, 16, 2, 5, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230347954, 'issue_id': 2402137738, 'author': 'WiNloSt', 'body': ""@zuolixiang I'll close the issue then :)"", 'created_at': datetime.datetime(2024, 7, 16, 8, 43, 27, tzinfo=datetime.timezone.utc)}]","notrom on (2024-07-11 03:48:38 UTC): Have you looked at the documentation on linking filters? https://www.metabase.com/learn/dashboards/linking-filters

zuolixiang (Issue Creator) on (2024-07-11 07:13:29 UTC): I've read this and tried,  but it doesn't work

WiNloSt on (2024-07-12 06:06:33 UTC): @zuolixiang Could you give us more info 
- What Metabase version you are using
- What database are you using
- Screenshots of linked filters

I tested that the link filters work with People table from Metabase sample database.

![image](https://github.com/user-attachments/assets/93f1847d-66a4-4282-b116-3cb3f293b55a)
![image](https://github.com/user-attachments/assets/5a880dbf-bc23-4d4a-a1dd-4f5b0a45d4f8)
![image](https://github.com/user-attachments/assets/889d80af-8bde-416b-91a4-c5097ecceaa1)

zuolixiang (Issue Creator) on (2024-07-12 23:37:43 UTC): @WiNloSt 
I pulled the current master branch, and builded in my Mac
I just use Sample Database.  Details  as follow, thanks

<img width=""490"" alt=""image"" src=""https://github.com/user-attachments/assets/8cfcc792-3259-41d5-8a43-3758bc9264a0"">

<img width=""1428"" alt=""image"" src=""https://github.com/user-attachments/assets/37542006-e6f0-4412-8f21-0ddea9dad856"">

<img width=""1086"" alt=""image"" src=""https://github.com/user-attachments/assets/a43f777c-42ba-45f6-990e-feeac87b6f9e"">

<img width=""1681"" alt=""image"" src=""https://github.com/user-attachments/assets/0cb357a2-2eec-48f2-8040-28c0c063db7e"">

<img width=""1682"" alt=""image"" src=""https://github.com/user-attachments/assets/7fd1340f-6dd1-4041-85cb-41dae19edac4"">

firstly, I chose State CA and add filter
<img width=""1025"" alt=""image"" src=""https://github.com/user-attachments/assets/fbe1b325-0558-462d-a50c-4450e9a38325"">

when I wanted to choose City, the filter is not a droplist, I had to type in some words to let the filter show city list
<img width=""943"" alt=""image"" src=""https://github.com/user-attachments/assets/f2c3bef1-b1f4-45ac-89a8-dc215de8addc"">

WiNloSt on (2024-07-15 05:34:15 UTC): Hi @zuolixiang thanks for the info!

I believe in your case, even though you have to type something before the values start showing, the linked filter should work as intended by filtering the available values that only match the selected state which is not what you indicated in the bug description.

If you want City to be a dropdown list, you can ensure the column setting in table metadata is set to `A list of all values` instead of `Search box`. To see this setting go to Admin > Table Metadata > Select the db (Sample database in this case) > Select the table (People) > Select the column by clicking on the Cog icon on the column (City)

![image](https://github.com/user-attachments/assets/3bd5a81a-1fee-4549-b8d9-2488f8b72aaf)

Then the filter should show the dropdown immediately when you click on it without having to type anything.
![image](https://github.com/user-attachments/assets/5d740f3a-083e-4431-ac10-5b94f1432a67)

zuolixiang (Issue Creator) on (2024-07-16 02:05:06 UTC): Thanks youï¼ŒI did as you told, it worksï¼Œamazing! @WiNloSt

WiNloSt on (2024-07-16 08:43:27 UTC): @zuolixiang I'll close the issue then :)

"
2402053402,issue,open,,"Upgrading from V0.49 to V0.50, question is error","**Describe the bug**
SQL is different between V0.49 and V0.50.
Maybe it happens when schema,table,column name is the same.

**To Reproduce**
Steps to reproduce the behavior:
1. V0.49 -> V0.50
2. Open question
3. See error

**Screenshots**
![image](https://github.com/metabase/metabase/assets/50532623/70fe2319-0e76-4e16-8442-17ae6cc8abb1)

**Severity**
P1

**Additional context**
[V0.49.20(OK).txt](https://github.com/user-attachments/files/16170426/V0.49.20.OK.txt)
[V0.50.11(NG).txt](https://github.com/user-attachments/files/16170427/V0.50.11.NG.txt)


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""ja"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.3+9-LTS"",
    ""java.vendor"": ""Microsoft"",
    ""java.vendor.url"": ""https://www.microsoft.com"",
    ""java.version"": ""21.0.3"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.3+9-LTS"",
    ""os.name"": ""Windows 11"",
    ""os.version"": ""10.0"",
    ""user.language"": ""ja"",
    ""user.timezone"": ""Asia/Tokyo""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v0.50.11"",
      ""hash"": ""e08c1fb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",koukun2005,2024-07-11 01:58:45+00:00,[],2025-02-04 20:27:35+00:00,,https://github.com/metabase/metabase/issues/45403,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/', ''), ('.Team/Querying', '')]","[{'comment_id': 2222916645, 'issue_id': 2402053402, 'author': 'bshepherdson', 'body': 'This looks likely to be related to similar issues (eg. #43993) with nested queries not properly matching up field refs in later stages with their origins in the newly created stage.', 'created_at': datetime.datetime(2024, 7, 11, 13, 16, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249538265, 'issue_id': 2402053402, 'author': 'koukun2005', 'body': 'Error with attached DB question â€œM1+Q1â€.\r\n\r\nH2DB(v0.50.15)\r\nUser:test@metabase.com\r\nPass:metabase0\r\n[metabase.db.mv.zip](https://github.com/user-attachments/files/16371315/metabase.db.mv.zip)\r\nPostgreSQL(v16.3)\r\n[pg_dump.txt](https://github.com/user-attachments/files/16371316/pg_dump.txt)', 'created_at': datetime.datetime(2024, 7, 25, 6, 13, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533453845, 'issue_id': 2402053402, 'author': 'koukun2005', 'body': ""I upgraded to V0.52.2 in the hope that maybe it was fixed, but the phenomenon remained the same.\nI can't upgrade from V0.49 at this point, so could you please investigate?"", 'created_at': datetime.datetime(2024, 12, 11, 2, 3, 17, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-11 13:16:12 UTC): This looks likely to be related to similar issues (eg. #43993) with nested queries not properly matching up field refs in later stages with their origins in the newly created stage.

koukun2005 (Issue Creator) on (2024-07-25 06:13:10 UTC): Error with attached DB question â€œM1+Q1â€.

H2DB(v0.50.15)
User:test@metabase.com
Pass:metabase0
[metabase.db.mv.zip](https://github.com/user-attachments/files/16371315/metabase.db.mv.zip)
PostgreSQL(v16.3)
[pg_dump.txt](https://github.com/user-attachments/files/16371316/pg_dump.txt)

koukun2005 (Issue Creator) on (2024-12-11 02:03:17 UTC): I upgraded to V0.52.2 in the hope that maybe it was fixed, but the phenomenon remained the same.
I can't upgrade from V0.49 at this point, so could you please investigate?

"
2402052499,issue,closed,not_planned,"Whether to link s3 protocol database, such as minio program",,vitaaaaa1,2024-07-11 01:57:57+00:00,[],2024-07-11 20:34:52+00:00,2024-07-11 20:34:52+00:00,https://github.com/metabase/metabase/issues/45402,"[('Type:New Feature', ''), ('.Needs Triage', '')]",[],
2402016159,issue,open,,"Always encrypt, with a default secret key if MB_ENCRYPTION_SECRET_KEY is unset","Currently, setting MB_ENCRYPTION_SECRET_KEY is optional so Metabase instances can either be encrypted or not. That means we have to handle each case in migrations (encrypted data vs not). In the past we've failed to do so, leading to many high-priority bugs and risk of corrupting data.

One solution to this is to enable encryption in every instance, using a default secret key if `MB_ENCRYPTION_SECRET_KEY` is not set.

We'd have to:
- Change `rotate-encryption-key!` to default to using the default secret key
- Change `maybe-encrypt` and `maybe-decrypt` to use the default secret key
- Create a migration that encrypts all the unencrypted data with the default secret key if MB_ENCRYPTION_SECRET_KEY is not set, with a copy of `rotate-encryption-key!`
- Provide or document a way to do encrypt and decrypt values manually, for doing manual surgery on the app DB. [More context here](https://metaboat.slack.com/archives/C013N8XL286/p1719616188723299?thread_ts=1719428120.504909&cid=C013N8XL286).

An easier alternative is to always encrypt in dev or test mode, but it still comes with risks that we ship code that only works with encrypted settings, and not unencrypted settings. That alternative was started here: https://github.com/metabase/metabase/pull/44657",calherries,2024-07-11 01:19:56+00:00,[],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/45401,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/DevEx', '')]",[],
2401873101,issue,closed,completed,Pulse card render error - getSeriesVizSettingsKey - TypeError: Cannot read property 'name' of undefined,"### Describe the bug

A question using a stacked bar chart displays fine on the web, however when it is included in an emailed pulse we get ""An error occurred while displaying this card"" in place of the graph.  In the log we get a stack trace reflecting an issue with `getSeriesVizSettingsKey` as per logs below.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

The pulse email should display the same result as web.

### Logs

[metabase-pulse-error.log](https://github.com/user-attachments/files/16169645/metabase-pulse-error.log)


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:127.0) Gecko/20100101 Firefox/127.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.218-208.862.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.11""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v0.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": ""Australia/Sydney""
    }
  }
}
```


### Severity

Blocking distribution of data to external entities.

### Additional context

_No response_",BenPhegan,2024-07-10 22:55:16+00:00,['alxnddr'],2024-08-01 22:14:15+00:00,2024-07-13 01:17:23+00:00,https://github.com/metabase/metabase/issues/45397,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2229426722, 'issue_id': 2401873101, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231963115, 'issue_id': 2401873101, 'author': 'BenPhegan', 'body': 'Thanks for your quick response @alxnddr!', 'created_at': datetime.datetime(2024, 7, 16, 23, 9, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2254945970, 'issue_id': 2401873101, 'author': 'BenPhegan', 'body': '@alxnddr Just a heads up, we are still getting the exact same error (including identical stack trace).  We have tried v0.50.13, v0.50.14 and v0.50.16, so pretty sure the fix is in place but is not addressing the root cause.  Can we reopen this issue?', 'created_at': datetime.datetime(2024, 7, 29, 4, 58, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264103975, 'issue_id': 2401873101, 'author': 'BenPhegan', 'body': '@alxnddr is it better to reopen this issue or create a new one?  As mentioned above, the issue does not seem to be resolved.', 'created_at': datetime.datetime(2024, 8, 1, 22, 14, 13, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-15 21:00:47 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

BenPhegan (Issue Creator) on (2024-07-16 23:09:43 UTC): Thanks for your quick response @alxnddr!

BenPhegan (Issue Creator) on (2024-07-29 04:58:33 UTC): @alxnddr Just a heads up, we are still getting the exact same error (including identical stack trace).  We have tried v0.50.13, v0.50.14 and v0.50.16, so pretty sure the fix is in place but is not addressing the root cause.  Can we reopen this issue?

BenPhegan (Issue Creator) on (2024-08-01 22:14:13 UTC): @alxnddr is it better to reopen this issue or create a new one?  As mentioned above, the issue does not seem to be resolved.

"
2401668764,issue,closed,completed,Snowflake RSA Private Key stored in /tmp directory on single node in load balanced setup,"### Describe the bug

When using a local file for the Snowflake RSA Private Key, the key should not be stored in a `/tmp` file. This breaks when running Metabase in load balanced mode where the private key is only available on the node where the connection was originally created.

### To Reproduce

Run Metabase in load balanced setup with multiple nodes/pods. Create a Snowflake database connection using a local private key. Attempt to query Snowflake. You'll see this error if you are serviced by a pod that doesn't have the `/tmp` private key file.

```
Private key provided is invalid or not supported: /tmp/metabase-secret_5371015221724238340.tmp: null
```

### Expected behavior

If possible, it would be good to bypass the `/tmp` file pointer to the private key. If you look in the contents of `/tmp/metabase-secret_5371015221724238340.tmp` it's just a file path to the private key not the actual contents of the key.

### Logs

Private key provided is invalid or not supported: /tmp/metabase-secret_5371015221724238340.tmp: null

### Information about your Metabase installation

```JSON
Metabase 1.50.11. Postgres backend. Snowflake data warehouse. Running on EKS with 3 pods.
```


### Severity

Blocking us from using Snowflake as a Pro customer

### Additional context

_No response_",troyharvey,2024-07-10 20:39:09+00:00,['noahmoss'],2024-08-23 13:49:25+00:00,2024-08-22 18:08:22+00:00,https://github.com/metabase/metabase/issues/45393,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Snowflake', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2223683753, 'issue_id': 2401668764, 'author': 'troyharvey', 'body': 'Thanks for working on this @escherize! If you need to hop on a call for me to demonstrate or have any questions just let me know. Fellow Escher fan ðŸ™Œ', 'created_at': datetime.datetime(2024, 7, 11, 19, 2, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2234174012, 'issue_id': 2401668764, 'author': 'escherize', 'body': ""Hey Troy, I am going to have a fix for this out soon. \r\n\r\n\r\n~In the meantime there is a quick fix that while not ideal should have your snowflake connections working again.~\r\n\r\n~If you are able to put the file containing your RSA Key on each cluster at the same path, then that should sidestep this issue.~\r\n\r\n~Another quick fix would be to upload the key instead of using a local one, if you tried that and it didn't work can you give me some more info?~\r\n\r\n----\r\n\r\nThanks for the chat today Troy. We determined that those quick fixes do not help, and I have a better understanding of where that issue is coming from."", 'created_at': datetime.datetime(2024, 7, 17, 20, 11, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250707796, 'issue_id': 2401668764, 'author': 'troyharvey', 'body': 'Hey @escherize! Checking in to see if there are any updates on this one.', 'created_at': datetime.datetime(2024, 7, 25, 15, 35, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250732535, 'issue_id': 2401668764, 'author': 'perivamsi', 'body': ""Moving this to QPD after discussion with Bryan\r\n\r\nHere's a doc Bryan wrote summarizing the current state: https://www.notion.so/metabase/Snowflake-RSA-Key-HA-setup-secrets-a9c53a10ffb443969a0f783387027a8d"", 'created_at': datetime.datetime(2024, 7, 25, 15, 42, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250734410, 'issue_id': 2401668764, 'author': 'perivamsi', 'body': ""@troyharvey we don't have a fix for this yet, sorry. will keep you posted."", 'created_at': datetime.datetime(2024, 7, 25, 15, 43, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260850737, 'issue_id': 2401668764, 'author': 'dpsutton', 'body': 'I\'ve got some news.\r\n\r\nEverything works as expected with passwords, and with upload files (please confirm or dispute). I can recreate this locally in a cluster. \r\n\r\nThe great thing is I can recreate this locally _without a cluster at all_. And it\'s because there\'s nothing special about the ""other"" instances. Restarting a single process is enough to make it behave as a second instance in a cluster.\r\n\r\nThe gist is that we memoize some information when you point it to the local file. We correctly check that we can connect and that information stays around. \r\n\r\nI suspect it\'s in this function that we memoize\r\n\r\n```clojure\r\n(def\r\n  ^java.io.File\r\n  ^{:arglists \'([{:keys [connection-property-name id value] :as secret} & [driver? ext?]])}\r\n  value->file!\r\n  ""Returns the value of the given `secret` instance in the form of a file. If the given instance has a `:file-path` as\r\n  its source, a `File` referring to that is returned. Otherwise, the `:value` is written to a temporary file, which is\r\n  then returned.\r\n\r\n  `driver?` is an optional argument that is only used if an ostensibly existing file value (i.e. `:file-path`) can\'t be\r\n  resolved, in order to render a more user-friendly error message (by looking up the display names of the connection\r\n  properties involved).\r\n\r\n  `ext?` is an optional argument that sets the file extension used for the temporary file, if one needs to be created.""\r\n  (memoize/memo\r\n   (with-meta value->file!*\r\n     {::memoize/args-fn (fn [[secret _driver? ext?]]\r\n                          ;; not clear if value->string could return nil due to the cond so we\'ll just cache on a key\r\n                          ;; that is unique\r\n                          [(vec (:value secret)) ext?])})))\r\n```\r\n\r\n\r\nIn the cluster setup, when it was ""good"" (on the machine that configured the db connection):\r\n\r\n```clojure\r\nsnowflake=> (let [details (:details (toucan2.core/select-one :model/Database :id 3))]\r\n              (select-keys (sql-jdbc.conn/connection-details->spec :snowflake details) [:private_key_file :connection-uri]))\r\n{:private_key_file #object[java.io.File 0x31bebf2a ""snowflake.key""],\r\n :connection-uri\r\n ""jdbc:snowflake://host?user=USER&private_key_file=%2Fapp%2Fsnowflake.key""}\r\n```\r\n\r\nOn the other instance in the cluster i see\r\n\r\n```clojure\r\nsnowflake=> (let [details (:details (toucan2.core/select-one :model/Database :id 3))]\r\n              (select-keys (sql-jdbc.conn/connection-details->spec :snowflake details) [:private_key_file :connection-uri]))\r\n{:private_key_file #object[java.io.File 0x60d9f23a ""/tmp/metabase-secret_4021735193230304791.tmp""],\r\n :connection-uri\r\n ""jdbc:snowflake://host?user=USER&private_key_file=%2Ftmp%2Fmetabase-secret_4021735193230304791.tmp""}\r\n```\r\n\r\nbut you can recreate this in a regular dev setup by configuring a local file path, seeing the query succeeds, restarting the process, and seeing that the query fails.\r\n\r\nI would check the differences in what happens in `defmethod driver/can-connect? :snowflake` and `defmethod sql-jdbc.conn/connection-details->spec :snowflake`. My guess is that we changed how secrets work and never updated the snowflake implementation, just the stuff in the core app.', 'created_at': datetime.datetime(2024, 7, 31, 15, 55, 22, tzinfo=datetime.timezone.utc)}]","troyharvey (Issue Creator) on (2024-07-11 19:02:55 UTC): Thanks for working on this @escherize! If you need to hop on a call for me to demonstrate or have any questions just let me know. Fellow Escher fan ðŸ™Œ

escherize on (2024-07-17 20:11:17 UTC): Hey Troy, I am going to have a fix for this out soon. 


~In the meantime there is a quick fix that while not ideal should have your snowflake connections working again.~

~If you are able to put the file containing your RSA Key on each cluster at the same path, then that should sidestep this issue.~

~Another quick fix would be to upload the key instead of using a local one, if you tried that and it didn't work can you give me some more info?~

----

Thanks for the chat today Troy. We determined that those quick fixes do not help, and I have a better understanding of where that issue is coming from.

troyharvey (Issue Creator) on (2024-07-25 15:35:30 UTC): Hey @escherize! Checking in to see if there are any updates on this one.

perivamsi on (2024-07-25 15:42:59 UTC): Moving this to QPD after discussion with Bryan

Here's a doc Bryan wrote summarizing the current state: https://www.notion.so/metabase/Snowflake-RSA-Key-HA-setup-secrets-a9c53a10ffb443969a0f783387027a8d

perivamsi on (2024-07-25 15:43:33 UTC): @troyharvey we don't have a fix for this yet, sorry. will keep you posted.

dpsutton on (2024-07-31 15:55:22 UTC): I've got some news.

Everything works as expected with passwords, and with upload files (please confirm or dispute). I can recreate this locally in a cluster. 

The great thing is I can recreate this locally _without a cluster at all_. And it's because there's nothing special about the ""other"" instances. Restarting a single process is enough to make it behave as a second instance in a cluster.

The gist is that we memoize some information when you point it to the local file. We correctly check that we can connect and that information stays around. 

I suspect it's in this function that we memoize

```clojure
(def
  ^java.io.File
  ^{:arglists '([{:keys [connection-property-name id value] :as secret} & [driver? ext?]])}
  value->file!
  ""Returns the value of the given `secret` instance in the form of a file. If the given instance has a `:file-path` as
  its source, a `File` referring to that is returned. Otherwise, the `:value` is written to a temporary file, which is
  then returned.

  `driver?` is an optional argument that is only used if an ostensibly existing file value (i.e. `:file-path`) can't be
  resolved, in order to render a more user-friendly error message (by looking up the display names of the connection
  properties involved).

  `ext?` is an optional argument that sets the file extension used for the temporary file, if one needs to be created.""
  (memoize/memo
   (with-meta value->file!*
     {::memoize/args-fn (fn [[secret _driver? ext?]]
                          ;; not clear if value->string could return nil due to the cond so we'll just cache on a key
                          ;; that is unique
                          [(vec (:value secret)) ext?])})))
```


In the cluster setup, when it was ""good"" (on the machine that configured the db connection):

```clojure
snowflake=> (let [details (:details (toucan2.core/select-one :model/Database :id 3))]
              (select-keys (sql-jdbc.conn/connection-details->spec :snowflake details) [:private_key_file :connection-uri]))
{:private_key_file #object[java.io.File 0x31bebf2a ""snowflake.key""],
 :connection-uri
 ""jdbc:snowflake://host?user=USER&private_key_file=%2Fapp%2Fsnowflake.key""}
```

On the other instance in the cluster i see

```clojure
snowflake=> (let [details (:details (toucan2.core/select-one :model/Database :id 3))]
              (select-keys (sql-jdbc.conn/connection-details->spec :snowflake details) [:private_key_file :connection-uri]))
{:private_key_file #object[java.io.File 0x60d9f23a ""/tmp/metabase-secret_4021735193230304791.tmp""],
 :connection-uri
 ""jdbc:snowflake://host?user=USER&private_key_file=%2Ftmp%2Fmetabase-secret_4021735193230304791.tmp""}
```

but you can recreate this in a regular dev setup by configuring a local file path, seeing the query succeeds, restarting the process, and seeing that the query fails.

I would check the differences in what happens in `defmethod driver/can-connect? :snowflake` and `defmethod sql-jdbc.conn/connection-details->spec :snowflake`. My guess is that we changed how secrets work and never updated the snowflake implementation, just the stuff in the core app.

"
2401475067,issue,open,,Unify the api key used for `api/notify` with the new api keys,"We have a user-provided api key for `api/notify`, allowing people to programatically hit the endpoints
- `POST api/notify/db/:id`
- `POST ""/db/:id/new-table""`

The endpoints let users sync databases when they like, and do not require a user session token to do so. This mechanism was built a long time ago and is seeded in the env with a key of the user's choosing.

> This endpoint is secured by an API key that needs to be passed as a `X-METABASE-APIKEY` header which needs to be defined in   the `MB_API_KEY` [environment variable](https://www.metabase.com/docs/latest/configuring-metabase/environment-variables.html#mb_api_key)

We added api keys to enable precisely this kind of interaction so we could deprecate and remove this feature. 

Ideally we allow new api keys to hit these endpoints in 51, and log a warning if an _old_ api key hits this in 51. And then in 52 remove the old api key in totality.

NOTE: there is one feature that the old style api key allows that the new ones do not: knowing what an api key before instance creation or without any admin action in the UI. To obtain a new style api key, you must log in with an admin account and get the secret key. The old key could be decided on beforehand and set at startup (`MB_API_KEY=kittens java -jar metabase.jar`). ",dpsutton,2024-07-10 19:13:56+00:00,[],2024-07-12 09:42:33+00:00,,https://github.com/metabase/metabase/issues/45386,"[('Misc/API', ''), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2222215236, 'issue_id': 2401475067, 'author': 'piranha', 'body': 'Why remove old api keys rather than unify them under the same mechanics?', 'created_at': datetime.datetime(2024, 7, 11, 7, 19, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2223115500, 'issue_id': 2401475067, 'author': 'dpsutton', 'body': ""The older style keys are set in the environment and cannot be disabled (absent restarting the process without the key in the env) nor do they have complexity requirements. They only allow access to the `api/notify` endpoints. The new keys are configured through the UI and allow api access to all routes. They can be rotated and revoked. They are seen once and then may be regenerated but not seen again.\r\n\r\nI'm not sure what unifying the two means here."", 'created_at': datetime.datetime(2024, 7, 11, 14, 39, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225210158, 'issue_id': 2401475067, 'author': 'piranha', 'body': ""Just thought that ability to seed API key without looking at interface is quite useful. But given that you have to know serial DB id it doesn't seem that necessary after some thinking."", 'created_at': datetime.datetime(2024, 7, 12, 9, 42, 32, tzinfo=datetime.timezone.utc)}]","piranha on (2024-07-11 07:19:29 UTC): Why remove old api keys rather than unify them under the same mechanics?

dpsutton (Issue Creator) on (2024-07-11 14:39:39 UTC): The older style keys are set in the environment and cannot be disabled (absent restarting the process without the key in the env) nor do they have complexity requirements. They only allow access to the `api/notify` endpoints. The new keys are configured through the UI and allow api access to all routes. They can be rotated and revoked. They are seen once and then may be regenerated but not seen again.

I'm not sure what unifying the two means here.

piranha on (2024-07-12 09:42:32 UTC): Just thought that ability to seed API key without looking at interface is quite useful. But given that you have to know serial DB id it doesn't seem that necessary after some thinking.

"
2401424530,issue,open,,Reduce bundle size of SDK,"**Is your feature request related to a problem? Please describe.**
Right now, `@metabase/embedding-sdk-react@^0.1.16` has a bundle size of Ëœ10MB. Customers would like to see the bundle size reduced.

**Describe the solution you'd like**
Smaller bundle size

**Describe alternatives you've considered**
None

**How important is this feature to you?**

**Additional context**
Add any other context or screenshots about the feature request here.
",albertoperdomo,2024-07-10 18:42:10+00:00,[],2024-07-10 18:42:11+00:00,,https://github.com/metabase/metabase/issues/45383,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2401419200,issue,open,,Peer dependency warnings when running npm install @metabase/embedding-sdk-react,"### Describe the bug

```
npm warn node_modules/react
npm warn   peer react@""^16.6.3 || ^17.0.0"" from react-virtual@2.10.4
npm warn   node_modules/kbar/node_modules/react-virtual
npm warn     react-virtual@""^2.8.2"" from kbar@0.1.0-beta.45
npm warn     node_modules/kbar
npm warn
npm warn Could not resolve dependency:
npm warn peer react@""^0.14.0 || ^15.0.0 || ^16.0.0"" from react-router@3.2.6
npm warn node_modules/react-router
npm warn   react-router@""3"" from @metabase/embedding-sdk-react@0.1.16
npm warn   node_modules/@metabase/embedding-sdk-react
npm warn
npm warn Conflicting peer dependency: react@16.14.0
npm warn node_modules/react
npm warn   peer react@""^0.14.0 || ^15.0.0 || ^16.0.0"" from react-router@3.2.6
npm warn   node_modules/react-router
npm warn     react-router@""3"" from @metabase/embedding-sdk-react@0.1.16
npm warn     node_modules/@metabase/embedding-sdk-react
```

### To Reproduce

`yarn add react@^18 react-dom@^18 @types/react @types/react-dom @metabase/embedding-sdk-react@^0.1.16`

### Expected behavior

Ideally there are no dependency warnings

### Logs

_No response_

### Information about your Metabase installation

```JSON
- @metabase/embedding-sdk-react@^0.1.16
```


### Severity

P3

### Additional context

_No response_",albertoperdomo,2024-07-10 18:38:42+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/45382,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2324882395, 'issue_id': 2401419200, 'author': 'albertoperdomo', 'body': ""This isn't necessarily a bug, but it would be nice to be able to get rid of these."", 'created_at': datetime.datetime(2024, 9, 2, 14, 29, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473066353, 'issue_id': 2401419200, 'author': 'npretto', 'body': ""Related:  [[Task] Remove dependencies that we don't need in the package.json of the sdk](https://github.com/metabase/metabase/issues/49655)"", 'created_at': datetime.datetime(2024, 11, 13, 10, 8, 29, tzinfo=datetime.timezone.utc)}]","albertoperdomo (Issue Creator) on (2024-09-02 14:29:03 UTC): This isn't necessarily a bug, but it would be nice to be able to get rid of these.

npretto on (2024-11-13 10:08:29 UTC): Related:  [[Task] Remove dependencies that we don't need in the package.json of the sdk](https://github.com/metabase/metabase/issues/49655)

"
2401386014,issue,closed,completed,Automatically mark FKs for test data drivers like BigQuery that don't actually have real FKs,This way we can run tests that rely on implicit joins. We have `mt/with-mock-fks-for-drivers-without-fk-constraints` but you have to use it on each individual test. It would be nice to eliminate the need for this ,camsaul,2024-07-10 18:17:29+00:00,[],2024-10-08 16:20:19+00:00,2024-07-19 11:55:12+00:00,https://github.com/metabase/metabase/issues/45381,"[('Type:Tech Debt', 'or Refactoring'), ('.CI & Tests', ''), ('.Backend', '')]","[{'comment_id': 2221364945, 'issue_id': 2401386014, 'author': 'camsaul', 'body': 'Should be fixed by #44894 ?', 'created_at': datetime.datetime(2024, 7, 10, 20, 18, 53, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-07-10 20:18:53 UTC): Should be fixed by #44894 ?

"
2401317463,issue,closed,not_planned,[Epic] Core flows review and improvements,,luizarakaki,2024-07-10 17:32:42+00:00,[],2024-11-20 18:30:24+00:00,2024-11-20 18:30:24+00:00,https://github.com/metabase/metabase/issues/45379,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2401220410,issue,closed,completed,Test data loading should be smart enough to reload data when needed automatically,"The H2 test data loading code is smart enough to reload the data if it was created in a different session (since itâ€™s an in-memory database. 

We should have BigQuery and Redshift be smart too since these get deleted every few hours in automatic cleanup -- figure out that the DB is gone upstream and recreate it automatically next time you try to use it, ideally in place (using the same `Database`) so you don't lose any test Cards using that DB

We should also do this for DBs we run locally with Docker images, if the Docker image gets nuked and restarted, it should be smart enough to figure it out there too.

It would be good to come up with a general way to do this as opposed to having to write custom code for each driver.",camsaul,2024-07-10 16:37:53+00:00,['camsaul'],2024-10-08 16:20:28+00:00,2024-07-18 04:06:13+00:00,https://github.com/metabase/metabase/issues/45378,"[('Type:Tech Debt', 'or Refactoring'), ('.CI & Tests', ''), ('.Backend', '')]",[],
2401159315,issue,open,,[Epic] Optimize Embedding SDK package size,"**Links**
- feature branch: `branch-name` _this should be the feature branch where this work will be done in. PRs will be delivered against this branch_

**Context**
We have some feedback that SDK is too heavy in it's size. We should try to optimize amount of code and assets we bundle into the SDK.
SDK is enabled with tree-shaking when we build it, so we already strip-out most of code we don't use, but there is still a lot of improvements that we can implement to enable deeper tree-shaking optimizations, and remove code that is not needed for the SDK.

**Implementation Plan**
Please do initial research and suggest implementation plan.

***Milestone 1***
_insert tasklist here_


",deniskaber,2024-07-10 16:06:30+00:00,[],2025-02-04 20:25:56+00:00,,https://github.com/metabase/metabase/issues/45375,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2330964146, 'issue_id': 2401159315, 'author': 'npretto', 'body': ""I'm not sure three-shaking is working because of the barrel files and the way we import things, I found this plugin that may be helpful though: https://github.com/ts-plugin/ts-import-plugin#readme"", 'created_at': datetime.datetime(2024, 9, 5, 8, 50, 30, tzinfo=datetime.timezone.utc)}]","npretto on (2024-09-05 08:50:30 UTC): I'm not sure three-shaking is working because of the barrel files and the way we import things, I found this plugin that may be helpful though: https://github.com/ts-plugin/ts-import-plugin#readme

"
2401031913,issue,closed,completed,Serialization should not stop on an error,"We should provide a way for serialization to continue even if an error arises: not every error, this error could be as trivial as an archived card having stale data in `dataset_query`.

- it should be a limit of errors to happen (possibly unlimited)
- serialization should provide a report in the end
- snowplow event should have indication how many errors happened",piranha,2024-07-10 15:08:05+00:00,['piranha'],2024-08-12 17:51:50+00:00,2024-08-12 09:46:37+00:00,https://github.com/metabase/metabase/issues/45371,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]",[],
2400993112,issue,closed,not_planned,Migration error on PostgreSQL 11.22,"https://github.com/metabase/metabase/blame/d814074bea5b697868d2bf494fd44da827a122e7/resources/migrations/001_update_migrations.yaml#L6495

Hi! I guess this change is not compatible with Postgres 11.22 and would work only starting from version 12. Metabase docs say that the product is compatible with PostgreSQL 9.0 and higher, so to keep this a valid point I think a fix is needed. Here is the error we get starting from yesterday, after automatic upgrade:

```
ERROR:  syntax error at or near ""("" at character 87
STATEMENT:  ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
	  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
	) STORED
```
Let me know if you are planning to keep it compatible with older PostgreSQL versions. If not, I would suggest to update the docs.",entvia,2024-07-10 14:50:56+00:00,[],2024-07-11 10:55:13+00:00,2024-07-11 06:31:34+00:00,https://github.com/metabase/metabase/issues/45367,[],"[{'comment_id': 2220974505, 'issue_id': 2400993112, 'author': 'camsaul', 'body': ""Our general policy is to only officially support databases that are supported upstream. [Postgres 11 was EOL'ed in November 2023](https://endoflife.date/postgresql), so we're not officially supporting it anymore. Which doc page did you see where it said we support 9+? We'll update it."", 'created_at': datetime.datetime(2024, 7, 10, 16, 30, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220975366, 'issue_id': 2400993112, 'author': 'camsaul', 'body': ""CC @jeff303 -- let's update the documentation about supported versions of Postgres"", 'created_at': datetime.datetime(2024, 7, 10, 16, 31, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221820863, 'issue_id': 2400993112, 'author': 'notrom', 'body': ""I agree, only supporting supported versions makes a lot of sense. But a heads up in the release notes would have been nice. Worth noting that v0.48 release notes had a section about no longer supporting Postgres lower than 9.5. https://www.metabase.com/releases/metabase-48 \r\n\r\n> # Postgres as app db for Metabase must be 9.5 or higher\r\n> If youâ€™re using Postgres as your application database for Metabase, youâ€™ll need to upgrade to Postgres version 9.5 or higher before you upgrade your Metabase to 48.\r\n\r\nI tripped up on this one myself today when trying to upgrade from v0.49.7 to v0.50.11. No excuses, this one's on me for not keeping Postgres up to date."", 'created_at': datetime.datetime(2024, 7, 11, 1, 34, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222625217, 'issue_id': 2400993112, 'author': 'entvia', 'body': 'Hi @camsaul and @jeff303! Thank you for a fast reply and clarification.\r\nHere is the link https://www.metabase.com/docs/latest/installation-and-operation/migrating-from-h2#supported-databases-for-storing-your-metabase-application-data \r\nSo, this is present also in the docs of the latest version.', 'created_at': datetime.datetime(2024, 7, 11, 10, 55, 12, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-07-10 16:30:34 UTC): Our general policy is to only officially support databases that are supported upstream. [Postgres 11 was EOL'ed in November 2023](https://endoflife.date/postgresql), so we're not officially supporting it anymore. Which doc page did you see where it said we support 9+? We'll update it.

camsaul on (2024-07-10 16:31:01 UTC): CC @jeff303 -- let's update the documentation about supported versions of Postgres

notrom on (2024-07-11 01:34:05 UTC): I agree, only supporting supported versions makes a lot of sense. But a heads up in the release notes would have been nice. Worth noting that v0.48 release notes had a section about no longer supporting Postgres lower than 9.5. https://www.metabase.com/releases/metabase-48 


I tripped up on this one myself today when trying to upgrade from v0.49.7 to v0.50.11. No excuses, this one's on me for not keeping Postgres up to date.

entvia (Issue Creator) on (2024-07-11 10:55:12 UTC): Hi @camsaul and @jeff303! Thank you for a fast reply and clarification.
Here is the link https://www.metabase.com/docs/latest/installation-and-operation/migrating-from-h2#supported-databases-for-storing-your-metabase-application-data 
So, this is present also in the docs of the latest version.

"
2400840086,issue,closed,completed,Duplicate a tab on dashboard only works once per dashboard,"### Describe the bug

I can make a duplicate of a dashboard tab only a single time. When trying to make another duplicate (of the same tab or another tab), nothing happens.  
Deleting the first tab doesn't work either.

Even after saving the dashboard, refreshing the browser window, and opening the dashboard again, duplicate/delete doesn't work.

I managed to delete the first tab when opening the dashboard in an Incognito window. However, this workaround does NOT work for our real (more complicated) dashboards.

### To Reproduce

1. New dashbaord
2. Add a text element to the first (and only) tab ""Tab 1""
3. Duplicate the tab      
    ![image](https://github.com/metabase/metabase/assets/18148910/b2789044-d637-4321-be18-c143f8606c0e)
4. --> Now I have two tabs: ""Tab 1"" and ""Copy of Tab 1""      
![image](https://github.com/metabase/metabase/assets/18148910/efb5799a-39ce-4d95-b558-ee0e8f5e66f7)
5. Try to create another duplicate of ""Tab 1""  
    ![image](https://github.com/metabase/metabase/assets/18148910/6430e7aa-8e78-4759-92db-96bf1b3f4155)
6. --> Nothing happens

And to delete:
7. Try to delete ""Tab 1""  
    ![image](https://github.com/metabase/metabase/assets/18148910/612377cc-fc4b-4b99-884f-43b150913ff6)
8. --> Nothing happens

Retry delete:
9. Save the dashboard
10. Refresh the browser
11. Open dashboard in edit mode
12. Try to delete ""Tab 1""
13. --> Nothing happens

### Expected behavior

Duplication and deletion should work without the need to open a new Incognito browser window after each operation.

### Logs

Just clicking the pencil to ""Edit the dashboard"" already gives errors in the browser:

```
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
```

When trying the second duplicate:
```
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 16
        ir
        ia
        io
        eB
        tF
        re
        n9
        n7
        n7
        n
        a8
        a6
        a4
        a4
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
        ir
        ia
        io
        eB
        tF
[use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
    r use-click-outside.js:10
    (Async: EventListener.handleEvent)
    o use-click-outside.js:17
    forEach self-hosted:157
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
    unstable_runWithPriority scheduler.production.min.js:18
    React 8
    forEach self-hosted:4280
    React 8
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 6
        ir
        ia
        io
        a$
        enqueueSetState
        setState
    __updateSize ExplicitSize.tsx:192
    Lodash 2
        M
        O
    t resize-observer.ts:12
    t resize-observer.ts:12
    t resize-observer.ts:10
3 [use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
    r use-click-outside.js:10
    (Async: EventListener.handleEvent)
    o use-click-outside.js:17
    forEach self-hosted:157
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
    unstable_runWithPriority scheduler.production.min.js:18
    React 6
    __updateSize ExplicitSize.tsx:192
    Lodash 2
    t resize-observer.ts:12
    forEach self-hosted:157
    t resize-observer.ts:12
    forEach self-hosted:157
    t resize-observer.ts:10
```

When trying to delete:
```
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
        ir
        ia
        io
        eB
        tF
[use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
    r use-click-outside.js:10
    (Async: EventListener.handleEvent)
    o use-click-outside.js:17
    forEach self-hosted:157
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 6
        ir
        ia
        io
        a$
        enqueueSetState
        setState
    __updateSize ExplicitSize.tsx:192
    Lodash 2
        M
        O
    t resize-observer.ts:12
    t resize-observer.ts:12
    t resize-observer.ts:10
3 [use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
    r use-click-outside.js:10
    (Async: EventListener.handleEvent)
    o use-click-outside.js:17
    forEach self-hosted:157
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
    unstable_runWithPriority scheduler.production.min.js:18
    React 6
    __updateSize ExplicitSize.tsx:192
    Lodash 2
    t resize-observer.ts:12
    forEach self-hosted:157
    t resize-observer.ts:12
    forEach self-hosted:157
    t resize-observer.ts:10
```

After saving, refreshing the browser window and editing again. When trying to delete:
```
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        ia
        io
        aJ
    Redux 12
        notify
        notifyNestedSubs
        i
        m
        default
        el
        el
        eF
        default
        a
        dispatch
        unsubscribe
    React 2
        r
        sn
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 13
        ir
        ia
        io
        eB
        tF
        re
        n9
        n7
        n7
        sz
        _reactRootContainer
        s_
        render
    fn app.js:68
    fl app.js:99
    32900 app-main.js:24
    Webpack 6
        a
        <anonymous>
        O
        <anonymous>
        i
        <anonymous>
[use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
Uncaught TypeError: r.hasAttribute is not a function
    r use-click-outside.js:10
    o use-click-outside.js:17
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
        ir
        ia
        io
        a$
        oW
    d use-tooltip.js:15
    React 4
        T
        r
        A
        sn
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        ia
        io
        aJ
    Redux 12
        notify
        notifyNestedSubs
        i
        m
        default
        el
        el
        eF
        default
        a
        dispatch
        unsubscribe
    React 2
        r
        sn
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 13
        ir
        ia
        io
        eB
        tF
        re
        n9
        n7
        n7
        sz
        _reactRootContainer
        s_
        render
    fn app.js:68
    fl app.js:99
    32900 app-main.js:24
    Webpack 6
        a
        <anonymous>
        O
        <anonymous>
        i
        <anonymous>
3 [use-click-outside.js:10:63](webpack:///node_modules/@mantine/hooks/esm/use-click-outside/use-click-outside.js)
    r use-click-outside.js:10
    (Async: EventListener.handleEvent)
    o use-click-outside.js:17
    forEach self-hosted:157
    o use-click-outside.js:17
    sn React
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
        ir
        ia
        io
        a$
        oW
    d use-tooltip.js:15
    React 4
        T
        r
    (Async: EventListener.handleEvent)
        A
        sn
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        ia
        io
        aJ
    Redux 12
        notify
        notifyNestedSubs
        i
        m
        default
        el
    (Async: VoidFunction)
        el
        eF
        default
        a
        dispatch
        unsubscribe
    React 2
        r
        sn
    unstable_runWithPriority scheduler.production.min.js:18
    React 4
        ir
        se
        aK
        ia
    unstable_runWithPriority scheduler.production.min.js:18
    React 8
        ir
        ia
        io
        eB
        tF
    (Async: EventListener.handleEvent)
        re
        n9
        n7
    forEach self-hosted:4280
    React 5
        n7
        sz
        _reactRootContainer
        s_
        render
    fn app.js:68
    fl app.js:99
    32900 app-main.js:24
    Webpack 6
        a
        <anonymous>
        O
        <anonymous>
        i
        <anonymous>
```

No message in the server log.

### Information about your Metabase installation

```
- Firefox 127.0.2
- Windows 11
- Postgres 14
- Metabase 0.50.11
- Metabase internal database: Postgres 14
```


### Severity

Blocks dashboard creators
",janfrederik,2024-07-10 13:54:17+00:00,['EmmadUsmani'],2024-08-02 09:00:35+00:00,2024-08-02 09:00:35+00:00,https://github.com/metabase/metabase/issues/45364,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2221893348, 'issue_id': 2400840086, 'author': 'EmmadUsmani', 'body': ""Hi @janfrederik, thanks for reporting this issue. I'm currently working on a fix that will hopefully be included in version 50.12 next Tuesday. For now, could you try using Metabase in Chrome? I believe this issue only impacts Firefox"", 'created_at': datetime.datetime(2024, 7, 11, 2, 55, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222751978, 'issue_id': 2400840086, 'author': 'janfrederik', 'body': ""@EmmadUsmani \r\nThank you for the fast response. Indeed, it works perfectly in Chrome.  \r\nDidn't know the browser/javascript would be so different between browsers ;-)"", 'created_at': datetime.datetime(2024, 7, 11, 12, 3, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2237811887, 'issue_id': 2400840086, 'author': 'EmmadUsmani', 'body': '@janfrederik No problem! The fix has been backported to the v50 release branch, so the issue will no longer appear in the next v50 minor release, which is tentatively scheduled for next Tuesday July 23rd.', 'created_at': datetime.datetime(2024, 7, 19, 0, 31, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244659616, 'issue_id': 2400840086, 'author': 'janfrederik', 'body': 'Hi @EmmadUsmani,\r\nI just upgraded to 0.50.14, but the problem persists :-(\r\n\r\nhttps://github.com/user-attachments/assets/2a2433c8-e522-4add-aa49-613cd2523965', 'created_at': datetime.datetime(2024, 7, 23, 9, 4, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261269552, 'issue_id': 2400840086, 'author': 'EmmadUsmani', 'body': ""@janfrederik Sorry to hear you're still experiencing the issue :(\r\n\r\nStrangely enough I'm not able to reproduce it, below is a recording of me trying on the 0.50.14 jar and it works just fine. FWIW I am on a more recent version of firefox (in the original issue you reported using 127.0.2, I am on 129.0b9.\r\n\r\nCould you try clearing your cache? It may be that your browser has cached an older frontend bundle. If that doesn't work, maybe trying the most recent firefox version will help\r\n\r\nhttps://github.com/user-attachments/assets/57f6e2b5-b28e-4a38-9da8-be0d6e2fab8d"", 'created_at': datetime.datetime(2024, 7, 31, 19, 27, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264908880, 'issue_id': 2400840086, 'author': 'janfrederik', 'body': ""@EmmadUsmani Indeed, that works. I don't know if it is clearing the cache or upgrading Firefox (128.0.3) that did the trick.\r\nThanks for helping!"", 'created_at': datetime.datetime(2024, 8, 2, 9, 0, 35, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Assginee) on (2024-07-11 02:55:08 UTC): Hi @janfrederik, thanks for reporting this issue. I'm currently working on a fix that will hopefully be included in version 50.12 next Tuesday. For now, could you try using Metabase in Chrome? I believe this issue only impacts Firefox

janfrederik (Issue Creator) on (2024-07-11 12:03:06 UTC): @EmmadUsmani 
Thank you for the fast response. Indeed, it works perfectly in Chrome.  
Didn't know the browser/javascript would be so different between browsers ;-)

EmmadUsmani (Assginee) on (2024-07-19 00:31:39 UTC): @janfrederik No problem! The fix has been backported to the v50 release branch, so the issue will no longer appear in the next v50 minor release, which is tentatively scheduled for next Tuesday July 23rd.

janfrederik (Issue Creator) on (2024-07-23 09:04:18 UTC): Hi @EmmadUsmani,
I just upgraded to 0.50.14, but the problem persists :-(

https://github.com/user-attachments/assets/2a2433c8-e522-4add-aa49-613cd2523965

EmmadUsmani (Assginee) on (2024-07-31 19:27:09 UTC): @janfrederik Sorry to hear you're still experiencing the issue :(

Strangely enough I'm not able to reproduce it, below is a recording of me trying on the 0.50.14 jar and it works just fine. FWIW I am on a more recent version of firefox (in the original issue you reported using 127.0.2, I am on 129.0b9.

Could you try clearing your cache? It may be that your browser has cached an older frontend bundle. If that doesn't work, maybe trying the most recent firefox version will help

https://github.com/user-attachments/assets/57f6e2b5-b28e-4a38-9da8-be0d6e2fab8d

janfrederik (Issue Creator) on (2024-08-02 09:00:35 UTC): @EmmadUsmani Indeed, that works. I don't know if it is clearing the cache or upgrading Firefox (128.0.3) that did the trick.
Thanks for helping!

"
2400770683,issue,open,,No translations in the calendar widget in the dashboard,"### Describe the bug

Hello

Several versions later, there are still many errors and inconsistencies in translations. Most of these concern translations for relative dates and I see related open bugs, but I don't see a report in what follows. I use Polish translations. I checked on three of my installations and the problem is the same, also in other languages â€‹â€‹(I checked German and Spanish).
Perhaps the problem is somewhere in my installation and the settings of the system on which it is installed.

Problem:
Short day of week names in the calendar widget are not translated when in the dashboard filter. In question mode, translations are provided.

Screenshot from date filter in dashboard:
![image](https://github.com/metabase/metabase/assets/84914645/6565bb83-aee5-41a1-b371-704c2814fc23)

Screenshot from question:
![image](https://github.com/metabase/metabase/assets/84914645/8b283cf5-0c0b-4ea1-b833-5c19fc5ea5b0)

Does anyone have the same problem and managed to solve it at the system settings level, or is it a bug at the Metabase code level?



### To Reproduce

Add any date filter with calendar on dashboard.

### Expected behavior

Proper translations.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Ubuntu 22.04
Metabase run from .jar as a systemd service
Configuration database: PostgreSQL
System language: pl_PL.utf8
```


### Severity

The problem is irritating for non-english users, new features are being added but the basic functionality looks unfinished :(

### Additional context

_No response_",rciszynski,2024-07-10 13:28:46+00:00,[],2025-01-03 15:30:33+00:00,,https://github.com/metabase/metabase/issues/45362,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2400752165,issue,closed,completed,"Exception ""Unknown type of ref"" when using a division in Summarize of question","### Describe the bug

When I execute a question (or metric) with a Custom Expression as Summarize like `Sum([MyField1]) / Sum([MyField2])`, the server logs show error: ""Error saving query execution info"", caused by exception ""Unknown type of ref"".

There is no error when just doing `Sum([MyField1])`or `Sum([MyField2])`.

`Sum([MyField2])` is non-zero.

### To Reproduce

1. Add the metabase internal database as database
2. New Question based on table `metabase_database`
3. Summarize: ""Custom Expression"": `Sum([id]) / Sum([id])`
4. Visualize

Result: the error appears in the log

![image](https://github.com/metabase/metabase/assets/18148910/4acc2a69-f81e-4fb2-b83c-69fa9d23139c)


### Expected behavior

_No response_

### Logs

Browser log:
```
Cookie â€œ_sp_root_domain_test_1720617153389â€ has been rejected for invalid domain. [index.module.js:496:17](webpack:///node_modules/@snowplow/browser-tracker-core/dist/index.module.js)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n"" [core.cljs:4009:5](webpack:///target/cljs_release/cljs/core.cljs)
[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""
```

Server log:
```
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 20.5 ms (10 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (2 idle, 0 queued) (99 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 20.4 ms (7 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (99 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/collection/root 200 8.0 ms (2 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (2 idle, 0 queued) (99 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/database 200 8.6 ms (1 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (0 idle, 0 queued) (99 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/bookmark 200 4.1 ms (1 DB calls) App DB connections: 1/15 Jetty threads: 8/50 (0 idle, 0 queued) (99 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 24.3 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 7/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:35+02:00 DEBUG metabase.server.middleware.log GET /api/search 200 41.1 ms (5 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 4.6 ms (3 DB calls) App DB connections: 2/15 Jetty threads: 7/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log GET /api/search 200 59.5 ms (11 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log POST /api/dataset/query_metadata 200 68.2 ms (18 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log GET /api/dashboard/24 200 310.6 ms (57 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (1 idle, 0 queued) (100 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 63.7 ms (16 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (1 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued); postgres DB 3 connections: 0/2 (0 threads blocked) {:metabase-user-id 2}
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 ERROR metabase.query-processor.middleware.process-userland-query Error saving query execution info,clojure.lang.ExceptionInfo: Unknown type of ref {:ref [:sum {:lib/uuid ""49484458-696c-4748-bc4c-3baac64dbb31""} [:field {:base-type :type/Integer, :lib/uuid ""b99a66a0-e0c4-46ba-8233-207a7e7fedf9"", :effective-type :type/Integer} 13884]]},	at metabase.lib.equality$find_matching_column.invokeStatic(equality.cljc:293),	at metabase.lib.equality$find_matching_column.invoke(equality.cljc:249),	at metabase.lib.equality$find_matching_column.invokeStatic(equality.cljc:274),	at metabase.lib.equality$find_matching_column.invoke(equality.cljc:249),	at metabase.lib.aggregation$aggregation_column.invokeStatic(aggregation.cljc:433),	at metabase.lib.aggregation$aggregation_column.invoke(aggregation.cljc:423),	at metabase.models.field_usage$aggregation__GT_field_usage.invokeStatic(field_usage.clj:38),	at metabase.models.field_usage$aggregation__GT_field_usage.invoke(field_usage.clj:36),	at metabase.models.field_usage$stage__GT_field_usages$fn__75606.invoke(field_usage.clj:77),	at clojure.core$keep$fn__8649.invoke(core.clj:7406),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:58),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$concat$cat__5560$fn__5561.invoke(core.clj:736),	at clojure.lang.LazySeq.sval(LazySeq.java:42),	at clojure.lang.LazySeq.seq(LazySeq.java:58),	at clojure.lang.RT.seq(RT.java:535),	at clojure.core$seq__5467.invokeStatic(core.clj:139),	at clojure.core$seq__5467.invoke(core.clj:139),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG__STAR_.invokeStatic(process_userland_query.clj:50),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG__STAR_.invoke(process_userland_query.clj:42),	at metabase.query_processor.middleware.process_userland_query$save_execution_metadata_BANG_$fn__75632.invoke(process_userland_query.clj:68),	at clojure.lang.AFn.run(AFn.java:22),	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	at java.base/java.lang.Thread.run(Unknown Source)
[5e2344d9-397b-49cb-9caa-9391fe864a5c] 2024-07-10T15:11:36+02:00 DEBUG metabase.server.middleware.log GET /api/database/3 200 11.0 ms (5 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (1 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
```

### Information about your Metabase installation

```
- Firefox 127.0.2
- Windows 11
- Postgres 14
- Metabase 0.50.11
- Metabase internal database: Postgres 14
```


### Severity

annoying

### Additional context

_No response_",janfrederik,2024-07-10 13:21:39+00:00,[],2025-01-27 12:10:20+00:00,2025-01-27 12:10:18+00:00,https://github.com/metabase/metabase/issues/45361,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Unable to Reproduce', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2605993717, 'issue_id': 2400752165, 'author': 'mngr', 'body': 'I\'m unable to reproduce it when I just divide Sum([Id])/Sum(Id]) on the Accounts table.\nSo I guess the problem is either fixed or not in the division but rather something related to summing id\'s.\n<img width=""624"" alt=""Image"" src=""https://github.com/user-attachments/assets/137a7adb-9dcd-44fe-9b21-adca201d7664"" />', 'created_at': datetime.datetime(2025, 1, 22, 0, 6, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613187404, 'issue_id': 2400752165, 'author': 'paoliniluis', 'body': '@janfrederik do you still see this in 52?', 'created_at': datetime.datetime(2025, 1, 24, 18, 55, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615591066, 'issue_id': 2400752165, 'author': 'janfrederik', 'body': 'This has been resolved, indeed. Probably since the major changes in 52.', 'created_at': datetime.datetime(2025, 1, 27, 12, 10, 19, tzinfo=datetime.timezone.utc)}]","mngr on (2025-01-22 00:06:29 UTC): I'm unable to reproduce it when I just divide Sum([Id])/Sum(Id]) on the Accounts table.
So I guess the problem is either fixed or not in the division but rather something related to summing id's.
<img width=""624"" alt=""Image"" src=""https://github.com/user-attachments/assets/137a7adb-9dcd-44fe-9b21-adca201d7664"" />

paoliniluis on (2025-01-24 18:55:55 UTC): @janfrederik do you still see this in 52?

janfrederik (Issue Creator) on (2025-01-27 12:10:19 UTC): This has been resolved, indeed. Probably since the major changes in 52.

"
2400710488,issue,closed,completed,"In the dashboard picker, when creating a dashboard, the wrong dashboard is chosen when you press enter","### Describe the bug

When you go to add a question to a dashboard, and you try to create a dashboard through the modal, if you press the enter key rather than clicking select, the wrong dashboard is chosen. Pressing the enter key activates the main button on the wrong modal (the one behind the modal you're looking at).

### To Reproduce

1. Create a question.
2. Click '...' then ""Add to dashboard"".
3. Click the Dashboards tab. A dashboard may already be highlighted in blue. If not, click one to highlight it. Note the name of the highlighted dashboard. Then click ""Create a new dashboard"".
4. Enter a name for your new dashboard.
5. Press Enter (don't click).
6. You will be taken to the highlighted dashboard, not the new dashboard.

### Expected behavior

You should be taken to the new dashboard.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.11 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-05"",
      ""src_hash"": ""2e15d58efe970d258b692e724a54b6958e0ce16b"",
      ""tag"": ""v1.1.17-SNAPSHOT"",
      ""hash"": ""e72bec9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

Screencast: https://www.loom.com/share/85925cd6f9f04cfba99a5e401990ca87?sid=aa7ed458-19b0-49f4-a55c-1f586ed038e5",rafpaf,2024-07-10 13:04:59+00:00,['npfitz'],2024-07-23 19:29:03+00:00,2024-07-23 18:58:21+00:00,https://github.com/metabase/metabase/issues/45360,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2400680809,issue,open,,Incorrect font in e2e tests in CI,"### Describe the bug

Background: [Slack thread](https://metaboat.slack.com/archives/C052LBPDAF3/p1720176721037599?thread_ts=1720096231.281389&cid=C052LBPDAF3)

![image](https://github.com/metabase/metabase/assets/6830683/a1735138-eaeb-4132-8717-906ce5f34cfd)

This is how it should look like: [image](https://github.com/metabase/metabase/assets/6830683/2ef9924b-202f-499f-b10e-8b7afdfe596b)


### To Reproduce

1. Open any Replay recording from any e2e test.
2. Notice text/font looks off and shifted (i.e. not the same as locally/in prod)

or

1. Unskip this test and run it in CI https://github.com/metabase/metabase/pull/45274/files#diff-1c12d5f5d863b106eb6103df0e4c0bade6d135344abdba2a88d051bf589fbbc4R1789

### Information about your Metabase installation

master, 4db6ede44af77f1abce3186718400ddad232ace4

also v50, v49, v48 and most likely beyond


### Severity

P2
",kamilmielnik,2024-07-10 12:51:39+00:00,[],2025-02-04 20:23:39+00:00,,https://github.com/metabase/metabase/issues/45359,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.CI & Tests', ''), ('.Frontend', ''), ('.Team/DevEx', '')]","[{'comment_id': 2232926122, 'issue_id': 2400680809, 'author': 'nemanjaglumac', 'body': 'Does this happen locally or only in CI?\r\nAnd is it related to Replay or the CI environment in general?', 'created_at': datetime.datetime(2024, 7, 17, 10, 3, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233418724, 'issue_id': 2400680809, 'author': 'kamilmielnik', 'body': ""> Does this happen locally or only in CI? And is it related to Replay or the CI environment in general?\r\n\r\nOnly in CI. I never managed to reproduce it locally.\r\n\r\n> And is it related to Replay or the CI environment in general?\r\n\r\nCI environment in general.\r\nInitially there was suspicion that Replay may be involved, because disabling it made font-related tests pass in CI.\r\nIt's unclear why tests passed. However screenshots showed that font was not loaded, so it looks like Replay is not a factor here (`reproductions-3.cy.spec.js` unexpectedly passed [in this job](https://github.com/metabase/metabase/actions/runs/9793750039/job/27043917738) with Replay disabled, and [here are screenshots](https://github.com/metabase/metabase/actions/runs/9793750039/artifacts/1668007294) from that run showing wrong font)."", 'created_at': datetime.datetime(2024, 7, 17, 14, 6, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2456815829, 'issue_id': 2400680809, 'author': 'kamilmielnik', 'body': ""Works correctly locally in headless mode too.\n\n[Changing font file format](https://github.com/metabase/metabase/commit/ede30e5545208c7f3db2f4ceacff64bd0597aebb) didn't help.\n\nThese look similar:\n- https://github.com/percy/percy-cypress/issues/312 \n- https://github.com/cypress-io/cypress/issues/23485"", 'created_at': datetime.datetime(2024, 11, 5, 10, 35, 37, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-17 10:03:10 UTC): Does this happen locally or only in CI?
And is it related to Replay or the CI environment in general?

kamilmielnik (Issue Creator) on (2024-07-17 14:06:51 UTC): Only in CI. I never managed to reproduce it locally.


CI environment in general.
Initially there was suspicion that Replay may be involved, because disabling it made font-related tests pass in CI.
It's unclear why tests passed. However screenshots showed that font was not loaded, so it looks like Replay is not a factor here (`reproductions-3.cy.spec.js` unexpectedly passed [in this job](https://github.com/metabase/metabase/actions/runs/9793750039/job/27043917738) with Replay disabled, and [here are screenshots](https://github.com/metabase/metabase/actions/runs/9793750039/artifacts/1668007294) from that run showing wrong font).

kamilmielnik (Issue Creator) on (2024-11-05 10:35:37 UTC): Works correctly locally in headless mode too.

[Changing font file format](https://github.com/metabase/metabase/commit/ede30e5545208c7f3db2f4ceacff64bd0597aebb) didn't help.

These look similar:
- https://github.com/percy/percy-cypress/issues/312 
- https://github.com/cypress-io/cypress/issues/23485

"
2400640985,issue,closed,completed,`useIsTruncated` gives incorrect results,"### Describe the bug

The current [`getIsTruncated`](https://github.com/metabase/metabase/blob/54c1e07/frontend/src/metabase/hooks/use-is-truncated.ts#L41-L46) implementation uses `clientHeight`/`clientWidth`/`scrollHeight`/`scrollWidth`:
- these properties are integers and so they lose precision - it means they don't account for cases where 0px < difference < 1px
- setting `width` on an element may prevent it from resizing when ellipsis is applied, so comparing the aforementioned properties won't give any useful information

Background: [Slack thread](https://metaboat.slack.com/archives/C052LBPDAF3/p1720176721037599?thread_ts=1720096231.281389&cid=C052LBPDAF3)

### To Reproduce

https://jsfiddle.net/8b14pv96/1/

-----

1. New question > Orders
2. Add breakout ""Created At"" - ""Month of year""
3. Click to edit breakout
4. Hover over truncated ""by month of year""

There should be a tooltip.

### Information about your Metabase installation

master, 4db6ede44af77f1abce3186718400ddad232ace4

### Severity

P3
",kamilmielnik,2024-07-10 12:33:41+00:00,['kamilmielnik'],2024-07-16 14:23:04+00:00,2024-07-16 13:49:49+00:00,https://github.com/metabase/metabase/issues/45358,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2400522287,issue,closed,completed,[Cache] Add e2e tests for questions and dashboards,"```[tasklist]
### Tasks
- [x] dashboard > direct > adaptive
- [x] dashboard > via database > adaptive
- [x] dashboard > via root > adaptive
- [x] dashboard > direct > duration
- [x] dashboard > via database > duration
- [x] dashboard > via root > duration
- [x] dashboard > direct > nocache
- [x] dashboard > via database > nocache
- [x] dashboard > via root > nocache
- [x] question > direct > adaptive
- [x] question > via database > adaptive
- [x] question > via root > adaptive
- [x] question > direct > duration
- [x] question > via database > duration
- [x] question > via root > duration
- [x] question > direct > nocache
- [x] question > via database > nocache
- [x] question > via root > nocache
```

```[tasklist]
### Not currently planned
- [ ] question > via root > schedule
- [ ] question > via database > schedule
- [ ] question > direct > schedule
- [ ] dashboard > via root > schedule
- [ ] dashboard > via database > schedule
- [ ] dashboard > direct > schedule
```
",rafpaf,2024-07-10 11:34:27+00:00,['rafpaf'],2024-10-08 16:14:56+00:00,2024-09-11 12:57:30+00:00,https://github.com/metabase/metabase/issues/45355,[],[],
2400393219,issue,closed,completed,Use metabase-registry for ee-extra cloud builds,,iethree,2024-07-10 10:40:49+00:00,['iethree'],2024-07-15 23:08:18+00:00,2024-07-15 23:08:18+00:00,https://github.com/metabase/metabase/issues/45353,"[('.Building & Releasing', '')]",[],
2400304601,issue,closed,completed,Window function for offset is generated incorrectly when there is a foreign key remapping in the breakout,"### Describe the bug

The intended logic of generating window function for offset() used in aggregations is to order by first breakout and partition by all the others if any.
This breaks when there is a foreign key remapping in the breakout.

### To Reproduce

1. Go to Admin settings
2. Go to Table metadata
3. Choose Sample database, Orders table
4. Click the gear icon for Product_ID
5. Set Display values to use Foreign Key and show Title
6. Start new question
7. Select Orders table from Sample database
8. Add Product ID as a breakout
9. Add `Offset(Sum([Total]), -1)` as an aggregation
10. See the SQL for LAG function generated incorrectly (it should not add a partition by Product_ID):

`SELECT
  ""source"".""PRODUCTS__via__PRODUCT_ID__TITLE"" AS ""PRODUCTS__via__PRODUCT_ID__TITLE"",
  ""source"".""PRODUCT_ID"" AS ""PRODUCT_ID"",
  LAG(SUM(""source"".""TOTAL""), 1) OVER (
    PARTITION BY ""source"".""PRODUCT_ID""
   
ORDER BY
      ""source"".""PRODUCTS__via__PRODUCT_ID__TITLE"" ASC
  ) AS ""Offset""
FROM
  (
    SELECT
      ""PRODUCTS__via__PRODUCT_ID"".""TITLE"" AS ""PRODUCTS__via__PRODUCT_ID__TITLE"",
      ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" AS ""PRODUCT_ID"",
      ""PUBLIC"".""ORDERS"".""TOTAL"" AS ""TOTAL""
    FROM
      ""PUBLIC"".""ORDERS""
     
LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""PRODUCTS__via__PRODUCT_ID"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS__via__PRODUCT_ID"".""ID""
  ) AS ""source""
GROUP BY
  ""source"".""PRODUCTS__via__PRODUCT_ID__TITLE"",
  ""source"".""PRODUCT_ID""
ORDER BY
  ""source"".""PRODUCTS__via__PRODUCT_ID__TITLE"" ASC`

<img width=""1458"" alt=""Captura de ecraÌƒ 2024-07-10, aÌ€s 11 54 04"" src=""https://github.com/metabase/metabase/assets/777800/17867bdf-f8c4-45c8-b4c0-9098d60429e7"">



### Expected behavior

It should generate the lag function with order by PRODUCTS__via__PRODUCT_ID__TITLE and PRODUCT_ID but without partition by clause.
In case there are more breakout columns, they should be added in the partition by clause.

Also, this is minor, but it seems PRODUCT_ID is also missing in the order by for the whole query.

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Produces unintended results

### Additional context

_No response_",mngr,2024-07-10 10:04:41+00:00,[],2025-02-05 20:21:44+00:00,2025-02-05 19:34:01+00:00,https://github.com/metabase/metabase/issues/45348,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2220193849, 'issue_id': 2400304601, 'author': 'nemanjaglumac', 'body': '@mngr what last version?\r\nLast version of master or the last released version `v0.50.11`?', 'created_at': datetime.datetime(2024, 7, 10, 10, 54, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220200486, 'issue_id': 2400304601, 'author': 'mngr', 'body': '@nemanjaglumac sorry, added the hash', 'created_at': datetime.datetime(2024, 7, 10, 10, 57, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2377823919, 'issue_id': 2400304601, 'author': 'mngr', 'body': 'The same problem with cumulative functions', 'created_at': datetime.datetime(2024, 9, 26, 19, 59, 47, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-10 10:54:39 UTC): @mngr what last version?
Last version of master or the last released version `v0.50.11`?

mngr (Issue Creator) on (2024-07-10 10:57:54 UTC): @nemanjaglumac sorry, added the hash

mngr (Issue Creator) on (2024-09-26 19:59:47 UTC): The same problem with cumulative functions

"
2400199365,issue,closed,completed,Passing `?limit=` twice to a question URL returns a bare 500,"### Describe the bug

When adding the `?limit=` url search parameter to a question twice, I get a bare unstyled 500 page. Even for questions that do not have a `limit` parameter defined at all.

<img width=""1474"" alt=""Screenshot 2024-07-09 at 16 51 59"" src=""https://github.com/metabase/metabase/assets/1250185/1331d955-821d-49fd-b698-137655721d36"">


### To Reproduce

1. Create any question and save it
2. Visit the question and add `?limit=1&limit=2` to the url
3. See the bare 500 page



### Expected behavior

Passing the limit url param twice is not supported, but we should either redirect to remove one of the limits, or render a more useful error page.

### Logs

_No response_

### Information about your Metabase installation

```JSON
On `master` at 6946a5d3dd122d4510cabbae407a44d1ab1e2d6b as well as on stats.
```


### Severity

P3

### Additional context

_No response_",romeovs,2024-07-10 09:14:34+00:00,[],2024-12-10 19:20:20+00:00,2024-12-09 19:25:32+00:00,https://github.com/metabase/metabase/issues/45345,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Misc/API', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2220491824, 'issue_id': 2400199365, 'author': 'piranha', 'body': ""This could be a bit more than just a problem with `limit`, every query parameter is implicitly converted to a vector internally if it's supplied a few times."", 'created_at': datetime.datetime(2024, 7, 10, 13, 18, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221349809, 'issue_id': 2400199365, 'author': 'dpsutton', 'body': ""My thinking is that we don't want to prevent the error in full generality (as @piranha says that sounds like an endless struggle) but we absolutely have to handle errors thrown at this point in the middleware.\r\n\r\n\r\n<details>\r\n<summary>Stactrace:</summary>\r\n\r\n```\r\njava.lang.IllegalArgumentException: Expected string, got clojure.lang.PersistentVector\r\n\tat clojure.core$parse_long.invokeStatic(core.clj:8165)\r\n\tat clojure.core$parse_long.invoke(core.clj:8158)\r\n\tat metabase.server.middleware.offset_paging$parse_paging_params.invokeStatic(offset_paging.clj:19)\r\n\tat metabase.server.middleware.offset_paging$parse_paging_params.invoke(offset_paging.clj:18)\r\n\tat metabase.server.middleware.offset_paging$handle_paging$fn__146009.invoke(offset_paging.clj:38)\r\n\tat metabase.server.middleware.json$wrap_streamed_json_response$fn__83890.invoke(json.clj:88)\r\n\tat ring.middleware.keyword_params$wrap_keyword_params$fn__169538.invoke(keyword_params.clj:55)\r\n\tat ring.middleware.params$wrap_params$fn__169565.invoke(params.clj:77)\r\n\tat metabase.server.middleware.misc$maybe_set_site_url$fn__121734.invoke(misc.clj:60)\r\n.clj:568)t metabase.server.middleware.session$reset_session_timeout$fn__127307.invoke(session\r\n\tat metabase.server.middleware.session$bind_current_user$fn__127265$fn__127266.invoke(session.clj:462)\r\n\tat metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)\r\n\tat metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)\r\n\tat metabase.server.middleware.session$bind_current_user$fn__127265.invoke(session.clj:461)\r\n\tat metabase.server.middleware.session$wrap_current_user_info$fn__127238.invoke(session.clj:385)\r\n\tat metabase.server.middleware.session$wrap_session_id$fn__127210.invoke(session.clj:261)\r\n\tat metabase.server.middleware.auth$wrap_static_api_key$fn__145513.invoke(auth.clj:32)\r\n\tat ring.middleware.cookies$wrap_cookies$fn__169353.invoke(cookies.clj:200)\r\n\tat metabase.server.middleware.misc$add_content_type$fn__121716.invoke(misc.clj:28)\r\n\tat metabase.server.middleware.misc$disable_streaming_buffering$fn__121742.invoke(misc.clj:77)\r\n\tat ring.middleware.gzip$wrap_gzip$fn__169403.invoke(gzip.clj:86)\r\n_id$wrap_request_id$fn__146024.invoke(request_id.clj:9)\r\n\tat metabase.server.middleware.misc$bind_request$fn__121745.invoke(misc.clj:94)\r\n\tat metabase.server.middleware.ssl$redirect_to_https_middleware$fn__146047.invoke(ssl.clj:41)\r\n\tat clojure.lang.Var.invoke(Var.java:395)\r\n\tat metabase.server$async_proxy_handler$fn__119058.invoke(server.clj:77)\r\n\tat metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)\r\n\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:563)\r\n\tat org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)\r\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)\r\nlipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)\r\n\tat org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)\r\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)\r\nutil.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n2024-07-10 13:30:09,942 ERROR metabase.server :: Unexpected exception in endpoint\r\njava.lang.IllegalArgumentException: Expected string, got clojure.lang.PersistentVector\r\n\tat clojure.core$parse_long.invokeStatic(core.clj:8165)\r\n\tat clojure.core$parse_long.invoke(core.clj:8158)\r\n\tat metabase.server.middleware.offset_paging$parse_paging_params.invokeStatic(offset_paging.clj:19)\r\n\tat metabase.server.middleware.offset_paging$parse_paging_params.invoke(offset_paging.clj:18)\r\n\tat metabase.server.middleware.offset_paging$handle_paging$fn__146009.invoke(offset_paging.clj:38)\r\n\tat metabase.server.middleware.json$wrap_streamed_json_response$fn__83890.invoke(json.clj:88)\r\n\tat ring.middleware.keyword_params$wrap_keyword_params$fn__169538.invoke(keyword_params.clj:55)\r\n\tat ring.middleware.params$wrap_params$fn__169565.invoke(params.clj:77)\r\n1734.invoke(misc.clj:60)er.middleware.misc$maybe_set_site_url$fn__12\r\n\tat metabase.server.middleware.session$reset_session_timeout$fn__127307.invoke(session.clj:568)\r\n\tat metabase.server.middleware.session$bind_current_user$fn__127265$fn__127266.invoke(session.clj:462)\r\n\tat metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)\r\n\tat metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)\r\n\tat metabase.server.middleware.session$bind_current_user$fn__127265.invoke(session.clj:461)\r\n\tat metabase.server.middleware.session$wrap_current_user_info$fn__127238.invoke(session.clj:385)\r\n\tat metabase.server.middleware.session$wrap_session_id$fn__127210.invoke(session.clj:261)\r\n\tat metabase.server.middleware.auth$wrap_static_api_key$fn__145513.invoke(auth.clj:32)\r\n\tat ring.middleware.cookies$wrap_cookies$fn__169353.invoke(cookies.clj:200)\r\n\tat metabase.server.middleware.misc$add_content_type$fn__121716.invoke(misc.clj:28)\r\nj:77)\tat metabase.server.middleware.misc$disable_streaming_buffering$fn__121742.invoke(misc.cl\r\n\tat ring.middleware.gzip$wrap_gzip$fn__169403.invoke(gzip.clj:86)\r\n\tat metabase.server.middleware.request_id$wrap_request_id$fn__146024.invoke(request_id.clj:9)\r\n\tat metabase.server.middleware.misc$bind_request$fn__121745.invoke(misc.clj:94)\r\n\tat metabase.server.middleware.ssl$redirect_to_https_middleware$fn__146047.invoke(ssl.clj:41)\r\n\tat clojure.lang.Var.invoke(Var.java:395)\r\n\tat metabase.server$async_proxy_handler$fn__119058.invoke(server.clj:77)\r\n\tat metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)\r\n\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:563)\r\n\tat org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)\r\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)\r\ntpChannel.java:501)pse.jetty.server.HttpChannel.handle(Ht\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)\r\n\tat org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)\r\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)\r\ng.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)\r\n\tat java.base/java.lang.Thread.run(Thread.java:1583)\r\n```\r\n</details>"", 'created_at': datetime.datetime(2024, 7, 10, 20, 12, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221412523, 'issue_id': 2400199365, 'author': 'piranha', 'body': ""I've been thinking that maybe if we type `limit` with malli with could have a converter from a vector to a single value in such a case. So it could be almost a general solution (provided parameter is typed and not used raw).\r\n\r\nEdit a bit later: I think our Malli transformers can be improved to handle that."", 'created_at': datetime.datetime(2024, 7, 10, 20, 42, 12, tzinfo=datetime.timezone.utc)}]","piranha on (2024-07-10 13:18:39 UTC): This could be a bit more than just a problem with `limit`, every query parameter is implicitly converted to a vector internally if it's supplied a few times.

dpsutton on (2024-07-10 20:12:15 UTC): My thinking is that we don't want to prevent the error in full generality (as @piranha says that sounds like an endless struggle) but we absolutely have to handle errors thrown at this point in the middleware.


<details>
<summary>Stactrace:</summary>

```
java.lang.IllegalArgumentException: Expected string, got clojure.lang.PersistentVector
	at clojure.core$parse_long.invokeStatic(core.clj:8165)
	at clojure.core$parse_long.invoke(core.clj:8158)
	at metabase.server.middleware.offset_paging$parse_paging_params.invokeStatic(offset_paging.clj:19)
	at metabase.server.middleware.offset_paging$parse_paging_params.invoke(offset_paging.clj:18)
	at metabase.server.middleware.offset_paging$handle_paging$fn__146009.invoke(offset_paging.clj:38)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__83890.invoke(json.clj:88)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__169538.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__169565.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__121734.invoke(misc.clj:60)
.clj:568)t metabase.server.middleware.session$reset_session_timeout$fn__127307.invoke(session
	at metabase.server.middleware.session$bind_current_user$fn__127265$fn__127266.invoke(session.clj:462)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)
	at metabase.server.middleware.session$bind_current_user$fn__127265.invoke(session.clj:461)
	at metabase.server.middleware.session$wrap_current_user_info$fn__127238.invoke(session.clj:385)
	at metabase.server.middleware.session$wrap_session_id$fn__127210.invoke(session.clj:261)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__145513.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__169353.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__121716.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__121742.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__169403.invoke(gzip.clj:86)
_id$wrap_request_id$fn__146024.invoke(request_id.clj:9)
	at metabase.server.middleware.misc$bind_request$fn__121745.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__146047.invoke(ssl.clj:41)
	at clojure.lang.Var.invoke(Var.java:395)
	at metabase.server$async_proxy_handler$fn__119058.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
lipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2024-07-10 13:30:09,942 ERROR metabase.server :: Unexpected exception in endpoint
java.lang.IllegalArgumentException: Expected string, got clojure.lang.PersistentVector
	at clojure.core$parse_long.invokeStatic(core.clj:8165)
	at clojure.core$parse_long.invoke(core.clj:8158)
	at metabase.server.middleware.offset_paging$parse_paging_params.invokeStatic(offset_paging.clj:19)
	at metabase.server.middleware.offset_paging$parse_paging_params.invoke(offset_paging.clj:18)
	at metabase.server.middleware.offset_paging$handle_paging$fn__146009.invoke(offset_paging.clj:38)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__83890.invoke(json.clj:88)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__169538.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__169565.invoke(params.clj:77)
1734.invoke(misc.clj:60)er.middleware.misc$maybe_set_site_url$fn__12
	at metabase.server.middleware.session$reset_session_timeout$fn__127307.invoke(session.clj:568)
	at metabase.server.middleware.session$bind_current_user$fn__127265$fn__127266.invoke(session.clj:462)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)
	at metabase.server.middleware.session$bind_current_user$fn__127265.invoke(session.clj:461)
	at metabase.server.middleware.session$wrap_current_user_info$fn__127238.invoke(session.clj:385)
	at metabase.server.middleware.session$wrap_session_id$fn__127210.invoke(session.clj:261)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__145513.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__169353.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__121716.invoke(misc.clj:28)
j:77)	at metabase.server.middleware.misc$disable_streaming_buffering$fn__121742.invoke(misc.cl
	at ring.middleware.gzip$wrap_gzip$fn__169403.invoke(gzip.clj:86)
	at metabase.server.middleware.request_id$wrap_request_id$fn__146024.invoke(request_id.clj:9)
	at metabase.server.middleware.misc$bind_request$fn__121745.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__146047.invoke(ssl.clj:41)
	at clojure.lang.Var.invoke(Var.java:395)
	at metabase.server$async_proxy_handler$fn__119058.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
tpChannel.java:501)pse.jetty.server.HttpChannel.handle(Ht
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
g.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:1583)
```
</details>

piranha on (2024-07-10 20:42:12 UTC): I've been thinking that maybe if we type `limit` with malli with could have a converter from a vector to a single value in such a case. So it could be almost a general solution (provided parameter is typed and not used raw).

Edit a bit later: I think our Malli transformers can be improved to handle that.

"
2400061800,issue,closed,completed,Ability to pass parameter values to static questions,Add ability to pass parameter values to static questions.,heypoom,2024-07-10 08:11:44+00:00,['heypoom'],2024-10-08 17:02:29+00:00,2024-07-15 12:40:33+00:00,https://github.com/metabase/metabase/issues/45343,[],[],
2399876568,issue,closed,not_planned,How to make a custom value as default in the dropdown list,"### Describe the bug

Hi, I am using a postgres database.
Firstly, I have created a question: Orgsprints data question
This question gives me three columns: id, name and status.
 
![image](https://github.com/metabase/metabase/assets/161418213/984db5c1-eda7-4d14-9fe6-a0c4ad9480f4)

Secondly, I have created another question: how to default orgsprint.
For this question, I am passing a parameter {{orgsprintname}}. These parameters come from the question: Orgsprints data question. I have populated the dropdown using the Orgsprints data question.
![image](https://github.com/metabase/metabase/assets/161418213/fc0176ce-aa59-4927-8fcb-a8373ba07c5d)

 
I want the default value in the dropdown to be as the row which contains status=â€™activeâ€™. 
How can I do this?
Thanks in advance.


### To Reproduce

Hi, I am using a postgres database.
Firstly, I have created a question: Orgsprints data question
This question gives me three columns: id, name and status.
 
![image](https://github.com/metabase/metabase/assets/161418213/984db5c1-eda7-4d14-9fe6-a0c4ad9480f4)

Secondly, I have created another question: how to default orgsprint.
For this question, I am passing a parameter {{orgsprintname}}. These parameters come from the question: Orgsprints data question. I have populated the dropdown using the Orgsprints data question.
![image](https://github.com/metabase/metabase/assets/161418213/fc0176ce-aa59-4927-8fcb-a8373ba07c5d)

 
I want the default value in the dropdown to be as the row which contains status=â€™activeâ€™. 
How can I do this?
Thanks in advance.



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version : v0.48.6
```


### Severity

High

### Additional context

_No response_",srikanthgarimilla1996,2024-07-10 06:35:03+00:00,[],2024-07-10 07:35:51+00:00,2024-07-10 07:35:10+00:00,https://github.com/metabase/metabase/issues/45340,"[('Type:Question', 'Please use the forum: https://discourse.metabase.com/')]","[{'comment_id': 2219771722, 'issue_id': 2399876568, 'author': 'nemanjaglumac', 'body': 'Hi @srikanthgarimilla1996, please go to https://discourse.metabase.com/ (as indicated in our ""new issue"" page). GitHub is not the place for general help questions.\r\n\r\nI don\'t know the exact scenario you\'re looking for, but maybe you can simplify this by connecting the filter to the `status` column. That way you can easily see only the active (organization?) name.\r\n\r\nThis might be interesting: https://www.metabase.com/glossary/linked_filter\r\n\r\n---\r\n\r\n> For help with installation and setup, information on how specific features work, or general questions about Metabase, please use our discussion forum.\r\n\r\n![image](https://github.com/metabase/metabase/assets/31325167/acfd9223-61ba-41f4-a44b-01a999919670)', 'created_at': datetime.datetime(2024, 7, 10, 7, 35, 10, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-10 07:35:10 UTC): Hi @srikanthgarimilla1996, please go to https://discourse.metabase.com/ (as indicated in our ""new issue"" page). GitHub is not the place for general help questions.

I don't know the exact scenario you're looking for, but maybe you can simplify this by connecting the filter to the `status` column. That way you can easily see only the active (organization?) name.

This might be interesting: https://www.metabase.com/glossary/linked_filter

---


![image](https://github.com/metabase/metabase/assets/31325167/acfd9223-61ba-41f4-a44b-01a999919670)

"
2399870950,issue,closed,not_planned,yarn build fails with Metabase with 0.50.11,"### Describe the bug

when run ""yarn build"" in the project dir, then print: 
root@iZf8zhs1taah6tauqg1dd1Z:~/metabase# yarn build
yarn run v1.22.22
$ yarn build:cljs && yarn build:js
$ yarn && yarn build-pure:cljs
$ echo $npm_execpath | grep -q yarn || echo '\033[0;33mSorry, npm is not supported. Please use Yarn (https://yarnpkg.com/).\033[0m'
[1/5] Validating package.json...
[2/5] Resolving packages...
warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^2.0.0""
warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^2.2.3""
warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^2.2.3""
warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^1.0.1""
warning Resolution field ""set-value@4.0.1"" is incompatible with requested version ""set-value@^2.0.0""
warning Resolution field ""unset-value@2.0.1"" is incompatible with requested version ""unset-value@^1.0.0""
warning Resolution field ""set-value@4.0.1"" is incompatible with requested version ""set-value@^2.0.1""
warning Resolution field ""source-map-js@1.2.0"" is incompatible with requested version ""source-map-js@^0.6.2""
warning Resolution field ""nth-check@2.0.1"" is incompatible with requested version ""nth-check@^1.0.2""
warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^2.0.0""
warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^1.0.2""
warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^6.0.1""
warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^2.2.3""
warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^6.0.1""
success Already up-to-date.
$ patch-package
patch-package 8.0.0
Applying patches...
@storybook/core-common@6.5.16 âœ”
echarts@5.5.0 âœ”
echarts@5.5.1-rc.1 âœ”
$ husky install
fatal: not a git repository (or any of the parent directories): .git
$ yarn clean-dev:cljs && shadow-cljs compile app
$ rm -rf target/cljs_dev/*
shadow-cljs - config: /root/metabase/shadow-cljs.edn
shadow-cljs - starting via ""clojure""
--- SHADOW-CLJS FAILED TO LOAD! ----------------------

This is most commonly caused by a dependency conflict.
When using deps.edn or project.clj you must ensure that all
required dependencies are provided with the correct version.

You are using shadow-cljs version: 2.27.5

The important dependencies are:

  org.clojure/clojure ""1.11.1""
  org.clojure/clojurescript ""1.11.132""
  com.google.javascript/closure-compiler-unshaded ""v20230802""

Please verify that you are loading these versions.
You can find all required dependencies here:

  https://clojars.org/thheller/shadow-cljs/versions/2.27.5

Please refer to the Guide for more information:

  https://shadow-cljs.github.io/docs/UsersGuide.html#failed-to-load

-----------------------------------------------------

The error encountered was:

Syntax error macroexpanding at (shadow/cljs/util.clj:1:1).
	at clojure.lang.Compiler.load(Compiler.java:7665)
	at clojure.lang.RT.loadResourceScript(RT.java:381)
	at clojure.lang.RT.loadResourceScript(RT.java:372)
	at clojure.lang.RT.load(RT.java:459)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.invoke(RestFn.java:551)
	at shadow.cljs.devtools.config$eval191$loading__6789__auto____192.invoke(config.clj:1)
	at shadow.cljs.devtools.config$eval191.invokeStatic(config.clj:1)
	at shadow.cljs.devtools.config$eval191.invoke(config.clj:1)
	at clojure.lang.Compiler.eval(Compiler.java:7194)
	at clojure.lang.Compiler.eval(Compiler.java:7183)
	at clojure.lang.Compiler.load(Compiler.java:7653)
	at clojure.lang.RT.loadResourceScript(RT.java:381)
	at clojure.lang.RT.loadResourceScript(RT.java:372)
	at clojure.lang.RT.load(RT.java:459)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.invoke(RestFn.java:1289)
	at shadow.cljs.devtools.cli_actual$eval173$loading__6789__auto____174.invoke(cli_actual.clj:1)
	at shadow.cljs.devtools.cli_actual$eval173.invokeStatic(cli_actual.clj:1)
	at shadow.cljs.devtools.cli_actual$eval173.invoke(cli_actual.clj:1)
	at clojure.lang.Compiler.eval(Compiler.java:7194)
	at clojure.lang.Compiler.eval(Compiler.java:7183)
	at clojure.lang.Compiler.load(Compiler.java:7653)
	at clojure.lang.RT.loadResourceScript(RT.java:381)
	at clojure.lang.RT.loadResourceScript(RT.java:372)
	at clojure.lang.RT.load(RT.java:459)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$serialized_require.invokeStatic(core.clj:6115)
	at clojure.core$requiring_resolve.invokeStatic(core.clj:6124)
	at clojure.core$requiring_resolve.invoke(core.clj:6118)
	at shadow.cljs.devtools.cli$_main$fn__166.invoke(cli.clj:70)
	at shadow.cljs.devtools.cli$_main.invokeStatic(cli.clj:69)
	at shadow.cljs.devtools.cli$_main.doInvoke(cli.clj:67)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.main$main_opt.invokeStatic(main.clj:514)
	at clojure.main$main_opt.invoke(main.clj:510)
	at clojure.main$main.invokeStatic(main.clj:664)
	at clojure.main$main.doInvoke(main.clj:616)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.main.main(main.java:40)
Caused by: java.lang.UnsupportedClassVersionError: com/google/javascript/jscomp/CompilerOptions has been compiled by a more recent version of the Java Runtime (class file version 55.0), this version of the Java Runtime only recognizes class file versions up to 52.0
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:359)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at clojure.lang.RT.classForName(RT.java:2209)
	at clojure.lang.RT.classForNameNonLoading(RT.java:2222)
	at cljs.externs$loading__6706__auto____1358.invoke(externs.clj:9)
	at cljs.externs__init.load(Unknown Source)
	at cljs.externs__init.<clinit>(Unknown Source)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at clojure.lang.RT.classForName(RT.java:2209)
	at clojure.lang.RT.classForName(RT.java:2218)
	at clojure.lang.RT.loadClassForName(RT.java:2237)
	at clojure.lang.RT.load(RT.java:449)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at cljs.env$loading__6706__auto____754.invoke(env.cljc:9)
	at cljs.env__init.load(Unknown Source)
	at cljs.env__init.<clinit>(Unknown Source)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at clojure.lang.RT.classForName(RT.java:2209)
	at clojure.lang.RT.classForName(RT.java:2218)
	at clojure.lang.RT.loadClassForName(RT.java:2237)
	at clojure.lang.RT.load(RT.java:449)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.invoke(RestFn.java:1523)
	at cljs.analyzer$loading__6706__auto____645.invoke(analyzer.cljc:9)
	at cljs.analyzer__init.load(Unknown Source)
	at cljs.analyzer__init.<clinit>(Unknown Source)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at clojure.lang.RT.classForName(RT.java:2209)
	at clojure.lang.RT.classForName(RT.java:2218)
	at clojure.lang.RT.loadClassForName(RT.java:2237)
	at clojure.lang.RT.load(RT.java:449)
	at clojure.lang.RT.load(RT.java:424)
	at clojure.core$load$fn__6908.invoke(core.clj:6162)
	at clojure.core$load.invokeStatic(core.clj:6161)
	at clojure.core$load.doInvoke(core.clj:6145)
	at clojure.lang.RestFn.invoke(RestFn.java:408)
	at clojure.core$load_one.invokeStatic(core.clj:5934)
	at clojure.core$load_one.invoke(core.clj:5929)
	at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
	at clojure.core$load_lib.invokeStatic(core.clj:5975)
	at clojure.core$load_lib.doInvoke(core.clj:5954)
	at clojure.lang.RestFn.applyTo(RestFn.java:142)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$load_libs.invokeStatic(core.clj:6017)
	at clojure.core$load_libs.doInvoke(core.clj:6001)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:669)
	at clojure.core$require.invokeStatic(core.clj:6039)
	at clojure.core$require.doInvoke(core.clj:6039)
	at clojure.lang.RestFn.invoke(RestFn.java:619)
	at shadow.cljs.util$eval263$loading__6789__auto____264.invoke(util.clj:1)
	at shadow.cljs.util$eval263.invokeStatic(util.clj:1)
	at shadow.cljs.util$eval263.invoke(util.clj:1)
	at clojure.lang.Compiler.eval(Compiler.java:7194)
	at clojure.lang.Compiler.eval(Compiler.java:7183)
	at clojure.lang.Compiler.load(Compiler.java:7653)
	... 95 more
error Command failed with exit code 1.
info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.
error Command failed with exit code 1.
info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.
error Command failed with exit code 1.
info Visit https://yarnpkg.com/en/docs/cli/run for documentation about this command.


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
OS:Debian 6.1.90-1 (2024-05-03) x86_64 GNU/Linux
java:java version ""1.8.0_411""
  Java(TM) SE Runtime Environment (build 1.8.0_411-b09)
  Java HotSpot(TM) 64-Bit Server VM (build 25.411-b09, mixed mode)
npm:v10.7.0
node: v20.15.0
yarn:v1.22.22
clj:Clojure 1.11.2
```


### Severity

entirely

### Additional context

_No response_",tumbler-x,2024-07-10 06:31:33+00:00,[],2024-07-10 10:22:00+00:00,2024-07-10 10:22:00+00:00,https://github.com/metabase/metabase/issues/45339,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2219748169, 'issue_id': 2399870950, 'author': 'nemanjaglumac', 'body': 'Please use the node version indicated in `.nvmrc`, which is `v.18.20.0`.\r\n\r\nP.S. The minimum supported Java version is 11. We recommend using Temurin.', 'created_at': datetime.datetime(2024, 7, 10, 7, 21, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220116538, 'issue_id': 2399870950, 'author': 'paoliniluis', 'body': 'Youâ€™re using Java 8 which is no longer supported', 'created_at': datetime.datetime(2024, 7, 10, 10, 21, 53, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-10 07:21:47 UTC): Please use the node version indicated in `.nvmrc`, which is `v.18.20.0`.

P.S. The minimum supported Java version is 11. We recommend using Temurin.

paoliniluis on (2024-07-10 10:21:53 UTC): Youâ€™re using Java 8 which is no longer supported

"
2399632981,issue,open,,[Athena] Improve sync field values performance,"It might not be specific to Athena at all, but it's exceptionally bad on it. A user reported that the sync process ran for ~ 48 hours https://github.com/metabase/metabase/issues/45208

I tried syncing the dev database locally, and it took 2.6 mins for a DB with 180 fields.",qnkhuat,2024-07-10 02:53:56+00:00,[],2024-07-10 07:11:00+00:00,,https://github.com/metabase/metabase/issues/45335,"[('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('Database/Athena', ''), ('.Team/Workflows', 'aka BEC')]",[],
2399554332,issue,closed,completed,"Migrations failing in 0.50.11 with: constraint ""idx_uniq_field_table_id_parent_id_name"" of relation ""metabase_field"" does not exist","### Describe the bug

Upgraded to 0.50.11 self-hosted, started getting the logs below. Downgrading to 0.50.10 fixed it.

```
2024-07-10 08:46:44,933 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:05::calherries:
     Reason: liquibase.exception.DatabaseException: ERROR: constraint ""idx_uniq_field_table_id_parent_id_name"" of relation ""metabase_field"" does not exist [Failed SQL: (0) ALTER TABLE ""public"".""metabase_field"" DROP CONSTRAINT ""idx_uniq_field_table_id_parent_id_name""]
```

### To Reproduce

1. Run 0.50.10
2. Deploy 0.50.11


### Expected behavior

The migration should not fail. Metabase should start.

### Logs

See above

### Information about your Metabase installation

```
0.50.11, self hosted as AWS ECS Fargate container using RDS Aurora PostreSQL for application database.
```


### Severity

CRITICAL

### Additional context

_No response_",michael-gratton,2024-07-10 02:01:03+00:00,[],2024-07-10 23:53:20+00:00,2024-07-10 04:47:28+00:00,https://github.com/metabase/metabase/issues/45334,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2219337402, 'issue_id': 2399554332, 'author': 'michael-gratton', 'body': 'Likely caused by https://github.com/metabase/metabase/pull/45246 ?', 'created_at': datetime.datetime(2024, 7, 10, 2, 5, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219403227, 'issue_id': 2399554332, 'author': 'calherries', 'body': ""@michael-gratton thanks for raising this so quickly. Can you try upgrading again to 0.50.11 and tell us if it succeeds? Downgrading adds the constraint again, so you shouldn't encounter the problem if you upgrade, downgrade, and upgrade a second time."", 'created_at': datetime.datetime(2024, 7, 10, 2, 42, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219453606, 'issue_id': 2399554332, 'author': 'michael-gratton', 'body': ""@calherries Can't roll forward again to 0.50.11 at the moment, since it is in production. However re-deploying to 0.50.10 didn't add `idx_uniq_field_table_id_parent_id_name` back to `metabase_field`, so I don't see rolling forward again helping."", 'created_at': datetime.datetime(2024, 7, 10, 3, 4, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219552203, 'issue_id': 2399554332, 'author': 'qnkhuat', 'body': '@michael-gratton A fix will be included in the next release; in the meantime, you can work around it by manually adding the index and then upgrading again.\r\n\r\n```sql\r\nCREATE UNIQUE INDEX idx_uniq_field_table_id_parent_id_name ON ""metabase_field"" (""table_id"", ""name"", ""parent_id"")\r\n```', 'created_at': datetime.datetime(2024, 7, 10, 4, 55, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220008430, 'issue_id': 2399554332, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.12](https://github.com/metabase/metabase/milestone/252)', 'created_at': datetime.datetime(2024, 7, 10, 9, 28, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221649740, 'issue_id': 2399554332, 'author': 'calherries', 'body': ""@michael-gratton can you share the results of this query? I'm trying to understand why there was no `idx_uniq_field_table_id_parent_id_name` constraint in your app DB.\r\n\r\n```\r\nSELECT 'CONSTRAINT' as type,\r\n       conname as name,\r\n       pg_get_constraintdef(c.oid) as definition\r\nFROM pg_constraint c\r\nJOIN pg_namespace n ON n.oid = c.connamespace\r\nJOIN pg_class cl ON cl.oid = c.conrelid\r\nWHERE cl.relname = 'metabase_table'\r\n\r\nUNION ALL\r\n\r\nSELECT 'INDEX' as type,\r\n       i.relname as name,\r\n       pg_get_indexdef(i.oid) as definition\r\nFROM pg_index x\r\nJOIN pg_class c ON c.oid = x.indrelid\r\nJOIN pg_class i ON i.oid = x.indexrelid\r\nJOIN pg_namespace n ON n.oid = c.relnamespace\r\nWHERE c.relname = 'metabase_table'\r\n\r\nORDER BY type, name;\r\n```"", 'created_at': datetime.datetime(2024, 7, 10, 22, 43, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221698014, 'issue_id': 2399554332, 'author': 'michael-gratton', 'body': 'Output of that is:\r\n\r\n| type       | name                                       | definition                                                                                                             |\r\n|------------|--------------------------------------------|------------------------------------------------------------------------------------------------------------------------|\r\n| CONSTRAINT | fk_table_ref_database_id                   | FOREIGN KEY (db_id) REFERENCES metabase_database(id) ON DELETE CASCADE                                                 |\r\n| CONSTRAINT | pk_metabase_table                          | PRIMARY KEY (id)                                                                                                       |\r\n| INDEX      | idx_metabase_table_db_id_schema            | CREATE INDEX idx_metabase_table_db_id_schema ON public.metabase_table USING btree (schema)                             |\r\n| INDEX      | idx_metabase_table_show_in_getting_started | CREATE INDEX idx_metabase_table_show_in_getting_started ON public.metabase_table USING btree (show_in_getting_started) |\r\n| INDEX      | idx_table_db_id                            | CREATE INDEX idx_table_db_id ON public.metabase_table USING btree (db_id)                                              |\r\n| INDEX      | pk_metabase_table                          | CREATE UNIQUE INDEX pk_metabase_table ON public.metabase_table USING btree (id)                                        |', 'created_at': datetime.datetime(2024, 7, 10, 23, 26, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221726715, 'issue_id': 2399554332, 'author': 'calherries', 'body': ""Thanks! That lead me to the likely culprit. The migration that adds the `idx_uniq_field_table_id_parent_id_name` included a precondition that would not add the constraint in the case where this query results in 0 rows:\r\n```\r\nSELECT count(*) FROM METABASE_FIELD GROUP BY TABLE_ID, PARENT_ID, NAME HAVING count(*) > 1\r\n```\r\nhttps://github.com/metabase/metabase/blob/cf92c8bff67bd508741c05b90db4218b827d53a2/resources/migrations/000_legacy_migrations.yaml#L5663-L5692\r\n\r\nYour app DB failed to pass this precondition and the constraint was never added.\r\n\r\nThe same is true of `metabase_table`: there's a precondition on the constraints that add `idx_uniq_table_db_id_schema_name` and `idx_uniq_table_db_id_schema_name_2col`:\r\n\r\nhttps://github.com/metabase/metabase/blob/cf92c8bff67bd508741c05b90db4218b827d53a2/resources/migrations/000_legacy_migrations.yaml#L5632-L5662\r\n\r\n You app DB also doesn't have these constraints.\r\n\r\nThe lack of `metabase_field` constraints will be addressed by [v0.50.12](https://github.com/metabase/metabase/milestone/252) but the lack of `metabase_table` constraints should be addressed. Not having those constraints increases the likelihood of bugs in the future."", 'created_at': datetime.datetime(2024, 7, 10, 23, 53, 18, tzinfo=datetime.timezone.utc)}]","michael-gratton (Issue Creator) on (2024-07-10 02:05:27 UTC): Likely caused by https://github.com/metabase/metabase/pull/45246 ?

calherries on (2024-07-10 02:42:07 UTC): @michael-gratton thanks for raising this so quickly. Can you try upgrading again to 0.50.11 and tell us if it succeeds? Downgrading adds the constraint again, so you shouldn't encounter the problem if you upgrade, downgrade, and upgrade a second time.

michael-gratton (Issue Creator) on (2024-07-10 03:04:35 UTC): @calherries Can't roll forward again to 0.50.11 at the moment, since it is in production. However re-deploying to 0.50.10 didn't add `idx_uniq_field_table_id_parent_id_name` back to `metabase_field`, so I don't see rolling forward again helping.

qnkhuat on (2024-07-10 04:55:46 UTC): @michael-gratton A fix will be included in the next release; in the meantime, you can work around it by manually adding the index and then upgrading again.

```sql
CREATE UNIQUE INDEX idx_uniq_field_table_id_parent_id_name ON ""metabase_field"" (""table_id"", ""name"", ""parent_id"")
```

github-actions[bot] on (2024-07-10 09:28:38 UTC): ðŸš€ This should also be released by [v0.50.12](https://github.com/metabase/metabase/milestone/252)

calherries on (2024-07-10 22:43:28 UTC): @michael-gratton can you share the results of this query? I'm trying to understand why there was no `idx_uniq_field_table_id_parent_id_name` constraint in your app DB.

```
SELECT 'CONSTRAINT' as type,
       conname as name,
       pg_get_constraintdef(c.oid) as definition
FROM pg_constraint c
JOIN pg_namespace n ON n.oid = c.connamespace
JOIN pg_class cl ON cl.oid = c.conrelid
WHERE cl.relname = 'metabase_table'

UNION ALL

SELECT 'INDEX' as type,
       i.relname as name,
       pg_get_indexdef(i.oid) as definition
FROM pg_index x
JOIN pg_class c ON c.oid = x.indrelid
JOIN pg_class i ON i.oid = x.indexrelid
JOIN pg_namespace n ON n.oid = c.relnamespace
WHERE c.relname = 'metabase_table'

ORDER BY type, name;
```

michael-gratton (Issue Creator) on (2024-07-10 23:26:46 UTC): Output of that is:

| type       | name                                       | definition                                                                                                             |
|------------|--------------------------------------------|------------------------------------------------------------------------------------------------------------------------|
| CONSTRAINT | fk_table_ref_database_id                   | FOREIGN KEY (db_id) REFERENCES metabase_database(id) ON DELETE CASCADE                                                 |
| CONSTRAINT | pk_metabase_table                          | PRIMARY KEY (id)                                                                                                       |
| INDEX      | idx_metabase_table_db_id_schema            | CREATE INDEX idx_metabase_table_db_id_schema ON public.metabase_table USING btree (schema)                             |
| INDEX      | idx_metabase_table_show_in_getting_started | CREATE INDEX idx_metabase_table_show_in_getting_started ON public.metabase_table USING btree (show_in_getting_started) |
| INDEX      | idx_table_db_id                            | CREATE INDEX idx_table_db_id ON public.metabase_table USING btree (db_id)                                              |
| INDEX      | pk_metabase_table                          | CREATE UNIQUE INDEX pk_metabase_table ON public.metabase_table USING btree (id)                                        |

calherries on (2024-07-10 23:53:18 UTC): Thanks! That lead me to the likely culprit. The migration that adds the `idx_uniq_field_table_id_parent_id_name` included a precondition that would not add the constraint in the case where this query results in 0 rows:
```
SELECT count(*) FROM METABASE_FIELD GROUP BY TABLE_ID, PARENT_ID, NAME HAVING count(*) > 1
```
https://github.com/metabase/metabase/blob/cf92c8bff67bd508741c05b90db4218b827d53a2/resources/migrations/000_legacy_migrations.yaml#L5663-L5692

Your app DB failed to pass this precondition and the constraint was never added.

The same is true of `metabase_table`: there's a precondition on the constraints that add `idx_uniq_table_db_id_schema_name` and `idx_uniq_table_db_id_schema_name_2col`:

https://github.com/metabase/metabase/blob/cf92c8bff67bd508741c05b90db4218b827d53a2/resources/migrations/000_legacy_migrations.yaml#L5632-L5662

 You app DB also doesn't have these constraints.

The lack of `metabase_field` constraints will be addressed by [v0.50.12](https://github.com/metabase/metabase/milestone/252) but the lack of `metabase_table` constraints should be addressed. Not having those constraints increases the likelihood of bugs in the future.

"
2399215577,issue,closed,completed,Unclear Error Message When Using Offset in Custom Column,"### Describe the bug

If you try to use the offset() function in a custom column you receive the error ""OFFSET is not supported in custom expressions"". 

### To Reproduce

1. Open Metabase v50.10
2. Create a Question on the sample DB
3. Try to write a basic offset in a custom column
4. See error

### Expected behavior

I believe this should say ""OFFSET is not supported in custom columns.""

You can/should use it in a custom expression in the summarize box.

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.10
```


### Severity

annoying / unxclear

### Additional context

_No response_",ixipixi,2024-07-09 21:09:32+00:00,['ranquild'],2024-07-17 13:41:37+00:00,2024-07-17 12:15:13+00:00,https://github.com/metabase/metabase/issues/45327,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/MBQL', ''), ('.Frontend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2219063752, 'issue_id': 2399215577, 'author': 'calherries', 'body': ""@kamilmielnik I've triaged this to your team because it looks related to https://github.com/metabase/metabase/pull/43224. \r\n\r\nThe message is coming from metabase.lib Clojure code here:\r\nhttps://github.com/metabase/metabase/blob/ab3eff95d7488ec3759f3282951a422f78060770/src/metabase/lib/expression.cljc#L486-L488\r\n\r\nLooks like you made the latest changes to this message in the above PR."", 'created_at': datetime.datetime(2024, 7, 9, 23, 59, 11, tzinfo=datetime.timezone.utc)}]","calherries on (2024-07-09 23:59:11 UTC): @kamilmielnik I've triaged this to your team because it looks related to https://github.com/metabase/metabase/pull/43224. 

The message is coming from metabase.lib Clojure code here:
https://github.com/metabase/metabase/blob/ab3eff95d7488ec3759f3282951a422f78060770/src/metabase/lib/expression.cljc#L486-L488

Looks like you made the latest changes to this message in the above PR.

"
2399180187,issue,open,,Improve migrations testing,"Too easy to write a migration that works on paper but blows up IRL. I think we should do two things

- Add a weekly job to CI that fetches a current snapshot of stats or some other real-life application DB and tries running migrations backwards a full major release or two

- Add new test tooling that makes it easier to load up a mock application DB with meaningful data to test against",camsaul,2024-07-09 20:42:57+00:00,[],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/45325,"[('Type:Tech Debt', 'or Refactoring'), ('.CI & Tests', ''), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.DX', 'Developer experience and QoL related.'), ('.Team/DevEx', '')]",[],
2398461576,issue,open,,Ensure usefulness of events tracking failed CSV uploads,"Context: [this postmortem](https://www.notion.so/metabase/v50-Regression-Comma-in-quoted-string-during-CSV-upload-CSV-error-unexpected-character-c52f385abb0e423e85b4b11faba225d4)

We want to be able to reach out to the people facing failures with CSV uploads and ask them to share whichever data they can to beef up our test data with some real-world stuff.",darksciencebase,2024-07-09 15:03:43+00:00,[],2024-07-09 15:04:25+00:00,,https://github.com/metabase/metabase/issues/45303,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2217966386, 'issue_id': 2398461576, 'author': 'darksciencebase', 'body': 'this has been blessed by PM', 'created_at': datetime.datetime(2024, 7, 9, 15, 4, 24, tzinfo=datetime.timezone.utc)}]","darksciencebase (Issue Creator) on (2024-07-09 15:04:24 UTC): this has been blessed by PM

"
2398401113,issue,closed,completed,Weird (split) Filter modal when joining two tables using their foreign keys,"### Describe the bug

A filter modal is split and it renders the foreign key relation (table) twice if tables are joined using foreign keys only.



### To Reproduce

1. Open ""Reviews""
2. Join with ""Orders""
3. Condition ""Reviews.product_id"" <> ""Orders.product_id"" (both are FK
4. Visualize
5. Click Filter
6. There are two ""Products"" in the sidebar
7. The UI of the filter modal is split

![image](https://github.com/metabase/metabase/assets/31325167/dcddafc2-fd6f-405d-9d47-f65c1c6cf370)

### Expected behavior

The FK table is referenced only once in the sidebar.
The UI is not split and works as for any other regular table.

### Logs

_No response_

### Information about your Metabase installation
local dev, `master`, f434c6c, H2, Sample Database

### Severity

P2

### Additional context

_No response_",nemanjaglumac,2024-07-09 14:37:56+00:00,[],2024-07-11 07:46:13+00:00,2024-07-11 00:22:00+00:00,https://github.com/metabase/metabase/issues/45300,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]",[],
2398391981,issue,closed,not_planned,API calls using the API key don't work for all endpoints,"### Describe the bug

It's possible that some endpoints don't work with the API key. I managed to find one `api/user`

### To Reproduce

1. Go to Admin -> Authentication -> Manage API -> Create new API key in Admin Group

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/bbaafc03-9d79-4ae6-9283-a8ec07d2e520"">

Then try to use the API. The following call works:

`curl -H 'x-api-key: Ymb_UGXWibc0YbG+s9AClYhUTDk0bw3Wxe9GqQraBWcBvnQ=' -X GET 'http://localhost:3000/permissions/group'`

This one doesn't

`curl -H 'x-api-key: Ymb_UGXWibc0YbG+s9AClYhUTDk0bw3Wxe9GqQraBWcBvnQ=' -X GET 'http://localhost:3000/api/user'
`

### Expected behavior

Yeah API key should work for all endpoints if it was created in the admin group ... There might be more endpoints that doesn't work so we need to confirm it works on all endpoints

### Logs

GET /api/user/ 401 4.9 ms (0 DB calls) {:metabase-user-id nil}

### Information about your Metabase installation

```JSON
1.50.10
```


### Severity

Not blocking

### Additional context

_No response_",Tony-metabase,2024-07-09 14:33:43+00:00,[],2024-07-12 17:57:03+00:00,2024-07-09 15:05:13+00:00,https://github.com/metabase/metabase/issues/45299,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2217939830, 'issue_id': 2398391981, 'author': 'dpsutton', 'body': 'Works for me?\r\n\r\n#### Against master\r\n```\r\nâ¯ curl -s -H ""x-api-key: $API_KEY"" -X GET \'http://localhost:3000/api/user\' | jq \'.data|map(.email)\'\r\n[\r\n  ""crowberto@metabase.com"",\r\n  ""dan@metabase.com"",\r\n  ""limited@metabase.com"",\r\n  ""lucky@metabase.com"",\r\n  ""rasta@metabase.com"",\r\n  ""segment@metabase.com""\r\n]\r\n\r\n```\r\n\r\n##### against 0.50.9:\r\n\r\nUsing port 3059:\r\n\r\n<img width=""1102"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/86995f7b-6520-4912-992d-bc50f8a10cd2"">\r\n\r\n\r\n```\r\nâ¯ http get localhost:3059/api/user x-api-key:$API_KEY -pb | jq \'.data|map(.email)\'\r\n[\r\n  ""dan@metabase.com""\r\n]\r\n```', 'created_at': datetime.datetime(2024, 7, 9, 14, 52, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217965072, 'issue_id': 2398391981, 'author': 'noahmoss', 'body': 'Works for me as well. @Tony-metabase pretty sure you just have an extra character at the start of the API key.', 'created_at': datetime.datetime(2024, 7, 9, 15, 3, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217969106, 'issue_id': 2398391981, 'author': 'dpsutton', 'body': 'I think the urls are wrong\r\n\r\n`\'http://localhost:3000/permissions/group\'` is not an api route. So it returns html and doesn\'t check the api key\r\n\r\n```\r\nâ¯ curl -H ""x-api-key: $API_KEY"" -X GET \'http://localhost:3000/permissions/group\'\r\n<!doctype html><html lang=""en"" translate=""no""><head><meta charset=""utf-8""/><meta http-equiv=""X-UA-Compatible"" ...\r\n```', 'created_at': datetime.datetime(2024, 7, 9, 15, 5, 13, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-07-09 14:52:51 UTC): Works for me?

#### Against master
```
â¯ curl -s -H ""x-api-key: $API_KEY"" -X GET 'http://localhost:3000/api/user' | jq '.data|map(.email)'
[
  ""crowberto@metabase.com"",
  ""dan@metabase.com"",
  ""limited@metabase.com"",
  ""lucky@metabase.com"",
  ""rasta@metabase.com"",
  ""segment@metabase.com""
]

```

##### against 0.50.9:

Using port 3059:

<img width=""1102"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/86995f7b-6520-4912-992d-bc50f8a10cd2"">


```
â¯ http get localhost:3059/api/user x-api-key:$API_KEY -pb | jq '.data|map(.email)'
[
  ""dan@metabase.com""
]
```

noahmoss on (2024-07-09 15:03:58 UTC): Works for me as well. @Tony-metabase pretty sure you just have an extra character at the start of the API key.

dpsutton on (2024-07-09 15:05:13 UTC): I think the urls are wrong

`'http://localhost:3000/permissions/group'` is not an api route. So it returns html and doesn't check the api key

```
â¯ curl -H ""x-api-key: $API_KEY"" -X GET 'http://localhost:3000/permissions/group'
<!doctype html><html lang=""en"" translate=""no""><head><meta charset=""utf-8""/><meta http-equiv=""X-UA-Compatible"" ...
```

"
2398390067,issue,closed,completed,Shutdown releasing migration locks has an error in the log statement,"### Describe the bug

https://github.com/metabase/metabase/blob/master/src/metabase/db/liquibase.clj#L261

This line logs a ratio with a float formatter. 

```clojure
liquibase=> (log/infof ""Waiting for migration lock(s) to be released (max %.1f secs)"" (/ 2000 1000))
Execution error (IllegalFormatConversionException) at java.util.Formatter$FormatSpecifier/failConversion (Formatter.java:4515).
f != java.lang.Long
```

note the ratio becomes a long if it is exact. otherwise you get 

```clojure
liquibase=> (log/infof ""Waiting for migration lock(s) to be released (max %.1f secs)"" (/ 2001 1000))
Execution error (IllegalFormatConversionException) at java.util.Formatter$FormatSpecifier/failConversion (Formatter.java:4515).
f != clojure.lang.Ratio
```

### To Reproduce

kinda hard to reproduce in the wild because it's related to db state. 

### Expected behavior

we should not throw an error when shutting down. Especially if we are removing locks in the db

### Logs

https://github.com/metabase/metabase/issues/45124 has an example in the wild:

```
2024-07-04 15:54:39,081 INFO metabase.core :: Metabase Shutting Down ...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,084 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Exception in thread ""Thread-9"" java.util.IllegalFormatConversionException: f != java.lang.Long
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,122 WARN db.liquibase :: (#object[liquibase.Liquibase 0x2b7e6614 liquibase.Liquibase@2b7e6614])
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.failConversion(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.printFloat(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.print(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.lang.String.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.core$format.invokeStatic(core.clj:5770)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.core$format.doInvoke(core.clj:5764)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.lang.RestFn.invoke(RestFn.java:423)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.liquibase$wait_for_all_locks.invokeStatic(liquibase.clj:258)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.liquibase$wait_for_all_locks.invoke(liquibase.clj:251)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.setup$release_migration_locks_BANG_.invokeStatic(setup.clj:175)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.setup$release_migration_locks_BANG_.invoke(setup.clj:170)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db$release_migration_locks_BANG_.invokeStatic(db.clj:91)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db$release_migration_locks_BANG_.invoke(db.clj:86)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.core$destroy_BANG_.invokeStatic(core.clj:90)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.core$destroy_BANG_.invoke(core.clj:81)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.lang.AFn.run(AFn.java:22)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.lang.Thread.run(Unknown Source)
```

### Information about your Metabase installation

```JSON
master, release-x.50.x, 0.50.9
```


### Severity

p3

### Additional context

_No response_",dpsutton,2024-07-09 14:32:50+00:00,['dpsutton'],2024-07-09 18:45:54+00:00,2024-07-09 17:16:22+00:00,https://github.com/metabase/metabase/issues/45298,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2398335090,issue,closed,completed,Funnel column ordering freak out,"### Describe the bug

When trying to reorder the columns in a funnel, the list freaks out.  This may be because there are numerous same values and there is an order by in the query?

See video:
https://www.loom.com/share/9fedfc525e6e44eba83e93d29ee66901

![image](https://github.com/metabase/metabase/assets/897229/6942fe9e-fea4-424b-84f0-d0aa6f7c7e7a)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

I should be able to drag a column to reorder it in the funnel.



### Logs

_No response_

### Information about your Metabase installation

```JSON
Running: 1.50.9
Using Chrome: Version 126.0.6478.127 (Official Build) (arm64)
```


### Severity

Our funnel chart is broken, which is causing issues with our client reports.

### Additional context

_No response_",boneill42,2024-07-09 14:08:52+00:00,['alxnddr'],2024-07-15 20:58:36+00:00,2024-07-11 15:26:57+00:00,https://github.com/metabase/metabase/issues/45296,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2217860634, 'issue_id': 2398335090, 'author': 'uladzimirdev', 'body': '@boneill42 could you please check browser console, is there any error reported?', 'created_at': datetime.datetime(2024, 7, 9, 14, 16, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217892700, 'issue_id': 2398335090, 'author': 'boneill42', 'body': '![image](https://github.com/metabase/metabase/assets/897229/4d082543-4ad2-4b10-ac6f-c7dc3c58e446)', 'created_at': datetime.datetime(2024, 7, 9, 14, 30, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229422189, 'issue_id': 2398335090, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 58, 35, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-07-09 14:16:14 UTC): @boneill42 could you please check browser console, is there any error reported?

boneill42 (Issue Creator) on (2024-07-09 14:30:45 UTC): ![image](https://github.com/metabase/metabase/assets/897229/4d082543-4ad2-4b10-ac6f-c7dc3c58e446)

github-actions[bot] on (2024-07-15 20:58:35 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2398319755,issue,closed,completed,Use more lines when inferring CSV separator,"See [internal discussion](https://www.notion.so/metabase/Update-CSV-Uploads-inference-code-to-use-additional-data-rows-d90c532a287444c78ca3892c35ac2fd0)

### Description

Currently we only look at the header and the first data row when inferring the separator (e.g. `,` or `;`) used in an uploaded file, and this may result in ambiguities that lead to us picking the wrong separator, and failing the upload.

By looking at more rows, we decrease the chance of this happening.

Here's an example of where currently we would make a mistake, and this change would fix it:

```csv
product name; amount, in dollars
blunderbuss;  1,000
cyberwagon;   1,000,000
```

If we just looked at the header and first data row, both separators break their lines in half, and we give the comma higher precedence. In the third row we now have the comma breaking it into 3 pieces, which is more than the header, so this is not viable, and we will pick the semicolon.

### Fix

Update `metabase.upload/infer-separator` to keep looking at further rows until there is 1 or less viable separator, or we've looked at N (and fallback to precendence).
",crisptrutski,2024-07-09 14:01:47+00:00,['crisptrutski'],2024-08-07 15:11:56+00:00,2024-08-07 13:36:39+00:00,https://github.com/metabase/metabase/issues/45295,"[('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2398105022,issue,closed,completed,x-rays on the home screen are disappearing too quickly,"### Describe the bug

Even in a new instance, x-rays disappear on the home screen as soon as there are any recent items

### To Reproduce

1. Create a fresh instance
2. note the x-rays on the home page
3. go to examples -> E-commerce insights
4. Now go back to the homepage. The x-rays are gone, and now you have recents

### Expected behavior

I believe the expected result is that users should see the x-rays until there is at least 1 user generated question and dashboard on the instance. However, looking at the code (`user.clj#298`), it appears that we only do this until the user *has access* to 1 question and 1 dashboard (and there are no recent items). 

### Logs

N/A

### Information about your Metabase installation

```JSON
Current Master
```


### Severity

p2

### Additional context

_No response_",npfitz,2024-07-09 12:40:39+00:00,[],2024-07-09 20:35:07+00:00,2024-07-09 20:35:07+00:00,https://github.com/metabase/metabase/issues/45289,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2398060719,issue,closed,not_planned,[Cache] Add e2e tests for caching a dashboard adaptively by configuring the database or by setting the default policy,"TODO:
Combine all the e2e tests into one milestone.",rafpaf,2024-07-09 12:22:05+00:00,[],2024-07-12 00:51:02+00:00,2024-07-12 00:51:01+00:00,https://github.com/metabase/metabase/issues/45288,[],"[{'comment_id': 2224227676, 'issue_id': 2398060719, 'author': 'rafpaf', 'body': 'Reorganized this', 'created_at': datetime.datetime(2024, 7, 12, 0, 51, 1, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-07-12 00:51:01 UTC): Reorganized this

"
2397837251,issue,closed,completed,Ability to pass authentication headers when fetching request tokens in embedding SDK,"Some SDK customers has SSO endpoints that authenticates with bearer tokens in the request headers, not cookies. We currently set `credentials: ""include""` in the fetch request to get the refresh token, which only works for cookie-based session authentication but not for header-based bearer tokens. We should expose an API to allow SDK customers to customize authentication headers. 

We currently use the `refreshTokenAsync` thunk to get the refresh token from the customer's SSO endpoint: https://github.com/metabase/metabase/blob/master/enterprise/frontend/src/embedding-sdk/store/reducer.ts#L49-L58

We could implement this in two ways:

Option 1: Specify a function to get the refresh token.

```ts
const config = {
  async getAuthRefreshToken() {
    // customer calls fetch() or calls a function they have to get a refresh token
  }
}

<MetabaseProvider config={config} />
```

Option 2: Specify a function to get the auth header, which we internally pass to `fetch()` and remove `credentials: ""include""`

```ts
const config = {
  async getAuthHeaders() {
    return { ""Authorization"": ""<whatever>"" }
  }
}

<MetabaseProvider config={config} />
```",heypoom,2024-07-09 10:40:27+00:00,['heypoom'],2024-10-08 17:04:48+00:00,2024-07-10 09:55:46+00:00,https://github.com/metabase/metabase/issues/45286,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2397333917,issue,closed,completed,Incorrect default pinned Metric description,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/8766ac32-471b-4fbc-b85a-924ca3e1f9de)


### To Reproduce

1. Create a new metric and save it
2. Go to the collection it's been saved in
3. It's been automatically pinned
4. ""Don't show visualization"" for it
5. See description

### Information about your Metabase installation

master, 2d7891b8ed


### Severity

P3
",kamilmielnik,2024-07-09 07:08:03+00:00,['nemanjaglumac'],2024-10-08 17:04:54+00:00,2024-07-09 14:21:37+00:00,https://github.com/metabase/metabase/issues/45270,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2')]",[],
2396884730,issue,closed,completed,[Epic] Migrate `column_settings` viz setting from field refs,"Follow up for https://github.com/metabase/metabase/pull/45237

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/46383
- [ ] https://github.com/metabase/metabase/pull/46460
- [ ] https://github.com/metabase/metabase/pull/46025
```",ranquild,2024-07-09 01:19:39+00:00,['ranquild'],2024-08-08 10:01:50+00:00,2024-08-08 10:01:50+00:00,https://github.com/metabase/metabase/issues/45266,"[('.Epic', 'Feature Implementation or Project')]",[],
2396794575,issue,closed,completed,Technical Debt: Logs page testing depends on hardcoded numbers,"On `Logs.unit.spec.tsx` we test polling logic by advancing time using fake timers, but the amount of time is hardcoded based on default value of `1000ms`, such as:

```
jest.advanceTimersByTime(1100); // wait longer than polling period
```

As suggested in https://github.com/metabase/metabase/pull/44585#discussion_r1666071238, by depending on a constant, we'll have more robust tests and avoid potential false positives whenever default value changes.

The idea is:
1. Exporting a constant with default polling time
2. Use this constant on tests
",elton-okawa,2024-07-08 23:56:59+00:00,[],2024-07-09 08:42:54+00:00,2024-07-09 07:38:10+00:00,https://github.com/metabase/metabase/issues/45263,"[('Type:Tech Debt', 'or Refactoring'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2396746185,issue,open,,Static funnel chart incorrectly filters out null dimension values,"Static funnel chart incorrectly filters out null dimension values. Since static funnel chart is a duplicated and buggy implementation of the dynamic one it makes sense to prevent any further diverging by implementing an isomorphic funnel chart using ECharts.

Steps:
- Create a funnel chart with null dimension value
- Send a test dashboard subscription with the chart
- The null value has been filtered out which is wrong

Example query:
```
select 'foo' step, 10 v
union all select 'baz' step, 8 v
union all select null step, 6 v
union all select 'bar' step, 4 v
```
",alxnddr,2024-07-08 23:30:52+00:00,[],2025-02-04 20:31:55+00:00,,https://github.com/metabase/metabase/issues/45261,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Backend', ''), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2273982305, 'issue_id': 2396746185, 'author': 'cdeweyx', 'body': ""Let's wait until we migrate funnels"", 'created_at': datetime.datetime(2024, 8, 7, 17, 34, 14, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-07 17:34:14 UTC): Let's wait until we migrate funnels

"
2396707202,issue,closed,completed,Funnel chart handles null values incorrectly,"[Original report](https://metaboat.slack.com/archives/C05MPF0TM3L/p1720462668399529)

Dynamic funnel chart viz settings crash when funnel dimension values include null",alxnddr,2024-07-08 22:53:03+00:00,['alxnddr'],2024-07-10 01:13:48+00:00,2024-07-09 21:09:05+00:00,https://github.com/metabase/metabase/issues/45255,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2396642173,issue,closed,completed,Stacked bar charts don't take into account negative values when the positive values are very large,"### Describe the bug

When you make a stacked bar chart, the negative values don't subtract from the total so the bar is artificially higher. If you hover in the breakdown of a bart you can see the negative values. 
Example:
![Screenshot 2024-07-08 at 3 21 42â€¯p m](https://github.com/metabase/metabase/assets/114109351/83f4e49c-6cee-4eaa-bec3-095e40312a2e) 
Total appears to be 103 k.
Breakdown: 
![Screenshot 2024-07-08 at 3 21 48â€¯p m](https://github.com/metabase/metabase/assets/114109351/0a76bc5a-9ffb-4b96-977f-438666e11a30) 
Negative value doesn't subtract from the total



### To Reproduce

1. Run this query: 
`select 1 as class, 'A' as type, 1000000 as value union all select 2 as class, 'A' as type, 1000000 as value union all select 3 as class, 'A' as type, 1000000 as value union all select 1 as class, 'B' as type, 1000000 as value union all select 2 as class, 'B' as type, 1000000 as value union all select 3 as class, 'B' as type, 1000000 as value union all select 1 as class, 'C' as type, 1000000 as value union all select 2 as class, 'C' as type, 1000000 as value union all select 3 as class, 'C' as type, 1000000 as value union all select 1 as class, 'D' as type, 1000000 as value union all select 2 as class, 'D' as type, 1000000 as value union all select 3 as class, 'D' as type, 1000000 as value union all select 1 as class, 'E' as type, 1000000 as value union all select 2 as class, 'E' as type, 1000000 as value union all select 3 as class, 'E' as type, 1000000 as value union all select 1 as class, 'F' as type, 1000000 as value union all select 2 as class, 'F' as type, 1000000 as value union all select 3 as class, 'F' as type, 1000000 as value union all select 1 as class, 'G' as type, 1000000 as value union all select 2 as class, 'G' as type, 1000000 as value union all select 3 as class, 'G' as type, 1000000 as value union all select 1 as class, 'H' as type, 1000000 as value union all select 2 as class, 'H' as type, 1000000 as value union all select 3 as class, 'H' as type, 1000000 as value union all select 1 as class, 'I' as type, 1000000 as value union all select 2 as class, 'I' as type, 1000000 as value union all select 3 as class, 'I' as type, 1000000 as value union all select 1 as class, 'J' as type, 1000000 as value union all select 2 as class, 'J' as type, 1000000 as value union all select 3 as class, 'J' as type, 1000000 as value union all select 1 as class, 'K' as type, 1000000 as value union all select 2 as class, 'K' as type, 1000000 as value union all select 3 as class, 'K' as type, 1000000 as value union all select 1 as class, 'L' as type, 1000000 as value union all select 2 as class, 'L' as type, 1000000 as value union all select 3 as class, 'L' as type, 1000000 as value union all select 1 as class, 'M' as type, 1000000 as value union all select 2 as class, 'M' as type, 1000000 as value union all select 3 as class, 'M' as type, 1000000 as value union all select 1 as class, 'N' as type, 100000 as value union all select 2 as class, 'N' as type, 100000 as value union all select 3 as class, 'N' as type, -10000 as value`
2. Click on 'Visualization'
3. Click on 'Bar'
4. Click on the settings gear icon for visualization
5. Select the 'type' column as the X-Axis value, 'class' column as the breakdown value for the x-axis,  and 'value' as the y-axis value
6. Click on Display tab
7. Click on 'Stack' for the Stacking setting
8. Click on 'Show values on data points' toggle
9. Click done
10. See error
![Screenshot 2024-07-08 at 3 48 31â€¯p m](https://github.com/metabase/metabase/assets/114109351/3f3c84bd-c114-412b-b5f5-4f122ffc31ae)
![Screenshot 2024-07-08 at 3 48 37â€¯p m](https://github.com/metabase/metabase/assets/114109351/bb0e2f89-f92e-4285-a3ed-bffa03695f4f)
Even if you click on 'Full' in 'Auto formatting' , the mistake is still there
![Screenshot 2024-07-08 at 3 50 09â€¯p m](https://github.com/metabase/metabase/assets/114109351/6a3037c0-e0ce-4193-b4cf-0e76a489de25)




### Expected behavior

The last bar on the x-axis (called 'N' in the example) should show a total of 190k in Compact or Auto, or 190,000 in Full for 'Auto formattting'. And the bar should take into account the negative value for the total.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v1.49.18"",
      ""hash"": ""fd3765d""
    },
    ""settings"": {
      ""report-timezone"": ""America/Mexico_City""
    }
  }
}
```


### Severity

Blocking some users that need accurate financial reporting

### Additional context

_No response_",a-termis,2024-07-08 21:53:26+00:00,['alxnddr'],2024-07-09 16:49:45+00:00,2024-07-09 16:48:13+00:00,https://github.com/metabase/metabase/issues/45254,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2218213367, 'issue_id': 2396642173, 'author': 'alxnddr', 'body': 'Hi @a-termis ðŸ‘‹ When we stack values on bar/area charts, we do it separately for positive and negative values. It is more noticeable on the example below:\r\n<img width=""457"" alt=""Screenshot 2024-07-09 at 12 40 50\u202fPM"" src=""https://github.com/metabase/metabase/assets/14301985/f5b530d5-0828-4596-a24b-6471ac3087df"">\r\n\r\nIn the case you mentioned, the negative value is too small relatively to positive ones so it is hardly visible but it is there. The `103.0k` label is correct because it shows the value of the positive stack. The fact that this chart while having a negative `-10000` value starts from zero causes confusion which makes it easy to miss the negative value. In Metabase v50 we\'ve reworked the bar chart and the new implementation makes it visible there is a negative value:\r\n\r\n<img width=""1339"" alt=""Screenshot 2024-07-09 at 12 47 35\u202fPM"" src=""https://github.com/metabase/metabase/assets/14301985/f71bb5df-3a74-490b-89cb-9aaf3fc124fc"">\r\n\r\nPlease let me know if you have any other concerns or ideas!', 'created_at': datetime.datetime(2024, 7, 9, 16, 48, 13, tzinfo=datetime.timezone.utc)}]","alxnddr (Assginee) on (2024-07-09 16:48:13 UTC): Hi @a-termis ðŸ‘‹ When we stack values on bar/area charts, we do it separately for positive and negative values. It is more noticeable on the example below:
<img width=""457"" alt=""Screenshot 2024-07-09 at 12 40 50â€¯PM"" src=""https://github.com/metabase/metabase/assets/14301985/f5b530d5-0828-4596-a24b-6471ac3087df"">

In the case you mentioned, the negative value is too small relatively to positive ones so it is hardly visible but it is there. The `103.0k` label is correct because it shows the value of the positive stack. The fact that this chart while having a negative `-10000` value starts from zero causes confusion which makes it easy to miss the negative value. In Metabase v50 we've reworked the bar chart and the new implementation makes it visible there is a negative value:

<img width=""1339"" alt=""Screenshot 2024-07-09 at 12 47 35â€¯PM"" src=""https://github.com/metabase/metabase/assets/14301985/f71bb5df-3a74-490b-89cb-9aaf3fc124fc"">

Please let me know if you have any other concerns or ideas!

"
2396629468,issue,closed,completed,Reduce Filter Options to Those that Work (Array fields),"### Describe the bug

If you have an array column and you attempt to filter on it, most filter options are not currently supported: https://github.com/metabase/metabase/issues/18108

It would be ideal if the GUI didn't present filter options that don't currently work ([like we do with JSON and XML columns](https://github.com/metabase/metabase/pull/23872)).

### To Reproduce

1. Set up a test Metabase Instance
2. In Postgres set up a test table with arrays:

CREATE TABLE test_table (
    id SERIAL PRIMARY KEY,
    identifiers VARCHAR[] NOT NULL
);

INSERT INTO test_table (identifiers) values
    (ARRAY['abc', 'def', 'ghi']),
    (ARRAY['jkl', 'mno']),
    (ARRAY['pqr', 'stu', 'vwx', 'yz']),
    (ARRAY['test1', 'test2', 'test3']);

3. Interact with filters from table columns, the filter modal, etc
4. If the column has no semantic type set the filter options simply don't react when you click on them
5. If the column is set to a semantic type, like Category, the empty/not empty filters work but all other options in the menu will fail (see above linked issue)

### Expected behavior

We shouldn't present the user with unsupported filter options 

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""postgres"",
      ""athena"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.49.17"",
      ""hash"": ""7e2b7bb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Confusing to users

### Additional context

_No response_",ixipixi,2024-07-08 21:43:28+00:00,['ranquild'],2024-07-17 19:02:36+00:00,2024-07-17 16:12:09+00:00,https://github.com/metabase/metabase/issues/45252,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2396496351,issue,closed,completed,Recents and Search tabs in move modal do not filter out incorrect options,"### Describe the bug

When trying to move a collection, The `recents` tab will display recently viewed collections, even if they are children of the currently selected collection. Selecting the invalid collection results in an API error, but doesn't give the user any indication something went wrong.

### To Reproduce

1. Go to a nested collection
2. Next, go to the parent collection, and select move from the entity menu
3. Notice the child collection in the `recents` tab
4. Now search for the child collection. Notice that it is selectable

### Expected behavior

Child collections should not be present in the `Search` and `Recents` tabs

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master
```


### Severity

p2

### Additional context

_No response_",npfitz,2024-07-08 20:21:14+00:00,['iethree'],2024-07-26 17:22:26+00:00,2024-07-26 16:52:50+00:00,https://github.com/metabase/metabase/issues/45248,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2396481556,issue,closed,not_planned,Collection and Dashboard pickers do not disregard initial value if it is invalid,"Both the Collection and Dashboard picker make the assumption that the initial value given to them is a valid option that is selectable within the picker. However, it's possible that the initial value given is not actually valid. We have functions that we can pass in to decide if something is valid to show in the `recents` and `search` tabs, as well as a `shouldDisableItem` function for the nested item picker.

As part of the setup phase for the pickers, we should run the initial item through one of these functions to validate that the value is valid and selectable. This came up in [Slack](https://metaboat.slack.com/archives/C064EB1UE5P/p1720447043941669) a while back, and while there was a BE solution to this specific instance, we should also improve the resiliency of our pickers


```[tasklist]
### Tasks
- [ ] Collection Picker update
- [ ] Dashboard Picker update
```
",npfitz,2024-07-08 20:13:43+00:00,[],2025-01-22 14:20:26+00:00,2025-01-22 14:20:26+00:00,https://github.com/metabase/metabase/issues/45245,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2396072031,issue,closed,not_planned,[Cache] Add e2e test for setting adaptive cache invalidation strategy via dashboard info sidebar,"In EE, a dashboard can be configured to invalidate its cache ""adaptively"" - that is, for a length of time based on the average query runtime. One way to configure a dashboard to do this is via the info sidebar. Add an e2e test to cover this functionality.

Note: another way to configure a dashboard to use the adaptive strategy is to tell it to ""Use default"" (i.e. use the default cache invalidation policy) and then configure the underlying database to use the adaptive strategy. A third way is to tell the dashboard to ""Use default"" and set the instance-wide default policy to adaptive. These methods are not relevant to this issue.",rafpaf,2024-07-08 16:29:12+00:00,['rafpaf'],2024-07-12 00:51:20+00:00,2024-07-12 00:51:20+00:00,https://github.com/metabase/metabase/issues/45236,[],"[{'comment_id': 2224227898, 'issue_id': 2396072031, 'author': 'rafpaf', 'body': 'Reorganized this work', 'created_at': datetime.datetime(2024, 7, 12, 0, 51, 20, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-07-12 00:51:20 UTC): Reorganized this work

"
2396067841,issue,closed,not_planned,[Cache] Add e2e test for setting adaptive cache invalidation strategy via question info sidebar,,rafpaf,2024-07-08 16:26:49+00:00,['rafpaf'],2024-07-12 00:51:49+00:00,2024-07-12 00:51:49+00:00,https://github.com/metabase/metabase/issues/45235,"[('backport', 'Automatically create PR on current release branch on merge')]",[],
2395823729,issue,closed,completed,Serialization: better errors,"When serialization breaks because Metabase threw an exception - so, it's not an unexpected logic error, but more like ""we don't know what to do with that data"" - we should output this error in a concise way (so, no long stacktraces, Toucan connection details which confuse users) without losing useful data (so all the nested messages and their data).

Also: possibly append `:table` to data when data contains `:model` so it's easier for users to determine where's the error coming from.",piranha,2024-07-08 14:34:26+00:00,['crisptrutski'],2024-08-15 11:40:41+00:00,2024-08-15 09:07:07+00:00,https://github.com/metabase/metabase/issues/45225,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2271211820, 'issue_id': 2395823729, 'author': 'crisptrutski', 'body': 'Waiting for https://github.com/metabase/metabase/pull/46147#discussion_r1705411916 to land before doing this.', 'created_at': datetime.datetime(2024, 8, 6, 12, 48, 52, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-08-06 12:48:52 UTC): Waiting for https://github.com/metabase/metabase/pull/46147#discussion_r1705411916 to land before doing this.

"
2395793416,issue,closed,completed,Serialize by entity_id,"Serialization should give a way to specify collections with entity ids, both in CLI and HTTP API.",piranha,2024-07-08 14:23:48+00:00,['piranha'],2024-07-15 20:58:32+00:00,2024-07-11 17:14:51+00:00,https://github.com/metabase/metabase/issues/45224,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2216739949, 'issue_id': 2395793416, 'author': 'darksciencebase', 'body': '(this is a big pain for at least one customer)', 'created_at': datetime.datetime(2024, 7, 9, 6, 53, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229422033, 'issue_id': 2395793416, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 58, 31, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-07-09 06:53:52 UTC): (this is a big pain for at least one customer)

github-actions[bot] on (2024-07-15 20:58:31 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2395788781,issue,closed,completed,`GET /api/activity/most_recently_viewed_dashboard` should not return archived dashboards,"### Describe the bug

If the most recently viewed dashboard is archived, the `/api/activity/most_recently_viewed_dashboard` endpoint will still return it and the FE will request it and then show weird state.

<img width=""1303"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/9b80431a-60ce-4ee0-8d4b-348ba423bc89"">

I'm updating to a p1 because of the behavior on master:

have two dashboards. Visit one, and then archive that. You want that to be the most recent. Go to a question and click on add to a dashboard.

Normally the most recent dashboard is highlighted and the blue button is ready to choose that dashboard
<img width=""1329"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/57ae56c2-b571-4949-8964-2a2cd8ff5f63"">

But if the archived dash is most recent, it is returned from the BE. But the FE will not show it, but it is still ""selected"" and the blue button will confirm that as your choice

<img width=""1471"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/40e79e75-05ee-45ed-bbe2-77ebb6b50033"">

If you select this, you are in an invalid state as you are ""moving"" a card into the archive.

<img width=""1471"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/49712a6b-826d-4d51-a576-19aff2e2a605"">
<img width=""1471"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/63949b5c-40c8-450c-8491-aace28d682b1"">

## How to fix

Make sure that both `release-x.50.x` and `master` have a tested fix for this.


### To Reproduce

Create a dashboard, then archive it. Go to question, on the menu click ""add to a dashboard"" and see the above UI state.

### Expected behavior

it should gracefully handle archived dashboards. Don't return that

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.50.9
```


### Severity

p1

### Additional context

_No response_",dpsutton,2024-07-08 14:22:08+00:00,"['npfitz', 'noahmoss']",2024-07-08 21:37:46+00:00,2024-07-08 17:41:41+00:00,https://github.com/metabase/metabase/issues/45223,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Organization/Collections', ''), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Browse Data', '')]","[{'comment_id': 2214545038, 'issue_id': 2395788781, 'author': 'paoliniluis', 'body': 'dupe of https://github.com/metabase/metabase/issues/44382', 'created_at': datetime.datetime(2024, 7, 8, 16, 1, 2, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-08 16:01:02 UTC): dupe of https://github.com/metabase/metabase/issues/44382

"
2395326851,issue,closed,not_planned,Athena connection constantly syncing,"### Describe the bug

After creating an Athena connection, Metabase is issuing an endless stream of queries to Athena. I have not created any dashboards or models. The Athena queries run every few seconds, incurring read costs each time. Over the course of 48 hours 1000's of queries where issued by Metabase generated over 200GB of data in the Athena results folder with no human interaction. I'd expect these queries to stop once Metabase has synced under underlying data model but they did not stop until I deleted the db connection.  



### To Reproduce

Add new Athena db using the following params:
Database Type: Amazonf Athena
Display name: test
Region: eu-west-1
Workgroup: Primary
S3 Staging Directory: xxxxxx-datalake-athena
Catalog: AwsDataCatalog
Access Key: xxx
Secret Key: xxx
Include User ID and query hash in queries: false
Rerun queries for simple explorations: false
Choose when syncs and scans happen: false
Periodically refingerprint tables: false


### Expected behavior

The connection should not keep running queries against Athena - once sync has completed this process should stop. Every query running against Athena costs $$.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""22.0.1+8-16"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""22.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""22.0.1+8-16"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.94-99.176.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High

### Additional context

_No response_",james-n-centric,2024-07-08 11:04:54+00:00,[],2024-07-16 12:16:26+00:00,2024-07-16 12:16:26+00:00,https://github.com/metabase/metabase/issues/45208,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('Database/Athena', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2217034270, 'issue_id': 2395326851, 'author': 'qnkhuat', 'body': '@james-n-centric can you get us a dump of running this query?\r\n```sql\r\nselect task, started_at, duration, ended_at  from task_history where db_id = <your-athena-db-id> order by started_at desc;\r\n```\r\nYou should be able to get your athena DB by checking the URL when visiting your db in admin panel.\r\n\r\nMy suspect is that scanning field values is super slow. You can try turning it off in the advanced setting like so\r\n![Screenshot 2024-07-09 at 15 57 45](https://github.com/metabase/metabase/assets/25661381/7650893e-3ab8-41ca-82b9-16e346fcc0ce)', 'created_at': datetime.datetime(2024, 7, 9, 8, 59, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217941298, 'issue_id': 2395326851, 'author': 'james-n-centric', 'body': 'Thanks for looking at this.\r\n\r\nI made a new connection to Athena today at [2024-07-09 15:32:46.872 +0100] UK\r\n\r\nThe is the dump from task_history after 15 mins:\r\n\r\n""task"",""started_at"",""duration"",""ended_at"",""db_id""\r\nupdate-field-values,2024-07-09 15:38:25.321 +0100,,,7\r\ndelete-expired-advanced-field-values,2024-07-09 15:38:13.279 +0100,12032,2024-07-09 15:38:25.311 +0100,7\r\nfield values scanning,2024-07-09 15:38:13.208 +0100,,,7\r\nclassify-tables,2024-07-09 15:38:10.116 +0100,448,2024-07-09 15:38:10.564 +0100,7\r\nclassify-fields,2024-07-09 15:37:46.671 +0100,23432,2024-07-09 15:38:10.103 +0100,7\r\nfingerprint-fields,2024-07-09 15:33:01.680 +0100,284970,2024-07-09 15:37:46.650 +0100,7\r\nanalyze,2024-07-09 15:33:01.671 +0100,308900,2024-07-09 15:38:10.572 +0100,7\r\nsync-table-privileges,2024-07-09 15:33:01.198 +0100,12,2024-07-09 15:33:01.210 +0100,7\r\nsync-metabase-metadata,2024-07-09 15:33:01.174 +0100,14,2024-07-09 15:33:01.189 +0100,7\r\nsync-indexes,2024-07-09 15:33:01.156 +0100,9,2024-07-09 15:33:01.166 +0100,7\r\nsync-fks,2024-07-09 15:33:01.008 +0100,137,2024-07-09 15:33:01.145 +0100,7\r\nsync-fields,2024-07-09 15:32:48.198 +0100,12796,2024-07-09 15:33:00.994 +0100,7\r\nsync-tables,2024-07-09 15:32:47.089 +0100,1102,2024-07-09 15:32:48.191 +0100,7\r\nsync-timezone,2024-07-09 15:32:47.009 +0100,24,2024-07-09 15:32:47.034 +0100,7\r\nsync-dbms-version,2024-07-09 15:32:46.910 +0100,73,2024-07-09 15:32:46.983 +0100,7\r\nsync,2024-07-09 15:32:46.872 +0100,14741,2024-07-09 15:33:01.614 +0100,7\r\n\r\nAthena show queries being issues almost constantly:\r\n\r\n![image](https://github.com/metabase/metabase/assets/173671402/73a8e078-fd4e-4511-8854-23befdd3708d)\r\n\r\nI tried to set the Scan setting as you showed, but nothing has changed so far.', 'created_at': datetime.datetime(2024, 7, 9, 14, 53, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219426158, 'issue_id': 2395326851, 'author': 'qnkhuat', 'body': ""These queries are part of our sync field values process to power filter dropdown.\r\n\r\n> I tried to set the Scan setting as you showed, but nothing has changed so far.\r\n\r\nIf you don't want this process to run, you should uncheck the option before creating the database.\r\n\r\nThough this sync performance is unacceptable, we'll create another issue for it."", 'created_at': datetime.datetime(2024, 7, 10, 2, 50, 29, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-09 08:59:31 UTC): @james-n-centric can you get us a dump of running this query?
```sql
select task, started_at, duration, ended_at  from task_history where db_id = <your-athena-db-id> order by started_at desc;
```
You should be able to get your athena DB by checking the URL when visiting your db in admin panel.

My suspect is that scanning field values is super slow. You can try turning it off in the advanced setting like so
![Screenshot 2024-07-09 at 15 57 45](https://github.com/metabase/metabase/assets/25661381/7650893e-3ab8-41ca-82b9-16e346fcc0ce)

james-n-centric (Issue Creator) on (2024-07-09 14:53:32 UTC): Thanks for looking at this.

I made a new connection to Athena today at [2024-07-09 15:32:46.872 +0100] UK

The is the dump from task_history after 15 mins:

""task"",""started_at"",""duration"",""ended_at"",""db_id""
update-field-values,2024-07-09 15:38:25.321 +0100,,,7
delete-expired-advanced-field-values,2024-07-09 15:38:13.279 +0100,12032,2024-07-09 15:38:25.311 +0100,7
field values scanning,2024-07-09 15:38:13.208 +0100,,,7
classify-tables,2024-07-09 15:38:10.116 +0100,448,2024-07-09 15:38:10.564 +0100,7
classify-fields,2024-07-09 15:37:46.671 +0100,23432,2024-07-09 15:38:10.103 +0100,7
fingerprint-fields,2024-07-09 15:33:01.680 +0100,284970,2024-07-09 15:37:46.650 +0100,7
analyze,2024-07-09 15:33:01.671 +0100,308900,2024-07-09 15:38:10.572 +0100,7
sync-table-privileges,2024-07-09 15:33:01.198 +0100,12,2024-07-09 15:33:01.210 +0100,7
sync-metabase-metadata,2024-07-09 15:33:01.174 +0100,14,2024-07-09 15:33:01.189 +0100,7
sync-indexes,2024-07-09 15:33:01.156 +0100,9,2024-07-09 15:33:01.166 +0100,7
sync-fks,2024-07-09 15:33:01.008 +0100,137,2024-07-09 15:33:01.145 +0100,7
sync-fields,2024-07-09 15:32:48.198 +0100,12796,2024-07-09 15:33:00.994 +0100,7
sync-tables,2024-07-09 15:32:47.089 +0100,1102,2024-07-09 15:32:48.191 +0100,7
sync-timezone,2024-07-09 15:32:47.009 +0100,24,2024-07-09 15:32:47.034 +0100,7
sync-dbms-version,2024-07-09 15:32:46.910 +0100,73,2024-07-09 15:32:46.983 +0100,7
sync,2024-07-09 15:32:46.872 +0100,14741,2024-07-09 15:33:01.614 +0100,7

Athena show queries being issues almost constantly:

![image](https://github.com/metabase/metabase/assets/173671402/73a8e078-fd4e-4511-8854-23befdd3708d)

I tried to set the Scan setting as you showed, but nothing has changed so far.

qnkhuat on (2024-07-10 02:50:29 UTC): These queries are part of our sync field values process to power filter dropdown.


If you don't want this process to run, you should uncheck the option before creating the database.

Though this sync performance is unacceptable, we'll create another issue for it.

"
2395186400,issue,closed,completed,Snowflake regextract no longer working,"### Describe the bug

We have just upgraded to v0.50.6 ( and v0.50.10) using the docker image, when creating a custom column using the below expression:

substring(regexextract([Tags], ""\""Name\"":\""((\\\""|[^\""])*)""), 9, 60)

we're now getting ""Invalid expression"". I can't remember the exact version we were on but I believe it was v.0.48. I've also tried the sample from the documentation regexextract([Tags], ""^[^?#]+\?utm_campaign=(.*)"") and that gives the same error

[This has more details](https://discourse.metabase.com/t/snowflake-regextract-no-longer-working/128266/4)

Metabase datatype ""Field containing JSON""
Snowflake datatype ""Variant""

### To Reproduce

1. Enter substring(regexextract([Tags], ""\""Name\"":\""((\\\""|[^\""])*)""), 9, 60) into a custom expression


### Expected behavior

This should work as per previous versions

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""athena"",
      ""snowflake"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Broken most of our Dashboards

### Additional context

_No response_",nmeneil,2024-07-08 09:56:47+00:00,['camsaul'],2024-08-28 02:08:59+00:00,2024-07-17 17:02:03+00:00,https://github.com/metabase/metabase/issues/45206,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('Database/Snowflake', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2216935183, 'issue_id': 2395186400, 'author': 'kamilmielnik', 'body': 'Error is coming from `Lib.diagnoseExpression`, assigning to QP.\r\nIt seems to depend on field type.', 'created_at': datetime.datetime(2024, 7, 9, 8, 28, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231517750, 'issue_id': 2395186400, 'author': 'camsaul', 'body': '@kamilmielnik can you please post the error that popped up?', 'created_at': datetime.datetime(2024, 7, 16, 18, 10, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231636495, 'issue_id': 2395186400, 'author': 'camsaul', 'body': 'to repro locally:\r\n\r\n1. Load Snowflake `test-data`\r\n2. manually change `venues.name` `base_type` to `type/*` and `database_type` to `VARIANT`\r\n3. In QB, start a new query against Venues\r\n4. Add custom column with expression `regexextract([Name] , ""\\""((\\\\\\""|[^\\""])*)"")`\r\n5. Observe error\r\n\r\n![image](https://github.com/user-attachments/assets/424e7ef2-a17d-40ba-aa81-665137592e67)\r\n\r\n```\r\ncore.cljs:3996 [metabase.lib.normalize] Error normalizing pMBQL:\r\n{:value\r\n [:regex-match-first\r\n  {:lib/uuid ""fc8e78ed-a4ee-43f5-aa3f-fbff96d62d62""}\r\n  [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]\r\n  ""\\\\\\""((\\\\\\\\\\\\\\""|[^\\\\\\""])*)""],\r\n :schema #object[malli.core.t_malli$core39458],\r\n :explain\r\n {:schema #object[malli.core.t_malli$core39458],\r\n  :value\r\n  [:regex-match-first\r\n   {:lib/uuid ""fc8e78ed-a4ee-43f5-aa3f-fbff96d62d62""}\r\n   [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]\r\n   ""\\\\\\""((\\\\\\\\\\\\\\""|[^\\\\\\""])*)""],\r\n  :errors\r\n  ({:path [0 2 0 0 1],\r\n    :in [2],\r\n    :schema #object[malli.core.t_malli$core39189],\r\n    :value [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]})}}\r\n\r\ndiagnostics.ts:158 diagnostic error Type error: , , [""expression returning a string""]\r\n```', 'created_at': datetime.datetime(2024, 7, 16, 19, 3, 55, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-07-09 08:28:27 UTC): Error is coming from `Lib.diagnoseExpression`, assigning to QP.
It seems to depend on field type.

camsaul (Assginee) on (2024-07-16 18:10:13 UTC): @kamilmielnik can you please post the error that popped up?

camsaul (Assginee) on (2024-07-16 19:03:55 UTC): to repro locally:

1. Load Snowflake `test-data`
2. manually change `venues.name` `base_type` to `type/*` and `database_type` to `VARIANT`
3. In QB, start a new query against Venues
4. Add custom column with expression `regexextract([Name] , ""\""((\\\""|[^\""])*)"")`
5. Observe error

![image](https://github.com/user-attachments/assets/424e7ef2-a17d-40ba-aa81-665137592e67)

```
core.cljs:3996 [metabase.lib.normalize] Error normalizing pMBQL:
{:value
 [:regex-match-first
  {:lib/uuid ""fc8e78ed-a4ee-43f5-aa3f-fbff96d62d62""}
  [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]
  ""\\\""((\\\\\\\""|[^\\\""])*)""],
 :schema #object[malli.core.t_malli$core39458],
 :explain
 {:schema #object[malli.core.t_malli$core39458],
  :value
  [:regex-match-first
   {:lib/uuid ""fc8e78ed-a4ee-43f5-aa3f-fbff96d62d62""}
   [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]
   ""\\\""((\\\\\\\""|[^\\\""])*)""],
  :errors
  ({:path [0 2 0 0 1],
    :in [2],
    :schema #object[malli.core.t_malli$core39189],
    :value [:field {:base-type :type/*, :lib/uuid ""5250f36c-2d28-4ece-bd03-0ed63836b433""} 33526]})}}

diagnostics.ts:158 diagnostic error Type error: , , [""expression returning a string""]
```

"
2395063354,issue,closed,completed,Ctrl + click on Search results and recent items is opening in the current tab instead of a new tab,"### Describe the bug

Ctrl + click on Search results and recent items should open in a new tab instead of the current tab.
Note that ""Ctrl + click"" is working for the ""Documentation"" part of the search result (probably because it is external links).

### To Reproduce

1. Browse Metabase v0.50.10 with Microsoft Edge
2. Open the search
3. Ctrl + click on Search results or a recent items


### Expected behavior

It should work like planned in https://github.com/metabase/metabase/pull/42167

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.11+9-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""17.0.11"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.11+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.94-99.176.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Shanghai""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""sqlserver"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Hong_Kong""
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",MarcSamD,2024-07-08 09:01:00+00:00,['npfitz'],2024-08-28 18:53:30+00:00,2024-08-28 18:17:25+00:00,https://github.com/metabase/metabase/issues/45205,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Search', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2395018691,issue,closed,completed,Unsupported function offset `Offset` Function in Metabase Query Builder ,"### Describe the bug

I am encountering an issue where the `Offset` function does not work as expected in the Summarize step of the Metabase Query Builder. When attempting to use `Offset` to access values from previous or next rows based on the current row, it either results in an error is returned, contrary to the expectations set by the official Metabase documentation.


**Actual Behavior**:
The function does not return an error

**Metabase Version**:
v0.50.8

**Additional Information**:
Any other details that might be helpful for the developers to diagnose the issue, such as the browser used, specific settings in Metabase, or screenshots depicting the problem.


### To Reproduce

1. Open Metabase and navigate to the Query Builder.
2. Select the `your-table` table.
3. Set up an aggregation to calculate the sum of the `Total` column.
4. Apply `Offset(Sum([Total]), -1)` to attempt retrieving the sum from the previous row.
5. Observe that the output does not match expected results or an error message is displayed.

### Expected behavior

The `Offset` function should return the sum of `Total` from the previous row according to the documentation but i have:

![image](https://github.com/metabase/metabase/assets/123993587/1e3f7d6f-6419-47f6-8962-69a3dcadc538)



### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.146.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-28"",
      ""tag"": ""v0.50.8"",
      ""hash"": ""dc9e68b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking my usage

### Additional context

_No response_",DieudonneCesar,2024-07-08 08:41:36+00:00,[],2024-10-21 09:16:25+00:00,2024-07-09 08:38:30+00:00,https://github.com/metabase/metabase/issues/45204,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2217333784, 'issue_id': 2395018691, 'author': 'uladzimirdev', 'body': '@DieudonneCesar how did you solve the issue? I checked 50.8 and offset function is available there', 'created_at': datetime.datetime(2024, 7, 9, 11, 0, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217461037, 'issue_id': 2395018691, 'author': 'DieudonneCesar', 'body': ""> @DieudonneCesar how did you solve the issue? I checked 50.8 and offset function is available there\r\n\r\nRefers to this issue https://github.com/metabase/metabase/issues/42908\r\n\r\nI didn't know that MySQL didn't support the offset function."", 'created_at': datetime.datetime(2024, 7, 9, 12, 2, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217511483, 'issue_id': 2395018691, 'author': 'uladzimirdev', 'body': 'indeed, it\'s not atm \r\n<img width=""846"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/7cffe557-21a2-4091-81a6-993bd37b8605"">', 'created_at': datetime.datetime(2024, 7, 9, 12, 21, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2348109850, 'issue_id': 2395018691, 'author': 'Jianbin719', 'body': 'Looking forward to the same for me.', 'created_at': datetime.datetime(2024, 9, 13, 6, 10, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426090491, 'issue_id': 2395018691, 'author': 'synque-dev-admin', 'body': 'Looking forward to this function', 'created_at': datetime.datetime(2024, 10, 21, 9, 16, 24, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-07-09 11:00:31 UTC): @DieudonneCesar how did you solve the issue? I checked 50.8 and offset function is available there

DieudonneCesar (Issue Creator) on (2024-07-09 12:02:10 UTC): Refers to this issue https://github.com/metabase/metabase/issues/42908

I didn't know that MySQL didn't support the offset function.

uladzimirdev on (2024-07-09 12:21:57 UTC): indeed, it's not atm 
<img width=""846"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/7cffe557-21a2-4091-81a6-993bd37b8605"">

Jianbin719 on (2024-09-13 06:10:17 UTC): Looking forward to the same for me.

synque-dev-admin on (2024-10-21 09:16:24 UTC): Looking forward to this function

"
2394560100,issue,closed,completed,Handle a case when `theme=transparent` and `background=false` are supplied,,WiNloSt,2024-07-08 03:57:03+00:00,['WiNloSt'],2024-07-11 09:09:31+00:00,2024-07-11 09:09:31+00:00,https://github.com/metabase/metabase/issues/45202,[],[],
2393440221,issue,closed,not_planned,DB Migration from H2 to MariaDB fails with Incorrect string value,"### Describe the bug

In reference to my previous encountered migration issue https://github.com/metabase/metabase/issues/40830 I have decided to retry the H2 DB migration, since quite a few new releases have been published; and my user interest is growing in this platform.

It looks like I am now seeing a different issue during the DB migration process, however I don't know whether this is an additional problem (and my previous issue just hasn't been hit yet).

My upgrade command:
`
java -DMB_DB_TYPE=mysql -DMB_DB_CONNECTION_URI=""jdbc:mysql://it-db-server-2.my-domain.local:3306/metabase?user=metabase-rw&password=12345678"" -jar metabase.jar load-from-h2 metabase.db
`

Essentially, to my untrained eyes, it appears to be falling over here:

`
2024-07-06 07:25:40,589 ERROR cmd.copy :: BatchUpdateException:
 Message: (conn=3536) Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
 SQLState: 22007
 Error Code: 1366
`

But I don't know what I can do to fix it.

Any advice or assistance would be appreciated.


### To Reproduce

Upgrade DB from H2 to MariaDB.

### Expected behavior

The H2 DB migrates to MariaDB smoothly and without error.

### Logs


`
2024-07-06 07:24:58,258 INFO metabase.util :: Maximum memory available to JVM: 916.0 MB
2024-07-06 07:25:03,655 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-06 07:25:14,929 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
2024-07-06 07:25:14,939 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-07-06 07:25:14,947 INFO metabase.util :: Load driver :sql-jdbc took 56.1 ms
2024-07-06 07:25:14,949 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-07-06 07:25:15,269 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
2024-07-06 07:25:15,337 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-07-06 07:25:18,807 INFO metabase.core ::
Metabase v0.50.10 (49d9e46)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-07-06 07:25:18,906 INFO driver.impl :: Registered abstract driver :metabase.driver.sql-jdbc.execute.legacy-impl/use-legacy-classes-for-read-and-set  ðŸšš
2024-07-06 07:25:18,915 INFO driver.impl :: Registered abstract driver :metabase.driver.sql.query-processor.empty-string-is-null/empty-string-is-null  ðŸšš
2024-07-06 07:25:19,582 INFO cmd.copy :: Set up h2 source database and run migrations...
2024-07-06 07:25:19,585 INFO db.setup :: Verifying h2 Database Connection ...
2024-07-06 07:25:20,614 INFO db.setup :: Successfully verified H2 2.1.214 (2022-06-13) application database connection. âœ…
2024-07-06 07:25:20,615 INFO db.setup :: Checking if a database downgrade is required...
2024-07-06 07:25:22,154 INFO db.setup :: Running Database Migrations...
2024-07-06 07:25:22,161 INFO db.setup :: Setting up Liquibase...
2024-07-06 07:25:22,727 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-07-06 07:25:22,871 INFO db.liquibase :: No migration lock found.
2024-07-06 07:25:22,872 INFO db.liquibase :: Migration lock acquired.
2024-07-06 07:25:23,041 INFO db.setup :: Liquibase is ready.
2024-07-06 07:25:23,041 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-06 07:25:24,233 INFO db.liquibase :: No unrun migrations found.
2024-07-06 07:25:24,236 INFO db.setup :: Database Migrations Current ... âœ…
2024-07-06 07:25:24,239 INFO metabase.util :: Database setup took 4.7 s
2024-07-06 07:25:24,241 INFO cmd.copy :: [OK]
2024-07-06 07:25:24,243 INFO cmd.copy :: Set up mysql target database and run migrations...
2024-07-06 07:25:24,244 INFO db.setup :: Verifying mysql Database Connection ...
2024-07-06 07:25:24,464 INFO db.setup :: Successfully verified MariaDB 10.6.12-MariaDB-log application database connection. âœ…
2024-07-06 07:25:24,465 INFO db.setup :: Checking if a database downgrade is required...
2024-07-06 07:25:24,923 INFO db.setup :: Running Database Migrations...
2024-07-06 07:25:24,925 INFO db.setup :: Setting up Liquibase...
2024-07-06 07:25:25,258 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-07-06 07:25:25,271 INFO db.liquibase :: No migration lock found.
2024-07-06 07:25:25,271 INFO db.liquibase :: Migration lock acquired.
2024-07-06 07:25:25,285 INFO db.setup :: Liquibase is ready.
2024-07-06 07:25:25,286 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-06 07:25:26,406 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-07-06 07:25:26,420 INFO db.liquibase :: No migration lock found.
2024-07-06 07:25:26,421 INFO db.liquibase :: Migration lock acquired.
2024-07-06 07:25:27,137 INFO db.liquibase :: Running 385 migrations ...
2024-07-06 07:25:32,640 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-07-06 07:25:32,663 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-07-06 07:25:32,664 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-07-06 07:25:32,666 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-07-06 07:25:32,670 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-07-06 07:25:32,672 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'g0001111720247132643'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-07-06 07:25:32,674 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-07-06 07:25:32,674 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-07-06 07:25:32,717 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247132643 started.
2024-07-06 07:25:32,745 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247132643 shutting down.
2024-07-06 07:25:32,745 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247132643 paused.
2024-07-06 07:25:32,747 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247132643 shutdown complete.
2024-07-06 07:25:33,428 INFO db.custom-migrations :: No forward migration for DowngradeDashboardTab
2024-07-06 07:25:38,950 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-07-06 07:25:38,954 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-07-06 07:25:38,955 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-07-06 07:25:38,955 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-07-06 07:25:38,955 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-07-06 07:25:38,955 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'g0001111720247138951'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-07-06 07:25:38,956 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-07-06 07:25:38,956 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-07-06 07:25:38,964 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247138951 started.
2024-07-06 07:25:38,983 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247138951 shutting down.
2024-07-06 07:25:38,985 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247138951 paused.
2024-07-06 07:25:38,986 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111720247138951 shutdown complete.
2024-07-06 07:25:38,993 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
2024-07-06 07:25:39,001 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade

UPDATE SUMMARY
Run:                        385
Previously run:               0
Filtered out:                 6
-------------------------------
Total change sets:          391


FILTERED CHANGE SETS SUMMARY
Ignored:                      1
DBMS mismatch:                5

2024-07-06 07:25:39,718 INFO db.liquibase :: Migration complete in 12.6 s
2024-07-06 07:25:39,727 INFO db.setup :: Database Migrations Current ... âœ…
2024-07-06 07:25:39,730 INFO metabase.util :: Database setup took 15.5 s
2024-07-06 07:25:39,731 INFO cmd.copy :: [OK]
2024-07-06 07:25:39,733 INFO cmd.copy :: Testing if target mysql database is already populated...
2024-07-06 07:25:39,738 INFO cmd.copy :: [OK]
2024-07-06 07:25:39,740 INFO cmd.copy :: Clearing default entries created by Liquibase migrations...
2024-07-06 07:25:39,742 INFO cmd.copy :: Temporarily disabling DB constraints...
2024-07-06 07:25:39,746 INFO cmd.copy :: [OK]
2024-07-06 07:25:40,327 INFO cmd.copy :: Re-enabling DB constraints...
2024-07-06 07:25:40,330 INFO cmd.copy :: [OK]
2024-07-06 07:25:40,331 INFO cmd.copy :: [OK]
2024-07-06 07:25:40,336 INFO cmd.copy :: Temporarily disabling DB constraints...
2024-07-06 07:25:40,337 INFO cmd.copy :: [OK]
2024-07-06 07:25:40,357 INFO cmd.copy :: Copying instances of Database...
2024-07-06 07:25:40,428 INFO cmd.copy ::  copied 5 instances.
2024-07-06 07:25:40,435 INFO cmd.copy :: Copying instances of User...
2024-07-06 07:25:40,463 INFO cmd.copy ::  copied 13 instances.
2024-07-06 07:25:40,486 INFO cmd.copy :: Copying instances of Setting...
2024-07-06 07:25:40,589 ERROR cmd.copy :: BatchUpdateException:
 Message: (conn=3536) Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
 SQLState: 22007
 Error Code: 1366

2024-07-06 07:25:40,601 INFO cmd.copy :: Re-enabling DB constraints...
2024-07-06 07:25:40,609 INFO cmd.copy :: [OK]
clojure.lang.ExceptionInfo: Error copying instances of Setting {:model ""Setting""}
        at metabase.cmd.copy$copy_data_BANG_$fn__100057$fn__100058.invoke(copy.clj:196)
        at metabase.cmd.copy$copy_data_BANG_$fn__100057.invoke(copy.clj:193)
        at clojure.core$partition_all$fn__8625$fn__8626.invoke(core.clj:7326)
        at clojure.core$filter$fn__5958$fn__5959.invoke(core.clj:2820)
        at clojure.core$transduce.invokeStatic(core.clj:6949)
        at clojure.core$transduce.invoke(core.clj:6934)
        at metabase.cmd.copy$copy_data_BANG_.invokeStatic(copy.clj:180)
        at metabase.cmd.copy$copy_data_BANG_.invoke(copy.clj:174)
        at metabase.cmd.copy$copy_BANG_$fn__100192$fn__100193$fn__100194.invoke(copy.clj:411)
        at metabase.cmd.copy$do_with_disabled_db_constraints.invokeStatic(copy.clj:275)
        at metabase.cmd.copy$do_with_disabled_db_constraints.invoke(copy.clj:271)
        at metabase.cmd.copy$copy_BANG_$fn__100192$fn__100193.invoke(copy.clj:410)
        at metabase.cmd.copy$do_with_connection_rollback_only.invokeStatic(copy.clj:217)
        at metabase.cmd.copy$do_with_connection_rollback_only.invoke(copy.clj:215)
        at metabase.cmd.copy$copy_BANG_$fn__100192.invoke(copy.clj:408)
        at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:807)
        at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776)
        at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:852)
        at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776)
        at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789)
        at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776)
        at metabase.cmd.copy$copy_BANG_.invokeStatic(copy.clj:405)
        at metabase.cmd.copy$copy_BANG_.invoke(copy.clj:380)
        at metabase.cmd.load_from_h2$load_from_h2_BANG_.invokeStatic(load_from_h2.clj:35)
        at metabase.cmd.load_from_h2$load_from_h2_BANG_.invoke(load_from_h2.clj:25)
        at clojure.lang.Var.invoke(Var.java:384)
        at metabase.cmd$load_from_h2.invokeStatic(cmd.clj:74)
        at metabase.cmd$load_from_h2.invoke(cmd.clj:68)
        at clojure.lang.AFn.applyToHelper(AFn.java:154)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.cmd$run_cmd$fn__106782.invoke(cmd.clj:301)
        at metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)
        at metabase.cmd$run_cmd.invoke(cmd.clj:290)
        at clojure.lang.Var.invoke(Var.java:388)
        at metabase.core$run_cmd.invokeStatic(core.clj:192)
        at metabase.core$run_cmd.invoke(core.clj:190)
        at metabase.core$entrypoint.invokeStatic(core.clj:214)
        at metabase.core$entrypoint.doInvoke(core.clj:209)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at metabase.bootstrap.main(Unknown Source)
Caused by: java.sql.BatchUpdateException: (conn=3536) Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
        at org.mariadb.jdbc.MariaDbStatement.executeBatchExceptionEpilogue(MariaDbStatement.java:323)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeBatch(ClientSidePreparedStatement.java:299)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeBatch(NewProxyPreparedStatement.java:2544)
        at clojure.java.jdbc$execute_batch.invokeStatic(jdbc.clj:598)
        at clojure.java.jdbc$execute_batch.invoke(jdbc.clj:591)
        at clojure.java.jdbc$db_do_execute_prepared_statement.invokeStatic(jdbc.clj:1058)
        at clojure.java.jdbc$db_do_execute_prepared_statement.invoke(jdbc.clj:1042)
        at clojure.java.jdbc$db_do_prepared.invokeStatic(jdbc.clj:1080)
        at clojure.java.jdbc$db_do_prepared.invoke(jdbc.clj:1060)
        at clojure.java.jdbc$insert_cols_BANG_.invokeStatic(jdbc.clj:1594)
        at clojure.java.jdbc$insert_cols_BANG_.invoke(jdbc.clj:1585)
        at clojure.java.jdbc$insert_multi_BANG_.invokeStatic(jdbc.clj:1653)
        at clojure.java.jdbc$insert_multi_BANG_.invoke(jdbc.clj:1619)
        at metabase.cmd.copy$insert_chunk_BANG_.invokeStatic(copy.clj:129)
        at metabase.cmd.copy$insert_chunk_BANG_.invoke(copy.clj:123)
        at metabase.cmd.copy$copy_data_BANG_$fn__100057$fn__100058.invoke(copy.clj:194)
        ... 47 more
Caused by: java.sql.SQLSyntaxErrorException: (conn=3536) Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
        at org.mariadb.jdbc.MariaDbStatement.executeBatchExceptionEpilogue(MariaDbStatement.java:319)
        ... 62 more
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
        at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.access$000(AbstractQueryProtocol.java:108)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol$1.handleResultException(AbstractQueryProtocol.java:690)
        at org.mariadb.jdbc.internal.protocol.AsyncMultiRead.call(AsyncMultiRead.java:141)
        at org.mariadb.jdbc.internal.protocol.AsyncMultiRead.call(AsyncMultiRead.java:67)
        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
        at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\xA4\x96 b...' for column `metabase`.`setting`.`value` at row 1
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
        at org.mariadb.jdbc.internal.protocol.AsyncMultiRead.call(AsyncMultiRead.java:132)
        ... 5 more
Command failed with exception: Error copying instances of Setting

`

### Information about your Metabase installation

```JSON
**Metabase v0.50.10** 
**Rocky 9.4** 
Attempting to migrate the **H2 DB** to an separate **MariaDB (v10.6.12)** server.
MariaDB database configured as DB charset: utf8mb4 and database collation: utf8mb4_unicode_ci
```


### Severity

High - My DB grows as my users are beginning to use it more and more and will soon be quite critical to their jobs. I understand that H2 shouldn't be used in production or for larger DB's, so getting it migrated successfully feels like a priority now.

### Additional context

_No response_",hgpit,2024-07-06 06:44:56+00:00,[],2025-01-22 14:22:06+00:00,2025-01-22 14:22:04+00:00,https://github.com/metabase/metabase/issues/45200,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/MySQL', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2607380743, 'issue_id': 2393440221, 'author': 'luizarakaki', 'body': ""@hgpit do you have news about this?\nHighly recommend using Postgres as the Metabase application database.\nClosing while we don't have more info."", 'created_at': datetime.datetime(2025, 1, 22, 14, 22, 4, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-22 14:22:04 UTC): @hgpit do you have news about this?
Highly recommend using Postgres as the Metabase application database.
Closing while we don't have more info.

"
2392990142,issue,closed,not_planned,Improve look of sidebar cache section error messages,,rafpaf,2024-07-05 18:20:37+00:00,[],2024-08-08 12:48:13+00:00,2024-08-08 12:48:12+00:00,https://github.com/metabase/metabase/issues/45193,[],"[{'comment_id': 2275740198, 'issue_id': 2392990142, 'author': 'rafpaf', 'body': 'Will move this into the Cache followups issue to simplify the board', 'created_at': datetime.datetime(2024, 8, 8, 12, 48, 12, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-08-08 12:48:12 UTC): Will move this into the Cache followups issue to simplify the board

"
2392833778,issue,open,,history.back in the browser will go to a 404 when metabase lives in a sub-path (probably only on interactive embedding?),"### Describe the bug

If you set up metabase on a sub domain, then every back history will append the sub-path on the path, leading to 404's

### To Reproduce

1) set up metabase on a sub path (E.g. domain/metabase
2) embed metabase via interactive embedding
3) on the embedded session, create an x-ray and then click on the back button, see that you go to a 404

### Expected behavior

Metabase should not send you to a 404

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P2-3

### Additional context

We don't support sub-paths
Video: 
![Peek 2024-07-05 12-47](https://github.com/metabase/metabase/assets/1711649/2e874916-2aa2-46a6-9c19-1797e69ce542)

",paoliniluis,2024-07-05 15:47:34+00:00,[],2024-07-05 16:04:12+00:00,,https://github.com/metabase/metabase/issues/45186,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]",[],
2392734023,issue,closed,completed,Cannot change the stacking setting on stats,"It is not possible to change the stacking setting on the question from [this slack message](https://metaboat.slack.com/archives/C01LQQ2UW03/p1720165581389739)
",alxnddr,2024-07-05 14:39:44+00:00,['alxnddr'],2024-07-08 23:38:33+00:00,2024-07-08 23:05:46+00:00,https://github.com/metabase/metabase/issues/45182,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2392702464,issue,open,,A model fail to cache but query works,"### Describe the bug

I have seven models using the same database, but only six of them have been successfully refreshed. When I run the query for the model that failed, it executes in less than one minute. Why does it continue to fail?

### To Reproduce

1 - Allow time for caching.
2 - On the tools page, the model encounters the following error:
ERREUR: annulation de la requÃªte Ã  cause du dÃ©lai Ã©coulÃ© pour l'exÃ©cution de l'instruction



### Expected behavior

The model should be cached as it was previously.

### Logs

> INFO metabase.task.persist-refresh Error refreshing persisting model with card-id 273,org.postgresql.util.PSQLException: ERREUR: annulation de la requÃªte Ã  cause du dÃ©lai Ã©coulÃ© pour l'exÃ©cution de l'instruction,	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725),	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412),	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371),	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502),	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419),	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194),	at org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:155),	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502),	at clojure.java.jdbc$db_do_execute_prepared_statement$fn__41953.invoke(jdbc.clj:1049),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:860),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_do_execute_prepared_statement.invokeStatic(jdbc.clj:1048),	at clojure.java.jdbc$db_do_execute_prepared_statement.invoke(jdbc.clj:1042),	at clojure.java.jdbc$db_do_prepared.invokeStatic(jdbc.clj:1080),	at clojure.java.jdbc$db_do_prepared.invoke(jdbc.clj:1060),	at clojure.java.jdbc$execute_BANG_$execute_helper__42027.invoke(jdbc.clj:1464),	at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1466),	at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),	at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1456),	at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),	at metabase.driver.sql.ddl$execute_BANG_.invokeStatic(ddl.clj:27),	at metabase.driver.sql.ddl$execute_BANG_.invoke(ddl.clj:24),	at metabase.driver.postgres.ddl$fn__85617$fn__85619$fn__85620.invoke(ddl.clj:49),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:807),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at metabase.driver.postgres.ddl$fn__85617$fn__85619.invoke(ddl.clj:46),	at metabase.driver.sql_jdbc.execute$fn__81291$fn__81292.invoke(execute.clj:397),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320),	at metabase.driver.sql_jdbc.execute$fn__81291.invokeStatic(execute.clj:391),	at metabase.driver.sql_jdbc.execute$fn__81291.invoke(execute.clj:389),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.driver.postgres.ddl$fn__85617.invokeStatic(ddl.clj:41),	at metabase.driver.postgres.ddl$fn__85617.invoke(ddl.clj:38),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.task.persist_refresh$reify__86565.refresh_BANG_(persist_refresh.clj:53),	at metabase.task.persist_refresh$refresh_with_stats_BANG_$fn__86568.invoke(persist_refresh.clj:73),	at metabase.task.persist_refresh$refresh_with_stats_BANG_.invokeStatic(persist_refresh.clj:72),	at metabase.task.persist_refresh$refresh_with_stats_BANG_.invoke(persist_refresh.clj:57),	at clojure.lang.AFn.applyToHelper(AFn.java:165),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:673),	at clojure.core$partial$fn__5914.doInvoke(core.clj:2660),	at clojure.lang.RestFn.invoke(RestFn.java:397),	at metabase.task.persist_refresh$save_task_history_BANG_$fn__86586.invoke(persist_refresh.clj:123),	at metabase.models.task_history$do_with_task_history.invokeStatic(task_history.clj:116),	at metabase.models.task_history$do_with_task_history.invoke(task_history.clj:105),	at metabase.task.persist_refresh$save_task_history_BANG_.invokeStatic(persist_refresh.clj:115),	at metabase.task.persist_refresh$save_task_history_BANG_.invoke(persist_refresh.clj:111),	at metabase.task.persist_refresh$refresh_individual_BANG_.invokeStatic(persist_refresh.clj:219),	at metabase.task.persist_refresh$refresh_individual_BANG_.invoke(persist_refresh.clj:211),	at metabase.task.persist_refresh$refresh_job_fn_BANG_.invokeStatic(persist_refresh.clj:235),	at metabase.task.persist_refresh$refresh_job_fn_BANG_.invoke(persist_refresh.clj:229),	at metabase.task.persist_refresh.PersistenceRefresh.execute(persist_refresh.clj:245),	at org.quartz.core.JobRunShell.run(JobRunShell.java:202),	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
[d7ed4fe8-1eca-4698-9c79-6a1166322f22] 2024-07-05T16:11:19+02:00 INFO metabase.task.persist-refresh Finished updated model-id 273 from persisted-info 161.

### Information about your Metabase installation

```JSON
Metabase is installed on Windows Server 2016 and is configured for production mode with a MySQL 8 server. It is running version v0.50.8. The database that the model points to is PostgreSQL.
```


### Severity

I can't run my other reports that depend on this model

### Additional context

_No response_",vipera7,2024-07-05 14:20:15+00:00,[],2025-02-04 20:28:23+00:00,,https://github.com/metabase/metabase/issues/45181,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Cache', ''), ('.Team/Querying', '')]","[{'comment_id': 2228352620, 'issue_id': 2392702464, 'author': 'vipera7', 'body': 'I observed that if I disable the option to persist the model in the admin settings and then re-enable it, the models are correctly persisted. This might provide a clue.', 'created_at': datetime.datetime(2024, 7, 15, 12, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228403615, 'issue_id': 2392702464, 'author': 'paoliniluis', 'body': 'metabase version?', 'created_at': datetime.datetime(2024, 7, 15, 12, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228412327, 'issue_id': 2392702464, 'author': 'vipera7', 'body': 'Hello paoliniluis,\r\n\r\nHere are the info of my Metabase:\r\n\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""fr-FR"",\r\n    ""platform"": ""Win32"",\r\n    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""Cp1252"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.23+9"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.23"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.23+9"",\r\n    ""os.name"": ""Windows Server 2016"",\r\n    ""os.version"": ""10.0"",\r\n    ""user.language"": ""fr"",\r\n    ""user.timezone"": ""Europe/Paris""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres"",\r\n      ""mysql""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""mysql"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""MySQL"",\r\n        ""version"": ""8.0.36""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""MariaDB Connector/J"",\r\n        ""version"": ""2.7.10""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""plan-alias"": """",\r\n    ""version"": {\r\n      ""date"": ""2024-07-12"",\r\n      ""tag"": ""v0.50.12"",\r\n      ""hash"": ""86d4671""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": ""Europe/Paris""\r\n    }\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 7, 15, 12, 40, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2235832555, 'issue_id': 2392702464, 'author': 'vipera7', 'body': 'I wonder if the name of the last model is related to this issue: \r\n\r\n![Sans titre](https://github.com/user-attachments/assets/97a5b6de-2b6e-4bfe-bc0b-cce042808045)', 'created_at': datetime.datetime(2024, 7, 18, 7, 37, 52, tzinfo=datetime.timezone.utc)}]","vipera7 (Issue Creator) on (2024-07-15 12:09:38 UTC): I observed that if I disable the option to persist the model in the admin settings and then re-enable it, the models are correctly persisted. This might provide a clue.

paoliniluis on (2024-07-15 12:35:43 UTC): metabase version?

vipera7 (Issue Creator) on (2024-07-15 12:40:27 UTC): Hello paoliniluis,

Here are the info of my Metabase:

```
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""fr"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.36""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-12"",
      ""tag"": ""v0.50.12"",
      ""hash"": ""86d4671""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```

vipera7 (Issue Creator) on (2024-07-18 07:37:52 UTC): I wonder if the name of the last model is related to this issue: 

![Sans titre](https://github.com/user-attachments/assets/97a5b6de-2b6e-4bfe-bc0b-cce042808045)

"
2392625572,issue,open,,[Epic] Faster sync on more databases,"[Product doc](https://www.notion.so/metabase/Faster-sync-for-more-drivers-d5b657aba7354a19bf89d62f1038a8ff?pvs=4)

related issues:
https://github.com/metabase/metabase/issues/45335",luizarakaki,2024-07-05 13:35:14+00:00,[],2025-02-04 20:24:34+00:00,,https://github.com/metabase/metabase/issues/45179,"[('Administration/Metadata & Sync', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]",[],
2392111084,issue,open,,Support users to manually set more than 2 y axis,"When a user displays multiple related line charts in one line chart, but their units are not the same; It is therefore necessary for users to set multiple corresponding Y-axes to see their trends, such as those on grafana
https://grafana.com/docs/grafana/latest/panels-visualizations/visualizations/xy-chart/
![image](https://github.com/metabase/metabase/assets/116729925/a89aa4e9-9918-439c-8092-e9fa00f22eca)
",aruizhong,2024-07-05 08:21:03+00:00,[],2025-02-04 20:31:41+00:00,,https://github.com/metabase/metabase/issues/45172,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Visualization/Legend', '')]","[{'comment_id': 2568054340, 'issue_id': 2392111084, 'author': 'brunobergher', 'body': ""@aruizhong can you please expand on why you'd need more than 2 y axes? How would the legend be displayed? Do you have links to examples of that being done well elsewhere?"", 'created_at': datetime.datetime(2025, 1, 2, 16, 37, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572730570, 'issue_id': 2392111084, 'author': 'aruizhong', 'body': ""> [@aruizhong](https://github.com/aruizhong) can you please expand on why you'd need more than 2 y axes? How would the legend be displayed? Do you have links to examples of that being done well elsewhere?\n\nhttps://community.grafana.com/t/multiple-y-axis/49550/4 ![Image](https://github.com/user-attachments/assets/f7438274-946b-424e-9ebb-ee55e19545ac)\nBecause of the strong correlation in several trends, users want to be able to view in one line chart without having to make too many line charts and take up too much space on the dashboard"", 'created_at': datetime.datetime(2025, 1, 6, 9, 38, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572738265, 'issue_id': 2392111084, 'author': 'aruizhong', 'body': ""> > [@aruizhong](https://github.com/aruizhong) can you please expand on why you'd need more than 2 y axes? How would the legend be displayed? Do you have links to examples of that being done well elsewhere?\n> \n> https://community.grafana.com/t/multiple-y-axis/49550/4 ![Image](https://github.com/user-attachments/assets/f7438274-946b-424e-9ebb-ee55e19545ac) Because of the strong correlation in several trends, users want to be able to view in one line chart without having to make too many line charts and take up too much space on the dashboard\n\nAnd because their value units or min max have large differences, the flexibility to specify the Y-axis can clearly see the development of the trend"", 'created_at': datetime.datetime(2025, 1, 6, 9, 42, 47, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 16:37:45 UTC): @aruizhong can you please expand on why you'd need more than 2 y axes? How would the legend be displayed? Do you have links to examples of that being done well elsewhere?

aruizhong (Issue Creator) on (2025-01-06 09:38:09 UTC): https://community.grafana.com/t/multiple-y-axis/49550/4 ![Image](https://github.com/user-attachments/assets/f7438274-946b-424e-9ebb-ee55e19545ac)
Because of the strong correlation in several trends, users want to be able to view in one line chart without having to make too many line charts and take up too much space on the dashboard

aruizhong (Issue Creator) on (2025-01-06 09:42:47 UTC): And because their value units or min max have large differences, the flexibility to specify the Y-axis can clearly see the development of the trend

"
2392082209,issue,open,,Separate number and date formatting for CSV uploads from display settings,"**Is your feature request related to a problem? Please describe.**
Currently the Separator Style setting in Admin Settings / Localization / Numbers / Separator Style affects how numbers in uploaded files are parsed. This may occasionally lead to unexpected behavior.

For example, setting the display number format to `100.000,00` (used in Denmark) causes the parser to ignore the decimal comma, and a number like `18500.00` will be parsed as the integer `1850000`.

**Describe the solution you'd like**
Ideally, the number format for parsing CSV files should be configurable separately from the display number format. 
This would allow users to set the number format for their CSV that might differ from the one preferred to displaying them.

**Describe alternatives you've considered**
Currently, there are no good alternatives. Users must use the same number format for both display and CSV parsing. If their input format differs from their display preference, they either need to convert the file or select a less desirable display format compatible with their input.

**How important is this feature to you?**
Reported by a customer - I used their actual example above.

**Additional context**
n/a
",zbodi74,2024-07-05 08:06:10+00:00,[],2025-02-04 20:30:19+00:00,,https://github.com/metabase/metabase/issues/45171,"[('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2260417380, 'issue_id': 2392082209, 'author': 'ds-clearago', 'body': ""I agree â€“ effectively Metabase is the only tool now where we have to convert `.`-decimals to `,`-decimals prior to uploading into the system just because our display settings are set to Germany (where our clients reside).\r\n\r\nEverywhere else where we export/import CSVs the values are comma-separated while no thousands separator is used and decimals are split by the international digital `.`\r\n\r\nSince almost every other code denotes floats with `.` just metabase CSV doesn't that's very unintuitive behavior â€“\xa0and has already caused us multiple wrong dashboards for clients as there was a mixup between usage of `.` and `,`... Can I upvote this somehow?"", 'created_at': datetime.datetime(2024, 7, 31, 12, 33, 31, tzinfo=datetime.timezone.utc)}]","ds-clearago on (2024-07-31 12:33:31 UTC): I agree â€“ effectively Metabase is the only tool now where we have to convert `.`-decimals to `,`-decimals prior to uploading into the system just because our display settings are set to Germany (where our clients reside).

Everywhere else where we export/import CSVs the values are comma-separated while no thousands separator is used and decimals are split by the international digital `.`

Since almost every other code denotes floats with `.` just metabase CSV doesn't that's very unintuitive behavior â€“Â and has already caused us multiple wrong dashboards for clients as there was a mixup between usage of `.` and `,`... Can I upvote this somehow?

"
2392080555,issue,closed,not_planned,"No more new records produced in table ""view_log"" after upgrading metabase to v0.50.9","### Describe the bug

After upgrading metabase to v0.50.9 and v0.50.10, no more new data produced in table ""view_log"", the system table of metabase.

### To Reproduce

1. Viewing any reports on metabase.
2. Checking if the metabase system table ""view_log"" produces the newest records.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
* Metabase hosting environment: CentOS, Docker
* Metabase internal database: Postgres
* Metabase version: v0.50.9 and v0.50.10
```


### Severity

Low

### Additional context

_No response_",Jerrylovescoding,2024-07-05 08:05:17+00:00,[],2024-07-05 16:11:25+00:00,2024-07-05 13:18:59+00:00,https://github.com/metabase/metabase/issues/45170,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2210866387, 'issue_id': 2392080555, 'author': 'luizarakaki', 'body': 'This change was announced on v49 but only implemented on v50: `view_log` is not populated anymore on the community version.', 'created_at': datetime.datetime(2024, 7, 5, 13, 18, 59, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-07-05 13:18:59 UTC): This change was announced on v49 but only implemented on v50: `view_log` is not populated anymore on the community version.

"
2392057730,issue,open,,Legend Support Visibility and Values,"When users are faced with multiple line chart trends, it is very important to view the trend of a specific line chart by clicking on a legend.
The value of the legend can help the user quickly obtain the value, maximum value, average value, etc., for the last day.
All of these features are supported on grafana, and I look forward to seeing them on metabase.
https://grafana.com/docs/grafana/latest/panels-visualizations/configure-legend/
![image](https://github.com/metabase/metabase/assets/116729925/bc8b7919-8d62-4ac4-9b53-b089a1d93a13)
",aruizhong,2024-07-05 07:53:13+00:00,[],2025-02-05 14:54:39+00:00,,https://github.com/metabase/metabase/issues/45169,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Visualization/Legend', '')]","[{'comment_id': 2568056350, 'issue_id': 2392057730, 'author': 'brunobergher', 'body': ""@aruizhong I'm having some difficulty understanding your request.\n\nAre you asking for the ability to see get characteristics of a series (min, max, avg, median) automatically from a click or from the legend?"", 'created_at': datetime.datetime(2025, 1, 2, 16, 39, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572711507, 'issue_id': 2392057730, 'author': 'aruizhong', 'body': ""> [@aruizhong](https://github.com/aruizhong) I'm having some difficulty understanding your request.\n> \n> Are you asking for the ability to see get characteristics of a series (min, max, avg, median) automatically from a click or from the legend?\n\nyes, ![Image](https://github.com/user-attachments/assets/4e1d1779-101f-4381-aff9-e7aac1d85ef1)\nhere is grafana legend values supportted"", 'created_at': datetime.datetime(2025, 1, 6, 9, 30, 10, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 16:39:17 UTC): @aruizhong I'm having some difficulty understanding your request.

Are you asking for the ability to see get characteristics of a series (min, max, avg, median) automatically from a click or from the legend?

aruizhong (Issue Creator) on (2025-01-06 09:30:10 UTC): yes, ![Image](https://github.com/user-attachments/assets/4e1d1779-101f-4381-aff9-e7aac1d85ef1)
here is grafana legend values supportted

"
2391973302,issue,closed,not_planned,"Server startup fails with ""Unterminated string literal"" error","### Describe the bug

After upgrade to `Metabase v0.50.10` I have started getting below error during server start which is causing the metabase to crash.

```
2024-07-05 06:44:47,729 INFO db.liquibase :: Running 64 migrations ...
2024-07-05 06:44:48,019 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:30::noahmoss encountered an exception.
liquibase.exception.DatabaseException: Unterminated string literal started at position 1,694 in SQL -- Insert table-level permissions only where no DB-level permissions exist
```

### To Reproduce

1. Use `Metabase v0.50.10 (49d9e46)`
2. Start/Restart the metabase server


### Expected behavior

Should start the metabase server without any migration errors

### Logs

```
2024-07-05 06:44:46,028 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-07-05 06:44:46,028 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""]
2024-07-05 06:44:46,034 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-05 06:44:46,036 INFO db.setup :: Verifying postgres Database Connection ...
2024-07-05 06:44:46,368 INFO db.setup :: Successfully verified PostgreSQL 10.7 application database connection. âœ…
2024-07-05 06:44:46,368 INFO db.setup :: Checking if a database downgrade is required...
2024-07-05 06:44:46,909 INFO db.setup :: Running Database Migrations...
2024-07-05 06:44:46,910 INFO db.setup :: Setting up Liquibase...
2024-07-05 06:44:47,066 INFO db.setup :: Liquibase is ready.
2024-07-05 06:44:47,067 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-05 06:44:47,506 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-07-05 06:44:47,517 INFO db.liquibase :: No migration lock found.
2024-07-05 06:44:47,517 INFO db.liquibase :: Migration lock acquired.
2024-07-05 06:44:47,729 INFO db.liquibase :: Running 64 migrations ...
2024-07-05 06:44:48,019 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:30::noahmoss encountered an exception.
liquibase.exception.DatabaseException: Unterminated string literal started at position 1,694 in SQL -- Insert table-level permissions only where no DB-level permissions exist

WITH escaped_schema_table AS (
    SELECT
    mt.id,
    mt.db_id,
    mt.schema,
    REPLACE(REPLACE(mt.schema, '\', '\\'), '/', '\/') AS escaped_schema
    FROM metabase_table mt
)
INSERT INTO data_permissions (group_id, perm_type, db_id, schema_name, table_id, perm_value)
SELECT pg.id AS group_id,
       'perms/data-access' AS perm_type,
       mt.db_id,
       mt.schema AS schema_name,
       mt.id AS table_id,
       CASE
           WHEN EXISTS
                  (SELECT 1
                   FROM permissions p
                   WHERE p.group_id = pg.id
                     AND (p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/query/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/query/segmented/')) ) THEN 'unrestricted'
           ELSE 'no-self-service'
       END AS perm_value
FROM permissions_group pg
CROSS JOIN escaped_schema_table mt
WHERE pg.name != 'Administrators'
  AND NOT EXISTS
    (SELECT 1
     FROM data_permissions dp
     WHERE dp.group_id = pg.id
       AND dp.db_id = mt.db_id
       AND dp.table_id = mt.id
       AND dp.perm_type = 'perms/data-access' )
  AND NOT EXISTS
    (SELECT 1
     FROM data_permissions dp
     WHERE dp.group_id = pg.id
       AND dp.db_id = mt.db_id
       AND dp.table_id IS NULL
       AND dp.perm_type = 'perms/data-access' ). Expected  char [Failed SQL: (0) -- Insert table-level permissions only where no DB-level permissions exist

WITH escaped_schema_table AS (
    SELECT
    mt.id,
    mt.db_id,
    mt.schema,
    REPLACE(REPLACE(mt.schema, '\', '\\'), '/', '\/') AS escaped_schema
    FROM metabase_table mt
)
INSERT INTO data_permissions (group_id, perm_type, db_id, schema_name, table_id, perm_value)
SELECT pg.id AS group_id,
       'perms/data-access' AS perm_type,
       mt.db_id,
       mt.schema AS schema_name,
       mt.id AS table_id,
       CASE
           WHEN EXISTS
                  (SELECT 1
                   FROM permissions p
                   WHERE p.group_id = pg.id
                     AND (p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/query/')
                          OR p.object = concat('/db/', mt.db_id, '/schema/', mt.escaped_schema, '/table/', mt.id, '/query/segmented/')) ) THEN 'unrestricted'
           ELSE 'no-self-service'
       END AS perm_value
FROM permissions_group pg
CROSS JOIN escaped_schema_table mt
WHERE pg.name != 'Administrators'
  AND NOT EXISTS
    (SELECT 1
     FROM data_permissions dp
     WHERE dp.group_id = pg.id
       AND dp.db_id = mt.db_id
       AND dp.table_id = mt.id
       AND dp.perm_type = 'perms/data-access' )
  AND NOT EXISTS
    (SELECT 1
     FROM data_permissions dp
     WHERE dp.group_id = pg.id
       AND dp.db_id = mt.db_id
       AND dp.table_id IS NULL
       AND dp.perm_type = 'perms/data-access' )]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44437.invoke(liquibase.clj:359)
	at metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:348)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:341)
	at metabase.db.setup$migrate_BANG_$fn__53364.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53392$fn__53393.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53392.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53417.invoke(db.clj:82)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: Unterminated string literal started at position 1,694 in SQL -- Insert table-level permissions only where no DB-level permissions exist
```



### Information about your Metabase installation

```JSON
- Database: PostgreSQL 42.6.0
- Metabase: v0.50.10 (49d9e46)
- Hosting: Kubernetes using Docker image
```


### Severity

High

### Additional context

I tried using lower version of Metebase by updating the version in Dockerfile but it started giving another error with same migration file",trojanh,2024-07-05 07:00:12+00:00,[],2024-08-01 13:57:20+00:00,2024-08-01 13:57:19+00:00,https://github.com/metabase/metabase/issues/45166,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2210326783, 'issue_id': 2391973302, 'author': 'piranha', 'body': '> 2024-07-05 06:44:46,368 INFO db.setup :: Successfully verified PostgreSQL 10.7 application database connection. âœ…\r\n\r\nMetabase supports Postgres 11 and later (and we certainly hit an issue with 10 just recently), so even if this is not a reason I suggest updating it.', 'created_at': datetime.datetime(2024, 7, 5, 7, 13, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210336117, 'issue_id': 2391973302, 'author': 'trojanh', 'body': 'thanks @piranha \r\nthis issue started happening in recent weeks which might be because v0.50.9 and v0.50.10 but will check with updated version and see if it works\r\n\r\ncould we add some kind of deprecation warning in the logs itself which will help people know to update the DB version?', 'created_at': datetime.datetime(2024, 7, 5, 7, 21, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210357774, 'issue_id': 2391973302, 'author': 'piranha', 'body': ""Yeah, I think we started hitting actual miscompatibilities with pg 10 just recently, but it's been long out of support, so it makes sense to update it.\r\n\r\nWe're discussing adding a log saying your app db is too old, thanks for the suggestion!"", 'created_at': datetime.datetime(2024, 7, 5, 7, 36, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217679572, 'issue_id': 2391973302, 'author': 'darksciencebase', 'body': '@trojanh did it work for you with a newer postgres?', 'created_at': datetime.datetime(2024, 7, 9, 12, 59, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217720789, 'issue_id': 2391973302, 'author': 'trojanh', 'body': ""haven't been able to try this out yet but will update here once we do that, \r\n\r\nwe are also considering [rollback](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade) to previous version temporarily so if you are stuck, you could give that a shot but it would mean you won't be able to use newer version."", 'created_at': datetime.datetime(2024, 7, 9, 13, 17, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225419469, 'issue_id': 2391973302, 'author': 'darksciencebase', 'body': ""@trojanh oh, thanks, i'm not stuck, i work for metabase :)"", 'created_at': datetime.datetime(2024, 7, 12, 11, 50, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2258601627, 'issue_id': 2391973302, 'author': 'trojanh', 'body': 'downgrading to `v0.48.13` fixed this issue, \r\nhttps://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#upgrading-metabase-on-other-platforms', 'created_at': datetime.datetime(2024, 7, 30, 15, 15, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2258634302, 'issue_id': 2391973302, 'author': 'paoliniluis', 'body': '@trojanh please upgrade your postgres DB and try again', 'created_at': datetime.datetime(2024, 7, 30, 15, 30, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263143304, 'issue_id': 2391973302, 'author': 'darksciencebase', 'body': ""@trojanh if it doesn't work with a newer postgres, leave a comment and we'll reopen the issue."", 'created_at': datetime.datetime(2024, 8, 1, 13, 57, 19, tzinfo=datetime.timezone.utc)}]","piranha on (2024-07-05 07:13:44 UTC): Metabase supports Postgres 11 and later (and we certainly hit an issue with 10 just recently), so even if this is not a reason I suggest updating it.

trojanh (Issue Creator) on (2024-07-05 07:21:01 UTC): thanks @piranha 
this issue started happening in recent weeks which might be because v0.50.9 and v0.50.10 but will check with updated version and see if it works

could we add some kind of deprecation warning in the logs itself which will help people know to update the DB version?

piranha on (2024-07-05 07:36:51 UTC): Yeah, I think we started hitting actual miscompatibilities with pg 10 just recently, but it's been long out of support, so it makes sense to update it.

We're discussing adding a log saying your app db is too old, thanks for the suggestion!

darksciencebase on (2024-07-09 12:59:48 UTC): @trojanh did it work for you with a newer postgres?

trojanh (Issue Creator) on (2024-07-09 13:17:07 UTC): haven't been able to try this out yet but will update here once we do that, 

we are also considering [rollback](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade) to previous version temporarily so if you are stuck, you could give that a shot but it would mean you won't be able to use newer version.

darksciencebase on (2024-07-12 11:50:06 UTC): @trojanh oh, thanks, i'm not stuck, i work for metabase :)

trojanh (Issue Creator) on (2024-07-30 15:15:56 UTC): downgrading to `v0.48.13` fixed this issue, 
https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#upgrading-metabase-on-other-platforms

paoliniluis on (2024-07-30 15:30:03 UTC): @trojanh please upgrade your postgres DB and try again

darksciencebase on (2024-08-01 13:57:19 UTC): @trojanh if it doesn't work with a newer postgres, leave a comment and we'll reopen the issue.

"
2391562171,issue,closed,completed,OOM errors during JSON unfolding,"### Describe the bug

Some customers have OOM errors while inferring the schema of a JSON column during the sync-fields step. This issue is just to track its investigation and the fix.

[Context in slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719624233280609)

### To Reproduce

NA

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
NA
```


### Severity

high

### Additional context

_No response_",calherries,2024-07-04 23:59:26+00:00,['calherries'],2024-08-13 08:15:30+00:00,2024-08-13 08:15:29+00:00,https://github.com/metabase/metabase/issues/45163,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2255960203, 'issue_id': 2391562171, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.18](https://github.com/metabase/metabase/milestone/259)', 'created_at': datetime.datetime(2024, 7, 29, 13, 31, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285293287, 'issue_id': 2391562171, 'author': 'qnkhuat', 'body': ""Reopening as it's not fully resolved, see this discussing [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1722607969980679)"", 'created_at': datetime.datetime(2024, 8, 13, 3, 56, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285639025, 'issue_id': 2391562171, 'author': 'calherries', 'body': 'false alarm, that was before this change landed', 'created_at': datetime.datetime(2024, 8, 13, 8, 15, 29, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-29 13:31:28 UTC): ðŸš€ This should also be released by [v0.50.18](https://github.com/metabase/metabase/milestone/259)

qnkhuat on (2024-08-13 03:56:59 UTC): Reopening as it's not fully resolved, see this discussing [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1722607969980679)

calherries (Issue Creator) on (2024-08-13 08:15:29 UTC): false alarm, that was before this change landed

"
2391529812,issue,closed,completed,Creating a new folder on the snippet menu will use the new entity modal which suggests collections,"### Describe the bug

The folder picker in the snippet view is the new entity picker modal, which was made for collections
![image](https://github.com/metabase/metabase/assets/1711649/a34586ed-d204-4d74-b967-01cebcdc2669)

clicking on ""create a new collection"" will actually create a collection and not a folder, and then selecting a collection to save a snippet will end up in a failed api call

### To Reproduce

Just try to create a snippet and select the folder where you want the snippet to live

### Expected behavior

we should either return to the old modal there or allow the new picker to create folders

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-07-04 22:48:15+00:00,['npfitz'],2024-08-26 18:18:57+00:00,2024-08-26 18:18:57+00:00,https://github.com/metabase/metabase/issues/45161,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Querying/Snippets', '')]","[{'comment_id': 2209623622, 'issue_id': 2391529812, 'author': 'paoliniluis', 'body': 'it seems that the modal works, but suggest collections as well, so we should make very slight changes', 'created_at': datetime.datetime(2024, 7, 4, 22, 50, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261201859, 'issue_id': 2391529812, 'author': 'npfitz', 'body': '@paoliniluis I believe this was resolved by https://github.com/metabase/metabase/pull/45477, Which solved the ""Create New Collection"" bug and removed the recents tab from that particular modal. Can you confirm that the recents tab was what was suggesting incorrect collections for you?', 'created_at': datetime.datetime(2024, 7, 31, 18, 58, 17, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-07-04 22:50:02 UTC): it seems that the modal works, but suggest collections as well, so we should make very slight changes

npfitz (Assginee) on (2024-07-31 18:58:17 UTC): @paoliniluis I believe this was resolved by https://github.com/metabase/metabase/pull/45477, Which solved the ""Create New Collection"" bug and removed the recents tab from that particular modal. Can you confirm that the recents tab was what was suggesting incorrect collections for you?

"
2391486145,issue,open,,Humanize schema names,"**Is your feature request related to a problem? Please describe.**
Our current humanization of table and field names do not include schemas. It would be nice if we humanize schema names as well

**Describe the solution you'd like**
Do the same we do with field and table names but with schemas

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-04 21:35:52+00:00,[],2025-02-04 20:30:56+00:00,,https://github.com/metabase/metabase/issues/45157,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', '')]","[{'comment_id': 2276158633, 'issue_id': 2391486145, 'author': 'benjdl', 'body': 'https://github.com/metabase/metabase/issues/6619', 'created_at': datetime.datetime(2024, 8, 8, 15, 53, 16, tzinfo=datetime.timezone.utc)}]","benjdl on (2024-08-08 15:53:16 UTC): https://github.com/metabase/metabase/issues/6619

"
2391461897,issue,open,,Dashboard fails to load or redirects incorrectly after a question's title is edited,"### Describe the bug

When editing the title of a question (native or GUI) after having it opened from a dashboard, navigating back without saving the title change causes the dashboard behave unexpectedly.

### To Reproduce

1. Create a dashboard and add any native question, e.g. `select * from products`
2. Open the dashboard, and click on ... / Edit question on the card
3. Click on the title of the card, start typing to change it, but do not click elsewhere to persist the change
4. Click on the Metabase back arrow button
5. (!) The dashboard opens, but the recently changed card doesn't load, only a spinning circle is shown

6. Repeat steps 1 - 4, this time with a GUI question
7. (!) The dashboard displays briefly, then
8.(!) the browser is redirected back to the question and the circular back arrow icon is missing.

### Expected behavior

It should work

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.49.18
1.50.10
```


### Severity

P2, annoying, reported by a customer

### Additional context
The issue can also be triggered by hitting enter or clicking out of the box. If the back arrow is clicked quickly, before the update has a chance to complete, the problem will occur.

_No response_",zbodi74,2024-07-04 21:03:00+00:00,['kulyk'],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/45155,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2391403227,issue,closed,completed,legend improvements,"- [x] [17855](https://metaboat.slack.com/archives/C07B9G2V1CH/p1720018382128289)
_""legend is a bit unwieldy."" Potential solution would be to disallow one column layouts, use minimum two columns and truncate text when needed._
Fixed by https://github.com/metabase/metabase/pull/43555/commits/0b3eae8bb726228f5789b7021bbcc6281f910cc5

- [x] [17972](https://metaboat.slack.com/archives/C07B9G2V1CH/p1720018387173619) [13691](https://metaboat.slack.com/archives/C07B9G2V1CH/p1720018945132979)
_Single row legend needs more space between entires_
Fixed by https://github.com/metabase/metabase/pull/43555/commits/83a73bef654c274dc4692dc527baeed17f91192a

- [x] [16372](https://metaboat.slack.com/archives/C07B9G2V1CH/p1720019123249239)
_Long legend labels can overlap with percentage_
Fixed by https://github.com/metabase/metabase/pull/43555/commits/d7a87713cb2e46fbe4be23726fedc90605b8fbd7",EmmadUsmani,2024-07-04 19:56:17+00:00,['EmmadUsmani'],2024-07-08 18:17:02+00:00,2024-07-08 18:17:02+00:00,https://github.com/metabase/metabase/issues/45149,[],[],
2391377510,issue,closed,completed,Downloads from public questions or dashboards are not logged,"### Describe the bug

Logging of downloads from publicly shared questions do not appear to work. The download events do not show up in `v_query_log`.



### To Reproduce

Enable public sharing for a question. Open it, and download data as csv / json / xlsx. 
The view event is logged, however the download event does not show up in Metabase Analytics / `v_query_log` .

### Expected behavior

We should log these events as well.

### Logs

n/a

### Information about your Metabase installation

```JSON
v50.8
```


### Severity

P2

### Additional context

_No response_",zbodi74,2024-07-04 19:27:12+00:00,['noahmoss'],2024-08-27 12:09:36+00:00,2024-08-26 15:27:06+00:00,https://github.com/metabase/metabase/issues/45147,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Sharing/Public', '')]","[{'comment_id': 2209495672, 'issue_id': 2391377510, 'author': 'adam-james-v', 'body': '@zbodi74 , can you clarify this:\r\n\r\n> Downloads from publicly shared dashboards or questions do not work.\r\n\r\nDo you mean that the downloads are failing? \r\nOr is it simply that the (successful) download is not being logged?', 'created_at': datetime.datetime(2024, 7, 4, 19, 40, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209500445, 'issue_id': 2391377510, 'author': 'zbodi74', 'body': 'Hi, sorry, corrected the description. The issue is only the (successful) downloads are not being logged.', 'created_at': datetime.datetime(2024, 7, 4, 19, 46, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209594008, 'issue_id': 2391377510, 'author': 'notrom', 'body': ""Are downloads of question data to CSV/xlsx from a public shared dashboard available? It doesn't appear as an option for me but I'd love to be able to do it. Reading this issue makes me think it should be working, am I missing something?\r\n\r\nDashboard question when logged in:\r\n![image](https://github.com/metabase/metabase/assets/4504437/f5afc348-9c25-41e8-a57e-eab05e001dc1)\r\n\r\nSame dashboard question when public shared:\r\n![image](https://github.com/metabase/metabase/assets/4504437/dd3c2f77-825d-45ae-b41a-c4ecb2e4f281)\r\n\r\nv0.50.10\r\n\r\nOld open issue asking for this https://github.com/metabase/metabase/issues/6687"", 'created_at': datetime.datetime(2024, 7, 4, 21, 57, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210611511, 'issue_id': 2391377510, 'author': 'zbodi74', 'body': '@notrom - apologies for the incorrect title, fixed it, this applies only for individual questions, not dashboards.', 'created_at': datetime.datetime(2024, 7, 5, 10, 17, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248737587, 'issue_id': 2391377510, 'author': 'tom-vpj', 'body': '@notrom im having the same issue', 'created_at': datetime.datetime(2024, 7, 24, 19, 19, 29, tzinfo=datetime.timezone.utc)}]","adam-james-v on (2024-07-04 19:40:03 UTC): @zbodi74 , can you clarify this:


Do you mean that the downloads are failing? 
Or is it simply that the (successful) download is not being logged?

zbodi74 (Issue Creator) on (2024-07-04 19:46:36 UTC): Hi, sorry, corrected the description. The issue is only the (successful) downloads are not being logged.

notrom on (2024-07-04 21:57:03 UTC): Are downloads of question data to CSV/xlsx from a public shared dashboard available? It doesn't appear as an option for me but I'd love to be able to do it. Reading this issue makes me think it should be working, am I missing something?

Dashboard question when logged in:
![image](https://github.com/metabase/metabase/assets/4504437/f5afc348-9c25-41e8-a57e-eab05e001dc1)

Same dashboard question when public shared:
![image](https://github.com/metabase/metabase/assets/4504437/dd3c2f77-825d-45ae-b41a-c4ecb2e4f281)

v0.50.10

Old open issue asking for this https://github.com/metabase/metabase/issues/6687

zbodi74 (Issue Creator) on (2024-07-05 10:17:54 UTC): @notrom - apologies for the incorrect title, fixed it, this applies only for individual questions, not dashboards.

tom-vpj on (2024-07-24 19:19:29 UTC): @notrom im having the same issue

"
2391343785,issue,open,,"Making a model with a native question that was ""transformed"" with ""Explore results"" will lead to model with no metadata","### Describe the bug

In the process of hunting where metadata gets lots, I found a flow that might actually be a big culprit of why things don't work: if you make a native question look like a GUI question and then transform this question into a model, Metabase will treat this question as a GUI one, but without any metadata on it

### To Reproduce

1) new native question -> select * from people
2) click on ""explore results"", then transform it into a model
3) try to map the state field to the actual state field that exists on the table, you can't
![image](https://github.com/metabase/metabase/assets/1711649/bcb15b7d-2192-42bb-9a20-215f0e43b18f)
![image](https://github.com/metabase/metabase/assets/1711649/695564be-e5ea-4e9d-91d4-60726df5196b)

... now:
1) new native question -> select * from people
2) transform this into a model
3) see that the field now can be mapped to the state field in the table
![image](https://github.com/metabase/metabase/assets/1711649/13812e29-4654-49e7-a791-0ef6be5fe725)
![image](https://github.com/metabase/metabase/assets/1711649/325f6cd7-83cb-4a34-9ee9-27e65f3d135d)


### Expected behavior

We should know that the query is a native one and offer the metadata mapping

### Logs

NA

### Information about your Metabase installation

```JSON
I think it has always been like that
```


### Severity

P1

### Additional context

This might be a big reason why we lose Metadata and we don't know why, it might be that the users made a SQL question and masked it as a GUI one, and then we ""believe"" that metadata should be there as it seems like a normal GUI question",paoliniluis,2024-07-04 18:52:07+00:00,['metamben'],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/45146,"[('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2210821381, 'issue_id': 2391343785, 'author': 'paoliniluis', 'body': 'moving into a P1, as this can cause real trouble', 'created_at': datetime.datetime(2024, 7, 5, 12, 49, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231121241, 'issue_id': 2391343785, 'author': 'metamben', 'body': 'The cause of the issue is that \'Explore results"" creates a new card based on the native card. If one turns the native card into a model, then mapping columns to database fields is possible. This is not possible if a card based on another (native) card is turned into a model. @luizarakaki what should we do, do you think? I\'ve heard we want to move away from turning cards into models. If that\'s the case, then the use case might not be that important after all.', 'created_at': datetime.datetime(2024, 7, 16, 14, 52, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241353754, 'issue_id': 2391343785, 'author': 'perivamsi', 'body': ""I agree with @luizarakaki's comments [here](https://metaboat.slack.com/archives/C04DN5VRQM6/p1721221208813019?thread_ts=1721155235.038309&cid=C04DN5VRQM6)\n\nThis seems to be by design. Not sure what the real issue is. \n\n@paoliniluis you can still add metadata, just not map columns - why do you think that is causing bugs as opposed to a limitation of product?"", 'created_at': datetime.datetime(2024, 7, 21, 0, 35, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259517331, 'issue_id': 2391343785, 'author': 'paoliniluis', 'body': ""@perivamsi and @luizarakaki \r\nThe problem here is that users will:\r\n1) create questions on top of this model\r\n2) then they'll add those questions to dashboards and flters on those questions\r\n3) they'll later find out that the filters don't have any filter values, and they'll have to re-do everything from scratch (since they won't be able to revert the question back to a SQL question/SQL model\r\n\r\nit's a user flow which has a dead end and you end up with a huge pain"", 'created_at': datetime.datetime(2024, 7, 31, 2, 25, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-07-05 12:49:41 UTC): moving into a P1, as this can cause real trouble

metamben (Assginee) on (2024-07-16 14:52:26 UTC): The cause of the issue is that 'Explore results"" creates a new card based on the native card. If one turns the native card into a model, then mapping columns to database fields is possible. This is not possible if a card based on another (native) card is turned into a model. @luizarakaki what should we do, do you think? I've heard we want to move away from turning cards into models. If that's the case, then the use case might not be that important after all.

perivamsi on (2024-07-21 00:35:48 UTC): I agree with @luizarakaki's comments [here](https://metaboat.slack.com/archives/C04DN5VRQM6/p1721221208813019?thread_ts=1721155235.038309&cid=C04DN5VRQM6)

This seems to be by design. Not sure what the real issue is. 

@paoliniluis you can still add metadata, just not map columns - why do you think that is causing bugs as opposed to a limitation of product?

paoliniluis (Issue Creator) on (2024-07-31 02:25:24 UTC): @perivamsi and @luizarakaki 
The problem here is that users will:
1) create questions on top of this model
2) then they'll add those questions to dashboards and flters on those questions
3) they'll later find out that the filters don't have any filter values, and they'll have to re-do everything from scratch (since they won't be able to revert the question back to a SQL question/SQL model

it's a user flow which has a dead end and you end up with a huge pain

"
2391331797,issue,closed,completed,"Test issue (testing an automation, sorry for this)","### Describe the bug

Test issue (testing an automation, sorry for this)

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
test
```


### Severity

test

### Additional context

_No response_",ignacio-mb,2024-07-04 18:39:30+00:00,[],2024-07-04 18:40:49+00:00,2024-07-04 18:40:49+00:00,https://github.com/metabase/metabase/issues/45145,[],[],
2391225976,issue,closed,not_planned,Cumulative Sums and Counts not working with MySQL 5.7 in v0.50 due to CTE ,"### Describe the bug

Starting from version v0.50 of Metabase, it is not possible to perform cumulative sums or cumulative counts using MySQL 5.7.

This functionality was working in v0.49

I can not found in changelog if 5.7 was deprecated, just this issue #26328

### To Reproduce

1. Create a simple question with comulative sum and mysql 5.7
2. See error
 ```
You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '(ORDER BY `source`.`FechPago` ASC ROWS UNBOUNDED PRECEDING) AS `count` FROM (SEL' at line 2
```


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""3.10.0-1062.1.2.el7.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Argentina/Buenos_Aires""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""sqlserver"",
      ""sqlite"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.17-MariaDB-1:10.3.17+maria~bionic""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-02"",
      ""tag"": ""v0.50.9"",
      ""hash"": ""720e549""
    },
    ""settings"": {
      ""report-timezone"": ""America/Argentina/Buenos_Aires""
    }
  }
}
```


### Severity

blocking and upgrade

### Additional context

v0.49 sql:

```sql
SELECT
  `pago`.`FechPago` AS `FechPago`,
  SUM(`pago`.`TotaPago`) AS `sum`
FROM
  `pago`
WHERE
  (`pago`.`PeriPago` = 2024)
 
   AND (
    `pago`.`FechPago` >= STR_TO_DATE(
      CONCAT(DATE_FORMAT(NOW(6), '%Y-%m'), '-01'),
      '%Y-%m-%d'
    )
  )
  AND (
    `pago`.`FechPago` < STR_TO_DATE(
      CONCAT(
        DATE_FORMAT(DATE_ADD(NOW(6), INTERVAL 1 month), '%Y-%m'),
        '-01'
      ),
      '%Y-%m-%d'
    )
  )
GROUP BY
  `pago`.`FechPago`
ORDER BY
  `pago`.`FechPago` ASC
```
v0.50 sql with `OVER ... AS` statement

```sql
SELECT
  `source`.`FechPago` AS `FechPago`,
  SUM(COUNT(*)) OVER (
   
ORDER BY
      `source`.`FechPago` ASC ROWS UNBOUNDED PRECEDING
  ) AS `count`
FROM
  (
    SELECT
      DAYOFMONTH(`pago`.`FechPago`) AS `FechPago`
    FROM
      `pago`
   
WHERE
      (`pago`.`PeriPago` = 2024)
     
   AND (
        `pago`.`FechPago` >= STR_TO_DATE(
          CONCAT(DATE_FORMAT(NOW(6), '%Y-%m'), '-01'),
          '%Y-%m-%d'
        )
      )
      AND (
        `pago`.`FechPago` < STR_TO_DATE(
          CONCAT(
            DATE_FORMAT(DATE_ADD(NOW(6), INTERVAL 1 month), '%Y-%m'),
            '-01'
          ),
          '%Y-%m-%d'
        )
      )
  ) AS `source`
GROUP BY
  `source`.`FechPago`
ORDER BY
  `source`.`FechPago` ASC
```",tomeli5n,2024-07-04 17:03:31+00:00,[],2025-01-20 11:22:49+00:00,2024-07-04 17:22:18+00:00,https://github.com/metabase/metabase/issues/45142,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2209376583, 'issue_id': 2391225976, 'author': 'camsaul', 'body': ""Hi, we don't officially support MySQL 5.7, it has been unsupported upstream for 8 months. https://endoflife.date/mysql"", 'created_at': datetime.datetime(2024, 7, 4, 17, 21, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602159105, 'issue_id': 2391225976, 'author': 'ngm', 'body': 'I encountered this, and just to report for future travellers that those questions failing when pointing at MySQL 5.7 do work fine when upgrading MySQL to v8.', 'created_at': datetime.datetime(2025, 1, 20, 11, 22, 47, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-07-04 17:21:43 UTC): Hi, we don't officially support MySQL 5.7, it has been unsupported upstream for 8 months. https://endoflife.date/mysql

ngm on (2025-01-20 11:22:47 UTC): I encountered this, and just to report for future travellers that those questions failing when pointing at MySQL 5.7 do work fine when upgrading MySQL to v8.

"
2391183098,issue,closed,completed,Make collection table navigable by pressing Tab,"Currently, if you try to tab through a collection table, the focus cursor will stop at the first action menu you reach.",rafpaf,2024-07-04 16:25:49+00:00,['rafpaf'],2024-07-18 23:41:28+00:00,2024-07-17 13:42:28+00:00,https://github.com/metabase/metabase/issues/45141,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround')]",[],
2390934387,issue,closed,completed,Improve dark theme metabase logo footer visibility,"https://metaboat.slack.com/archives/C063Q3F1HPF/p1720078600140479

[Figma file](https://www.figma.com/design/OamRqg07JOoC4bUqfCkh4t/SDK-Reference-APP?node-id=2454-3166&t=VFe50YsZ23K5aNN8-0)

![image](https://github.com/metabase/metabase/assets/1937582/b5cb3189-39f4-44d9-abc2-ef602205fa1b)

",WiNloSt,2024-07-04 13:53:39+00:00,[],2024-07-12 11:17:10+00:00,2024-07-12 11:17:10+00:00,https://github.com/metabase/metabase/issues/45135,[],[],
2390765670,issue,closed,completed,"subscribe to a dashboard with charts, the mail received has Changed chart's size and settings.","**Describe the bug**
When sending dashboard charts via email subscriptions and then converting them to Slack reports, I am noticing unintended changes in the dashboardâ€™s appearance and functionality. These modifications include resizing of the charts, conversion of data from raw numbers to percentages, and changing from line charts to bar charts. These transformations often compromise the original design and clarity of the dashboard, affecting the overall understanding of the data presented.


link to the report 
https://metabase.voyantis.co/dashboard/124-predictions-dashboard-mosh?product_id=mosh&version=2&cohort_dates=2024-01-01~2025-01-


01&action_id=&run_id=&prediction_target=intent%20with%20PMI%20to%20LTV&action_type=Foresight&iw_days=7&iw_hours=&horizon=30&raw%252Fpmi=PMI&is_matured=true&exclude_backfills=&cv_buckets=10&cohort_dates_(cv2)_=&birds_segment=&segment_name_1=&segment_value_1=&segment_name_2=&segment_value_2=&segment_name_3=&segment_value_3=
**Expected behavior**
The behavior is that I don't want the change happening in the visualization. I added pictures 
**Screenshots**
![Screenshot 2024-07-04 at 15 23 52](https://github.com/metabase/metabase/assets/162147634/61fcf01b-9717-4532-9971-1c9939ad60ab)
![Screenshot 2024-07-04 at 15 23 59](https://github.com/metabase/metabase/assets/162147634/530c8ac5-19d6-4992-b46a-b02d36cc7743)
![Screenshot 2024-07-04 at 15 24 07](https://github.com/metabase/metabase/assets/162147634/84938ffb-be03-485c-acda-c86e219f6b08)
![Screenshot 2024-07-04 at 15 27 03](https://github.com/metabase/metabase/assets/162147634/c29fc01f-fb84-4ccd-8fef-b47365db801a)
![Screenshot 2024-07-04 at 15 27 12](https://github.com/metabase/metabase/assets/162147634/404ed04a-b70a-4ce7-9755-881109807a2d)
![Screenshot 2024-07-04 at 15 27 18](https://github.com/metabase/metabase/assets/162147634/fb8f9793-5f6b-4049-9f13-1ccff986bdc5)

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.218-208.862.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-23"",
      ""tag"": ""v0.49.12"",
      ""hash"": ""77e7a81""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",ErezBlockTemin,2024-07-04 12:32:40+00:00,[],2024-07-04 18:04:51+00:00,2024-07-04 18:04:51+00:00,https://github.com/metabase/metabase/issues/45130,[],"[{'comment_id': 2209417915, 'issue_id': 2390765670, 'author': 'alxnddr', 'body': ""Hey @ErezBlockTemin ðŸ‘‹ We've reworked line, bar, area, combo, scatter, waterfall charts entirely in v50 and one of the goals was to make the email/slack versions of them look exactly as what you can see in the app. This already should've been fixed in the latest version but if not please let us know. As for resizing, emailed charts may have different dimensions but this is needed to make emails readable, otherwise some labels may look very tiny"", 'created_at': datetime.datetime(2024, 7, 4, 18, 4, 51, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-07-04 18:04:51 UTC): Hey @ErezBlockTemin ðŸ‘‹ We've reworked line, bar, area, combo, scatter, waterfall charts entirely in v50 and one of the goals was to make the email/slack versions of them look exactly as what you can see in the app. This already should've been fixed in the latest version but if not please let us know. As for resizing, emailed charts may have different dimensions but this is needed to make emails readable, otherwise some labels may look very tiny

"
2390670762,issue,closed,completed,[Cache] Ensure Question last updated message is accurate,"This message seems to have problems:

![Image](https://github.com/metabase/metabase/assets/130925/0958057a-d494-4691-a9bb-9a4f706536c3)

",rafpaf,2024-07-04 11:42:57+00:00,[],2024-07-26 13:15:09+00:00,2024-07-26 13:15:08+00:00,https://github.com/metabase/metabase/issues/45128,[],"[{'comment_id': 2252743143, 'issue_id': 2390670762, 'author': 'rafpaf', 'body': 'This is fixed now', 'created_at': datetime.datetime(2024, 7, 26, 13, 15, 8, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-07-26 13:15:08 UTC): This is fixed now

"
2390666567,issue,closed,completed,"[Cache] Change short label for duration policy to ""Duration: N hours""",,rafpaf,2024-07-04 11:40:29+00:00,[],2024-10-08 16:19:35+00:00,2024-07-25 20:37:44+00:00,https://github.com/metabase/metabase/issues/45127,[],[],
2390532272,issue,closed,completed,Add more logging during upgrade,"**Is your feature request related to a problem? Please describe.**

During the upgrade from versions let's say  v49 to v50, the DB migration process can run for too long and a process might kill metabase (like a readiness or health check from kubernetes) and you will see these in the logs:

```
...
â”‚ metabase 2024-07-03 21:31:21,708 INFO db.setup :: Verifying postgres Database Connection ... â”‚
â”‚ metabase 2024-07-03 21:31:22,070 INFO db.setup :: Successfully verified PostgreSQL 14.9 application database connection. âœ… â”‚
â”‚ metabase 2024-07-03 21:31:22,071 INFO db.setup :: Checking if a database downgrade is required... â”‚
â”‚ metabase 2024-07-03 21:31:22,613 INFO db.setup :: Running Database Migrations... â”‚
â”‚ metabase 2024-07-03 21:31:22,614 INFO db.setup :: Setting up Liquibase... â”‚
â”‚ metabase 2024-07-03 21:31:22,794 INFO db.setup :: Liquibase is ready. â”‚
â”‚ metabase 2024-07-03 21:31:22,795 INFO db.liquibase :: Checking if Database has unrun migrations... â”‚
â”‚ metabase 2024-07-03 21:31:23,216 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken... â”‚
â”‚ metabase 2024-07-03 21:31:23,231 INFO db.liquibase :: No migration lock found. â”‚
â”‚ metabase 2024-07-03 21:31:23,231 INFO db.liquibase :: Migration lock acquired. â”‚
â”‚ metabase 2024-07-03 21:31:23,439 INFO db.liquibase :: Running 64 migrations ... â”‚
metabase 2024-07-03 21:33:56,932 INFO metabase.core :: Metabase Shutting Down ... â”‚
â”‚ metabase 2024-07-03 21:33:56,933 INFO metabase.server :: Shutting Down Embedded Jetty Webserver â”‚
...
```
So we have no clue of which migration from the 64 was the problem. You might need to go to the databasechangelog table and see whats in there to make sense of it all.

**Describe the solution you'd like**

Before triggering the upgrade DB migration, in the application log, some estimations such as expected wait time based on data volume and complexity would be very helpful. In addition, it would be nice to have a migration progress update in the log as well. Currently we have have zero exposure to the DB migration status

**How important is this feature to you?**

The more complex migrations we add the more this becomes relevant. In the v50 we touched permissions and some migrations are taking a lot of time cause i believe we are touching the permission graph tables which might be large for some customers. 

**Additional context**
3 customers already had some issues around upgrading and get the `Shutting Down Embedded ...` so more visibility on the issue would be helpful",Tony-metabase,2024-07-04 10:33:48+00:00,[],2024-10-02 13:37:41+00:00,2024-10-02 13:00:02+00:00,https://github.com/metabase/metabase/issues/45125,"[('Type:New Feature', ''), ('.Needs Triage', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2388586720, 'issue_id': 2390532272, 'author': 'dpsutton', 'body': ""This was implemented in https://github.com/metabase/metabase/pull/47397\r\n\r\n\r\n<details>\r\n<summary>\r\nHere's what the logs of a 49 -> 50 upgrade look like\r\n</summary>\r\n\r\n```\r\n2024-10-02 07:58:14,269 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulsesTask\r\n2024-10-02 07:58:14,269 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:05::qnkhuat ran successfully in 38ms\r\n2024-10-02 07:58:14,270 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade\r\n2024-10-02 07:58:14,270 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulseTaskOnDowngrade\r\n2024-10-02 07:58:14,270 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:06::qnkhuat ran successfully in 0ms\r\n2024-10-02 07:58:14,271 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade\r\n2024-10-02 07:58:14,272 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteInitSendPulseTriggersOnDowngrade\r\n2024-10-02 07:58:14,272 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:07::qnkhuat ran successfully in 1ms\r\n2024-10-02 07:58:14,277 INFO liquibase.changelog :: Columns entity_id(char(21)) added to core_user\r\n2024-10-02 07:58:14,277 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:01::noahmoss ran successfully in 5ms\r\n2024-10-02 07:58:14,281 INFO liquibase.changelog :: Columns entity_id(char(21)) added to permissions_group\r\n2024-10-02 07:58:14,281 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:02::noahmoss ran successfully in 3ms\r\n2024-10-02 07:58:14,287 INFO liquibase.changelog :: Columns view_count(integer) added to report_card\r\n2024-10-02 07:58:14,288 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:31::calherries ran successfully in 7ms\r\n2024-10-02 07:58:14,289 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,289 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 1ms\r\n2024-10-02 07:58:14,294 INFO liquibase.changelog :: Columns view_count(integer) added to report_dashboard\r\n2024-10-02 07:58:14,294 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:33::calherries ran successfully in 4ms\r\n2024-10-02 07:58:14,295 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,295 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:34::calherries ran successfully in 0ms\r\n2024-10-02 07:58:14,298 INFO liquibase.changelog :: Columns view_count(integer) added to metabase_table\r\n2024-10-02 07:58:14,299 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:35::calherries ran successfully in 3ms\r\n2024-10-02 07:58:14,300 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,300 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:36::calherries ran successfully in 1ms\r\n2024-10-02 07:58:14,304 INFO liquibase.changelog :: Table user_parameter_value created\r\n2024-10-02 07:58:14,304 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:19:00::adam-james ran successfully in 3ms\r\n2024-10-02 07:58:14,305 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id created\r\n2024-10-02 07:58:14,305 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:25:00::adam-james ran successfully in 0ms\r\n2024-10-02 07:58:14,307 INFO liquibase.changelog :: Columns scope(varchar(64)) added to api_key\r\n2024-10-02 07:58:14,307 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:57:23::noahmoss ran successfully in 1ms\r\n2024-10-02 07:58:14,308 INFO liquibase.changelog :: Null constraint dropped from api_key.user_id\r\n2024-10-02 07:58:14,308 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:58:24::noahmoss ran successfully in 0ms\r\n2024-10-02 07:58:14,311 INFO liquibase.changelog :: Columns status(varchar(21)) added to task_history\r\n2024-10-02 07:58:14,311 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:00::qnkhuat ran successfully in 2ms\r\n2024-10-02 07:58:14,312 INFO liquibase.changelog :: Default value dropped from task_history.status\r\n2024-10-02 07:58:14,312 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:01::qnkhuat ran successfully in 1ms\r\n2024-10-02 07:58:14,312 INFO liquibase.changelog :: Default value added to task_history.status\r\n2024-10-02 07:58:14,313 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:02::qnkhuat ran successfully in 0ms\r\n2024-10-02 07:58:14,313 INFO liquibase.changelog :: Null constraint dropped from task_history.ended_at\r\n2024-10-02 07:58:14,313 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:03::qnkhuat ran successfully in 0ms\r\n2024-10-02 07:58:14,314 INFO liquibase.changelog :: Null constraint dropped from task_history.duration\r\n2024-10-02 07:58:14,314 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:04::qnkhuat ran successfully in 0ms\r\n2024-10-02 07:58:14,315 INFO liquibase.changelog :: Default value dropped from task_history.ended_at\r\n2024-10-02 07:58:14,315 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:05::qnkhuat ran successfully in 1ms\r\n2024-10-02 07:58:14,315 INFO liquibase.changelog :: Default value added to task_history.ended_at\r\n2024-10-02 07:58:14,316 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:06::qnkhuat ran successfully in 1ms\r\n2024-10-02 07:58:14,319 INFO liquibase.changelog :: Table cloud_migration created\r\n2024-10-02 07:58:14,319 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-13T16:00:00::filipesilva ran successfully in 3ms\r\n2024-10-02 07:58:14,322 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateStackedAreaBarComboDisplaySettings\r\n2024-10-02 07:58:14,322 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-15T13:13:13::adam-james ran successfully in 3ms\r\n2024-10-02 07:58:14,325 INFO liquibase.changelog :: Columns uploads_enabled(boolean) added to metabase_database\r\n2024-10-02 07:58:14,325 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:23::calherries ran successfully in 2ms\r\n2024-10-02 07:58:14,327 INFO liquibase.changelog :: Columns uploads_schema_name(text) added to metabase_database\r\n2024-10-02 07:58:14,327 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:24::calherries ran successfully in 2ms\r\n2024-10-02 07:58:14,330 INFO liquibase.changelog :: Columns uploads_table_prefix(text) added to metabase_database\r\n2024-10-02 07:58:14,330 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:25::calherries ran successfully in 2ms\r\n2024-10-02 07:58:14,333 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateUploadsSettings\r\n2024-10-02 07:58:14,333 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:26::calherries ran successfully in 2ms\r\n2024-10-02 07:58:14,340 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateSampleContent\r\n2024-10-02 07:58:14,340 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-27T15:55:22::calherries ran successfully in 6ms\r\n2024-10-02 07:58:14,342 INFO liquibase.changelog :: Columns context(varchar(256)) added to recent_views\r\n2024-10-02 07:58:14,342 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-30T16:04:20::escherize ran successfully in 1ms\r\n2024-10-02 07:58:14,352 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DecryptCacheSettings\r\n2024-10-02 07:58:14,352 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:07::piranha ran successfully in 9ms\r\n2024-10-02 07:58:14,371 INFO liquibase.changelog :: SQL in file custom_sql/fill_cache_config.h2.sql executed\r\n2024-10-02 07:58:14,371 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha ran successfully in 18ms\r\n2024-10-02 07:58:14,374 INFO liquibase.changelog :: Column sandboxes.permission_id dropped\r\n2024-10-02 07:58:14,374 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-20T13:21:30::noahmoss ran successfully in 2ms\r\n2024-10-02 07:58:14,375 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,375 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-28T12:35:50::piranha ran successfully in 1ms\r\n2024-10-02 07:58:14,375 INFO liquibase.changelog :: Data deleted from user_parameter_value\r\n2024-10-02 07:58:14,376 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:48:21::adam-james ran successfully in 1ms\r\n2024-10-02 07:58:14,377 INFO liquibase.changelog :: Columns dashboard_id(int) added to user_parameter_value\r\n2024-10-02 07:58:14,377 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:49:29::adam-james ran successfully in 1ms\r\n2024-10-02 07:58:14,378 INFO liquibase.changelog :: Foreign key constraint added to user_parameter_value (dashboard_id)\r\n2024-10-02 07:58:14,378 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:55:42::adam-james ran successfully in 0ms\r\n2024-10-02 07:58:14,379 INFO liquibase.changelog :: Index idx_user_parameter_value_dashboard_id created\r\n2024-10-02 07:58:14,379 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T17:07:15::adam-james ran successfully in 0ms\r\n2024-10-02 07:58:14,380 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,380 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:00::calherries ran successfully in 1ms\r\n2024-10-02 07:58:14,380 INFO liquibase.changelog :: NOT NULL constraint has been added to report_card.last_used_at\r\n2024-10-02 07:58:14,380 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:02::calherries ran successfully in 0ms\r\n2024-10-02 07:58:14,381 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 07:58:14,382 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:03::calherries ran successfully in 1ms\r\n2024-10-02 07:58:14,382 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id_dashboard_id_parameter_id created\r\n2024-10-02 07:58:14,382 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-08T20:04:03::qnkhuat ran successfully in 0ms\r\n```\r\n</details>"", 'created_at': datetime.datetime(2024, 10, 2, 13, 0, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388658737, 'issue_id': 2390532272, 'author': 'dpsutton', 'body': 'Created the local instance with ` MB_JETTY_PORT=3006 java -jar $JARS/1.49.16.jar`\r\n\r\nIt has the meager logging of 49:\r\n\r\n```\r\n2024-10-02 08:26:57,181 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-10-02 08:26:57,183 INFO db.setup :: Verifying h2 Database Connection ...\r\n2024-10-02 08:26:57,317 INFO db.setup :: Successfully verified H2 2.1.214 (2022-06-13) application database connection. âœ…\r\n2024-10-02 08:26:57,317 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-10-02 08:26:57,583 INFO db.setup :: Running Database Migrations...\r\n2024-10-02 08:26:57,583 INFO db.setup :: Setting up Liquibase...\r\n2024-10-02 08:26:57,651 INFO db.setup :: Liquibase is ready.\r\n2024-10-02 08:26:57,651 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-10-02 08:26:57,830 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-10-02 08:26:57,834 INFO db.liquibase :: No migration lock found.\r\n2024-10-02 08:26:57,914 INFO db.liquibase :: Running 271 migrations ...\r\n... [logs about schedulers from tasks omitted]\r\n2024-10-02 08:26:59,007 INFO db.liquibase :: Migration complete in 1.1 s\r\n2024-10-02 08:26:59,008 INFO db.setup :: Database Migrations Current ...  âœ…\r\n2024-10-02 08:26:59,008 INFO metabase.util :: Database setup took 1.8 s\r\n```\r\n\r\n\r\nRunning `MB_JETTY_PORT=3006 java -jar $JARS/1.50.27.jar`\r\neach migration run includes information\r\n\r\n```\r\nChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 6ms\r\nColumns view_count(integer) added to report_dashboard\r\n```\r\n<details>\r\n<summary>\r\nlogs from 1.50.27\r\n</summary>\r\n\r\n```\r\n2024-10-02 08:27:21,140 INFO db.liquibase :: Running 96 migrations ...\r\n2024-10-02 08:27:21,175 INFO liquibase.changelog :: Reading from ""PUBLIC"".""DATABASECHANGELOG""\r\n2024-10-02 08:27:21,235 INFO liquibase.command :: Using deploymentId: 7875641235\r\n2024-10-02 08:27:21,236 INFO liquibase.changelog :: Reading from ""PUBLIC"".""DATABASECHANGELOG""\r\n2024-10-02 08:27:21,261 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:00::calherries ran successfully in 0ms\r\n2024-10-02 08:27:21,287 INFO liquibase.changelog :: Columns is_defective_duplicate(boolean) added to metabase_field\r\n2024-10-02 08:27:21,287 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:01::calherries ran successfully in 22ms\r\n2024-10-02 08:27:21,304 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,304 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:02::calherries ran successfully in 16ms\r\n2024-10-02 08:27:21,307 INFO liquibase.changelog :: Foreign key fk_field_parent_ref_field_id dropped\r\n2024-10-02 08:27:21,307 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:03::calherries ran successfully in 1ms\r\n2024-10-02 08:27:21,309 INFO liquibase.changelog :: Foreign key constraint added to metabase_field (parent_id)\r\n2024-10-02 08:27:21,309 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries ran successfully in 1ms\r\n2024-10-02 08:27:21,311 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,376 INFO liquibase.changelog :: Unique constraint idx_uniq_field_table_id_parent_id_name dropped from metabase_field\r\n2024-10-02 08:27:21,376 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:05::calherries ran successfully in 66ms\r\n2024-10-02 08:27:21,377 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:06::calherries ran successfully in 0ms\r\n2024-10-02 08:27:21,389 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,389 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries ran successfully in 12ms\r\n2024-10-02 08:27:21,392 INFO liquibase.changelog :: Unique constraint added to metabase_field(name, table_id, unique_field_helper)\r\n2024-10-02 08:27:21,392 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:08::calherries ran successfully in 2ms\r\n2024-10-02 08:27:21,394 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,394 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:09::calherries ran successfully in 1ms\r\n2024-10-02 08:27:21,410 INFO liquibase.changelog :: Columns perm_value(varchar(64)) added to permissions\r\n2024-10-02 08:27:21,410 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:06::johnswanson ran successfully in 15ms\r\n2024-10-02 08:27:21,415 INFO liquibase.changelog :: Columns perm_type(varchar(64)) added to permissions\r\n2024-10-02 08:27:21,416 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:07::johnswanson ran successfully in 5ms\r\n2024-10-02 08:27:21,421 INFO liquibase.changelog :: Columns collection_id(int) added to permissions\r\n2024-10-02 08:27:21,421 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:08::johnswanson ran successfully in 4ms\r\n2024-10-02 08:27:21,425 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,474 INFO liquibase.changelog :: Foreign key constraint added to permissions (collection_id)\r\n2024-10-02 08:27:21,475 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:09::johnswanson ran successfully in 53ms\r\n2024-10-02 08:27:21,481 INFO liquibase.changelog :: SQL in file permissions/collection-access-h2.sql executed\r\n2024-10-02 08:27:21,481 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:10::johnswanson ran successfully in 5ms\r\n2024-10-02 08:27:21,482 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,549 INFO liquibase.changelog :: Index idx_permissions_collection_id created\r\n2024-10-02 08:27:21,550 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:11::johnswanson ran successfully in 68ms\r\n2024-10-02 08:27:21,551 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,606 INFO liquibase.changelog :: Index idx_permissions_perm_type created\r\n2024-10-02 08:27:21,607 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:12::johnswanson ran successfully in 56ms\r\n2024-10-02 08:27:21,608 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,655 INFO liquibase.changelog :: Index idx_permissions_perm_value created\r\n2024-10-02 08:27:21,656 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:13::johnswanson ran successfully in 48ms\r\n2024-10-02 08:27:21,662 INFO liquibase.changelog :: Table data_permissions created\r\n2024-10-02 08:27:21,662 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-04T13:52:51::noahmoss ran successfully in 5ms\r\n2024-10-02 08:27:21,663 INFO liquibase.changelog :: Index idx_data_permissions_table_id created\r\n2024-10-02 08:27:21,664 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:52:21::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,665 INFO liquibase.changelog :: Index idx_data_permissions_db_id created\r\n2024-10-02 08:27:21,665 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:53:50::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,666 INFO liquibase.changelog :: Index idx_data_permissions_group_id created\r\n2024-10-02 08:27:21,666 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:53:54::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,667 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:20::noahmoss ran successfully in 0ms\r\n2024-10-02 08:27:21,667 INFO liquibase.changelog :: Foreign key fk_sandboxes_ref_permissions dropped\r\n2024-10-02 08:27:21,668 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:29::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,681 INFO liquibase.changelog :: SQL in file permissions/h2_data_access.sql executed\r\n2024-10-02 08:27:21,681 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:30::noahmoss ran successfully in 13ms\r\n2024-10-02 08:27:21,684 INFO liquibase.changelog :: SQL in file permissions/native_query_editing.sql executed\r\n2024-10-02 08:27:21,684 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:31::noahmoss ran successfully in 2ms\r\n2024-10-02 08:27:21,695 INFO liquibase.changelog :: SQL in file permissions/h2_download_results.sql executed\r\n2024-10-02 08:27:21,695 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:32::noahmoss ran successfully in 10ms\r\n2024-10-02 08:27:21,702 INFO liquibase.changelog :: SQL in file permissions/h2_manage_table_metadata.sql executed\r\n2024-10-02 08:27:21,702 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:33::noahmoss ran successfully in 6ms\r\n2024-10-02 08:27:21,704 INFO liquibase.changelog :: SQL in file permissions/manage_database.sql executed\r\n2024-10-02 08:27:21,705 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:34::noahmoss ran successfully in 2ms\r\n2024-10-02 08:27:21,706 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,706 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-19T21:32:04::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,707 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,707 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:21:04::camsaul ran successfully in 1ms\r\n2024-10-02 08:27:21,719 INFO liquibase.changelog :: Column report_card.dataset dropped\r\n2024-10-02 08:27:21,719 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:25:40::camsaul ran successfully in 11ms\r\n2024-10-02 08:27:21,725 INFO liquibase.changelog :: SQL in file instance_analytics_views/content/v2/h2-content.sql executed\r\n2024-10-02 08:27:21,725 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:26:38::camsaul ran successfully in 4ms\r\n2024-10-02 08:27:21,727 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,776 INFO liquibase.changelog :: Index idx_data_permissions_group_id_db_id_perm_value created\r\n2024-10-02 08:27:21,777 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:52::noahmoss ran successfully in 50ms\r\n2024-10-02 08:27:21,778 INFO liquibase.snapshot :: Creating snapshot\r\n2024-10-02 08:27:21,829 INFO liquibase.changelog :: Index idx_data_permissions_group_id_db_id_table_id_perm_value created\r\n2024-10-02 08:27:21,830 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:53::noahmoss ran successfully in 52ms\r\n2024-10-02 08:27:21,841 INFO liquibase.changelog :: SQL in file permissions/view_data.sql executed\r\n2024-10-02 08:27:21,841 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss ran successfully in 11ms\r\n2024-10-02 08:27:21,855 INFO liquibase.changelog :: SQL in file permissions/create_queries.sql executed\r\n2024-10-02 08:27:21,855 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:55::noahmoss ran successfully in 13ms\r\n2024-10-02 08:27:21,858 INFO liquibase.changelog :: Table query_field created\r\n2024-10-02 08:27:21,859 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:06:43::tsmacdonald ran successfully in 3ms\r\n2024-10-02 08:27:21,859 INFO liquibase.changelog :: Index idx_query_field_card_id created\r\n2024-10-02 08:27:21,860 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:07:43::tsmacdonald ran successfully in 1ms\r\n2024-10-02 08:27:21,861 INFO liquibase.changelog :: Index idx_query_field_field_id created\r\n2024-10-02 08:27:21,861 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:08:43::tsmacdonald ran successfully in 1ms\r\n2024-10-02 08:27:21,862 INFO liquibase.changelog :: Table activity dropped\r\n2024-10-02 08:27:21,862 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-12T17:16:38::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,865 INFO liquibase.changelog :: Table cache_config created\r\n2024-10-02 08:27:21,865 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-18T16:00:00::piranha ran successfully in 2ms\r\n2024-10-02 08:27:21,866 INFO liquibase.changelog :: Unique constraint added to cache_config(model, model_id)\r\n2024-10-02 08:27:21,866 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-18T16:00:01::piranha ran successfully in 0ms\r\n2024-10-02 08:27:21,870 INFO liquibase.changelog :: Columns estimated_row_count(bigint) added to metabase_table\r\n2024-10-02 08:27:21,870 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-21T17:41:00::qnkhuat ran successfully in 3ms\r\n2024-10-02 08:27:21,874 INFO liquibase.changelog :: Table field_usage created\r\n2024-10-02 08:27:21,874 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-22T00:38:28::qnkhuat ran successfully in 3ms\r\n2024-10-02 08:27:21,875 INFO liquibase.changelog :: Index idx_field_usage_field_id created\r\n2024-10-02 08:27:21,875 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-22T00:39:28::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:21,876 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,876 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-24T19:34:11::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:21,881 INFO liquibase.changelog :: Columns direct_reference(boolean) added to query_field\r\n2024-10-02 08:27:21,881 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-25T14:53:00::tsmacdonald ran successfully in 2ms\r\n2024-10-02 08:27:21,905 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateInternalUser\r\n2024-10-02 08:27:21,905 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-28T16:30:35::calherries ran successfully in 23ms\r\n2024-10-02 08:27:21,916 INFO liquibase.changelog :: Columns cache_invalidated_at(timestamp with time zone) added to report_card\r\n2024-10-02 08:27:21,916 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-29T10:00:00::piranha ran successfully in 10ms\r\n2024-10-02 08:27:21,922 INFO liquibase.changelog :: Columns is_sample(boolean) added to collection\r\n2024-10-02 08:27:21,922 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-09T15:55:19::calherries ran successfully in 5ms\r\n2024-10-02 08:27:21,933 INFO liquibase.changelog :: Columns last_used_at(timestamp with time zone) added to report_card\r\n2024-10-02 08:27:21,933 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-15T16:30:35::qnkhuat ran successfully in 10ms\r\n2024-10-02 08:27:21,935 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:21,936 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-19T17:04:04::noahmoss ran successfully in 2ms\r\n... [omitting logs about schedulers]\r\n\r\n\r\n2024-10-02 08:27:21,991 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulsesTask\r\n2024-10-02 08:27:21,992 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:05::qnkhuat ran successfully in 55ms\r\n2024-10-02 08:27:21,994 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade\r\n2024-10-02 08:27:21,994 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulseTaskOnDowngrade\r\n2024-10-02 08:27:21,995 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:06::qnkhuat ran successfully in 1ms\r\n2024-10-02 08:27:21,996 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade\r\n2024-10-02 08:27:21,996 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteInitSendPulseTriggersOnDowngrade\r\n2024-10-02 08:27:21,996 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:07::qnkhuat ran successfully in 1ms\r\n2024-10-02 08:27:22,004 INFO liquibase.changelog :: Columns entity_id(char(21)) added to core_user\r\n2024-10-02 08:27:22,004 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:01::noahmoss ran successfully in 7ms\r\n2024-10-02 08:27:22,007 INFO liquibase.changelog :: Columns entity_id(char(21)) added to permissions_group\r\n2024-10-02 08:27:22,008 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:02::noahmoss ran successfully in 3ms\r\n2024-10-02 08:27:22,018 INFO liquibase.changelog :: Columns view_count(integer) added to report_card\r\n2024-10-02 08:27:22,018 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:31::calherries ran successfully in 10ms\r\n2024-10-02 08:27:22,024 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,025 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 6ms\r\n2024-10-02 08:27:22,031 INFO liquibase.changelog :: Columns view_count(integer) added to report_dashboard\r\n2024-10-02 08:27:22,032 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:33::calherries ran successfully in 5ms\r\n2024-10-02 08:27:22,033 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,033 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:34::calherries ran successfully in 1ms\r\n2024-10-02 08:27:22,037 INFO liquibase.changelog :: Columns view_count(integer) added to metabase_table\r\n2024-10-02 08:27:22,037 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:35::calherries ran successfully in 3ms\r\n2024-10-02 08:27:22,039 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,039 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:36::calherries ran successfully in 1ms\r\n2024-10-02 08:27:22,041 INFO liquibase.changelog :: Table user_parameter_value created\r\n2024-10-02 08:27:22,041 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:19:00::adam-james ran successfully in 1ms\r\n2024-10-02 08:27:22,042 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id created\r\n2024-10-02 08:27:22,042 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:25:00::adam-james ran successfully in 0ms\r\n2024-10-02 08:27:22,045 INFO liquibase.changelog :: Columns scope(varchar(64)) added to api_key\r\n2024-10-02 08:27:22,046 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:57:23::noahmoss ran successfully in 3ms\r\n2024-10-02 08:27:22,047 INFO liquibase.changelog :: Null constraint dropped from api_key.user_id\r\n2024-10-02 08:27:22,047 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:58:24::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:22,050 INFO liquibase.changelog :: Columns status(varchar(21)) added to task_history\r\n2024-10-02 08:27:22,050 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:00::qnkhuat ran successfully in 2ms\r\n2024-10-02 08:27:22,051 INFO liquibase.changelog :: Default value dropped from task_history.status\r\n2024-10-02 08:27:22,051 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:01::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,052 INFO liquibase.changelog :: Default value added to task_history.status\r\n2024-10-02 08:27:22,052 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:02::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,053 INFO liquibase.changelog :: Null constraint dropped from task_history.ended_at\r\n2024-10-02 08:27:22,053 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:03::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,054 INFO liquibase.changelog :: Null constraint dropped from task_history.duration\r\n2024-10-02 08:27:22,054 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:04::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,054 INFO liquibase.changelog :: Default value dropped from task_history.ended_at\r\n2024-10-02 08:27:22,055 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:05::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,055 INFO liquibase.changelog :: Default value added to task_history.ended_at\r\n2024-10-02 08:27:22,055 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:06::qnkhuat ran successfully in 0ms\r\n2024-10-02 08:27:22,058 INFO liquibase.changelog :: Table cloud_migration created\r\n2024-10-02 08:27:22,058 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-13T16:00:00::filipesilva ran successfully in 2ms\r\n2024-10-02 08:27:22,063 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateStackedAreaBarComboDisplaySettings\r\n2024-10-02 08:27:22,063 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-15T13:13:13::adam-james ran successfully in 4ms\r\n2024-10-02 08:27:22,067 INFO liquibase.changelog :: Columns uploads_enabled(boolean) added to metabase_database\r\n2024-10-02 08:27:22,067 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:23::calherries ran successfully in 3ms\r\n2024-10-02 08:27:22,070 INFO liquibase.changelog :: Columns uploads_schema_name(text) added to metabase_database\r\n2024-10-02 08:27:22,070 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:24::calherries ran successfully in 2ms\r\n2024-10-02 08:27:22,073 INFO liquibase.changelog :: Columns uploads_table_prefix(text) added to metabase_database\r\n2024-10-02 08:27:22,074 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:25::calherries ran successfully in 3ms\r\n2024-10-02 08:27:22,077 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateUploadsSettings\r\n2024-10-02 08:27:22,077 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:26::calherries ran successfully in 3ms\r\n2024-10-02 08:27:22,083 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateSampleContent\r\n2024-10-02 08:27:22,083 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-27T15:55:22::calherries ran successfully in 6ms\r\n2024-10-02 08:27:22,085 INFO liquibase.changelog :: Columns context(varchar(256)) added to recent_views\r\n2024-10-02 08:27:22,085 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-30T16:04:20::escherize ran successfully in 1ms\r\n2024-10-02 08:27:22,096 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DecryptCacheSettings\r\n2024-10-02 08:27:22,096 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:07::piranha ran successfully in 10ms\r\n2024-10-02 08:27:22,114 INFO liquibase.changelog :: SQL in file custom_sql/fill_cache_config.h2.sql executed\r\n2024-10-02 08:27:22,114 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha ran successfully in 17ms\r\n2024-10-02 08:27:22,116 INFO liquibase.changelog :: Column sandboxes.permission_id dropped\r\n2024-10-02 08:27:22,116 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-20T13:21:30::noahmoss ran successfully in 1ms\r\n2024-10-02 08:27:22,118 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,118 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-28T12:35:50::piranha ran successfully in 1ms\r\n2024-10-02 08:27:22,118 INFO liquibase.changelog :: Data deleted from user_parameter_value\r\n2024-10-02 08:27:22,119 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:48:21::adam-james ran successfully in 1ms\r\n2024-10-02 08:27:22,120 INFO liquibase.changelog :: Columns dashboard_id(int) added to user_parameter_value\r\n2024-10-02 08:27:22,121 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:49:29::adam-james ran successfully in 2ms\r\n2024-10-02 08:27:22,122 INFO liquibase.changelog :: Foreign key constraint added to user_parameter_value (dashboard_id)\r\n2024-10-02 08:27:22,122 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:55:42::adam-james ran successfully in 1ms\r\n2024-10-02 08:27:22,122 INFO liquibase.changelog :: Index idx_user_parameter_value_dashboard_id created\r\n2024-10-02 08:27:22,122 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T17:07:15::adam-james ran successfully in 0ms\r\n2024-10-02 08:27:22,126 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,127 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:00::calherries ran successfully in 4ms\r\n2024-10-02 08:27:22,170 INFO liquibase.changelog :: NOT NULL constraint has been added to report_card.last_used_at\r\n2024-10-02 08:27:22,170 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:02::calherries ran successfully in 42ms\r\n2024-10-02 08:27:22,172 INFO liquibase.changelog :: Custom SQL executed\r\n2024-10-02 08:27:22,172 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:03::calherries ran successfully in 1ms\r\n2024-10-02 08:27:22,173 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id_dashboard_id_parameter_id created\r\n2024-10-02 08:27:22,174 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-08T20:04:03::qnkhuat ran successfully in 1ms\r\n2024-10-02 08:27:22,178 INFO liquibase.changelog :: Columns is_attached_dwh(boolean) added to metabase_database\r\n2024-10-02 08:27:22,178 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-27T00:00:00::devurandom ran successfully in 4ms\r\n\r\nUPDATE SUMMARY\r\nRun:                         96\r\nPreviously run:             270\r\nFiltered out:                51\r\n-------------------------------\r\nTotal change sets:          417\r\n\r\n\r\nFILTERED CHANGE SETS SUMMARY\r\nDBMS mismatch:               51\r\n\r\n2024-10-02 08:27:22,185 INFO liquibase.util :: UPDATE SUMMARY\r\n2024-10-02 08:27:22,185 INFO liquibase.util :: Run:                         96\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: Previously run:             270\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: Filtered out:                51\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: -------------------------------\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: Total change sets:          417\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: FILTERED CHANGE SETS SUMMARY\r\n2024-10-02 08:27:22,186 INFO liquibase.util :: DBMS mismatch:               51\r\n2024-10-02 08:27:22,189 INFO liquibase.util :: Update summary generated\r\n2024-10-02 08:27:22,192 INFO liquibase.command :: Update command completed successfully.\r\n2024-10-02 08:27:22,193 INFO liquibase.lockservice :: Successfully released change log lock\r\n2024-10-02 08:27:22,193 INFO liquibase.command :: Command execution complete\r\n2024-10-02 08:27:22,194 INFO db.liquibase :: Migration complete in 1.1 s\r\n2024-10-02 08:27:22,194 INFO liquibase.lockservice :: Successfully released change log lock\r\n2024-10-02 08:27:22,197 INFO db.setup :: Database Migrations Current ... âœ…\r\n2024-10-02 08:27:22,198 INFO metabase.util :: Database setup took 2.0 s\r\n```\r\n</details>\r\n\r\nNOTE: this behavior is entirely controlled by the change to `resources/log4j2.xml` which includes\r\n\r\n```xml\r\n<Logger name=""liquibase"" level=""INFO""/>\r\n```\r\n\r\nIf a custom logging configuration is used then adding this line will restore the more verbose migration logging.', 'created_at': datetime.datetime(2024, 10, 2, 13, 33, 28, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-02 13:00:02 UTC): This was implemented in https://github.com/metabase/metabase/pull/47397


<details>
<summary>
Here's what the logs of a 49 -> 50 upgrade look like
</summary>

```
2024-10-02 07:58:14,269 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulsesTask
2024-10-02 07:58:14,269 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:05::qnkhuat ran successfully in 38ms
2024-10-02 07:58:14,270 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
2024-10-02 07:58:14,270 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulseTaskOnDowngrade
2024-10-02 07:58:14,270 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:06::qnkhuat ran successfully in 0ms
2024-10-02 07:58:14,271 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade
2024-10-02 07:58:14,272 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteInitSendPulseTriggersOnDowngrade
2024-10-02 07:58:14,272 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:07::qnkhuat ran successfully in 1ms
2024-10-02 07:58:14,277 INFO liquibase.changelog :: Columns entity_id(char(21)) added to core_user
2024-10-02 07:58:14,277 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:01::noahmoss ran successfully in 5ms
2024-10-02 07:58:14,281 INFO liquibase.changelog :: Columns entity_id(char(21)) added to permissions_group
2024-10-02 07:58:14,281 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:02::noahmoss ran successfully in 3ms
2024-10-02 07:58:14,287 INFO liquibase.changelog :: Columns view_count(integer) added to report_card
2024-10-02 07:58:14,288 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:31::calherries ran successfully in 7ms
2024-10-02 07:58:14,289 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,289 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 1ms
2024-10-02 07:58:14,294 INFO liquibase.changelog :: Columns view_count(integer) added to report_dashboard
2024-10-02 07:58:14,294 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:33::calherries ran successfully in 4ms
2024-10-02 07:58:14,295 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,295 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:34::calherries ran successfully in 0ms
2024-10-02 07:58:14,298 INFO liquibase.changelog :: Columns view_count(integer) added to metabase_table
2024-10-02 07:58:14,299 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:35::calherries ran successfully in 3ms
2024-10-02 07:58:14,300 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,300 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:36::calherries ran successfully in 1ms
2024-10-02 07:58:14,304 INFO liquibase.changelog :: Table user_parameter_value created
2024-10-02 07:58:14,304 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:19:00::adam-james ran successfully in 3ms
2024-10-02 07:58:14,305 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id created
2024-10-02 07:58:14,305 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:25:00::adam-james ran successfully in 0ms
2024-10-02 07:58:14,307 INFO liquibase.changelog :: Columns scope(varchar(64)) added to api_key
2024-10-02 07:58:14,307 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:57:23::noahmoss ran successfully in 1ms
2024-10-02 07:58:14,308 INFO liquibase.changelog :: Null constraint dropped from api_key.user_id
2024-10-02 07:58:14,308 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:58:24::noahmoss ran successfully in 0ms
2024-10-02 07:58:14,311 INFO liquibase.changelog :: Columns status(varchar(21)) added to task_history
2024-10-02 07:58:14,311 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:00::qnkhuat ran successfully in 2ms
2024-10-02 07:58:14,312 INFO liquibase.changelog :: Default value dropped from task_history.status
2024-10-02 07:58:14,312 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:01::qnkhuat ran successfully in 1ms
2024-10-02 07:58:14,312 INFO liquibase.changelog :: Default value added to task_history.status
2024-10-02 07:58:14,313 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:02::qnkhuat ran successfully in 0ms
2024-10-02 07:58:14,313 INFO liquibase.changelog :: Null constraint dropped from task_history.ended_at
2024-10-02 07:58:14,313 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:03::qnkhuat ran successfully in 0ms
2024-10-02 07:58:14,314 INFO liquibase.changelog :: Null constraint dropped from task_history.duration
2024-10-02 07:58:14,314 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:04::qnkhuat ran successfully in 0ms
2024-10-02 07:58:14,315 INFO liquibase.changelog :: Default value dropped from task_history.ended_at
2024-10-02 07:58:14,315 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:05::qnkhuat ran successfully in 1ms
2024-10-02 07:58:14,315 INFO liquibase.changelog :: Default value added to task_history.ended_at
2024-10-02 07:58:14,316 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:06::qnkhuat ran successfully in 1ms
2024-10-02 07:58:14,319 INFO liquibase.changelog :: Table cloud_migration created
2024-10-02 07:58:14,319 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-13T16:00:00::filipesilva ran successfully in 3ms
2024-10-02 07:58:14,322 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateStackedAreaBarComboDisplaySettings
2024-10-02 07:58:14,322 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-15T13:13:13::adam-james ran successfully in 3ms
2024-10-02 07:58:14,325 INFO liquibase.changelog :: Columns uploads_enabled(boolean) added to metabase_database
2024-10-02 07:58:14,325 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:23::calherries ran successfully in 2ms
2024-10-02 07:58:14,327 INFO liquibase.changelog :: Columns uploads_schema_name(text) added to metabase_database
2024-10-02 07:58:14,327 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:24::calherries ran successfully in 2ms
2024-10-02 07:58:14,330 INFO liquibase.changelog :: Columns uploads_table_prefix(text) added to metabase_database
2024-10-02 07:58:14,330 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:25::calherries ran successfully in 2ms
2024-10-02 07:58:14,333 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateUploadsSettings
2024-10-02 07:58:14,333 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:26::calherries ran successfully in 2ms
2024-10-02 07:58:14,340 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateSampleContent
2024-10-02 07:58:14,340 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-27T15:55:22::calherries ran successfully in 6ms
2024-10-02 07:58:14,342 INFO liquibase.changelog :: Columns context(varchar(256)) added to recent_views
2024-10-02 07:58:14,342 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-30T16:04:20::escherize ran successfully in 1ms
2024-10-02 07:58:14,352 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DecryptCacheSettings
2024-10-02 07:58:14,352 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:07::piranha ran successfully in 9ms
2024-10-02 07:58:14,371 INFO liquibase.changelog :: SQL in file custom_sql/fill_cache_config.h2.sql executed
2024-10-02 07:58:14,371 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha ran successfully in 18ms
2024-10-02 07:58:14,374 INFO liquibase.changelog :: Column sandboxes.permission_id dropped
2024-10-02 07:58:14,374 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-20T13:21:30::noahmoss ran successfully in 2ms
2024-10-02 07:58:14,375 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,375 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-28T12:35:50::piranha ran successfully in 1ms
2024-10-02 07:58:14,375 INFO liquibase.changelog :: Data deleted from user_parameter_value
2024-10-02 07:58:14,376 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:48:21::adam-james ran successfully in 1ms
2024-10-02 07:58:14,377 INFO liquibase.changelog :: Columns dashboard_id(int) added to user_parameter_value
2024-10-02 07:58:14,377 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:49:29::adam-james ran successfully in 1ms
2024-10-02 07:58:14,378 INFO liquibase.changelog :: Foreign key constraint added to user_parameter_value (dashboard_id)
2024-10-02 07:58:14,378 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:55:42::adam-james ran successfully in 0ms
2024-10-02 07:58:14,379 INFO liquibase.changelog :: Index idx_user_parameter_value_dashboard_id created
2024-10-02 07:58:14,379 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T17:07:15::adam-james ran successfully in 0ms
2024-10-02 07:58:14,380 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,380 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:00::calherries ran successfully in 1ms
2024-10-02 07:58:14,380 INFO liquibase.changelog :: NOT NULL constraint has been added to report_card.last_used_at
2024-10-02 07:58:14,380 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:02::calherries ran successfully in 0ms
2024-10-02 07:58:14,381 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 07:58:14,382 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:03::calherries ran successfully in 1ms
2024-10-02 07:58:14,382 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id_dashboard_id_parameter_id created
2024-10-02 07:58:14,382 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-08T20:04:03::qnkhuat ran successfully in 0ms
```
</details>

dpsutton on (2024-10-02 13:33:28 UTC): Created the local instance with ` MB_JETTY_PORT=3006 java -jar $JARS/1.49.16.jar`

It has the meager logging of 49:

```
2024-10-02 08:26:57,181 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-10-02 08:26:57,183 INFO db.setup :: Verifying h2 Database Connection ...
2024-10-02 08:26:57,317 INFO db.setup :: Successfully verified H2 2.1.214 (2022-06-13) application database connection. âœ…
2024-10-02 08:26:57,317 INFO db.setup :: Checking if a database downgrade is required...
2024-10-02 08:26:57,583 INFO db.setup :: Running Database Migrations...
2024-10-02 08:26:57,583 INFO db.setup :: Setting up Liquibase...
2024-10-02 08:26:57,651 INFO db.setup :: Liquibase is ready.
2024-10-02 08:26:57,651 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-10-02 08:26:57,830 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-10-02 08:26:57,834 INFO db.liquibase :: No migration lock found.
2024-10-02 08:26:57,914 INFO db.liquibase :: Running 271 migrations ...
... [logs about schedulers from tasks omitted]
2024-10-02 08:26:59,007 INFO db.liquibase :: Migration complete in 1.1 s
2024-10-02 08:26:59,008 INFO db.setup :: Database Migrations Current ...  âœ…
2024-10-02 08:26:59,008 INFO metabase.util :: Database setup took 1.8 s
```


Running `MB_JETTY_PORT=3006 java -jar $JARS/1.50.27.jar`
each migration run includes information

```
ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 6ms
Columns view_count(integer) added to report_dashboard
```
<details>
<summary>
logs from 1.50.27
</summary>

```
2024-10-02 08:27:21,140 INFO db.liquibase :: Running 96 migrations ...
2024-10-02 08:27:21,175 INFO liquibase.changelog :: Reading from ""PUBLIC"".""DATABASECHANGELOG""
2024-10-02 08:27:21,235 INFO liquibase.command :: Using deploymentId: 7875641235
2024-10-02 08:27:21,236 INFO liquibase.changelog :: Reading from ""PUBLIC"".""DATABASECHANGELOG""
2024-10-02 08:27:21,261 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:00::calherries ran successfully in 0ms
2024-10-02 08:27:21,287 INFO liquibase.changelog :: Columns is_defective_duplicate(boolean) added to metabase_field
2024-10-02 08:27:21,287 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:01::calherries ran successfully in 22ms
2024-10-02 08:27:21,304 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,304 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:02::calherries ran successfully in 16ms
2024-10-02 08:27:21,307 INFO liquibase.changelog :: Foreign key fk_field_parent_ref_field_id dropped
2024-10-02 08:27:21,307 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:03::calherries ran successfully in 1ms
2024-10-02 08:27:21,309 INFO liquibase.changelog :: Foreign key constraint added to metabase_field (parent_id)
2024-10-02 08:27:21,309 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:04::calherries ran successfully in 1ms
2024-10-02 08:27:21,311 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,376 INFO liquibase.changelog :: Unique constraint idx_uniq_field_table_id_parent_id_name dropped from metabase_field
2024-10-02 08:27:21,376 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:05::calherries ran successfully in 66ms
2024-10-02 08:27:21,377 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:06::calherries ran successfully in 0ms
2024-10-02 08:27:21,389 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,389 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries ran successfully in 12ms
2024-10-02 08:27:21,392 INFO liquibase.changelog :: Unique constraint added to metabase_field(name, table_id, unique_field_helper)
2024-10-02 08:27:21,392 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:08::calherries ran successfully in 2ms
2024-10-02 08:27:21,394 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,394 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:09::calherries ran successfully in 1ms
2024-10-02 08:27:21,410 INFO liquibase.changelog :: Columns perm_value(varchar(64)) added to permissions
2024-10-02 08:27:21,410 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:06::johnswanson ran successfully in 15ms
2024-10-02 08:27:21,415 INFO liquibase.changelog :: Columns perm_type(varchar(64)) added to permissions
2024-10-02 08:27:21,416 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:07::johnswanson ran successfully in 5ms
2024-10-02 08:27:21,421 INFO liquibase.changelog :: Columns collection_id(int) added to permissions
2024-10-02 08:27:21,421 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:08::johnswanson ran successfully in 4ms
2024-10-02 08:27:21,425 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,474 INFO liquibase.changelog :: Foreign key constraint added to permissions (collection_id)
2024-10-02 08:27:21,475 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:09::johnswanson ran successfully in 53ms
2024-10-02 08:27:21,481 INFO liquibase.changelog :: SQL in file permissions/collection-access-h2.sql executed
2024-10-02 08:27:21,481 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:10::johnswanson ran successfully in 5ms
2024-10-02 08:27:21,482 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,549 INFO liquibase.changelog :: Index idx_permissions_collection_id created
2024-10-02 08:27:21,550 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:11::johnswanson ran successfully in 68ms
2024-10-02 08:27:21,551 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,606 INFO liquibase.changelog :: Index idx_permissions_perm_type created
2024-10-02 08:27:21,607 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:12::johnswanson ran successfully in 56ms
2024-10-02 08:27:21,608 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,655 INFO liquibase.changelog :: Index idx_permissions_perm_value created
2024-10-02 08:27:21,656 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-08-21T08:33:13::johnswanson ran successfully in 48ms
2024-10-02 08:27:21,662 INFO liquibase.changelog :: Table data_permissions created
2024-10-02 08:27:21,662 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-04T13:52:51::noahmoss ran successfully in 5ms
2024-10-02 08:27:21,663 INFO liquibase.changelog :: Index idx_data_permissions_table_id created
2024-10-02 08:27:21,664 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:52:21::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,665 INFO liquibase.changelog :: Index idx_data_permissions_db_id created
2024-10-02 08:27:21,665 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:53:50::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,666 INFO liquibase.changelog :: Index idx_data_permissions_group_id created
2024-10-02 08:27:21,666 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-09T13:53:54::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,667 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:20::noahmoss ran successfully in 0ms
2024-10-02 08:27:21,667 INFO liquibase.changelog :: Foreign key fk_sandboxes_ref_permissions dropped
2024-10-02 08:27:21,668 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:29::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,681 INFO liquibase.changelog :: SQL in file permissions/h2_data_access.sql executed
2024-10-02 08:27:21,681 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:30::noahmoss ran successfully in 13ms
2024-10-02 08:27:21,684 INFO liquibase.changelog :: SQL in file permissions/native_query_editing.sql executed
2024-10-02 08:27:21,684 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:31::noahmoss ran successfully in 2ms
2024-10-02 08:27:21,695 INFO liquibase.changelog :: SQL in file permissions/h2_download_results.sql executed
2024-10-02 08:27:21,695 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:32::noahmoss ran successfully in 10ms
2024-10-02 08:27:21,702 INFO liquibase.changelog :: SQL in file permissions/h2_manage_table_metadata.sql executed
2024-10-02 08:27:21,702 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:33::noahmoss ran successfully in 6ms
2024-10-02 08:27:21,704 INFO liquibase.changelog :: SQL in file permissions/manage_database.sql executed
2024-10-02 08:27:21,705 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:34::noahmoss ran successfully in 2ms
2024-10-02 08:27:21,706 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,706 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-19T21:32:04::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,707 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,707 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:21:04::camsaul ran successfully in 1ms
2024-10-02 08:27:21,719 INFO liquibase.changelog :: Column report_card.dataset dropped
2024-10-02 08:27:21,719 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:25:40::camsaul ran successfully in 11ms
2024-10-02 08:27:21,725 INFO liquibase.changelog :: SQL in file instance_analytics_views/content/v2/h2-content.sql executed
2024-10-02 08:27:21,725 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-20T19:26:38::camsaul ran successfully in 4ms
2024-10-02 08:27:21,727 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,776 INFO liquibase.changelog :: Index idx_data_permissions_group_id_db_id_perm_value created
2024-10-02 08:27:21,777 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:52::noahmoss ran successfully in 50ms
2024-10-02 08:27:21,778 INFO liquibase.snapshot :: Creating snapshot
2024-10-02 08:27:21,829 INFO liquibase.changelog :: Index idx_data_permissions_group_id_db_id_table_id_perm_value created
2024-10-02 08:27:21,830 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:53::noahmoss ran successfully in 52ms
2024-10-02 08:27:21,841 INFO liquibase.changelog :: SQL in file permissions/view_data.sql executed
2024-10-02 08:27:21,841 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss ran successfully in 11ms
2024-10-02 08:27:21,855 INFO liquibase.changelog :: SQL in file permissions/create_queries.sql executed
2024-10-02 08:27:21,855 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:55::noahmoss ran successfully in 13ms
2024-10-02 08:27:21,858 INFO liquibase.changelog :: Table query_field created
2024-10-02 08:27:21,859 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:06:43::tsmacdonald ran successfully in 3ms
2024-10-02 08:27:21,859 INFO liquibase.changelog :: Index idx_query_field_card_id created
2024-10-02 08:27:21,860 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:07:43::tsmacdonald ran successfully in 1ms
2024-10-02 08:27:21,861 INFO liquibase.changelog :: Index idx_query_field_field_id created
2024-10-02 08:27:21,861 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-29T15:08:43::tsmacdonald ran successfully in 1ms
2024-10-02 08:27:21,862 INFO liquibase.changelog :: Table activity dropped
2024-10-02 08:27:21,862 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-12T17:16:38::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,865 INFO liquibase.changelog :: Table cache_config created
2024-10-02 08:27:21,865 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-18T16:00:00::piranha ran successfully in 2ms
2024-10-02 08:27:21,866 INFO liquibase.changelog :: Unique constraint added to cache_config(model, model_id)
2024-10-02 08:27:21,866 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-18T16:00:01::piranha ran successfully in 0ms
2024-10-02 08:27:21,870 INFO liquibase.changelog :: Columns estimated_row_count(bigint) added to metabase_table
2024-10-02 08:27:21,870 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-21T17:41:00::qnkhuat ran successfully in 3ms
2024-10-02 08:27:21,874 INFO liquibase.changelog :: Table field_usage created
2024-10-02 08:27:21,874 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-22T00:38:28::qnkhuat ran successfully in 3ms
2024-10-02 08:27:21,875 INFO liquibase.changelog :: Index idx_field_usage_field_id created
2024-10-02 08:27:21,875 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-22T00:39:28::qnkhuat ran successfully in 0ms
2024-10-02 08:27:21,876 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,876 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-24T19:34:11::noahmoss ran successfully in 1ms
2024-10-02 08:27:21,881 INFO liquibase.changelog :: Columns direct_reference(boolean) added to query_field
2024-10-02 08:27:21,881 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-25T14:53:00::tsmacdonald ran successfully in 2ms
2024-10-02 08:27:21,905 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateInternalUser
2024-10-02 08:27:21,905 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-28T16:30:35::calherries ran successfully in 23ms
2024-10-02 08:27:21,916 INFO liquibase.changelog :: Columns cache_invalidated_at(timestamp with time zone) added to report_card
2024-10-02 08:27:21,916 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-03-29T10:00:00::piranha ran successfully in 10ms
2024-10-02 08:27:21,922 INFO liquibase.changelog :: Columns is_sample(boolean) added to collection
2024-10-02 08:27:21,922 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-09T15:55:19::calherries ran successfully in 5ms
2024-10-02 08:27:21,933 INFO liquibase.changelog :: Columns last_used_at(timestamp with time zone) added to report_card
2024-10-02 08:27:21,933 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-15T16:30:35::qnkhuat ran successfully in 10ms
2024-10-02 08:27:21,935 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:21,936 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-19T17:04:04::noahmoss ran successfully in 2ms
... [omitting logs about schedulers]


2024-10-02 08:27:21,991 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulsesTask
2024-10-02 08:27:21,992 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:05::qnkhuat ran successfully in 55ms
2024-10-02 08:27:21,994 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
2024-10-02 08:27:21,994 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteSendPulseTaskOnDowngrade
2024-10-02 08:27:21,995 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:06::qnkhuat ran successfully in 1ms
2024-10-02 08:27:21,996 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade
2024-10-02 08:27:21,996 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DeleteInitSendPulseTriggersOnDowngrade
2024-10-02 08:27:21,996 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T01:04:07::qnkhuat ran successfully in 1ms
2024-10-02 08:27:22,004 INFO liquibase.changelog :: Columns entity_id(char(21)) added to core_user
2024-10-02 08:27:22,004 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:01::noahmoss ran successfully in 7ms
2024-10-02 08:27:22,007 INFO liquibase.changelog :: Columns entity_id(char(21)) added to permissions_group
2024-10-02 08:27:22,008 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T03:15:02::noahmoss ran successfully in 3ms
2024-10-02 08:27:22,018 INFO liquibase.changelog :: Columns view_count(integer) added to report_card
2024-10-02 08:27:22,018 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:31::calherries ran successfully in 10ms
2024-10-02 08:27:22,024 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,025 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:32::calherries ran successfully in 6ms
2024-10-02 08:27:22,031 INFO liquibase.changelog :: Columns view_count(integer) added to report_dashboard
2024-10-02 08:27:22,032 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:33::calherries ran successfully in 5ms
2024-10-02 08:27:22,033 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,033 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:34::calherries ran successfully in 1ms
2024-10-02 08:27:22,037 INFO liquibase.changelog :: Columns view_count(integer) added to metabase_table
2024-10-02 08:27:22,037 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:35::calherries ran successfully in 3ms
2024-10-02 08:27:22,039 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,039 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-25T16:29:36::calherries ran successfully in 1ms
2024-10-02 08:27:22,041 INFO liquibase.changelog :: Table user_parameter_value created
2024-10-02 08:27:22,041 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:19:00::adam-james ran successfully in 1ms
2024-10-02 08:27:22,042 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id created
2024-10-02 08:27:22,042 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-26T09:25:00::adam-james ran successfully in 0ms
2024-10-02 08:27:22,045 INFO liquibase.changelog :: Columns scope(varchar(64)) added to api_key
2024-10-02 08:27:22,046 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:57:23::noahmoss ran successfully in 3ms
2024-10-02 08:27:22,047 INFO liquibase.changelog :: Null constraint dropped from api_key.user_id
2024-10-02 08:27:22,047 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-04-30T23:58:24::noahmoss ran successfully in 1ms
2024-10-02 08:27:22,050 INFO liquibase.changelog :: Columns status(varchar(21)) added to task_history
2024-10-02 08:27:22,050 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:00::qnkhuat ran successfully in 2ms
2024-10-02 08:27:22,051 INFO liquibase.changelog :: Default value dropped from task_history.status
2024-10-02 08:27:22,051 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:01::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,052 INFO liquibase.changelog :: Default value added to task_history.status
2024-10-02 08:27:22,052 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:02::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,053 INFO liquibase.changelog :: Null constraint dropped from task_history.ended_at
2024-10-02 08:27:22,053 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:03::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,054 INFO liquibase.changelog :: Null constraint dropped from task_history.duration
2024-10-02 08:27:22,054 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:04::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,054 INFO liquibase.changelog :: Default value dropped from task_history.ended_at
2024-10-02 08:27:22,055 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:05::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,055 INFO liquibase.changelog :: Default value added to task_history.ended_at
2024-10-02 08:27:22,055 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-08T09:00:06::qnkhuat ran successfully in 0ms
2024-10-02 08:27:22,058 INFO liquibase.changelog :: Table cloud_migration created
2024-10-02 08:27:22,058 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-13T16:00:00::filipesilva ran successfully in 2ms
2024-10-02 08:27:22,063 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateStackedAreaBarComboDisplaySettings
2024-10-02 08:27:22,063 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-15T13:13:13::adam-james ran successfully in 4ms
2024-10-02 08:27:22,067 INFO liquibase.changelog :: Columns uploads_enabled(boolean) added to metabase_database
2024-10-02 08:27:22,067 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:23::calherries ran successfully in 3ms
2024-10-02 08:27:22,070 INFO liquibase.changelog :: Columns uploads_schema_name(text) added to metabase_database
2024-10-02 08:27:22,070 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:24::calherries ran successfully in 2ms
2024-10-02 08:27:22,073 INFO liquibase.changelog :: Columns uploads_table_prefix(text) added to metabase_database
2024-10-02 08:27:22,074 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:25::calherries ran successfully in 3ms
2024-10-02 08:27:22,077 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.MigrateUploadsSettings
2024-10-02 08:27:22,077 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-17T19:54:26::calherries ran successfully in 3ms
2024-10-02 08:27:22,083 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.CreateSampleContent
2024-10-02 08:27:22,083 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-27T15:55:22::calherries ran successfully in 6ms
2024-10-02 08:27:22,085 INFO liquibase.changelog :: Columns context(varchar(256)) added to recent_views
2024-10-02 08:27:22,085 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-05-30T16:04:20::escherize ran successfully in 1ms
2024-10-02 08:27:22,096 INFO liquibase.changelog :: Custom migration: class metabase.db.custom_migrations.DecryptCacheSettings
2024-10-02 08:27:22,096 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:07::piranha ran successfully in 10ms
2024-10-02 08:27:22,114 INFO liquibase.changelog :: SQL in file custom_sql/fill_cache_config.h2.sql executed
2024-10-02 08:27:22,114 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha ran successfully in 17ms
2024-10-02 08:27:22,116 INFO liquibase.changelog :: Column sandboxes.permission_id dropped
2024-10-02 08:27:22,116 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-20T13:21:30::noahmoss ran successfully in 1ms
2024-10-02 08:27:22,118 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,118 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-28T12:35:50::piranha ran successfully in 1ms
2024-10-02 08:27:22,118 INFO liquibase.changelog :: Data deleted from user_parameter_value
2024-10-02 08:27:22,119 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:48:21::adam-james ran successfully in 1ms
2024-10-02 08:27:22,120 INFO liquibase.changelog :: Columns dashboard_id(int) added to user_parameter_value
2024-10-02 08:27:22,121 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:49:29::adam-james ran successfully in 2ms
2024-10-02 08:27:22,122 INFO liquibase.changelog :: Foreign key constraint added to user_parameter_value (dashboard_id)
2024-10-02 08:27:22,122 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T16:55:42::adam-james ran successfully in 1ms
2024-10-02 08:27:22,122 INFO liquibase.changelog :: Index idx_user_parameter_value_dashboard_id created
2024-10-02 08:27:22,122 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-02T17:07:15::adam-james ran successfully in 0ms
2024-10-02 08:27:22,126 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,127 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:00::calherries ran successfully in 4ms
2024-10-02 08:27:22,170 INFO liquibase.changelog :: NOT NULL constraint has been added to report_card.last_used_at
2024-10-02 08:27:22,170 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:02::calherries ran successfully in 42ms
2024-10-02 08:27:22,172 INFO liquibase.changelog :: Custom SQL executed
2024-10-02 08:27:22,172 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-07-09T20:04:03::calherries ran successfully in 1ms
2024-10-02 08:27:22,173 INFO liquibase.changelog :: Index idx_user_parameter_value_user_id_dashboard_id_parameter_id created
2024-10-02 08:27:22,174 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-08T20:04:03::qnkhuat ran successfully in 1ms
2024-10-02 08:27:22,178 INFO liquibase.changelog :: Columns is_attached_dwh(boolean) added to metabase_database
2024-10-02 08:27:22,178 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-08-27T00:00:00::devurandom ran successfully in 4ms

UPDATE SUMMARY
Run:                         96
Previously run:             270
Filtered out:                51
-------------------------------
Total change sets:          417


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               51

2024-10-02 08:27:22,185 INFO liquibase.util :: UPDATE SUMMARY
2024-10-02 08:27:22,185 INFO liquibase.util :: Run:                         96
2024-10-02 08:27:22,186 INFO liquibase.util :: Previously run:             270
2024-10-02 08:27:22,186 INFO liquibase.util :: Filtered out:                51
2024-10-02 08:27:22,186 INFO liquibase.util :: -------------------------------
2024-10-02 08:27:22,186 INFO liquibase.util :: Total change sets:          417
2024-10-02 08:27:22,186 INFO liquibase.util :: FILTERED CHANGE SETS SUMMARY
2024-10-02 08:27:22,186 INFO liquibase.util :: DBMS mismatch:               51
2024-10-02 08:27:22,189 INFO liquibase.util :: Update summary generated
2024-10-02 08:27:22,192 INFO liquibase.command :: Update command completed successfully.
2024-10-02 08:27:22,193 INFO liquibase.lockservice :: Successfully released change log lock
2024-10-02 08:27:22,193 INFO liquibase.command :: Command execution complete
2024-10-02 08:27:22,194 INFO db.liquibase :: Migration complete in 1.1 s
2024-10-02 08:27:22,194 INFO liquibase.lockservice :: Successfully released change log lock
2024-10-02 08:27:22,197 INFO db.setup :: Database Migrations Current ... âœ…
2024-10-02 08:27:22,198 INFO metabase.util :: Database setup took 2.0 s
```
</details>

NOTE: this behavior is entirely controlled by the change to `resources/log4j2.xml` which includes

```xml
<Logger name=""liquibase"" level=""INFO""/>
```

If a custom logging configuration is used then adding this line will restore the more verbose migration logging.

"
2390447994,issue,closed,completed,java.util.IllegalFormatConversionException Issue on Metabase v0.50.9 ,"Hi all,

I am using [Docker Compose file](https://paste.opensuse.org/pastes/f4e10a3fe9ee) to deploy Metabase v0.50.9 (with Postgres 16.3)  on Swarm Cluster:

```
version: '3.9'

services:
  postgres:
    image: postgres:16.3
    volumes:
      - /mnt/nfs/metabase.yoursite.com/postgres-data:/var/lib/postgresql/data
    networks:
      - metabasenetwork
    deploy:
      placement:
        constraints:
          - node.hostname == vm-manager01
      labels:
        - traefik.enable=false
      restart_policy:
        condition: any
    environment:
      POSTGRES_USER_FILE: /run/secrets/postgres_user_metabase
      POSTGRES_DB_FILE: /run/secrets/postgres_db_metabase
      POSTGRES_PASSWORD_FILE: /run/secrets/postgres_user_password_metabase
    secrets:
       - postgres_user_metabase
       - postgres_db_metabase
       - postgres_user_password_metabase

  metabase:
    depends_on:
      - postgres
    image: metabase/metabase:v0.50.9
    volumes:
      - /dev/urandom:/dev/random:ro
      - /mnt/nfs/metabase.yoursite.com/metabase-data:/metabase-data
      - /mnt/nfs/metabase.yoursite.com/metabase-plugins:/plugins
    networks:
      metabasenetwork:
        aliases:
          - metabase.yoursite.com
      proxy:
        aliases:
          - metabase.yoursite.com
    deploy:
      replicas: 1
      placement:
        constraints: [node.hostname == vm-manager01]
      restart_policy:
        condition: any
      labels:
          - ""traefik.enable=true""
          - ""traefik.docker.network=proxy""
          - ""traefik.http.routers.metabase-secure.entrypoints=websecure""
          - ""traefik.http.routers.metabase.entrypoints=web""
          - ""traefik.http.routers.metabase-secure.rule=Host(`metabase.yoursite.com`)""
          - ""traefik.http.routers.metabase.rule=Host(`metabase.yoursite.com`)""
          - ""traefik.http.routers.metabase-secure.service=metabase-service""
          - ""traefik.http.routers.metabase-secure.tls.certResolver=letsencrypt""
          - ""traefik.http.services.metabase-service.loadbalancer.server.port=3000""
    healthcheck:
      test: curl --fail -I http://metabase:3000/api/health || exit 1
      interval: 15s
      timeout: 5s
      retries: 5
    environment:
      MB_DB_FILE: /metabase-data/metabase.db
      MB_DB_TYPE: postgres
      MB_DB_DBNAME_FILE: /run/secrets/postgres_db_metabase
      MB_DB_PORT: 5432
      MB_DB_USER_FILE: /run/secrets/postgres_user_metabase
      MB_DB_PASS_FILE: /run/secrets/postgres_user_password_metabase
      MB_DB_HOST: postgres
      JAVA_TIMEZONE: Asia/Jakarta
    secrets:
       - postgres_user_metabase
       - postgres_db_metabase
       - postgres_user_password_metabase
    extra_hosts:
       - ""host.docker.internal:host-gateway""

secrets:
   postgres_user_metabase:
     external: true
   postgres_db_metabase:
     external: true
   postgres_user_password_metabase:
     external: true

networks:
  metabasenetwork:
  proxy:
    external: true
```

The log so far is:

```
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:53:40,703 INFO metabase.util :: Maximum memory available to JVM: 11.8 GB
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:53:49,738 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:08,842 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:08,890 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:08,921 INFO metabase.util :: Load driver :sql-jdbc took 493.1 ms
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:08,925 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:09,759 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:09,899 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,525 INFO metabase.core :: 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Metabase v0.50.9 (720e549) 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Copyright Â© 2024 Metabase, Inc. 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Metabase Enterprise Edition extensions are NOT PRESENT.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,544 INFO metabase.core :: Starting Metabase in STANDALONE mode
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,637 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  {:port 3000, :host ""0.0.0.0""}
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,733 INFO metabase.core :: Starting Metabase version v0.50.9 (720e549) ...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,744 INFO metabase.core :: System info:
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  {""file.encoding"" ""UTF-8"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.runtime.version"" ""11.0.23+9"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.vendor"" ""Eclipse Adoptium"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.vendor.url"" ""https://adoptium.net/"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.version"" ""11.0.23"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""java.vm.version"" ""11.0.23+9"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""os.name"" ""Linux"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""os.version"" ""5.15.0-113-generic"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""user.language"" ""en"",
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |  ""user.timezone"" ""Asia/Jakarta""}
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:16,748 INFO metabase.plugins :: Loading plugins in /plugins...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,105 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,107 INFO plugins.classloader :: Added URL file:/plugins/vertica-jdbc-8.0.1-0.jar to classpath
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,222 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,224 INFO driver.impl :: Registered driver :druid  ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,273 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,274 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,484 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? true
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,485 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,486 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,523 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,524 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,552 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,553 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,554 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,555 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,606 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,607 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,716 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,718 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,728 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,729 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,752 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,753 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,754 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,781 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,782 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,791 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,792 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,822 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,826 INFO driver.impl :: Registered driver :mongo  ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,840 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,842 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,903 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:18,910 INFO db.setup :: Verifying postgres Database Connection ...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:19,983 INFO db.setup :: Successfully verified PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) application database connection. âœ…
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:19,984 INFO db.setup :: Checking if a database downgrade is required...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:22,271 INFO db.setup :: Running Database Migrations...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:22,273 INFO db.setup :: Setting up Liquibase...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:22,970 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:23,007 INFO db.liquibase :: No migration lock found.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:23,008 INFO db.liquibase :: Migration lock acquired.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:23,039 INFO db.setup :: Liquibase is ready.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:23,040 INFO db.liquibase :: Checking if Database has unrun migrations...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:24,837 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:24,854 INFO db.liquibase :: No migration lock found.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:24,854 INFO db.liquibase :: Migration lock acquired.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:25,524 INFO db.liquibase :: Running 336 migrations ...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,771 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,803 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,803 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,806 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,810 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,811 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId '0f50dc1c8c9c1720083271774'
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   NOT STARTED.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   Currently in standby mode.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   Number of jobs executed: 0
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    |   Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,812 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,812 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,862 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_0f50dc1c8c9c1720083271774 started.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,908 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_0f50dc1c8c9c1720083271774 shutting down.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,909 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_0f50dc1c8c9c1720083271774 paused.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:31,933 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_0f50dc1c8c9c1720083271774 shutdown complete.
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:36,711 INFO db.custom-migrations :: No forward migration for DowngradeDashboardTab
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,081 INFO metabase.core :: Metabase Shutting Down ...
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,084 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Exception in thread ""Thread-9"" java.util.IllegalFormatConversionException: f != java.lang.Long
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,122 WARN db.liquibase :: (#object[liquibase.Liquibase 0x2b7e6614 liquibase.Liquibase@2b7e6614])
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.failConversion(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.printFloat(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter$FormatSpecifier.print(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.util.Formatter.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.lang.String.format(Unknown Source)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.core$format.invokeStatic(core.clj:5770)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.core$format.doInvoke(core.clj:5764)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.lang.RestFn.invoke(RestFn.java:423)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.liquibase$wait_for_all_locks.invokeStatic(liquibase.clj:258)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.liquibase$wait_for_all_locks.invoke(liquibase.clj:251)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.setup$release_migration_locks_BANG_.invokeStatic(setup.clj:175)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db.setup$release_migration_locks_BANG_.invoke(setup.clj:170)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db$release_migration_locks_BANG_.invokeStatic(db.clj:91)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.db$release_migration_locks_BANG_.invoke(db.clj:86)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.core$destroy_BANG_.invokeStatic(core.clj:90)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at metabase.core$destroy_BANG_.invoke(core.clj:81)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at clojure.lang.AFn.run(AFn.java:22)
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 	at java.base/java.lang.Thread.run(Unknown Source)
metabase-instance_metabase.1.fi0r9lju9jlo@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
```

The complete log message is [here](https://paste.opensuse.org/pastes/0b3336f13dbb).

What do you suggest?",andidotsugandi,2024-07-04 09:51:12+00:00,['dpsutton'],2024-07-11 13:10:50+00:00,2024-07-11 13:10:49+00:00,https://github.com/metabase/metabase/issues/45124,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2208808541, 'issue_id': 2390447994, 'author': 'andidotsugandi', 'body': 'Trying with older version like `v0.50.8`, but  the issue still persists.\r\n\r\nPlease help, and suggestions.\r\n\r\nThank you in advance.', 'created_at': datetime.datetime(2024, 7, 4, 12, 9, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217908184, 'issue_id': 2390447994, 'author': 'dpsutton', 'body': 'Hi @andidotsugandi \r\n\r\nI think there are two issues.\r\n1. Your metabase instance is shutting down\r\n2. While shutting down, it\'s hitting an error clearing locks.\r\n\r\nI\'ll tackle them in reverse order\r\n\r\n#### 2. while shutting down it\'s hitting an error clearing locks\r\n\r\nI think this is a red herring. It\'s bad, and it could leave locks in place. But this is happening when already shutting down. So it\'s not even a symptom of your issue. I\'ve made a separate issue for us to fix this.\r\n\r\n#### 1. Your metabase instance is shutting down\r\n\r\nNote the order of the logs:\r\n\r\n```\r\nmetabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,084 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\nmetabase-instance_metabase.1.18gh6zvf3fe8@vm    | Exception in thread ""Thread-9"" java.util.IllegalFormatConversionException: f != java.lang.Long\r\n```\r\n\r\nWe start shutting down and then hit the error. Your instance shuts down. From your logs it starts at `2024-07-04 15:53:40` and then begins shutting down at `2024-07-04 15:54:39` so about 1 minute. My suggestion is to make your health check longer\r\n\r\n```\r\n    healthcheck:\r\n      test: curl --fail -I http://metabase:3000/api/health || exit 1\r\n      interval: 15s\r\n      timeout: 5s\r\n      retries: 5\r\n```\r\n\r\nMy suspicion is that you are deciding your instance is unhealthy and tearing it down before it reports it is healthy. Can you try that and let us know?', 'created_at': datetime.datetime(2024, 7, 9, 14, 38, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219482846, 'issue_id': 2390447994, 'author': 'paoliniluis', 'body': 'Please post the machines specs in the cluster', 'created_at': datetime.datetime(2024, 7, 10, 3, 40, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219583651, 'issue_id': 2390447994, 'author': 'andidotsugandi', 'body': 'Hi @dpsutton ,\r\n\r\nThank you for the response and suggestions.\r\n\r\nIt finally resolves by using:\r\n\r\n\r\n    healthcheck:\r\n      test: curl --fail -I http://localhost:3000/api/health || exit 1\r\n      interval: 30s\r\n      timeout: 15s\r\n      retries: 5\r\n\r\nI did choose to use `http://metabase` (in the first try) instead of `http://localhost`  because of the eror message: `ERROR middleware.log :: HEAD /api/health`.\r\n\r\n    metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:36,051 ERROR middleware.log :: HEAD /api/health 503 10.7 ms (0 DB calls) {:metabase-user-id nil}\r\n\r\nI then just feel that it may be one of the causes of the issue so it is back to using : `http://localhost` like it is said in [the offical guide](https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-docker#example-docker-compose-yaml-file).\r\n\r\nThe log message on booting up the Metabase instance:\r\n\r\n```\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:02:39,775 INFO metabase.util :: Maximum memory available to JVM: 11.8 GB\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:02:49,693 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:10,944 INFO driver.impl :: Registered abstract driver :sql  ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:10,989 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,042 INFO metabase.util :: Load driver :sql-jdbc took 233.4 ms\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,044 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,934 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:12,053 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,361 INFO metabase.core :: \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Metabase v0.50.9 (720e549) \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Copyright Â© 2024 Metabase, Inc. \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Metabase Enterprise Edition extensions are NOT PRESENT.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,398 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,585 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  {:port 3000, :host ""0.0.0.0""}\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,823 INFO metabase.core :: Starting Metabase version v0.50.9 (720e549) ...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,839 INFO metabase.core :: System info:\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  {""file.encoding"" ""UTF-8"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.runtime.version"" ""11.0.23+9"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vendor"" ""Eclipse Adoptium"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vendor.url"" ""https://adoptium.net/"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.version"" ""11.0.23"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vm.version"" ""11.0.23+9"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""os.name"" ""Linux"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""os.version"" ""5.15.0-113-generic"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""user.language"" ""en"",\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""user.timezone"" ""Asia/Jakarta""}\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,844 INFO metabase.plugins :: Loading plugins in /plugins...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,796 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,799 INFO plugins.classloader :: Added URL file:/plugins/vertica-jdbc-8.0.1-0.jar to classpath\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,899 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,901 INFO driver.impl :: Registered driver :druid  ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,944 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,945 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,969 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? true\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,970 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,971 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,985 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,986 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,003 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,004 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,005 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,006 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,052 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,053 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,132 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,132 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,143 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,144 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,164 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,165 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,165 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,190 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,190 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,198 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,199 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,212 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,213 INFO driver.impl :: Registered driver :mongo  ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,218 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,219 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,245 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,249 INFO db.setup :: Verifying postgres Database Connection ...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:24,427 INFO db.setup :: Successfully verified PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) application database connection. âœ…\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:24,429 INFO db.setup :: Checking if a database downgrade is required...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:27,499 INFO db.setup :: Running Database Migrations...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:27,503 INFO db.setup :: Setting up Liquibase...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,514 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,577 INFO db.liquibase :: No migration lock found.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,578 INFO db.liquibase :: Migration lock acquired.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,626 INFO db.setup :: Liquibase is ready.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,627 INFO db.liquibase :: Checking if Database has unrun migrations...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,830 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,854 INFO db.liquibase :: No migration lock found.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,855 INFO db.liquibase :: Migration lock acquired.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:31,699 INFO db.liquibase :: Running 336 migrations ...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:36,051 ERROR middleware.log :: HEAD /api/health 503 10.7 ms (0 DB calls) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,542 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,584 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,586 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,593 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,600 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,602 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'5842fb6367cd1720584221550\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   NOT STARTED.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Currently in standby mode.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Number of jobs executed: 0\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,603 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,604 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,675 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 started.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,704 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 shutting down.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,705 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 paused.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,711 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 shutdown complete.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:45,314 INFO db.custom-migrations :: No forward migration for DowngradeDashboardTab\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,035 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,045 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,046 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,046 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'5842fb6367cd1720584233037\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   NOT STARTED.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Currently in standby mode.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Number of jobs executed: 0\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,048 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,062 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 started.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,087 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 shutting down.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,088 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 paused.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,094 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 shutdown complete.\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,111 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,125 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | UPDATE SUMMARY\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Run:                        336\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Previously run:               0\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Filtered out:                51\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | -------------------------------\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Total change sets:          387\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | FILTERED CHANGE SETS SUMMARY\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | Ignored:                      1\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | DBMS mismatch:               50\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,444 INFO db.liquibase :: Migration complete in 22.7 s\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,465 INFO db.setup :: Database Migrations Current ... âœ…\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,467 INFO metabase.util :: Database setup took 31.2 s\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,587 INFO metabase.core :: Looks like this is a new installation ... preparing setup wizard\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,732 INFO metabase.core :: Please use the following URL to setup your Metabase installation:\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | http://0.0.0.0:3000/setup/\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | \r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,797 INFO metabase.events :: Loading events namespace: metabase.events.audit-log ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,941 INFO metabase.events :: Loading events namespace: metabase.events.driver-notifications ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,975 INFO metabase.events :: Loading events namespace: metabase.events.last-login ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,994 INFO metabase.events :: Loading events namespace: metabase.events.persisted-info ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,048 INFO metabase.events :: Loading events namespace: metabase.events.recent-views ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,095 INFO metabase.events :: Loading events namespace: metabase.events.revision ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,178 INFO metabase.events :: Loading events namespace: metabase.events.schema ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,179 INFO metabase.events :: Loading events namespace: metabase.events.sync-database ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,215 INFO metabase.events :: Loading events namespace: metabase.events.view-log ðŸ‘‚\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,532 INFO metabase.sample-data :: Loading sample database\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,122 INFO util.files :: Extract file /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,537 INFO driver.impl :: Initializing driver :sql...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,538 INFO driver.impl :: Initializing driver :sql-jdbc...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,538 INFO driver.impl :: Initializing driver :h2...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,590 INFO driver.impl :: Initializing driver :postgres...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,798 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,799 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,880 INFO sync.util :: STARTING: Sync h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,885 INFO sync.util :: STARTING: Sync metadata for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,029 INFO sync.util :: STARTING: step \'\'sync-dbms-version\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,125 INFO sync.util :: FINISHED: step \'\'sync-dbms-version\'\' for h2 Database 1 \'\'Sample Database\'\' (95.1 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,126 INFO sync.util :: STARTING: step \'\'sync-timezone\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,159 INFO sync-metadata.sync-timezone :: :h2 database 1 default timezone is ""Asia/Jakarta""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,235 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,236 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,261 INFO sync.util :: FINISHED: step \'\'sync-timezone\'\' for h2 Database 1 \'\'Sample Database\'\' (134.7 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,263 INFO sync.util :: STARTING: step \'\'sync-tables\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,385 INFO sync-metadata.tables :: Updating table metadata for Table 8 \'\'PUBLIC.PRODUCTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,387 INFO sync-metadata.tables :: Updating table metadata for Table 3 \'\'PUBLIC.PEOPLE\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,388 INFO sync-metadata.tables :: Updating table metadata for Table 7 \'\'PUBLIC.INVOICES\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,389 INFO sync-metadata.tables :: Updating table metadata for Table 5 \'\'PUBLIC.ORDERS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,390 INFO sync-metadata.tables :: Updating table metadata for Table 4 \'\'PUBLIC.REVIEWS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,392 INFO sync-metadata.tables :: Updating table metadata for Table 2 \'\'PUBLIC.FEEDBACK\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,395 INFO sync-metadata.tables :: Updating table metadata for Table 1 \'\'PUBLIC.ANALYTIC_EVENTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,396 INFO sync-metadata.tables :: Updating table metadata for Table 6 \'\'PUBLIC.ACCOUNTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,451 INFO sync.util :: FINISHED: step \'\'sync-tables\'\' for h2 Database 1 \'\'Sample Database\'\' (187.5 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,452 INFO sync.util :: STARTING: step \'\'sync-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,706 INFO sync.util :: FINISHED: step \'\'sync-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (1.3 s)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,709 INFO sync.util :: STARTING: step \'\'sync-fks\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,941 INFO sync.util :: FINISHED: step \'\'sync-fks\'\' for h2 Database 1 \'\'Sample Database\'\' (231.2 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,941 INFO sync.util :: STARTING: step \'\'sync-indexes\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:01,400 INFO sync.util :: FINISHED: step \'\'sync-indexes\'\' for h2 Database 1 \'\'Sample Database\'\' (1.5 s)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:01,403 INFO sync.util :: STARTING: step \'\'sync-metabase-metadata\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,901 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,902 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,964 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,966 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,029 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,034 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,663 INFO sync.util :: FINISHED: step \'\'sync-metabase-metadata\'\' for h2 Database 1 \'\'Sample Database\'\' (4.3 s)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,665 INFO sync.util :: STARTING: step \'\'sync-table-privileges\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,710 INFO sync.util :: FINISHED: step \'\'sync-table-privileges\'\' for h2 Database 1 \'\'Sample Database\'\' (42.8 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,743 INFO sync.util :: FINISHED: Sync metadata for h2 Database 1 \'\'Sample Database\'\' (8.9 s)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,769 INFO sync.util :: STARTING: Analyze data for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,819 INFO sync.util :: STARTING: step \'\'fingerprint-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,976 INFO sync.analyze :: fingerprint-fields Analyzed [*****Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¢   12% Table 2 \'\'PUBLIC.FEEDBACK\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,020 INFO sync.analyze :: fingerprint-fields Analyzed [***********Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜’   24% Table 3 \'\'PUBLIC.PEOPLE\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,079 INFO sync.util :: FINISHED: step \'\'fingerprint-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (258.9 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,080 INFO sync.util :: STARTING: step \'\'classify-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,137 INFO sync.analyze :: classify-fields Analyzed [******************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜•   36% Table 6 \'\'PUBLIC.ACCOUNTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,169 INFO sync.analyze :: classify-fields Analyzed [***********************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¬   48% Table 7 \'\'PUBLIC.INVOICES\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,200 INFO sync.analyze :: classify-fields Analyzed [******************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Œ   60% Table 8 \'\'PUBLIC.PRODUCTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,238 INFO sync.util :: FINISHED: step \'\'classify-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (157.2 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,239 INFO sync.util :: STARTING: step \'\'classify-tables\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,277 INFO sync.analyze :: classify-tables Analyzed [************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜‹   72% Table 1 \'\'PUBLIC.ANALYTIC_EVENTS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,301 INFO sync.analyze :: classify-tables Analyzed [*****************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Š   84% Table 5 \'\'PUBLIC.ORDERS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,303 INFO sync.analyze :: classify-tables Analyzed [***********************************************Â·Â·Â·] ðŸ˜Ž   96% Table 4 \'\'PUBLIC.REVIEWS\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,330 INFO sync.util :: FINISHED: step \'\'classify-tables\'\' for h2 Database 1 \'\'Sample Database\'\' (89.8 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,380 INFO sync.util :: FINISHED: Analyze data for h2 Database 1 \'\'Sample Database\'\' (609.8 ms)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,387 INFO sync.util :: STARTING: Cache field values in h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,411 ERROR middleware.log :: HEAD /api/health 503 4.5 ms (0 DB calls) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,439 INFO sync.util :: STARTING: step \'\'delete-expired-advanced-field-values\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,100 INFO sync.util :: FINISHED: step \'\'delete-expired-advanced-field-values\'\' for h2 Database 1 \'\'Sample Database\'\' (2.7 s)\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,101 INFO sync.util :: STARTING: step \'\'update-field-values\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,319 INFO metabase.core :: Metabase Shutting Down ...\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,326 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\nmetabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,358 INFO metabase.core :: Metabase Shutdown COMPLETE\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:19,006 INFO metabase.util :: Maximum memory available to JVM: 11.8 GB\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:28,865 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,844 INFO driver.impl :: Registered abstract driver :sql  ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,898 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,930 INFO metabase.util :: Load driver :sql-jdbc took 217.2 ms\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,931 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:51,808 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:51,954 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:59,804 INFO metabase.core :: \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Metabase v0.50.9 (720e549) \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Copyright Â© 2024 Metabase, Inc. \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Metabase Enterprise Edition extensions are NOT PRESENT.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:59,840 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,036 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  {:port 3000, :host ""0.0.0.0""}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,211 INFO metabase.core :: Starting Metabase version v0.50.9 (720e549) ...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,230 INFO metabase.core :: System info:\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  {""file.encoding"" ""UTF-8"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.runtime.version"" ""11.0.23+9"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vendor"" ""Eclipse Adoptium"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vendor.url"" ""https://adoptium.net/"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.version"" ""11.0.23"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vm.version"" ""11.0.23+9"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""os.name"" ""Linux"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""os.version"" ""5.15.0-113-generic"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""user.language"" ""en"",\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""user.timezone"" ""Asia/Jakarta""}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,240 INFO metabase.plugins :: Loading plugins in /plugins...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,308 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,316 INFO plugins.classloader :: Added URL file:/plugins/vertica-jdbc-8.0.1-0.jar to classpath\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,631 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,634 INFO driver.impl :: Registered driver :druid  ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,731 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,757 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,815 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? true\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,817 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,818 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,850 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,852 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,912 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,913 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,915 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,916 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,971 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,972 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,125 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,127 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,143 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,145 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,187 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,189 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,190 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,255 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,273 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,283 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,284 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,311 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,312 INFO driver.impl :: Registered driver :mongo  ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,320 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,321 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,359 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,370 INFO db.setup :: Verifying postgres Database Connection ...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:06,934 INFO db.setup :: Successfully verified PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) application database connection. âœ…\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:06,935 INFO db.setup :: Checking if a database downgrade is required...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:10,040 INFO db.setup :: Running Database Migrations...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:10,044 INFO db.setup :: Setting up Liquibase...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,427 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,582 INFO db.liquibase :: No migration lock found.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,583 INFO db.liquibase :: Migration lock acquired.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,696 INFO db.setup :: Liquibase is ready.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,697 INFO db.liquibase :: Checking if Database has unrun migrations...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,374 INFO db.liquibase :: No unrun migrations found.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,378 INFO db.setup :: Database Migrations Current ... âœ…\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,391 INFO metabase.util :: Database setup took 9.0 s\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,304 INFO metabase.core :: Looks like this is a new installation ... preparing setup wizard\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,401 INFO metabase.core :: Please use the following URL to setup your Metabase installation:\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | http://0.0.0.0:3000/setup/\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,567 INFO metabase.events :: Loading events namespace: metabase.events.audit-log ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,722 INFO metabase.events :: Loading events namespace: metabase.events.driver-notifications ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,762 INFO metabase.events :: Loading events namespace: metabase.events.last-login ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,795 INFO metabase.events :: Loading events namespace: metabase.events.persisted-info ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,872 INFO metabase.events :: Loading events namespace: metabase.events.recent-views ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,943 INFO metabase.events :: Loading events namespace: metabase.events.revision ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,075 INFO metabase.events :: Loading events namespace: metabase.events.schema ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,076 INFO metabase.events :: Loading events namespace: metabase.events.sync-database ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,104 INFO metabase.events :: Loading events namespace: metabase.events.view-log ðŸ‘‚\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,272 INFO metabase.sample-data :: Loading sample database\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,584 INFO util.files :: Extract file /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,864 INFO driver.impl :: Initializing driver :sql...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,872 INFO driver.impl :: Initializing driver :sql-jdbc...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,876 INFO driver.impl :: Initializing driver :h2...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,927 INFO driver.impl :: Initializing driver :postgres...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,142 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,154 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,237 INFO sync.util :: STARTING: Sync h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,240 INFO sync.util :: STARTING: Sync metadata for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,096 INFO sync.util :: STARTING: step \'\'sync-dbms-version\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,407 INFO sync.util :: FINISHED: step \'\'sync-dbms-version\'\' for h2 Database 1 \'\'Sample Database\'\' (310.3 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,409 INFO sync.util :: STARTING: step \'\'sync-timezone\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,462 INFO sync-metadata.sync-timezone :: :h2 database 1 default timezone is ""Asia/Jakarta""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,511 INFO sync.util :: FINISHED: step \'\'sync-timezone\'\' for h2 Database 1 \'\'Sample Database\'\' (101.3 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,513 INFO sync.util :: STARTING: step \'\'sync-tables\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,689 INFO sync-metadata.tables :: Updating table metadata for Table 8 \'\'PUBLIC.PRODUCTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,697 INFO sync-metadata.tables :: Updating table metadata for Table 3 \'\'PUBLIC.PEOPLE\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,699 INFO sync-metadata.tables :: Updating table metadata for Table 7 \'\'PUBLIC.INVOICES\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,700 INFO sync-metadata.tables :: Updating table metadata for Table 5 \'\'PUBLIC.ORDERS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,701 INFO sync-metadata.tables :: Updating table metadata for Table 4 \'\'PUBLIC.REVIEWS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,702 INFO sync-metadata.tables :: Updating table metadata for Table 2 \'\'PUBLIC.FEEDBACK\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,703 INFO sync-metadata.tables :: Updating table metadata for Table 1 \'\'PUBLIC.ANALYTIC_EVENTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,704 INFO sync-metadata.tables :: Updating table metadata for Table 6 \'\'PUBLIC.ACCOUNTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,734 INFO sync.util :: FINISHED: step \'\'sync-tables\'\' for h2 Database 1 \'\'Sample Database\'\' (220.5 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,735 INFO sync.util :: STARTING: step \'\'sync-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,032 INFO sync.util :: FINISHED: step \'\'sync-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (1.3 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,035 INFO sync.util :: STARTING: step \'\'sync-fks\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,278 INFO sync.util :: FINISHED: step \'\'sync-fks\'\' for h2 Database 1 \'\'Sample Database\'\' (243.3 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,279 INFO sync.util :: STARTING: step \'\'sync-indexes\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:21,529 INFO sync.util :: FINISHED: step \'\'sync-indexes\'\' for h2 Database 1 \'\'Sample Database\'\' (1.2 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:21,530 INFO sync.util :: STARTING: step \'\'sync-metabase-metadata\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,579 ERROR middleware.log :: HEAD /api/health 503 10.1 ms (0 DB calls) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,681 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,683 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,754 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,756 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,829 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,831 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,425 INFO sync.util :: FINISHED: step \'\'sync-metabase-metadata\'\' for h2 Database 1 \'\'Sample Database\'\' (2.9 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,426 INFO sync.util :: STARTING: step \'\'sync-table-privileges\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,457 INFO sync.util :: FINISHED: step \'\'sync-table-privileges\'\' for h2 Database 1 \'\'Sample Database\'\' (30.4 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,472 INFO sync.util :: FINISHED: Sync metadata for h2 Database 1 \'\'Sample Database\'\' (8.2 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,478 INFO sync.util :: STARTING: Analyze data for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,516 INFO sync.util :: STARTING: step \'\'fingerprint-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,641 INFO sync.analyze :: fingerprint-fields Analyzed [*****Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¢   12% Table 2 \'\'PUBLIC.FEEDBACK\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,671 INFO sync.analyze :: fingerprint-fields Analyzed [***********Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜’   24% Table 3 \'\'PUBLIC.PEOPLE\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,721 INFO sync.util :: FINISHED: step \'\'fingerprint-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (204.3 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,722 INFO sync.util :: STARTING: step \'\'classify-fields\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,772 INFO sync.analyze :: classify-fields Analyzed [******************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜•   36% Table 6 \'\'PUBLIC.ACCOUNTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,797 INFO sync.analyze :: classify-fields Analyzed [***********************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¬   48% Table 7 \'\'PUBLIC.INVOICES\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,819 INFO sync.analyze :: classify-fields Analyzed [******************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Œ   60% Table 8 \'\'PUBLIC.PRODUCTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,847 INFO sync.util :: FINISHED: step \'\'classify-fields\'\' for h2 Database 1 \'\'Sample Database\'\' (123.9 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,848 INFO sync.util :: STARTING: step \'\'classify-tables\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,869 INFO sync.analyze :: classify-tables Analyzed [************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜‹   72% Table 1 \'\'PUBLIC.ANALYTIC_EVENTS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,884 INFO sync.analyze :: classify-tables Analyzed [*****************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Š   84% Table 5 \'\'PUBLIC.ORDERS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,886 INFO sync.analyze :: classify-tables Analyzed [***********************************************Â·Â·Â·] ðŸ˜Ž   96% Table 4 \'\'PUBLIC.REVIEWS\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,906 INFO sync.util :: FINISHED: step \'\'classify-tables\'\' for h2 Database 1 \'\'Sample Database\'\' (57.7 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,934 INFO sync.util :: FINISHED: Analyze data for h2 Database 1 \'\'Sample Database\'\' (455.5 ms)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,940 INFO sync.util :: STARTING: Cache field values in h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,977 INFO sync.util :: STARTING: step \'\'delete-expired-advanced-field-values\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:26,354 INFO sync.util :: FINISHED: step \'\'delete-expired-advanced-field-values\'\' for h2 Database 1 \'\'Sample Database\'\' (1.4 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:26,355 INFO sync.util :: STARTING: step \'\'update-field-values\'\' for h2 Database 1 \'\'Sample Database\'\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,761 INFO sync.util :: FINISHED: step \'\'update-field-values\'\' for h2 Database 1 \'\'Sample Database\'\' (6.4 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,790 INFO sync.util :: FINISHED: Cache field values in h2 Database 1 \'\'Sample Database\'\' (7.8 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,794 INFO sync.util :: FINISHED: Sync h2 Database 1 \'\'Sample Database\'\' (16.6 s)\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,888 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,930 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,931 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,934 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,939 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,941 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'d198aefc2e401720584392898\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   NOT STARTED.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Currently in standby mode.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Number of jobs executed: 0\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,942 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,942 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,369 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_d198aefc2e401720584392898 paused.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,370 INFO metabase.task :: Task scheduler initialized into standby mode.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,485 INFO metabase.task :: Initializing task Cache ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,487 INFO metabase.task :: Initializing task SyncDatabases ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,584 INFO task.sync-databases :: Updated default schedules for 0 databases\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,585 INFO metabase.task :: Initializing task PersistRefresh ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,681 INFO metabase.task :: Initializing task CheckForNewVersions ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,750 INFO metabase.task :: Initializing task PersistPrune ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,760 INFO metabase.task :: Initializing task SendAnonymousUsageStats ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,779 INFO metabase.task :: Initializing task ModelIndexValues ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,787 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,814 INFO metabase.task :: Initializing task TruncateAuditTables ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,837 INFO metabase.task :: Initializing task SendPulses ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,870 INFO metabase.task :: Initializing task SendFollowUpEmails ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,892 INFO metabase.task :: Initializing task SendCreatorSentimentEmails ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,908 INFO metabase.task :: Initializing task SendLegacyNoSelfServiceEmail ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,921 INFO metabase.task :: Initializing task TaskHistoryCleanup ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,990 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail ðŸ“†\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,039 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,040 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""5842fb6367cd1720584221550""\'s failed in-progress jobs.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,048 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""5842fb6367cd1720584233037""\'s failed in-progress jobs.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,055 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_d198aefc2e401720584392898 started.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,056 INFO metabase.task :: Task scheduler started\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,059 INFO metabase.core :: Metabase Initialization COMPLETE in 1.7 mins\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,214 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:53,924 DEBUG middleware.log :: HEAD /api/health 200 1.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (1 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:24,148 DEBUG middleware.log :: HEAD /api/health 200 1.4 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (1 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:29,098 INFO middleware.misc :: Setting Metabase site URL to metabase.yoursite.com\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:30,175 INFO i18n.impl :: Reading available locales from locales.clj...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:30,654 INFO util.fonts :: Reading available fonts from /frontend_client/app/fonts\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:34,503 DEBUG middleware.log :: GET /api/user/current 401 7.3 ms (0 DB calls) {:metabase-user-id nil} \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | ""Unauthenticated""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:34,623 DEBUG middleware.log :: GET /api/session/properties 200 118.8 ms (2 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:54,340 DEBUG middleware.log :: HEAD /api/health 200 1.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:08:24,550 DEBUG middleware.log :: HEAD /api/health 200 975.4 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:08:54,790 DEBUG middleware.log :: HEAD /api/health 200 1.7 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (8 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:08,472 DEBUG middleware.log :: GET /api/user/current 401 1.5 ms (0 DB calls) {:metabase-user-id nil} \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | ""Unauthenticated""\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | \r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:08,544 DEBUG middleware.log :: GET /api/session/properties 200 61.5 ms (2 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (59 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:25,056 DEBUG middleware.log :: HEAD /api/health 200 1.0 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (59 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:55,229 DEBUG middleware.log :: HEAD /api/health 200 934.6 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (4 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:09,168 DEBUG middleware.log :: POST /api/util/password_check 200 109.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (6 idle, 0 queued) (52 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:09,185 DEBUG middleware.log :: POST /api/util/password_check 200 118.2 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (6 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,303 DEBUG middleware.log :: POST /api/util/password_check 200 1.1 s (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (6 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,388 DEBUG middleware.log :: POST /api/util/password_check 200 54.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,411 DEBUG middleware.log :: POST /api/util/password_check 200 129.0 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,281 INFO models.user :: Setting User 1\'s last_acknowledged_version to v0.50.9, the current version\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,420 INFO models.user :: Adding User 1 to All Users permissions group...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,420 INFO models.user :: Adding User 1 to All Users permissions group...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,990 DEBUG middleware.log :: POST /api/setup 200 1.2 s (46 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:16,672 DEBUG middleware.log :: GET /api/setting 200 322.6 ms (13 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:16,678 DEBUG middleware.log :: GET /api/session/properties 200 251.9 ms (15 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:25,441 DEBUG middleware.log :: HEAD /api/health 200 969.9 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (57 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:55,737 DEBUG middleware.log :: HEAD /api/health 200 1.1 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:11:25,949 DEBUG middleware.log :: HEAD /api/health 200 1.2 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:11:56,152 DEBUG middleware.log :: HEAD /api/health 200 881.5 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (51 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:26,335 DEBUG middleware.log :: HEAD /api/health 200 974.7 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (51 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:31,032 INFO driver.impl :: Initializing driver :mysql...\r\nmetabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:31,083 INFO driver.mysql :: You may need to add \'trustServerCertificate=true\' to the additional connection options to connect with SSL.\r\n```\r\n\r\nNow the Metabase v0.50.9 instance is finally running successfully on our Docker Swarm Cluster, and also succeeds updating the Metabase to v0.50.11.\r\n\r\n@paoliniluis , it is: 16 vCPUs and 48 GB RAM.', 'created_at': datetime.datetime(2024, 7, 10, 5, 20, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222904184, 'issue_id': 2390447994, 'author': 'dpsutton', 'body': ""excellent! We've made a separate issue (and already fixed) the error in shutdown. Glad to know your issue is resolved as well."", 'created_at': datetime.datetime(2024, 7, 11, 13, 10, 49, tzinfo=datetime.timezone.utc)}]","andidotsugandi (Issue Creator) on (2024-07-04 12:09:47 UTC): Trying with older version like `v0.50.8`, but  the issue still persists.

Please help, and suggestions.

Thank you in advance.

dpsutton (Assginee) on (2024-07-09 14:38:03 UTC): Hi @andidotsugandi 

I think there are two issues.
1. Your metabase instance is shutting down
2. While shutting down, it's hitting an error clearing locks.

I'll tackle them in reverse order

#### 2. while shutting down it's hitting an error clearing locks

I think this is a red herring. It's bad, and it could leave locks in place. But this is happening when already shutting down. So it's not even a symptom of your issue. I've made a separate issue for us to fix this.

#### 1. Your metabase instance is shutting down

Note the order of the logs:

```
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | 2024-07-04 15:54:39,084 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
metabase-instance_metabase.1.18gh6zvf3fe8@vm    | Exception in thread ""Thread-9"" java.util.IllegalFormatConversionException: f != java.lang.Long
```

We start shutting down and then hit the error. Your instance shuts down. From your logs it starts at `2024-07-04 15:53:40` and then begins shutting down at `2024-07-04 15:54:39` so about 1 minute. My suggestion is to make your health check longer

```
    healthcheck:
      test: curl --fail -I http://metabase:3000/api/health || exit 1
      interval: 15s
      timeout: 5s
      retries: 5
```

My suspicion is that you are deciding your instance is unhealthy and tearing it down before it reports it is healthy. Can you try that and let us know?

paoliniluis on (2024-07-10 03:40:22 UTC): Please post the machines specs in the cluster

andidotsugandi (Issue Creator) on (2024-07-10 05:20:08 UTC): Hi @dpsutton ,

Thank you for the response and suggestions.

It finally resolves by using:


    healthcheck:
      test: curl --fail -I http://localhost:3000/api/health || exit 1
      interval: 30s
      timeout: 15s
      retries: 5

I did choose to use `http://metabase` (in the first try) instead of `http://localhost`  because of the eror message: `ERROR middleware.log :: HEAD /api/health`.

    metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:36,051 ERROR middleware.log :: HEAD /api/health 503 10.7 ms (0 DB calls) {:metabase-user-id nil}

I then just feel that it may be one of the causes of the issue so it is back to using : `http://localhost` like it is said in [the offical guide](https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-docker#example-docker-compose-yaml-file).

The log message on booting up the Metabase instance:

```
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:02:39,775 INFO metabase.util :: Maximum memory available to JVM: 11.8 GB
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:02:49,693 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ 
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:10,944 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:10,989 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,042 INFO metabase.util :: Load driver :sql-jdbc took 233.4 ms
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,044 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:11,934 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:12,053 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,361 INFO metabase.core :: 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Metabase v0.50.9 (720e549) 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Copyright Â© 2024 Metabase, Inc. 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Metabase Enterprise Edition extensions are NOT PRESENT.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,398 INFO metabase.core :: Starting Metabase in STANDALONE mode
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,585 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  {:port 3000, :host ""0.0.0.0""}
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,823 INFO metabase.core :: Starting Metabase version v0.50.9 (720e549) ...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,839 INFO metabase.core :: System info:
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  {""file.encoding"" ""UTF-8"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.runtime.version"" ""11.0.23+9"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vendor"" ""Eclipse Adoptium"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vendor.url"" ""https://adoptium.net/"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.version"" ""11.0.23"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""java.vm.version"" ""11.0.23+9"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""os.name"" ""Linux"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""os.version"" ""5.15.0-113-generic"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""user.language"" ""en"",
metabase-instance_metabase.1.x2fxjck3y59h@vm    |  ""user.timezone"" ""Asia/Jakarta""}
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:20,844 INFO metabase.plugins :: Loading plugins in /plugins...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,796 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,799 INFO plugins.classloader :: Added URL file:/plugins/vertica-jdbc-8.0.1-0.jar to classpath
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,899 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,901 INFO driver.impl :: Registered driver :druid  ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,944 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,945 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,969 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? true
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,970 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,971 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,985 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:22,986 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,003 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,004 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,005 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,006 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,052 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,053 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,132 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,132 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,143 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,144 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,164 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,165 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,165 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,190 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,190 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,198 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,199 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,212 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,213 INFO driver.impl :: Registered driver :mongo  ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,218 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,219 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,245 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:23,249 INFO db.setup :: Verifying postgres Database Connection ...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:24,427 INFO db.setup :: Successfully verified PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) application database connection. âœ…
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:24,429 INFO db.setup :: Checking if a database downgrade is required...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:27,499 INFO db.setup :: Running Database Migrations...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:27,503 INFO db.setup :: Setting up Liquibase...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,514 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,577 INFO db.liquibase :: No migration lock found.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,578 INFO db.liquibase :: Migration lock acquired.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,626 INFO db.setup :: Liquibase is ready.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:28,627 INFO db.liquibase :: Checking if Database has unrun migrations...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,830 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,854 INFO db.liquibase :: No migration lock found.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:30,855 INFO db.liquibase :: Migration lock acquired.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:31,699 INFO db.liquibase :: Running 336 migrations ...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:36,051 ERROR middleware.log :: HEAD /api/health 503 10.7 ms (0 DB calls) {:metabase-user-id nil}
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,542 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,584 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,586 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,593 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,600 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,602 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId '5842fb6367cd1720584221550'
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   NOT STARTED.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Currently in standby mode.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Number of jobs executed: 0
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,603 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,604 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,675 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 started.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,704 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 shutting down.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,705 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 paused.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:41,711 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584221550 shutdown complete.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:45,314 INFO db.custom-migrations :: No forward migration for DowngradeDashboardTab
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,035 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,045 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,046 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,046 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId '5842fb6367cd1720584233037'
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   NOT STARTED.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Currently in standby mode.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Number of jobs executed: 0
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
metabase-instance_metabase.1.x2fxjck3y59h@vm    |   Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,047 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,048 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,062 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 started.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,087 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 shutting down.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,088 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 paused.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,094 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5842fb6367cd1720584233037 shutdown complete.
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,111 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:53,125 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | UPDATE SUMMARY
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Run:                        336
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Previously run:               0
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Filtered out:                51
metabase-instance_metabase.1.x2fxjck3y59h@vm    | -------------------------------
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Total change sets:          387
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | FILTERED CHANGE SETS SUMMARY
metabase-instance_metabase.1.x2fxjck3y59h@vm    | Ignored:                      1
metabase-instance_metabase.1.x2fxjck3y59h@vm    | DBMS mismatch:               50
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,444 INFO db.liquibase :: Migration complete in 22.7 s
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,465 INFO db.setup :: Database Migrations Current ... âœ…
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,467 INFO metabase.util :: Database setup took 31.2 s
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,587 INFO metabase.core :: Looks like this is a new installation ... preparing setup wizard
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,732 INFO metabase.core :: Please use the following URL to setup your Metabase installation:
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | http://0.0.0.0:3000/setup/
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,797 INFO metabase.events :: Loading events namespace: metabase.events.audit-log ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,941 INFO metabase.events :: Loading events namespace: metabase.events.driver-notifications ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,975 INFO metabase.events :: Loading events namespace: metabase.events.last-login ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:54,994 INFO metabase.events :: Loading events namespace: metabase.events.persisted-info ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,048 INFO metabase.events :: Loading events namespace: metabase.events.recent-views ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,095 INFO metabase.events :: Loading events namespace: metabase.events.revision ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,178 INFO metabase.events :: Loading events namespace: metabase.events.schema ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,179 INFO metabase.events :: Loading events namespace: metabase.events.sync-database ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,215 INFO metabase.events :: Loading events namespace: metabase.events.view-log ðŸ‘‚
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:55,532 INFO metabase.sample-data :: Loading sample database
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,122 INFO util.files :: Extract file /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,537 INFO driver.impl :: Initializing driver :sql...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,538 INFO driver.impl :: Initializing driver :sql-jdbc...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,538 INFO driver.impl :: Initializing driver :h2...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,590 INFO driver.impl :: Initializing driver :postgres...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,798 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,799 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,880 INFO sync.util :: STARTING: Sync h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:56,885 INFO sync.util :: STARTING: Sync metadata for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,029 INFO sync.util :: STARTING: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,125 INFO sync.util :: FINISHED: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database'' (95.1 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,126 INFO sync.util :: STARTING: step ''sync-timezone'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,159 INFO sync-metadata.sync-timezone :: :h2 database 1 default timezone is ""Asia/Jakarta""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,235 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,236 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,261 INFO sync.util :: FINISHED: step ''sync-timezone'' for h2 Database 1 ''Sample Database'' (134.7 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,263 INFO sync.util :: STARTING: step ''sync-tables'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,385 INFO sync-metadata.tables :: Updating table metadata for Table 8 ''PUBLIC.PRODUCTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,387 INFO sync-metadata.tables :: Updating table metadata for Table 3 ''PUBLIC.PEOPLE''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,388 INFO sync-metadata.tables :: Updating table metadata for Table 7 ''PUBLIC.INVOICES''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,389 INFO sync-metadata.tables :: Updating table metadata for Table 5 ''PUBLIC.ORDERS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,390 INFO sync-metadata.tables :: Updating table metadata for Table 4 ''PUBLIC.REVIEWS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,392 INFO sync-metadata.tables :: Updating table metadata for Table 2 ''PUBLIC.FEEDBACK''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,395 INFO sync-metadata.tables :: Updating table metadata for Table 1 ''PUBLIC.ANALYTIC_EVENTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,396 INFO sync-metadata.tables :: Updating table metadata for Table 6 ''PUBLIC.ACCOUNTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,451 INFO sync.util :: FINISHED: step ''sync-tables'' for h2 Database 1 ''Sample Database'' (187.5 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:58,452 INFO sync.util :: STARTING: step ''sync-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,706 INFO sync.util :: FINISHED: step ''sync-fields'' for h2 Database 1 ''Sample Database'' (1.3 s)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,709 INFO sync.util :: STARTING: step ''sync-fks'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,941 INFO sync.util :: FINISHED: step ''sync-fks'' for h2 Database 1 ''Sample Database'' (231.2 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:03:59,941 INFO sync.util :: STARTING: step ''sync-indexes'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:01,400 INFO sync.util :: FINISHED: step ''sync-indexes'' for h2 Database 1 ''Sample Database'' (1.5 s)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:01,403 INFO sync.util :: STARTING: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,901 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,902 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,964 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:04,966 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,029 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,034 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,663 INFO sync.util :: FINISHED: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database'' (4.3 s)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,665 INFO sync.util :: STARTING: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,710 INFO sync.util :: FINISHED: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database'' (42.8 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,743 INFO sync.util :: FINISHED: Sync metadata for h2 Database 1 ''Sample Database'' (8.9 s)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,769 INFO sync.util :: STARTING: Analyze data for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,819 INFO sync.util :: STARTING: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:05,976 INFO sync.analyze :: fingerprint-fields Analyzed [*****Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¢   12% Table 2 ''PUBLIC.FEEDBACK''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,020 INFO sync.analyze :: fingerprint-fields Analyzed [***********Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜’   24% Table 3 ''PUBLIC.PEOPLE''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,079 INFO sync.util :: FINISHED: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database'' (258.9 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,080 INFO sync.util :: STARTING: step ''classify-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,137 INFO sync.analyze :: classify-fields Analyzed [******************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜•   36% Table 6 ''PUBLIC.ACCOUNTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,169 INFO sync.analyze :: classify-fields Analyzed [***********************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¬   48% Table 7 ''PUBLIC.INVOICES''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,200 INFO sync.analyze :: classify-fields Analyzed [******************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Œ   60% Table 8 ''PUBLIC.PRODUCTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,238 INFO sync.util :: FINISHED: step ''classify-fields'' for h2 Database 1 ''Sample Database'' (157.2 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,239 INFO sync.util :: STARTING: step ''classify-tables'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,277 INFO sync.analyze :: classify-tables Analyzed [************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜‹   72% Table 1 ''PUBLIC.ANALYTIC_EVENTS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,301 INFO sync.analyze :: classify-tables Analyzed [*****************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Š   84% Table 5 ''PUBLIC.ORDERS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,303 INFO sync.analyze :: classify-tables Analyzed [***********************************************Â·Â·Â·] ðŸ˜Ž   96% Table 4 ''PUBLIC.REVIEWS''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,330 INFO sync.util :: FINISHED: step ''classify-tables'' for h2 Database 1 ''Sample Database'' (89.8 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,380 INFO sync.util :: FINISHED: Analyze data for h2 Database 1 ''Sample Database'' (609.8 ms)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,387 INFO sync.util :: STARTING: Cache field values in h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,411 ERROR middleware.log :: HEAD /api/health 503 4.5 ms (0 DB calls) {:metabase-user-id nil}
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:06,439 INFO sync.util :: STARTING: step ''delete-expired-advanced-field-values'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,100 INFO sync.util :: FINISHED: step ''delete-expired-advanced-field-values'' for h2 Database 1 ''Sample Database'' (2.7 s)
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,101 INFO sync.util :: STARTING: step ''update-field-values'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,319 INFO metabase.core :: Metabase Shutting Down ...
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,326 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
metabase-instance_metabase.1.x2fxjck3y59h@vm    | 2024-07-10 11:04:09,358 INFO metabase.core :: Metabase Shutdown COMPLETE
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:19,006 INFO metabase.util :: Maximum memory available to JVM: 11.8 GB
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:28,865 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,844 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,898 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,930 INFO metabase.util :: Load driver :sql-jdbc took 217.2 ms
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:50,931 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:51,808 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:51,954 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:59,804 INFO metabase.core :: 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Metabase v0.50.9 (720e549) 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Copyright Â© 2024 Metabase, Inc. 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | Metabase Enterprise Edition extensions are NOT PRESENT.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:05:59,840 INFO metabase.core :: Starting Metabase in STANDALONE mode
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,036 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  {:port 3000, :host ""0.0.0.0""}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,211 INFO metabase.core :: Starting Metabase version v0.50.9 (720e549) ...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,230 INFO metabase.core :: System info:
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  {""file.encoding"" ""UTF-8"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.runtime.version"" ""11.0.23+9"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vendor"" ""Eclipse Adoptium"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vendor.url"" ""https://adoptium.net/"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.version"" ""11.0.23"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""java.vm.version"" ""11.0.23+9"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""os.name"" ""Linux"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""os.version"" ""5.15.0-113-generic"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""user.language"" ""en"",
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |  ""user.timezone"" ""Asia/Jakarta""}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:00,240 INFO metabase.plugins :: Loading plugins in /plugins...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,308 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,316 INFO plugins.classloader :: Added URL file:/plugins/vertica-jdbc-8.0.1-0.jar to classpath
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,631 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,634 INFO driver.impl :: Registered driver :druid  ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,731 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,757 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,815 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? true
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,817 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,818 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,850 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,852 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,912 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,913 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,915 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,916 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,971 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:03,972 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,125 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,127 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,143 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,145 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,187 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,189 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,190 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,255 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,273 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,283 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,284 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,311 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,312 INFO driver.impl :: Registered driver :mongo  ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,320 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,321 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,359 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:04,370 INFO db.setup :: Verifying postgres Database Connection ...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:06,934 INFO db.setup :: Successfully verified PostgreSQL 16.3 (Debian 16.3-1.pgdg120+1) application database connection. âœ…
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:06,935 INFO db.setup :: Checking if a database downgrade is required...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:10,040 INFO db.setup :: Running Database Migrations...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:10,044 INFO db.setup :: Setting up Liquibase...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,427 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,582 INFO db.liquibase :: No migration lock found.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,583 INFO db.liquibase :: Migration lock acquired.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,696 INFO db.setup :: Liquibase is ready.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:11,697 INFO db.liquibase :: Checking if Database has unrun migrations...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,374 INFO db.liquibase :: No unrun migrations found.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,378 INFO db.setup :: Database Migrations Current ... âœ…
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:13,391 INFO metabase.util :: Database setup took 9.0 s
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,304 INFO metabase.core :: Looks like this is a new installation ... preparing setup wizard
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,401 INFO metabase.core :: Please use the following URL to setup your Metabase installation:
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | http://0.0.0.0:3000/setup/
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,567 INFO metabase.events :: Loading events namespace: metabase.events.audit-log ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,722 INFO metabase.events :: Loading events namespace: metabase.events.driver-notifications ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,762 INFO metabase.events :: Loading events namespace: metabase.events.last-login ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,795 INFO metabase.events :: Loading events namespace: metabase.events.persisted-info ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,872 INFO metabase.events :: Loading events namespace: metabase.events.recent-views ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:14,943 INFO metabase.events :: Loading events namespace: metabase.events.revision ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,075 INFO metabase.events :: Loading events namespace: metabase.events.schema ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,076 INFO metabase.events :: Loading events namespace: metabase.events.sync-database ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,104 INFO metabase.events :: Loading events namespace: metabase.events.view-log ðŸ‘‚
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,272 INFO metabase.sample-data :: Loading sample database
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,584 INFO util.files :: Extract file /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,864 INFO driver.impl :: Initializing driver :sql...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,872 INFO driver.impl :: Initializing driver :sql-jdbc...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,876 INFO driver.impl :: Initializing driver :h2...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:15,927 INFO driver.impl :: Initializing driver :postgres...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,142 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,154 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,237 INFO sync.util :: STARTING: Sync h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:16,240 INFO sync.util :: STARTING: Sync metadata for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,096 INFO sync.util :: STARTING: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,407 INFO sync.util :: FINISHED: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database'' (310.3 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,409 INFO sync.util :: STARTING: step ''sync-timezone'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,462 INFO sync-metadata.sync-timezone :: :h2 database 1 default timezone is ""Asia/Jakarta""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,511 INFO sync.util :: FINISHED: step ''sync-timezone'' for h2 Database 1 ''Sample Database'' (101.3 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,513 INFO sync.util :: STARTING: step ''sync-tables'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,689 INFO sync-metadata.tables :: Updating table metadata for Table 8 ''PUBLIC.PRODUCTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,697 INFO sync-metadata.tables :: Updating table metadata for Table 3 ''PUBLIC.PEOPLE''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,699 INFO sync-metadata.tables :: Updating table metadata for Table 7 ''PUBLIC.INVOICES''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,700 INFO sync-metadata.tables :: Updating table metadata for Table 5 ''PUBLIC.ORDERS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,701 INFO sync-metadata.tables :: Updating table metadata for Table 4 ''PUBLIC.REVIEWS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,702 INFO sync-metadata.tables :: Updating table metadata for Table 2 ''PUBLIC.FEEDBACK''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,703 INFO sync-metadata.tables :: Updating table metadata for Table 1 ''PUBLIC.ANALYTIC_EVENTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,704 INFO sync-metadata.tables :: Updating table metadata for Table 6 ''PUBLIC.ACCOUNTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,734 INFO sync.util :: FINISHED: step ''sync-tables'' for h2 Database 1 ''Sample Database'' (220.5 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:18,735 INFO sync.util :: STARTING: step ''sync-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,032 INFO sync.util :: FINISHED: step ''sync-fields'' for h2 Database 1 ''Sample Database'' (1.3 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,035 INFO sync.util :: STARTING: step ''sync-fks'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,278 INFO sync.util :: FINISHED: step ''sync-fks'' for h2 Database 1 ''Sample Database'' (243.3 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:20,279 INFO sync.util :: STARTING: step ''sync-indexes'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:21,529 INFO sync.util :: FINISHED: step ''sync-indexes'' for h2 Database 1 ''Sample Database'' (1.2 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:21,530 INFO sync.util :: STARTING: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,579 ERROR middleware.log :: HEAD /api/health 503 10.1 ms (0 DB calls) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,681 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,683 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,754 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,756 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,829 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Sample Database"" has been enabled with schedule: ""0 26 * * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:23,831 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""Sample Database"" has been enabled with schedule: ""0 0 17 * * ? *""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,425 INFO sync.util :: FINISHED: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database'' (2.9 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,426 INFO sync.util :: STARTING: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,457 INFO sync.util :: FINISHED: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database'' (30.4 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,472 INFO sync.util :: FINISHED: Sync metadata for h2 Database 1 ''Sample Database'' (8.2 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,478 INFO sync.util :: STARTING: Analyze data for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,516 INFO sync.util :: STARTING: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,641 INFO sync.analyze :: fingerprint-fields Analyzed [*****Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¢   12% Table 2 ''PUBLIC.FEEDBACK''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,671 INFO sync.analyze :: fingerprint-fields Analyzed [***********Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜’   24% Table 3 ''PUBLIC.PEOPLE''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,721 INFO sync.util :: FINISHED: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database'' (204.3 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,722 INFO sync.util :: STARTING: step ''classify-fields'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,772 INFO sync.analyze :: classify-fields Analyzed [******************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜•   36% Table 6 ''PUBLIC.ACCOUNTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,797 INFO sync.analyze :: classify-fields Analyzed [***********************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¬   48% Table 7 ''PUBLIC.INVOICES''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,819 INFO sync.analyze :: classify-fields Analyzed [******************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Œ   60% Table 8 ''PUBLIC.PRODUCTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,847 INFO sync.util :: FINISHED: step ''classify-fields'' for h2 Database 1 ''Sample Database'' (123.9 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,848 INFO sync.util :: STARTING: step ''classify-tables'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,869 INFO sync.analyze :: classify-tables Analyzed [************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜‹   72% Table 1 ''PUBLIC.ANALYTIC_EVENTS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,884 INFO sync.analyze :: classify-tables Analyzed [*****************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Š   84% Table 5 ''PUBLIC.ORDERS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,886 INFO sync.analyze :: classify-tables Analyzed [***********************************************Â·Â·Â·] ðŸ˜Ž   96% Table 4 ''PUBLIC.REVIEWS''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,906 INFO sync.util :: FINISHED: step ''classify-tables'' for h2 Database 1 ''Sample Database'' (57.7 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,934 INFO sync.util :: FINISHED: Analyze data for h2 Database 1 ''Sample Database'' (455.5 ms)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,940 INFO sync.util :: STARTING: Cache field values in h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:24,977 INFO sync.util :: STARTING: step ''delete-expired-advanced-field-values'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:26,354 INFO sync.util :: FINISHED: step ''delete-expired-advanced-field-values'' for h2 Database 1 ''Sample Database'' (1.4 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:26,355 INFO sync.util :: STARTING: step ''update-field-values'' for h2 Database 1 ''Sample Database''
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,761 INFO sync.util :: FINISHED: step ''update-field-values'' for h2 Database 1 ''Sample Database'' (6.4 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,790 INFO sync.util :: FINISHED: Cache field values in h2 Database 1 ''Sample Database'' (7.8 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,794 INFO sync.util :: FINISHED: Sync h2 Database 1 ''Sample Database'' (16.6 s)
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,888 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,930 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,931 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,934 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,939 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,941 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'd198aefc2e401720584392898'
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   NOT STARTED.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Currently in standby mode.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Number of jobs executed: 0
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    |   Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,942 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:32,942 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,369 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_d198aefc2e401720584392898 paused.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,370 INFO metabase.task :: Task scheduler initialized into standby mode.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,485 INFO metabase.task :: Initializing task Cache ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,487 INFO metabase.task :: Initializing task SyncDatabases ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,584 INFO task.sync-databases :: Updated default schedules for 0 databases
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,585 INFO metabase.task :: Initializing task PersistRefresh ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,681 INFO metabase.task :: Initializing task CheckForNewVersions ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,750 INFO metabase.task :: Initializing task PersistPrune ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,760 INFO metabase.task :: Initializing task SendAnonymousUsageStats ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,779 INFO metabase.task :: Initializing task ModelIndexValues ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,787 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,814 INFO metabase.task :: Initializing task TruncateAuditTables ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,837 INFO metabase.task :: Initializing task SendPulses ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,870 INFO metabase.task :: Initializing task SendFollowUpEmails ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,892 INFO metabase.task :: Initializing task SendCreatorSentimentEmails ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,908 INFO metabase.task :: Initializing task SendLegacyNoSelfServiceEmail ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,921 INFO metabase.task :: Initializing task TaskHistoryCleanup ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:33,990 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail ðŸ“†
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,039 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,040 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""5842fb6367cd1720584221550""'s failed in-progress jobs.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,048 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""5842fb6367cd1720584233037""'s failed in-progress jobs.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,055 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_d198aefc2e401720584392898 started.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,056 INFO metabase.task :: Task scheduler started
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,059 INFO metabase.core :: Metabase Initialization COMPLETE in 1.7 mins
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:34,214 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:06:53,924 DEBUG middleware.log :: HEAD /api/health 200 1.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (1 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:24,148 DEBUG middleware.log :: HEAD /api/health 200 1.4 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (1 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:29,098 INFO middleware.misc :: Setting Metabase site URL to metabase.yoursite.com
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:30,175 INFO i18n.impl :: Reading available locales from locales.clj...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:30,654 INFO util.fonts :: Reading available fonts from /frontend_client/app/fonts
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:34,503 DEBUG middleware.log :: GET /api/user/current 401 7.3 ms (0 DB calls) {:metabase-user-id nil} 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | ""Unauthenticated""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:34,623 DEBUG middleware.log :: GET /api/session/properties 200 118.8 ms (2 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:07:54,340 DEBUG middleware.log :: HEAD /api/health 200 1.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:08:24,550 DEBUG middleware.log :: HEAD /api/health 200 975.4 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (61 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:08:54,790 DEBUG middleware.log :: HEAD /api/health 200 1.7 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (8 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:08,472 DEBUG middleware.log :: GET /api/user/current 401 1.5 ms (0 DB calls) {:metabase-user-id nil} 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | ""Unauthenticated""
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:08,544 DEBUG middleware.log :: GET /api/session/properties 200 61.5 ms (2 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (59 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:25,056 DEBUG middleware.log :: HEAD /api/health 200 1.0 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (59 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:09:55,229 DEBUG middleware.log :: HEAD /api/health 200 934.6 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (4 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:09,168 DEBUG middleware.log :: POST /api/util/password_check 200 109.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (6 idle, 0 queued) (52 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:09,185 DEBUG middleware.log :: POST /api/util/password_check 200 118.2 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (6 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,303 DEBUG middleware.log :: POST /api/util/password_check 200 1.1 s (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (6 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,388 DEBUG middleware.log :: POST /api/util/password_check 200 54.9 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:10,411 DEBUG middleware.log :: POST /api/util/password_check 200 129.0 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (54 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,281 INFO models.user :: Setting User 1's last_acknowledged_version to v0.50.9, the current version
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,420 INFO models.user :: Adding User 1 to All Users permissions group...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,420 INFO models.user :: Adding User 1 to All Users permissions group...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:15,990 DEBUG middleware.log :: POST /api/setup 200 1.2 s (46 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:16,672 DEBUG middleware.log :: GET /api/setting 200 322.6 ms (13 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:16,678 DEBUG middleware.log :: GET /api/session/properties 200 251.9 ms (15 DB calls) App DB connections: 0/10 Jetty threads: 7/50 (5 idle, 0 queued) (55 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:25,441 DEBUG middleware.log :: HEAD /api/health 200 969.9 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (57 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:10:55,737 DEBUG middleware.log :: HEAD /api/health 200 1.1 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:11:25,949 DEBUG middleware.log :: HEAD /api/health 200 1.2 ms (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (58 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:11:56,152 DEBUG middleware.log :: HEAD /api/health 200 881.5 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (5 idle, 0 queued) (51 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:26,335 DEBUG middleware.log :: HEAD /api/health 200 974.7 Âµs (0 DB calls) App DB connections: 0/10 Jetty threads: 6/50 (3 idle, 0 queued) (51 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:31,032 INFO driver.impl :: Initializing driver :mysql...
metabase-instance_metabase.1.ro4ghh9ndlvg@vm    | 2024-07-10 11:12:31,083 INFO driver.mysql :: You may need to add 'trustServerCertificate=true' to the additional connection options to connect with SSL.
```

Now the Metabase v0.50.9 instance is finally running successfully on our Docker Swarm Cluster, and also succeeds updating the Metabase to v0.50.11.

@paoliniluis , it is: 16 vCPUs and 48 GB RAM.

dpsutton (Assginee) on (2024-07-11 13:10:49 UTC): excellent! We've made a separate issue (and already fixed) the error in shutdown. Glad to know your issue is resolved as well.

"
2390085552,issue,closed,completed,Can't Remove Dashboard Sole Tab Name in Pulse,"### Describe the bug

For a dashboard that previously added new tabs, after removing all tabs but the last one, the pulse still attaches that last tab's name. 

### To Reproduce

1. Create a new dashboard.
2. Add a random question.
3. Create a new tab, save, then remove the new tab.
4. Email that dashboard.
5. Email shows 'Tab 1' under dashboard title.


### Expected behavior

It should not show tab's name if there is only one tab.

### Logs

_No response_

### Information about your Metabase installation

```JSON
""version"": {
      ""date"": ""2024-07-02"",
      ""tag"": ""v0.50.9"",
      ""hash"": ""720e549""
    },
```


### Severity

Mild

### Additional context

_No response_",ojjj13,2024-07-04 06:49:18+00:00,[],2024-07-26 11:09:45+00:00,2024-07-26 02:45:04+00:00,https://github.com/metabase/metabase/issues/45123,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2209362002, 'issue_id': 2390085552, 'author': 'alxnddr', 'body': '@cdeweyx what do you think about the issue? Maybe we can omit the tab name in subscriptions only if it is the only tab', 'created_at': datetime.datetime(2024, 7, 4, 17, 8, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209668778, 'issue_id': 2390085552, 'author': 'ojjj13', 'body': '> @cdeweyx what do you think about the issue? Maybe we can omit the tab name in subscriptions only if it is the only tab\r\n\r\nOr give user ability to change the tab name? There is a work around where you create a second tab and rename the first one, but it is not very elegant.', 'created_at': datetime.datetime(2024, 7, 5, 0, 34, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2215936535, 'issue_id': 2390085552, 'author': 'cdeweyx', 'body': ""> Maybe we can omit the tab name in subscriptions only if it is the only tab\r\n\r\n@alxnddr Yeah we should omit tab name if there's only one tab"", 'created_at': datetime.datetime(2024, 7, 9, 1, 6, 30, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-07-04 17:08:18 UTC): @cdeweyx what do you think about the issue? Maybe we can omit the tab name in subscriptions only if it is the only tab

ojjj13 (Issue Creator) on (2024-07-05 00:34:15 UTC): Or give user ability to change the tab name? There is a work around where you create a second tab and rename the first one, but it is not very elegant.

cdeweyx on (2024-07-09 01:06:30 UTC): @alxnddr Yeah we should omit tab name if there's only one tab

"
2389547167,issue,closed,completed,"Upgrade to v50 where Permissions are Mapped to ""No self-service (deprecated)"" Blocks View Access to Other Data in the Database","### Describe the bug

Upgrading from v49 to v50 with ""No Self Service"" in play can cause other schemas to be blocked (tested with Snowflake - didn't attempt to replicate with other DBs).

### To Reproduce

1. In v49 set up a Snowflake Connection that contains at least 2 schemas
2. Set all user to ""Block""
3. Create a test user and assign them to a test group
4. For the group assign one of the schemas in Snowflake to ""No Self Service"" and the other to ""Unrestricted""
5. Create a test Question from each schema and place it in a collection the group has view access to (confirm user can access both questions before upgrade)
7. Upgrade to v50
8. Note the permissions map correctly
9. Note that test user cannot view Questions from either schema even though they have ""Can View"" data permissions


Loom recording: https://www.loom.com/share/4b4154c362e342ba9811addaf7c62a18

### Expected behavior

If the user has ""View Data"" permission they should be able to view the questions

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-28"",
      ""tag"": ""v1.50.8"",
      ""hash"": ""dc9e68b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Severe

### Additional context

_No response_",ixipixi,2024-07-03 21:47:40+00:00,['noahmoss'],2024-07-09 00:04:17+00:00,2024-07-08 23:17:05+00:00,https://github.com/metabase/metabase/issues/45116,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2212582585, 'issue_id': 2389547167, 'author': 'kbrownlees', 'body': ""We just hit this upgrading to 0.50 from 0.49 as well. All out permissions are broken, to the point where I can't even save a question I am currently looking at (and running): https://www.loom.com/share/f8e2060528264e718dda59508478c7f3"", 'created_at': datetime.datetime(2024, 7, 7, 21, 29, 57, tzinfo=datetime.timezone.utc)}]","kbrownlees on (2024-07-07 21:29:57 UTC): We just hit this upgrading to 0.50 from 0.49 as well. All out permissions are broken, to the point where I can't even save a question I am currently looking at (and running): https://www.loom.com/share/f8e2060528264e718dda59508478c7f3

"
2389449438,issue,closed,completed,Invalid visualization settings crash combined cartesian charts on dashboards,"[Slack report](https://metaboat.slack.com/archives/C064QMXEV9N/p1720000226075329)

Invalid visualization settings crash combined cartesian charts on dashboards. Dashboard reproduction: https://stats.metabase.com/dashboard/240-github-issues
The issue here is that the dashcard combines 3 cards and two of them have invalid `graph.metric` viz settings values `count-where` which I assume previously referred to the summarized metric column but at some point BE changed the naming of such summarized metric columns that use custom expressions",alxnddr,2024-07-03 20:52:40+00:00,['alxnddr'],2024-07-09 00:33:44+00:00,2024-07-08 23:05:03+00:00,https://github.com/metabase/metabase/issues/45114,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2389342860,issue,open,,"The query builder allows me to have custom columns with the same name as the original columns, leading to weird behaviors","### Describe the bug

If I create a custom column with the same name as a another column, the custom column won't appear

### To Reproduce

1) new question->orders
2) create a custom column like convertTimezone([Created At], ""America/Buenos_Aires"", ""UTC""), use created_at as the name
3) visualize the question

see that the original created_at is there but not the custom column, but the custom column is still there
![image](https://github.com/metabase/metabase/assets/1711649/da8a2783-0bc8-46a0-b1f6-0bae895b6365)


### Expected behavior

Disallow the user to create custom columns with the same names as the original columns in the table/s

### Logs

NA

### Information about your Metabase installation

```JSON
v50.x
```


### Severity

P2, only because you can change the name of the custom column, but the query builder is on an inconsistent state (a column that's not there)

### Additional context

NA",paoliniluis,2024-07-03 19:50:56+00:00,[],2025-02-04 20:27:12+00:00,,https://github.com/metabase/metabase/issues/45112,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2207101733, 'issue_id': 2389342860, 'author': 'bshepherdson', 'body': ""This is a known issue and there are several user issues in this vein. (I don't have a canonical one to point this at.)"", 'created_at': datetime.datetime(2024, 7, 3, 19, 52, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207118082, 'issue_id': 2389342860, 'author': 'ranquild', 'body': ""We have this logic on the FE for expression names but it doesn't take other columns into account https://github.com/metabase/metabase/blob/e5e0c2ccd03428c622ffa3d1bc468dd98201c3cd/frontend/src/metabase/query_builder/components/notebook/steps/ExpressionStep.tsx#L116\r\n\r\nI think we need to remove it and make `Lib.expression` automatically make the name unique."", 'created_at': datetime.datetime(2024, 7, 3, 19, 57, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207354250, 'issue_id': 2389342860, 'author': 'nemanjaglumac', 'body': 'Related https://github.com/metabase/metabase/issues/25189', 'created_at': datetime.datetime(2024, 7, 3, 21, 36, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208929435, 'issue_id': 2389342860, 'author': 'bshepherdson', 'body': ""> I think we need to remove it and make `Lib.expression` automatically make the name unique.\r\n\r\nI don't know about this. Some of the user reports of this issue they were explicitly trying to replace the field with an expression with the same name. Like `coalesce([Discount], 0)` to smooth over a `NULL`able field.\r\n\r\nThe trouble is that it's possible to get a name collision with an expression after an edit other than creating the expression. In those cases renaming the expression is unexpected magic and would break some downstream references. For example:\r\n- Create a model, and a question based on it.\r\n- Create an expression `foo`.\r\n- Set its viz settings, like number formatting or whatever.\r\n- Update the underlying model to also have a field `foo`.\r\n\r\nI don't think there's a good solution here powered by `_2` renaming.\r\n- If the expression is renamed, its viz settings are wrongly captured by the model column.\r\n- If the incoming field is renamed, there's a latent issue: re-naming the fields based on their output order would swap the `_2`s, causing potentially other weird effects."", 'created_at': datetime.datetime(2024, 7, 4, 13, 0, 10, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-03 19:52:24 UTC): This is a known issue and there are several user issues in this vein. (I don't have a canonical one to point this at.)

ranquild on (2024-07-03 19:57:33 UTC): We have this logic on the FE for expression names but it doesn't take other columns into account https://github.com/metabase/metabase/blob/e5e0c2ccd03428c622ffa3d1bc468dd98201c3cd/frontend/src/metabase/query_builder/components/notebook/steps/ExpressionStep.tsx#L116

I think we need to remove it and make `Lib.expression` automatically make the name unique.

nemanjaglumac on (2024-07-03 21:36:47 UTC): Related https://github.com/metabase/metabase/issues/25189

bshepherdson on (2024-07-04 13:00:10 UTC): I don't know about this. Some of the user reports of this issue they were explicitly trying to replace the field with an expression with the same name. Like `coalesce([Discount], 0)` to smooth over a `NULL`able field.

The trouble is that it's possible to get a name collision with an expression after an edit other than creating the expression. In those cases renaming the expression is unexpected magic and would break some downstream references. For example:
- Create a model, and a question based on it.
- Create an expression `foo`.
- Set its viz settings, like number formatting or whatever.
- Update the underlying model to also have a field `foo`.

I don't think there's a good solution here powered by `_2` renaming.
- If the expression is renamed, its viz settings are wrongly captured by the model column.
- If the incoming field is renamed, there's a latent issue: re-naming the fields based on their output order would swap the `_2`s, causing potentially other weird effects.

"
2389024687,issue,open,,Custom column with math function expression not working with MongoDB,"### Describe the bug

Using MongoDB as data source, trying to create a custom column with the log() function fails:

<img width=""736"" alt=""image"" src=""https://github.com/metabase/metabase/assets/105419547/5fc8d496-363c-45df-949c-898e14bdeb9b"">

Standard math + - * / is working just fine...

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

The log() function is referenced in the documentation as an available function and should just be useable. 

### Logs

2024-07-03 18:17:01,941 INFO sync.util :: FINISHED: step ''fingerprint-fields'' for mongo Database 2 ''NewBank'' (43,6 ms)
2024-07-03 18:17:01,941 INFO sync.util :: STARTING: step ''classify-fields'' for mongo Database 2 ''NewBank''
2024-07-03 18:17:01,943 INFO sync.analyze :: classify-fields Analyzed [********************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜   40% Table 15 ''Card Issuing - Investigation - Logfile''
2024-07-03 18:17:01,946 INFO sync.analyze :: classify-fields Analyzed [*************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜¬   50% Table 26 ''production''
2024-07-03 18:17:01,948 INFO sync.analyze :: classify-fields Analyzed [******************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Œ   60% Table 67 ''Credit Issuing Investigation Logfile''
2024-07-03 18:17:01,949 INFO sync.util :: FINISHED: step ''classify-fields'' for mongo Database 2 ''NewBank'' (7,7 ms)
2024-07-03 18:17:01,949 INFO sync.util :: STARTING: step ''classify-tables'' for mongo Database 2 ''NewBank''
2024-07-03 18:17:01,950 INFO sync.analyze :: classify-tables Analyzed [**********************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜   70% Table 12 ''Card Issuing - Investigation - Status Total''
2024-07-03 18:17:01,951 INFO sync.analyze :: classify-tables Analyzed [****************************************Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·] ðŸ˜Š   80% Table 22 ''CardRecords''
2024-07-03 18:17:01,951 INFO sync.analyze :: classify-tables Analyzed [********************************************Â·Â·Â·Â·Â·Â·] ðŸ˜   90% Table 64 ''Card Issuing Processing Card Authorization Latencies''
2024-07-03 18:17:01,951 INFO sync.util :: FINISHED: step ''classify-tables'' for mongo Database 2 ''NewBank'' (2,1 ms)
2024-07-03 18:17:01,954 INFO sync.util :: FINISHED: Analyze data for mongo Database 2 ''NewBank'' (61,2 ms)

### Information about your Metabase installation

```JSON
Tested in multiple browsers.
```


### Severity

blocking my entire usage of metaphase

### Additional context

_No response_",cvaltrock,2024-07-03 16:24:55+00:00,[],2025-02-04 20:29:00+00:00,,https://github.com/metabase/metabase/issues/45108,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Backend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Drivers', '')]",[],
2388641498,issue,closed,not_planned,Consolidate remapping logic and custom label logic in BE endpoints,"In #43914 we currently pull a lot of data from the backend to show the custom labels for values on parameters on dashboards and native questions.

This has some issues, since we don't always have enough context to display the correct label.
On top of that, there are a lot of heuristics we need to keep in mind and it would be safer to consolidate all this knowledge on the back end.

We would need to update the parameter values endpoints, which are

- for unsaved dashboards:
  ```
  POST /api/dataset/parameter/values
  ```
- for dashboards:
  ```
  GET /api/dashboard/{dashboardId}/parameter/{parameterId}/values
  GET /api/public/dashboard/{dashboardId}/parameter/{parameterId}/values
  GET /api/embed/dashboard/{token}/parameter/{parameterId}/values
  ```
- for questions:
  ```
  GET /api/card/{questionId}/parameter/{parameterId}/values
  GET /api/public/card/{cardId}/parameter/{parameterId}/values
  GET /api/embed/card/{token}/parameter/{parameterId}/values
  ```

To
1. accept a `values` parameter to limit the results to
2. to return the values in the same format always:
   - values is an array of value, label pairs
   - the first item of each pair is the value (ie. a `""foo""`, `12`, ...)
   - In the case of FP/PK remapping, the second item is the remapped value
   - In the presence of custom labels/values in the `values_source_config` for the parameter, the second item of the pair is the custom label for the value
   - In the case none of the above holds the second item of the pair just holds the stringified value

### Examples

For a parameter without PK/FK remapping and no custom `values_source_config`, the returned values could look like: 
```json
{
  ""values"": [
    [10042, ""10,042""],
    [55, ""55""],
    ...
  ]
}
```

With remapped PK/FK:
```json
{
  ""values"": [
    [10, ""Macy - 10""],
    [55, ""Mark - 55""],
    ...
  ]
}
```

With custom `values_source_config`:
```json
{
  ""values"": [
    [10, ""Custom label for 10""]
    [55, ""Custom label for 55""],
    ...
  ]
}
```",romeovs,2024-07-03 13:30:19+00:00,['romeovs'],2024-07-17 10:28:31+00:00,2024-07-17 10:28:31+00:00,https://github.com/metabase/metabase/issues/45097,"[('.Backend', ''), ('.Team/Querying', '')]",[],
2388489281,issue,closed,completed,Update Dark (we call it `night` under the hood) theme CSS to match the design when background is transparent,,WiNloSt,2024-07-03 12:20:51+00:00,['WiNloSt'],2024-07-10 08:30:10+00:00,2024-07-10 08:30:10+00:00,https://github.com/metabase/metabase/issues/45090,[],[],
2388268026,issue,closed,not_planned,Can't load schema of database in Spark SQL,"### Describe the bug

I'm using latest version of Metabase and use SparkSQL to connect to data warehouse
![image](https://github.com/metabase/metabase/assets/171651073/a4813af0-a07e-42a6-befe-bb32851865ce)

although I can use SQL to show the schemas in the warehouse like this


![image](https://github.com/metabase/metabase/assets/171651073/38311ad5-c38d-465a-a669-65de3428e1d6)

But when I access the browser database I don't see any schemas or tables, even when I use the Sync database and schemas function in the admin section.

![image](https://github.com/metabase/metabase/assets/171651073/059423a4-0625-44d5-99c8-03273d961edf)




### To Reproduce

1. Go to Admin page
2. Click on database and create database
3. Input connection info of Spark SQL
4. Back to browser database and can't see any schema???


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser: Chrome Version 126.0.6478.126 (Official Build) (64-bit)
- OS: Ubuntu 20.04
- Database: SparkSQL
- Metabase version: 0.50.8
- Metabase hosting environment: Docker
- Metabase internal database: postgres
```


### Severity

The error is quite serious as I cannot explore my data and view the schemas or tables in my warehouse.

### Additional context

_No response_",lakechain,2024-07-03 10:28:40+00:00,[],2024-07-23 03:13:55+00:00,2024-07-17 11:37:39+00:00,https://github.com/metabase/metabase/issues/45086,"[('Administration/Metadata & Sync', ''), ('.Limitation', ''), ('Database/Spark', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2206522717, 'issue_id': 2388268026, 'author': 'tsmacdonald', 'body': ""Hi @lakechain , do you see anything about the Database Sync for this DB happening in `/admin/troubleshooting/tasks` ? It'd be helpful to know if the issue is the sync not running, the sync failing, or the sync allegedly succeeding but not populating things correctly."", 'created_at': datetime.datetime(2024, 7, 3, 15, 20, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206952218, 'issue_id': 2388268026, 'author': 'calherries', 'body': '@lakechain I tested syncing the test database we have for Spark on 0.50.8, and the tables are syncing fine, so this is likely something specific about your setup. Can you share the log messages during database sync?\r\n1. go to the Databases page for that database in Admin Settings and click ""Sync database schema now""\r\n2. go to Admin Settings > Troubleshooting > Logs. The database logs for syncing database schema should start with something like this:\r\n```\r\n2024-07-03 18:04:53,996 INFO sync.util :: STARTING: Sync sparksql Database 1 \'\'test-data\'\'\r\n2024-07-03 18:04:53,997 INFO sync.util :: STARTING: Sync metadata for sparksql Database 1 \'\'test-data\'\'\r\n...\r\n```', 'created_at': datetime.datetime(2024, 7, 3, 18, 28, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207694044, 'issue_id': 2388268026, 'author': 'lakechain', 'body': '@calherries @tsmacdonald table sync is fine, but schemas are not. And I don\'t understand why Database name is required, in Spark SQL, Schema and Database are one, so when I enter database name as ""default"", no tables appear in the Database browser of metabase, but when I enter the name of a schema in the database name input, the tables of that schema appear in the Database browser.\r\nHow can I display all schemas (databases) in my warehouse on the database browser of Metabase?', 'created_at': datetime.datetime(2024, 7, 4, 0, 43, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207705675, 'issue_id': 2388268026, 'author': 'calherries', 'body': ""Ah yes, now I understand your issue. Having to specify a single schema is indeed a limitation of the Spark driver. Can you confirm whether [this issue](https://github.com/metabase/metabase/issues/13763) represents the solution you'd like? \r\n\r\nSpecifically:\r\n\r\n> if you leave the database blank, the UI will show the metadata from all databases."", 'created_at': datetime.datetime(2024, 7, 4, 0, 48, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207748857, 'issue_id': 2388268026, 'author': 'lakechain', 'body': ""Maybe that's what I need.\r\nBut I read in the SparkSQL connector documentation. I see that the database name is not required. https://www.metabase.com/docs/latest/databases/connections/sparksql"", 'created_at': datetime.datetime(2024, 7, 4, 1, 3, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207757017, 'issue_id': 2388268026, 'author': 'lakechain', 'body': ""@calherries I can't leave the database blank, it's required, Is this a bug?\r\n![image](https://github.com/metabase/metabase/assets/171651073/08c00203-a33c-4997-9911-c7d9408f4f74)"", 'created_at': datetime.datetime(2024, 7, 4, 1, 6, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208013527, 'issue_id': 2388268026, 'author': 'calherries', 'body': "">  I read in the SparkSQL connector documentation. I see that the database name is not required.\r\n\r\nCan you point out exactly where you see that in the documentation?\r\n\r\nI think this is definitely a limitation in the design of the Spark SQL driver. But it looks like it was intentionally designed this way, so I'm not sure it's a bug. As you said before:\r\n\r\n> when I enter the name of a schema in the database name input, the tables of that schema appear in the Database browser.\r\n\r\nIs it a feasible workaround to create a database in Metabase for each database/schema in your Spark SQL database?"", 'created_at': datetime.datetime(2024, 7, 4, 3, 23, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208083155, 'issue_id': 2388268026, 'author': 'lakechain', 'body': ""In the document I don't see anything that says I need to input a database name. I'll try some ways to see if I can get around it, thanks for your help."", 'created_at': datetime.datetime(2024, 7, 4, 4, 7, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208236041, 'issue_id': 2388268026, 'author': 'calherries', 'body': ""Thanks, please update this issue if you find the workaround satisfactory. Given you and a few others are obviously having issues with this, I will see if there's an easy way to fix this limitation. No promises though! There might be a good reason for this"", 'created_at': datetime.datetime(2024, 7, 4, 6, 44, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227756374, 'issue_id': 2388268026, 'author': 'darksciencebase', 'body': '@lakechain did the workaround work for you?', 'created_at': datetime.datetime(2024, 7, 15, 6, 5, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244168362, 'issue_id': 2388268026, 'author': 'lakechain', 'body': '@darksciencebase I am having to create a database for each schema in the data warehouse. This is probably the best way possible.', 'created_at': datetime.datetime(2024, 7, 23, 3, 13, 54, tzinfo=datetime.timezone.utc)}]","tsmacdonald on (2024-07-03 15:20:25 UTC): Hi @lakechain , do you see anything about the Database Sync for this DB happening in `/admin/troubleshooting/tasks` ? It'd be helpful to know if the issue is the sync not running, the sync failing, or the sync allegedly succeeding but not populating things correctly.

calherries on (2024-07-03 18:28:23 UTC): @lakechain I tested syncing the test database we have for Spark on 0.50.8, and the tables are syncing fine, so this is likely something specific about your setup. Can you share the log messages during database sync?
1. go to the Databases page for that database in Admin Settings and click ""Sync database schema now""
2. go to Admin Settings > Troubleshooting > Logs. The database logs for syncing database schema should start with something like this:
```
2024-07-03 18:04:53,996 INFO sync.util :: STARTING: Sync sparksql Database 1 ''test-data''
2024-07-03 18:04:53,997 INFO sync.util :: STARTING: Sync metadata for sparksql Database 1 ''test-data''
...
```

lakechain (Issue Creator) on (2024-07-04 00:43:58 UTC): @calherries @tsmacdonald table sync is fine, but schemas are not. And I don't understand why Database name is required, in Spark SQL, Schema and Database are one, so when I enter database name as ""default"", no tables appear in the Database browser of metabase, but when I enter the name of a schema in the database name input, the tables of that schema appear in the Database browser.
How can I display all schemas (databases) in my warehouse on the database browser of Metabase?

calherries on (2024-07-04 00:48:37 UTC): Ah yes, now I understand your issue. Having to specify a single schema is indeed a limitation of the Spark driver. Can you confirm whether [this issue](https://github.com/metabase/metabase/issues/13763) represents the solution you'd like? 

Specifically:

lakechain (Issue Creator) on (2024-07-04 01:03:44 UTC): Maybe that's what I need.
But I read in the SparkSQL connector documentation. I see that the database name is not required. https://www.metabase.com/docs/latest/databases/connections/sparksql

lakechain (Issue Creator) on (2024-07-04 01:06:53 UTC): @calherries I can't leave the database blank, it's required, Is this a bug?
![image](https://github.com/metabase/metabase/assets/171651073/08c00203-a33c-4997-9911-c7d9408f4f74)

calherries on (2024-07-04 03:23:40 UTC): Can you point out exactly where you see that in the documentation?

I think this is definitely a limitation in the design of the Spark SQL driver. But it looks like it was intentionally designed this way, so I'm not sure it's a bug. As you said before:


Is it a feasible workaround to create a database in Metabase for each database/schema in your Spark SQL database?

lakechain (Issue Creator) on (2024-07-04 04:07:37 UTC): In the document I don't see anything that says I need to input a database name. I'll try some ways to see if I can get around it, thanks for your help.

calherries on (2024-07-04 06:44:59 UTC): Thanks, please update this issue if you find the workaround satisfactory. Given you and a few others are obviously having issues with this, I will see if there's an easy way to fix this limitation. No promises though! There might be a good reason for this

darksciencebase on (2024-07-15 06:05:08 UTC): @lakechain did the workaround work for you?

lakechain (Issue Creator) on (2024-07-23 03:13:54 UTC): @darksciencebase I am having to create a database for each schema in the data warehouse. This is probably the best way possible.

"
2388136870,issue,closed,not_planned,Table schema not refreshing if the table visibility is set to hidden,"### Describe the bug

I'm using Metabase 0.50.6 and Snowflake as the database. I couldn't find a matching issue.


The table does update immediately after setting visibility to Queryable, which leads me to believe this is strictly tied to table visibility. The same issue does not happen for tables that are always queryable.

### To Reproduce

1. Create a new table in snowflake
2. Make sure the schema is synced to metabase
3. Set the table visibility to hidden in metabase
4. Change the table schema (rename a field)
5. The table doesn't update in metabase no matter what I do (cache dropping, rescan, sign in/out, wait 12h)

### Expected behavior

the table schema updates either immediately, shortly after the schema change, or at least upon manually rescanning the schema

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version: 0.50.6
- Database: Snowflake
```


### Severity

annoying

### Additional context

The rescan query itself is executed after I manually trigger it:

> [6f056a24-7796-4859-89b7-06a0edf3d698] 2024-07-03T11:24:15+02:00 DEBUG metabase.server.middleware.log POST /api/table/67/rescan_values 200 4.7 ms (2 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (2 idle, 0 queued) (104 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 20}

but does not update the schema if the table is hidden",kaiks,2024-07-03 09:25:20+00:00,[],2024-07-03 11:39:48+00:00,2024-07-03 11:17:29+00:00,https://github.com/metabase/metabase/issues/45085,[],"[{'comment_id': 2205837337, 'issue_id': 2388136870, 'author': 'Tony-metabase', 'body': 'That is expected. If you mark it as hidden ... You can mark it as visible and the scan will pick the table up', 'created_at': datetime.datetime(2024, 7, 3, 11, 17, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205865786, 'issue_id': 2388136870, 'author': 'kaiks', 'body': 'Is this behavior documented somewhere? Should we disable scanning hidden tables, if it deliberately does not do anything? (or, preferably, change the behavior so that it still does update; after all, why would it not?)', 'created_at': datetime.datetime(2024, 7, 3, 11, 33, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205872617, 'issue_id': 2388136870, 'author': 'Tony-metabase', 'body': 'Hidden tables should not be synced or scanned for reference:\r\n\r\nhttps://www.metabase.com/docs/latest/databases/sync-scan#disabling-syncing-and-scanning-for-specific-tables', 'created_at': datetime.datetime(2024, 7, 3, 11, 37, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205875774, 'issue_id': 2388136870, 'author': 'kaiks', 'body': 'Okay, thanks. I might create a feature request ticket later for a way of hiding tables but still keeping them in sync.', 'created_at': datetime.datetime(2024, 7, 3, 11, 39, 47, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-07-03 11:17:29 UTC): That is expected. If you mark it as hidden ... You can mark it as visible and the scan will pick the table up

kaiks (Issue Creator) on (2024-07-03 11:33:47 UTC): Is this behavior documented somewhere? Should we disable scanning hidden tables, if it deliberately does not do anything? (or, preferably, change the behavior so that it still does update; after all, why would it not?)

Tony-metabase on (2024-07-03 11:37:56 UTC): Hidden tables should not be synced or scanned for reference:

https://www.metabase.com/docs/latest/databases/sync-scan#disabling-syncing-and-scanning-for-specific-tables

kaiks (Issue Creator) on (2024-07-03 11:39:47 UTC): Okay, thanks. I might create a feature request ticket later for a way of hiding tables but still keeping them in sync.

"
2388054118,issue,open,,Custom maps that span wide viewports aren't handled well,"**Describe the bug**
The custom geoJson map is not displayed, but correctly parsed.

**Logs**
No error logs.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to Admin panel
2. Click on Maps
3. Add a custom map with this URL ""https://transport.data.gouv.fr/api/aoms/geojson""
4. See the map isn't displayed

**Expected behavior**
A map displayed with polygons.

**Screenshots**
<img width=""1076"" alt=""image"" src=""https://github.com/metabase/metabase/assets/4528670/7ea40fa2-9e13-4f2e-b348-e1e421e2459f"">


**Severity**
Low


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.3+9-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.3"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.3+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.11-clevercloud-vm-dirty"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-23"",
      ""tag"": ""v0.49.12"",
      ""hash"": ""77e7a81""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",AurelienC,2024-07-03 08:48:33+00:00,[],2024-07-24 20:00:05+00:00,,https://github.com/metabase/metabase/issues/45084,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Product Input Needed', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2248546378, 'issue_id': 2388054118, 'author': 'npfitz', 'body': '@AurelienC I tried loading your GeoJSON file and noticed that it spanned a very wide viewport (it contains data for French colonies all over the world, not just france). The issue is that the bound of the map span all the way from South America to the Pacific just outside of Russia. This causes things to be rendered in sizes less than 1px because of the preview size.\r\n\r\nIf you do go ahead and use the map, this is what it will likely look like on a standard 1080p monitor (you can see the grey bits that are the map regions):\r\n![image](https://github.com/user-attachments/assets/16f5625a-0c16-4509-b587-00459373ad62)', 'created_at': datetime.datetime(2024, 7, 24, 17, 27, 43, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-07-24 17:27:43 UTC): @AurelienC I tried loading your GeoJSON file and noticed that it spanned a very wide viewport (it contains data for French colonies all over the world, not just france). The issue is that the bound of the map span all the way from South America to the Pacific just outside of Russia. This causes things to be rendered in sizes less than 1px because of the preview size.

If you do go ahead and use the map, this is what it will likely look like on a standard 1080p monitor (you can see the grey bits that are the map regions):
![image](https://github.com/user-attachments/assets/16f5625a-0c16-4509-b587-00459373ad62)

"
2387967197,issue,open,,Ð¡hanging the source text of the link in the link type request field,"### Describe the bug

Metabase version v0.50.9
I'm using a reverse proxy. 
I have a link configured: https:/mysite/metabase
I have an upload location on the same resource:
https:/mysite/upload
when I create a query in the constructor and add a link type field whose value contains the initial fragment:
https:/mysite/upload
This link automatically changes and the location metabase is added:
https:/mysite/metabase/upload
This behavior can be changed by changing the site name:
https:/mysite_another_name/upload -> https:/mysite_another_name/upload
https:/mysite/upload ->https:/mysite/metabase/upload

This behavior makes no sense since you need to save the link specified in the database table. Therefore, it seems to me that this is an error related to the coincidence of the initial fragment of the link with the name of the metabase location.

### To Reproduce

1. create a field of type link whose initial fragment matches the name of the metabase resource:
2. https:/mysite/metabase


### Expected behavior

The link text received in the link type field must remain unchanged since it is determined by the user data.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""ru"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 YaBrowser/24.6.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.11+9-Debian-1deb11u1"",
    ""java.vendor"": ""Debian"",
    ""java.vendor.url"": ""https://tracker.debian.org/openjdk-17"",
    ""java.version"": ""17.0.11"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.11+9-Debian-1deb11u1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-29-amd64"",
    ""user.language"": ""ru"",
    ""user.timezone"": ""Asia/Yekaterinburg""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12 (Debian 14.12-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-02"",
      ""tag"": ""v0.50.9"",
      ""hash"": ""720e549""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

This led to a malfunction of the links in the finished solution

### Additional context

_No response_",firstDismay,2024-07-03 08:07:24+00:00,[],2024-07-08 17:11:16+00:00,,https://github.com/metabase/metabase/issues/45082,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Customization/Formatting', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2214730670, 'issue_id': 2387967197, 'author': 'firstDismay', 'body': 'My colleague localized the problem. As expected, the problem is caused by a link match in the part that defines the location of the metabase:\r\nmetabase/frontend/src/metabase/lib/dom.js line 310 of function open:\r\n```\r\nif (shouldOpenInBlankWindow(url, options)) {\r\n    openInBlankWindow(url);\r\n  } else if (isSameOrigin(url)) {\r\n    if (!isMetabaseUrl(url)) {\r\n      clickLink(url, false);\r\n    } else {\r\n      openInSameOrigin(getLocation(url));\r\n    }\r\n  } else {\r\n    openInSameWindow(url);\r\n  }\r\n```\r\nopening a link through the dom router when isSameOrigin(url) matches.\r\nThere is reason to believe that a more complex calculation method could cause you serious problems. Because this function has changed several times to suit conflicting needs. This is clear from the history of the Commits.\r\n\r\nSince the origin comparison also includes the protocol, we used http links instead of https. This changed the comparison condition. Then we carried out an unconditional transition to https through a 301 response using nginx.\r\nThis is how we managed to get the required result.\r\nPS:\r\nI remember your suggestion to use a separate URL for the application. But unfortunately at the moment there is no way to configure DNS to resolve links like NameApp.MyServer', 'created_at': datetime.datetime(2024, 7, 8, 17, 7, 25, tzinfo=datetime.timezone.utc)}]","firstDismay (Issue Creator) on (2024-07-08 17:07:25 UTC): My colleague localized the problem. As expected, the problem is caused by a link match in the part that defines the location of the metabase:
metabase/frontend/src/metabase/lib/dom.js line 310 of function open:
```
if (shouldOpenInBlankWindow(url, options)) {
    openInBlankWindow(url);
  } else if (isSameOrigin(url)) {
    if (!isMetabaseUrl(url)) {
      clickLink(url, false);
    } else {
      openInSameOrigin(getLocation(url));
    }
  } else {
    openInSameWindow(url);
  }
```
opening a link through the dom router when isSameOrigin(url) matches.
There is reason to believe that a more complex calculation method could cause you serious problems. Because this function has changed several times to suit conflicting needs. This is clear from the history of the Commits.

Since the origin comparison also includes the protocol, we used http links instead of https. This changed the comparison condition. Then we carried out an unconditional transition to https through a 301 response using nginx.
This is how we managed to get the required result.
PS:
I remember your suggestion to use a separate URL for the application. But unfortunately at the moment there is no way to configure DNS to resolve links like NameApp.MyServer

"
2387940475,issue,closed,not_planned,data lables missing in charts in night theme,"### Describe the bug

data lables missing in charts in night theme

vedio link
https://drive.google.com/file/d/1f5qC3ydIxMFz2d0nsKQO4E9_kMQOQdZg/view?usp=sharing

### To Reproduce

when downloading the charts in png  in light mode everthing works fine but when theme is changed to night then data lables goes missing


### Expected behavior

data lables should be present reagadless of theme

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome
ubuntu 22.4
mysql 8.0.37
metabase 0.50.9
running on jar file
mysql
```


### Severity

blocking the usage

### Additional context

_No response_",MeharG811,2024-07-03 07:54:32+00:00,[],2024-07-03 15:24:56+00:00,2024-07-03 14:22:40+00:00,https://github.com/metabase/metabase/issues/45081,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2206269058, 'issue_id': 2387940475, 'author': 'alxnddr', 'body': 'Thanks for the report, it is a duplicate of https://github.com/metabase/metabase/issues/39546 which is about to be merged', 'created_at': datetime.datetime(2024, 7, 3, 14, 22, 40, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-07-03 14:22:40 UTC): Thanks for the report, it is a duplicate of https://github.com/metabase/metabase/issues/39546 which is about to be merged

"
2387396830,issue,closed,completed,Decouple MB_UNAGGREGATED_QUERY_ROW_LIMIT from FE rendering (subscriptions issue),"**Is your feature request related to a problem? Please describe.**
At some point in the past we decided that we would use this variable to allow users to get all the results in the attachments on subscriptions. But also this env var is used to set how many items get back on API calls, which means that now the FE will need to render more items if the env var is raised.

**Describe the solution you'd like**
Decouple these 2 things:
1) allow users to get all items on the attachments while
2) have the normal Metabase behavior on the FE (max 2K or more items, if defined)

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer who now has performance regressions on the FE

**Additional context**
There's also a bug:
![image](https://github.com/metabase/metabase/assets/1711649/26d90147-7f19-453e-bc85-285722864c22)

",paoliniluis,2024-07-03 00:37:41+00:00,[],2024-08-29 10:01:26+00:00,2024-08-26 17:12:42+00:00,https://github.com/metabase/metabase/issues/45078,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2310680213, 'issue_id': 2387396830, 'author': 'adam-james-v', 'body': 'Closing as https://github.com/metabase/metabase/pull/46401 provides this', 'created_at': datetime.datetime(2024, 8, 26, 17, 12, 42, tzinfo=datetime.timezone.utc)}]","adam-james-v on (2024-08-26 17:12:42 UTC): Closing as https://github.com/metabase/metabase/pull/46401 provides this

"
2387332194,issue,open,,CumulativeSumIf Custom Expression Support,"We'd love to have a `CumulativeSumIf` option when creating expressions. Just like `SumIf`, but `Cumulative`.

Is there another way to accomplish the same thing with existing Metabase features?

Thanks!",LukeAbell,2024-07-02 23:29:16+00:00,[],2025-02-04 20:30:20+00:00,,https://github.com/metabase/metabase/issues/45077,"[('Querying/MBQL', ''), ('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook/Custom Expression', '')]",[],
2387234940,issue,closed,completed,Add explanations for permissions changes,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6377293/15ef59d4-c082-4a55-ac07-a3c1f956ccf1)

Permissions for ""No self service"" in 49 and after ""the split"" in 50.

We went from orange to green (and red) but can make people think we have failed open.

Copying from Maz in slack: https://metaboat.slack.com/archives/C01LQQ2UW03/p1719956904707119?thread_ts=1719953628.467729&cid=C01LQQ2UW03

> permissions all of a sudden look different, and there is no explanation why. To address this, we need to identify (A) the message we want to deliver to admins and (B) how best to deliver that message.

> For (A), I think the message should take the shape of something like, â€œ<H1>Permissions look different, but user access hasnâ€™t changed.</H1> Weâ€™ve attempted to clarify the different things users can have access to. Hereâ€™s a summary of how each dimension of access has changed: (summary)â€

> For (B), there are pros and cons to a modal vs. a banner (or something else), and they are not mutually exclusive. A modal is attention grabbing and can ensure that the admin sees the message, even if they instinctively dismiss it. A banner has actually IMO a greater chance of being overlooked, but has the benefit of persistence. One possible solution would be to show the modal once per admin as Luiz spelled out, and then â€œminimizeâ€ it into a persistent content block (a banner or something) which could be a trigger to reopen the modal or to link off to a webpage with a summary and explanation of the changes. (And that content block could also be dismissible.)

### To Reproduce

on a 49.x series, set all users to ""no self service"" on the sample db, then upgrade to a 50.x.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
49 -> 50
```


### Severity

p1

### Additional context

_No response_",dpsutton,2024-07-02 22:00:21+00:00,['npfitz'],2024-07-10 23:52:00+00:00,2024-07-10 19:06:20+00:00,https://github.com/metabase/metabase/issues/45073,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2387183432,issue,open,,Surface errors on FE when reverting cards/dashboards,"### Describe the bug

When you try to revert a card or dashboard to a previous revision, if the BE returns an error response, the FE doesn't show anything.

### To Reproduce

0. Make it so that the `POST /api/revert` endpoint returns an error. You can do this by reproducing https://github.com/metabase/metabase/issues/31901 or just by mocking an error response.
1. Create a card/dashboard
2. Make a change to it, like editing the title
3. In the info sidebar, try to revert to a previous version
4. See that nothing happens


### Expected behavior

We should show an error message if the revert fails, preferably with a reason why it failed. We'll need both FE work + designs for showing the error message, as well as BE work to return more detailed errors.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master (1e35115cdd)
```


### Severity

P3

### Additional context

_No response_",noahmoss,2024-07-02 21:17:07+00:00,[],2025-02-04 20:26:40+00:00,,https://github.com/metabase/metabase/issues/45070,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2206016056, 'issue_id': 2387183432, 'author': 'nemanjaglumac', 'body': '@noahmoss and @metabase/admin-webapp please take a look at [this thread](https://metaboat.slack.com/archives/C02H619CJ8K/p1720003195981019) before you start working on the issue. This needs an input from the product+design.', 'created_at': datetime.datetime(2024, 7, 3, 12, 56, 40, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-03 12:56:40 UTC): @noahmoss and @metabase/admin-webapp please take a look at [this thread](https://metaboat.slack.com/archives/C02H619CJ8K/p1720003195981019) before you start working on the issue. This needs an input from the product+design.

"
2386990064,issue,closed,completed,`type/FK` -> column and `type/FK` -> `type/Name` field values remapping doesn't work in QB filter widgets when `Search box` is used,"### Describe the bug

Automatic PK field values remapping to a field with ""Entity Name"" semantic type doesn't work in query builder widgets with `Search box`. The same with FK -> Use foreign key -> Column remapping.

### To Reproduce

`type/FK` -> `type/Name`:
1. Admin -> Table Metadata -> People. 
2. Make sure that `People.Name` has `Entity Name` semantic type.
3. Make sure that `People.ID` has `Search box` in `Filtering on this field` section (`has_field_values` property).
4. New -> Question -> Tables -> People
5. Filter -> ID
6. Start typing a person name. Nothing happens - there is no autocomplete.
7. Enter some valid person ID and add this filter.
8. Open the filter again. See that the value is not remapped either.

`type/FK` -> column:
1. Admin -> Table Metadata -> Orders. 
2. Open `PRODUCT_ID` -> Remapping -> Use foreign key -> Select `Product.Title`.
3. Make sure there is `Search box` enabled as well.
4. New -> Question -> Tables -> Orders
5. Filter -> Product ID
7. Start typing a product title. Nothing happens - there is no autocomplete.
8. Enter some valid product ID and add this filter.
9. Open the filter again. See that the value is not remapped either.


### Expected behavior

Both cases work with `List of values`. They should work with `Search box`. 
<img width=""552"" alt=""Screenshot 2024-07-02 at 15 19 51"" src=""https://github.com/metabase/metabase/assets/8542534/d090996f-413f-4e59-9932-79c0db16452d"">
<img width=""459"" alt=""Screenshot 2024-07-02 at 15 21 13"" src=""https://github.com/metabase/metabase/assets/8542534/ced6e325-fff2-4dfd-85fd-610e4d60ffb2"">


### Logs

_No response_

### Information about your Metabase installation

```JSON
- v50
```


### Severity

P1

### Additional context

_No response_",ranquild,2024-07-02 19:22:17+00:00,"['bshepherdson', 'ranquild']",2024-08-28 02:08:57+00:00,2024-07-12 11:19:44+00:00,https://github.com/metabase/metabase/issues/45063,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2229426784, 'issue_id': 2386990064, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 49, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-15 21:00:49 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2386928266,issue,closed,completed,Dashboard level visualization settings not taken into account on dashboard subscriptions,"### Describe the bug

If you change a column name in a dashboard, these changes are not taken into account on the subscription and on the static rendering

### To Reproduce

1) make a question (e.g. orders table)
2) add it to a dashboard
3) change the name of the address column to something you like
4) send a subscription with an xlsx attachment

### Expected behavior

We should respect the column names in the following orders:
1) dashboard level column name
2) question level column name

This should happen on the rendering + on the attachments

### Logs

NA

### Information about your Metabase installation

```JSON
v50.x

I think it's a regression
```


### Severity

P1

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/713d256e-f040-4214-9de0-2a1ec9ce1281)
![image](https://github.com/metabase/metabase/assets/1711649/76950ec9-f58a-45e3-b678-ab129fda23fe)


Please make sure that in the tests we respect the situations mentioned above",paoliniluis,2024-07-02 18:53:10+00:00,['adam-james-v'],2024-07-11 14:44:04+00:00,2024-07-10 19:23:44+00:00,https://github.com/metabase/metabase/issues/45061,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2386735693,issue,open,,Dev-mode-only schema error,"While working on [the fix](https://github.com/metabase/metabase/pull/44987) validation for #35954, I kept bumping into an error in my local dev instance. Everything was running smoothly in CI and even in my local Cypress runs (because Cypress builds an actual JAR first). 

@bshepherdson confirmed that this is a dev-only-schema error.
[Slack context](https://metaboat.slack.com/archives/C04CYTEL9N2/p1719937777746019)

> Invalid output: [nil [""should be a boolean, got: [:template-tag \""person\""]"" ""should be a number, got: [:template-tag \""person\""]"" ""should be a string, got: [:template-tag \""person\""]"" ""must be a `:relative-datetime` clause, got: [:template-tag \""person\""]"" ""not an :absolute-datetime clause, got: [:template-tag \""person\""]"" ""local date time string literal, got: [:template-tag \""person\""]"" ""offset date time string literal, got: [:template-tag \""person\""]"" ""instance of java.time.LocalDateTime, got: [:template-tag \""person\""]"" ""instance of java.time.OffsetDateTime, got: [:template-tag \""person\""]"" ""instance of java.time.ZonedDateTime, got: [:template-tag \""person\""]"" ""instance of java.time.LocalDate, got: [:template-tag \""person\""]"" ""date string literal, got: [:template-tag \""person\""]"" ""must be a `:time` clause, got: [:template-tag \""person\""]"" ""local time string literal, got: [:template-tag \""person\""]"" ""offset time string literal, got: [:template-tag \""person\""]"" ""instance of java.time.LocalTime, got: [:template-tag \""person\""]"" ""instance of java.time.OffsetTime, got: [:template-tag \""person\""]"" ""valid instance of one of these MBQL clauses: :expression, :field, got: [:template-tag \""person\""]"" ""valid instance of one of these MBQL clauses: :expression, :field, got: [:template-tag \""person\""]"" ""must be a `:value` clause, got: [:template-tag \""person\""]""]]
",nemanjaglumac,2024-07-02 16:57:51+00:00,[],2025-02-04 20:27:51+00:00,,https://github.com/metabase/metabase/issues/45054,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2386692696,issue,closed,completed,Static embedding: iframe spews out deprecation warnings in developer console,"### Describe the bug

Static embedding: iframe spews out deprecation warnings in developer console

### To Reproduce

1. Open https://appytown.metabase.com/
2. Open developer tools / console
3. See deprecation warnings

<img width=""1493"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24216/939d1246-1e60-4f06-b8e7-ec1f267c6bf6"">


### Expected behavior

No deprecation warnings coming from Metabase

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome
- Appytown (running Metabase 50?)
```


### Severity

Annoying for developers because it pollutes console

### Additional context

_No response_",albertoperdomo,2024-07-02 16:33:05+00:00,['deniskaber'],2024-10-08 17:05:24+00:00,2024-07-02 21:42:45+00:00,https://github.com/metabase/metabase/issues/45053,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]",[],
2386672975,issue,closed,completed,Filtering on a custom date time column will add 00:00 to the filter making it unusable,"### Describe the bug

If you filter on an exact date on a custom date column, then it won't cover the full day, but just a specific moment in time.

### To Reproduce

1) go to the orders table and use a convert timezone function, e.g. convertTimezone([Created At], ""America/Argentina/Buenos_Aires"", ""UTC"")
2) save the question and now try to filter on the same date on both the created at and the new column, e.g. 
February 11, 2019
![image](https://github.com/metabase/metabase/assets/1711649/0ce281c1-2047-4dee-9458-2d9aa77b352f)

... you will see that filtering on the normal column makes a query like
```
SELECT ""source"".""id"" AS ""id"", ""source"".""user_id"" AS ""user_id"", ""source"".""product_id"" AS ""product_id"", ""source"".""subtotal"" AS ""subtotal"", ""source"".""tax"" AS ""tax"", ""source"".""total"" AS ""total"", ""source"".""discount"" AS ""discount"", ""source"".""created_at"" AS ""created_at"", ""source"".""quantity"" AS ""quantity"", ""source"".""created_at_BA"" AS ""created_at_BA"" FROM (SELECT ""public"".""orders"".""id"" AS ""id"", ""public"".""orders"".""user_id"" AS ""user_id"", ""public"".""orders"".""product_id"" AS ""product_id"", ""public"".""orders"".""subtotal"" AS ""subtotal"", ""public"".""orders"".""tax"" AS ""tax"", ""public"".""orders"".""total"" AS ""total"", ""public"".""orders"".""discount"" AS ""discount"", ""public"".""orders"".""created_at"" AS ""created_at"", ""public"".""orders"".""quantity"" AS ""quantity"", TIMEZONE($1, TIMEZONE($2, ""public"".""orders"".""created_at"")) AS ""created_at_BA"" FROM ""public"".""orders"" WHERE (""public"".""orders"".""created_at"" >= $3) AND (""public"".""orders"".""created_at"" < $4)) AS ""source"" LIMIT 2000
2024-07-02 16:10:30.770 UTC [214] DETAIL:  parameters: $1 = 'America/Argentina/Buenos_Aires', $2 = 'UTC', $3 = '2019-02-19 00:00:00', $4 = '2019-02-20 00:00:00'
```

and filtering on the custom column makes:
```
SELECT ""source"".""id"" AS ""id"", ""source"".""user_id"" AS ""user_id"", ""source"".""product_id"" AS ""product_id"", ""source"".""subtotal"" AS ""subtotal"", ""source"".""tax"" AS ""tax"", ""source"".""total"" AS ""total"", ""source"".""discount"" AS ""discount"", ""source"".""created_at"" AS ""created_at"", ""source"".""quantity"" AS ""quantity"", ""source"".""created_at_BA"" AS ""created_at_BA"" FROM (SELECT ""public"".""orders"".""id"" AS ""id"", ""public"".""orders"".""user_id"" AS ""user_id"", ""public"".""orders"".""product_id"" AS ""product_id"", ""public"".""orders"".""subtotal"" AS ""subtotal"", ""public"".""orders"".""tax"" AS ""tax"", ""public"".""orders"".""total"" AS ""total"", ""public"".""orders"".""discount"" AS ""discount"", ""public"".""orders"".""created_at"" AS ""created_at"", ""public"".""orders"".""quantity"" AS ""quantity"", TIMEZONE($1, TIMEZONE($2, ""public"".""orders"".""created_at"")) AS ""created_at_BA"" FROM ""public"".""orders"") AS ""source"" WHERE ""source"".""created_at_BA"" = $3 LIMIT 2000
2024-07-02 16:09:13.601 UTC [214] DETAIL:  parameters: $1 = 'America/Argentina/Buenos_Aires', $2 = 'UTC', $3 = '2019-02-11 00:00:00'
```

The normal query makes a WHERE field >= param and field < param+1

while the custom column is just a WHERE field = param (which is wrong)

### Expected behavior

The custom column should generate the same query as with the normal parameter

### Logs

NA

### Information about your Metabase installation

```JSON
It seems that it has always been like this
```


### Severity

P1

### Additional context

probably related to https://github.com/metabase/metabase/issues/43196",paoliniluis,2024-07-02 16:21:08+00:00,['lbrdnk'],2024-08-28 02:08:57+00:00,2024-07-23 06:07:14+00:00,https://github.com/metabase/metabase/issues/45052,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2206873542, 'issue_id': 2386672975, 'author': 'camsaul', 'body': 'I think there was a very good chance this was fixed by #41864 in 49.8', 'created_at': datetime.datetime(2024, 7, 3, 17, 35, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206989684, 'issue_id': 2386672975, 'author': 'paoliniluis', 'body': 'I reproduced this in 50.9', 'created_at': datetime.datetime(2024, 7, 3, 18, 55, 26, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-07-03 17:35:14 UTC): I think there was a very good chance this was fixed by #41864 in 49.8

paoliniluis (Issue Creator) on (2024-07-03 18:55:26 UTC): I reproduced this in 50.9

"
2386498509,issue,closed,completed,Upgrading to 50v causes some permission in No self-service (deprecated) to block access to the Browse Data,"### Describe the bug

Upgrading to 50v causes some permission to be turned into No self-service (deprecated) ... This in turn will impact any table that is part of the database and block access to the Browse Data. More context here:

https://metaboat.slack.com/archives/C013N8XL286/p1719925976490589

### To Reproduce

Have permissions setup on 49 (no self service for some tables and a sandbox permission for another) and then upgrade. You will notice the permissions change in this way:

![image](https://github.com/metabase/metabase/assets/110378427/b223e281-e39e-4624-883c-60a097b265a0)

This will cause the sandboxed user to lose browse data permissions

![image](https://github.com/metabase/metabase/assets/110378427/922cd091-cf01-4854-be0c-9a9a748b4279)

Again more context here https://metaboat.slack.com/archives/C013N8XL286/p1719925976490589


### Expected behavior

The sandboxed user should not be impacted by the other tables permissions

### Logs

N/A

### Information about your Metabase installation

```JSON
50.8
```


### Severity

Major issue 

### Additional context

_No response_",Tony-metabase,2024-07-02 14:59:52+00:00,['noahmoss'],2024-07-03 15:00:33+00:00,2024-07-03 13:32:32+00:00,https://github.com/metabase/metabase/issues/45046,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2386351652,issue,closed,completed,Hamburger menu is not functional in Admin app on moble,"### Describe the bug

The menu icon is the wrong color, and clicking it does not show the nav manu

### To Reproduce

1. Go to Admin
2. Shrink your screen so that the mobile view is shown
3. The menu icon is the wrong color, and clicking it does nothing

### Expected behavior

The menu icon should be white, and clicking it should expose a navigation menu

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current Master (v.50)
```


### Severity

p2 - broken functionality

### Additional context

_No response_",npfitz,2024-07-02 14:00:38+00:00,['npfitz'],2024-07-08 20:32:02+00:00,2024-07-08 13:45:30+00:00,https://github.com/metabase/metabase/issues/45042,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2386349873,issue,open,reopened,Notebook editor shows too many buttons after removing query stages,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/5c70f57a-715c-473e-9ab2-229d29a90acb



### To Reproduce

1. New Question > Orders
2. Add an aggregation and a breakout
3. In another stage add an aggregation and a breakout 
4. Remove the filter step
5. Remove the first summarize step

:x: Notebook editor shows 2 filter buttons, 2 join buttons and 2 custom column buttons

6. Remove the remaining summarize step

:x:  Notebook editor shows 2 join buttons and 2 custom column buttons

### Information about your Metabase installation

master, 213b6d2c81


### Severity

P3
",kamilmielnik,2024-07-02 13:59:54+00:00,[],2025-02-04 20:27:14+00:00,,https://github.com/metabase/metabase/issues/45041,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2229083610, 'issue_id': 2386349873, 'author': 'ranquild', 'body': 'The issue here is that after calling `Lib.removeClause` on the inner aggregation clause we end up with a query that has 2 query stages:\r\n```\r\n{\r\n  ""source-query"": { ""source-table"": 1 },\r\n  ""aggregation"": [[""count""]]\r\n}\r\n```\r\n\r\nwhile it\'s a valid MBQL query, the FE generally doesn\'t expect this to happen. I believe it\'s unfair for the FE to expect this, so the lib could handle this case and convert this query to:\r\n```\r\n{\r\n  ""source-table"": 1\r\n  ""aggregation"": [[""count""]]\r\n}\r\n```', 'created_at': datetime.datetime(2024, 7, 15, 18, 1, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494739527, 'issue_id': 2386349873, 'author': 'cbalusek', 'body': 'test', 'created_at': datetime.datetime(2024, 11, 22, 20, 26, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494739909, 'issue_id': 2386349873, 'author': 'cbalusek', 'body': 'Duplicate of 45041', 'created_at': datetime.datetime(2024, 11, 22, 20, 26, 38, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-15 18:01:38 UTC): The issue here is that after calling `Lib.removeClause` on the inner aggregation clause we end up with a query that has 2 query stages:
```
{
  ""source-query"": { ""source-table"": 1 },
  ""aggregation"": [[""count""]]
}
```

while it's a valid MBQL query, the FE generally doesn't expect this to happen. I believe it's unfair for the FE to expect this, so the lib could handle this case and convert this query to:
```
{
  ""source-table"": 1
  ""aggregation"": [[""count""]]
}
```

cbalusek on (2024-11-22 20:26:23 UTC): test

cbalusek on (2024-11-22 20:26:38 UTC): Duplicate of 45041

"
2386183108,issue,open,,Multiple bucketing menus can be opened simultaneously,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/12ac64ef-d3d3-4874-b39f-6d46fa0b5e84)


### To Reproduce

1. Orders > Breakout
2. Hover over every item and click the binning picker


### Expected behavior

Only one binning picker should be opened at a time


### Information about your Metabase installation

master, 213b6d2c81


### Severity

P2
",kamilmielnik,2024-07-02 12:54:58+00:00,[],2025-02-04 20:27:32+00:00,,https://github.com/metabase/metabase/issues/45036,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2203088939, 'issue_id': 2386183108, 'author': 'kamilmielnik', 'body': 'Similar to #44910', 'created_at': datetime.datetime(2024, 7, 2, 12, 55, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203091731, 'issue_id': 2386183108, 'author': 'kamilmielnik', 'body': 'It worked in v48.7', 'created_at': datetime.datetime(2024, 7, 2, 12, 56, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220889881, 'issue_id': 2386183108, 'author': 'nemanjaglumac', 'body': ""Triaged the root cause to be: https://github.com/metabase/metabase/pull/40144/files#diff-53c7f193f8a41d505c4cae1b00fb7632af6327316adc156a052f111edcab234bR26\r\n\r\nIt affects other places in the app. I've added [E2E reproductions](https://github.com/metabase/metabase/pull/45369) that should help while working on the fix for this.\r\n\r\nMore context [in Slack](https://metaboat.slack.com/archives/C505ZNNH4/p1720527541628559)."", 'created_at': datetime.datetime(2024, 7, 10, 15, 50, 30, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-02 12:55:24 UTC): Similar to #44910

kamilmielnik (Issue Creator) on (2024-07-02 12:56:46 UTC): It worked in v48.7

nemanjaglumac on (2024-07-10 15:50:30 UTC): Triaged the root cause to be: https://github.com/metabase/metabase/pull/40144/files#diff-53c7f193f8a41d505c4cae1b00fb7632af6327316adc156a052f111edcab234bR26

It affects other places in the app. I've added [E2E reproductions](https://github.com/metabase/metabase/pull/45369) that should help while working on the fix for this.

More context [in Slack](https://metaboat.slack.com/archives/C505ZNNH4/p1720527541628559).

"
2385735702,issue,closed,completed,Track queries with tables that don't correspond to known `Table`s,,tsmacdonald,2024-07-02 09:26:58+00:00,['crisptrutski'],2024-08-02 14:44:04+00:00,2024-08-01 14:17:04+00:00,https://github.com/metabase/metabase/issues/45028,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2242597198, 'issue_id': 2385735702, 'author': 'crisptrutski', 'body': 'The plan to expose this data is to introduce a new `query_data_source` table which holds the name of the ""table"" and a nullable reference to `metabase_table`.\r\n\r\nFor future proofing to using models as sources as well, there will be a type column (`table` or `card`) and a nullable `card_id` field.\r\n\r\nThe query for the SQL validation should thus be checking `type == \'table\' AND table_id IS NULL`.', 'created_at': datetime.datetime(2024, 7, 22, 10, 14, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243234941, 'issue_id': 2385735702, 'author': 'crisptrutski', 'body': 'We should probably also differentiate between cases more finely.\r\n\r\nHere is the current behavior:\r\n\r\n _ | No such table | Table is inactive | Table is active\r\n--|--|--|--\r\nNo such field | *not detected* | *not detected* | *not detected*\r\nField is inactive | - | Field is inactive | Field is inactive\r\nField is active | - | - | âœ… \r\n\r\nI think that we should classify them as follows rather:\r\n\r\n _ | No such table | Table is inactive | Table is active\r\n--|--|--|--\r\nNo such field | _**Table not found**_ | _**Table is inactive**_ | _**Field not found**_\r\nField is inactive | - | _**Table is inactive**_ | Field is inactive\r\nField is active | - | - | âœ…', 'created_at': datetime.datetime(2024, 7, 22, 15, 26, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250655503, 'issue_id': 2385735702, 'author': 'crisptrutski', 'body': 'It\'s also important to consider the case where it\'s a naked table reference, e.g. ""SELECT COUNT(*)""\r\n\r\nI will probably handle this in a second pass.', 'created_at': datetime.datetime(2024, 7, 25, 15, 19, 38, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-07-22 10:14:27 UTC): The plan to expose this data is to introduce a new `query_data_source` table which holds the name of the ""table"" and a nullable reference to `metabase_table`.

For future proofing to using models as sources as well, there will be a type column (`table` or `card`) and a nullable `card_id` field.

The query for the SQL validation should thus be checking `type == 'table' AND table_id IS NULL`.

crisptrutski (Assginee) on (2024-07-22 15:26:19 UTC): We should probably also differentiate between cases more finely.

Here is the current behavior:

 _ | No such table | Table is inactive | Table is active
--|--|--|--
No such field | *not detected* | *not detected* | *not detected*
Field is inactive | - | Field is inactive | Field is inactive
Field is active | - | - | âœ… 

I think that we should classify them as follows rather:

 _ | No such table | Table is inactive | Table is active
--|--|--|--
No such field | _**Table not found**_ | _**Table is inactive**_ | _**Field not found**_
Field is inactive | - | _**Table is inactive**_ | Field is inactive
Field is active | - | - | âœ…

crisptrutski (Assginee) on (2024-07-25 15:19:38 UTC): It's also important to consider the case where it's a naked table reference, e.g. ""SELECT COUNT(*)""

I will probably handle this in a second pass.

"
2385735556,issue,closed,completed,Track queries with columns that don't correspond to known `Field`s,See https://www.notion.so/metabase/Query-Validator-Backend-df75801389a1434c95139fa1227798bf for a discussion of the implementation ideas - we chose Option 5.,tsmacdonald,2024-07-02 09:26:54+00:00,['crisptrutski'],2024-08-02 14:44:10+00:00,2024-07-30 09:28:55+00:00,https://github.com/metabase/metabase/issues/45027,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2242641935, 'issue_id': 2385735556, 'author': 'crisptrutski', 'body': 'The essential part of the schema change is that `field_id` becomes nullable, and we add a `name` field so that we can make sense of these non-resolving rows.', 'created_at': datetime.datetime(2024, 7, 22, 10, 38, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242647617, 'issue_id': 2385735556, 'author': 'crisptrutski', 'body': ""It'll be important to filter out references that (could) point to cards rather than tables, to avoid false positives for bad references."", 'created_at': datetime.datetime(2024, 7, 22, 10, 41, 18, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-07-22 10:38:13 UTC): The essential part of the schema change is that `field_id` becomes nullable, and we add a `name` field so that we can make sense of these non-resolving rows.

crisptrutski (Assginee) on (2024-07-22 10:41:18 UTC): It'll be important to filter out references that (could) point to cards rather than tables, to avoid false positives for bad references.

"
2385735400,issue,closed,completed,Create EE-only REST endpoint for invalid cards,"Should use the general shape we use for all Card endpoints (specifically including name, author, updated_at, and the collection name) and additionally have something like this poked in:

```json
""errors"": {""fields"": [""TOTAL"", ""DEALS""],
           ""tables"": [""ORDERS""]}
```",tsmacdonald,2024-07-02 09:26:51+00:00,['tsmacdonald'],2024-07-15 11:49:07+00:00,2024-07-10 14:23:11+00:00,https://github.com/metabase/metabase/issues/45026,"[('.Team/Workflows', 'aka BEC')]",[],
2385627259,issue,open,,Visualization: Custom Image Heatmaps,"**Is your feature request related to a problem? Please describe.**
I find it challenging to visualize data on custom images, like mechanical parts. Metabase supports heatmaps with real-life maps using latitude and longitude, but there is no option to overlay heatmaps on custom images, which limits the ability to represent data in a context-specific manner for many applications.

**Describe the solution you'd like**
I would like Metabase to support creating heatmaps over custom images. This feature should allow users to upload custom images, place a grid overlay on these images, and map data points to specific grid cells.

**Describe alternatives you've considered**
An alternative would be to use external tools to create heatmaps on custom images. Unfortunately, you can't import these into Metabase, resulting in the need to check two different sites, which is inefficient and inconvenient.

**How important is this feature to you?**
This feature is very important as it would significantly enhance the ability to visualize and analyze data in context-specific scenarios.

**Additional context**
Below is an example image illustrating the desired functionality. In this example, a mechanical part is shown with specific areas highlighted using a heatmap. This feature would allow users to directly visualize problem areas on the part image.

![img](https://github.com/metabase/metabase/assets/138104893/875a254f-8229-44ad-a223-f12a4ba47dac)


â¬‡ï¸ Please click the ðŸ‘ reaction instead of leaving a `+1` or `update?` comment",domi-bue,2024-07-02 08:42:57+00:00,[],2025-02-04 20:30:27+00:00,,https://github.com/metabase/metabase/issues/45024,"[('Visualization/', ''), ('Type:New Feature', '')]",[],
2385572599,issue,closed,completed,"Uncaught ""Unknown type of ref"" when trying to link a new Dashboard Filter to a SQL-Question","### Describe the bug

After adding a new filter to a dashboard consisting of 3 Tabs, i wanted to link said filter to fields in some of the SQL-Questions. However selecting a field of one of the Questions has no effect on the GUI and instead throws an uncaught exception in the dev-console. The dashboard was initially created on an older version (0.48.x).

### To Reproduce

I was not able to reproduce the bug. As it seems, it only happens in that particular dashboard

### Expected behavior

The chosen field should be linked to the filter

### Logs

```
Uncaught (in promise) 
Object { message: ""Unknown type of ref"", data: {â€¦}, cause: null, name: ""Error"", description: undefined, number: undefined, fileName: ""https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js"", lineNumber: 259, columnNumber: 92509, stack: ""91930/n1.$h@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92509\n91930/n1.ai@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92814\n91930/n1.bi@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92771\nn@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:886094\ne@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:885175\nt@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:885669\n85463/d/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:967752\neX@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:61674\n91930/n1.g.fa@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:138330\n91930/n1.y@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:50551\n91930/n1.qe@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:62128\n85463/find_column_indexes_from_legacy_refs/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:983024\n71733/r.Q2@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:755673\nfind_column_indexes_from_legacy_refs@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:982698\neO@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:7:8726\nc@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:110014\n75262/eS</</</n<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59974\n75262/eS</</</u<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59992\n75262/eS</</<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:60108\n13043/a/</</<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:7:508677\ndispatch@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:139:23609\n75262/eS</<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59333\n80190/g/</n/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:228608\n13043/a/</</<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:7:508677\n40148/P/f</n[r]@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:106:5324\n7722/tn</Z<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:100197\nonChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:102340\nonChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:95185\nhandleChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:246:79177\n89513/S/t<.children<.onClick<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:246:73870\neZ@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:216041\ne1@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:216195\n83975/n5/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234101\nn5@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234200\nn4@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234616\n83975/rt/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:240277\neY@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315802\n83975/rt/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:236079\nrt@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:236109\nt$@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:223828\ntX@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:223057\n39666/t.unstable_runWithPriority@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:144:9011\nir@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244439\neB@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315544\ntF@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:222848\nEventListener.handleEvent*re@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:235532\nn9@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:235174\n83975/n7/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234867\nn7@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234836\n83975/a8/n<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:294555\na8@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:296393\na6@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290271\n83975/a4/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290080\na4@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290085\naK@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:287029\n83975/ia/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244665\n39666/t.unstable_runWithPriority@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:144:9011\nir@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244439\nia@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244613\nio@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244546\neB@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315598\ntF@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:222848\n"" }
â€‹
cause: null
â€‹
columnNumber: 92509
â€‹
data: Object { N: 1, C: 16647951, I: 401412, â€¦ }
â€‹
description: undefined
â€‹
fileName: ""https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js""
â€‹
lineNumber: 259
â€‹
message: ""Unknown type of ref""
â€‹
name: ""Error""
â€‹
number: undefined
â€‹
stack: ""91930/n1.$h@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92509\n91930/n1.ai@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92814\n91930/n1.bi@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:92771\nn@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:886094\ne@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:885175\nt@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:885669\n85463/d/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:967752\neX@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:61674\n91930/n1.g.fa@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:138330\n91930/n1.y@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:50551\n91930/n1.qe@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:62128\n85463/find_column_indexes_from_legacy_refs/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:983024\n71733/r.Q2@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:755673\nfind_column_indexes_from_legacy_refs@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:259:982698\neO@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:7:8726\nc@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:110014\n75262/eS</</</n<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59974\n75262/eS</</</u<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59992\n75262/eS</</<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:60108\n13043/a/</</<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:7:508677\ndispatch@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:139:23609\n75262/eS</<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:59333\n80190/g/</n/<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:228608\n13043/a/</</<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:7:508677\n40148/P/f</n[r]@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:106:5324\n7722/tn</Z<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:100197\nonChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:102340\nonChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:32:95185\nhandleChange@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:246:79177\n89513/S/t<.children<.onClick<@https://{{our metabase url}}/app/dist/app-main.dfd79efad72befa0fc5c.js:246:73870\neZ@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:216041\ne1@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:216195\n83975/n5/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234101\nn5@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234200\nn4@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234616\n83975/rt/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:240277\neY@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315802\n83975/rt/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:236079\nrt@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:236109\nt$@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:223828\ntX@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:223057\n39666/t.unstable_runWithPriority@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:144:9011\nir@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244439\neB@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315544\ntF@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:222848\nEventListener.handleEvent*re@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:235532\nn9@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:235174\n83975/n7/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234867\nn7@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:234836\n83975/a8/n<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:294555\na8@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:296393\na6@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290271\n83975/a4/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290080\na4@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:290085\naK@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:287029\n83975/ia/<@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244665\n39666/t.unstable_runWithPriority@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:144:9011\nir@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244439\nia@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244613\nio@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:244546\neB@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:315598\ntF@https://{{our metabase url}}/app/dist/vendor.30aa33f36fcc00be617e.js:83:222848\n""
â€‹
<prototype>: Object { pa: {}, da: da(e, t, n), toString: toString(), â€¦ }
5 utils.js:210:10

```

The server logs around this time contain no info on this issue as no requests where sent when selecting the field to link

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:127.0) Gecko/20100101 Firefox/127.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.7.4-200.fc39.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""mysql"",
      ""sparksql"",
      ""clickhouse"",
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.34-26""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v0.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

not very severe, it only affects one dashboard

### Additional context

_No response_",J-Reichardt,2024-07-02 08:17:58+00:00,[],2024-07-04 15:49:38+00:00,2024-07-04 15:49:37+00:00,https://github.com/metabase/metabase/issues/45022,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2203106066, 'issue_id': 2385572599, 'author': 'apostoltego', 'body': ""I'm getting the same. On an existing dashboard, linking a filter isn't working however for the same question on a brand new dashboard it works fine. Potentially related to migrations to 0.50.x? \r\n\r\nFurthermore, adding the same question to the dashboard again, the filter gets automatically mapped but when trying to map it manually the same error comes through. \r\nI'm on 0.50.8."", 'created_at': datetime.datetime(2024, 7, 2, 13, 3, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203495232, 'issue_id': 2385572599, 'author': 'nemanjaglumac', 'body': ""That is the exact same error we're seeing in https://github.com/metabase/metabase/issues/35954.\r\nThe potential fix is here: https://github.com/metabase/metabase/pull/44987\r\n\r\nBut I have to double-check that it covers all cases."", 'created_at': datetime.datetime(2024, 7, 2, 15, 14, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205304547, 'issue_id': 2385572599, 'author': 'nemanjaglumac', 'body': ""@J-Reichardt and @apostoltego [the fix](https://github.com/metabase/metabase/pull/44987) for the related issue has been merged to `master` and backported to the `release-x.50.x` branch. It'll go out in `x.50.10` release.\r\n\r\nOnce that happens, please let me know does that solve your issues as well. I suspect it might.\r\nOnce you confirm, we can close this issue.\r\n\r\nThanks\r\n\r\np.s. If you have dev environments and are eager to try this out before the release, you can check out the latest commit on the `release-x.50.x` branch."", 'created_at': datetime.datetime(2024, 7, 3, 7, 37, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208510178, 'issue_id': 2385572599, 'author': 'Tony-metabase', 'body': 'Confirmed from some customers the fix worked', 'created_at': datetime.datetime(2024, 7, 4, 9, 21, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208851815, 'issue_id': 2385572599, 'author': 'apostoltego', 'body': 'Hey @Tony-metabase  I\'ve just updated to 0.50.10 and tried to map a filter to a SQL question and I\'m getting exactly the same behaviour as previously with the same console error. \r\n\r\n<img width=""983"" alt=""Screenshot 2024-07-04 at 15 26 04"" src=""https://github.com/metabase/metabase/assets/16501677/207c65fd-06a8-408f-b251-738788978011"">', 'created_at': datetime.datetime(2024, 7, 4, 12, 26, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208869534, 'issue_id': 2385572599, 'author': 'Tony-metabase', 'body': 'Can you share the Admin -> Troubleshooting -> Diagnostic Info ... Just in case can you try in incognito as well. I had 2 reports from different users that it worked but could be there is something else we are missing hre', 'created_at': datetime.datetime(2024, 7, 4, 12, 34, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209198498, 'issue_id': 2385572599, 'author': 'apostoltego', 'body': 'Just tried incognito - it worked. Should\'ve tried that before replying here but thank you for the prompt instructions. \r\n\r\nDiagnostics just in case they\'re useful for any validation work:\r\n\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""en-GB"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.23+9"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.23"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.23+9"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""5.10.216-204.855.amzn2.x86_64"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""UTC""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres"",\r\n      ""clickhouse""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""13.10 (Ubuntu 13.10-1.pgdg22.04+1)""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.3""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""version"": {\r\n      ""date"": ""2024-07-04"",\r\n      ""tag"": ""v0.50.10"",\r\n      ""hash"": ""49d9e46""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": ""UTC""\r\n    }\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 7, 4, 15, 6, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209268250, 'issue_id': 2385572599, 'author': 'Tony-metabase', 'body': ""Don't worry! Glad to hear it works ðŸ™  ... Caching plays funny tricks!!"", 'created_at': datetime.datetime(2024, 7, 4, 15, 49, 37, tzinfo=datetime.timezone.utc)}]","apostoltego on (2024-07-02 13:03:42 UTC): I'm getting the same. On an existing dashboard, linking a filter isn't working however for the same question on a brand new dashboard it works fine. Potentially related to migrations to 0.50.x? 

Furthermore, adding the same question to the dashboard again, the filter gets automatically mapped but when trying to map it manually the same error comes through. 
I'm on 0.50.8.

nemanjaglumac on (2024-07-02 15:14:24 UTC): That is the exact same error we're seeing in https://github.com/metabase/metabase/issues/35954.
The potential fix is here: https://github.com/metabase/metabase/pull/44987

But I have to double-check that it covers all cases.

nemanjaglumac on (2024-07-03 07:37:38 UTC): @J-Reichardt and @apostoltego [the fix](https://github.com/metabase/metabase/pull/44987) for the related issue has been merged to `master` and backported to the `release-x.50.x` branch. It'll go out in `x.50.10` release.

Once that happens, please let me know does that solve your issues as well. I suspect it might.
Once you confirm, we can close this issue.

Thanks

p.s. If you have dev environments and are eager to try this out before the release, you can check out the latest commit on the `release-x.50.x` branch.

Tony-metabase on (2024-07-04 09:21:37 UTC): Confirmed from some customers the fix worked

apostoltego on (2024-07-04 12:26:43 UTC): Hey @Tony-metabase  I've just updated to 0.50.10 and tried to map a filter to a SQL question and I'm getting exactly the same behaviour as previously with the same console error. 

<img width=""983"" alt=""Screenshot 2024-07-04 at 15 26 04"" src=""https://github.com/metabase/metabase/assets/16501677/207c65fd-06a8-408f-b251-738788978011"">

Tony-metabase on (2024-07-04 12:34:17 UTC): Can you share the Admin -> Troubleshooting -> Diagnostic Info ... Just in case can you try in incognito as well. I had 2 reports from different users that it worked but could be there is something else we are missing hre

apostoltego on (2024-07-04 15:06:39 UTC): Just tried incognito - it worked. Should've tried that before replying here but thank you for the prompt instructions. 

Diagnostics just in case they're useful for any validation work:

```
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.216-204.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.10 (Ubuntu 13.10-1.pgdg22.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```

Tony-metabase on (2024-07-04 15:49:37 UTC): Don't worry! Glad to hear it works ðŸ™  ... Caching plays funny tricks!!

"
2385508749,issue,closed,not_planned,[Flaky Test]: collection-items-include-here-and-below-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:17+00:00,[],2024-12-13 16:43:43+00:00,2024-12-13 16:43:43+00:00,https://github.com/metabase/metabase/issues/45021,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508699,issue,closed,not_planned,[Flaky Test]: collection-items-include-datasets-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:16+00:00,[],2024-12-13 16:43:43+00:00,2024-12-13 16:43:43+00:00,https://github.com/metabase/metabase/issues/45020,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508663,issue,closed,not_planned,[Flaky Test]: collection-items-include-authority-level-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:15+00:00,[],2024-12-13 16:43:42+00:00,2024-12-13 16:43:42+00:00,https://github.com/metabase/metabase/issues/45019,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508629,issue,closed,not_planned,[Flaky Test]: collection-items-children-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:14+00:00,[],2024-12-13 16:43:42+00:00,2024-12-13 16:43:42+00:00,https://github.com/metabase/metabase/issues/45018,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508577,issue,closed,not_planned,[Flaky Test]: collection-items-archived-parameter-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:12+00:00,[],2024-12-13 16:43:42+00:00,2024-12-13 16:43:42+00:00,https://github.com/metabase/metabase/issues/45017,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508529,issue,closed,not_planned,[Flaky Test]: cards-and-dashboards-get-can-write,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:11+00:00,[],2024-12-13 16:43:41+00:00,2024-12-13 16:43:41+00:00,https://github.com/metabase/metabase/issues/45016,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508481,issue,closed,not_planned,[Flaky Test]: archive-collection-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:10+00:00,[],2024-12-13 16:43:41+00:00,2024-12-13 16:43:41+00:00,https://github.com/metabase/metabase/issues/45015,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508444,issue,closed,not_planned,[Flaky Test]: archive-collection-perms-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9739528594
Last Flake Time: 2024-07-01T00:32:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-02 07:51:09+00:00,[],2024-12-13 16:43:40+00:00,2024-12-13 16:43:40+00:00,https://github.com/metabase/metabase/issues/45014,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2385508378,issue,closed,completed,[Flaky Test]: should not clip dashcard actions (metabase#31274),"Last Flake: https://github.com/metabase/metabase/actions/runs/9741172020
Last Flake Time: 2024-07-01T02:22:00-07:00
Flakes in the last day: 2
Flakes in the last 3d: 2
Flakes in the last 7d: 10",github-automation-metabase,2024-07-02 07:51:08+00:00,['kamilmielnik'],2024-11-06 16:29:02+00:00,2024-11-06 15:44:36+00:00,https://github.com/metabase/metabase/issues/45013,"[('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2385348788,issue,closed,completed,Parallelize slower driver tests,"I [tried](https://github.com/metabase/metabase/pull/45392) splitting tests up using simple path filtering using `:only` and `:exclude` directories. This didn't work because of some [limitations](https://github.com/metabase/hawk#excluding-directories) in :exclude-directories.

The right way to handle this is likely to update hawk to support batching tests. (see [thread](https://metaboat.slack.com/archives/CKZEMT1MJ/p1720731827221419))",iethree,2024-07-02 06:27:43+00:00,[],2024-11-26 18:52:48+00:00,2024-10-08 19:11:29+00:00,https://github.com/metabase/metabase/issues/45009,"[('.CI & Tests', '')]",[],
2384917661,issue,open,,Latitude and longitude fields don't have binning on MongoDB,"### Describe the bug

fields that have latitude and longitude simply don't bin on MongoDB
![image](https://github.com/metabase/metabase/assets/1711649/0aef277f-2f21-4fb8-a11e-016eb240f974)

### To Reproduce

1) add MongoDB to Metabase
2) ensure that latitude and longitude have semantic types
3) try making a grid map with the people table

### Expected behavior

It should work in the same way as in the rest of the tables

### Logs

NA

### Information about your Metabase installation

```JSON
it has always been like that, I believe
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-07-01 23:40:18+00:00,[],2025-02-04 20:27:35+00:00,,https://github.com/metabase/metabase/issues/45005,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/', ''), ('.Team/Querying', '')]",[],
2384868549,issue,closed,completed,Recents selection context gets diluted by recently viewed items.,"### Describe the bug

> When I open the data picker in the query builder I expect to see in Recents only stuff that I recently picked there, and nothing else.

---

We can achieve this by removing the `context=views` query parameter from the `api/actions/recents` api call used to populate the data picker.

### To Reproduce

1. Have some recent views (you can view them by hitting Cmd+K). Make some recent views by viewing ~5 collections, dashboards, cards, models, and/or tables.
2. New > Question > select something. This is the recent item that you should see as first, next time you open the data-picker.
3. Make some more recent *views* by viewing ~5 collections, dashboards, cards, models, and/or tables.
5. You will see recently _viewed_ items, not ones that you recently picked using the datapicker.


### Expected behavior

We ought to show only recent items that were recently picked there, and either nothing else, or sort the selected items first. 

Currently that view is sorted by timestamp of the most-recent view.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21+35-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21+35-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.3"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""valid-thru"": ""2025-01-01T12:00:00Z"",
    ""current-user-count"": 4,
    ""application-database"": ""postgres"",
    ""settings"": {
      ""report-timezone"": null
    },
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""max-users"": 7,
    ""hosting-env"": ""unknown"",
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-06-27"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""2d911b9""
    },
  }
}
```


### Severity

P2

### Additional context

_No response_",escherize,2024-07-01 22:52:43+00:00,['npfitz'],2024-08-23 18:54:28+00:00,2024-08-08 14:57:12+00:00,https://github.com/metabase/metabase/issues/45003,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2271625998, 'issue_id': 2384868549, 'author': 'iethree', 'body': 'note: in order for the frontend to log models as recents, we need to fix the backend api: we should accept `dataset` as the model for models, not `model` ðŸ¥´', 'created_at': datetime.datetime(2024, 8, 6, 15, 55, 54, tzinfo=datetime.timezone.utc)}]","iethree on (2024-08-06 15:55:54 UTC): note: in order for the frontend to log models as recents, we need to fix the backend api: we should accept `dataset` as the model for models, not `model` ðŸ¥´

"
2384718852,issue,open,,Change the documentation regarding the exp key in the embedding,"We need to replace everywhere it says that there's an ""exp"" key that can be modified in the JWT SSO to changing the expiration via mb_max_session_age and mb_session_timeout env vars

taken from our internal metabase repository after seeing that the exp property issue was not an issue in the end",paoliniluis,2024-07-01 20:53:10+00:00,['jeff-bruemmer'],2025-02-04 20:31:08+00:00,,https://github.com/metabase/metabase/issues/44998,"[('Type:Documentation', '')]",[],
2384657371,issue,open,,Help Admins Identify Duplicate Cards for Cleanup / Make It Easier for Users to Identify Existing Content,"**Is your feature request related to a problem? Please describe.**
Users will sometimes not search Metabase before creating questions, which results in them making their own version of a question that already exists. Especially when there are a lot of active users, this creates many duplicate questions. Admins would like a way to be able to triage these duplicate questions and then clean up the ones that are not needed.


**Describe the solution you'd like**
Add a report in Metabase Analytics that highlights duplicate questions to triage.

A cool (far in the future) feature would be to suggest existing content for the user to look at based on the query they've started building and/or before saving a question Metabase could pop up similar questions that already exist to deter users from saving duplicates. 


**Describe alternatives you've considered**
- Guiding users to review an official collection with verified questions before creating their own questions. 
- Reminding users to search before creating questions. ",jessicaul,2024-07-01 20:15:33+00:00,[],2025-02-04 20:30:30+00:00,,https://github.com/metabase/metabase/issues/44997,"[('Type:New Feature', ''), ('Organization/', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2384554967,issue,closed,completed,Add analytics context for API requests made by Embedding SDK,"**Context**
We are developing an embedding SDK for React and we want to track its adoption and usage by customers.

Product doc: https://www.notion.so/metabase/Analytics-for-the-React-embedding-SDK-255c976aad364db78339bc983cc88cf1

### Task
We want to see which queries have been made using the Embedding SDK in `Metabase analytics` / `Query log` table.
For that [we have added](https://github.com/metabase/metabase/pull/45059) a separate header `X-Metabase-Client` which would be equal `embedding-sdk-react` for all API requests from the SDK.

### Possible approach to achieve the solution:

1. I think we need a separate column in Query log to track sdk / regular app (default) query client.
OR
2. We can add a set of new values for the existing `Query Source` column:
- ad-hoc (sdk)
- collection (sdk) 
- csv-download (sdk)
- dashboard (sdk)
- question (sdk)
",deniskaber,2024-07-01 19:08:47+00:00,['deniskaber'],2024-07-30 12:27:01+00:00,2024-07-30 09:49:45+00:00,https://github.com/metabase/metabase/issues/44994,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2251363001, 'issue_id': 2384554967, 'author': 'escherize', 'body': 'I think the BE portion of this task has been completed. That work has merged to master, so I will unassign myself now, let me know if I can help with anything for it, @deniskaber', 'created_at': datetime.datetime(2024, 7, 25, 20, 43, 57, tzinfo=datetime.timezone.utc)}]","escherize on (2024-07-25 20:43:57 UTC): I think the BE portion of this task has been completed. That work has merged to master, so I will unassign myself now, let me know if I can help with anything for it, @deniskaber

"
2384528930,issue,open,,Give me reference to Timezone or next fire while setting up an Alert,"**Is your feature request related to a problem? Please describe.**
I never know the timezone when setting up an alert and it makes me feel sad

**Describe the solution you'd like**
Some reference to timezone in the Alert setting (if it's the user timezone, that would be the ideal thing)

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Little but nice improvement

**Additional context**
Internal discussion here: 

",ignacio-mb,2024-07-01 18:54:00+00:00,[],2024-07-01 18:54:00+00:00,,https://github.com/metabase/metabase/issues/44992,"[('Type:New Feature', ''), ('Misc/Timezones', ''), ('Reporting/Alerts', '')]",[],
2384193199,issue,closed,completed,"can't click non-other slice with name ""Other""",,EmmadUsmani,2024-07-01 15:53:59+00:00,['EmmadUsmani'],2024-07-01 17:49:30+00:00,2024-07-01 17:49:27+00:00,https://github.com/metabase/metabase/issues/44988,[],"[{'comment_id': 2200708968, 'issue_id': 2384193199, 'author': 'EmmadUsmani', 'body': 'Fixed by https://github.com/metabase/metabase/pull/43555/commits/4bed6e2a9613292a4a8fcfecd0515134f307b6fd', 'created_at': datetime.datetime(2024, 7, 1, 17, 49, 27, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-07-01 17:49:27 UTC): Fixed by https://github.com/metabase/metabase/pull/43555/commits/4bed6e2a9613292a4a8fcfecd0515134f307b6fd

"
2384067414,issue,open,,Inconsistency between how we display information icons in dashbaords for number and other cards,"### Describe the bug

The Number card has a different display of the information icon (i) in dashoards. This makes things inconsistent and can make data accessibility harder for users, as the expected behavior is to see the information icon on every card as it shows on the number card.


In the following video, check out how the information icon (i) displays on the Number compared to the other cards. If you hover away from the number card, the icon remains, unlike the other chart types.
https://www.loom.com/share/87d88eacc13e457a8902e240dc82762a



### To Reproduce

1. Add a number card and other cards with a description to a dashboard


### Expected behavior

The expected behavior from a customer (internal ticket: [28483](https://metabase.zendesk.com/agent/tickets/28483) is that all cards in dashbaords, if they have a description, the information icon should appear and not have to hover over the card to see it.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 50.7
```


### Severity

P3

### Additional context

_No response_",ignacio-mb,2024-07-01 14:54:22+00:00,[],2024-07-25 16:22:15+00:00,,https://github.com/metabase/metabase/issues/44984,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2250876668, 'issue_id': 2384067414, 'author': 'use-tusk[bot]', 'body': 'I created a [pull request](https://github.com/metabase/metabase/pull/46152) for this issue. ðŸ§‘\u200dðŸ’»\n\nPlease approve and merge the PR once you\'ve verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I\'ll address it.', 'created_at': datetime.datetime(2024, 7, 25, 16, 21, 13, tzinfo=datetime.timezone.utc)}]","use-tusk[bot] on (2024-07-25 16:21:13 UTC): I created a [pull request](https://github.com/metabase/metabase/pull/46152) for this issue. ðŸ§‘â€ðŸ’»

Please approve and merge the PR once you've verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I'll address it.

"
2384064974,issue,closed,completed,OOM errors during fingerprinting,"### Describe the bug

Some customers have OOM errors during the fingerprinting step. This issue is just to track its investigation and the fix

[Context in slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719624233280609)

### To Reproduce

NA, yet

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
various
```


### Severity

high

### Additional context

_No response_",calherries,2024-07-01 14:53:30+00:00,['calherries'],2024-08-06 09:19:48+00:00,2024-07-23 09:18:36+00:00,https://github.com/metabase/metabase/issues/44983,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2222000106, 'issue_id': 2384064974, 'author': 'calherries', 'body': 'I expect this to be closed by https://github.com/metabase/metabase/pull/45160, but I will wait for confirmation from @ixipixi before closing', 'created_at': datetime.datetime(2024, 7, 11, 4, 25, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231144391, 'issue_id': 2384064974, 'author': 'ixipixi', 'body': 'We can confirm impacted cloud customers OOM errors resolve once 49.21 is cloud available.', 'created_at': datetime.datetime(2024, 7, 16, 15, 2, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243068580, 'issue_id': 2384064974, 'author': 'piranha', 'body': '@ixipixi any news on that front? :)', 'created_at': datetime.datetime(2024, 7, 22, 14, 12, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243166217, 'issue_id': 2384064974, 'author': 'ixipixi', 'body': ""@piranha this knocked out a sizable number of instances with OOM errors. There are still more OOM instances but I spot checked the 10 of the 15 and they appear to be mostly sync related. None of them appear to be fingerprint related. So I think we're good to close this one! Cal opened another one specific to the sync issues: https://github.com/metabase/metabase/issues/45163"", 'created_at': datetime.datetime(2024, 7, 22, 14, 55, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244690014, 'issue_id': 2384064974, 'author': 'calherries', 'body': 'Great news. Thanks', 'created_at': datetime.datetime(2024, 7, 23, 9, 18, 36, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-07-11 04:25:07 UTC): I expect this to be closed by https://github.com/metabase/metabase/pull/45160, but I will wait for confirmation from @ixipixi before closing

ixipixi on (2024-07-16 15:02:39 UTC): We can confirm impacted cloud customers OOM errors resolve once 49.21 is cloud available.

piranha on (2024-07-22 14:12:55 UTC): @ixipixi any news on that front? :)

ixipixi on (2024-07-22 14:55:40 UTC): @piranha this knocked out a sizable number of instances with OOM errors. There are still more OOM instances but I spot checked the 10 of the 15 and they appear to be mostly sync related. None of them appear to be fingerprint related. So I think we're good to close this one! Cal opened another one specific to the sync issues: https://github.com/metabase/metabase/issues/45163

calherries (Issue Creator) on (2024-07-23 09:18:36 UTC): Great news. Thanks

"
2383912786,issue,closed,completed,[Epic] REST API for the Query Validator,"**Links**
- [product doc](https://www.notion.so/metabase/Query-validator-a8981d498f324da5acf9284e7d7ba2f6)
- [eng doc](https://www.notion.so/df75801389a1434c95139fa1227798bf?pvs=25)

**Implementation Plan**

## Milestone 1

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/45026
- [ ] https://github.com/metabase/metabase/issues/45673
- [ ] https://github.com/metabase/metabase/issues/45756
- [ ] #43516
- [x] [Allow filtering endpoint by collection](https://github.com/metabase/metabase/pull/46024)
- [x] [Add effective_ancestors to the response to populate the collection breadcrumb](https://github.com/metabase/metabase/pull/46024)
```

### Deferred
-  https://github.com/metabase/metabase/issues/45552

## Milestone 2

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/45971
- [ ] https://github.com/metabase/metabase/issues/45027
- [ ] https://github.com/metabase/metabase/issues/45028
```",tsmacdonald,2024-07-01 13:48:09+00:00,"['tsmacdonald', 'crisptrutski']",2024-08-02 14:43:06+00:00,2024-08-02 08:01:59+00:00,https://github.com/metabase/metabase/issues/44976,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]",[],
2383892969,issue,closed,completed,Entity picker surfaces questions that are not valid joins,"### Describe the bug

_Arakaki comment: this is not only about recents, the collection navigation also shows questions and models in other databases ([context](https://metaboat.slack.com/archives/C0645JP1W81/p1720027645702959))_ 

When joining data in a table, the entity picker surfaces recent questions and models from different databases. 

Until we have https://github.com/metabase/metabase/issues/3953, that is always going to lead to errors, [so as @mazameli mentioned](https://github.com/metabase/metabase/issues/38989#issuecomment-2070982901), it would be better to now show these suggestions in the entity picker at all when joining.

### To Reproduce

1. Set up two databases (locally the sample database and Postgres will work for example)
2. Create a new question in the Postgres database (details do not matter) and save it as ""Question A""
3. Create a new question that has a table from the Sample database as source
4. Click Join
5. The entity picker shows ""Question A"" under the ""Recents"" tab

For this issue to come up it seems like both databases need to have questions in the recents tab.

### Expected behavior

Questions, models and tables that would result in invalid joins should not be shown in the entity picker for joins.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:127.0) Gecko/20100101 Firefox/127.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.20.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.20.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.20.1+1"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.2.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Amsterdam""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-06-28"",
      ""src_hash"": ""af14ffe6d342f2c32114b0cac8d56b060c3bcd29"",
      ""tag"": ""v1.1.15-SNAPSHOT"",
      ""hash"": ""da0c9cb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

This issue is a follow up for https://github.com/metabase/metabase/issues/38989",romeovs,2024-07-01 13:39:52+00:00,['iethree'],2024-07-20 01:37:50+00:00,2024-07-19 15:46:29+00:00,https://github.com/metabase/metabase/issues/44974,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Organization/', ''), ('.Frontend', ''), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2206975640, 'issue_id': 2383892969, 'author': 'ranquild', 'body': 'Caused by https://github.com/metabase/metabase/pull/29698\r\n\r\nhttps://github.com/metabase/metabase/pull/29698/files#diff-2dc4d6ebb8cf3c4a3003c7b94201d62cd7f31e09239c00a28d3d984ce75acd52L55', 'created_at': datetime.datetime(2024, 7, 3, 18, 45, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229590824, 'issue_id': 2383892969, 'author': 'iethree', 'body': 'FWIW, this has existed since v47, though in v47, we had a better error message\r\n\r\nv50 | v47\r\n---|---\r\n![Screen Shot 2024-07-15 at 4 57 48 PM](https://github.com/user-attachments/assets/b926db94-edcb-4140-a4b6-de1decbf59aa) | ![Screen Shot 2024-07-15 at 4 38 41 PM](https://github.com/user-attachments/assets/cbde1f0c-f51e-4d15-9d4c-9fda38653d44)', 'created_at': datetime.datetime(2024, 7, 15, 23, 2, 10, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-03 18:45:31 UTC): Caused by https://github.com/metabase/metabase/pull/29698

https://github.com/metabase/metabase/pull/29698/files#diff-2dc4d6ebb8cf3c4a3003c7b94201d62cd7f31e09239c00a28d3d984ce75acd52L55

iethree (Assginee) on (2024-07-15 23:02:10 UTC): FWIW, this has existed since v47, though in v47, we had a better error message

v50 | v47
---|---
![Screen Shot 2024-07-15 at 4 57 48 PM](https://github.com/user-attachments/assets/b926db94-edcb-4140-a4b6-de1decbf59aa) | ![Screen Shot 2024-07-15 at 4 38 41 PM](https://github.com/user-attachments/assets/cbde1f0c-f51e-4d15-9d4c-9fda38653d44)

"
2383815452,issue,closed,completed,Deleted dashboards show up in the entity picker,"### Describe the bug

Dashboards that are in ""Trash"" (archived) or even the ones that are permanently deleted will still show up in an entity picker.
At first, I thought this was only a cache problem, but even the hard refresh doesn't help. So it might be an actual flaw in the logic.

### To Reproduce

1. Create a new dashoard
2. Then ""trash"" it.

From here we have two ways to reproduce this and both should be covered in an E2E test.
1. Create a new question
2. Save it
3. Modal will ask you to 

or

1. Open an existing question
2. Click on `...` menu and click on ""Add to dashboard""

### Expected behavior

We should never show archived or deleted items in the entity picker.

### Logs

`GET http://localhost:3000/api/activity/most_recently_viewed_dashboard 404 (Not Found)`

### Information about your Metabase installation

local dev, `master`, 781c948, H2, Sample Database


### Severity

P2, but I'm closer to give this a P1 because the ""common feature"" is broken

### Additional context

_No response_",nemanjaglumac,2024-07-01 13:10:02+00:00,['npfitz'],2024-09-30 16:03:58+00:00,2024-09-30 16:03:58+00:00,https://github.com/metabase/metabase/issues/44973,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2315298992, 'issue_id': 2383815452, 'author': 'npfitz', 'body': ""I'll confirm with @escherize , but I believe there was some BE work done to remove archived items from recents in the not-too-distant past. I'm unable to reproduce on `master` or on `50.20`"", 'created_at': datetime.datetime(2024, 8, 28, 13, 18, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383605677, 'issue_id': 2383815452, 'author': 'escherize', 'body': ""I also was unable to reproduce. I think it got fixed by [Don't return an archived dashboard as the most recently viewed dashboard](https://github.com/metabase/metabase/pull/45229)."", 'created_at': datetime.datetime(2024, 9, 30, 16, 3, 58, tzinfo=datetime.timezone.utc)}]","npfitz (Assginee) on (2024-08-28 13:18:40 UTC): I'll confirm with @escherize , but I believe there was some BE work done to remove archived items from recents in the not-too-distant past. I'm unable to reproduce on `master` or on `50.20`

escherize on (2024-09-30 16:03:58 UTC): I also was unable to reproduce. I think it got fixed by [Don't return an archived dashboard as the most recently viewed dashboard](https://github.com/metabase/metabase/pull/45229).

"
2383569041,issue,open,,Jammy scrollbar in the Entity Picker Modal,"### Describe the bug

Affects all tabs (recents, search, etc.).
It's because the list is virtualized and estimated item size does not matches the actual item size.

https://github.com/metabase/metabase/assets/6830683/1f0a1566-9535-4ac6-aee9-8ebf80d01db3



### To Reproduce

1. Open Entity Picker Modal
2. Open a list of entities that has enough items to be vertically scrollable

### Expected behavior

`scrollHeight` should be constant

### Information about your Metabase installation

master. 44427fb61d


### Severity

P3
",kamilmielnik,2024-07-01 11:19:24+00:00,[],2025-02-04 20:26:44+00:00,,https://github.com/metabase/metabase/issues/44966,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Entity picker', '')]","[{'comment_id': 2199890490, 'issue_id': 2383569041, 'author': 'kamilmielnik', 'body': 'When this issue is fixed please clean up [this block](https://github.com/metabase/metabase/pull/44965/files#diff-24e38b1692d063b0570aa526370606cec467c391051bbcb05a26935e5510a91bR420-R424) and leave only one `cy.get(""@schemasList"").scrollTo(""bottom"");`:', 'created_at': datetime.datetime(2024, 7, 1, 11, 24, 27, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-01 11:24:27 UTC): When this issue is fixed please clean up [this block](https://github.com/metabase/metabase/pull/44965/files#diff-24e38b1692d063b0570aa526370606cec467c391051bbcb05a26935e5510a91bR420-R424) and leave only one `cy.get(""@schemasList"").scrollTo(""bottom"");`:

"
2383325937,issue,closed,completed,Dashboard parameter values doesn't work in the static embed modal preview when the dashboard isn't published,"### Describe the bug


![image](https://github.com/metabase/metabase/assets/1937582/a5aae09b-f442-4519-9a58-960efec1a6ad)

`/preview_embed/*` endpoint is supposed to work without requiring the resource to be published.

I think the culprit might be this line
https://github.com/metabase/metabase/blob/44427fb61df5aca633d2a2aa0103457f10a656c2/src/metabase/api/embed/common.clj#L420

This util is used in the `preview_embed` as well that's why it throws this error. https://github.com/metabase/metabase/blob/44427fb61df5aca633d2a2aa0103457f10a656c2/src/metabase/api/preview_embed.clj#L62

### To Reproduce

I followed the repro here (https://github.com/metabase/metabase/issues/27643) using `Invoice` table from sample database since it contains a boolean field, but we could actually use any table. We just need the static embedded dashboard preview to call the parameter values endpoint. 

### Expected behavior

We should get the parameter values without having to publish the dashboard first.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-06-28"",
      ""src_hash"": ""58821c9b03182508a0baad8b060bcb4a219eba4a"",
      ""tag"": ""v1.1.15-SNAPSHOT"",
      ""hash"": ""578f5d3""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",WiNloSt,2024-07-01 09:28:59+00:00,[],2024-07-15 20:58:12+00:00,2024-07-10 23:45:23+00:00,https://github.com/metabase/metabase/issues/44962,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2208178706, 'issue_id': 2383325937, 'author': 'WiNloSt', 'body': 'Change team label to `.Team/DashViz` since https://github.com/metabase/metabase/issues/27643 also has the same label.', 'created_at': datetime.datetime(2024, 7, 4, 6, 2, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229421397, 'issue_id': 2383325937, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 58, 11, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-07-04 06:02:54 UTC): Change team label to `.Team/DashViz` since https://github.com/metabase/metabase/issues/27643 also has the same label.

github-actions[bot] on (2024-07-15 20:58:11 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2383240336,issue,closed,completed,Can't upgrade from 0.49.13 to 0.50.8,"### Describe the bug

I attempted to upgrade my Metabase, but the process failed. My current Metabase is functioning well in production mode.

### To Reproduce

1. On windows CLI as admin : 
```
set MB_DB_TYPE=mysql
set MB_DB_DBNAME=metabaseappdb
set MB_DB_PORT=3306
set MB_DB_USER=USER
set MB_DB_PASS=PASSWORD
set MB_DB_HOST=localhost
C:\Metabase>""C:\Program Files\Eclipse Adoptium\jre-11.0.23.9-hotspot\bin\java.exe"" -Dlogfile.path=C:\Metabase -jar metabase.jar
2024-07-01 10:32:00,848 INFO metabase.util :: Maximum memory available to JVM: 4,0 GB
2024-07-01 10:32:04,176 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-01 10:32:11,301 INFO driver.impl :: Registered abstract driver :sql
2024-07-01 10:32:11,317 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql])
2024-07-01 10:32:11,332 INFO metabase.util :: Load driver :sql-jdbc took 55,4 ms
2024-07-01 10:32:11,332 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc])
2024-07-01 10:32:11,567 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc])
2024-07-01 10:32:11,629 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc])
2024-07-01 10:32:13,989 INFO metabase.core ::
Metabase v0.50.8 (dc9e68b)

Copyright Â® 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-07-01 10:32:14,004 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-07-01 10:32:14,082 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000}

2024-07-01 10:32:14,129 ERROR metabase.core :: Metabase Initialization FAILED
java.io.IOException: Failed to bind to 0.0.0.0/0.0.0.0:3000
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:344)
        at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:304)
        at org.eclipse.jetty.server.Server.lambda$doStart$0(Server.java:402)
        at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(Unknown Source)
        at java.base/java.util.stream.ReferencePipeline$3$1.accept(Unknown Source)
        at java.base/java.util.stream.ReferencePipeline$2$1.accept(Unknown Source)
        at java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Unknown Source)
        at java.base/java.util.stream.AbstractPipeline.copyInto(Unknown Source)
        at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(Unknown Source)
        at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(Unknown Source)
        at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(Unknown Source)
        at java.base/java.util.stream.AbstractPipeline.evaluate(Unknown Source)
        at java.base/java.util.stream.ReferencePipeline.forEach(Unknown Source)
        at org.eclipse.jetty.server.Server.doStart(Server.java:398)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:93)
        at metabase.server$start_web_server_BANG_.invokeStatic(server.clj:120)
        at metabase.server$start_web_server_BANG_.invoke(server.clj:106)
        at metabase.core$start_normally.invokeStatic(core.clj:180)
        at metabase.core$start_normally.invoke(core.clj:176)
        at metabase.core$entrypoint.invokeStatic(core.clj:215)
        at metabase.core$entrypoint.doInvoke(core.clj:209)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at metabase.bootstrap.main(Unknown Source)
Caused by: java.net.BindException: Address already in use: bind
        at java.base/sun.nio.ch.Net.bind0(Native Method)
        at java.base/sun.nio.ch.Net.bind(Unknown Source)
        at java.base/sun.nio.ch.Net.bind(Unknown Source)
        at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(Unknown Source)
        at org.eclipse.jetty.server.ServerConnector.openAcceptChannel(ServerConnector.java:339)
        ... 32 more

C:\Metabase>
```



### Expected behavior

Metabase should be upgraded to 0.50.8


### Logs

_No response_

### Information about your Metabase installation

```JSON
Windows server 2016
MySQL 8
```


### Severity

I'm unable to upgrade my instance, so I can't benefit from new content, bug fixes, and features.

### Additional context

_No response_",vipera7,2024-07-01 08:50:56+00:00,[],2024-07-01 09:31:56+00:00,2024-07-01 09:30:19+00:00,https://github.com/metabase/metabase/issues/44961,"[('Operation/Environment variables', '')]","[{'comment_id': 2199595132, 'issue_id': 2383240336, 'author': 'Tony-metabase', 'body': 'The error is self explanatory:\r\n\r\nFailed to bind to 0.0.0.0/0.0.0.0:3000\r\n\r\nYou have another service which is binded to port 3000 ... You need to free that port first', 'created_at': datetime.datetime(2024, 7, 1, 8, 52, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199606712, 'issue_id': 2383240336, 'author': 'vipera7', 'body': 'Hello Tony,\r\n\r\nI freed the port (I forgot to stop my Metabase service first), and here is the log showing the failure:\r\n\r\n\r\n```\r\nC:\\Metabase>""C:\\Program Files\\Eclipse Adoptium\\jre-11.0.23.9-hotspot\\bin\\java.exe"" -Dlogfile.path=C:\\Metabase -jar metabase.jar\r\n2024-07-01 10:56:06,883 INFO metabase.util :: Maximum memory available to JVM: 4,0 GB\r\n2024-07-01 10:56:10,064 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-07-01 10:56:16,942 INFO driver.impl :: Registered abstract driver :sql\r\n2024-07-01 10:56:16,957 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql])\r\n2024-07-01 10:56:16,957 INFO metabase.util :: Load driver :sql-jdbc took 55,9 ms\r\n2024-07-01 10:56:16,957 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc])\r\n2024-07-01 10:56:17,192 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc])\r\n2024-07-01 10:56:17,254 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc])\r\n2024-07-01 10:56:19,754 INFO metabase.core ::\r\nMetabase v0.50.8 (dc9e68b)\r\n\r\nCopyright Â® 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-07-01 10:56:19,754 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\n2024-07-01 10:56:19,832 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\n {:port 3000}\r\n\r\n2024-07-01 10:56:19,895 INFO metabase.core :: Starting Metabase version v0.50.8 (dc9e68b) ...\r\n2024-07-01 10:56:19,911 INFO metabase.core :: System info:\r\n {""file.encoding"" ""Cp1252"",\r\n ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\n ""java.runtime.version"" ""11.0.23+9"",\r\n ""java.vendor"" ""Eclipse Adoptium"",\r\n ""java.vendor.url"" ""https://adoptium.net/"",\r\n ""java.version"" ""11.0.23"",\r\n ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\n ""java.vm.version"" ""11.0.23+9"",\r\n ""os.name"" ""Windows Server 2016"",\r\n ""os.version"" ""10.0"",\r\n ""user.language"" ""fr"",\r\n ""user.timezone"" ""Europe/Paris""}\r\n\r\n2024-07-01 10:56:19,911 INFO metabase.plugins :: Loading plugins in C:\\Metabase\\plugins...\r\n2024-07-01 10:56:20,129 ERROR middleware.log :: GET /api/health 503 3,4 ms (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.2}\r\n\r\n2024-07-01 10:56:20,426 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...\r\n2024-07-01 10:56:20,426 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,457 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...\r\n2024-07-01 10:56:20,457 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql])\r\n2024-07-01 10:56:20,457 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...\r\n2024-07-01 10:56:20,457 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,473 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...\r\n2024-07-01 10:56:20,473 INFO driver.impl :: Registered driver :druid\r\n2024-07-01 10:56:20,473 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :googleanalytics...\r\n2024-07-01 10:56:20,473 INFO driver.impl :: Registered driver :googleanalytics\r\n2024-07-01 10:56:20,489 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...\r\n2024-07-01 10:56:20,504 INFO driver.impl :: Registered driver :mongo\r\n2024-07-01 10:56:20,520 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can\'t ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.\r\n\r\n2024-07-01 10:56:20,520 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false\r\n2024-07-01 10:56:20,520 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]\r\n2024-07-01 10:56:20,536 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...\r\n2024-07-01 10:56:20,536 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,551 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...\r\n2024-07-01 10:56:20,551 INFO driver.impl :: Registered driver :redshift (parents: [:postgres])\r\n2024-07-01 10:56:20,582 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...\r\n2024-07-01 10:56:20,582 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,598 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...\r\n2024-07-01 10:56:20,598 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,614 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...\r\n2024-07-01 10:56:20,614 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like])\r\n2024-07-01 10:56:20,614 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...\r\n2024-07-01 10:56:20,614 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,629 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...\r\n2024-07-01 10:56:20,629 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc])\r\n2024-07-01 10:56:20,629 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can\'t ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.\r\n\r\n2024-07-01 10:56:20,629 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false\r\n2024-07-01 10:56:20,629 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]\r\n2024-07-01 10:56:20,645 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-07-01 10:56:20,645 INFO db.setup :: Verifying mysql Database Connection ...\r\n2024-07-01 10:56:21,661 ERROR middleware.log :: GET /api/health 503 375.9 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:22,661 ERROR middleware.log :: GET /api/health 503 300.7 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:23,661 ERROR middleware.log :: GET /api/health 503 332.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:24,661 ERROR middleware.log :: GET /api/health 503 298.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:25,661 ERROR middleware.log :: GET /api/health 503 314.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:26,661 ERROR middleware.log :: GET /api/health 503 257.5 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:27,661 ERROR middleware.log :: GET /api/health 503 287.4 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:28,661 ERROR middleware.log :: GET /api/health 503 277.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:29,661 ERROR middleware.log :: GET /api/health 503 307.9 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:30,661 ERROR middleware.log :: GET /api/health 503 275.0 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:31,661 ERROR middleware.log :: GET /api/health 503 284.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:32,661 ERROR middleware.log :: GET /api/health 503 304.9 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:33,661 ERROR middleware.log :: GET /api/health 503 415.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:34,661 ERROR middleware.log :: GET /api/health 503 556.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:35,661 ERROR middleware.log :: GET /api/health 503 308.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:36,661 ERROR middleware.log :: GET /api/health 503 282.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:37,653 ERROR middleware.log :: GET /api/health 503 290.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:38,653 ERROR middleware.log :: GET /api/health 503 287.4 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:39,653 ERROR middleware.log :: GET /api/health 503 359.7 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:40,654 ERROR middleware.log :: GET /api/health 503 422.5 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:41,654 ERROR middleware.log :: GET /api/health 503 285.7 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:42,656 ERROR middleware.log :: GET /api/health 503 278.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:43,656 ERROR middleware.log :: GET /api/health 503 276.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:44,656 ERROR middleware.log :: GET /api/health 503 278.4 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:45,656 ERROR middleware.log :: GET /api/health 503 326.7 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:46,656 ERROR middleware.log :: GET /api/health 503 335.3 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:47,656 ERROR middleware.log :: GET /api/health 503 316.9 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:48,656 ERROR middleware.log :: GET /api/health 503 305.8 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:49,656 ERROR middleware.log :: GET /api/health 503 307.5 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:50,656 ERROR middleware.log :: GET /api/health 503 292.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 10:56:50,921 ERROR metabase.core :: Metabase Initialization FAILED\r\nclojure.lang.ExceptionInfo: Unable to connect to Metabase mysql DB. {}\r\n        at metabase.db.setup$verify_db_connection$fn__53372.invoke(setup.clj:117)\r\n        at metabase.db.setup$verify_db_connection.invokeStatic(setup.clj:115)\r\n        at metabase.db.setup$verify_db_connection.invoke(setup.clj:107)\r\n        at metabase.db.setup$setup_db_BANG_$fn__53392$fn__53393.invoke(setup.clj:165)\r\n        at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)\r\n        at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)\r\n        at metabase.db.setup$setup_db_BANG_$fn__53392.invoke(setup.clj:161)\r\n        at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)\r\n        at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)\r\n        at metabase.db$setup_db_BANG_$fn__53417.invoke(db.clj:82)\r\n        at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)\r\n        at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:421)\r\n        at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)\r\n        at metabase.core$init_BANG__STAR_.invoke(core.clj:98)\r\n        at metabase.core$init_BANG_.invokeStatic(core.clj:170)\r\n        at metabase.core$init_BANG_.invoke(core.clj:165)\r\n        at metabase.core$start_normally.invokeStatic(core.clj:182)\r\n        at metabase.core$start_normally.invoke(core.clj:176)\r\n        at metabase.core$entrypoint.invokeStatic(core.clj:215)\r\n        at metabase.core$entrypoint.doInvoke(core.clj:209)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:397)\r\n        at clojure.lang.AFn.applyToHelper(AFn.java:152)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n        at clojure.lang.Var.applyTo(Var.java:705)\r\n        at clojure.core$apply.invokeStatic(core.clj:667)\r\n        at clojure.core$apply.invoke(core.clj:662)\r\n        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)\r\n        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:397)\r\n        at clojure.lang.AFn.applyToHelper(AFn.java:152)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n        at metabase.bootstrap.main(Unknown Source)\r\nCaused by: java.sql.SQLException: Connections could not be acquired from the underlying database!\r\n        at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118)\r\n        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutPooledConnection(C3P0PooledConnectionPool.java:692)\r\n        at com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource.getConnection(AbstractPoolBackedDataSource.java:140)\r\n        at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372)\r\n        at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274)\r\n        at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111)\r\n        at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093)\r\n        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182)\r\n        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)\r\n        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160)\r\n        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)\r\n        at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:329)\r\n        at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:326)\r\n        at clojure.lang.Var.invoke(Var.java:384)\r\n        at metabase.db.setup$verify_db_connection$fn__53372.invoke(setup.clj:115)\r\n        ... 32 more\r\nCaused by: com.mchange.v2.resourcepool.CannotAcquireResourceException: A ResourcePool could not acquire a resource from its primary factory or source.\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.awaitAvailable(BasicResourcePool.java:1507)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.prelimCheckoutResource(BasicResourcePool.java:644)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.checkoutResource(BasicResourcePool.java:554)\r\n        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutAndMarkConnectionInUse(C3P0PooledConnectionPool.java:758)\r\n        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutPooledConnection(C3P0PooledConnectionPool.java:685)\r\n        ... 45 more\r\nCaused by: java.sql.SQLTransientConnectionException: Could not connect to address=(host=localhost)(port=3306)(type=master) : RSA public key is not available client side (option serverRsaPublicKeyFile not set)\r\n        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:79)\r\n        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:197)\r\n        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.connectWithoutProxy(AbstractConnectProtocol.java:1395)\r\n        at org.mariadb.jdbc.internal.util.Utils.retrieveProxy(Utils.java:635)\r\n        at org.mariadb.jdbc.MariaDbConnection.newConnection(MariaDbConnection.java:150)\r\n        at org.mariadb.jdbc.Driver.connect(Driver.java:89)\r\n        at java.sql/java.sql.DriverManager.getConnection(Unknown Source)\r\n        at java.sql/java.sql.DriverManager.getConnection(Unknown Source)\r\n        at metabase.db.data_source.DataSource.getConnection(data_source.clj:35)\r\n        at com.mchange.v2.c3p0.WrapperConnectionPoolDataSource.getPooledConnection(WrapperConnectionPoolDataSource.java:161)\r\n        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool$1PooledConnectionResourcePoolManager.acquireResource(C3P0PooledConnectionPool.java:213)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.doAcquire(BasicResourcePool.java:1176)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.doAcquireAndDecrementPendingAcquiresWithinLockOnSuccess(BasicResourcePool.java:1163)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool.access$700(BasicResourcePool.java:44)\r\n        at com.mchange.v2.resourcepool.BasicResourcePool$ScatteredAcquireTask.run(BasicResourcePool.java:1908)\r\n        at com.mchange.v2.async.ThreadPoolAsynchronousRunner$PoolThread.run(ThreadPoolAsynchronousRunner.java:696)\r\nCaused by: java.sql.SQLException: RSA public key is not available client side (option serverRsaPublicKeyFile not set)\r\n        at org.mariadb.jdbc.internal.com.send.authentication.CachingSha2PasswordPlugin.process(CachingSha2PasswordPlugin.java:189)\r\n        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.authenticationHandler(AbstractConnectProtocol.java:767)\r\n        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.createConnection(AbstractConnectProtocol.java:571)\r\n        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.connectWithoutProxy(AbstractConnectProtocol.java:1390)\r\n        ... 13 more\r\n2024-07-01 10:56:50,937 INFO metabase.core :: Metabase Shutting Down ...\r\n2024-07-01 10:56:50,937 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\n2024-07-01 10:56:50,953 WARN db.liquibase :: ()\r\n2024-07-01 10:56:50,953 INFO metabase.core :: Metabase Shutdown COMPLETE\r\n\r\nC:\\Metabase>\r\n```', 'created_at': datetime.datetime(2024, 7, 1, 8, 58, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199611023, 'issue_id': 2383240336, 'author': 'Tony-metabase', 'body': 'Now the error points to metabase not being able to connect to your App DB:\r\n\r\n`Unable to connect to Metabase mysql DB`\r\n\r\nHas nothing to do with 0.50.8 ... if you simply deploy 0.49.13 what happens? are you able to connect to the App DB?', 'created_at': datetime.datetime(2024, 7, 1, 9, 0, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199615414, 'issue_id': 2383240336, 'author': 'vipera7', 'body': ""But why is it failing to connect? I always use the same credentials, and I just tested themâ€”they work fine. I reverted my backup to version 0.49.13, and it's working again in this version."", 'created_at': datetime.datetime(2024, 7, 1, 9, 2, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199666027, 'issue_id': 2383240336, 'author': 'Tony-metabase', 'body': 'The only error pointed in the logs is the following:\r\n\r\n`Could not connect to address=(host=localhost)(port=3306)(type=master) : RSA public key is not available client side (option serverRsaPublicKeyFile not set)`\r\n\r\nWhat version of MYSQL are you running? And just to confirm you simply changed the version of the metabase.jar to the 49 and it loaded without issues?', 'created_at': datetime.datetime(2024, 7, 1, 9, 27, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199673069, 'issue_id': 2383240336, 'author': 'vipera7', 'body': 'I reran the same command, and the upgrade was successful. I didn\'t make any changes to the configuration or anything else; I simply executed it a second time.\r\n\r\nLog: \r\n\r\n```\r\nC:\\Metabase>""C:\\Program Files\\Eclipse Adoptium\\jre-11.0.23.9-hotspot\\bin\\java.exe"" -jar metabase.jar\r\n2024-07-01 11:19:05,805 INFO metabase.util :: Maximum memory available to JVM: 4,0 GB\r\n2024-07-01 11:19:09,039 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-07-01 11:19:16,430 INFO driver.impl :: Registered abstract driver :sql\r\n2024-07-01 11:19:16,430 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql])\r\n2024-07-01 11:19:16,445 INFO metabase.util :: Load driver :sql-jdbc took 58,1 ms\r\n2024-07-01 11:19:16,445 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc])\r\n2024-07-01 11:19:16,680 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc])\r\n2024-07-01 11:19:16,742 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc])\r\n2024-07-01 11:19:19,164 INFO metabase.core ::\r\nMetabase v0.50.8 (dc9e68b)\r\n\r\nCopyright Â® 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-07-01 11:19:19,180 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\n2024-07-01 11:19:19,226 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\n {:port 3000}\r\n\r\n2024-07-01 11:19:19,305 INFO metabase.core :: Starting Metabase version v0.50.8 (dc9e68b) ...\r\n2024-07-01 11:19:19,305 INFO metabase.core :: System info:\r\n {""file.encoding"" ""Cp1252"",\r\n ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\n ""java.runtime.version"" ""11.0.23+9"",\r\n ""java.vendor"" ""Eclipse Adoptium"",\r\n ""java.vendor.url"" ""https://adoptium.net/"",\r\n ""java.version"" ""11.0.23"",\r\n ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\n ""java.vm.version"" ""11.0.23+9"",\r\n ""os.name"" ""Windows Server 2016"",\r\n ""os.version"" ""10.0"",\r\n ""user.language"" ""fr"",\r\n ""user.timezone"" ""Europe/Paris""}\r\n\r\n2024-07-01 11:19:19,305 INFO metabase.plugins :: Loading plugins in C:\\Metabase\\plugins...\r\n2024-07-01 11:19:19,726 ERROR middleware.log :: GET /api/health 503 3,2 ms (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.2}\r\n\r\n2024-07-01 11:19:19,836 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...\r\n2024-07-01 11:19:19,836 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc])\r\n2024-07-01 11:19:19,867 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...\r\n2024-07-01 11:19:19,867 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql])\r\n2024-07-01 11:19:19,883 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...\r\n2024-07-01 11:19:19,883 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc])\r\n2024-07-01 11:19:19,883 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...\r\n2024-07-01 11:19:19,883 INFO driver.impl :: Registered driver :druid\r\n2024-07-01 11:19:19,898 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :googleanalytics...\r\n2024-07-01 11:19:19,898 INFO driver.impl :: Registered driver :googleanalytics\r\n2024-07-01 11:19:19,914 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...\r\n2024-07-01 11:19:19,914 INFO driver.impl :: Registered driver :mongo\r\n2024-07-01 11:19:19,914 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can\'t ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.\r\n\r\n2024-07-01 11:19:19,930 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false\r\n2024-07-01 11:19:19,930 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]\r\n2024-07-01 11:19:19,945 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...\r\n2024-07-01 11:19:19,945 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc])\r\n2024-07-01 11:19:19,961 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...\r\n2024-07-01 11:19:19,961 INFO driver.impl :: Registered driver :redshift (parents: [:postgres])\r\n2024-07-01 11:19:20,008 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...\r\n2024-07-01 11:19:20,008 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc])\r\n2024-07-01 11:19:20,023 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...\r\n2024-07-01 11:19:20,023 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc])\r\n2024-07-01 11:19:20,023 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...\r\n2024-07-01 11:19:20,023 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like])\r\n2024-07-01 11:19:20,039 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...\r\n2024-07-01 11:19:20,039 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc])\r\n2024-07-01 11:19:20,039 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...\r\n2024-07-01 11:19:20,039 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc])\r\n2024-07-01 11:19:20,055 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can\'t ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.\r\n\r\n2024-07-01 11:19:20,055 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false\r\n2024-07-01 11:19:20,055 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]\r\n2024-07-01 11:19:20,070 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-07-01 11:19:20,070 INFO db.setup :: Verifying mysql Database Connection ...\r\n2024-07-01 11:19:20,226 INFO db.setup :: Successfully verified MySQL 8.0.36 application database connection.\r\n2024-07-01 11:19:20,226 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-07-01 11:19:20,695 ERROR middleware.log :: GET /api/health 503 307.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:20,867 INFO db.setup :: Running Database Migrations...\r\n2024-07-01 11:19:20,867 INFO db.setup :: Setting up Liquibase...\r\n2024-07-01 11:19:21,039 INFO db.setup :: Liquibase is ready.\r\n2024-07-01 11:19:21,039 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-07-01 11:19:21,664 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...\r\n2024-07-01 11:19:21,680 ERROR middleware.log :: GET /api/health 503 319.5 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:21,695 INFO db.liquibase :: No migration lock found.\r\n2024-07-01 11:19:21,695 INFO db.liquibase :: Migration lock acquired.\r\n2024-07-01 11:19:21,976 INFO db.liquibase :: Running 96 migrations ...\r\n2024-07-01 11:19:22,680 ERROR middleware.log :: GET /api/health 503 340.0 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:23,681 ERROR middleware.log :: GET /api/health 503 324.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:24,681 ERROR middleware.log :: GET /api/health 503 280.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:25,681 ERROR middleware.log :: GET /api/health 503 345.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:22:51,165 ERROR middleware.log :: GET /api/health 503 313.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:20:31,052 ERROR middleware.log :: GET /api/health 503 519.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:20:06,564 ERROR middleware.log :: GET /api/health 503 371.2 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:19:32,492 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-07-01 11:23:08,585 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-07-01 11:23:08,585 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-07-01 11:23:08,601 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-07-01 11:23:08,601 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-07-01 11:23:08,617 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'BBS-SMAREP-Q0011719825788570\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-07-01 11:23:08,617 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-07-01 11:23:08,617 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-07-01 11:23:08,680 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.\r\n2024-07-01 11:23:08,689 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""BBS-SMAREP-Q0011719322507746""\'s failed in-progress jobs.\r\n2024-07-01 11:23:08,700 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 started.\r\n2024-07-01 11:23:08,730 INFO jdbcjobstore.JobStoreTX :: Handling 7 trigger(s) that missed their scheduled fire-time.\r\n2024-07-01 11:23:08,803 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 shutting down.\r\n2024-07-01 11:23:08,803 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 paused.\r\n2024-07-01 11:23:08,806 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 shutdown complete.\r\n2024-07-01 11:23:08,806 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade\r\n2024-07-01 11:23:08,822 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade\r\n2024-07-01 11:23:09,681 ERROR middleware.log :: GET /api/health 503 340.4 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:23:10,681 ERROR middleware.log :: GET /api/health 503 315.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:23:11,681 ERROR middleware.log :: GET /api/health 503 281.4 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:23:12,681 ERROR middleware.log :: GET /api/health 503 266.0 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:23:13,682 ERROR middleware.log :: GET /api/health 503 304.1 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n\r\nUPDATE SUMMARY\r\nRun:                         96\r\nPreviously run:             284\r\nFiltered out:                 6\r\n-------------------------------\r\nTotal change sets:          386\r\n\r\n\r\nFILTERED CHANGE SETS SUMMARY\r\nIgnored:                      1\r\nAlready ran:                  1\r\nDBMS mismatch:                5\r\n\r\n2024-07-01 11:23:14,680 ERROR middleware.log :: GET /api/health 503 407.6 Ãs (0 DB calls) {:metabase-user-id nil}\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-07-01 11:23:32,888 INFO db.liquibase :: Migration complete in 4.2 mins\r\n2024-07-01 11:23:32,904 INFO db.setup :: Database Migrations Current ...\r\n2024-07-01 11:23:32,904 INFO metabase.util :: Database setup took 4,2 mins\r\n2024-07-01 11:23:33,013 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-07-01 11:23:33,013 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-07-01 11:23:33,013 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-07-01 11:23:33,013 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-07-01 11:23:33,013 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-07-01 11:23:33,029 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'BBS-SMAREP-Q0011719825813013\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-07-01 11:23:33,029 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-07-01 11:23:33,029 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-07-01 11:23:33,201 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825813013 paused.\r\n2024-07-01 11:23:33,201 INFO metabase.task :: Task scheduler initialized into standby mode.\r\n2024-07-01 11:23:33,232 INFO metabase.task :: Initializing task Cache\r\n2024-07-01 11:23:33,232 INFO metabase.task :: Initializing task SyncDatabases\r\n2024-07-01 11:23:33,248 INFO task.sync-databases :: Updated default schedules for 0 databases\r\n2024-07-01 11:23:33,248 INFO metabase.task :: Initializing task PersistRefresh\r\n2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :sql...\r\n2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :sql-jdbc...\r\n2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :postgres...\r\n2024-07-01 11:23:33,310 INFO driver.impl :: Initializing driver :mysql...\r\n2024-07-01 11:23:33,357 INFO metabase.task :: Initializing task CheckForNewVersions\r\n2024-07-01 11:23:33,373 INFO metabase.task :: Initializing task PersistPrune\r\n2024-07-01 11:23:33,373 INFO metabase.task :: Initializing task SendAnonymousUsageStats\r\n2024-07-01 11:23:33,388 INFO metabase.task :: Initializing task ModelIndexValues\r\n2024-07-01 11:23:33,388 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers\r\n2024-07-01 11:23:33,420 INFO metabase.task :: Initializing task TruncateAuditTables\r\n2024-07-01 11:23:33,420 INFO metabase.task :: Initializing task SendPulses\r\n2024-07-01 11:23:33,435 INFO metabase.task :: Initializing task SendFollowUpEmails\r\n2024-07-01 11:23:33,451 INFO metabase.task :: Initializing task SendCreatorSentimentEmails\r\n2024-07-01 11:23:33,482 INFO metabase.task :: Initializing task SendLegacyNoSelfServiceEmail\r\n2024-07-01 11:23:33,482 INFO metabase.task :: Initializing task TaskHistoryCleanup\r\n2024-07-01 11:23:33,498 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail\r\n2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.\r\n2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""BBS-SMAREP-Q0011719825788570""\'s failed in-progress jobs.\r\n2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: ......Freed 1 acquired trigger(s).\r\n2024-07-01 11:23:33,513 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825813013 started.\r\n2024-07-01 11:23:33,545 INFO metabase.task :: Task scheduler started\r\n2024-07-01 11:23:33,560 INFO metabase.core :: Metabase Initialization COMPLETE in 4,6 mins\r\n2024-07-01 11:23:33,607 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.\r\n2024-07-01 11:23:33,920 DEBUG middleware.log :: GET /api/health 200 2,1 ms (0 DB calls) App DB connections: 1/4 Jetty threads: 4/50 (7 idle, 0 queued) (38 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n2024-07-01 11:23:34,068 INFO i18n.impl :: Reading available locales from locales.clj...\r\n2024-07-01 11:23:34,238 INFO util.fonts :: Reading available fonts from /frontend_client/app/fonts\r\n2024-07-01 11:23:35,579 DEBUG middleware.log :: GET /api/session/properties 200 142,6 ms (8 DB calls) App DB connections: 1/4 Jetty threads: 7/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n2024-07-01 11:23:35,821 DEBUG middleware.log :: GET /api/user/current 200 396,1 ms (11 DB calls) App DB connections: 0/4 Jetty threads: 6/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n2024-07-01 11:23:36,023 DEBUG middleware.log :: GET /api/collection/root 200 62,9 ms (2 DB calls) App DB connections: 1/4 Jetty threads: 8/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n```', 'created_at': datetime.datetime(2024, 7, 1, 9, 30, 20, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-07-01 08:52:28 UTC): The error is self explanatory:

Failed to bind to 0.0.0.0/0.0.0.0:3000

You have another service which is binded to port 3000 ... You need to free that port first

vipera7 (Issue Creator) on (2024-07-01 08:58:16 UTC): Hello Tony,

I freed the port (I forgot to stop my Metabase service first), and here is the log showing the failure:


```
C:\Metabase>""C:\Program Files\Eclipse Adoptium\jre-11.0.23.9-hotspot\bin\java.exe"" -Dlogfile.path=C:\Metabase -jar metabase.jar
2024-07-01 10:56:06,883 INFO metabase.util :: Maximum memory available to JVM: 4,0 GB
2024-07-01 10:56:10,064 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-01 10:56:16,942 INFO driver.impl :: Registered abstract driver :sql
2024-07-01 10:56:16,957 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql])
2024-07-01 10:56:16,957 INFO metabase.util :: Load driver :sql-jdbc took 55,9 ms
2024-07-01 10:56:16,957 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc])
2024-07-01 10:56:17,192 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc])
2024-07-01 10:56:17,254 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc])
2024-07-01 10:56:19,754 INFO metabase.core ::
Metabase v0.50.8 (dc9e68b)

Copyright Â® 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-07-01 10:56:19,754 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-07-01 10:56:19,832 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000}

2024-07-01 10:56:19,895 INFO metabase.core :: Starting Metabase version v0.50.8 (dc9e68b) ...
2024-07-01 10:56:19,911 INFO metabase.core :: System info:
 {""file.encoding"" ""Cp1252"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Windows Server 2016"",
 ""os.version"" ""10.0"",
 ""user.language"" ""fr"",
 ""user.timezone"" ""Europe/Paris""}

2024-07-01 10:56:19,911 INFO metabase.plugins :: Loading plugins in C:\Metabase\plugins...
2024-07-01 10:56:20,129 ERROR middleware.log :: GET /api/health 503 3,4 ms (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.2}

2024-07-01 10:56:20,426 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-07-01 10:56:20,426 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc])
2024-07-01 10:56:20,457 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-07-01 10:56:20,457 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql])
2024-07-01 10:56:20,457 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-07-01 10:56:20,457 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc])
2024-07-01 10:56:20,473 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-07-01 10:56:20,473 INFO driver.impl :: Registered driver :druid
2024-07-01 10:56:20,473 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :googleanalytics...
2024-07-01 10:56:20,473 INFO driver.impl :: Registered driver :googleanalytics
2024-07-01 10:56:20,489 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-07-01 10:56:20,504 INFO driver.impl :: Registered driver :mongo
2024-07-01 10:56:20,520 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-07-01 10:56:20,520 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-07-01 10:56:20,520 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]
2024-07-01 10:56:20,536 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-07-01 10:56:20,536 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc])
2024-07-01 10:56:20,551 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-07-01 10:56:20,551 INFO driver.impl :: Registered driver :redshift (parents: [:postgres])
2024-07-01 10:56:20,582 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-07-01 10:56:20,582 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc])
2024-07-01 10:56:20,598 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-07-01 10:56:20,598 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc])
2024-07-01 10:56:20,614 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-07-01 10:56:20,614 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like])
2024-07-01 10:56:20,614 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-07-01 10:56:20,614 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc])
2024-07-01 10:56:20,629 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-07-01 10:56:20,629 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc])
2024-07-01 10:56:20,629 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-07-01 10:56:20,629 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-07-01 10:56:20,629 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]
2024-07-01 10:56:20,645 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-01 10:56:20,645 INFO db.setup :: Verifying mysql Database Connection ...
2024-07-01 10:56:21,661 ERROR middleware.log :: GET /api/health 503 375.9 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:22,661 ERROR middleware.log :: GET /api/health 503 300.7 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:23,661 ERROR middleware.log :: GET /api/health 503 332.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:24,661 ERROR middleware.log :: GET /api/health 503 298.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:25,661 ERROR middleware.log :: GET /api/health 503 314.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:26,661 ERROR middleware.log :: GET /api/health 503 257.5 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:27,661 ERROR middleware.log :: GET /api/health 503 287.4 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:28,661 ERROR middleware.log :: GET /api/health 503 277.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:29,661 ERROR middleware.log :: GET /api/health 503 307.9 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:30,661 ERROR middleware.log :: GET /api/health 503 275.0 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:31,661 ERROR middleware.log :: GET /api/health 503 284.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:32,661 ERROR middleware.log :: GET /api/health 503 304.9 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:33,661 ERROR middleware.log :: GET /api/health 503 415.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:34,661 ERROR middleware.log :: GET /api/health 503 556.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:35,661 ERROR middleware.log :: GET /api/health 503 308.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:36,661 ERROR middleware.log :: GET /api/health 503 282.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:37,653 ERROR middleware.log :: GET /api/health 503 290.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:38,653 ERROR middleware.log :: GET /api/health 503 287.4 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:39,653 ERROR middleware.log :: GET /api/health 503 359.7 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:40,654 ERROR middleware.log :: GET /api/health 503 422.5 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:41,654 ERROR middleware.log :: GET /api/health 503 285.7 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:42,656 ERROR middleware.log :: GET /api/health 503 278.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:43,656 ERROR middleware.log :: GET /api/health 503 276.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:44,656 ERROR middleware.log :: GET /api/health 503 278.4 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:45,656 ERROR middleware.log :: GET /api/health 503 326.7 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:46,656 ERROR middleware.log :: GET /api/health 503 335.3 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:47,656 ERROR middleware.log :: GET /api/health 503 316.9 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:48,656 ERROR middleware.log :: GET /api/health 503 305.8 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:49,656 ERROR middleware.log :: GET /api/health 503 307.5 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:50,656 ERROR middleware.log :: GET /api/health 503 292.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 10:56:50,921 ERROR metabase.core :: Metabase Initialization FAILED
clojure.lang.ExceptionInfo: Unable to connect to Metabase mysql DB. {}
        at metabase.db.setup$verify_db_connection$fn__53372.invoke(setup.clj:117)
        at metabase.db.setup$verify_db_connection.invokeStatic(setup.clj:115)
        at metabase.db.setup$verify_db_connection.invoke(setup.clj:107)
        at metabase.db.setup$setup_db_BANG_$fn__53392$fn__53393.invoke(setup.clj:165)
        at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
        at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
        at metabase.db.setup$setup_db_BANG_$fn__53392.invoke(setup.clj:161)
        at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
        at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
        at metabase.db$setup_db_BANG_$fn__53417.invoke(db.clj:82)
        at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
        at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
        at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
        at metabase.core$init_BANG_.invokeStatic(core.clj:170)
        at metabase.core$init_BANG_.invoke(core.clj:165)
        at metabase.core$start_normally.invokeStatic(core.clj:182)
        at metabase.core$start_normally.invoke(core.clj:176)
        at metabase.core$entrypoint.invokeStatic(core.clj:215)
        at metabase.core$entrypoint.doInvoke(core.clj:209)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at metabase.bootstrap.main(Unknown Source)
Caused by: java.sql.SQLException: Connections could not be acquired from the underlying database!
        at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118)
        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutPooledConnection(C3P0PooledConnectionPool.java:692)
        at com.mchange.v2.c3p0.impl.AbstractPoolBackedDataSource.getConnection(AbstractPoolBackedDataSource.java:140)
        at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372)
        at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274)
        at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111)
        at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093)
        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182)
        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160)
        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
        at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:329)
        at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:326)
        at clojure.lang.Var.invoke(Var.java:384)
        at metabase.db.setup$verify_db_connection$fn__53372.invoke(setup.clj:115)
        ... 32 more
Caused by: com.mchange.v2.resourcepool.CannotAcquireResourceException: A ResourcePool could not acquire a resource from its primary factory or source.
        at com.mchange.v2.resourcepool.BasicResourcePool.awaitAvailable(BasicResourcePool.java:1507)
        at com.mchange.v2.resourcepool.BasicResourcePool.prelimCheckoutResource(BasicResourcePool.java:644)
        at com.mchange.v2.resourcepool.BasicResourcePool.checkoutResource(BasicResourcePool.java:554)
        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutAndMarkConnectionInUse(C3P0PooledConnectionPool.java:758)
        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool.checkoutPooledConnection(C3P0PooledConnectionPool.java:685)
        ... 45 more
Caused by: java.sql.SQLTransientConnectionException: Could not connect to address=(host=localhost)(port=3306)(type=master) : RSA public key is not available client side (option serverRsaPublicKeyFile not set)
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:79)
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:197)
        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.connectWithoutProxy(AbstractConnectProtocol.java:1395)
        at org.mariadb.jdbc.internal.util.Utils.retrieveProxy(Utils.java:635)
        at org.mariadb.jdbc.MariaDbConnection.newConnection(MariaDbConnection.java:150)
        at org.mariadb.jdbc.Driver.connect(Driver.java:89)
        at java.sql/java.sql.DriverManager.getConnection(Unknown Source)
        at java.sql/java.sql.DriverManager.getConnection(Unknown Source)
        at metabase.db.data_source.DataSource.getConnection(data_source.clj:35)
        at com.mchange.v2.c3p0.WrapperConnectionPoolDataSource.getPooledConnection(WrapperConnectionPoolDataSource.java:161)
        at com.mchange.v2.c3p0.impl.C3P0PooledConnectionPool$1PooledConnectionResourcePoolManager.acquireResource(C3P0PooledConnectionPool.java:213)
        at com.mchange.v2.resourcepool.BasicResourcePool.doAcquire(BasicResourcePool.java:1176)
        at com.mchange.v2.resourcepool.BasicResourcePool.doAcquireAndDecrementPendingAcquiresWithinLockOnSuccess(BasicResourcePool.java:1163)
        at com.mchange.v2.resourcepool.BasicResourcePool.access$700(BasicResourcePool.java:44)
        at com.mchange.v2.resourcepool.BasicResourcePool$ScatteredAcquireTask.run(BasicResourcePool.java:1908)
        at com.mchange.v2.async.ThreadPoolAsynchronousRunner$PoolThread.run(ThreadPoolAsynchronousRunner.java:696)
Caused by: java.sql.SQLException: RSA public key is not available client side (option serverRsaPublicKeyFile not set)
        at org.mariadb.jdbc.internal.com.send.authentication.CachingSha2PasswordPlugin.process(CachingSha2PasswordPlugin.java:189)
        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.authenticationHandler(AbstractConnectProtocol.java:767)
        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.createConnection(AbstractConnectProtocol.java:571)
        at org.mariadb.jdbc.internal.protocol.AbstractConnectProtocol.connectWithoutProxy(AbstractConnectProtocol.java:1390)
        ... 13 more
2024-07-01 10:56:50,937 INFO metabase.core :: Metabase Shutting Down ...
2024-07-01 10:56:50,937 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-07-01 10:56:50,953 WARN db.liquibase :: ()
2024-07-01 10:56:50,953 INFO metabase.core :: Metabase Shutdown COMPLETE

C:\Metabase>
```

Tony-metabase on (2024-07-01 09:00:18 UTC): Now the error points to metabase not being able to connect to your App DB:

`Unable to connect to Metabase mysql DB`

Has nothing to do with 0.50.8 ... if you simply deploy 0.49.13 what happens? are you able to connect to the App DB?

vipera7 (Issue Creator) on (2024-07-01 09:02:24 UTC): But why is it failing to connect? I always use the same credentials, and I just tested themâ€”they work fine. I reverted my backup to version 0.49.13, and it's working again in this version.

Tony-metabase on (2024-07-01 09:27:01 UTC): The only error pointed in the logs is the following:

`Could not connect to address=(host=localhost)(port=3306)(type=master) : RSA public key is not available client side (option serverRsaPublicKeyFile not set)`

What version of MYSQL are you running? And just to confirm you simply changed the version of the metabase.jar to the 49 and it loaded without issues?

vipera7 (Issue Creator) on (2024-07-01 09:30:20 UTC): I reran the same command, and the upgrade was successful. I didn't make any changes to the configuration or anything else; I simply executed it a second time.

Log: 

```
C:\Metabase>""C:\Program Files\Eclipse Adoptium\jre-11.0.23.9-hotspot\bin\java.exe"" -jar metabase.jar
2024-07-01 11:19:05,805 INFO metabase.util :: Maximum memory available to JVM: 4,0 GB
2024-07-01 11:19:09,039 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance.
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-01 11:19:16,430 INFO driver.impl :: Registered abstract driver :sql
2024-07-01 11:19:16,430 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql])
2024-07-01 11:19:16,445 INFO metabase.util :: Load driver :sql-jdbc took 58,1 ms
2024-07-01 11:19:16,445 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc])
2024-07-01 11:19:16,680 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc])
2024-07-01 11:19:16,742 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc])
2024-07-01 11:19:19,164 INFO metabase.core ::
Metabase v0.50.8 (dc9e68b)

Copyright Â® 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-07-01 11:19:19,180 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-07-01 11:19:19,226 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000}

2024-07-01 11:19:19,305 INFO metabase.core :: Starting Metabase version v0.50.8 (dc9e68b) ...
2024-07-01 11:19:19,305 INFO metabase.core :: System info:
 {""file.encoding"" ""Cp1252"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Windows Server 2016"",
 ""os.version"" ""10.0"",
 ""user.language"" ""fr"",
 ""user.timezone"" ""Europe/Paris""}

2024-07-01 11:19:19,305 INFO metabase.plugins :: Loading plugins in C:\Metabase\plugins...
2024-07-01 11:19:19,726 ERROR middleware.log :: GET /api/health 503 3,2 ms (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.2}

2024-07-01 11:19:19,836 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-07-01 11:19:19,836 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc])
2024-07-01 11:19:19,867 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-07-01 11:19:19,867 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql])
2024-07-01 11:19:19,883 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-07-01 11:19:19,883 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc])
2024-07-01 11:19:19,883 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-07-01 11:19:19,883 INFO driver.impl :: Registered driver :druid
2024-07-01 11:19:19,898 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :googleanalytics...
2024-07-01 11:19:19,898 INFO driver.impl :: Registered driver :googleanalytics
2024-07-01 11:19:19,914 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-07-01 11:19:19,914 INFO driver.impl :: Registered driver :mongo
2024-07-01 11:19:19,914 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-07-01 11:19:19,930 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-07-01 11:19:19,930 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]
2024-07-01 11:19:19,945 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-07-01 11:19:19,945 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc])
2024-07-01 11:19:19,961 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-07-01 11:19:19,961 INFO driver.impl :: Registered driver :redshift (parents: [:postgres])
2024-07-01 11:19:20,008 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-07-01 11:19:20,008 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc])
2024-07-01 11:19:20,023 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-07-01 11:19:20,023 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc])
2024-07-01 11:19:20,023 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-07-01 11:19:20,023 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like])
2024-07-01 11:19:20,039 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-07-01 11:19:20,039 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc])
2024-07-01 11:19:20,039 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-07-01 11:19:20,039 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc])
2024-07-01 11:19:20,055 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-07-01 11:19:20,055 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-07-01 11:19:20,055 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]
2024-07-01 11:19:20,070 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-01 11:19:20,070 INFO db.setup :: Verifying mysql Database Connection ...
2024-07-01 11:19:20,226 INFO db.setup :: Successfully verified MySQL 8.0.36 application database connection.
2024-07-01 11:19:20,226 INFO db.setup :: Checking if a database downgrade is required...
2024-07-01 11:19:20,695 ERROR middleware.log :: GET /api/health 503 307.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:20,867 INFO db.setup :: Running Database Migrations...
2024-07-01 11:19:20,867 INFO db.setup :: Setting up Liquibase...
2024-07-01 11:19:21,039 INFO db.setup :: Liquibase is ready.
2024-07-01 11:19:21,039 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-01 11:19:21,664 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-07-01 11:19:21,680 ERROR middleware.log :: GET /api/health 503 319.5 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:21,695 INFO db.liquibase :: No migration lock found.
2024-07-01 11:19:21,695 INFO db.liquibase :: Migration lock acquired.
2024-07-01 11:19:21,976 INFO db.liquibase :: Running 96 migrations ...
2024-07-01 11:19:22,680 ERROR middleware.log :: GET /api/health 503 340.0 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:23,681 ERROR middleware.log :: GET /api/health 503 324.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:24,681 ERROR middleware.log :: GET /api/health 503 280.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:25,681 ERROR middleware.log :: GET /api/health 503 345.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:22:51,165 ERROR middleware.log :: GET /api/health 503 313.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:20:31,052 ERROR middleware.log :: GET /api/health 503 519.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:20:06,564 ERROR middleware.log :: GET /api/health 503 371.2 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:19:32,492 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-07-01 11:23:08,585 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-07-01 11:23:08,585 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-07-01 11:23:08,601 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-07-01 11:23:08,601 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-07-01 11:23:08,617 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'BBS-SMAREP-Q0011719825788570'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-07-01 11:23:08,617 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-07-01 11:23:08,617 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-07-01 11:23:08,680 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.
2024-07-01 11:23:08,689 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""BBS-SMAREP-Q0011719322507746""'s failed in-progress jobs.
2024-07-01 11:23:08,700 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 started.
2024-07-01 11:23:08,730 INFO jdbcjobstore.JobStoreTX :: Handling 7 trigger(s) that missed their scheduled fire-time.
2024-07-01 11:23:08,803 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 shutting down.
2024-07-01 11:23:08,803 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 paused.
2024-07-01 11:23:08,806 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825788570 shutdown complete.
2024-07-01 11:23:08,806 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
2024-07-01 11:23:08,822 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade
2024-07-01 11:23:09,681 ERROR middleware.log :: GET /api/health 503 340.4 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:23:10,681 ERROR middleware.log :: GET /api/health 503 315.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:23:11,681 ERROR middleware.log :: GET /api/health 503 281.4 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:23:12,681 ERROR middleware.log :: GET /api/health 503 266.0 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:23:13,682 ERROR middleware.log :: GET /api/health 503 304.1 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}


UPDATE SUMMARY
Run:                         96
Previously run:             284
Filtered out:                 6
-------------------------------
Total change sets:          386


FILTERED CHANGE SETS SUMMARY
Ignored:                      1
Already ran:                  1
DBMS mismatch:                5

2024-07-01 11:23:14,680 ERROR middleware.log :: GET /api/health 503 407.6 Ãs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.3}

2024-07-01 11:23:32,888 INFO db.liquibase :: Migration complete in 4.2 mins
2024-07-01 11:23:32,904 INFO db.setup :: Database Migrations Current ...
2024-07-01 11:23:32,904 INFO metabase.util :: Database setup took 4,2 mins
2024-07-01 11:23:33,013 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-07-01 11:23:33,013 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-07-01 11:23:33,013 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-07-01 11:23:33,013 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-07-01 11:23:33,013 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-07-01 11:23:33,029 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'BBS-SMAREP-Q0011719825813013'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-07-01 11:23:33,029 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-07-01 11:23:33,029 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-07-01 11:23:33,201 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825813013 paused.
2024-07-01 11:23:33,201 INFO metabase.task :: Task scheduler initialized into standby mode.
2024-07-01 11:23:33,232 INFO metabase.task :: Initializing task Cache
2024-07-01 11:23:33,232 INFO metabase.task :: Initializing task SyncDatabases
2024-07-01 11:23:33,248 INFO task.sync-databases :: Updated default schedules for 0 databases
2024-07-01 11:23:33,248 INFO metabase.task :: Initializing task PersistRefresh
2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :sql...
2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :sql-jdbc...
2024-07-01 11:23:33,279 INFO driver.impl :: Initializing driver :postgres...
2024-07-01 11:23:33,310 INFO driver.impl :: Initializing driver :mysql...
2024-07-01 11:23:33,357 INFO metabase.task :: Initializing task CheckForNewVersions
2024-07-01 11:23:33,373 INFO metabase.task :: Initializing task PersistPrune
2024-07-01 11:23:33,373 INFO metabase.task :: Initializing task SendAnonymousUsageStats
2024-07-01 11:23:33,388 INFO metabase.task :: Initializing task ModelIndexValues
2024-07-01 11:23:33,388 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers
2024-07-01 11:23:33,420 INFO metabase.task :: Initializing task TruncateAuditTables
2024-07-01 11:23:33,420 INFO metabase.task :: Initializing task SendPulses
2024-07-01 11:23:33,435 INFO metabase.task :: Initializing task SendFollowUpEmails
2024-07-01 11:23:33,451 INFO metabase.task :: Initializing task SendCreatorSentimentEmails
2024-07-01 11:23:33,482 INFO metabase.task :: Initializing task SendLegacyNoSelfServiceEmail
2024-07-01 11:23:33,482 INFO metabase.task :: Initializing task TaskHistoryCleanup
2024-07-01 11:23:33,498 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail
2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.
2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""BBS-SMAREP-Q0011719825788570""'s failed in-progress jobs.
2024-07-01 11:23:33,513 INFO jdbcjobstore.JobStoreTX :: ClusterManager: ......Freed 1 acquired trigger(s).
2024-07-01 11:23:33,513 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_BBS-SMAREP-Q0011719825813013 started.
2024-07-01 11:23:33,545 INFO metabase.task :: Task scheduler started
2024-07-01 11:23:33,560 INFO metabase.core :: Metabase Initialization COMPLETE in 4,6 mins
2024-07-01 11:23:33,607 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.
2024-07-01 11:23:33,920 DEBUG middleware.log :: GET /api/health 200 2,1 ms (0 DB calls) App DB connections: 1/4 Jetty threads: 4/50 (7 idle, 0 queued) (38 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-07-01 11:23:34,068 INFO i18n.impl :: Reading available locales from locales.clj...
2024-07-01 11:23:34,238 INFO util.fonts :: Reading available fonts from /frontend_client/app/fonts
2024-07-01 11:23:35,579 DEBUG middleware.log :: GET /api/session/properties 200 142,6 ms (8 DB calls) App DB connections: 1/4 Jetty threads: 7/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-07-01 11:23:35,821 DEBUG middleware.log :: GET /api/user/current 200 396,1 ms (11 DB calls) App DB connections: 0/4 Jetty threads: 6/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
2024-07-01 11:23:36,023 DEBUG middleware.log :: GET /api/collection/root 200 62,9 ms (2 DB calls) App DB connections: 1/4 Jetty threads: 8/50 (5 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
```

"
2383170155,issue,open,,PRs get CI cancelled,"happens more frequently on backport PRs, but not exclusively

see

* [discussion](https://metaboat.slack.com/archives/C052ZBWRG3W/p1719305520294029?thread_ts=1718801266.946919&cid=C052ZBWRG3W)
* [discussion](https://metaboat.slack.com/archives/C5XHN8GLW/p1719817926501729)

temporary workaround:

```bash
alias kick=""git commit -m 'kick ci' --allow-empty && git push""
```",iethree,2024-07-01 08:17:52+00:00,[],2025-02-06 15:19:30+00:00,,https://github.com/metabase/metabase/issues/44957,[],"[{'comment_id': 2640120929, 'issue_id': 2383170155, 'author': 'iethree', 'body': 'possibly fixed by: https://github.com/metabase/metabase/pull/53235 ðŸ¤ž', 'created_at': datetime.datetime(2025, 2, 6, 15, 19, 29, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2025-02-06 15:19:29 UTC): possibly fixed by: https://github.com/metabase/metabase/pull/53235 ðŸ¤ž

"
2382919308,issue,open,,Use a cypress tag instead of .skip in e2e reproductions of current bugs,"https://metaboat.slack.com/archives/C0669P4AF9N/p1719398790899269

This will allow us to run these tests periodically and see if any issues have been fixed as side effects of other things. It will also give us more information about why something is skipped. 

Maybe
- `@unfixed-reproduction` for reproductions of unfixed bugs
- `@broken` for tests that are broken for some other reason",iethree,2024-07-01 06:05:57+00:00,[],2024-07-01 06:08:19+00:00,,https://github.com/metabase/metabase/issues/44952,"[('.CI & Tests', '')]",[],
2382427117,issue,open,,Allow searching column names in source data,"**Is your feature request related to a problem? Please describe.**
Allow searching column names in questions source data columns selection the same way it is done on filter and summarize sections. When working with highly denormalized/one big table data modeling pattern you can/we have tables with hundreds of columns and end users struggle to find the data they need.

**Describe the solution you'd like**
Allow searching column names in questions source data columns selection the same way it is done on filter and summarize sections of questions.

**Describe alternatives you've considered**
Using browser search works as a workaround but it would be better to have the same capability as other question sections.

**How important is this feature to you?**
It is an active complaint and struggle of our end users

**Additional context**
Add any other context or screenshots about the feature request here.
",felipe-curebase,2024-06-30 20:24:12+00:00,[],2025-02-04 20:30:59+00:00,,https://github.com/metabase/metabase/issues/44951,"[('Type:New Feature', ''), ('Organization/Search', '')]",[],
2382395352,issue,open,,Map whitelabeling customization to user groups,"**Is your feature request related to a problem? Please describe.**
We are a SaaS company working with multiple B2B customers. We would like to tailor metabase whitelabeling for each of our customers because we already offer this capability in our SaaS. 

**Describe the solution you'd like**
One way to achieve that would be to create whitelabeling configurations that could be associated with user groups.

**Describe alternatives you've considered**
Creating multiple metabase instances for each customer. We would not like/won't do that because of the configuration and management overhead of having multiple metabase instances just to have the whitelabel per group feature.

**How important is this feature to you?**
It is important to maintain a unified look and feel of our SaaS offering to our customers when we start using embedding.

**Additional context**
Add any other context or screenshots about the feature request here.
",felipe-curebase,2024-06-30 19:36:40+00:00,[],2025-02-04 20:30:32+00:00,,https://github.com/metabase/metabase/issues/44950,"[('Type:New Feature', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('Administration/', ''), ('Administration/Whitelabel', 'Enterprise white labelling')]","[{'comment_id': 2568044611, 'issue_id': 2382395352, 'author': 'brunobergher', 'body': ""Felipe, you should be able to get a lot of flexibility with our [new SDK](https://www.metabase.com/product/embedded-analytics-sdk), but I see the value in having a native way to pair whitelabeling config to specific user groups (and we're exploring something along those lines), so keeping this open."", 'created_at': datetime.datetime(2025, 1, 2, 16, 30, 44, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 16:30:44 UTC): Felipe, you should be able to get a lot of flexibility with our [new SDK](https://www.metabase.com/product/embedded-analytics-sdk), but I see the value in having a native way to pair whitelabeling config to specific user groups (and we're exploring something along those lines), so keeping this open.

"
2382389943,issue,open,,Invalidate pivot table pending/queued? work after user makes a change,"### Describe the bug

The experience of creating complex pivot tables feels a bit clunky. I believe it is mostly caused because when you edit multiple metrics or pivot fields at the same time looks like the pivot table is processing the changes one by one in which looks like a queue. 

If each change takes one minute to process, the user needs to wait a lot of time to have their final pivot table design ready and it is confusing to the end user to see some changes appear on their screen but not be what they wanted in the end, causing further attempts to make changes that cause even more confusion.

What would make sense is that whatever change is done in a pivot table instantly invalidates whatever work it was doing previously because if multiple metrics were changed, only the last change done is the desired one and any previous processing that was to be done is basically useless. 

I noticed https://github.com/metabase/metabase/pull/28945 was an initial improvement in this direction but pivot table design is still confusing for end users IMO.

### To Reproduce

Create pivot table with multiple row aggregations and column pivot fields.
Try to pivot 2 or more columns to be pivot columns at the same time. It will either process one pivot change at a time or rollback the changes you tried to do.

### Expected behavior

pivot table instantly invalidates whatever work it was doing previously allowing moving multiple pivot fields at one go.

### Logs

No relevant logs.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.216-204.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v1.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2

### Additional context

_No response_",felipe-curebase,2024-06-30 19:20:35+00:00,[],2024-07-02 00:40:32+00:00,,https://github.com/metabase/metabase/issues/44949,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2382383931,issue,open,,Allow renaming of map pin/grid columns,"**Is your feature request related to a problem? Please describe.**
Map pin and grid types doesn't allow renaming metric and lat/long to friendly column names. lat/long column names shows up like this on a map visualization if you have joins: ""Us Zip Codes - Customer Zipcode â†’ Latitude""

**Describe the solution you'd like**
Allow renaming the columns the same way as table visualizations.

**Describe alternatives you've considered**
There is a workaround for metric columns by creating a custom renamed column but it doesn't work for lat/long columns because they don't inherit the geographic metadata type of the original columns.

**How important is this feature to you?**
This would make the map visualizations grid/pin visualizations more clean.

**Additional context**
Add any other context or screenshots about the feature request here.
",felipe-curebase,2024-06-30 19:03:27+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/44948,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Maps', '')]",[],
2381821299,issue,open,,"Bug Report: ""Too Many Open Statements"" Error in Metabase with Apache Druid JDBC","Hello

### Describe the bug

When using the Druid JDBC connector in Metabase and creating a dashboard with field filters, an error occurs if a non-existent field is used in the query. After this error, almost all subsequent queries fail with a ""Too many open statements"" error, even after removing the problematic filter.

### To Reproduce

- Connect Metabase to Druid using the JDBC connector.
- Create a dashboard with field filters.
- Add a filter with a field that does not exist in the datasource: eg `[[ AND fieldX = {{FilterField}} ]]
- Save question, add to the Dashboard
- Apply the filter, causing an expected error.
- Remove the value of the filter
- Attempt to run other queries on the dashboard.

If the behavior do not show, with just one query, maybe it's because it's using just statement per 'failure', try adding more questions (at least 4)


### Expected behavior

Queries should execute normally after removing the erroneous filter

Errors should release the statement, if this is the real issue, but I'm just guessing the cause

### Logs

```
[736d08d2-68c6-4d0d-bcfd-7a3f2d76fb51] 2024-06-29T12:05:45-03:00 DEBUG metabase.server.middleware.log POST /api/dashboard/2/dashcard/126/card/119/query 202 [ASYNC: completed] 1.6 s (18 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (18 idle, 0 queued) (127 total active threads) Queries in flight: 9 (0 queued); druid-jdbc DB 4 connections: 1/8 (0 threads blocked) {:metabase-user-id 1}
[736d08d2-68c6-4d0d-bcfd-7a3f2d76fb51] 2024-06-29T12:05:45-03:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: An SQLException was provoked by the following failure: AvaticaClientRuntimeException: Remote driver error: ISE: Too many open statements, limit is 4. Error -1 (00000) UNKNOWN
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-12-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""druid-jdbc"",
      ""druid""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-12"",
      ""tag"": ""v0.50.2"",
      ""hash"": ""1a2c2da""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    }
  }
}
```

Druid Version: 27.0.0

### Severity

low

### Additional context

The issue seems to be related to the way Metabase handles statement cleanup after a query fails. Itâ€™s possible that the failed query does not properly release its statements, causing subsequent queries to fail due to the open statements limit.

The error disappears if either Metabase is restarted or some parameter on the database admin page is changed (e.g., changing the username/password). ",renatocron,2024-06-29 15:42:43+00:00,[],2025-02-04 20:27:56+00:00,,https://github.com/metabase/metabase/issues/44947,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Druid', None), ('Difficulty:Hard', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2233845193, 'issue_id': 2381821299, 'author': 'lbrdnk', 'body': ""Not yet a solution but symptoms can be mitigated using `druid.sql.avatica.maxStatementsPerConnection` configuration parameter, as found in [the docs](https://druid.apache.org/docs/latest/configuration/#sql). I've set it arbitrarily to 50 while testing and I was unable to hit the issue.\r\n\r\nPrior to that, with regards to reproduction, I've saved question as described, with optional broken param. I've added 8 same broken questions to a dashboard, which execute without an issue when param is not set. the I've changed the params value multiple times. Then, after removing the value queries should execute successfully again, but do result in errors.\r\n\r\nI've also noticed that queries start to work after some time (minutes). \r\n\r\nWith regards to debugging, I was unable to find a problem in our execution code. It seems to me we are closing connections, statements and result sets correctly. I suspect it could be mishandled in the pool we are using. I think [jmx](https://www.mchange.com/projects/c3p0/#jmx_configuration_and_management) could be of help with further debugging.\r\n\r\nAs there is a mitigation problem _should not_ be blocking. Hence I'm changing the priority to P2. If I'm correct with the connection pool clue, debugging becomes relatively harder, hence the change of difficulty."", 'created_at': datetime.datetime(2024, 7, 17, 17, 36, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233863392, 'issue_id': 2381821299, 'author': 'renatocron', 'body': ""Hi lbrdnk,\r\nThank you, I will set druid.sql.avatica.maxStatementsPerConnection\r\nI was not able to find this field during my search, I only found the code\r\nwith the value 4, and thought it was no way to override it\r\n\r\nOn Wed, Jul 17, 2024 at 2:36\u202fPM lbrdnk ***@***.***> wrote:\r\n\r\n> Not yet a solution but symptoms can be mitigated using\r\n> druid.sql.avatica.maxStatementsPerConnection configuration parameter, as\r\n> found in the docs\r\n> <https://druid.apache.org/docs/latest/configuration/#sql>. I've set it\r\n> arbitrarily to 50 while testing and I was unable to hit the issue.\r\n>\r\n> Prior to that, with regards to reproduction, I've saved question as\r\n> described, with optional broken param. I've added 8 same broken questions\r\n> to a dashboard, which execute without an issue when param is not set. the\r\n> I've changed the params value multiple times. Then, after removing the\r\n> value queries should execute successfully again, but do result in errors.\r\n>\r\n> I've also noticed that queries start to work after some time (minutes).\r\n>\r\n> With regards to debugging, I was unable to find a problem in our execution\r\n> code. It seems to me we are closing connections, statements and result sets\r\n> correctly. I suspect it could be mishandled in the pool we are using. I\r\n> think jmx\r\n> <https://www.mchange.com/projects/c3p0/#jmx_configuration_and_management>\r\n> could be of help with further debugging.\r\n>\r\n> As there is a mitigation problem *should not* be blocking. Hence I'm\r\n> changing the priority to P2. If I'm correct with the connection pool clue,\r\n> debugging becomes relatively harder, hence the change of difficulty.\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/44947#issuecomment-2233845193>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAOUQZENC2ZRBQFFJLMRYFTZM2TTXAVCNFSM6AAAAABKDJJ5OKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZTHA2DKMJZGM>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n\r\n\r\n-- \r\nYAGNI,\r\nRenato CRON\r\nhttp://www.renatocron.com/\r\n@renato_cron <http://twitter.com/renatocron>"", 'created_at': datetime.datetime(2024, 7, 17, 17, 45, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249227722, 'issue_id': 2381821299, 'author': 'renatocron', 'body': 'Just wanted to warn about the issues that arise when setting maxStatementsPerConnection to 50 and leaving it for a few days. You can exhaust the number of threads available in the routers, and drivers that do not use persistent connections may randomly encounter socket hang up errors when trying to initiate new connections. This can be ""fixed"" by restarting the router component.\r\n\r\n\r\n-----\r\n\r\nMy settings for router: replica 2x:\r\n```\r\n\r\n      runtime.properties: |\r\n        druid.service=druid/router\r\n\r\n        # HTTP proxy\r\n        druid.router.http.numConnections=32\r\n        druid.router.http.readTimeout=PT8M\r\n        druid.router.http.numMaxThreads=900\r\n        druid.server.http.numThreads=1000\r\n\r\n        # Service discovery\r\n        druid.router.defaultBrokerServiceName=druid/broker\r\n        druid.router.coordinatorServiceName=druid/coordinator\r\n\r\n        # Management proxy to coordinator / overlord: required for unified web console.\r\n        druid.router.managementProxy.enabled=true\r\n```\r\n\r\n3 brokers, each with\r\n\r\n```\r\n        druid.broker.http.numConnections=6 # this is the number of threads initiatel to the MM and Historicals\r\n        druid.server.http.numThreads=100 # this is the number of threads avaiable for commands and queries\r\n\r\n        druid.sql.avatica.maxStatementsPerConnection=4 # now back to 4 :warau:\r\n\r\n        druid.query.scheduler.laning.strategy=hilo\r\n        druid.broker.http.maxQueuedBytes=30MiB\r\n```', 'created_at': datetime.datetime(2024, 7, 25, 2, 13, 1, tzinfo=datetime.timezone.utc)}]","lbrdnk on (2024-07-17 17:36:37 UTC): Not yet a solution but symptoms can be mitigated using `druid.sql.avatica.maxStatementsPerConnection` configuration parameter, as found in [the docs](https://druid.apache.org/docs/latest/configuration/#sql). I've set it arbitrarily to 50 while testing and I was unable to hit the issue.

Prior to that, with regards to reproduction, I've saved question as described, with optional broken param. I've added 8 same broken questions to a dashboard, which execute without an issue when param is not set. the I've changed the params value multiple times. Then, after removing the value queries should execute successfully again, but do result in errors.

I've also noticed that queries start to work after some time (minutes). 

With regards to debugging, I was unable to find a problem in our execution code. It seems to me we are closing connections, statements and result sets correctly. I suspect it could be mishandled in the pool we are using. I think [jmx](https://www.mchange.com/projects/c3p0/#jmx_configuration_and_management) could be of help with further debugging.

As there is a mitigation problem _should not_ be blocking. Hence I'm changing the priority to P2. If I'm correct with the connection pool clue, debugging becomes relatively harder, hence the change of difficulty.

renatocron (Issue Creator) on (2024-07-17 17:45:15 UTC): Hi lbrdnk,
Thank you, I will set druid.sql.avatica.maxStatementsPerConnection
I was not able to find this field during my search, I only found the code
with the value 4, and thought it was no way to override it

On Wed, Jul 17, 2024 at 2:36â€¯PM lbrdnk ***@***.***> wrote:



-- 
YAGNI,
Renato CRON
http://www.renatocron.com/
@renato_cron <http://twitter.com/renatocron>

renatocron (Issue Creator) on (2024-07-25 02:13:01 UTC): Just wanted to warn about the issues that arise when setting maxStatementsPerConnection to 50 and leaving it for a few days. You can exhaust the number of threads available in the routers, and drivers that do not use persistent connections may randomly encounter socket hang up errors when trying to initiate new connections. This can be ""fixed"" by restarting the router component.


-----

My settings for router: replica 2x:
```

      runtime.properties: |
        druid.service=druid/router

        # HTTP proxy
        druid.router.http.numConnections=32
        druid.router.http.readTimeout=PT8M
        druid.router.http.numMaxThreads=900
        druid.server.http.numThreads=1000

        # Service discovery
        druid.router.defaultBrokerServiceName=druid/broker
        druid.router.coordinatorServiceName=druid/coordinator

        # Management proxy to coordinator / overlord: required for unified web console.
        druid.router.managementProxy.enabled=true
```

3 brokers, each with

```
        druid.broker.http.numConnections=6 # this is the number of threads initiatel to the MM and Historicals
        druid.server.http.numThreads=100 # this is the number of threads avaiable for commands and queries

        druid.sql.avatica.maxStatementsPerConnection=4 # now back to 4 :warau:

        druid.query.scheduler.laning.strategy=hilo
        druid.broker.http.maxQueuedBytes=30MiB
```

"
2381770228,issue,open,,We're updating the updated_at field in metabase_table on every field even though there's no change,"### Describe the bug

We started updating the updated_at field on the metabase_table table on recent versions although there's no change in the table. This lead to a problem on a customer who was using a trigger on that field, which started firing on every single sync no matter if there was a change or not

### To Reproduce

1) start v47 and add a table to the DW
2) sync it, see the updated_at field not changing
3) now move to v48 or v49, do the syncs, see that the updated_at field having updated values on every sync

### Expected behavior

We should not change stuff on the DB if there's no change

### Logs

NA

### Information about your Metabase installation

```JSON
v48+
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-06-29 14:03:38+00:00,[],2025-02-04 20:24:32+00:00,,https://github.com/metabase/metabase/issues/44946,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2200639867, 'issue_id': 2381770228, 'author': 'luizarakaki', 'body': '@calherries Is this because of the `view_count` column?\r\nI think this is more severe than P3 if `updated_at` is refreshing on every read.', 'created_at': datetime.datetime(2024, 7, 1, 17, 3, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203064387, 'issue_id': 2381770228, 'author': 'bshepherdson', 'body': ""No, actually, this isn't related to `view_count`."", 'created_at': datetime.datetime(2024, 7, 2, 12, 42, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203070738, 'issue_id': 2381770228, 'author': 'bshepherdson', 'body': ""This one starts out as an update of `result_metadata` on the card after we execute its query.\r\n\r\nSo it starts as `(t2/update! [:model/Card card-id] {:result_metadata result-metadata})`, which is implemented like this:\r\n\r\n1. start a transaction\r\n2. `SELECT` the card\r\n3. compare its values with the new ones, and drop those that are `=` from the update\r\n4. issue the `UPDATE` for the things that actually changed\r\n\r\nwhich would be fine except that we already added `:updated_at (now)` to the updates. So the only real update (to `result_metadata`) got removed, and we don't have a special case to drop an `UPDATE` with nothing in it but `updated_at`."", 'created_at': datetime.datetime(2024, 7, 2, 12, 46, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221778247, 'issue_id': 2381770228, 'author': 'calherries', 'body': '@paoliniluis is this a postgres DW? I suspect this is because of https://github.com/metabase/metabase/pull/39494', 'created_at': datetime.datetime(2024, 7, 11, 0, 46, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224090262, 'issue_id': 2381770228, 'author': 'calherries', 'body': ""@paoliniluis do you know? `updated_at` should not change unless the estimated number of rows in the table changes, from `pg_stat_user_tables.n_live_tup`. in that case we'll update `metabase_table.estimated_row_count` and also `updated_at`."", 'created_at': datetime.datetime(2024, 7, 11, 23, 0, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224292715, 'issue_id': 2381770228, 'author': 'paoliniluis', 'body': '@calherries nope, in fact I was doing this test on the sample database, with no change in rows at all', 'created_at': datetime.datetime(2024, 7, 12, 2, 5, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224318094, 'issue_id': 2381770228, 'author': 'calherries', 'body': ""Okay thanks for clarifying, that's a separate issue then. Even if we fix that, because of `estimated_row_count`, do you think that `metabase_table.updated_at` should not change even if `estimated_row_count` changes? Because if a customer is using a Postgres DW, a trigger on `updated_at` will fire much more frequently than before https://github.com/metabase/metabase/pull/39494"", 'created_at': datetime.datetime(2024, 7, 12, 2, 38, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229331973, 'issue_id': 2381770228, 'author': 'luizarakaki', 'body': ""I think it is fine to update `updated_at` if `estimated_row_count` changes... I'm not 100% confident, but doesn't look terrible because there is indeed a change in the entity.\r\n\r\nBut analytical properties like view_count shouldn't update updated_at because the entity isn't changing"", 'created_at': datetime.datetime(2024, 7, 15, 20, 21, 32, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-07-01 17:03:24 UTC): @calherries Is this because of the `view_count` column?
I think this is more severe than P3 if `updated_at` is refreshing on every read.

bshepherdson on (2024-07-02 12:42:59 UTC): No, actually, this isn't related to `view_count`.

bshepherdson on (2024-07-02 12:46:06 UTC): This one starts out as an update of `result_metadata` on the card after we execute its query.

So it starts as `(t2/update! [:model/Card card-id] {:result_metadata result-metadata})`, which is implemented like this:

1. start a transaction
2. `SELECT` the card
3. compare its values with the new ones, and drop those that are `=` from the update
4. issue the `UPDATE` for the things that actually changed

which would be fine except that we already added `:updated_at (now)` to the updates. So the only real update (to `result_metadata`) got removed, and we don't have a special case to drop an `UPDATE` with nothing in it but `updated_at`.

calherries on (2024-07-11 00:46:53 UTC): @paoliniluis is this a postgres DW? I suspect this is because of https://github.com/metabase/metabase/pull/39494

calherries on (2024-07-11 23:00:59 UTC): @paoliniluis do you know? `updated_at` should not change unless the estimated number of rows in the table changes, from `pg_stat_user_tables.n_live_tup`. in that case we'll update `metabase_table.estimated_row_count` and also `updated_at`.

paoliniluis (Issue Creator) on (2024-07-12 02:05:21 UTC): @calherries nope, in fact I was doing this test on the sample database, with no change in rows at all

calherries on (2024-07-12 02:38:13 UTC): Okay thanks for clarifying, that's a separate issue then. Even if we fix that, because of `estimated_row_count`, do you think that `metabase_table.updated_at` should not change even if `estimated_row_count` changes? Because if a customer is using a Postgres DW, a trigger on `updated_at` will fire much more frequently than before https://github.com/metabase/metabase/pull/39494

luizarakaki on (2024-07-15 20:21:32 UTC): I think it is fine to update `updated_at` if `estimated_row_count` changes... I'm not 100% confident, but doesn't look terrible because there is indeed a change in the entity.

But analytical properties like view_count shouldn't update updated_at because the entity isn't changing

"
2381559125,issue,closed,not_planned,ISO8601 date,"**Describe the bug**
Please add the ISO8601 data format as an option-> YYYY-MM-DD HH:mm:ss

**Logs**
n/a

**To Reproduce**
n/a

**Expected behavior**
ISO8601 date format available 

**Screenshots**
n/a

**Severity**
42 countries already have accepted ISO8601 as national standards, these include United States; United Kingdom, Switzerland, Sweden, Russia, Norway, Netherlands, Japan, Germany, France, China, Canada, ....

**Additional context**
Date just read more ""normal"" for users accustomed to it in a specific format.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.14.0-427.22.1.el9_4.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Africa/Johannesburg""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.11.8-MariaDB-log""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-12"",
      ""tag"": ""v0.50.2"",
      ""hash"": ""1a2c2da""
    },
    ""settings"": {
      ""report-timezone"": ""Africa/Johannesburg""
    }
  }
}
```",pegxit,2024-06-29 07:42:10+00:00,[],2024-08-22 11:22:36+00:00,2024-08-22 11:22:06+00:00,https://github.com/metabase/metabase/issues/44945,"[('Type:New Feature', ''), ('Customization/i18n', ''), ('Customization/Formatting', ''), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2216834082, 'issue_id': 2381559125, 'author': 'NicolasPA', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/9539', 'created_at': datetime.datetime(2024, 7, 9, 7, 38, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304423506, 'issue_id': 2381559125, 'author': 'mngr', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/9539', 'created_at': datetime.datetime(2024, 8, 22, 11, 22, 6, tzinfo=datetime.timezone.utc)}]","NicolasPA on (2024-07-09 07:38:41 UTC): Duplicate of https://github.com/metabase/metabase/issues/9539

mngr on (2024-08-22 11:22:06 UTC): Duplicate of https://github.com/metabase/metabase/issues/9539

"
2381316604,issue,closed,completed,Joining the Same Table Multiple Times Creates Buggy Behavior with Custom Expressions,"### Describe the bug

If you have a Question and you've joined the same table multiple times in the query editor, custom expressions that refer to fields in the duplicate table behave strangely (if they only contain the field itself - EG if it's used to rename the column).


### To Reproduce

1. Set up Metabase v50
2. Create a Question with ""People"", join ""Orders"", then join ""Orders"" again
3. Create a custom expression to rename the ""Total"" from one of the Orders tables something else and preview the results
4. Note the results display the custom column
5. Click on the custom expression and note that the expression box is empty
6. Now visualize the results in a table viz
7. Try to filter on the renamed column - the filter doesn't work
8. Try to filter on the column you targeted with the renamed - the filter doesn't work

https://www.loom.com/share/a6f79c57e1454671ba4c51b3e38e6e1c

### Expected behavior

The expressions should be visible and filterable

### Logs

equality.cljc:237 Multiple plausible matches with the same :join-alias - more disambiguation needed n1.h
b @ equality.cljc:237Understand this warning
equality.cljc:237 Multiple plausible matches with the same :join-alias - more disambiguation needed n1.h
b @ equality.cljc:237Understand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n [:concat\n  {:lib/uuid \""35a3f47d-40dc-4158-a4b9-9367219606f8\""}\n  [:field {:base-type :type/Float, :join-alias \""Orders_2\"", :lib/uuid \""59b8c2ba-d937-4d3c-a462-8b176389b525\""} 42]],\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  [:concat\n   {:lib/uuid \""35a3f47d-40dc-4158-a4b9-9367219606f8\""}\n   [:field {:base-type :type/Float, :join-alias \""Orders_2\"", :lib/uuid \""59b8c2ba-d937-4d3c-a462-8b176389b525\""} 42]],\n  :errors\n  ({:path [0 0 :args 0],\n    :in [3], \n    :sch

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking some users - preventing them from sharing Questions with business users

### Additional context

You can work around this by wrapping the fields in a custom expression. EX if you use a concat([FIELD],"""") on a text field you can now see the expression and filter on it downstream. For numeric columns if you multiply by 1 you can also retain the expression and the downstream filter.",ixipixi,2024-06-28 23:35:19+00:00,['metamben'],2024-08-28 00:04:35+00:00,2024-08-23 21:30:30+00:00,https://github.com/metabase/metabase/issues/44940,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 2313777379, 'issue_id': 2381316604, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.22](https://github.com/metabase/metabase/milestone/265)', 'created_at': datetime.datetime(2024, 8, 28, 0, 4, 34, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-08-28 00:04:34 UTC): ðŸš€ This should also be released by [v0.50.22](https://github.com/metabase/metabase/milestone/265)

"
2381244735,issue,open,,"Users with ""Create Queries"" Disabled are Prompted to Ask a New Question on empty Dashboards","### Describe the bug

If a user doesn't have ""Create Query"" access for any databases the ""Question"" option disappears from the ""New"" menu as expected. But when they create an empty dashboard they're prompted to ""Add a saved question or ask a new one"". Following the prompts they can select a saved question or model as a data source and land on a non functional version of the query builder.

### To Reproduce

1. Set up v50 locally
2. Set ""Create Query"" access to all database to ""No"" for ""All Users""
3. Make a test question
4. Create a test user
5. Log in as test user
6. Create a dashboard
7. Click ""Ask a new one""
8. Select the test question as the data source
9. Note that you're in the query builder but only the top field selector box is visible

They can't actually use the GUI query builder but it's odd that they can get there

### Expected behavior

They shouldn't have access to create a new question at all.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""athena"",
      ""h2"",
      ""mysql"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v1.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

Ultimately they still don't have access to perform the functions they shouldn't; but it's confusing",ixipixi,2024-06-28 21:45:24+00:00,[],2024-07-01 10:02:11+00:00,,https://github.com/metabase/metabase/issues/44937,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2381122230,issue,closed,completed,Collection picker behaving oddly for snippets,"### Describe the bug

There are three main issues with the collection picker in the context of adding a snippet to a collection.

- the ""Recents"" tab on the collection picker is showing all recent collections, including non-snippet collections
- the regular collection picker is showing a weird mix of regular collections and snippet collections
- if i try to add a new collection, it tries to create it without the ""snippet"" namespace (which fails)

### To Reproduce

1. Create some regular collections.
2. Create a native query and click SQL Snippets
3. Click the + sign and ""New Folder""
4. Type some details and hit ""Save""
5. Click the + sign again and ""New Folder""
6. Click ""Folder this should be in"" to open the collection picker
7. **Problem 1: See your regular collections in the Recents tab**
8. Click ""Collections"" tab
9. **Problem 2: See your regular collections in this tab** (This one was inconsistent - caching?)
10. Click ""Create a new collection""
11. If you created a new collection in the ""root"" collection, it'll be invisible. If you tried to create one in your snippet collection, the creation will fail. (The frontend is trying to create a collection without the ""snippets"" namespace inside a collection that has the ""snippets"" namespace.

### Expected behavior

The collection picker should consistently show/create collections with the correct namespace.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master
```


### Severity

minor annoyance

### Additional context

https://www.loom.com/share/4635fcfc23f6456c91b26896189618c0",johnswanson,2024-06-28 20:18:47+00:00,['npfitz'],2024-07-16 12:03:03+00:00,2024-07-15 19:06:57+00:00,https://github.com/metabase/metabase/issues/44930,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2381116512,issue,closed,completed,"If you click on the ""Loading..."" bar in the command palette before results have loaded, the palette locks up","### Describe the bug

https://www.loom.com/share/80a19a60af1c48d4854076b2332e997d?sid=4010da60-614e-4da6-aaf6-f265183ae3b2

### To Reproduce

1. Open the command palette with Cmd+K
2. Type in a search query. If the instance has enough data, it'll take at least a couple seconds to load. In the meantime it'll show a `Loading...` text
3. If you click on this `Loading...` text before data has loaded, it'll cause everything in the command palette to vanish and essentially lock up. You won't be able to use it at all, even if you close and re-open it. Only way to fix it is with a refresh.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master (23ef0e2)
```


### Severity

P3 but annoying

### Additional context

_No response_",noahmoss,2024-06-28 20:15:50+00:00,['npfitz'],2024-07-15 12:31:40+00:00,2024-07-15 11:51:08+00:00,https://github.com/metabase/metabase/issues/44928,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Search', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2380980472,issue,open,,"Allow CSV appends/replacements to have duplicate columns, just like original uploads","From the [slack discussion](https://metaboat.slack.com/archives/C04S696LRUM/p1719524350450169):

We implemented de-duplicating column names in the first iteration of CSV uploads so you could upload a CSV file with multiple identical column names and weâ€™d make them unique. e.g. â€œAddress, Addressâ€ in the CSV file would create two columns address and address_2.

But we donâ€™t attempt to de-duplicate columns when appending/replacing with CSVs. Uploading a CSV file with the same headers as the original will result in an error like â€œMissing column address_2"". I chose this behaviour in [the testing plan](https://www.notion.so/metabase/Eng-Allow-appending-more-data-to-CSV-uploads-4c40e06fa64744c699588b8d8576e5df?pvs=4#18f0b6ce998043de8a4ec34d25f062b6), but I donâ€™t think we discussed this together.[@Chris Truter](https://metaboat.slack.com/team/U06C5MNFF0S) just pointed this behaviour out and Iâ€™m questioning whether I had a good reason for this limitation.

From Arakaki: ""This is P3'ish imo""",calherries,2024-06-28 18:45:19+00:00,[],2024-06-28 18:45:51+00:00,,https://github.com/metabase/metabase/issues/44926,"[('Type:New Feature', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2380903883,issue,open,,"Implement initial ""Kitchen Sink"" app DB for development and testing of complex scenarios","
## Description:

This task is from the v50 postmortem, where we identified that our typical
development app DB is too simplistic, leading to correctness regressions that
occur in more complex real-world scenarios. We need to create a ""Kitchen Sink""
(KS) app-db that represents a more realistic and complex Metabase instance to
use during development and testing.

We already have a lot of this machinery for h2, which is how e2e tests work. But
we are trying to get more realistic scenarios and that's not what customers
actually use so we should start by supporting only postgres.

## Background:

Our current development environments only have what the engineer has put into
them, often a blank-slate app DB. This has led to overlooking bugs that only
appear in more complex configurations.

## Goals:

- Establish a process for iteratively adding to and modifying the KSDB
- Make it trivial for developers to load and use this complex instance during development
- Create an initial version of the KS app DB with at least 1 known ""interesting"" case.

## Initial steps:

- [ ] Implement a mechanism to easily load, modify, and re-save this DB as plaintext (for git-friendly diffs)
    - [ ] Set up a basic postgres database dump file to serve as the initial KS app DB
    - [ ] Identify 1 ""interesting"" scenario from the v50 postmortem or other known edge scenario
    - [ ] Create SQL scripts to populate the DB, along with that scenario included

Implementation details:

- Load:

Use SQL scripts or a similar plaintext format to define the DB schema and contents
Ensure the save-to-disk format is reasonably git-diff friendly
Ensure the resulting sql is portable, do not include ownership info: `-O`
Provide clear documentation on how to load, use, and modify the KSDB

- Acceptance Criteria:

A working Postgres database file with initial KS data
Plaintext sql script to recreate the database from scratch
Documentation explaining how to load, use, and modify the KSDB, with a script
A well-defined process for adding new scenarios to the KSDB

- Future considerations:

Migration Tolerance: to make migrations work, we should load the ks, run the migration, and then save the sql dump back to disk.

- Regularly review and add new scenarios based on bug reports or feature developments
- Consider creating separate OSS and EE versions if needed

This approach allows us to start with a simple set of scenarios, while providing a framework for iterative improvements.",escherize,2024-06-28 17:50:53+00:00,"['appleby', 'bshepherdson', 'johnswanson']",2025-02-04 20:23:51+00:00,,https://github.com/metabase/metabase/issues/44924,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2380852664,issue,closed,completed,Build a backend api `metabase.stale` for getting stale items in a collection,,johnswanson,2024-06-28 17:15:29+00:00,[],2024-07-26 20:01:54+00:00,2024-07-26 20:01:54+00:00,https://github.com/metabase/metabase/issues/44923,[],[],
2380837371,issue,open,,Make it easy to spin up a large app DB for load testing,"This is a postmortem task related to certain performance regressions seen in v50.

We want to make it trivial to spin up an instance of Metabase on a dev branch with N entities, where N is an arbitrary large number, and the entities can be essentially any model: users, groups, DBs, tables, dashboards, collections, etc.

We have some precedence for this in tests, which use the `with-temp` macro to create temporary objects and then discard them at the end of the test. The idea here is to extend this so that you can create an arbitrary number of temp objects in an app DB and then check the performance of various features.",noahmoss,2024-06-28 17:05:49+00:00,[],2024-06-28 17:05:50+00:00,,https://github.com/metabase/metabase/issues/44922,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2380732697,issue,open,,Make things break in dev/CI/tests if too many DB queries,"We had a performance regression caused by an N+1 leading to a huge number of database queries being made for a single request.

We have an existing middleware that logs the number of database requests made during a single request. We can leverage this to make things break in dev/CI/tests in case there are too many requests. Even a very high limit (e.g. 100+ requests?) would probably catch the pathological cases without being a real limiting factor in general - maybe we can investigate the typical number as part of figuring this out.",johnswanson,2024-06-28 16:00:56+00:00,[],2024-06-28 16:00:56+00:00,,https://github.com/metabase/metabase/issues/44917,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2380725180,issue,closed,completed,Specifying a date in a custom expression breaks query (v50 regression),"### Describe the bug

Attempting to create a custom expression with either of the following breaks the query and show's an incorrect error:
- `[Ends At] > ""2023-05-01 23:59:59"" OR isnull([Ends At])`
- `coalesce([Ends At], ""2023-06-01 12:00:00"") > ""2023-05-01 23:59:59""`

This worked in v49.

Two issues here:
1. When attempting to create the expression, the UI complains that it's invalid.
![Screenshot 2024-06-27 at 03 52 00 PM@2x](https://github.com/metabase/metabase/assets/3343530/b9567589-efa3-4cea-a8f9-30600396dfcd)

2. For an existing question that had the expression already created in v49, when loading in v50 the query does not load. 
![Screenshot 2024-06-27 at 03 51 07 PM@2x](https://github.com/metabase/metabase/assets/3343530/22f7c819-be8b-4b03-b326-b01ab260b3e1)

### To Reproduce

1. Create a query
2. Attempt to create a custom expression with a date
3. See error.


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome
- App DB running MySQL
- Warehouse running bigquery
- Metabase version: v1.50.7
```


### Severity

Blocking upgrade to v50

### Additional context

_No response_",LukeAbell,2024-06-28 15:55:48+00:00,['bshepherdson'],2024-08-28 02:08:56+00:00,2024-07-03 13:02:10+00:00,https://github.com/metabase/metabase/issues/44916,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2197514599, 'issue_id': 2380725180, 'author': 'calherries', 'body': ""The second issue's error message indicates this is a type issue in metabase.lib. \r\nhttps://github.com/metabase/metabase/blob/d142da9984b0485c56c224b79116031973226399/src/metabase/lib/schema/filter.cljc#L21"", 'created_at': datetime.datetime(2024, 6, 28, 19, 34, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197518289, 'issue_id': 2380725180, 'author': 'calherries', 'body': 'Probably related: https://github.com/metabase/metabase/issues/44807. Also possibly related to any other issues in this slack [thread](https://metaboat.slack.com/archives/C05NXACAG1G/p1719602723317189?thread_ts=1719593031.652489&cid=C05NXACAG1G).', 'created_at': datetime.datetime(2024, 6, 28, 19, 37, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203671699, 'issue_id': 2380725180, 'author': 'bshepherdson', 'body': 'I tried this and it worked for me. Then I looked back at this bug and saw a difference:\r\n\r\n- `[Created At] < ""2024-06-30T23:59:59Z""` is allowed and queries correctly.\r\n- `[Created At] < ""2024-06-30 23:59:59Z""` gets `invalid expression`\r\n\r\nSo I think the key is that datetime strings need to be precisely ISO 8601 datetime strings, with the `T`. (And maybe the `Z` or other time zone indication like `+01:00` at the end?)\r\n\r\n@LukeAbell does that solve this issue, or do we know for sure the strings like\r\n`coalesce([Ends At], ""2023-06-01 12:00:00"") > ""2023-05-01 23:59:59""`\r\nused to work?', 'created_at': datetime.datetime(2024, 7, 2, 16, 0, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203718975, 'issue_id': 2380725180, 'author': 'LukeAbell', 'body': ""@bshepherdson `2023-06-01 12:00:00` definitely works in v49. I don't think we can specify a timezone in our saved question because the timezone is dependent on the tenant. Here's a screenshot of v49 working-\r\n![Screenshot 2024-07-02 at 12 09 31 PM@2x](https://github.com/metabase/metabase/assets/3343530/63cb332c-bfdc-4288-86c6-f9b2b2107c46)"", 'created_at': datetime.datetime(2024, 7, 2, 16, 12, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203730500, 'issue_id': 2380725180, 'author': 'LukeAbell', 'body': '@bshepherdson Does it work with just the `T`?', 'created_at': datetime.datetime(2024, 7, 2, 16, 15, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203911822, 'issue_id': 2380725180, 'author': 'bshepherdson', 'body': ""Yes, it works with the `T` and no time zone info.\r\n\r\nBut if it used to work, then this is still a regression, since it can break existing questions needlessly. I'll try to figure out where this change came from and make it more flexible."", 'created_at': datetime.datetime(2024, 7, 2, 17, 30, 41, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-28 19:34:53 UTC): The second issue's error message indicates this is a type issue in metabase.lib. 
https://github.com/metabase/metabase/blob/d142da9984b0485c56c224b79116031973226399/src/metabase/lib/schema/filter.cljc#L21

calherries on (2024-06-28 19:37:24 UTC): Probably related: https://github.com/metabase/metabase/issues/44807. Also possibly related to any other issues in this slack [thread](https://metaboat.slack.com/archives/C05NXACAG1G/p1719602723317189?thread_ts=1719593031.652489&cid=C05NXACAG1G).

bshepherdson (Assginee) on (2024-07-02 16:00:58 UTC): I tried this and it worked for me. Then I looked back at this bug and saw a difference:

- `[Created At] < ""2024-06-30T23:59:59Z""` is allowed and queries correctly.
- `[Created At] < ""2024-06-30 23:59:59Z""` gets `invalid expression`

So I think the key is that datetime strings need to be precisely ISO 8601 datetime strings, with the `T`. (And maybe the `Z` or other time zone indication like `+01:00` at the end?)

@LukeAbell does that solve this issue, or do we know for sure the strings like
`coalesce([Ends At], ""2023-06-01 12:00:00"") > ""2023-05-01 23:59:59""`
used to work?

LukeAbell (Issue Creator) on (2024-07-02 16:12:23 UTC): @bshepherdson `2023-06-01 12:00:00` definitely works in v49. I don't think we can specify a timezone in our saved question because the timezone is dependent on the tenant. Here's a screenshot of v49 working-
![Screenshot 2024-07-02 at 12 09 31 PM@2x](https://github.com/metabase/metabase/assets/3343530/63cb332c-bfdc-4288-86c6-f9b2b2107c46)

LukeAbell (Issue Creator) on (2024-07-02 16:15:22 UTC): @bshepherdson Does it work with just the `T`?

bshepherdson (Assginee) on (2024-07-02 17:30:41 UTC): Yes, it works with the `T` and no time zone info.

But if it used to work, then this is still a regression, since it can break existing questions needlessly. I'll try to figure out where this change came from and make it more flexible.

"
2380696017,issue,closed,completed,Column Name with Question Mark causes Filters to Fail (Athena),"### Describe the bug

If the column name contains a question mark and you attempt the filter the resulting table visualization, the filter fails with: 

[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. INVALID_PARAMETER_USAGE: line 2:1: Incorrect number of parameters: expected 1 but found 0 [Execution ID: 3971d852-2ff4-4ecf-80f2-027e703643b9]

### To Reproduce

1. Set up a connection to Athena w/ Sample DB
2. Edit a table to contain a question mark in the column
3. Make a simple question with the table and visualize it
4. Attempt to filter a column from the table
5. Observer error

You can also produce this by just writing a SQL question and aliasing the column so that it includes a Question mark in the alias name. 


### Expected behavior

The filter should work

### Logs

```
[3cb5effc-6b55-49f4-ba16-372bd1e30a16] 2024-06-28T10:35:04-05:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: [Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. INVALID_PARAMETER_USAGE: line 2:1: Incorrect number of parameters: expected 1 but found 0 [Execution ID: 56ecdd8c-45b0-4159-84ce-12088d9a601d]
{:database_id 2,
 :started_at #t ""2024-06-28T15:35:04.194391Z[GMT]"",
 :via
 [{:status :failed,
   :class java.sql.SQLException,
   :error
   ""[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. INVALID_PARAMETER_USAGE: line 2:1: Incorrect number of parameters: expected 1 but found 0 [Execution ID: 56ecdd8c-45b0-4159-84ce-12088d9a601d]"",
   :stacktrace
   [""com.simba.athena.athena.api.AJClient.executeQuery(Unknown Source)""
    ""com.simba.athena.athena.dataengine.AJQueryExecutor.execute(Unknown Source)""
    ""com.simba.athena.jdbc.common.SStatement.executeNoParams(Unknown Source)""
    ""com.simba.athena.jdbc.common.BaseStatement.execute(Unknown Source)""
    ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
    ""--> driver.sql_jdbc.execute$fn__79775.invokeStatic(execute.clj:561)""
    ""driver.sql_jdbc.execute$fn__79775.invoke(execute.clj:559)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:569)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:566)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79856$fn__79857.invoke(execute.clj:700)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79856.invoke(execute.clj:699)""
    ""driver.sql_jdbc.execute$fn__79649$fn__79650.invoke(execute.clj:389)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
    ""driver.sql_jdbc.execute$fn__79649.invokeStatic(execute.clj:383)""
    ""driver.sql_jdbc.execute$fn__79649.invoke(execute.clj:381)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc$fn__113249.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__113249.invoke(sql_jdbc.clj:76)""
    ""driver.athena$fn__125830.invokeStatic(athena.clj:448)""
    ""driver.athena$fn__125830.invoke(athena.clj:446)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72665.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__67012.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__107647$check_download_permissions__107648$fn__107649.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72486.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__108508$maybe_apply_column_level_perms_check__108509$fn__108510.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72496.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71928.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73833$combined_post_process__73838$combined_post_process_STAR___73839.invoke(query_processor.clj:262)""
    ""query_processor$fn__73833$combined_pre_process__73834$combined_pre_process_STAR___73835.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67109.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576$fn__72580.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67736$fn__67737.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67736.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72573.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72878.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__80257$handle_audit_app_internal_queries__80258$fn__80260.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72524.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71639.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72809.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73410.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___63228$thunk__63230.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___63228.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___63240.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__95067.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53640$fn__53642.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53640.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88)""],
   :state ""HY000""}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: [Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. INVALID_PARAMETER_USAGE: line 2:1: Incorrect number of parameters: expected 1 but found 0 [Execution ID: 56ecdd8c-45b0-4159-84ce-12088d9a601d]"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__79856$fn__79857.invoke(execute.clj:702)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79856.invoke(execute.clj:699)""
    ""driver.sql_jdbc.execute$fn__79649$fn__79650.invoke(execute.clj:389)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
    ""driver.sql_jdbc.execute$fn__79649.invokeStatic(execute.clj:383)""
    ""driver.sql_jdbc.execute$fn__79649.invoke(execute.clj:381)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
    ""driver.sql_jdbc$fn__113249.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__113249.invoke(sql_jdbc.clj:76)""
    ""driver.athena$fn__125830.invokeStatic(athena.clj:448)""
    ""driver.athena$fn__125830.invoke(athena.clj:446)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72665.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__67012.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__107647$check_download_permissions__107648$fn__107649.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72486.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__108508$maybe_apply_column_level_perms_check__108509$fn__108510.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72496.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71928.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73833$combined_post_process__73838$combined_post_process_STAR___73839.invoke(query_processor.clj:262)""
    ""query_processor$fn__73833$combined_pre_process__73834$combined_pre_process_STAR___73835.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67109.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576$fn__72580.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67736$fn__67737.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67736.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72573.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72878.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__80257$handle_audit_app_internal_queries__80258$fn__80260.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72524.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71639.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72809.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73410.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___63228$thunk__63230.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___63228.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___63240.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__95067.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53640$fn__53642.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53640.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :athena,
    :sql
    [""-- Metabase:: userID: 1 queryType: MBQL queryHash: 0342e026793fe558e3ee41c4920ab2ee2966db9c145aaabdbb1398a4e842e880""
     ""SELECT""
     ""  \""s3-data-source\"".\""param_test\"".\""column1\"" AS \""column1\"",""
     ""  \""s3-data-source\"".\""param_test\"".\""question' wut'\"" AS \""question?\"",""
     ""  \""s3-data-source\"".\""param_test\"".\""hello\"" AS \""hello\""""
     ""FROM""
     ""  \""s3-data-source\"".\""param_test\""""
     ""WHERE""
     ""  \""s3-data-source\"".\""param_test\"".\""hello\"" = ?""
     ""LIMIT""
     ""  2000""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 2,
  :type ""query"",
  :query {:source-table 392, :filter [""="" [""field"" 479 {:base-type ""type/Text""}] "" wut""]},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""s3-data-source\"".\""param_test\"".\""column1\"" AS \""column1\"", \""s3-data-source\"".\""param_test\"".\""question?\"" AS \""question?\"", \""s3-data-source\"".\""param_test\"".\""hello\"" AS \""hello\"" FROM \""s3-data-source\"".\""param_test\"" WHERE \""s3-data-source\"".\""param_test\"".\""hello\"" = ? LIMIT 1048575"",
  :params ("" wut"")},
 :status :failed,
 :class com.simba.athena.support.exceptions.GeneralException,
 :stacktrace
 [""com.simba.athena.athena.api.AJClient.executeQuery(Unknown Source)""
  ""com.simba.athena.athena.dataengine.AJQueryExecutor.execute(Unknown Source)""
  ""com.simba.athena.jdbc.common.SStatement.executeNoParams(Unknown Source)""
  ""com.simba.athena.jdbc.common.BaseStatement.execute(Unknown Source)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__79775.invokeStatic(execute.clj:561)""
  ""driver.sql_jdbc.execute$fn__79775.invoke(execute.clj:559)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:569)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:566)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__79856$fn__79857.invoke(execute.clj:700)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__79856.invoke(execute.clj:699)""
  ""driver.sql_jdbc.execute$fn__79649$fn__79650.invoke(execute.clj:389)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
  ""driver.sql_jdbc.execute$fn__79649.invokeStatic(execute.clj:383)""
  ""driver.sql_jdbc.execute$fn__79649.invoke(execute.clj:381)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
  ""driver.sql_jdbc$fn__113249.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__113249.invoke(sql_jdbc.clj:76)""
  ""driver.athena$fn__125830.invokeStatic(athena.clj:448)""
  ""driver.athena$fn__125830.invoke(athena.clj:446)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72665.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__67012.invoke(permissions.clj:140)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__107647$check_download_permissions__107648$fn__107649.invoke(permissions.clj:127)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72486.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__108508$maybe_apply_column_level_perms_check__108509$fn__108510.invoke(column_level_perms_check.clj:33)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72496.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71928.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73833$combined_post_process__73838$combined_post_process_STAR___73839.invoke(query_processor.clj:262)""
  ""query_processor$fn__73833$combined_pre_process__73834$combined_pre_process_STAR___73835.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67109.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576$fn__72580.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72576.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67736$fn__67737.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67736.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72573.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72878.invoke(normalize_query.clj:38)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__80257$handle_audit_app_internal_queries__80258$fn__80260.invoke(handle_audit_queries.clj:142)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72524.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71639.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72809.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73410.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___63228$thunk__63230.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___63228.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___63240.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__95067.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53640$fn__53642.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53640.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. INVALID_PARAMETER_USAGE: line 2:1: Incorrect number of parameters: expected 1 but found 0 [Execution ID: 56ecdd8c-45b0-4159-84ce-12088d9a601d]"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 2,
  :type :query,
  :query
  {:source-table 392,
   :filter
   [:=
    [:field 479 {:base-type :type/Text}]
    [:value
     "" wut""
     {:base_type :type/Text,
      :effective_type :type/Text,
      :coercion_strategy nil,
      :semantic_type :type/Category,
      :database_type ""string"",
      :name ""hello""}]],
   :fields [[:field 480 nil] [:field 478 nil] [:field 479 nil]],
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 1, :context :ad-hoc}},
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.49.17"",
      ""hash"": ""7e2b7bb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

Also fails when dashboard filters are applied",ixipixi,2024-06-28 15:37:33+00:00,['camsaul'],2024-08-28 02:08:56+00:00,2024-07-03 21:37:12+00:00,https://github.com/metabase/metabase/issues/44915,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('Database/Athena', ''), ('.Escalation', ''), ('.Team/Querying', '')]",[],
2380600246,issue,open,,Selection lost after cancelling move or delete in Trash,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/1d0227ef-9a1e-4194-b4f3-1baecf4f21b7



### To Reproduce

1. Delete a few entities
2. Go to trash
3. Select a few items
4. Click ""Delete permanently"" at the bottom of the screen
5. Change your mind - decide to move the items into a new ""My archive"" collection instead
6. Close the modal

All checkboxes get unchecked

### Expected behavior

Selection is not lost when cancelling move or delete.


### Information about your Metabase installation


master, [da0c9cb](https://github.com/metabase/metabase/commit/da0c9cb64568a0e9478a19b74c0652c2ba3be4a5)


### Severity

P3
",kamilmielnik,2024-06-28 14:43:59+00:00,[],2024-07-01 13:17:05+00:00,,https://github.com/metabase/metabase/issues/44911,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2197105773, 'issue_id': 2380600246, 'author': 'kamilmielnik', 'body': 'Also order of actions is inconsistent:\r\n\r\n![image](https://github.com/metabase/metabase/assets/6830683/e39c2b7b-e604-4dc8-bac7-db0abd2b9926)\r\n\r\n![image](https://github.com/metabase/metabase/assets/6830683/1df7ada5-9aae-4d04-898f-189151bf45cb)', 'created_at': datetime.datetime(2024, 6, 28, 14, 46, 18, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-06-28 14:46:18 UTC): Also order of actions is inconsistent:

![image](https://github.com/metabase/metabase/assets/6830683/e39c2b7b-e604-4dc8-bac7-db0abd2b9926)

![image](https://github.com/metabase/metabase/assets/6830683/1df7ada5-9aae-4d04-898f-189151bf45cb)

"
2380587516,issue,closed,completed,Multiple menus can be opened simultaneously in Trash ,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/764e47c2-2e51-4e31-a432-1765272c478d)


### To Reproduce

1. Delete a few entities
2. Go to trash
3. Click on ""..."" button for every item, starting from the last one


### Information about your Metabase installation

master, da0c9cb645


### Severity

P3
",kamilmielnik,2024-06-28 14:37:09+00:00,['rafpaf'],2024-07-18 23:41:28+00:00,2024-07-17 13:42:28+00:00,https://github.com/metabase/metabase/issues/44910,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2380271338,issue,open,,"Broken host input icon in ""add database"" form","### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/3a1e4651-0ec4-44ff-a305-746f6396ab32)

![image](https://github.com/metabase/metabase/assets/6830683/3394e19d-8df3-4de1-82ae-cada29e911e1)


### To Reproduce

1. Go to http://localhost:3000/admin/databases/create

:x: icon is wrong (the `class` of the element includes the tooltip text)
:x: `aria-label` is incorrect (it has ` icon` suffix)

### Information about your Metabase installation

master, da0c9cb645

### Severity

P3
",kamilmielnik,2024-06-28 11:59:38+00:00,[],2024-06-28 12:39:43+00:00,,https://github.com/metabase/metabase/issues/44902,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2380137520,issue,closed,completed,SDK crashes when the theme prop is not provided,"The embedding SDK crashes when the `theme` prop is not provided to the MetabaseProvider.

```tsx
    <MetabaseProvider config={config}>
      {children}
    </MetabaseProvider>
```",heypoom,2024-06-28 10:48:22+00:00,['heypoom'],2024-10-08 17:05:32+00:00,2024-07-02 08:29:55+00:00,https://github.com/metabase/metabase/issues/44897,[],[],
2380024342,issue,open,,List of refactor backports we paused regarding dashboard controls,"Full context: https://metaboat.slack.com/archives/C010L1Z4F9S/p1719486012935039?thread_ts=1719484942.602539&cid=C010L1Z4F9S

- https://github.com/metabase/metabase/pull/44689
- https://github.com/metabase/metabase/pull/44669
- https://github.com/metabase/metabase/pull/44621
- https://github.com/metabase/metabase/pull/44544
- https://github.com/metabase/metabase/pull/44490",npretto,2024-06-28 09:42:41+00:00,[],2024-06-28 10:07:21+00:00,,https://github.com/metabase/metabase/issues/44890,"[('Type:Tech Debt', 'or Refactoring'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', '')]",[],
2379841978,issue,open,,Metabase produces null values due to the nullif function,"### Describe the bug

Create custom expression in question with following data
=Sum([A]) / Sum([B])

metabase generate SQL
SELECT
  SUM(`test`.`a`) / NULLIF(SUM(`test`.`b`), 0) AS `test-a`
FROM
  `test`

resulting to ""NULL"" in the question



### To Reproduce

1. Create table in database, ""create table test ( a double, b double )  engine=columnstore"";
2. insert value to new table, ""insert into test values (100,100);
3. create question in metabase with custom expression sum(a)/sum(b)
4. result of question is null


### Expected behavior

metabase should return 1 for above example, instead null value

possible cause of this issue is, metabase auto generated NULLIF function for divide value, if the sql generated without NULLIF function, the system return correct value

### Logs

none

### Information about your Metabase installation

```JSON
- Client Browser 126.0.6478.127 (Official Build) (64-bit)
- Client OS - MS Windows 11
- Database connected to : MariaDB 11.4 with columnstore engine
- Metabase version : 0.50.6
- Metabase hosted on : Ubuntu Linux 20.04
- Metabase internal database : Mysql 8.0.37
```


### Severity

blocking usage of metabase for certain question

### Additional context

_No response_",BambangSumitra,2024-06-28 08:02:47+00:00,[],2025-02-04 20:27:53+00:00,,https://github.com/metabase/metabase/issues/44874,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/MySQL', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2379777678,issue,closed,completed,Dropdown slightly shifts after hover on items,"### Describe the bug

seems line-height of the item is changed when ""info"" icon is shown, we'd need to get rid of such shifts


https://github.com/metabase/metabase/assets/125459446/60ca7fa3-0866-424e-866b-46a2edef511f



### To Reproduce

1. new sql question
2. put `select * from orders where tax = {{t}}`
3. change variable type to the field filter
4. move mouse over the list of available fields


### Expected behavior

no shifts because of line-height

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.7+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.7"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.7+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Minsk""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-06-27"",
      ""src_hash"": ""75d377187a97224423e5813f4a17fa2eb49575b9"",
      ""tag"": ""v0.1.15-SNAPSHOT"",
      ""hash"": ""3798798""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

_No response_",uladzimirdev,2024-06-28 07:23:48+00:00,['romeovs'],2024-07-09 10:40:13+00:00,2024-07-09 10:04:51+00:00,https://github.com/metabase/metabase/issues/44869,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2214644098, 'issue_id': 2379777678, 'author': 'nemanjaglumac', 'body': '`legacy-popover` ðŸ’€', 'created_at': datetime.datetime(2024, 7, 8, 16, 35, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2214680335, 'issue_id': 2379777678, 'author': 'nemanjaglumac', 'body': 'Introduced in #39296', 'created_at': datetime.datetime(2024, 7, 8, 16, 49, 36, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-08 16:35:49 UTC): `legacy-popover` ðŸ’€

nemanjaglumac on (2024-07-08 16:49:36 UTC): Introduced in #39296

"
2379260561,issue,closed,completed,Updating filter on one dashboard automatically updates filters on other dashboards with cards referencing the same data,"### Describe the bug

Updating filter on one dashboard automatically updates filters on other dashboards with cards referencing the same data. It used to not be the case. 

eg. we have sales rep dashboard for each sales rep with a text filter defaults to that sales rep's name. Recently (not sure since when), whoever opens their dashboard first would change that text filter's value to their name across all sales reps' dashboards. 

### To Reproduce

1. open a dashboard with a text filter applying to a text field of a card. The text filter value defaults to ""a"" in the dashboard setting.
2. open another dashboard with a text filter applying to the same text field of a different card. The text filter value defaults to ""b"" in the dashboard setting.
3. open the dashboard from step 1, and the text filter value now defaults to ""b"" instead of ""a"".

### Expected behavior

changing filters in one dashboard should not change filters automatically of other dashboards

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",gloriaalt,2024-06-27 23:36:37+00:00,[],2024-07-03 22:06:32+00:00,2024-07-03 22:06:32+00:00,https://github.com/metabase/metabase/issues/44858,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2203496594, 'issue_id': 2379260561, 'author': 'adam-james-v', 'body': ""@gloriaalt, I'm sorry you've encountered this. \r\nSadly, I've not been able to reproduce this issue. \r\n\r\nAre you able to provide a bit more context? If it's possible do you have some screenshots showing the specifics of how you've encountered this?"", 'created_at': datetime.datetime(2024, 7, 2, 15, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204626242, 'issue_id': 2379260561, 'author': 'adam-james-v', 'body': ""@gloriaalt , I'm curious if you've created the dashboards exhibiting this behaviour by using the 'duplicate' feature? If the answer is 'yes', then I can confirm that the linked PR above #45064 will solve this bug and should be in an upcoming v50 minor release."", 'created_at': datetime.datetime(2024, 7, 2, 22, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204675368, 'issue_id': 2379260561, 'author': 'gloriaalt', 'body': ""That's right - the dashboards were duplicated and then modified. Thanks for\r\nthe update!\r\n\r\nOn Tue, Jul 2, 2024 at 3:56\u202fPM adam-james ***@***.***> wrote:\r\n\r\n> @gloriaalt <https://github.com/gloriaalt> , I'm curious if you've created\r\n> the dashboards exhibiting this behaviour by using the 'duplicate' feature?\r\n> If the answer is 'yes', then I can confirm that the linked PR above #45064\r\n> <https://github.com/metabase/metabase/pull/45064> will solve this bug and\r\n> should be in an upcoming v50 minor release.\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/44858#issuecomment-2204626242>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AYOPY5YGPSGGZBSE7VQQF4TZKMVYLAVCNFSM6AAAAABKA2XJCWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMBUGYZDMMRUGI>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 7, 2, 23, 25, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206764109, 'issue_id': 2379260561, 'author': 'adam-james-v', 'body': ""Thanks for letting me know. That's great news, once that PR is merged this issue should then be solved :)"", 'created_at': datetime.datetime(2024, 7, 3, 16, 35, 50, tzinfo=datetime.timezone.utc)}]","adam-james-v on (2024-07-02 15:15:00 UTC): @gloriaalt, I'm sorry you've encountered this. 
Sadly, I've not been able to reproduce this issue. 

Are you able to provide a bit more context? If it's possible do you have some screenshots showing the specifics of how you've encountered this?

adam-james-v on (2024-07-02 22:55:43 UTC): @gloriaalt , I'm curious if you've created the dashboards exhibiting this behaviour by using the 'duplicate' feature? If the answer is 'yes', then I can confirm that the linked PR above #45064 will solve this bug and should be in an upcoming v50 minor release.

gloriaalt (Issue Creator) on (2024-07-02 23:25:11 UTC): That's right - the dashboards were duplicated and then modified. Thanks for
the update!

On Tue, Jul 2, 2024 at 3:56â€¯PM adam-james ***@***.***> wrote:

adam-james-v on (2024-07-03 16:35:50 UTC): Thanks for letting me know. That's great news, once that PR is merged this issue should then be solved :)

"
2379239815,issue,open,,Don't 404 on `api/card/<id>/unpersist` if the card is not persisted,"we 404 on no card which is sensible. But we also 404 on the persistence record

`(api/let-404 [persisted-info (t2/select-one PersistedInfo :card_id card-id)]`

We should just 204 there if it isn't already persisted.

https://metaboat.slack.com/archives/C01LQQ2UW03/p1719529206708639",dpsutton,2024-06-27 23:13:34+00:00,[],2025-02-05 19:06:00+00:00,,https://github.com/metabase/metabase/issues/44857,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2338923750, 'issue_id': 2379239815, 'author': 'iethree', 'body': 'agreed. see: https://github.com/metabase/metabase/blob/b797ea4f036b1cf7fb05483e652c28c47558b15b/frontend/src/metabase/query_builder/components/view/sidebars/ModelCacheManagementSection/ModelCacheManagementSection.tsx#L49-L51', 'created_at': datetime.datetime(2024, 9, 9, 19, 34, 19, tzinfo=datetime.timezone.utc)}]","iethree on (2024-09-09 19:34:19 UTC): agreed. see: https://github.com/metabase/metabase/blob/b797ea4f036b1cf7fb05483e652c28c47558b15b/frontend/src/metabase/query_builder/components/view/sidebars/ModelCacheManagementSection/ModelCacheManagementSection.tsx#L49-L51

"
2379124460,issue,closed,completed,"Saving a Question based on a Question from ""Metabase Analytics"" makes Internal Database available in GUI","### Describe the bug

If you start from a question in the ""Metabase Analytics"" collection and save a copy of it anywhere you temporarily gain access to ""Internal Metabase Database"" in the native SQL editor and in ""Admin -> Data -> Permissions"".

### To Reproduce

1. Spin up an instance of v49
2. Go to ""Metabase Analytics""
3. Open any Question in the collection
4. Save a copy to Metabase Analytics -> Custom Reports
5. Now create a SQL Question and note that you can see ""Internal Metabase Database"" as an option
6. Go to Admin -> Permissions -> Data and select a group; you can also see it there
7. Refresh the page and it's gone
8. Rinse / repeat

Loom recording:
https://www.loom.com/share/ce2a5512835e493db96789957abe1ddc

### Expected behavior

""Internal Metabase Database"" shouldn't be visible in data permissions or accessible from the native editor

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2"",
      ""snowflake"",
      ""athena"",
      ""mysql"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-28"",
      ""tag"": ""v1.49.13"",
      ""hash"": ""de28e83""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

It's certainly confusing when it happens

### Additional context

I had v50.3 already up so I tested there, too, and I can partially reproduce. It shows up in ""Permissions -> Data"" but not the Native SQL Editor.",ixipixi,2024-06-27 21:34:16+00:00,['iethree'],2024-07-24 19:02:11+00:00,2024-07-23 16:25:38+00:00,https://github.com/metabase/metabase/issues/44856,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2248710777, 'issue_id': 2379124460, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.16](https://github.com/metabase/metabase/milestone/257)', 'created_at': datetime.datetime(2024, 7, 24, 19, 2, 10, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-24 19:02:10 UTC): ðŸš€ This should also be released by [v0.50.16](https://github.com/metabase/metabase/milestone/257)

"
2379070579,issue,closed,completed,"Users with ""No Query Access"" receive Incorrect error when trying to promote Questions to models","### Describe the bug

If a user does not have access to create queries for a database they are presented the option in the GUI to promote Questions for that Database to models. If they attempt to do so they're presented with the error: ""Variables in models aren't supported yet"" even though the questions do not have variables.

### To Reproduce

1. Spin up a new Metabase instance (v50)
2. Create a simple Question from the Sample DB and call is ""Test Question""
3. Create a test user
4. Set ""Create Queries"" data permission to ""No"" for hte ""All Users"" group on the Sample DB
5. Log in as test user
6. Navigate to ""Test Question"" and attempt to convert it into a model
7. Error says ""Variables in models aren't supported yet""

### Expected behavior

I am unclear on whether users with this access level should be able to promote questions to models or not. Either this should work or, if they're not able to do this, the option should be removed or the error message corrected.

### Logs

[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:10-05:00 DEBUG metabase.server.middleware.log GET /api/ee/audit-app/user/audit-info 200 4.5 ms (2 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 24.3 ms (8 DB calls) App DB connections: 1/15 Jetty threads: 7/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 30.0 ms (13 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/collection/root 200 9.2 ms (2 DB calls) App DB connections: 2/15 Jetty threads: 10/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/bookmark 200 7.1 ms (1 DB calls) App DB connections: 4/15 Jetty threads: 10/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 17.6 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 9/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/database 200 23.4 ms (2 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/search 200 34.0 ms (5 DB calls) App DB connections: 1/15 Jetty threads: 7/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 7.2 ms (3 DB calls) App DB connections: 1/15 Jetty threads: 8/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/card/120 200 67.1 ms (19 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/search 200 38.8 ms (11 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (1 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:23-05:00 DEBUG metabase.server.middleware.log GET /api/alert/question/120 200 8.0 ms (1 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 WARN metabase.api.query-metadata Some (possibly virtual) tables are not readable by the current user
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 WARN metabase.api.query-metadata Error in dashboard metadata :database 1: You don't have permissions to do that.
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 DEBUG metabase.server.middleware.log GET /api/card/120/query_metadata 200 77.2 ms (26 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 DEBUG metabase.server.middleware.log GET /api/collection/8 200 10.6 ms (4 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (2 idle, 0 queued) (75 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 DEBUG metabase.server.middleware.log POST /api/card/120/query 202 [ASYNC: completed] 196.5 ms (26 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (2 idle, 0 queued) (78 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked) {:metabase-user-id 2}
[2295ac22-8263-4a0f-9c0f-88fca6df06d1] 2024-06-27T15:41:24-05:00 WARN metabase.server.middleware.log GET /api/database/1 403 9.0 ms (2 DB calls) {:metabase-user-id 2} 
""You don't have permissions to do that.""

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""athena"",
      ""mysql"",
      ""sqlserver"",
      ""h2"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v1.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

In permissions the deprecation message for ""No Self Service"" also contains a link to documentation that does not exist anymore.",ixipixi,2024-06-27 20:49:20+00:00,['ranquild'],2024-07-04 20:57:51+00:00,2024-07-04 16:08:04+00:00,https://github.com/metabase/metabase/issues/44854,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2378973888,issue,closed,not_planned,Metabase enterprise migration failed v1.50.X,"### Describe the bug

When updating the metabase enterprise from version v1.48.7 to v1.50.7 I am receiving an error during the migration process.

### To Reproduce

1. Upgrade metabase enterprise v1.48.7 to version v1.50.7

### Expected behavior

Migration completed

### Logs

```
2024-06-27 18:10:27,685 INFO db.liquibase :: Running 1 migrations ...
2024-06-27 18:10:28,285 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha encountered an exception.
liquibase.exception.DatabaseException: ERROR: failed to find conversion function from unknown to text [Failed SQL: (0) WITH root AS (
  select 'root' AS model,
         0      AS model_id,
         'ttl'  AS strategy,
         json_build_object(
           'multiplier', coalesce((select value::float::int from setting where key = 'query-caching-ttl-ratio'), 10),
           'min_duration_ms', coalesce((select value::float::int from setting where key = 'query-caching-min-ttl'), 60000)
         ) AS config
), database AS (
  select 'database' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from metabase_database
   where cache_ttl is not null
), dashboard AS (
  select 'dashboard' AS model,
         id          AS model_id,
         'duration'  AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_dashboard
   where cache_ttl is not null
), card AS (
  select 'question' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_card
   where cache_ttl is not null
), rows1 AS (
  SELECT * FROM root UNION ALL
  SELECT * FROM database UNION ALL
  SELECT * FROM dashboard UNION ALL
  SELECT * FROM card
), rows AS (
  SELECT * FROM rows1
   WHERE (SELECT true FROM setting WHERE key = 'enable-query-caching' AND VALUE = 'true')
)
    INSERT INTO cache_config (model, model_id, strategy, config)
    SELECT * FROM rows
    ON CONFLICT (model, model_id) DO NOTHING]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44430.invoke(liquibase.clj:359)
	at metabase.db.liquibase$run_in_scope_locked$reify__44426.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:348)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:341)
	at metabase.db.setup$migrate_BANG_$fn__53357.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44367.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53385$fn__53386.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53385.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53410.invoke(db.clj:82)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: failed to find conversion function from unknown to text
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more

UPDATE SUMMARY
Run:                          1
Previously run:             334
Filtered out:                50
-------------------------------
Total change sets:          385


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               50

2024-06-27 18:10:28,474 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha:
     Reason: liquibase.exception.DatabaseException: ERROR: failed to find conversion function from unknown to text [Failed SQL: (0) WITH root AS (
  select 'root' AS model,
         0      AS model_id,
         'ttl'  AS strategy,
         json_build_object(
           'multiplier', coalesce((select value::float::int from setting where key = 'query-caching-ttl-ratio'), 10),
           'min_duration_ms', coalesce((select value::float::int from setting where key = 'query-caching-min-ttl'), 60000)
         ) AS config
), database AS (
  select 'database' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from metabase_database
   where cache_ttl is not null
), dashboard AS (
  select 'dashboard' AS model,
         id          AS model_id,
         'duration'  AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_dashboard
   where cache_ttl is not null
), card AS (
  select 'question' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_card
   where cache_ttl is not null
), rows1 AS (
  SELECT * FROM root UNION ALL
  SELECT * FROM database UNION ALL
  SELECT * FROM dashboard UNION ALL
  SELECT * FROM card
), rows AS (
  SELECT * FROM rows1
   WHERE (SELECT true FROM setting WHERE key = 'enable-query-caching' AND VALUE = 'true')
)
    INSERT INTO cache_config (model, model_id, strategy, config)
    SELECT * FROM rows
    ON CONFLICT (model, model_id) DO NOTHING]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44430.invoke(liquibase.clj:359)
	at metabase.db.liquibase$run_in_scope_locked$reify__44426.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:348)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:341)
	at metabase.db.setup$migrate_BANG_$fn__53357.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44367.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53385$fn__53386.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53385.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53410.invoke(db.clj:82)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha:
     Reason: liquibase.exception.DatabaseException: ERROR: failed to find conversion function from unknown to text [Failed SQL: (0) WITH root AS (
  select 'root' AS model,
         0      AS model_id,
         'ttl'  AS strategy,
         json_build_object(
           'multiplier', coalesce((select value::float::int from setting where key = 'query-caching-ttl-ratio'), 10),
           'min_duration_ms', coalesce((select value::float::int from setting where key = 'query-caching-min-ttl'), 60000)
         ) AS config
), database AS (
  select 'database' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from metabase_database
   where cache_ttl is not null
), dashboard AS (
  select 'dashboard' AS model,
         id          AS model_id,
         'duration'  AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_dashboard
   where cache_ttl is not null
), card AS (
  select 'question' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_card
   where cache_ttl is not null
), rows1 AS (
  SELECT * FROM root UNION ALL
  SELECT * FROM database UNION ALL
  SELECT * FROM dashboard UNION ALL
  SELECT * FROM card
), rows AS (
  SELECT * FROM rows1
   WHERE (SELECT true FROM setting WHERE key = 'enable-query-caching' AND VALUE = 'true')
)
    INSERT INTO cache_config (model, model_id, strategy, config)
    SELECT * FROM rows
    ON CONFLICT (model, model_id) DO NOTHING]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 58 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:08::piranha:
     Reason: liquibase.exception.DatabaseException: ERROR: failed to find conversion function from unknown to text [Failed SQL: (0) WITH root AS (
  select 'root' AS model,
         0      AS model_id,
         'ttl'  AS strategy,
         json_build_object(
           'multiplier', coalesce((select value::float::int from setting where key = 'query-caching-ttl-ratio'), 10),
           'min_duration_ms', coalesce((select value::float::int from setting where key = 'query-caching-min-ttl'), 60000)
         ) AS config
), database AS (
  select 'database' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from metabase_database
   where cache_ttl is not null
), dashboard AS (
  select 'dashboard' AS model,
         id          AS model_id,
         'duration'  AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_dashboard
   where cache_ttl is not null
), card AS (
  select 'question' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_card
   where cache_ttl is not null
), rows1 AS (
  SELECT * FROM root UNION ALL
  SELECT * FROM database UNION ALL
  SELECT * FROM dashboard UNION ALL
  SELECT * FROM card
), rows AS (
  SELECT * FROM rows1
   WHERE (SELECT true FROM setting WHERE key = 'enable-query-caching' AND VALUE = 'true')
)
    INSERT INTO cache_config (model, model_id, strategy, config)
    SELECT * FROM rows
    ON CONFLICT (model, model_id) DO NOTHING]
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: ERROR: failed to find conversion function from unknown to text [Failed SQL: (0) WITH root AS (
  select 'root' AS model,
         0      AS model_id,
         'ttl'  AS strategy,
         json_build_object(
           'multiplier', coalesce((select value::float::int from setting where key = 'query-caching-ttl-ratio'), 10),
           'min_duration_ms', coalesce((select value::float::int from setting where key = 'query-caching-min-ttl'), 60000)
         ) AS config
), database AS (
  select 'database' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from metabase_database
   where cache_ttl is not null
), dashboard AS (
  select 'dashboard' AS model,
         id          AS model_id,
         'duration'  AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_dashboard
   where cache_ttl is not null
), card AS (
  select 'question' AS model,
         id         AS model_id,
         'duration' AS strategy,
         json_build_object('duration', cache_ttl, 'unit', 'hours') AS config
    from report_card
   where cache_ttl is not null
), rows1 AS (
  SELECT * FROM root UNION ALL
  SELECT * FROM database UNION ALL
  SELECT * FROM dashboard UNION ALL
  SELECT * FROM card
), rows AS (
  SELECT * FROM rows1
   WHERE (SELECT true FROM setting WHERE key = 'enable-query-caching' AND VALUE = 'true')
)
    INSERT INTO cache_config (model, model_id, strategy, config)
    SELECT * FROM rows
    ON CONFLICT (model, model_id) DO NOTHING]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 81 more
Caused by: org.postgresql.util.PSQLException: ERROR: failed to find conversion function from unknown to text
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
2024-06-27 18:10:28,478 INFO metabase.core :: Metabase Shutting Down ...
2024-06-27 18:10:28,478 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-06-27 18:10:28,484 WARN db.liquibase :: ()
2024-06-27 18:10:28,484 INFO metabase.core :: Metabase Shutdown COMPLETE
```


### Information about your Metabase installation

```JSON
I can't get this information, because the metabase is not available
```


### Severity

Critical

### Additional context

_No response_",alexsanderp,2024-06-27 19:48:17+00:00,[],2024-07-04 11:45:08+00:00,2024-07-03 16:35:57+00:00,https://github.com/metabase/metabase/issues/44848,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Cache', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2195597713, 'issue_id': 2378973888, 'author': 'piranha', 'body': ""@alexsanderp can you please share results of `select key, value from setting where key in ('query-caching-ttl-ratio', 'query-caching-min-ttl');`?"", 'created_at': datetime.datetime(2024, 6, 27, 20, 15, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195677500, 'issue_id': 2378973888, 'author': 'alexsanderp', 'body': '![image](https://github.com/metabase/metabase/assets/30603084/26bfdbba-47ba-4d24-a1b3-3e173f130a5f)\r\n\r\n@piranha', 'created_at': datetime.datetime(2024, 6, 27, 21, 15, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196179917, 'issue_id': 2378973888, 'author': 'piranha', 'body': ""I wonder what's your Postgres version? Some googling indicates that this could be a problem with version 10 and earlier; I can fix the migration (I think I can ðŸ˜), but it still would make sense for you to upgrade.\r\n\r\nIf this is not the case... Maybe you can experiment with the query to understand what's tripping it?"", 'created_at': datetime.datetime(2024, 6, 28, 5, 40, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197406802, 'issue_id': 2378973888, 'author': 'alexsanderp', 'body': '@piranha Which version of postgres do you recommend?', 'created_at': datetime.datetime(2024, 6, 28, 18, 1, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197463867, 'issue_id': 2378973888, 'author': 'piranha', 'body': 'The newer the better in that case, IMO, so 16.3 :) But Metabase supports all versions up from 11.', 'created_at': datetime.datetime(2024, 6, 28, 18, 54, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199734475, 'issue_id': 2378973888, 'author': 'piranha', 'body': '@alexsanderp did it help?', 'created_at': datetime.datetime(2024, 7, 1, 10, 1, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2203952488, 'issue_id': 2378973888, 'author': 'alexsanderp', 'body': ""@piranha I'll test it today!"", 'created_at': datetime.datetime(2024, 7, 2, 17, 48, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206764268, 'issue_id': 2378973888, 'author': 'alexsanderp', 'body': '@piranha After updating Postgres to version 16 it worked!', 'created_at': datetime.datetime(2024, 7, 3, 16, 35, 57, tzinfo=datetime.timezone.utc)}]","piranha on (2024-06-27 20:15:56 UTC): @alexsanderp can you please share results of `select key, value from setting where key in ('query-caching-ttl-ratio', 'query-caching-min-ttl');`?

alexsanderp (Issue Creator) on (2024-06-27 21:15:36 UTC): ![image](https://github.com/metabase/metabase/assets/30603084/26bfdbba-47ba-4d24-a1b3-3e173f130a5f)

@piranha

piranha on (2024-06-28 05:40:17 UTC): I wonder what's your Postgres version? Some googling indicates that this could be a problem with version 10 and earlier; I can fix the migration (I think I can ðŸ˜), but it still would make sense for you to upgrade.

If this is not the case... Maybe you can experiment with the query to understand what's tripping it?

alexsanderp (Issue Creator) on (2024-06-28 18:01:35 UTC): @piranha Which version of postgres do you recommend?

piranha on (2024-06-28 18:54:28 UTC): The newer the better in that case, IMO, so 16.3 :) But Metabase supports all versions up from 11.

piranha on (2024-07-01 10:01:19 UTC): @alexsanderp did it help?

alexsanderp (Issue Creator) on (2024-07-02 17:48:14 UTC): @piranha I'll test it today!

alexsanderp (Issue Creator) on (2024-07-03 16:35:57 UTC): @piranha After updating Postgres to version 16 it worked!

"
2378938305,issue,closed,completed,handle all zero metric values,"This code from the old pie chart needs to be re-added

```javascript
    // no non-zero slices
    if (slices.length === 0) {
      otherSlice = {
        value: 1,
        color: color(""text-light""),
        noHover: true,
      };
      slices.push(otherSlice);
    }
```

Originally from https://github.com/metabase/metabase/commit/b182abe60542c008decc6871a37ab12953e42d9c    ",EmmadUsmani,2024-06-27 19:26:09+00:00,['EmmadUsmani'],2024-07-01 18:28:26+00:00,2024-07-01 18:28:25+00:00,https://github.com/metabase/metabase/issues/44847,[],"[{'comment_id': 2200768567, 'issue_id': 2378938305, 'author': 'EmmadUsmani', 'body': 'Fixed by https://github.com/metabase/metabase/pull/43555/commits/21f22c391e66d2e83f9c888352f26588c7965223#diff-4f9f0c926fa0149c416510a4f291787c40ff754aafa32fac8df00a463bab6f2c', 'created_at': datetime.datetime(2024, 7, 1, 18, 28, 25, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-07-01 18:28:25 UTC): Fixed by https://github.com/metabase/metabase/pull/43555/commits/21f22c391e66d2e83f9c888352f26588c7965223#diff-4f9f0c926fa0149c416510a4f291787c40ff754aafa32fac8df00a463bab6f2c

"
2378900417,issue,open,,Connecting to Atlas via an SSH tunnel yields a null pointer exception,"### Describe the bug

This might be a dns problem but you can't connect to mongo atlas via a local ssh server

### To Reproduce

1) use mongo atlas
2) set up an ssh server
3) try to connect to mongo atlas via the ssh server

### Expected behavior

It should connect

### Logs

```
2024-06-27 18:56:11,917 WARN forward.DefaultForwarder :: exceptionCaught(Nio2Session[local=/127.0.0.1:43989, remote=/127.0.0.1:34900]) NullPointerException: null
java.lang.NullPointerException
	at org.apache.sshd.common.forward.DefaultForwarder$StaticIoHandler.lambda$messageReceived$2(DefaultForwarder.java:1063)
	at org.apache.sshd.common.util.threads.ThreadUtils.runAsInternal(ThreadUtils.java:68)
	at org.apache.sshd.common.forward.DefaultForwarder$StaticIoHandler.messageReceived(DefaultForwarder.java:1063)
	at org.apache.sshd.common.io.nio2.Nio2Session.handleReadCycleCompletion(Nio2Session.java:409)
	at org.apache.sshd.common.io.nio2.Nio2Session$1.onCompleted(Nio2Session.java:382)
	at org.apache.sshd.common.io.nio2.Nio2Session$1.onCompleted(Nio2Session.java:377)
	at org.apache.sshd.common.io.nio2.Nio2CompletionHandler.lambda$completed$0(Nio2CompletionHandler.java:38)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at org.apache.sshd.common.io.nio2.Nio2CompletionHandler.completed(Nio2CompletionHandler.java:37)
	at java.base/sun.nio.ch.Invoker.invokeUnchecked(Invoker.java:127)
	at java.base/sun.nio.ch.Invoker$2.run(Invoker.java:219)
	at java.base/sun.nio.ch.AsynchronousChannelGroupImpl$1.run(AsynchronousChannelGroupImpl.java:112)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-06-27 18:56:11,989 ERROR driver.util :: Failed to connect to Database
java.util.concurrent.TimeoutException: Timed out after 10.0 s
	at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287)
	at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279)
	at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294)
	at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290)
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:148)
	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:137)
	at clojure.lang.RestFn.invoke(RestFn.java:442)
	at metabase.api.database$test_database_connection.invokeStatic(database.clj:728)
	at metabase.api.database$test_database_connection.doInvoke(database.clj:718)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.api.database$test_connection_details.invokeStatic(database.clj:782)
	at metabase.api.database$test_connection_details.invoke(database.clj:762)
	at metabase.api.database$fn__94894.invokeStatic(database.clj:803)
	at metabase.api.database$fn__94894.invoke(database.clj:786)
	at compojure.core$wrap_response$fn__52907.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__52891.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__52896.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.server.middleware.auth$enforce_authentication$fn__97991.invoke(auth.clj:18)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at metabase.api.routes$fn__104438$fn__104439.invoke(routes.clj:70)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__104718$fn__104719.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100863.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__100860.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__107047$fn__107048$fn__107049.invoke(log.clj:236)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__107047$fn__107048.invoke(log.clj:227)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__107047.invoke(log.clj:226)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__113166.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__100819.invoke(security.clj:238)
	at ring.middleware.json$wrap_json_body$fn__113425.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__87300.invoke(offset_paging.clj:43)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__54362.invoke(json.clj:83)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__113514.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__113533.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__69875.invoke(misc.clj:60)
	at metabase.server.middleware.session$reset_session_timeout$fn__77029.invoke(session.clj:552)
	at metabase.server.middleware.session$bind_current_user$fn__76995$fn__76996.invoke(session.clj:446)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:408)
	at metabase.server.middleware.session$bind_current_user$fn__76995.invoke(session.clj:445)
	at metabase.server.middleware.session$wrap_current_user_info$fn__76976.invoke(session.clj:383)
	at metabase.server.middleware.session$wrap_session_id$fn__76948.invoke(session.clj:259)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__97999.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__113353.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__69857.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__69883.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__113395.invoke(gzip.clj:86)
	at metabase.server.middleware.misc$bind_request$fn__69886.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__113182.invoke(ssl.clj:51)
	at metabase.server$async_proxy_handler$fn__70221.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-06-27 18:56:12,214 ERROR api.database :: Cannot connect to Database
clojure.lang.ExceptionInfo: Timed out after 10.0 s {:message ""Timed out after 10.0 s""}
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:166)
	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:137)
	at clojure.lang.RestFn.invoke(RestFn.java:442)
	at metabase.api.database$test_database_connection.invokeStatic(database.clj:728)
	at metabase.api.database$test_database_connection.doInvoke(database.clj:718)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.api.database$test_connection_details.invokeStatic(database.clj:782)
	at metabase.api.database$test_connection_details.invoke(database.clj:762)
	at metabase.api.database$fn__94894.invokeStatic(database.clj:803)
	at metabase.api.database$fn__94894.invoke(database.clj:786)
	at compojure.core$wrap_response$fn__52907.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__52891.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__52896.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.server.middleware.auth$enforce_authentication$fn__97991.invoke(auth.clj:18)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at metabase.api.routes$fn__104438$fn__104439.invoke(routes.clj:70)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__104718$fn__104719.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__52900.invoke(core.clj:153)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:199)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$make_context$handler__52947.invoke(core.clj:290)
	at compojure.core$make_context$fn__52951.invoke(core.clj:300)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919$f__52920$respond_SINGLEQUOTE___52921.invoke(core.clj:197)
	at compojure.core$make_context$fn__52951.invoke(core.clj:301)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at compojure.core$routes$fn__52919$f__52920.invoke(core.clj:198)
	at compojure.core$routes$fn__52919.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100863.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__100860.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__107047$fn__107048$fn__107049.invoke(log.clj:236)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__107047$fn__107048.invoke(log.clj:227)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__107047.invoke(log.clj:226)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__113166.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__100819.invoke(security.clj:238)
	at ring.middleware.json$wrap_json_body$fn__113425.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__87300.invoke(offset_paging.clj:43)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__54362.invoke(json.clj:83)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__113514.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__113533.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__69875.invoke(misc.clj:60)
	at metabase.server.middleware.session$reset_session_timeout$fn__77029.invoke(session.clj:552)
	at metabase.server.middleware.session$bind_current_user$fn__76995$fn__76996.invoke(session.clj:446)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:408)
	at metabase.server.middleware.session$bind_current_user$fn__76995.invoke(session.clj:445)
	at metabase.server.middleware.session$wrap_current_user_info$fn__76976.invoke(session.clj:383)
	at metabase.server.middleware.session$wrap_session_id$fn__76948.invoke(session.clj:259)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__97999.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__113353.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__69857.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__69883.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__113395.invoke(gzip.clj:86)
	at metabase.server.middleware.misc$bind_request$fn__69886.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__113182.invoke(ssl.clj:51)
	at metabase.server$async_proxy_handler$fn__70221.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:829)
```

### Information about your Metabase installation

```JSON
v50
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-06-27 19:02:23+00:00,[],2025-02-04 20:25:10+00:00,,https://github.com/metabase/metabase/issues/44846,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Mongo', None), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2307155874, 'issue_id': 2378900417, 'author': 'Gp2mv3', 'body': ""I'm having the same issue. Is there a workaround ?"", 'created_at': datetime.datetime(2024, 8, 23, 13, 57, 37, tzinfo=datetime.timezone.utc)}]","Gp2mv3 on (2024-08-23 13:57:37 UTC): I'm having the same issue. Is there a workaround ?

"
2378737377,issue,closed,completed,Sorting by joined field does not work on Mongo,"Create products joining orders on id in `test-data` and sort by id column from orders. Results are sorted on id column from products. This is prerequisite of https://github.com/metabase/metabase/issues/44511 as problem surfaced enabling implicit joins tests.
",lbrdnk,2024-06-27 17:43:18+00:00,['lbrdnk'],2024-10-08 16:20:18+00:00,2024-07-19 11:55:13+00:00,https://github.com/metabase/metabase/issues/44842,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Querying/MBQL', ''), ('.Team/Querying', '')]",[],
2378690704,issue,closed,not_planned,[Epic] Evolve content verification and deprecation,[Product doc](https://www.notion.so/metabase/Evolve-content-verification-and-deprecation-03e20f5c0cad4323be671423a1b473ce?pvs=4),luizarakaki,2024-06-27 17:17:46+00:00,[],2024-11-05 13:45:14+00:00,2024-11-05 13:45:14+00:00,https://github.com/metabase/metabase/issues/44841,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2457222949, 'issue_id': 2378690704, 'author': 'luizarakaki', 'body': 'closed in favor of https://github.com/metabase/metabase/issues/48911', 'created_at': datetime.datetime(2024, 11, 5, 13, 45, 14, tzinfo=datetime.timezone.utc)}]","luizarakaki (Issue Creator) on (2024-11-05 13:45:14 UTC): closed in favor of https://github.com/metabase/metabase/issues/48911

"
2378353401,issue,closed,completed,[50.x] N+1 queries while loading dashboard `query_metadata`,"### Describe the bug

While debugging slow dashboard loads with @LukeAbell yesterday, we found a case of N+1 queries that applies to all dashboard loads. (We found another, worse one #44786 with sandboxing, but this is separate.)

There are 833 queries like this in the logs while loading a midsize dashboard:

```sql
SELECT
  `field`.`base_type`, `field`.`coercion_strategy`, `field`.`database_type`,
  `field`.`description`, `field`.`display_name`, `field`.`effective_type`, `field`.`fingerprint`,
  `field`.`fk_target_field_id`, `field`.`id`, `field`.`name`, `field`.`nfc_path`,
  `field`.`parent_id`, `field`.`position`, `field`.`semantic_type`, `field`.`settings`,
  `field`.`table_id`, `field`.`visibility_type`,
  `dimension`.`human_readable_field_id`, `dimension`.`id`, `dimension`.`name`, `dimension`.`type`,
  `values`.`human_readable_values`, `values`.`values`
FROM `metabase_field` AS `field`
LEFT JOIN `metabase_table` AS `table` ON `field`.`table_id` = `table`.`id`
LEFT JOIN `dimension` AS `dimension` ON
    (`dimension`.`field_id` = `field`.`id`)
    AND `dimension`.`type` IN ('external', 'internal')
LEFT JOIN `metabase_fieldvalues` AS `values` ON
    (`values`.`field_id` = `field`.`id`)
    AND (`values`.`type` = 'full')
WHERE
  (`table`.`db_id` = 7)
  AND (`field`.`id` IN (15051));
```

which is coming from [`lib.metadata.jvm` selecting the pseudotable `:metadata.column`](https://github.com/metabase/metabase/blob/master/src/metabase/lib/metadata/jvm.clj#L135-L137).

I got so far in debugging this as to see that 99% of the calls are coming through the attached stack.
[stacktrace.log](https://github.com/user-attachments/files/16015684/stacktrace.log)

This is a P1 performance issue and the primary reason why `query_metadata` takes 1s instead of 80ms (without sandboxing), but I have to keep debugging the OOMs.

### To Reproduce

Instrument that Toucan call and load pretty much any dashboard.

### Expected behavior

One such call per table, rather than one per field.

(Currently it's also per-query, but I have separate changes queued up to fix that part. Caching these in the `CachedMetadataProvider` is sufficient I think.)

### Logs

_No response_

### Information about your Metabase installation

```JSON
50.x and master both show this.
```


### Severity

P1 perf regression

### Additional context

_No response_",bshepherdson,2024-06-27 14:38:29+00:00,['lbrdnk'],2024-08-28 02:08:55+00:00,2024-07-08 14:18:27+00:00,https://github.com/metabase/metabase/issues/44830,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Administration/Table Metadata', ''), ('.Team/Querying', '')]",[],
2378022597,issue,closed,completed,Ensure that the Trash collection is completely locked down,"As part of the prereq work for auto-archive, we want to make sure that the Trash collection is ""locked down"". It doesn't actually have any content inside it (things just appear there when archived) so we should ensure:

- you should not be able to create anything inside the Trash collection
- you should not be able to move anything into the Trash collection",johnswanson,2024-06-27 12:27:31+00:00,['johnswanson'],2024-10-08 16:19:39+00:00,2024-07-19 19:58:30+00:00,https://github.com/metabase/metabase/issues/44817,[],[],
2377875021,issue,open,,Field filter's timestamp UTC conversion does not eliminate BigQuery's partitions,"### Describe the bug

Environment: BigQuery table, partitioned on a `created_at` timestamp column, and partition filter is set to be required.

The metabase question has a field filter on the `created_at`. The generated query results in the BigQuery error:
```
Cannot query over table without a filter over column(s) 'created_at' that can be used for partition elimination
```
Looking at the SQL that metabase generates, I see the field filter is applied this way:
```
TIMESTAMP_TRUNC(created_at, minute, 'UTC') BETWEEN ...
```
If I remove the 'UTC' conversion part, the query works:
```
TIMESTAMP_TRUNC(created_at, minute) BETWEEN ...
```
Note that the `created_at` field is already a UTC timestamp. AFAIK timestamps in BigQuery do not store the time zone information. So there is no need to apply a UTC conversion.
I think it would make sense to drop that 'UTC' conversion when the field filter is on a BigQuery timestamp?

Also, here the problem is directly visible because the partition filter is set to be required, so we get an error. If it were not required, the query would work, but I'm guessing there would be no partition pruning, the whole table would be read, which is not good.

### To Reproduce

1. Have a BigQuery table with a partition on a timestamp column. Have the ""partition filter = required"" setting on that table.
2. In metabase, build a query on that table with a field filter on the timestamp column.
3. Apply a filter value and execute the query.
4. You should get the error mentioned: ""Cannot query over table without a filter over column(s) 'xxx' that can be used for partition elimination""


### Expected behavior

I expect no BigQuery error to happen. (partition pruning would work).

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1053-gke"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v0.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",SylvainGravejat,2024-06-27 11:17:41+00:00,[],2025-02-04 20:29:05+00:00,,https://github.com/metabase/metabase/issues/44814,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/BigQuery', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2194427223, 'issue_id': 2377875021, 'author': 'SylvainGravejat', 'body': 'Nevermind, I solved it by changing the ""report timezone"" setting to ""Database Default"".\r\n\r\n![image](https://github.com/metabase/metabase/assets/94012127/a39271e6-2c0f-4f97-af58-66574d33af0b)\r\n\r\n*Possibly* an improvement could be : if that setting is UTC, then still don\'t apply the conversion (for a BigQuery timestamp column at least).', 'created_at': datetime.datetime(2024, 6, 27, 11, 22, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197487985, 'issue_id': 2377875021, 'author': 'calherries', 'body': 'This could very well be QPDâ€™s scope but it looks like an edge case of [Bigquery sync partitioned fields](https://github.com/metabase/metabase/pull/36892#top), so I assigned it to BEC.', 'created_at': datetime.datetime(2024, 6, 28, 19, 14, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200016327, 'issue_id': 2377875021, 'author': 'qnkhuat', 'body': ""@calherries, I don't think it relates to the sync partitioned fields project at all. That projects only add the filter during sync. These filters are not automatically applied for questions, so it's probably a driver bug."", 'created_at': datetime.datetime(2024, 7, 1, 12, 28, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200958659, 'issue_id': 2377875021, 'author': 'calherries', 'body': ""Ah okay, I didn't realise that was out of the project's scope. Then this is related to https://github.com/metabase/metabase/issues/37185"", 'created_at': datetime.datetime(2024, 7, 1, 20, 23, 39, tzinfo=datetime.timezone.utc)}]","SylvainGravejat (Issue Creator) on (2024-06-27 11:22:52 UTC): Nevermind, I solved it by changing the ""report timezone"" setting to ""Database Default"".

![image](https://github.com/metabase/metabase/assets/94012127/a39271e6-2c0f-4f97-af58-66574d33af0b)

*Possibly* an improvement could be : if that setting is UTC, then still don't apply the conversion (for a BigQuery timestamp column at least).

calherries on (2024-06-28 19:14:46 UTC): This could very well be QPDâ€™s scope but it looks like an edge case of [Bigquery sync partitioned fields](https://github.com/metabase/metabase/pull/36892#top), so I assigned it to BEC.

qnkhuat on (2024-07-01 12:28:24 UTC): @calherries, I don't think it relates to the sync partitioned fields project at all. That projects only add the filter during sync. These filters are not automatically applied for questions, so it's probably a driver bug.

calherries on (2024-07-01 20:23:39 UTC): Ah okay, I didn't realise that was out of the project's scope. Then this is related to https://github.com/metabase/metabase/issues/37185

"
2377851361,issue,closed,completed,Empty state shown instead of loading state in new model page,"### Describe the bug

The issue is very easy to reproduce in stats instance. Locally it's easier to reproduce with network throttling.

https://github.com/metabase/metabase/assets/6830683/341cde3b-b1c9-4ebe-a844-85760a6bb030




### To Reproduce

1. Go to https://stats.metabase.com/model/new

----

1. Throttle your network 
2. Go to http://localhost:3000/model/new


### Expected behavior

Empty state is not displayed if data is still loading


### Information about your Metabase installation

master, 7091c9eb47


### Severity

P3
",kamilmielnik,2024-06-27 11:05:10+00:00,['nemanjaglumac'],2024-08-14 16:13:50+00:00,2024-08-12 19:39:49+00:00,https://github.com/metabase/metabase/issues/44813,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2250381366, 'issue_id': 2377851361, 'author': 'use-tusk[bot]', 'body': ""I'm working on this issue. Will comment once I have an update. ðŸ¤”\n      \nSee [activity logs](https://usetusk.ai/app/task/07fb1112-5b89-4996-a151-2743eb6a5195?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info."", 'created_at': datetime.datetime(2024, 7, 25, 13, 53, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250456620, 'issue_id': 2377851361, 'author': 'use-tusk[bot]', 'body': 'I created a [pull request](https://github.com/metabase/metabase/pull/46139) for this issue because automated checks failed, but the failure seems unrelated to the task. ðŸ§‘\u200dðŸ’»\n\nPlease approve and merge the PR once you\'ve verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I\'ll address it.', 'created_at': datetime.datetime(2024, 7, 25, 14, 24, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251832955, 'issue_id': 2377851361, 'author': 'use-tusk[bot]', 'body': ""I created a [branch](https://github.com/metabase/metabase/compare/master...tusk-44813-fix-new-model-loading-state-072620240137) with my proposed changes because automated checks failed.\n\nUse this command to checkout the branch locally: `git fetch origin tusk-44813-fix-new-model-loading-state-072620240137 && git checkout tusk-44813-fix-new-model-loading-state-072620240137`\n\nHere's some notes on how I approached this:\n\nMake sure the `NewModelOptions` component properly handles the loading state using the `useListDatabasesQuery` hook. Focus on updating the component to render a loading indicator when the data is loading, and ensure it only shows the empty state if thereâ€™s no data after loading completes.\n\n**Specific Steps:**\n- Update `NewModelOptions` in `frontend/src/metabase/models/containers/NewModelOptions/NewModelOptions.tsx` to utilize `useListDatabasesQuery`. Check the `isLoading` state and conditionally render a loading component.\n- Replace the deprecated `Databases.loadList` HOC and manage data loading state within `NewModelOptions`.\n- Use `LoadingAndErrorWrapper` to show a loading indicator while data is being fetched.\n- Adjust existing tests in `frontend/src/metabase/models/containers/NewModelOptions/tests/common.unit.spec.tsx` to account for the new loading state. Ensure tests mock API requests correctly and utilize `waitForLoaderToBeRemoved` to manage asynchronous behavior.\n- Verify UI behavior with both fast and throttled network conditions to ensure the loading state transitions as expected.\n\nWatch out for race conditions where the loading state could inadvertently display the empty state. Test thoroughly to guarantee a smooth user experience.\n\nSee [activity logs](https://usetusk.ai/app/task/07fb1112-5b89-4996-a151-2743eb6a5195?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info."", 'created_at': datetime.datetime(2024, 7, 26, 2, 9, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2252111364, 'issue_id': 2377851361, 'author': 'use-tusk[bot]', 'body': 'I created a [pull request](https://github.com/metabase/metabase/pull/46174) for this issue. ðŸ§‘\u200dðŸ’»\n\nPlease approve and merge the PR once you\'ve verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I\'ll address it.', 'created_at': datetime.datetime(2024, 7, 26, 7, 6, 40, tzinfo=datetime.timezone.utc)}]","use-tusk[bot] on (2024-07-25 13:53:14 UTC): I'm working on this issue. Will comment once I have an update. ðŸ¤”
      
See [activity logs](https://usetusk.ai/app/task/07fb1112-5b89-4996-a151-2743eb6a5195?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info.

use-tusk[bot] on (2024-07-25 14:24:41 UTC): I created a [pull request](https://github.com/metabase/metabase/pull/46139) for this issue because automated checks failed, but the failure seems unrelated to the task. ðŸ§‘â€ðŸ’»

Please approve and merge the PR once you've verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I'll address it.

use-tusk[bot] on (2024-07-26 02:09:17 UTC): I created a [branch](https://github.com/metabase/metabase/compare/master...tusk-44813-fix-new-model-loading-state-072620240137) with my proposed changes because automated checks failed.

Use this command to checkout the branch locally: `git fetch origin tusk-44813-fix-new-model-loading-state-072620240137 && git checkout tusk-44813-fix-new-model-loading-state-072620240137`

Here's some notes on how I approached this:

Make sure the `NewModelOptions` component properly handles the loading state using the `useListDatabasesQuery` hook. Focus on updating the component to render a loading indicator when the data is loading, and ensure it only shows the empty state if thereâ€™s no data after loading completes.

**Specific Steps:**
- Update `NewModelOptions` in `frontend/src/metabase/models/containers/NewModelOptions/NewModelOptions.tsx` to utilize `useListDatabasesQuery`. Check the `isLoading` state and conditionally render a loading component.
- Replace the deprecated `Databases.loadList` HOC and manage data loading state within `NewModelOptions`.
- Use `LoadingAndErrorWrapper` to show a loading indicator while data is being fetched.
- Adjust existing tests in `frontend/src/metabase/models/containers/NewModelOptions/tests/common.unit.spec.tsx` to account for the new loading state. Ensure tests mock API requests correctly and utilize `waitForLoaderToBeRemoved` to manage asynchronous behavior.
- Verify UI behavior with both fast and throttled network conditions to ensure the loading state transitions as expected.

Watch out for race conditions where the loading state could inadvertently display the empty state. Test thoroughly to guarantee a smooth user experience.

See [activity logs](https://usetusk.ai/app/task/07fb1112-5b89-4996-a151-2743eb6a5195?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info.

use-tusk[bot] on (2024-07-26 07:06:40 UTC): I created a [pull request](https://github.com/metabase/metabase/pull/46174) for this issue. ðŸ§‘â€ðŸ’»

Please approve and merge the PR once you've verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I'll address it.

"
2377628363,issue,closed,completed,Error replace function in editor,"### Describe the bug

The replace function works in SQL language, but does not work in the matabase editor

### To Reproduce


<img width=""639"" alt=""Capture2_metabase"" src=""https://github.com/metabase/metabase/assets/60504041/22634e48-6f64-4292-a984-3e6af44eb7fd"">

<img width=""451"" alt=""Capture1_metabase"" src=""https://github.com/metabase/metabase/assets/60504041/a469f2cb-7a59-47b7-9c58-9b20c785c65c"">


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-15-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""oracle"",
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v0.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

blocking usage

### Additional context

_No response_",TOH2F,2024-06-27 09:23:01+00:00,['metamben'],2024-08-28 02:08:54+00:00,2024-07-18 22:13:54+00:00,https://github.com/metabase/metabase/issues/44807,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2197500431, 'issue_id': 2377628363, 'author': 'calherries', 'body': 'Looks related to https://github.com/metabase/metabase/issues/44584 and https://github.com/metabase/metabase/issues/44767', 'created_at': datetime.datetime(2024, 6, 28, 19, 24, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197511524, 'issue_id': 2377628363, 'author': 'perivamsi', 'body': '@TOH2F what is the type of the `Status` column in your database in the `glpi_tickets` table?', 'created_at': datetime.datetime(2024, 6, 28, 19, 32, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227431670, 'issue_id': 2377628363, 'author': 'ranquild', 'body': '^ Likely MySQL enum.', 'created_at': datetime.datetime(2024, 7, 14, 18, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227580620, 'issue_id': 2377628363, 'author': 'ranquild', 'body': 'The problem is that the FE checks for `string`, e.g. `type/Text` in the expression parser config https://github.com/metabase/metabase/blob/3b3dcd8647ef7afa8723323297ab5c825e6aedd8/frontend/src/metabase-lib/v1/expressions/config.ts#L127. Each `string` should be changed to `expression` to avoid FE typechecking. And `Lib.diagnoseExpression` should check for correct types instead. For each string-based expression we need to clarify which work with `type/Text` only and which can work with both `type/Text` and `type/TextLike`, like the MySQL enum above.\n\nMBQL lib expression schemas are defined here https://github.com/metabase/metabase/blob/a24abaeae1a4eacf331528355268ab21779edca6/src/metabase/lib/schema/expression/string.cljc#L28.\n\nRemoving QC since the FE change is trivial and the fix is in MBQL lib.', 'created_at': datetime.datetime(2024, 7, 15, 1, 44, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233550208, 'issue_id': 2377628363, 'author': 'metamben', 'body': ""@TOH2F what is the type of the Status column in your database in the glpi_tickets table? Can you confirm it's an enum?"", 'created_at': datetime.datetime(2024, 7, 17, 15, 5, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236774792, 'issue_id': 2377628363, 'author': 'metamben', 'body': ""@luizarakaki, do we want to enable string operations on enums? I've enabled that in #45752, but @bshepherdson [seems to remember](https://github.com/metabase/metabase/pull/45752#issuecomment-2235129126) that we specifically don't want this."", 'created_at': datetime.datetime(2024, 7, 18, 14, 49, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259553085, 'issue_id': 2377628363, 'author': 'SeshTiliRest', 'body': 'Yo! I have a similar problem with my multiple replacement after updating from v0.49.14 to v0.50.18.\r\nMS SQL with TINYINT datatype.\r\n\r\n![invalid](https://github.com/user-attachments/assets/5b6af0b7-36b2-4c98-891b-2bb272baa9d5)\r\n`replace(replace(replace([Accept], ""1"", ""Ð""), ""0"", ""Ð’""), ""2"", ""Ðš"")`\r\n\r\n![problem](https://github.com/user-attachments/assets/38037bc2-1aec-47fb-a66f-9795a9066855)\r\n`Invalid query: {:stages [{:expressions [[nil nil [nil nil [nil nil [""expression returning a string""]]]]]}]}`\r\n\r\nAfter deleting custom column with dat replace function - error is gone.', 'created_at': datetime.datetime(2024, 7, 31, 3, 9, 25, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-28 19:24:07 UTC): Looks related to https://github.com/metabase/metabase/issues/44584 and https://github.com/metabase/metabase/issues/44767

perivamsi on (2024-06-28 19:32:48 UTC): @TOH2F what is the type of the `Status` column in your database in the `glpi_tickets` table?

ranquild on (2024-07-14 18:08:00 UTC): ^ Likely MySQL enum.

ranquild on (2024-07-15 01:44:39 UTC): The problem is that the FE checks for `string`, e.g. `type/Text` in the expression parser config https://github.com/metabase/metabase/blob/3b3dcd8647ef7afa8723323297ab5c825e6aedd8/frontend/src/metabase-lib/v1/expressions/config.ts#L127. Each `string` should be changed to `expression` to avoid FE typechecking. And `Lib.diagnoseExpression` should check for correct types instead. For each string-based expression we need to clarify which work with `type/Text` only and which can work with both `type/Text` and `type/TextLike`, like the MySQL enum above.

MBQL lib expression schemas are defined here https://github.com/metabase/metabase/blob/a24abaeae1a4eacf331528355268ab21779edca6/src/metabase/lib/schema/expression/string.cljc#L28.

Removing QC since the FE change is trivial and the fix is in MBQL lib.

metamben (Assginee) on (2024-07-17 15:05:46 UTC): @TOH2F what is the type of the Status column in your database in the glpi_tickets table? Can you confirm it's an enum?

metamben (Assginee) on (2024-07-18 14:49:36 UTC): @luizarakaki, do we want to enable string operations on enums? I've enabled that in #45752, but @bshepherdson [seems to remember](https://github.com/metabase/metabase/pull/45752#issuecomment-2235129126) that we specifically don't want this.

SeshTiliRest on (2024-07-31 03:09:25 UTC): Yo! I have a similar problem with my multiple replacement after updating from v0.49.14 to v0.50.18.
MS SQL with TINYINT datatype.

![invalid](https://github.com/user-attachments/assets/5b6af0b7-36b2-4c98-891b-2bb272baa9d5)
`replace(replace(replace([Accept], ""1"", ""Ð""), ""0"", ""Ð’""), ""2"", ""Ðš"")`

![problem](https://github.com/user-attachments/assets/38037bc2-1aec-47fb-a66f-9795a9066855)
`Invalid query: {:stages [{:expressions [[nil nil [nil nil [nil nil [""expression returning a string""]]]]]}]}`

After deleting custom column with dat replace function - error is gone.

"
2377562529,issue,closed,completed,Trash is not highlighted in the sidebar when opened,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/80865259-92c6-40b2-b639-5a6efa37c803)


### To Reproduce

1. Open Trash
2. Open sidebar

Trash is not highlighted as selected

### Expected behavior

Trash should be highlighted as selected when open ([like this](https://github.com/metabase/metabase/assets/6830683/7a839b2a-dfb9-45c0-b9de-fb0c603d8c97)).



### Information about your Metabase installation

master, 5260e2a



### Severity

P3

",kamilmielnik,2024-06-27 08:53:41+00:00,['sloansparger'],2024-07-02 11:22:20+00:00,2024-06-27 18:41:41+00:00,https://github.com/metabase/metabase/issues/44805,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2377440274,issue,closed,completed,Styles from EmbedFrame are leaking into the global scope in embedding sdk,"CSS styles from the EmbedFrame class is leaking into the global `<body>` scope of the user's page, under the React Embedding SDK. This overwrites any background-color the user has set on their body.

See `EmbedFrame.module.css`, first line:

```css
body {
  background-color: transparent;
}
```",heypoom,2024-06-27 07:58:06+00:00,[],2024-09-13 19:14:28+00:00,2024-09-13 19:14:28+00:00,https://github.com/metabase/metabase/issues/44802,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2349987912, 'issue_id': 2377440274, 'author': 'heypoom', 'body': 'Fixed by https://github.com/metabase/metabase/pull/47764, tested with the CLI runs.', 'created_at': datetime.datetime(2024, 9, 13, 19, 14, 28, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-09-13 19:14:28 UTC): Fixed by https://github.com/metabase/metabase/pull/47764, tested with the CLI runs.

"
2377011825,issue,closed,completed,Slack integration should list private channels,"You can make metabase send to private channels if the bot is invited to.

But the Slack channel dropdown when setting up an alert/dashboard subscription does not list these private channels.

We need to:
- add `private_channel` to the conversation.list API [here](https://github.com/metabase/metabase/blob/fe1f5950fb0ac03560b720b8cebeaf68b39a3eab/src/metabase/integrations/slack.clj#L203)
- the bot needs to have a new scope : [groups:read](https://api.slack.com/scopes/groups:read)
	- note: changing the scope require reinstalling the bot in the workspace",qnkhuat,2024-06-27 04:02:49+00:00,['wotbrew'],2025-02-06 16:38:37+00:00,2025-02-06 16:38:37+00:00,https://github.com/metabase/metabase/issues/44798,"[('Type:New Feature', ''), ('Reporting/', ''), ('Notifications/Slack', '')]","[{'comment_id': 2193661433, 'issue_id': 2377011825, 'author': 'qnkhuat', 'body': 'Doing this will also let users upload images to private channels', 'created_at': datetime.datetime(2024, 6, 27, 4, 24, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401923428, 'issue_id': 2377011825, 'author': 'jshum', 'body': 'ðŸ‘ \n\nCurrently, the behavior now is kind of strange. You need to choose a `channel 1` which is where the images are uploaded and a `channel 2` to send the notification to.\n\nIf you turn `channel 1` into a private channel afterwards, the images will actually still be correctly uploaded into `channel 1` but you will no longer be able to view the images in `channel 2`.', 'created_at': datetime.datetime(2024, 10, 9, 10, 21, 47, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-06-27 04:24:22 UTC): Doing this will also let users upload images to private channels

jshum on (2024-10-09 10:21:47 UTC): ðŸ‘ 

Currently, the behavior now is kind of strange. You need to choose a `channel 1` which is where the images are uploaded and a `channel 2` to send the notification to.

If you turn `channel 1` into a private channel afterwards, the images will actually still be correctly uploaded into `channel 1` but you will no longer be able to view the images in `channel 2`.

"
2376269763,issue,closed,completed,Page hangs when one of parameters contains `{{x}}` value,"### Describe the bug

[context](https://metaboat.slack.com/archives/C010L1Z4F9S/p1719422370411869)

### To Reproduce

open https://stats.metabase.com/dashboard/2183-customer-360-zendesk-version - value of one filters will be `{{something}}`, which causes passing `NaN` to `ML.query`

![image](https://github.com/metabase/metabase/assets/125459446/9eab786e-4178-4618-9440-43e7d57aa211)


### Expected behavior

page doesn't hang

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.7+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.7"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.7+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Minsk""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-06-26"",
      ""src_hash"": ""6b7207f672d178f236092abfeaf83d48dfb5ea31"",
      ""tag"": ""v0.1.15-SNAPSHOT"",
      ""hash"": ""03ca0ec""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

p1

### Additional context

_No response_",uladzimirdev,2024-06-26 20:57:24+00:00,['ranquild'],2024-06-27 15:20:31+00:00,2024-06-27 15:20:30+00:00,https://github.com/metabase/metabase/issues/44790,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2376209078,issue,open,,Give more context around Users in Metabase Analytics tables,"**Is your feature request related to a problem? Please describe.**
If you are looking quickly into Metabase Analytics, or you are not a technical user that knows about joins and such, and if you look at the Activity Log Table or any other that is not the People table in Metabase Analytics, you'd need to join it with the People table to get context around which user is which record, and that can take time (time to realize you can do the join, actually find the table, and save it in a place you might forget in the future)

**Describe the solution you'd like**
More user context in tables that are not People table in Metabase Analytics for faster analysis. 

**Describe alternatives you've considered**
Joining with People table

**How important is this feature to you?**
Requested by a customer, internal ticket: [28383](https://metabase.zendesk.com/agent/tickets/28383)

**Additional context**
N/A
",ignacio-mb,2024-06-26 20:26:05+00:00,[],2024-07-01 15:33:51+00:00,,https://github.com/metabase/metabase/issues/44789,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]","[{'comment_id': 2200463566, 'issue_id': 2376209078, 'author': 'brunobergher', 'body': 'We should enrich the People model which we use for this with a few bits of info.', 'created_at': datetime.datetime(2024, 7, 1, 15, 29, tzinfo=datetime.timezone.utc)}]","brunobergher on (2024-07-01 15:29:00 UTC): We should enrich the People model which we use for this with a few bits of info.

"
2376197313,issue,open,,Add PDF export functionality to Metabase Analytics,"**Is your feature request related to a problem? Please describe.**
I (and customers) get sad that I can't export a Metabase Analytics dashboard. Why would I, if I can export any other dashbaord?

**Describe the solution you'd like**
Add PDF export functionality to Metabase Analytics

**Describe alternatives you've considered**
Making a copy of the dashboard and exporting that.

**How important is this feature to you?**
Requested by a customer, internal ticket: [28383](https://metabase.zendesk.com/agent/tickets/28383)

**Additional context**
N/A
",ignacio-mb,2024-06-26 20:20:07+00:00,[],2024-06-27 00:20:21+00:00,,https://github.com/metabase/metabase/issues/44788,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Reporting/Export', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2376168063,issue,closed,completed,"[50.x] For a sandboxed user, thousands of appdb queries are sent during a dashboard read","### Describe the bug

This is part of the performance regressions reported by @LukeAbell in #44359.

Loading one midsize dashboard, the `query_metadata` request takes 1.2 or 1.5 seconds without sandboxing enabled. Loading it as a sandboxed user, the same request takes 8 seconds.

Logging all the appdb SQL queries shows 8956 queries like this issued for that dashboard load:

```sql
# Query_time: 0.000097  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 205
SELECT `p`.`perm_value` AS `value` FROM `data_permissions` AS `p`
WHERE (`p`.`group_id` = 1)
  AND (`p`.`perm_type` = 'perms/view-data')
  AND (`p`.`db_id` = 7) AND ((`table_id` = 1067) OR (`table_id` IS NULL));
```

The parameters vary slightly; there are 74 unique ones in the logs, for different `group_id` and `table_id` values.

That's a lot of duplicate requests - over 100x each on average. That has to stop, probably by remembering the result during execution of one API request, or some other memoization scheme.

As a lower priority follow-up, there's probably some N+1 queries to be squeezed out here. I'm not sure whether it's easier to group on tables or groups, but we should be able to eg. check all the user's groups wrt a single table in one query.

### To Reproduce

1. Be a sandboxed user.
2. Load a dashboard.
3. Observe appdb traffic somewhere. 

### Expected behavior

A halfway-reasonable number of database requests should be issued.

### Logs

_No response_

### Information about your Metabase installation

```JSON
50.7, MySQL DW and appdb, enterprise user with sandboxing enabled.
```


### Severity

P1

### Additional context

_No response_",bshepherdson,2024-06-26 20:03:33+00:00,['noahmoss'],2024-06-27 14:20:53+00:00,2024-06-27 14:20:53+00:00,https://github.com/metabase/metabase/issues/44786,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2376125626,issue,closed,completed,Metabase downgrade issue - v0.50.7 to v0.49.x,"### Describe the bug

Not able to downgrade metabase from v0.50.7 to v0.49.x

**Cluster configuration:**

ECS cluster with 2 tasks.
Task CPU: 3800 units (3.711 vCPU)
Task memory: 3700 MiB (3.613 GB)

**Steps that I followed for downgrading** (followed instructions from [here](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade)):

- Stopped the container running v0.50.7 metabase instance

- Ran the following on the EC2 instance directly:
```
# docker run --rm metabase/metabase:v0.50.7 ""migrate down""
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-26 18:59:08,086 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB2024-06-26 18:59:10,579 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html2024-06-26 18:59:11,325 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For productiondeployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database fileregularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html
2024-06-26 18:59:15,823 INFO driver.impl :: Registered abstract driver :sql  ðŸšš2024-06-26 18:59:15,829 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-06-26 18:59:15,835 INFO metabase.util :: Load driver :sql-jdbc took 33.1 ms
2024-06-26 18:59:15,836 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-06-26 18:59:15,977 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
2024-06-26 18:59:16,017 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-06-26 18:59:17,665 INFO metabase.core ::
Metabase v0.50.7 (431cd8f)

Copyright Â© 2024 Metabase, Inc.
Metabase Enterprise Edition extensions are NOT PRESENT.2024-06-26 18:59:17,956 INFO db.setup :: Setting up Liquibase...
2024-06-26 18:59:18,695 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-06-26 18:59:18,707 INFO db.liquibase :: No migration lock found.
2024-06-26 18:59:18,707 INFO db.liquibase :: Migration lock acquired.
2024-06-26 18:59:18,713 INFO db.setup :: Liquibase is ready.2024-06-26 18:59:18,717 INFO db.liquibase :: No migration lock found.
2024-06-26 18:59:18,718 INFO db.liquibase :: Migration lock acquired.2024-06-26 18:59:18,719 INFO db.liquibase :: Rolling back app database schema to version 49
#
```

- Tried spinning up a container using v0.49.12, logs attached
[Downgrade_logs.csv](https://github.com/user-attachments/files/15994385/Downgrade_logs.csv)



### To Reproduce

Check Describe the bug section

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Diagnostic info:

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.91-99.172.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v0.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Urgent. A lot of our clients are getting affected due to frequent timeouts in v0.50.1, and it's becoming a real problem for them.

### Additional context

_No response_",psneha716,2024-06-26 19:35:56+00:00,['piranha'],2024-07-01 08:18:11+00:00,2024-07-01 06:48:00+00:00,https://github.com/metabase/metabase/issues/44784,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2192512629, 'issue_id': 2376125626, 'author': 'noahmoss', 'body': ""@psneha716 Is that the entire contents of the logs when you ran `migrate down`? No errors were reported?\r\n\r\nIf you're able, could you copy the contents of the `databasechangelog` table in your app DB and attach it?"", 'created_at': datetime.datetime(2024, 6, 26, 19, 51, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194383479, 'issue_id': 2376125626, 'author': 'psneha716', 'body': ""@noahmoss, yes that's the entire contents of the logs, no errors. PFA the databasechangelog.\r\n[databasechangelog_dump.csv](https://github.com/user-attachments/files/16012373/databasechangelog_dump.csv)"", 'created_at': datetime.datetime(2024, 6, 27, 10, 57, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194599479, 'issue_id': 2376125626, 'author': 'piranha', 'body': ""@psneha716 I'm reading the logs and `ERROR: Downgrade detected` means the following: you have migrations applied to your database which are not present in the metabase version you're using to downgrade.\r\n\r\nYour logs (in the first message) indicate that it's executed with Metabase 0.49.12, so maybe something is happening here? Could you try again using 0.50.7 and look what's going on? Or do you mean that when running 0.50.7 it just hangs?"", 'created_at': datetime.datetime(2024, 6, 27, 12, 52, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194807620, 'issue_id': 2376125626, 'author': 'psneha716', 'body': '@piranha, the full error log says:\r\n\r\n```\r\nclojure.lang.ExceptionInfo: \x1b[31mERROR: Downgrade detected.\x1b[0m\r\nYour metabase instance appears to have been downgraded without a corresponding database downgrade.\r\nYou must run `java -jar metabase.jar migrate down` from version 50.\r\nOnce your database has been downgraded, try running the application again.\r\n```\r\nThe error log says instance has been downgraded (i.e instance version and not metabase db).', 'created_at': datetime.datetime(2024, 6, 27, 14, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194818632, 'issue_id': 2376125626, 'author': 'piranha', 'body': ""@psneha716 that's error log from 0.49.12, the one you've attached as a file. 0.49 cannot do a downgrade from 0.50. I think the message is a bit misleading and we need to revise it, but what it checks is `latest-available < latest-applied`, essentially that you have applied more migrations than there are available in a given Metabase jar.\r\n\r\nAlso your `databasechangelog` table indicates that you have applied all migrations up to 0.50.7, so that's the only version which can properly do a downgrade. Can you try using it again and if it's not successful - paste a full log of that execution?"", 'created_at': datetime.datetime(2024, 6, 27, 14, 14, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194835627, 'issue_id': 2376125626, 'author': 'cheyuriy', 'body': 'Tried to downgrade it too, but receive an error:\r\n```\r\nMetabase v0.50.7 (431cd8f)\r\n\r\nCopyright Â© 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-06-27 14:12:54,588 INFO db.setup :: Setting up Liquibase...\r\n2024-06-27 14:12:55,485 INFO db.setup :: Liquibase is ready.\r\n2024-06-27 14:12:55,529 INFO db.liquibase :: No migration lock found.\r\n2024-06-27 14:12:55,529 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-27 14:12:55,536 INFO db.liquibase :: Rolling back app database schema to version 49\r\n2024-06-27 14:12:56,031 INFO db.custom-migrations :: No rollback for:  CreateSampleContent\r\n2024-06-27 14:12:56,120 INFO db.custom-migrations :: No rollback for:  MigrateStackedAreaBarComboDisplaySettings\r\nliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:253)\r\n\tat liquibase.Liquibase.lambda$rollback$7(Liquibase.java:579)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.Liquibase.runInScope(Liquibase.java:1419)\r\n\tat liquibase.Liquibase.rollback(Liquibase.java:568)\r\n\tat liquibase.Liquibase.rollback(Liquibase.java:551)\r\n\tat liquibase.Liquibase.rollback(Liquibase.java:542)\r\n\tat metabase.db.liquibase$rollback_major_version$fn__44519.invoke(liquibase.clj:485)\r\n\tat metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:324)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)\r\n\tat metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)\r\n\tat metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:478)\r\n\tat metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)\r\n\tat metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:470)\r\n\tat metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.core$apply.invokeStatic(core.clj:671)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.db.setup$migrate_BANG_$fn__53364.invoke(setup.clj:86)\r\n\tat metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:139)\r\n\tat metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)\r\n\tat metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)\r\n\tat metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)\r\n\tat metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:425)\r\n\tat metabase.cmd.migrate$migrate_BANG_.invokeStatic(migrate.clj:8)\r\n\tat metabase.cmd.migrate$migrate_BANG_.invoke(migrate.clj:5)\r\n\tat clojure.lang.Var.invoke(Var.java:384)\r\n\tat metabase.cmd$migrate.invokeStatic(cmd.clj:66)\r\n\tat metabase.cmd$migrate.invoke(cmd.clj:62)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:154)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.core$apply.invokeStatic(core.clj:667)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.cmd$run_cmd$fn__106571.invoke(cmd.clj:301)\r\n\tat metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)\r\n\tat metabase.cmd$run_cmd.invoke(cmd.clj:290)\r\n\tat clojure.lang.Var.invoke(Var.java:388)\r\n\tat metabase.core$run_cmd.invokeStatic(core.clj:192)\r\n\tat metabase.core$run_cmd.invoke(core.clj:190)\r\n\tat metabase.core$entrypoint.invokeStatic(core.clj:214)\r\n\tat metabase.core$entrypoint.doInvoke(core.clj:209)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n\tat clojure.lang.Var.applyTo(Var.java:705)\r\n\tat clojure.core$apply.invokeStatic(core.clj:667)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)\r\n\tat metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n\tat metabase.bootstrap.main(Unknown Source)\r\nCaused by: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)\r\n\tat liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:112)\r\n\tat liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:82)\r\n\tat liquibase.command.core.RollbackCountCommandStep.lambda$run$0(RollbackCountCommandStep.java:48)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.command.core.RollbackCountCommandStep.run(RollbackCountCommandStep.java:48)\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:217)\r\n\t... 57 more\r\nCaused by: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]\r\n\tat liquibase.changelog.ChangeSet.rollback(ChangeSet.java:956)\r\n\tat liquibase.changelog.visitor.RollbackVisitor.visit(RollbackVisitor.java:63)\r\n\tat liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.Scope.child(Scope.java:252)\r\n\tat liquibase.Scope.child(Scope.java:256)\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)\r\n\t... 66 more\r\nCaused by: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]\r\n\tat liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)\r\n\tat liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)\r\n\tat liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)\r\n\tat liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1303)\r\n\tat liquibase.database.AbstractJdbcDatabase.executeRollbackStatements(AbstractJdbcDatabase.java:1327)\r\n\tat liquibase.database.AbstractJdbcDatabase.executeRollbackStatements(AbstractJdbcDatabase.java:1333)\r\n\tat liquibase.changelog.ChangeSet.rollback(ChangeSet.java:934)\r\n\t... 80 more\r\nCaused by: org.postgresql.util.PSQLException: ERROR: column ""duration"" of relation ""task_history"" contains null values\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)\r\n\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)\r\n\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)\r\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)\r\n\tat org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)\r\n\tat org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)\r\n\tat org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)\r\n\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)\r\n\tat com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)\r\n\tat liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)\r\n\t... 86 more\r\nCommand failed with exception: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]\r\n```', 'created_at': datetime.datetime(2024, 6, 27, 14, 20, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194895699, 'issue_id': 2376125626, 'author': 'psneha716', 'body': '@piranha Got it!\r\nI tried downgrading from 0.50.7 to 0.49.12, which did not work. Basically when I try to spin up 0.49.12 after db migration, it exits with that error. Shall I downgrade it to a version lower than 0.49.12?', 'created_at': datetime.datetime(2024, 6, 27, 14, 33, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194903570, 'issue_id': 2376125626, 'author': 'piranha', 'body': ""@cheyuriy Ohhh so we've catched your error, we had `NOT NULL` on `task_history.duration` and on `task_history.ended_at` before, and dropped those constraints in 0.50, and now it cannot rollback as you have entries with empty values in there. If you don't care about those, you can just `delete from task_history where duration is null or ended_at is null` and then rollback (using 0.50.7) again.\r\n\r\nIf you are worried about those entries it needs some more thinking. ðŸ˜"", 'created_at': datetime.datetime(2024, 6, 27, 14, 36, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194978528, 'issue_id': 2376125626, 'author': 'piranha', 'body': '@psneha716 wait, is that the same issue, or is that a separate case from your issue? ðŸ˜', 'created_at': datetime.datetime(2024, 6, 27, 15, 10, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195012630, 'issue_id': 2376125626, 'author': 'noahmoss', 'body': ""@psneha716 I'm pretty puzzled by the fact that it's not erroring at all when downgrading. Could you try running the downgrade from 50.7, and _then_ send the dump of `databasechangelog`? I'd like to see what migrations are still left after the downgrade that are blocking 49 from starting up."", 'created_at': datetime.datetime(2024, 6, 27, 15, 24, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195079616, 'issue_id': 2376125626, 'author': 'cheyuriy', 'body': 'We were able to downgrade from 50.7 to 49.3 after cleaning `task_history` table.', 'created_at': datetime.datetime(2024, 6, 27, 15, 52, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195089512, 'issue_id': 2376125626, 'author': 'psneha716', 'body': ""@piranha, it's a separate issue :p\r\n\r\n@noahmoss The logs and  changelog dump that I've shared are after migration from v0.50.7 to 0.49.12"", 'created_at': datetime.datetime(2024, 6, 27, 15, 57, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195093483, 'issue_id': 2376125626, 'author': 'piranha', 'body': '@psneha716 well that migration did not really happen to you: your `databasechangelog` dump indicates you still got all the migrations from v50. And logs are from executing 0.49.12. What we need is full logs from executing `migrate down` on 0.50.7.', 'created_at': datetime.datetime(2024, 6, 27, 15, 59, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195127876, 'issue_id': 2376125626, 'author': 'psneha716', 'body': '@piranha Okay, just ran the migrations and following are the full logs after executing `migrate down`\r\n\r\n```\r\n[root]# docker run --rm metabase/metabase:v0.50.7 ""migrate down""\r\nWarning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\n2024-06-27 16:10:10,249 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB\r\n2024-06-27 16:10:12,754 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-06-27 16:10:13,510 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For productiondeployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database fileregularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html\r\n2024-06-27 16:10:18,072 INFO driver.impl :: Registered abstract driver :sql  ðŸšš\r\n2024-06-27 16:10:18,078 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš\r\n2024-06-27 16:10:18,084 INFO metabase.util :: Load driver :sql-jdbc took 32.9 ms\r\n2024-06-27 16:10:18,084 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-27 16:10:18,243 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-27 16:10:18,282 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-27 16:10:20,097 INFO metabase.core ::\r\nMetabase v0.50.7 (431cd8f)\r\n\r\nCopyright Â© 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-06-27 16:10:20,401 INFO db.setup :: Setting up Liquibase...\r\n2024-06-27 16:10:21,173 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames\r\n2024-06-27 16:10:21,185 INFO db.liquibase :: No migration lock found.\r\n2024-06-27 16:10:21,185 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-27 16:10:21,191 INFO db.setup :: Liquibase is ready.\r\n2024-06-27 16:10:21,198 INFO db.liquibase :: No migration lock found.\r\n2024-06-27 16:10:21,198 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-27 16:10:21,199 INFO db.liquibase :: Rolling back app database schema to version 49\r\n[root]#\r\n```\r\n\r\n\r\ndatabasechangelogs: \r\n[DBChangelog_2.csv](https://github.com/user-attachments/files/16018033/DBChangelog_2.csv)', 'created_at': datetime.datetime(2024, 6, 27, 16, 15, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195177937, 'issue_id': 2376125626, 'author': 'psneha716', 'body': 'Oh wait, can I only revert back to the version that I was previously running and not any lower version of my choice?\r\n\r\n`But if youâ€™ve made changes to your application database since upgrading that you want to keep, you may be able to use the migrate down command to roll back your Metabase application database to support the previous Metabase version you were running. `', 'created_at': datetime.datetime(2024, 6, 27, 16, 33, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195201596, 'issue_id': 2376125626, 'author': 'noahmoss', 'body': '@psneha716 I think I just realized the issue. When you\'re running `migrate down` you still need to pass the connect details for your DB as environment variables. (i.e. as shown [here](https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-docker#running-docker-in-production)) Otherwise it will fall back to a default H2 app DB. It seems like it\'s ""successfully"" rolling back migrations on the wrong DB, which is why you\'re not seeing the rollback applied when you start Metabase 49 with Postgres.\r\n\r\nThis is definitely an issue with our docs/error messages â€”\xa0will work on getting those clarified. But in the meantime let me know if this works for you.', 'created_at': datetime.datetime(2024, 6, 27, 16, 47, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195282587, 'issue_id': 2376125626, 'author': 'psneha716', 'body': '@noahmoss Tried that. Getting the following error:\r\n\r\n```\r\n[root]# docker run  \\\r\n  -e ""MB_DB_TYPE= postgres"" \\\r\n  -e ""MB_DB_DBNAME= postgres"" \\\r\n  -e ""MB_DB_PORT=5432"" \\\r\n  -e ""MB_DB_USER= postgres"" \\\r\n  -e ""MB_DB_PASS=<pass>â€ \\\r\n  -e ""MB_DB_HOST=<host>â€ \\\r\n   --rm metabase/metabase:v0.50.7 ""migrate down""\r\n\r\nWarning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\n2024-06-27 17:30:01,728 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB\r\n2024-06-27 17:30:04,242 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\nException in thread ""main"" java.lang.ExceptionInInitializerError\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:619)\r\n        at metabase.db.connection$loading__6789__auto____42274.invoke(connection.clj:1)\r\n        at metabase.db.connection__init.load(Unknown Source)\r\n        at metabase.db.connection__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:703)\r\n        at metabase.db$loading__6789__auto____53409.invoke(db.clj:1)\r\n        at metabase.db__init.load(Unknown Source)\r\n        at metabase.db__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:2088)\r\n        at metabase.models.serialization$loading__6789__auto____53610.invoke(serialization.clj:1)\r\n        at metabase.models.serialization__init.load(Unknown Source)\r\n        at metabase.models.serialization__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:3894)\r\n        at metabase.models.setting$loading__6789__auto____54412.invoke(setting.clj:1)\r\n        at metabase.models.setting__init.load(Unknown Source)\r\n        at metabase.models.setting__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:930)\r\n        at metabase.analytics.prometheus$loading__6789__auto____70244.invoke(prometheus.clj:1)\r\n        at metabase.analytics.prometheus__init.load(Unknown Source)\r\n        at metabase.analytics.prometheus__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:3894)\r\n        at metabase.core$loading__6789__auto____107972.invoke(core.clj:1)\r\n        at metabase.core__init.load(Unknown Source)\r\n        at metabase.core__init.<clinit>(Unknown Source)\r\n        at java.base/java.lang.Class.forName0(Native Method)\r\n        at java.base/java.lang.Class.forName(Unknown Source)\r\n        at clojure.lang.RT.classForName(RT.java:2209)\r\n        at clojure.lang.RT.classForName(RT.java:2218)\r\n        at clojure.lang.RT.loadClassForName(RT.java:2237)\r\n        at clojure.lang.RT.load(RT.java:449)\r\n        at clojure.lang.RT.load(RT.java:424)\r\n        at clojure.core$load$fn__6908.invoke(core.clj:6162)\r\n        at clojure.core$load.invokeStatic(core.clj:6161)\r\n        at clojure.core$load.doInvoke(core.clj:6145)\r\n        at clojure.lang.RestFn.invoke(RestFn.java:408)\r\n        at clojure.core$load_one.invokeStatic(core.clj:5934)\r\n        at clojure.core$load_one.invoke(core.clj:5929)\r\n        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)\r\n        at clojure.core$load_lib.invokeStatic(core.clj:5975)\r\n        at clojure.core$load_lib.doInvoke(core.clj:5954)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:142)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$load_libs.invokeStatic(core.clj:6017)\r\n        at clojure.core$load_libs.doInvoke(core.clj:6001)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:669)\r\n        at clojure.core$require.invokeStatic(core.clj:6039)\r\n        at clojure.core$require.doInvoke(core.clj:6039)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at clojure.core$apply.invokeStatic(core.clj:667)\r\n        at clojure.core$serialized_require.invokeStatic(core.clj:6115)\r\n        at clojure.core$requiring_resolve.invokeStatic(core.clj:6124)\r\n        at clojure.core$requiring_resolve.invoke(core.clj:6118)\r\n        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)\r\n        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)\r\n        at clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n        at metabase.bootstrap.main(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException: No method in multimethod \'env-defaults\' for dispatch value: : postgres\r\n        at clojure.lang.MultiFn.getFn(MultiFn.java:156)\r\n        at clojure.lang.MultiFn.invoke(MultiFn.java:229)\r\n        at metabase.db.env$env_STAR_.invokeStatic(env.clj:132)\r\n        at metabase.db.env$env_STAR_.invoke(env.clj:117)\r\n        at metabase.db.env__init.load(Unknown Source)\r\n        at metabase.db.env__init.<clinit>(Unknown Source)\r\n        ... 201 more\r\n```', 'created_at': datetime.datetime(2024, 6, 27, 17, 32, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195317151, 'issue_id': 2376125626, 'author': 'noahmoss', 'body': '@psneha716 Try without the spaces after the `=` in the env vars', 'created_at': datetime.datetime(2024, 6, 27, 17, 55, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195427840, 'issue_id': 2376125626, 'author': 'psneha716', 'body': '@noahmoss I think the migration ran successfuly this time, but still not able to spin up a task with version 0.49.\r\n\r\n**Migrate down logs:**\r\n\r\n```\r\n[root]# docker run    -e ""MB_DB_TYPE=postgres""   -e ""MB_DB_DBNAME=postgres""   -e ""MB_DB_PORT=5432""   -e ""MB_DB_USER=postgres""   -e ""MB_DB_PASS=<pass>""   -e ""MB_DB_HOST=<host>""    --rm metabase/metabase:v0.50.7 ""migrate down""\r\nWarning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\n2024-06-27 18:09:22,842 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB\r\n2024-06-27 18:09:25,306 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-06-27 18:09:30,532 INFO driver.impl :: Registered abstract driver :sql  ðŸšš\r\n2024-06-27 18:09:30,538 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš\r\n2024-06-27 18:09:30,547 INFO metabase.util :: Load driver :sql-jdbc took 39.1 ms\r\n2024-06-27 18:09:30,548 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-27 18:09:30,731 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš2024-06-27 18:09:30,771 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-27 18:09:32,487 INFO metabase.core ::\r\nMetabase v0.50.7 (431cd8f)\r\n\r\nCopyright Â© 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-06-27 18:09:32,815 INFO db.setup :: Setting up Liquibase...\r\n2024-06-27 18:09:33,532 INFO db.setup :: Liquibase is ready.\r\n2024-06-27 18:09:33,562 INFO db.liquibase :: No migration lock found.\r\n2024-06-27 18:09:33,562 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-27 18:09:33,568 INFO db.liquibase :: Rolling back app database schema to version 49\r\n2024-06-27 18:09:34,113 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-27 18:09:34,123 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-27 18:09:34,123 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-27 18:09:34,124 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-27 18:09:34,125 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-27 18:09:34,126 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'ca643e45bdc01719511774114\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-27 18:09:34,127 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-27 18:09:34,127 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-27 18:09:34,150 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.\r\n2024-06-27 18:09:34,150 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""ip-172-30-4-155.ap-south-1.compute.internal1719509712251""\'s failed in-progress jobs.\r\n2024-06-27 18:09:34,155 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""ip-172-30-3-61.ap-south-1.compute.internal1719509711985""\'s failed in-progress jobs.\r\n2024-06-27 18:09:34,159 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 started.\r\n2024-06-27 18:09:34,173 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 shutting down.\r\n2024-06-27 18:09:34,173 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 paused.\r\n2024-06-27 18:09:34,174 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 shutdown complete.\r\n2024-06-27 18:09:34,182 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-27 18:09:34,185 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-27 18:09:34,185 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-27 18:09:34,186 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-27 18:09:34,186 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-27 18:09:34,186 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'ca643e45bdc01719511774183\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-27 18:09:34,187 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-27 18:09:34,187 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-27 18:09:34,195 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 started.\r\n2024-06-27 18:09:34,602 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 shutting down.\r\n2024-06-27 18:09:34,602 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 paused.\r\n2024-06-27 18:09:34,603 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 shutdown complete.\r\n2024-06-27 18:09:34,608 INFO db.custom-migrations :: No rollback for:  DeleteSendPulsesTask\r\n2024-06-27 18:09:34,627 INFO db.custom-migrations :: No rollback for:  CreateInternalUser\r\n```\r\n\r\n\r\n**Logs after spinning up v0.49.12:** \r\n[log-events-viewer-result (4).csv](https://github.com/user-attachments/files/16019424/log-events-viewer-result.4.csv)\r\n\r\n\r\n**databasechangelog dump:**\r\n[databasechangelog_3.csv](https://github.com/user-attachments/files/16019439/databasechangelog_3.csv)', 'created_at': datetime.datetime(2024, 6, 27, 18, 31, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195483705, 'issue_id': 2376125626, 'author': 'noahmoss', 'body': ""@piranha It seems like https://github.com/metabase/metabase/issues/44048 removed a migration ID that had already ran and now it can't be rolled back.\r\n\r\n@psneha716 You'll have to do some surgery on your app DB, I think. Can you run this and see if that resolves it? \r\n\r\n```\r\nDELETE FROM databasechangelog WHERE id = 'v50.2024-04-12T12:33:09';\r\n```"", 'created_at': datetime.datetime(2024, 6, 27, 19, 6, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195561423, 'issue_id': 2376125626, 'author': 'piranha', 'body': '@noahmoss yes it did and I regretfully was under a false impression that it was acceptable.', 'created_at': datetime.datetime(2024, 6, 27, 19, 51, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195633032, 'issue_id': 2376125626, 'author': 'psneha716', 'body': 'Phew, it worked! Thanks a lot guys! :)', 'created_at': datetime.datetime(2024, 6, 27, 20, 41, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196280321, 'issue_id': 2376125626, 'author': 'psneha716', 'body': 'Hi @noahmoss,\r\nIs there any way for me to know the versions of metabase that I had run previously? Basically a history of metabase versions.\r\n\r\nMetabase is still crashing with v0.49.12.', 'created_at': datetime.datetime(2024, 6, 28, 7, 7, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197006386, 'issue_id': 2376125626, 'author': 'piranha', 'body': '@psneha716 can you share a log of Metabase failing?', 'created_at': datetime.datetime(2024, 6, 28, 14, 3, 24, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-06-26 19:51:01 UTC): @psneha716 Is that the entire contents of the logs when you ran `migrate down`? No errors were reported?

If you're able, could you copy the contents of the `databasechangelog` table in your app DB and attach it?

psneha716 (Issue Creator) on (2024-06-27 10:57:01 UTC): @noahmoss, yes that's the entire contents of the logs, no errors. PFA the databasechangelog.
[databasechangelog_dump.csv](https://github.com/user-attachments/files/16012373/databasechangelog_dump.csv)

piranha (Assginee) on (2024-06-27 12:52:47 UTC): @psneha716 I'm reading the logs and `ERROR: Downgrade detected` means the following: you have migrations applied to your database which are not present in the metabase version you're using to downgrade.

Your logs (in the first message) indicate that it's executed with Metabase 0.49.12, so maybe something is happening here? Could you try again using 0.50.7 and look what's going on? Or do you mean that when running 0.50.7 it just hangs?

psneha716 (Issue Creator) on (2024-06-27 14:10:00 UTC): @piranha, the full error log says:

```
clojure.lang.ExceptionInfo: [31mERROR: Downgrade detected.[0m
Your metabase instance appears to have been downgraded without a corresponding database downgrade.
You must run `java -jar metabase.jar migrate down` from version 50.
Once your database has been downgraded, try running the application again.
```
The error log says instance has been downgraded (i.e instance version and not metabase db).

piranha (Assginee) on (2024-06-27 14:14:14 UTC): @psneha716 that's error log from 0.49.12, the one you've attached as a file. 0.49 cannot do a downgrade from 0.50. I think the message is a bit misleading and we need to revise it, but what it checks is `latest-available < latest-applied`, essentially that you have applied more migrations than there are available in a given Metabase jar.

Also your `databasechangelog` table indicates that you have applied all migrations up to 0.50.7, so that's the only version which can properly do a downgrade. Can you try using it again and if it's not successful - paste a full log of that execution?

cheyuriy on (2024-06-27 14:20:59 UTC): Tried to downgrade it too, but receive an error:
```
Metabase v0.50.7 (431cd8f)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-27 14:12:54,588 INFO db.setup :: Setting up Liquibase...
2024-06-27 14:12:55,485 INFO db.setup :: Liquibase is ready.
2024-06-27 14:12:55,529 INFO db.liquibase :: No migration lock found.
2024-06-27 14:12:55,529 INFO db.liquibase :: Migration lock acquired.
2024-06-27 14:12:55,536 INFO db.liquibase :: Rolling back app database schema to version 49
2024-06-27 14:12:56,031 INFO db.custom-migrations :: No rollback for:  CreateSampleContent
2024-06-27 14:12:56,120 INFO db.custom-migrations :: No rollback for:  MigrateStackedAreaBarComboDisplaySettings
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$rollback$7(Liquibase.java:579)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.rollback(Liquibase.java:568)
	at liquibase.Liquibase.rollback(Liquibase.java:551)
	at liquibase.Liquibase.rollback(Liquibase.java:542)
	at metabase.db.liquibase$rollback_major_version$fn__44519.invoke(liquibase.clj:485)
	at metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:478)
	at metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)
	at metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:470)
	at metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:671)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.db.setup$migrate_BANG_$fn__53364.invoke(setup.clj:86)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.cmd.migrate$migrate_BANG_.invokeStatic(migrate.clj:8)
	at metabase.cmd.migrate$migrate_BANG_.invoke(migrate.clj:5)
	at clojure.lang.Var.invoke(Var.java:384)
	at metabase.cmd$migrate.invokeStatic(cmd.clj:66)
	at metabase.cmd$migrate.invoke(cmd.clj:62)
	at clojure.lang.AFn.applyToHelper(AFn.java:154)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.cmd$run_cmd$fn__106571.invoke(cmd.clj:301)
	at metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)
	at metabase.cmd$run_cmd.invoke(cmd.clj:290)
	at clojure.lang.Var.invoke(Var.java:388)
	at metabase.core$run_cmd.invokeStatic(core.clj:192)
	at metabase.core$run_cmd.invoke(core.clj:190)
	at metabase.core$entrypoint.invokeStatic(core.clj:214)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:112)
	at liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:82)
	at liquibase.command.core.RollbackCountCommandStep.lambda$run$0(RollbackCountCommandStep.java:48)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.RollbackCountCommandStep.run(RollbackCountCommandStep.java:48)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 57 more
Caused by: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]
	at liquibase.changelog.ChangeSet.rollback(ChangeSet.java:956)
	at liquibase.changelog.visitor.RollbackVisitor.visit(RollbackVisitor.java:63)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1303)
	at liquibase.database.AbstractJdbcDatabase.executeRollbackStatements(AbstractJdbcDatabase.java:1327)
	at liquibase.database.AbstractJdbcDatabase.executeRollbackStatements(AbstractJdbcDatabase.java:1333)
	at liquibase.changelog.ChangeSet.rollback(ChangeSet.java:934)
	... 80 more
Caused by: org.postgresql.util.PSQLException: ERROR: column ""duration"" of relation ""task_history"" contains null values
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
Command failed with exception: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: ERROR: column ""duration"" of relation ""task_history"" contains null values [Failed SQL: (0) ALTER TABLE ""public"".""task_history"" ALTER COLUMN  ""duration"" SET NOT NULL]
```

psneha716 (Issue Creator) on (2024-06-27 14:33:19 UTC): @piranha Got it!
I tried downgrading from 0.50.7 to 0.49.12, which did not work. Basically when I try to spin up 0.49.12 after db migration, it exits with that error. Shall I downgrade it to a version lower than 0.49.12?

piranha (Assginee) on (2024-06-27 14:36:56 UTC): @cheyuriy Ohhh so we've catched your error, we had `NOT NULL` on `task_history.duration` and on `task_history.ended_at` before, and dropped those constraints in 0.50, and now it cannot rollback as you have entries with empty values in there. If you don't care about those, you can just `delete from task_history where duration is null or ended_at is null` and then rollback (using 0.50.7) again.

If you are worried about those entries it needs some more thinking. ðŸ˜

piranha (Assginee) on (2024-06-27 15:10:57 UTC): @psneha716 wait, is that the same issue, or is that a separate case from your issue? ðŸ˜

noahmoss on (2024-06-27 15:24:30 UTC): @psneha716 I'm pretty puzzled by the fact that it's not erroring at all when downgrading. Could you try running the downgrade from 50.7, and _then_ send the dump of `databasechangelog`? I'd like to see what migrations are still left after the downgrade that are blocking 49 from starting up.

cheyuriy on (2024-06-27 15:52:21 UTC): We were able to downgrade from 50.7 to 49.3 after cleaning `task_history` table.

psneha716 (Issue Creator) on (2024-06-27 15:57:21 UTC): @piranha, it's a separate issue :p

@noahmoss The logs and  changelog dump that I've shared are after migration from v0.50.7 to 0.49.12

piranha (Assginee) on (2024-06-27 15:59:29 UTC): @psneha716 well that migration did not really happen to you: your `databasechangelog` dump indicates you still got all the migrations from v50. And logs are from executing 0.49.12. What we need is full logs from executing `migrate down` on 0.50.7.

psneha716 (Issue Creator) on (2024-06-27 16:15:28 UTC): @piranha Okay, just ran the migrations and following are the full logs after executing `migrate down`

```
[root]# docker run --rm metabase/metabase:v0.50.7 ""migrate down""
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-27 16:10:10,249 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB
2024-06-27 16:10:12,754 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“ For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-06-27 16:10:13,510 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For productiondeployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database fileregularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html
2024-06-27 16:10:18,072 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
2024-06-27 16:10:18,078 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-06-27 16:10:18,084 INFO metabase.util :: Load driver :sql-jdbc took 32.9 ms
2024-06-27 16:10:18,084 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-06-27 16:10:18,243 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
2024-06-27 16:10:18,282 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-06-27 16:10:20,097 INFO metabase.core ::
Metabase v0.50.7 (431cd8f)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-27 16:10:20,401 INFO db.setup :: Setting up Liquibase...
2024-06-27 16:10:21,173 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-06-27 16:10:21,185 INFO db.liquibase :: No migration lock found.
2024-06-27 16:10:21,185 INFO db.liquibase :: Migration lock acquired.
2024-06-27 16:10:21,191 INFO db.setup :: Liquibase is ready.
2024-06-27 16:10:21,198 INFO db.liquibase :: No migration lock found.
2024-06-27 16:10:21,198 INFO db.liquibase :: Migration lock acquired.
2024-06-27 16:10:21,199 INFO db.liquibase :: Rolling back app database schema to version 49
[root]#
```


databasechangelogs: 
[DBChangelog_2.csv](https://github.com/user-attachments/files/16018033/DBChangelog_2.csv)

psneha716 (Issue Creator) on (2024-06-27 16:33:28 UTC): Oh wait, can I only revert back to the version that I was previously running and not any lower version of my choice?

`But if youâ€™ve made changes to your application database since upgrading that you want to keep, you may be able to use the migrate down command to roll back your Metabase application database to support the previous Metabase version you were running. `

noahmoss on (2024-06-27 16:47:42 UTC): @psneha716 I think I just realized the issue. When you're running `migrate down` you still need to pass the connect details for your DB as environment variables. (i.e. as shown [here](https://www.metabase.com/docs/latest/installation-and-operation/running-metabase-on-docker#running-docker-in-production)) Otherwise it will fall back to a default H2 app DB. It seems like it's ""successfully"" rolling back migrations on the wrong DB, which is why you're not seeing the rollback applied when you start Metabase 49 with Postgres.

This is definitely an issue with our docs/error messages â€”Â will work on getting those clarified. But in the meantime let me know if this works for you.

psneha716 (Issue Creator) on (2024-06-27 17:32:08 UTC): @noahmoss Tried that. Getting the following error:

```
[root]# docker run  \
  -e ""MB_DB_TYPE= postgres"" \
  -e ""MB_DB_DBNAME= postgres"" \
  -e ""MB_DB_PORT=5432"" \
  -e ""MB_DB_USER= postgres"" \
  -e ""MB_DB_PASS=<pass>â€ \
  -e ""MB_DB_HOST=<host>â€ \
   --rm metabase/metabase:v0.50.7 ""migrate down""

Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-27 17:30:01,728 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB
2024-06-27 17:30:04,242 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
Exception in thread ""main"" java.lang.ExceptionInInitializerError
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:619)
        at metabase.db.connection$loading__6789__auto____42274.invoke(connection.clj:1)
        at metabase.db.connection__init.load(Unknown Source)
        at metabase.db.connection__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:703)
        at metabase.db$loading__6789__auto____53409.invoke(db.clj:1)
        at metabase.db__init.load(Unknown Source)
        at metabase.db__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:2088)
        at metabase.models.serialization$loading__6789__auto____53610.invoke(serialization.clj:1)
        at metabase.models.serialization__init.load(Unknown Source)
        at metabase.models.serialization__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:3894)
        at metabase.models.setting$loading__6789__auto____54412.invoke(setting.clj:1)
        at metabase.models.setting__init.load(Unknown Source)
        at metabase.models.setting__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:930)
        at metabase.analytics.prometheus$loading__6789__auto____70244.invoke(prometheus.clj:1)
        at metabase.analytics.prometheus__init.load(Unknown Source)
        at metabase.analytics.prometheus__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.invoke(RestFn.java:3894)
        at metabase.core$loading__6789__auto____107972.invoke(core.clj:1)
        at metabase.core__init.load(Unknown Source)
        at metabase.core__init.<clinit>(Unknown Source)
        at java.base/java.lang.Class.forName0(Native Method)
        at java.base/java.lang.Class.forName(Unknown Source)
        at clojure.lang.RT.classForName(RT.java:2209)
        at clojure.lang.RT.classForName(RT.java:2218)
        at clojure.lang.RT.loadClassForName(RT.java:2237)
        at clojure.lang.RT.load(RT.java:449)
        at clojure.lang.RT.load(RT.java:424)
        at clojure.core$load$fn__6908.invoke(core.clj:6162)
        at clojure.core$load.invokeStatic(core.clj:6161)
        at clojure.core$load.doInvoke(core.clj:6145)
        at clojure.lang.RestFn.invoke(RestFn.java:408)
        at clojure.core$load_one.invokeStatic(core.clj:5934)
        at clojure.core$load_one.invoke(core.clj:5929)
        at clojure.core$load_lib$fn__6850.invoke(core.clj:5976)
        at clojure.core$load_lib.invokeStatic(core.clj:5975)
        at clojure.core$load_lib.doInvoke(core.clj:5954)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$load_libs.invokeStatic(core.clj:6017)
        at clojure.core$load_libs.doInvoke(core.clj:6001)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$require.invokeStatic(core.clj:6039)
        at clojure.core$require.doInvoke(core.clj:6039)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$serialized_require.invokeStatic(core.clj:6115)
        at clojure.core$requiring_resolve.invokeStatic(core.clj:6124)
        at clojure.core$requiring_resolve.invoke(core.clj:6118)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at metabase.bootstrap.main(Unknown Source)
Caused by: java.lang.IllegalArgumentException: No method in multimethod 'env-defaults' for dispatch value: : postgres
        at clojure.lang.MultiFn.getFn(MultiFn.java:156)
        at clojure.lang.MultiFn.invoke(MultiFn.java:229)
        at metabase.db.env$env_STAR_.invokeStatic(env.clj:132)
        at metabase.db.env$env_STAR_.invoke(env.clj:117)
        at metabase.db.env__init.load(Unknown Source)
        at metabase.db.env__init.<clinit>(Unknown Source)
        ... 201 more
```

noahmoss on (2024-06-27 17:55:04 UTC): @psneha716 Try without the spaces after the `=` in the env vars

psneha716 (Issue Creator) on (2024-06-27 18:31:06 UTC): @noahmoss I think the migration ran successfuly this time, but still not able to spin up a task with version 0.49.

**Migrate down logs:**

```
[root]# docker run    -e ""MB_DB_TYPE=postgres""   -e ""MB_DB_DBNAME=postgres""   -e ""MB_DB_PORT=5432""   -e ""MB_DB_USER=postgres""   -e ""MB_DB_PASS=<pass>""   -e ""MB_DB_HOST=<host>""    --rm metabase/metabase:v0.50.7 ""migrate down""
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-27 18:09:22,842 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB
2024-06-27 18:09:25,306 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-06-27 18:09:30,532 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
2024-06-27 18:09:30,538 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-06-27 18:09:30,547 INFO metabase.util :: Load driver :sql-jdbc took 39.1 ms
2024-06-27 18:09:30,548 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-06-27 18:09:30,731 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš2024-06-27 18:09:30,771 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-06-27 18:09:32,487 INFO metabase.core ::
Metabase v0.50.7 (431cd8f)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-27 18:09:32,815 INFO db.setup :: Setting up Liquibase...
2024-06-27 18:09:33,532 INFO db.setup :: Liquibase is ready.
2024-06-27 18:09:33,562 INFO db.liquibase :: No migration lock found.
2024-06-27 18:09:33,562 INFO db.liquibase :: Migration lock acquired.
2024-06-27 18:09:33,568 INFO db.liquibase :: Rolling back app database schema to version 49
2024-06-27 18:09:34,113 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-27 18:09:34,123 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-27 18:09:34,123 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-27 18:09:34,124 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-27 18:09:34,125 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-27 18:09:34,126 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'ca643e45bdc01719511774114'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-27 18:09:34,127 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-27 18:09:34,127 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-27 18:09:34,150 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.
2024-06-27 18:09:34,150 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""ip-172-30-4-155.ap-south-1.compute.internal1719509712251""'s failed in-progress jobs.
2024-06-27 18:09:34,155 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""ip-172-30-3-61.ap-south-1.compute.internal1719509711985""'s failed in-progress jobs.
2024-06-27 18:09:34,159 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 started.
2024-06-27 18:09:34,173 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 shutting down.
2024-06-27 18:09:34,173 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 paused.
2024-06-27 18:09:34,174 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774114 shutdown complete.
2024-06-27 18:09:34,182 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-27 18:09:34,185 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-27 18:09:34,185 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-27 18:09:34,186 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-27 18:09:34,186 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-27 18:09:34,186 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'ca643e45bdc01719511774183'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-27 18:09:34,187 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-27 18:09:34,187 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-27 18:09:34,195 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 started.
2024-06-27 18:09:34,602 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 shutting down.
2024-06-27 18:09:34,602 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 paused.
2024-06-27 18:09:34,603 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_ca643e45bdc01719511774183 shutdown complete.
2024-06-27 18:09:34,608 INFO db.custom-migrations :: No rollback for:  DeleteSendPulsesTask
2024-06-27 18:09:34,627 INFO db.custom-migrations :: No rollback for:  CreateInternalUser
```


**Logs after spinning up v0.49.12:** 
[log-events-viewer-result (4).csv](https://github.com/user-attachments/files/16019424/log-events-viewer-result.4.csv)


**databasechangelog dump:**
[databasechangelog_3.csv](https://github.com/user-attachments/files/16019439/databasechangelog_3.csv)

noahmoss on (2024-06-27 19:06:20 UTC): @piranha It seems like https://github.com/metabase/metabase/issues/44048 removed a migration ID that had already ran and now it can't be rolled back.

@psneha716 You'll have to do some surgery on your app DB, I think. Can you run this and see if that resolves it? 

```
DELETE FROM databasechangelog WHERE id = 'v50.2024-04-12T12:33:09';
```

piranha (Assginee) on (2024-06-27 19:51:59 UTC): @noahmoss yes it did and I regretfully was under a false impression that it was acceptable.

psneha716 (Issue Creator) on (2024-06-27 20:41:40 UTC): Phew, it worked! Thanks a lot guys! :)

psneha716 (Issue Creator) on (2024-06-28 07:07:51 UTC): Hi @noahmoss,
Is there any way for me to know the versions of metabase that I had run previously? Basically a history of metabase versions.

Metabase is still crashing with v0.49.12.

piranha (Assginee) on (2024-06-28 14:03:24 UTC): @psneha716 can you share a log of Metabase failing?

"
2376118059,issue,open,,"Small UI tweaks on browse section, application permissions, entity picker, and email settings","```[tasklist]
### Tasks
- [x] Move the `Browse` section in the sidebar below `Collections` and above `Trash` ([context](https://metaboat.slack.com/archives/C064EB1UE5P/p1718672513571679))
- [ ] Change the copy from the `Monitoring` permission tooltip to `This grants access to the Tools and Troubleshooting sections in Admin.` ([context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1718635102050019))
- [ ] In the dashboard picker, replace the dashboard tab and icon with `Collections` and the `folder` icon ([context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1718958110082899))
- [ ] In email settings, add a note `Recipients are always hidden to external users` in the ""Add recipientes as CC or BCC"" section ([context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1719416616046719))
- [ ] Add paths to tables in the entity picker and command palette ([figma](https://www.figma.com/design/3XI2BmzgPtXjmKRFGmElDG/Bug-fix---issue-%2344460?node-id=4-32&t=vF9o4DqNOpAfWl2H-0), [context](https://metaboat.slack.com/archives/C064EB1UE5P/p1719580372303259))
- [x] Add Model Icon to Model section inside a collection #43659
```


",luizarakaki,2024-06-26 19:31:39+00:00,['rafpaf'],2025-02-04 20:23:53+00:00,,https://github.com/metabase/metabase/issues/44783,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2376072825,issue,closed,completed,Add back `report_card.last_used_at`,"Updating `report_card.last_used_at` for cards was removed in [perf: disable view log and card used updates during metadata fetches](https://github.com/metabase/metabase/pull/44502/files). We need to add it back.

There is ongoing work that depends on `last_used_at` ([auto cleanup collections](https://www.notion.so/metabase/Auto-cleanup-collections-54b3b58e254a48e69b26a054c84fd944)), so we want to add it back.

Epic where we added `last_used_at`: https://github.com/metabase/metabase/issues/38229",calherries,2024-06-26 19:03:19+00:00,['qnkhuat'],2024-08-07 13:35:42+00:00,2024-07-16 10:38:52+00:00,https://github.com/metabase/metabase/issues/44782,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2196158275, 'issue_id': 2376072825, 'author': 'qnkhuat', 'body': 'We discussed using grouper as the batch processing tool in [slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719478364644629)', 'created_at': datetime.datetime(2024, 6, 28, 5, 14, 49, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-06-28 05:14:49 UTC): We discussed using grouper as the batch processing tool in [slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719478364644629)

"
2376067235,issue,closed,completed,Add back `view_count`,"Incrementing `view_count` for tables, cards, and dashboards was removed in [perf: disable view log and card used updates during metadata fetches](https://github.com/metabase/metabase/pull/44502/files). We need to add it back.

We will likely start using `view_count` at some point, so we want to add it back.

Epic where we added `view_count`: https://github.com/metabase/metabase/issues/38229",calherries,2024-06-26 18:59:39+00:00,['qnkhuat'],2024-08-08 09:11:10+00:00,2024-07-19 00:14:42+00:00,https://github.com/metabase/metabase/issues/44781,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2196158247, 'issue_id': 2376067235, 'author': 'qnkhuat', 'body': 'We discussed using grouper as the batch processing tool in [slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719478364644629)', 'created_at': datetime.datetime(2024, 6, 28, 5, 14, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2237800886, 'issue_id': 2376067235, 'author': 'qnkhuat', 'body': 'Closed by [Batch processing usage metadata](https://github.com/metabase/metabase/pull/45007)', 'created_at': datetime.datetime(2024, 7, 19, 0, 14, 40, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-06-28 05:14:47 UTC): We discussed using grouper as the batch processing tool in [slack](https://metaboat.slack.com/archives/C0641E4PB9B/p1719478364644629)

qnkhuat (Assginee) on (2024-07-19 00:14:40 UTC): Closed by [Batch processing usage metadata](https://github.com/metabase/metabase/pull/45007)

"
2376040460,issue,open,,Make it a setting whether Alert and Subscription email recipients are in Bcc or not,"**Is your feature request related to a problem? Please describe.**

- We have dozens of partnerships managed by several individuals at our organization and, if external recipients don't have easy access to their partnership manager on the email, they may respond to the email directly, sending the request to Metabase administrators, rather than their partnership manager. The partnership manager is typically the right person to do things like add or remove contacts, change report cadence, etc. and they are the internal user on the reports.
- Each subscription is sent to only one corporate entity, but possibly multiple contacts within the organization. The partnership managers are concerned that if the contacts are not visible to one another that they will receive questions and requests from those individuals about who else is receiving the report.
- We were able to disclose all recipients in these subscriptions prior to version 50.

**Describe the solution you'd like**
An option to allow recipients of a subscription or alert to see all of the other recipients. 

**Describe alternatives you've considered**
We tried using the ""Disclose recipients' setting in Metabase but it did not disclose all recipients - external users still receive individual emails without visible CCs

**How important is this feature to you?**
Internal processes were designed around the recipients being available to one another.
",ixipixi,2024-06-26 18:44:39+00:00,[],2025-02-04 20:30:40+00:00,,https://github.com/metabase/metabase/issues/44780,"[('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('Misc/Emails', '')]",[],
2376015660,issue,open,,Enabling/Disabling Password Auth for Certain Groups/Users,"**Is your feature request related to a problem? Please describe.**
We would like to set up SSO but still allow admins access to password authentication. This would allow admins to remediate auth issues without opening up security loopholes for the greater user base.

**Describe the solution you'd like**
When another authentication mechanism is in place, allow the option to enable password authentication by user or group rather than for all users.

**Describe alternatives you've considered**
Enabling password authentication for all users.


",ixipixi,2024-06-26 18:30:03+00:00,[],2025-02-04 20:30:11+00:00,,https://github.com/metabase/metabase/issues/44779,"[('Type:New Feature', ''), ('Administration/Auth', 'Google Auth, LDAP, pw+email login')]",[],
2376007409,issue,closed,completed,Improve cartesian chart performance on large datasets,"[Original report](https://metaboat.slack.com/archives/C064QMXEV9N/p1719407914830279)

Charts with 20k points may perform really slow and take 2 seconds to render on fast laptops vs 1 second previously:

<img width=""1725"" alt=""Screenshot 2024-06-26 at 2 17 30â€¯PM"" src=""https://github.com/metabase/metabase/assets/14301985/33d66384-5bb0-4c6f-9ca3-df8d3f356a38"">
",alxnddr,2024-06-26 18:25:00+00:00,['alxnddr'],2024-06-29 01:38:02+00:00,2024-06-28 23:21:07+00:00,https://github.com/metabase/metabase/issues/44778,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2375870654,issue,closed,completed,SDK - get rid of npm package installation warnings,"**Context**
When a user installs embedding sdk npm package, it generates dependencies warnings:

```
warning ""@metabase/embedding-sdk-react > @visx/axis@1.8.0"" has incorrect peer dependency ""react@^16.3.0-0"".
warning ""@metabase/embedding-sdk-react > @visx/grid@1.16.0"" has incorrect peer dependency ""react@^15.0.0-0 || ^16.0.0-0"".
warning ""@metabase/embedding-sdk-react > @visx/group@1.7.0"" has incorrect peer dependency ""react@^15.0.0-0 || ^16.0.0-0"".
warning ""@metabase/embedding-sdk-react > @visx/text@1.7.0"" has incorrect peer dependency ""react@^16.3.0-0"".
warning ""@metabase/embedding-sdk-react > postcss-discard-comments@6.0.2"" has unmet peer dependency ""postcss@^8.4.31"".
warning ""@metabase/embedding-sdk-react > react-motion@0.5.2"" has incorrect peer dependency ""react@^0.14.9 || ^15.3.0 || ^16.0.0"".
warning ""@metabase/embedding-sdk-react > react-router@3.2.6"" has incorrect peer dependency ""react@^0.14.0 || ^15.0.0 || ^16.0.0"".
warning ""@metabase/embedding-sdk-react > react-textarea-autosize@5.2.1"" has incorrect peer dependency ""react@>=0.14.0 <17.0.0"".
warning ""@metabase/embedding-sdk-react > @visx/axis > @visx/shape@1.8.0"" has incorrect peer dependency ""react@^16.3.0-0"".
warning ""@metabase/embedding-sdk-react > @visx/grid > @visx/shape@1.16.0"" has incorrect peer dependency ""react@^16.3.0-0"".
warning ""@metabase/embedding-sdk-react > kbar > react-virtual@2.10.4"" has incorrect peer dependency ""react@^16.6.3 || ^17.0.0"".
```

We want to get rid of these warnings.

",deniskaber,2024-06-26 17:07:00+00:00,['deniskaber'],2024-07-01 12:58:45+00:00,2024-07-01 12:58:45+00:00,https://github.com/metabase/metabase/issues/44772,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2375845461,issue,closed,completed,Unique constraint doesn't prevent duplicate fields for MySQL and H2,"Follows up on [Defective fields from JSON array values still exist and can be used in questions](https://github.com/metabase/metabase/issues/44659), and has to be landed afterwards.

Duplicate fields (fields with the same name in the same table) were allowed to be created https://github.com/metabase/metabase/issues/44459 and we fixed the root cause in #44465. We have a constraint that was meant to prevent this happening, but it didn't work for MySQL and H2.

On all db types, we have a unique index on metabase_field(table_id, parent_id, name). But most fields have parent_id = null, this column is only used for nested fields on MongoDB.  And in most databases, null != null, so thatâ€™s why you can have multiple a field with the same table_id, name and not violate the unique index.
On postgres, things are little brighter because it supports partial index and we added a unique index on (table_id, name) where parent_id is null. This is why it only fails when you migrate to postgres.

### To Reproduce

1. Start from https://github.com/metabase/metabase/pull/43812 with `git checkout 33df115`
2. Use MB with a MySQL app DB
3. Create a postgres DB with this table
```
CREATE TABLE my_table (
    id serial PRIMARY KEY,
    data jsonb
);

INSERT INTO my_table (data)
VALUES ('[1, 2, 3]'::jsonb);
```
4. Sync the created DB.
5. Create a question that selects from both ""Data"" fields.
![image](https://github.com/metabase/metabase/assets/39073188/cf2aefee-1a48-4df8-a6cf-4991e4c5c02b)

### Expected behavior

It should be impossible to create fields with the same name on the same table, unless they are nested fields and have different `parent_id`.

### Logs

_No response_

### Information about your Metabase installation

```JSON
it has been this way since we introduced nested fields
```


### Severity

High, these issues block cloud upgrades

### Additional context

_No response_",calherries,2024-06-26 16:57:17+00:00,[],2024-08-01 06:14:58+00:00,2024-08-01 06:14:58+00:00,https://github.com/metabase/metabase/issues/44771,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2262134501, 'issue_id': 2375845461, 'author': 'qnkhuat', 'body': 'Should be fixed as part of https://github.com/metabase/metabase/pull/44866', 'created_at': datetime.datetime(2024, 8, 1, 6, 14, 58, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-08-01 06:14:58 UTC): Should be fixed as part of https://github.com/metabase/metabase/pull/44866

"
2375782812,issue,closed,completed,PUT /api/permissions/graph is 7x slower in v50 than in v49,"### Describe the bug

There's a big performance regression when you change permissions on v50. This impacts customers with big permission graphs

### To Reproduce

1) run the following script to create big permission graphs (please use host, user, password, lower and upper bounds and also ensure you have a postgres sample db added
```
import requests, os

# Authentication
login_url = f""{os.environ['host']}/api/session""
login_payload = {""username"": f""{os.environ['user']}"", ""password"": f""{os.environ['password']}""}
session = requests.Session()
response = session.post(login_url, json=login_payload)

for i in range(int(os.environ['lower']), int(os.environ['upper'])):
    elapsed = 0
    # Create database
    create_db_url = f""{os.environ['host']}/api/database""
    create_db_payload = {
        ""is_on_demand"": False,
        ""is_full_sync"": False,
        ""is_sample"": False,
        ""cache_ttl"": None,
        ""refingerprint"": False,
        ""auto_run_queries"": True,
        ""schedules"": {},
        ""details"": {
            ""host"": ""postgres-data1"",
            ""port"": 5432,
            ""dbname"": ""sample"",
            ""user"": ""metabase"",
            ""password"": ""metasample123"",
            ""schema-filters-type"": ""all"",
            ""ssl"": False,
            ""tunnel-enabled"": False,
            ""advanced-options"": False,
        },
        ""name"": f""postgres-data-{i}"",
        ""engine"": ""postgres""
    }
    response = session.post(create_db_url, json=create_db_payload)
    db_time = response.elapsed
    db_id = response.json()[""id""]

    # Create group
    create_group_url = f""{os.environ['host']}/api/permissions/group""
    create_group_payload = {""name"": f""data{i}""}
    response = session.post(create_group_url, json=create_group_payload)
    group_time = response.elapsed

    group_id = response.json()[""id""]

    # Create user
    create_user_url = f""{os.environ['host']}/api/user""
    create_user_payload = {
        ""first_name"": f""data{i}"",
        ""last_name"": f""data{i}"",
        ""email"": f""data{i}@a.com"",
        ""user_group_memberships"": [
            {""id"": 1, ""is_group_manager"": False},
            {""id"": group_id, ""is_group_manager"": False},
        ],
    }
    response = session.post(create_user_url, json=create_user_payload)
    user_time = response.elapsed

    # Update permissions
    get_permissions_url = f""{os.environ['host']}/api/permissions/graph""
    response = session.get(get_permissions_url)
    graph_time = response.elapsed

    # Get the graph revision
    revision_id = response.json()[""revision""]

    update_permissions_url = f""{os.environ['host']}/api/permissions/graph""
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""write"",
                        ""schemas"": ""all""
                    }
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)
    permission_time = response.elapsed

    # Now change permissions 5 more times
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""none"",
                        ""schemas"": ""all""
                    },
                    ""data_model"": {
                        ""schemas"": ""all""
                    },
                    ""download"": {
                        ""schemas"": ""full""
                    },
                    ""details"": ""yes""
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)
    # One
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""write"",
                        ""schemas"": ""all""
                    }
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)

    # Two
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""none"",
                        ""schemas"": ""all""
                    },
                    ""data_model"": {
                        ""schemas"": ""all""
                    },
                    ""download"": {
                        ""schemas"": ""full""
                    },
                    ""details"": ""yes""
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)

    # Three
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""write"",
                        ""schemas"": ""all""
                    }
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)

    # Four
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""none"",
                        ""schemas"": ""all""
                    },
                    ""data_model"": {
                        ""schemas"": ""all""
                    },
                    ""download"": {
                        ""schemas"": ""full""
                    },
                    ""details"": ""yes""
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)

    # Five
    response = session.get(get_permissions_url)
    revision_id = response.json()[""revision""]
    update_permissions_payload = {
        ""groups"": {
            group_id: {
                db_id: {
                    ""data"": {
                        ""native"": ""write"",
                        ""schemas"": ""all""
                    }
                }
            }
        },
        ""revision"": revision_id
    }
    response = session.put(update_permissions_url, json=update_permissions_payload)

    print(f""{i} db: {db_time} group: {group_time} user: {user_time} graph: {graph_time} permission: {permission_time}"")
```
2) now with a big permissions graph use a telemetry tool to get the times

### Expected behavior

Performance should be equal or a little slower due to permissions being more atomic than on v49

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

[GET-api-permissions-graph-49.json](https://github.com/user-attachments/files/15992266/GET-api-permissions-graph-49.json)
[PUT-api-permissions-graph-49.json](https://github.com/user-attachments/files/15992272/PUT-api-permissions-graph-49.json)
[GET-api-permissions-graph-50.json](https://github.com/user-attachments/files/15992274/GET-api-permissions-graph-50.json)
[PUT-api-permissions-graph-50.json](https://github.com/user-attachments/files/15992278/PUT-api-permissions-graph-50.json)
",paoliniluis,2024-06-26 16:29:47+00:00,"['sloansparger', 'noahmoss']",2024-07-08 14:13:13+00:00,2024-07-02 17:13:04+00:00,https://github.com/metabase/metabase/issues/44768,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2192198117, 'issue_id': 2375782812, 'author': 'bshepherdson', 'body': ""This is possibly linked to the general performance issues I've been investigating. However I've been focusing on dashboard and query performance, and there might be a specific cause here."", 'created_at': datetime.datetime(2024, 6, 26, 16, 52, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192550065, 'issue_id': 2375782812, 'author': 'noahmoss', 'body': ""Root cause: it's more overhead to read the entire perms graph in 50 than it used to be when there are lots of both DBs and groups. And currently when you do a PUT, we read the entire thing twice: once to do a diff on the graph and determine what changed, and again to return the new state to the FE.\r\n\r\nWe'll fix this by doing partial graph updates and only sending/returning the groups that had permission changes."", 'created_at': datetime.datetime(2024, 6, 26, 20, 15, 57, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-06-26 16:52:44 UTC): This is possibly linked to the general performance issues I've been investigating. However I've been focusing on dashboard and query performance, and there might be a specific cause here.

noahmoss (Assginee) on (2024-06-26 20:15:57 UTC): Root cause: it's more overhead to read the entire perms graph in 50 than it used to be when there are lots of both DBs and groups. And currently when you do a PUT, we read the entire thing twice: once to do a diff on the graph and determine what changed, and again to return the new state to the FE.

We'll fix this by doing partial graph updates and only sending/returning the groups that had permission changes.

"
2375750721,issue,open,,"`displayInfo(query, stageIndex, column).selected` is computed incorrectly for questions based on models with metadata overrides where some db field is used more than once","### Describe the bug

When deselecting columns that are mapped to the same db column in model metadata, multiple columns are removed at once with `Lib.removeField`

### To Reproduce

1. Visit https://stats.metabase.com/model/6759-ticket
2. Click the âš™ï¸ gear icon on bottom left to edit Visualization Settings
3. Click `Add or Remove Columns`
4. Uncheck ""Assignee ID"" (3rd from last column)
<img width=""293"" alt=""Screenshot 2024-06-26 at 12 17 06"" src=""https://github.com/metabase/metabase/assets/8542534/0be2d9c7-cadb-44a4-877b-180e3c477fc2"">

See that 2 columns are removed at the same time:
<img width=""339"" alt=""Screenshot 2024-06-26 at 12 14 08"" src=""https://github.com/metabase/metabase/assets/8542534/e386dd34-9ba8-463d-9b22-23232a043f32"">


### Expected behavior

Only one column should be removed / deselected

### Logs

_No response_

### Information about your Metabase installation

```JSON
master (`7ade61330d991d755d9e17a1799453f7b0b59be5`)
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-06-26 16:15:24+00:00,[],2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/44767,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2194405517, 'issue_id': 2375750721, 'author': 'kamilmielnik', 'body': 'I got an exception trying to toggle these checkboxes. Hopefully the source of the issue is the same, so I\'m not reporting it separately.\r\nHere are repro steps:\r\n\r\n1. Create a question Orders join Orders on Orders.id = Orders.id\r\n2. Create a new question using the previous question as source\r\n3. Visualize\r\n4. Open visualization settings\r\n5. Click ""Add or remove columns""\r\n\r\n:x: columns that are shown in table viz are not checked\r\n:x: clicking the columns does not affect checkboxes\r\n:x: clicking on some columns results in following error coming from MLv2\r\n\r\n```\r\nInvalid output: {:query {:fields [""distinct, got: [[:field 34 {:base-type :type/BigInteger}] [:field 40 {:base-type :type/Integer}] [:field 37 {:base-type :type/Integer}] [:field 41 {:base-type :type/Float}] [:field 35 {:base-type :type/Float}] [:field 39 {:base-type :type/Float}] [:field 33 {:base-type :type/Float}] [:field 38 {:base-type :type/DateTime}] [:field 36 {:base-type :type/Integer}] [:field 16 {:base-type :type/Text}] [:field 34 {:base-type :type/BigInteger}] [:field 40 {:base-type :type/Integer}] [:field 37 {:base-type :type/Integer}] [:field 41 {:base-type :type/Float}] [:field 35 {:base-type :type/Float}] [:field 39 {:base-type :type/Float}] [:field 33 {:base-type :type/Float}] [:field 38 {:base-type :type/DateTime}] [:field 36 {:base-type :type/Integer}] [:field 64 {:base-type :type/Text, :source-field 37}]]""]}}\r\n```', 'created_at': datetime.datetime(2024, 6, 27, 11, 10, 2, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-06-27 11:10:02 UTC): I got an exception trying to toggle these checkboxes. Hopefully the source of the issue is the same, so I'm not reporting it separately.
Here are repro steps:

1. Create a question Orders join Orders on Orders.id = Orders.id
2. Create a new question using the previous question as source
3. Visualize
4. Open visualization settings
5. Click ""Add or remove columns""

:x: columns that are shown in table viz are not checked
:x: clicking the columns does not affect checkboxes
:x: clicking on some columns results in following error coming from MLv2

```
Invalid output: {:query {:fields [""distinct, got: [[:field 34 {:base-type :type/BigInteger}] [:field 40 {:base-type :type/Integer}] [:field 37 {:base-type :type/Integer}] [:field 41 {:base-type :type/Float}] [:field 35 {:base-type :type/Float}] [:field 39 {:base-type :type/Float}] [:field 33 {:base-type :type/Float}] [:field 38 {:base-type :type/DateTime}] [:field 36 {:base-type :type/Integer}] [:field 16 {:base-type :type/Text}] [:field 34 {:base-type :type/BigInteger}] [:field 40 {:base-type :type/Integer}] [:field 37 {:base-type :type/Integer}] [:field 41 {:base-type :type/Float}] [:field 35 {:base-type :type/Float}] [:field 39 {:base-type :type/Float}] [:field 33 {:base-type :type/Float}] [:field 38 {:base-type :type/DateTime}] [:field 36 {:base-type :type/Integer}] [:field 64 {:base-type :type/Text, :source-field 37}]]""]}}
```

"
2375526004,issue,closed,completed,Make SLO optional and default the SLO behavior to disabled,"**Is your feature request related to a problem? Please describe.**
We have a customer that's seeing an error when signing out of Okta due to SLO not being configured.

Also, they see the behavior of signing out from all applications strange, so it might seem reasonable to set it to default

**Describe the solution you'd like**
Make SLO optional and default the SLO behavior to disabled

**Describe alternatives you've considered**
None

**How important is this feature to you?**
1 customer is impacted

**Additional context**
NA
",paoliniluis,2024-06-26 14:30:32+00:00,['escherize'],2024-06-27 23:31:01+00:00,2024-06-27 18:21:18+00:00,https://github.com/metabase/metabase/issues/44758,"[('Type:New Feature', ''), ('.Backend', ''), ('Administration/Settings', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2375497680,issue,closed,completed,Users that upgraded to v50 receive an email with a link that goes to a 404,"### Describe the bug

The email about permission groups goes to https://www.metabase.com/docs/latest/permissions/no-self-service-deprecated, which doesnÂ´t exist

### To Reproduce

1) do any permission setup on v49
2) move to 50, get the email
3) click on it

### Expected behavior

We should have that page alive

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-06-26 14:18:11+00:00,['noahmoss'],2024-06-27 14:47:59+00:00,2024-06-26 17:12:40+00:00,https://github.com/metabase/metabase/issues/44755,"[('Type:Bug', 'Product defects'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)')]","[{'comment_id': 2191871333, 'issue_id': 2375497680, 'author': 'noahmoss', 'body': 'The docs location is being fixed: https://metaboat.slack.com/archives/C01R1JY03J4/p1719411982257589', 'created_at': datetime.datetime(2024, 6, 26, 14, 34, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192238572, 'issue_id': 2375497680, 'author': 'noahmoss', 'body': 'Fixed via redirect', 'created_at': datetime.datetime(2024, 6, 26, 17, 12, 41, tzinfo=datetime.timezone.utc)}]","noahmoss (Assginee) on (2024-06-26 14:34:50 UTC): The docs location is being fixed: https://metaboat.slack.com/archives/C01R1JY03J4/p1719411982257589

noahmoss (Assginee) on (2024-06-26 17:12:41 UTC): Fixed via redirect

"
2375497343,issue,closed,completed,"""It's okay to play around with saved questions"" modal can't be dismissed with keyboard","### Describe the bug

This modal can't be dismissed with escape or enter.

![image](https://github.com/metabase/metabase/assets/32746338/7aea85f5-f23a-4de6-8d6a-678ed9e396c2)


### To Reproduce

1. Start up a new instance
2. Create a saved question and view it
3. Try to close the model with the keyboard

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master
```


### Severity

p3

### Additional context

_No response_",noahmoss,2024-06-26 14:18:02+00:00,['nemanjaglumac'],2024-07-09 07:16:02+00:00,2024-07-08 15:50:55+00:00,https://github.com/metabase/metabase/issues/44754,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2375479722,issue,closed,completed,Loading state content layout shift when viewing a question,"### Describe the bug

It started to happen around v50.

![image](https://github.com/metabase/metabase/assets/6830683/6d7e3203-6619-445b-a88f-fef63ba91a71)


Here's a recording:

https://github.com/metabase/metabase/assets/6830683/fe1d3312-04ca-463c-985b-a291a93723fc



### To Reproduce

1. Navigate to different questions from sidebar


### Expected behavior

Loading state should be positioned in the center of the page and not be cut off.


### Information about your Metabase installation

master, dd7996b756


### Severity

P2 - because it happens all the time and it makes the product look wonky (I can't unsee it now)",kamilmielnik,2024-06-26 14:11:04+00:00,[],2024-07-04 13:29:15+00:00,2024-07-04 13:02:27+00:00,https://github.com/metabase/metabase/issues/44753,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2208933686, 'issue_id': 2375479722, 'author': 'kamilmielnik', 'body': 'Closing as duplicate of #44495', 'created_at': datetime.datetime(2024, 7, 4, 13, 2, 27, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-04 13:02:27 UTC): Closing as duplicate of #44495

"
2375116990,issue,closed,completed,You cannot do a full serialization export on stats via API,"If you go to `/api/docs/`, find serialization and click `Try` without changing anything, you'll get a following message â€” with some toucan context, but with no actual stacktrace. [Some context](https://metaboat.slack.com/archives/C05MPF0TM3L/p1718060686322929)

```
{""lvl"":""ERROR"",""lgr"":""metabase-enterprise.serialization.api"",""m"":""Error during serialization"",""exception"":{""exception_class"":""clojure.lang.ExceptionInfo"",""exception_message"":null,""stacktrace"":""clojure.lang.ExceptionInfo: null
```

Serializing some particular collection seems to be working â€” be sure to disable settings and data model export, they put quite a load on the server.",piranha,2024-06-26 11:47:50+00:00,['piranha'],2024-07-12 17:44:00+00:00,2024-07-05 15:05:54+00:00,https://github.com/metabase/metabase/issues/44747,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2191520783, 'issue_id': 2375116990, 'author': 'darksciencebase', 'body': 'might turn out to be a P1', 'created_at': datetime.datetime(2024, 6, 26, 12, 3, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202803233, 'issue_id': 2375116990, 'author': 'piranha', 'body': 'This seems like a problem with data. Serialization tries to extract dashboard 743, which was last edited (and archived) in 2022, and its click behavior has `{linkType: ""page""}`, which we do not support.', 'created_at': datetime.datetime(2024, 7, 2, 11, 14, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206044459, 'issue_id': 2375116990, 'author': 'darksciencebase', 'body': ""the investigation has uncovered a slew of issues, and generally it's not greatâ„¢ that we can't export stats. raising to P1"", 'created_at': datetime.datetime(2024, 7, 3, 13, 10, 44, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-06-26 12:03:50 UTC): might turn out to be a P1

piranha (Issue Creator) on (2024-07-02 11:14:33 UTC): This seems like a problem with data. Serialization tries to extract dashboard 743, which was last edited (and archived) in 2022, and its click behavior has `{linkType: ""page""}`, which we do not support.

darksciencebase on (2024-07-03 13:10:44 UTC): the investigation has uncovered a slew of issues, and generally it's not greatâ„¢ that we can't export stats. raising to P1

"
2375053083,issue,open,,Add CSV upload acceptance tests,"### Description

Our current CSV test suite is deep[^1] and thorough[^2], but we still had some basic regressions.

One issue is that the data we load is typically quite small and focused on a single edge case - by using larger files with a combination of details we can build more confidence. This will also make it easier to increase test coverage as we discover bugs or add functionality. Finally, having a harness for loading large files will make a good basis for doing performance oriented work in the future.

Included in this test is scouring for a good corpus of test data and edge cases to use (or be inspired by) - for example here is a list of a few that I found.

- https://github.com/max-mapper/csv-spectrum
- https://github.com/vincentlaucsb/csv-data/
- https://softwareengineering.stackexchange.com/a/65207

We can also adapt some files from real world usage as well, for example those leading to internal bug reports.

[^1]: We test mostly through the top-level methods, with read files etc, and very little mocking.
[^2]: A lot of edge cases are tested this way - we have 281 assertions, excluding type-inference related ones.",crisptrutski,2024-06-26 11:13:14+00:00,[],2024-06-26 11:13:15+00:00,,https://github.com/metabase/metabase/issues/44742,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/Workflows', 'aka BEC')]",[],
2375022816,issue,closed,not_planned,Users created incorrectly from config.yml during an import into an uninitialized instance,"### Describe the bug

Users are not created correctly when config.yml is specificed, and an `import` command is run on an uninitialized instance.

### To Reproduce

1. Create an instance, add some contents, export it via the CLI
2. Create a config.yml with a user
3. Import the exported resources into a new instance with an uninitialized database, and also use `config.yml` to add new users in the same step. Something like:
`MB_CONFIG_FILE_PATH=config_with_user.yml java -jar metabase.jar import export_dir`

4.(!) The import runs, but the users are created incorrectly.
* the internal user is created with the incorrect id: 1 (seen this only on 1.49.18, not in 1.49.7)
* first_name and last_name are null
* is_superuser set to false (was true in the import)

5.(!) Start the instance, and see that the password of the imported user doesn't work

### Expected behavior

config.yml should be processed correctly even during the import phase

### Logs

_No response_

### Information about your Metabase installation

```JSON
Recent versions of 49 and 50 (1.49.18 and 1.50.7).
```


### Severity

Reported by a customer on v49

### Additional context

config.yml
```
version: 1
config:
  users:
    - first_name: a
      last_name: b
      password: some_password
      email: a@b.com
      is_superuser: true
```

Records in core_user after the import:
```
# [
#   {
#     ""id"": 1,
#     ""email"": ""internal@metabase.com"",
#     ""first_name"": null,
#     ""last_name"": null,
#     ""password"": ""$2a$10$CP.liWQ6YXD5GEOLCWPQ1.b6DB0a3cibQMancy9Y/ArQ3crwKvDuS"",
#     ""password_salt"": ""b817b8c5-becc-4b01-92f9-99b2590dc623"",
#     ""date_joined"": ""2024-06-26 09:10:48.828406 +00:00"",
#     ""last_login"": null,
#     ""is_superuser"": false,
#     ""is_active"": true,
#     ""reset_token"": null,
#     ""reset_triggered"": null,
#     ""is_qbnewb"": true,
#     ""login_attributes"": null,
#     ""updated_at"": ""2024-06-26 09:10:48.828406 +00:00"",
#     ""sso_source"": null,
#     ""locale"": null,
#     ""is_datasetnewb"": true,
#     ""settings"": ""{\""last-acknowledged-version\"":\""v1.49.18\""}"",
#     ""type"": ""personal""
#   },
#   {
#     ""id"": 2,
#     ""email"": ""a@b.com"",
#     ""first_name"": null,
#     ""last_name"": null,
#     ""password"": ""$2a$10$WVAobp0p807JoNuJhQkFvOvXDOW.yoCpKFTdAtEKiYoYqGnXXKw/y"",
#     ""password_salt"": ""c16f7294-8db6-40d2-9797-f333f7e68bb1"",
#     ""date_joined"": ""2024-06-26 09:10:48.828406 +00:00"",
#     ""last_login"": null,
#     ""is_superuser"": false,
#     ""is_active"": true,
#     ""reset_token"": null,
#     ""reset_triggered"": null,
#     ""is_qbnewb"": true,
#     ""login_attributes"": null,
#     ""updated_at"": ""2024-06-26 09:10:48.828406 +00:00"",
#     ""sso_source"": null,
#     ""locale"": null,
#     ""is_datasetnewb"": true,
#     ""settings"": ""{\""last-acknowledged-version\"":\""v1.49.18\""}"",
#     ""type"": ""personal""
#   }
# ]
```",zbodi74,2024-06-26 10:57:15+00:00,['johnswanson'],2024-07-12 14:41:31+00:00,2024-07-05 18:16:49+00:00,https://github.com/metabase/metabase/issues/44739,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/', ''), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2195571404, 'issue_id': 2375022816, 'author': 'johnswanson', 'body': ""@zbodi74 I merged a PR to fix this, but wanted to elaborate a bit on the problem and its solution.\r\n\r\nFundamentally I think the problem is more that running `import` on a brand new Metabase App DB is broken. This is true even if you don't use a config file - the export contains the internal user, the new app DB doesn't, so we create the internal user in a broken state.\r\n\r\nMy fix doesn't actually change this - it just tells the user that they're trying to do something we don't support, and what to do instead. In this case, you could run `MB_CONFIG_FILE_PATH=config_with_user.yml java -jar metabase.jar` to launch Metabase and get everything initialized. Then, once the user has been created by *that* process, exit and run `java -jar metabase.jar import export_dir` to do the import before restarting Metabase.\r\n\r\nNote that if you do `MB_CONFIG_FILE_PATH=config_with_user.yml java -jar metabase.jar import export_dir`, the env var doesn't break anything - but it doesn't do anything either."", 'created_at': datetime.datetime(2024, 6, 27, 19, 59, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196818302, 'issue_id': 2375022816, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)', 'created_at': datetime.datetime(2024, 6, 28, 12, 39, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210789029, 'issue_id': 2375022816, 'author': 'zbodi74', 'body': '@johnswanson - reopening this based on the requestors feedback, attached below. It seems the import to a clean instance was at least partially usable, and that functionality is already in use in the wild.\r\nWe need to either revert the change, change the validation into a warning, or keep it but make it overridable.\r\n\r\n> Our current solution works in the following way:\r\n> \r\n> - we run the import on a brand new Metabase Instance\r\n> - we generate a config.yml file for Metabase containing the user and for the password we are using an env variable\r\n> - we start the metabase instance and itâ€™s correctly configured with the predefined dashboards and the superuser\r\n>  \r\n> \r\n> \r\n> Currently, we are ok with this approach and itâ€™s something that weâ€™d like to keep for the following releases.\r\n> [...]\r\n> Weâ€™ve done some tests with version 1.49.19 which should contain the fix that you were talking about below. \r\n> We found out that this fix breaks our implementation.\r\n> \r\n> To reiterate what we are doing to configure Metabase with some predefined dashboards:\r\n> 1. Run import command with some predefined dashboards\r\n> 2. Start Metabase fully configured', 'created_at': datetime.datetime(2024, 7, 5, 12, 27, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2211251219, 'issue_id': 2375022816, 'author': 'luizarakaki', 'body': ""@zbodi74 unfortunately, this isn't a supported use case. If this works, it was a fluke and we don't want to add a new way of starting a Metabase instance. There are other ways to achieve the same result, including simply creating an instance as usual and using the API to import content."", 'created_at': datetime.datetime(2024, 7, 5, 18, 16, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225740609, 'issue_id': 2375022816, 'author': 'johnswanson', 'body': '@zbodi74 I ended up making `import` [do the normal initialization procedure](https://github.com/metabase/metabase/pull/45390). Once that goes out you should now be able to run something like `MB_CONFIG_FILE=... java -jar metabase.jar import /path/to/export` to initialize the instance again. Sorry for the confusion here!', 'created_at': datetime.datetime(2024, 7, 12, 14, 41, 30, tzinfo=datetime.timezone.utc)}]","johnswanson (Assginee) on (2024-06-27 19:59:13 UTC): @zbodi74 I merged a PR to fix this, but wanted to elaborate a bit on the problem and its solution.

Fundamentally I think the problem is more that running `import` on a brand new Metabase App DB is broken. This is true even if you don't use a config file - the export contains the internal user, the new app DB doesn't, so we create the internal user in a broken state.

My fix doesn't actually change this - it just tells the user that they're trying to do something we don't support, and what to do instead. In this case, you could run `MB_CONFIG_FILE_PATH=config_with_user.yml java -jar metabase.jar` to launch Metabase and get everything initialized. Then, once the user has been created by *that* process, exit and run `java -jar metabase.jar import export_dir` to do the import before restarting Metabase.

Note that if you do `MB_CONFIG_FILE_PATH=config_with_user.yml java -jar metabase.jar import export_dir`, the env var doesn't break anything - but it doesn't do anything either.

github-actions[bot] on (2024-06-28 12:39:43 UTC): ðŸš€ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)

zbodi74 (Issue Creator) on (2024-07-05 12:27:02 UTC): @johnswanson - reopening this based on the requestors feedback, attached below. It seems the import to a clean instance was at least partially usable, and that functionality is already in use in the wild.
We need to either revert the change, change the validation into a warning, or keep it but make it overridable.

luizarakaki on (2024-07-05 18:16:49 UTC): @zbodi74 unfortunately, this isn't a supported use case. If this works, it was a fluke and we don't want to add a new way of starting a Metabase instance. There are other ways to achieve the same result, including simply creating an instance as usual and using the API to import content.

johnswanson (Assginee) on (2024-07-12 14:41:30 UTC): @zbodi74 I ended up making `import` [do the normal initialization procedure](https://github.com/metabase/metabase/pull/45390). Once that goes out you should now be able to run something like `MB_CONFIG_FILE=... java -jar metabase.jar import /path/to/export` to initialize the instance again. Sorry for the confusion here!

"
2374988679,issue,closed,completed,Last axis label is missing on all numerical axes,"### Describe the bug

When creating charts with a numerical axis, the last axis label is always missing. This might be kind of OK for absolute value charts with auto-ranging, however I believe this is particularly unfavorable when I'd like to show a value on a 0-100% scale (where I'd like to in-fact see a full 0-100% scale).

![image](https://github.com/metabase/metabase/assets/11353865/6ffe22b6-f98b-4bf4-8cb7-4b6ac8e4f7a5)


### To Reproduce

1. Create a new SQL-query as `select 0.8 as value, 'test' as category`
2. Set visualization to Row
3. Set value formatting style to `Percent`
4. Disable `Auto x-axis range` and set `Max` to 1

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.92-99.174.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    }
  }
}
```


### Severity

Minimal

### Additional context

_No response_",mkrauter,2024-06-26 10:39:29+00:00,['lorem--ipsum'],2025-01-31 13:50:08+00:00,2025-01-31 06:55:51+00:00,https://github.com/metabase/metabase/issues/44735,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.LongTerm', 'Issues we will fix in the long term, not a near term priority')]","[{'comment_id': 2273976168, 'issue_id': 2374988679, 'author': 'cdeweyx', 'body': ""Repro'ed [here](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7Im5hdGl2ZSI6eyJxdWVyeSI6InNlbGVjdCAwLjggQVMgXCJWYWxcIiwgJ3Rlc3QnIGFzIFwiQ2F0XCIiLCJ0ZW1wbGF0ZS10YWdzIjp7fX0sInR5cGUiOiJuYXRpdmUiLCJkYXRhYmFzZSI6NDh9LCJkaXNwbGF5Ijoicm93IiwiZGlzcGxheUlzTG9ja2VkIjp0cnVlLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6eyJjb2x1bW5fc2V0dGluZ3MiOnsiW1wibmFtZVwiLFwidmFsXCJdIjp7Im51bWJlcl9zdHlsZSI6InBlcmNlbnQifX0sImdyYXBoLnlfYXhpcy5hdXRvX3JhbmdlIjpmYWxzZSwiZ3JhcGgueV9heGlzLm1heCI6MX0sInR5cGUiOiJxdWVzdGlvbiJ9)"", 'created_at': datetime.datetime(2024, 8, 7, 17, 30, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2623246527, 'issue_id': 2374988679, 'author': 'tsplude', 'body': ""For posterity, did a little investigation in this:\n\nIn @cdeweyx 's repro, the last tick we want is `1`, which gets dropped by `omitOverlappingTicks` [here](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/ticks.ts#L40) because `currentTickEnd > max`.\n\nCuriously, `currentTickEnd` is greater than `max` by exactly `currentTickWidth / 2`.\n\nSo at first glance it appears that maybe we want to utilize `addSideSpacingForTicksAndLabels` but [we explicitly don't](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/RowChart.tsx#L205) if there are custom min / max axis values set.\n\nIf we take off that check we can see that `addScalePadding` [attempts to correct](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/scale.ts#L92) the d3 scale by exactly the `currentTickWidth / 2` that we need to account for, but `adjustedDomainEnd` reverts back to `1` in the example I believe because the linear scale has `clamping: False` ([here](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/scale.ts#L44)) since, again, we have user supplied min / max\n\nQuickest fix is to just adjust the trimming logic in `omitOverlappingTicks` to be e.g. below - but still being new to the frontend code this feels like we'd probably introduce tick label overflow issues:\n```\n    if (currentTickEnd > nextAvailableX || currentTickEnd > max + currentTickWidth / 2) {\n      continue;\n    }\n```"", 'created_at': datetime.datetime(2025, 1, 30, 0, 24, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627401863, 'issue_id': 2374988679, 'author': 'mkrauter', 'body': 'Thank you!', 'created_at': datetime.datetime(2025, 1, 31, 13, 50, 6, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-07 17:30:47 UTC): Repro'ed [here](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7Im5hdGl2ZSI6eyJxdWVyeSI6InNlbGVjdCAwLjggQVMgXCJWYWxcIiwgJ3Rlc3QnIGFzIFwiQ2F0XCIiLCJ0ZW1wbGF0ZS10YWdzIjp7fX0sInR5cGUiOiJuYXRpdmUiLCJkYXRhYmFzZSI6NDh9LCJkaXNwbGF5Ijoicm93IiwiZGlzcGxheUlzTG9ja2VkIjp0cnVlLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6eyJjb2x1bW5fc2V0dGluZ3MiOnsiW1wibmFtZVwiLFwidmFsXCJdIjp7Im51bWJlcl9zdHlsZSI6InBlcmNlbnQifX0sImdyYXBoLnlfYXhpcy5hdXRvX3JhbmdlIjpmYWxzZSwiZ3JhcGgueV9heGlzLm1heCI6MX0sInR5cGUiOiJxdWVzdGlvbiJ9)

tsplude on (2025-01-30 00:24:20 UTC): For posterity, did a little investigation in this:

In @cdeweyx 's repro, the last tick we want is `1`, which gets dropped by `omitOverlappingTicks` [here](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/ticks.ts#L40) because `currentTickEnd > max`.

Curiously, `currentTickEnd` is greater than `max` by exactly `currentTickWidth / 2`.

So at first glance it appears that maybe we want to utilize `addSideSpacingForTicksAndLabels` but [we explicitly don't](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/RowChart.tsx#L205) if there are custom min / max axis values set.

If we take off that check we can see that `addScalePadding` [attempts to correct](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/scale.ts#L92) the d3 scale by exactly the `currentTickWidth / 2` that we need to account for, but `adjustedDomainEnd` reverts back to `1` in the example I believe because the linear scale has `clamping: False` ([here](https://github.com/metabase/metabase/blob/a451a506a0d8b5274a936cde0f018672c8594b8e/frontend/src/metabase/visualizations/shared/components/RowChart/utils/scale.ts#L44)) since, again, we have user supplied min / max

Quickest fix is to just adjust the trimming logic in `omitOverlappingTicks` to be e.g. below - but still being new to the frontend code this feels like we'd probably introduce tick label overflow issues:
```
    if (currentTickEnd > nextAvailableX || currentTickEnd > max + currentTickWidth / 2) {
      continue;
    }
```

mkrauter (Issue Creator) on (2025-01-31 13:50:06 UTC): Thank you!

"
2374291269,issue,closed,not_planned,CSV cannot append CSV with column names that truncate to the same prefix,"### Describe the bug

Many databases have modest limits in the length of the column names that they support, and they may truncate them silently. When this truncation would result in two columns having the same name, ~~the upload~~ appending will fail.

**Update:** We have updated the ""unique-ification"" of columns to keep its deduplicated names within the maximum length. This fixed initial uploads, but appends are still broken as we do not modify them to ensure uniqueness.

### To Reproduce

1. Enable uploads for a Postgres database.
2. Go to a collection.
3. Upload a CSV file with two columns that differ only in their 64th character.
4. ~~See the following error:~~ *This now works for initial upload.*
5. Append the same file again.
6. See the following error:

> Error executing write query: ERROR: column ""really_long_name_with_a_difference_that_will_only_appear_later_o"" specified more than once

### Expected behavior

~~The upload succeeds and there are two distinct columns in the final table.~~

Appending to the relevant model will succeed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version: 48+
```


### Severity

P2

### Additional context

_No response_",crisptrutski,2024-06-26 05:01:47+00:00,[],2025-01-06 10:29:37+00:00,2025-01-06 10:29:37+00:00,https://github.com/metabase/metabase/issues/44725,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2190716080, 'issue_id': 2374291269, 'author': 'crisptrutski', 'body': 'A solution to this is to explicitly truncate names shorter than necessary, so that we can append some disambiguating identifier at the end, e.g. a counter.\r\n\r\nUnfortunately we use the database column name verbatim in the model, and these suffixes will have no meaning to the customer, who will thus have difficulty telling them apart. Additionally, this would make additional uploaded sensitive to column ordering.\r\n\r\nA solution to the previous two issues would be to store the non-truncated (and potentially non-munged) name somewhere else in the database, and to use *this* name for both the labels in the model and matching up with appended files (see https://github.com/metabase/metabase/issues/44724)', 'created_at': datetime.datetime(2024, 6, 26, 5, 6, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194517439, 'issue_id': 2374291269, 'author': 'crisptrutski', 'body': 'So, we can theoretically use `metabase_field.display_name` to store the original name, which would be spark joy in and of itself. Unfortunately, that is also bounded, which is two characters shorter than h2\'s identifier limit. For Postgres this would still give us an additional Â±200 characters though.\r\n\r\nI\'m guessing the reason we don\'t unique-ify column names on append, is because we could switch up columns due to different ordering. Perhaps @calherries can clarify this. If it is the case, the ""does this look right"" confirmation screen idea could solve the problem.\r\n\r\nA probably-too-smart-for-its-own-good idea would be to use a hash of the full name as a suffix of the physical column name, but that could still have collisions. A possibly overly heavy solution would be to introduce a new table joining to the field, with a text column. We could only populate it for the long ones, although migrating from h2 to postgres would change the definition (and result in missing values).\r\n\r\nProbably 254 characters is ample, since humans have to read these labels after all. If we can restrict this issue to only affecting longer titles, that is probably enough. So I\'m still gung-ho on using the display name as as fallback to match columns when the slugified name is ambiguous.', 'created_at': datetime.datetime(2024, 6, 27, 12, 8, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195780743, 'issue_id': 2374291269, 'author': 'calherries', 'body': 'Having a look at the solution in https://github.com/metabase/metabase/pull/44809 I\'m not convinced this issue is important enough to justify the extra complexity. It already feels a little too magic that we de-duplicate field names or truncate long names. It\'s far too much magic to de-duplicate and truncate long names to the exact number of characters required to store the required suffix to de-duplicate them. To demonstrate what I mean by complexity, imagine explaining this behaviour to a customer?\r\n```clj\r\n(metabase.driver/register! ::test-driver)\r\n(defmethod metabase.driver/column-name-length-limit ::test-driver [_] 4)\r\n(metabase.upload/derive-column-names ::test-driver [""abcd"" ""abcd"" ""ab_2_bc"" ""ab_3_bc""])\r\n;; => (:abcd :ab_2 :ab_3 :ab_4)\r\n```\r\n\r\nWithout any other bright ideas I suggest we just keep it simple and throw an exception if there are long column names that truncate to the same prefix. To quote [Arakaki](https://metaboat.slack.com/archives/C0641E4PB9B/p1719406719386459?thread_ts=1719378119.051019&cid=C0641E4PB9B):  ""This is the kind of issue that is between a bug and a limitation. Iâ€™d say that it is reasonable to expect not huge column names.""\r\n\r\nI liked the idea of using the display name to identify fields with duplicate slugified names, but I imagine most of its benefit would be from identifying names whose uniqueness had been removed by slugifying. Most of the benefit is not for truncated long names: that case seems a lot rarer in practice.', 'created_at': datetime.datetime(2024, 6, 27, 22, 39, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196388259, 'issue_id': 2374291269, 'author': 'crisptrutski', 'body': 'I agree that ""usurping"" prefixes is confusing. It would be even worse in the case `[""abcd"" ""abcd"" ""ab_2""]`, where we steal a name verbatim. That said, a surprising name is better than surprising behavior in my opinion. Coupled with using the original names as labels, and querying through models, I still lean in the direction of making this work. If you look at my [PR](https://github.com/metabase/metabase/pull/44873/files) which removes the buffer, and therefore introduces duplicates, we still have other problems to resolve.\r\n\r\nThat said, I wholeheartedly agree with fixing appends for existing tables, and we\'d need to get that fix into the deployment going out on Tuesday, so happy to put this on the backburner.\r\n\r\n> It\'s far too much magic to de-duplicate and truncate long names to the exact number of characters required to store the required suffix to de-duplicate them\r\n\r\nThis is something the original utility calls out support for, so I don\'t think it\'s that outlandish an idea, and I also think we can make it work. I\'ve updated the PR with a simple modification that ensures that we reserve a given name for the first column whose prefix matches it verbatim, to prevent any insolent usurper strings flipping things around rudely.\r\n\r\n```clojure\r\n(#\'metabase.upload/derive-column-names ::test-driver [""abcd"" ""abcd"" ""ab_2_bc"" ""ab_3_bc""])\r\n;; => (:abcd :ab_4 :ab_2 :ab_3)\r\n```', 'created_at': datetime.datetime(2024, 6, 28, 8, 19, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196388452, 'issue_id': 2374291269, 'author': 'crisptrutski', 'body': 'Update: I see actually MBQL thought about this edge case, and its solution is to resort to hashes for really long names. That\'s much less likely to result in these ""usurping"" gotchas, and also saves us forking this big method, so going to put up a PR just using that next.', 'created_at': datetime.datetime(2024, 6, 28, 8, 19, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196389678, 'issue_id': 2374291269, 'author': 'crisptrutski', 'body': 'Urgh, meant to close the PR not the issue ðŸ¤¦', 'created_at': datetime.datetime(2024, 6, 28, 8, 20, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217780692, 'issue_id': 2374291269, 'author': 'luizarakaki', 'body': ""Moving this to P3 while we don't hear about people hitting this.\r\nThere is also a workaround (use shorter column headers)"", 'created_at': datetime.datetime(2024, 7, 9, 13, 41, 35, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-06-26 05:06:36 UTC): A solution to this is to explicitly truncate names shorter than necessary, so that we can append some disambiguating identifier at the end, e.g. a counter.

Unfortunately we use the database column name verbatim in the model, and these suffixes will have no meaning to the customer, who will thus have difficulty telling them apart. Additionally, this would make additional uploaded sensitive to column ordering.

A solution to the previous two issues would be to store the non-truncated (and potentially non-munged) name somewhere else in the database, and to use *this* name for both the labels in the model and matching up with appended files (see https://github.com/metabase/metabase/issues/44724)

crisptrutski (Issue Creator) on (2024-06-27 12:08:08 UTC): So, we can theoretically use `metabase_field.display_name` to store the original name, which would be spark joy in and of itself. Unfortunately, that is also bounded, which is two characters shorter than h2's identifier limit. For Postgres this would still give us an additional Â±200 characters though.

I'm guessing the reason we don't unique-ify column names on append, is because we could switch up columns due to different ordering. Perhaps @calherries can clarify this. If it is the case, the ""does this look right"" confirmation screen idea could solve the problem.

A probably-too-smart-for-its-own-good idea would be to use a hash of the full name as a suffix of the physical column name, but that could still have collisions. A possibly overly heavy solution would be to introduce a new table joining to the field, with a text column. We could only populate it for the long ones, although migrating from h2 to postgres would change the definition (and result in missing values).

Probably 254 characters is ample, since humans have to read these labels after all. If we can restrict this issue to only affecting longer titles, that is probably enough. So I'm still gung-ho on using the display name as as fallback to match columns when the slugified name is ambiguous.

calherries on (2024-06-27 22:39:30 UTC): Having a look at the solution in https://github.com/metabase/metabase/pull/44809 I'm not convinced this issue is important enough to justify the extra complexity. It already feels a little too magic that we de-duplicate field names or truncate long names. It's far too much magic to de-duplicate and truncate long names to the exact number of characters required to store the required suffix to de-duplicate them. To demonstrate what I mean by complexity, imagine explaining this behaviour to a customer?
```clj
(metabase.driver/register! ::test-driver)
(defmethod metabase.driver/column-name-length-limit ::test-driver [_] 4)
(metabase.upload/derive-column-names ::test-driver [""abcd"" ""abcd"" ""ab_2_bc"" ""ab_3_bc""])
;; => (:abcd :ab_2 :ab_3 :ab_4)
```

Without any other bright ideas I suggest we just keep it simple and throw an exception if there are long column names that truncate to the same prefix. To quote [Arakaki](https://metaboat.slack.com/archives/C0641E4PB9B/p1719406719386459?thread_ts=1719378119.051019&cid=C0641E4PB9B):  ""This is the kind of issue that is between a bug and a limitation. Iâ€™d say that it is reasonable to expect not huge column names.""

I liked the idea of using the display name to identify fields with duplicate slugified names, but I imagine most of its benefit would be from identifying names whose uniqueness had been removed by slugifying. Most of the benefit is not for truncated long names: that case seems a lot rarer in practice.

crisptrutski (Issue Creator) on (2024-06-28 08:19:39 UTC): I agree that ""usurping"" prefixes is confusing. It would be even worse in the case `[""abcd"" ""abcd"" ""ab_2""]`, where we steal a name verbatim. That said, a surprising name is better than surprising behavior in my opinion. Coupled with using the original names as labels, and querying through models, I still lean in the direction of making this work. If you look at my [PR](https://github.com/metabase/metabase/pull/44873/files) which removes the buffer, and therefore introduces duplicates, we still have other problems to resolve.

That said, I wholeheartedly agree with fixing appends for existing tables, and we'd need to get that fix into the deployment going out on Tuesday, so happy to put this on the backburner.


This is something the original utility calls out support for, so I don't think it's that outlandish an idea, and I also think we can make it work. I've updated the PR with a simple modification that ensures that we reserve a given name for the first column whose prefix matches it verbatim, to prevent any insolent usurper strings flipping things around rudely.

```clojure
(#'metabase.upload/derive-column-names ::test-driver [""abcd"" ""abcd"" ""ab_2_bc"" ""ab_3_bc""])
;; => (:abcd :ab_4 :ab_2 :ab_3)
```

crisptrutski (Issue Creator) on (2024-06-28 08:19:46 UTC): Update: I see actually MBQL thought about this edge case, and its solution is to resort to hashes for really long names. That's much less likely to result in these ""usurping"" gotchas, and also saves us forking this big method, so going to put up a PR just using that next.

crisptrutski (Issue Creator) on (2024-06-28 08:20:34 UTC): Urgh, meant to close the PR not the issue ðŸ¤¦

luizarakaki on (2024-07-09 13:41:35 UTC): Moving this to P3 while we don't hear about people hitting this.
There is also a workaround (use shorter column headers)

"
2374285567,issue,closed,completed,Cannot append CSV with long column name,"### Describe the bug

Many databases have modest limits in the length of the column names that they support, and they may truncate them silently.

The Upload feature uses the column name as the source of truth, and compares these to the normalized header values from an appended file, which will not have been truncated.

This can cause a mismatch and a false positive on a missing field when comparing the schemas between the table and the new file.

### To Reproduce

1. Enable uploads.
2. Go to collection.
3. Upload a CSV file with a column containing 64 or more characters.
4. Open the model created by (3)
5. Attempt to append the same file to the model.


### Expected behavior

The append should succeed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version: 48+
```


### Severity

P2

### Additional context

_No response_",crisptrutski,2024-06-26 04:56:04+00:00,[],2024-06-26 13:50:17+00:00,2024-06-26 13:00:25+00:00,https://github.com/metabase/metabase/issues/44724,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2190749650, 'issue_id': 2374285567, 'author': 'crisptrutski', 'body': 'It turns out that the existing `table-name-length-limit` multi-method actually refers to identifiers in general, so we can use that to determine the maximum column length. \r\n\r\nOne potential concern, however, is that we will default to no truncation at all. Since very few drivers support CSV uploads right now, this concern is fairly moot for now.', 'created_at': datetime.datetime(2024, 6, 26, 5, 36, 55, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-06-26 05:36:55 UTC): It turns out that the existing `table-name-length-limit` multi-method actually refers to identifiers in general, so we can use that to determine the maximum column length. 

One potential concern, however, is that we will default to no truncation at all. Since very few drivers support CSV uploads right now, this concern is fairly moot for now.

"
2374083310,issue,closed,completed,Coercion strategies don't have human-friendly text in Admin Table Metadata,"On `master` (51.x)

Admin Panel > Table Metadata > (Select any table) > (Click the Gear Icon For any Column)

The list of possible coercion strategies just uses the underlying internal names for the strategies rather than a human friendly description of them.

IIRC these used to have human-friendly names, so I think this is probably a regression.

![image](https://github.com/metabase/metabase/assets/1455846/64ce9558-15c5-4a19-83d8-3124b278915b)
",camsaul,2024-06-26 03:04:54+00:00,['npfitz'],2024-08-12 15:53:41+00:00,2024-08-12 12:26:53+00:00,https://github.com/metabase/metabase/issues/44723,"[('Priority:P2', 'Average run of the mill bug'), ('Administration/Table Metadata', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2261295881, 'issue_id': 2374083310, 'author': 'npfitz', 'body': ""I went back to v45 and this is what we had. Not sure that they're more human readable, but they weren't namespaced ðŸ˜‚ \r\n\r\n![image](https://github.com/user-attachments/assets/eefd2917-f561-4c5e-8432-64987fe4602f)"", 'created_at': datetime.datetime(2024, 7, 31, 19, 39, 25, tzinfo=datetime.timezone.utc)}]","npfitz (Assginee) on (2024-07-31 19:39:25 UTC): I went back to v45 and this is what we had. Not sure that they're more human readable, but they weren't namespaced ðŸ˜‚ 

![image](https://github.com/user-attachments/assets/eefd2917-f561-4c5e-8432-64987fe4602f)

"
2374073703,issue,closed,not_planned,Columns in the order by list must be unique,"### Describe the bug

When using ""Summarize"" and ""Sort"", there is an error that generates a field twice, causing a conflict.
Error: ""A column has been specified more than once in the order by list. Columns in the order by list must be unique.""

![image](https://github.com/metabase/metabase/assets/26163387/aeaee6d0-1cfa-41c3-9b0f-be6210dcbee2)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version: v0.50.7
```


### Severity

For the time being, I need to go back and edit the Questions, removing the Sort section.

### Additional context

_No response_",ansutung,2024-06-26 02:54:28+00:00,['lbrdnk'],2024-08-28 02:08:54+00:00,2024-06-27 19:22:17+00:00,https://github.com/metabase/metabase/issues/44722,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Team/Querying', '')]","[{'comment_id': 2191127124, 'issue_id': 2374073703, 'author': 'lbrdnk', 'body': ""Thanks for the report. This issue is a potential duplicate of https://github.com/metabase/metabase/issues/44653. I'll verify that when I'll be closing the linked issue."", 'created_at': datetime.datetime(2024, 6, 26, 8, 33, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195507324, 'issue_id': 2374073703, 'author': 'lbrdnk', 'body': ""As mentioned before, it seems that scenario here is same as in https://github.com/metabase/metabase/issues/44653, ie. attempt to sort by breakout field of a question that has model as a source. That's been fixed by https://github.com/metabase/metabase/pull/44740 -- closing."", 'created_at': datetime.datetime(2024, 6, 27, 19, 22, 17, tzinfo=datetime.timezone.utc)}]","lbrdnk (Assginee) on (2024-06-26 08:33:14 UTC): Thanks for the report. This issue is a potential duplicate of https://github.com/metabase/metabase/issues/44653. I'll verify that when I'll be closing the linked issue.

lbrdnk (Assginee) on (2024-06-27 19:22:17 UTC): As mentioned before, it seems that scenario here is same as in https://github.com/metabase/metabase/issues/44653, ie. attempt to sort by breakout field of a question that has model as a source. That's been fixed by https://github.com/metabase/metabase/pull/44740 -- closing.

"
2373919234,issue,closed,completed,Unexpected Behavior with Auto Wiring of Filters in v50,"### Describe the bug

When adding cards to existing dashboards in v50 the auto wiring functionality links to incorrect fields.

### To Reproduce

Using the Sample database in v50.7:

1. Create a dashboard using X Ray of Orders
2. Create a new question from the Orders or Products table and add it to the dashboard
3. While in edit mode, select the filters and note that some of the filters auto wire to incorrect fields on the new card


### Expected behavior

Auto wiring should choose the correct fields

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2"",
      ""athena"",
      ""mysql"",
      ""sqlserver"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v1.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying - you have to fix them every time you add a card

### Additional context

https://www.loom.com/share/7173577fb695483d9486d02b0e41d47c",ixipixi,2024-06-26 00:32:28+00:00,['ranquild'],2024-07-19 00:18:54+00:00,2024-07-18 20:00:06+00:00,https://github.com/metabase/metabase/issues/44720,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]",[],
2373618406,issue,open,,[Epic] Support BigInt type,"Bug report: https://github.com/metabase/metabase/issues/5816

Since numbers in JS are in 64-bit floating-point format, BigInt values outside of `[-9007199254740991, 9007199254740991]` have precision issues. We can use native `bigint` type on the FE to support BigInt values.

This is an implementation plan if we go with using `bigint` javascript type.

## Implementation Plan

```[tasklist]
### Support big integers as IDs
- [ ] Correctly serialize requests payloads and deserialize responses with BigInts
- [ ] Support bigints in NumericInput
- [ ] Support BigInts in Clojure metabase-lib (filters construction)
```

```[tasklist]
### Support using big integers as chart values
- [ ] Support BigInts in ECharts: https://github.com/apache/echarts/issues/19237
- [ ] Row chart BigInts support
- [ ] Gauge chart BigInts support
- [ ] Trend chart BigInts support
- [ ] Funnel chart BigInts support
- [ ] Maps BigInts support
```
",alxnddr,2024-06-25 20:38:25+00:00,[],2024-10-03 01:27:53+00:00,,https://github.com/metabase/metabase/issues/44713,"[('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2213661332, 'issue_id': 2373618406, 'author': 'q578135872', 'body': 'strongly support this proposal', 'created_at': datetime.datetime(2024, 7, 8, 10, 43, 4, tzinfo=datetime.timezone.utc)}]","q578135872 on (2024-07-08 10:43:04 UTC): strongly support this proposal

"
2373430351,issue,closed,completed,Make sure the trash collection doesn't appear in the recents API,"The Trash collection is appearing in the list of Recent items that you may want to move an item to.

This should not happen, because you can't move something to the Trash directly. You can only mark it as Archived.
",johnswanson,2024-06-25 19:02:02+00:00,['johnswanson'],2024-10-08 17:05:29+00:00,2024-07-02 16:37:18+00:00,https://github.com/metabase/metabase/issues/44708,[],[],
2373303630,issue,open,,Custom filter dropdown values: can't get field values from question with custom column,"### Describe the bug

Trying to set a custom column as the source of dropdown field values causes error

### To Reproduce

1. Create a question with a custom column
2. Create a dashboard, add dashboard filter
3. Dropdown values > Edit > Select question created in step 1 > select the custom column
4. See error
![image](https://github.com/metabase/metabase/assets/32561114/adf8a4f1-4c26-4413-bb36-abbb2a32b760)


### Expected behavior

It should list the values of that column

### Logs

[a046c564-d0f0-42c7-9e10-c2498a1305c8] 2024-06-25T14:47:42-03:00 ERROR metabase.server.middleware.log POST /api/dataset/parameter/values 500 44.3 ms (7 DB calls) {:metabase-user-id 111} 
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message
   ""Error compiling query: Cannot determine the source table or query for Field clause [:field \""Domain\"" {:base-type :type/Text}]"",
   :data
   {:query
    {:database 1,
     :middleware {:disable-remaps? true},
     :type :query,
     :query
     {:source-table 4,
      :fields
      [[:field 30 {:base-type :type/BigInteger}]
       [:field 34 {:base-type :type/Text}]
       [:expression ""Domain"" {:base-type :type/Text}]],
      :expressions
      {""Domain""
       [:regex-match-first
        [:field 34 {:base-type :type/Text}]
        ""(?<=@|//|\\.|^)(?!www\\.)[^@\\.:/?#]+(?=\\.[^@\\.:/?#]{1,3}\\.[^@\\.:/?#]+(?:[:/?#].*)?$|\\.[^@\\.:/?#]+(?:[:/?#].*)?$)""]},
      :breakout [[:field ""Domain"" {:base-type :type/Text}]],
      :limit 1000,
      :filter
      [:and
       [:!= [:field ""Domain"" {:base-type :type/Text}] [:value nil {:base_type :type/Text}]]
       [:!= [:field ""Domain"" {:base-type :type/Text}] [:value """" {:base_type :type/Text}]]],
      :order-by [[:asc [:field ""Domain"" {:base-type :type/Text}]]]}},
    :type :driver},
   :at [metabase.query_processor.compile$compile_preprocessed$fn__66328 invoke ""compile.clj"" 25]}
  {:type clojure.lang.ExceptionInfo,
   :message ""Cannot determine the source table or query for Field clause [:field \""Domain\"" {:base-type :type/Text}]"",
   :data
   {:type :invalid-query,
    :clause [:field ""Domain"" {:base-type :type/Text}],
    :query
    {:source-table 4,
     :fields
     [[:field 30 {:base-type :type/BigInteger}]
      [:field 34 {:base-type :type/Text}]
      [:expression ""Domain"" {:base-type :type/Text}]],
     :expressions
     {""Domain""
      [:regex-match-first
       [:field 34 {:base-type :type/Text}]
       ""(?<=@|//|\\.|^)(?!www\\.)[^@\\.:/?#]+(?=\\.[^@\\.:/?#]{1,3}\\.[^@\\.:/?#]+(?:[:/?#].*)?$|\\.[^@\\.:/?#]+(?:[:/?#].*)?$)""]},
     :breakout [[:field ""Domain"" {:base-type :type/Text}]],
     :limit 1000,
     :filter
     [:and
      [:!= [:field ""Domain"" {:base-type :type/Text}] [:value nil {:base_type :type/Text}]]
      [:!= [:field ""Domain"" {:base-type :type/Text}] [:value """" {:base_type :type/Text}]]],
     :order-by [[:asc [:field ""Domain"" {:base-type :type/Text}]]]}},
   :at [metabase.query_processor.util.add_alias_info$field_source_table_alias invokeStatic ""add_alias_info.clj"" 192]}],
 :trace
 [[metabase.query_processor.util.add_alias_info$field_source_table_alias invokeStatic ""add_alias_info.clj"" 192]
  [metabase.query_processor.util.add_alias_info$field_source_table_alias invoke ""add_alias_info.clj"" 179]
  [metabase.query_processor.util.add_alias_info$fn__61542 invokeStatic ""add_alias_info.clj"" 403]
  [metabase.query_processor.util.add_alias_info$fn__61542 invoke ""add_alias_info.clj"" 400]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 239]
  [metabase.query_processor.util.add_alias_info$add_alias_info_STAR_$replace_61618__61619$fn__61626$fn__61627
   invoke
   ""add_alias_info.clj""
   490]
  [metabase.query_processor.util.add_alias_info$add_alias_info_STAR_$replace_61618__61619$fn__61626
   invoke
   ""add_alias_info.clj""
   490]
  [metabase.query_processor.util.add_alias_info$add_alias_info_STAR_$replace_61618__61619
   invoke
   ""add_alias_info.clj""
   490]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2641]
  [clojure.core$mapv$fn__8535 invoke ""core.clj"" 6980]
  [clojure.lang.PersistentVector reduce ""PersistentVector.java"" 343]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$mapv invokeStatic ""core.clj"" 6971]
  [clojure.core$mapv invoke ""core.clj"" 6971]

### Information about your Metabase installation

```JSON
In Stats: https://stats.metabase.com/dashboard/2494-test-field-filters-with-sandboxing
```


### Severity

P2

### Additional context

_No response_",luizarakaki,2024-06-25 17:56:38+00:00,[],2025-02-04 20:29:07+00:00,,https://github.com/metabase/metabase/issues/44703,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2323104867, 'issue_id': 2373303630, 'author': 'paoliniluis', 'body': ""Tagging as a regression. This was my workaround for getting field values from custom columns (as we don't get those on get-field-values)"", 'created_at': datetime.datetime(2024, 9, 1, 1, 29, 17, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-01 01:29:17 UTC): Tagging as a regression. This was my workaround for getting field values from custom columns (as we don't get those on get-field-values)

"
2373303568,issue,closed,completed,Filters on static embedding are not respecting the filter dropdown type and defaulting to an input box when filters are connected to models,"### Describe the bug

A filter that's configured as a dropdown list of ""a list of all values"" is setting itself up as an input box on static embedding. This is a ux regression as the users don't know what's the value to input beforehand. This is only when a filter is connected to a model

### To Reproduce

1) set zip as ""a list of all values"" in the table metadata
2) build a GUI model (orders + people)
3) add the model to a dashboard
4) connect 2 filters: source and zip. Check that zip displays a list
![image](https://github.com/metabase/metabase/assets/1711649/cad9735c-6c27-41b3-b0b8-06190727fe41)

5) embed it passing the source as a parameter
6) see that zip doesn't display a list
![image](https://github.com/metabase/metabase/assets/1711649/02d774ac-38c8-44cd-9b6d-e41a77616bc3)


### Expected behavior

It shoul display the list on the embedded context

### Logs

NA, it does not even fire an api call

### Information about your Metabase installation

```JSON
v50.x
```


### Severity

P1 - regression - escalation as it's hitting a pro customer

### Additional context

If you don't use models this works
![image](https://github.com/metabase/metabase/assets/1711649/edb4b4bd-d009-408f-9eb4-02e097709f92)
",paoliniluis,2024-06-25 17:56:36+00:00,['ranquild'],2024-06-25 18:30:00+00:00,2024-06-25 18:29:53+00:00,https://github.com/metabase/metabase/issues/44702,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 2189631026, 'issue_id': 2373303568, 'author': 'calherries', 'body': 'Looks like a duplicate of https://github.com/metabase/metabase/issues/44565. @ranquild since this was escalated and I probably misattributed it to the embedding team, perhaps you can close it as a dupe?', 'created_at': datetime.datetime(2024, 6, 25, 18, 0, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189690843, 'issue_id': 2373303568, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/44440', 'created_at': datetime.datetime(2024, 6, 25, 18, 29, 54, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-25 18:00:52 UTC): Looks like a duplicate of https://github.com/metabase/metabase/issues/44565. @ranquild since this was escalated and I probably misattributed it to the embedding team, perhaps you can close it as a dupe?

ranquild (Assginee) on (2024-06-25 18:29:54 UTC): Closed by https://github.com/metabase/metabase/pull/44440

"
2373193587,issue,open,,Field with many null values will wrongly be identified as a string in Mongo,"### Describe the bug

We have a customer that has many documents without a field value, and only a few with dates. We wrongly identify those fields as dates. As ~fingerprinting~ sync overrides (https://github.com/metabase/metabase/issues/18074) what the user tries to manually fix on each sync, then they can't provide self service analytics to their customers on some reports as we offer fields as text instead of dates

### To Reproduce

1) create a mongo collection that has a single date value and all other documents don't have values on the same key
2) sync it
3) see the field incorrectly identifying as string

### Expected behavior

We should allow users to manually specify the base type if needed

### Logs

NA

### Information about your Metabase installation

```JSON
It has been like that since forever
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-06-25 17:07:30+00:00,[],2025-02-04 20:25:08+00:00,,https://github.com/metabase/metabase/issues/44698,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Product Input Needed', ''), ('.Team/Drivers', '')]","[{'comment_id': 2189643259, 'issue_id': 2373193587, 'author': 'calherries', 'body': '@paoliniluis do you mean specify the semantic type? The base type is never updated from fingerprinting, only the semantic type is.', 'created_at': datetime.datetime(2024, 6, 25, 18, 6, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189680612, 'issue_id': 2373193587, 'author': 'paoliniluis', 'body': ""my bad, it's the sync process replacing the field type"", 'created_at': datetime.datetime(2024, 6, 25, 18, 24, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190216335, 'issue_id': 2373193587, 'author': 'calherries', 'body': 'I\'m not sure how the base type could be inferred as `type/Text`, but I can reproduce a similar problem where the base type will be set as `type/*`. \r\n\r\nHere\'s a script to create a test collection where `dateField` will have `:base-type = :type/*`:\r\n```\r\n// Create a new collection\r\ndb.createCollection(""testCollection"")\r\n// Insert 1000 documents without dateField\r\nfor (let i = 0; i < 1000; i++) {\r\n  db.testCollection.insertOne({ ""otherField"": ""value"" + i, ""dateField"": null })\r\n}\r\n// Insert 1 document with dateField\r\ndb.testCollection.insertOne({ ""dateField"": new Date(), ""otherField"": ""value with date"" })\r\n// Insert another 1000 documents without dateField\r\nfor (let i = 1000; i < 2000; i++) {\r\n  db.testCollection.insertOne({ ""otherField"": ""value"" + i, ""dateField"": null })\r\n}\r\n```\r\n\r\nTo calculate the `base-type`, we look at the first 500 and last 500 documents inserted into the collection. One idea would be to increase the sample size from 1000 to a much larger number if there are any fields with only null values.', 'created_at': datetime.datetime(2024, 6, 25, 23, 48, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190423619, 'issue_id': 2373193587, 'author': 'calherries', 'body': '[Slack discussion](https://metaboat.slack.com/archives/C0641E4PB9B/p1719336193648249)', 'created_at': datetime.datetime(2024, 6, 26, 2, 31, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192618132, 'issue_id': 2373193587, 'author': 'calherries', 'body': ""@paoliniluis do you know how to reproduce this issue exactly? I'm getting `type/*` using the steps above, not `type/Text`, so I'm worried there is something else going wrong with inferring the base type. If the customer is getting `type/Text`, that implies that there is a string value in the data, or something that we don't detect as a datetime type. Can you confirm what type the dates values are? Are they [BSON Date objects](https://www.mongodb.com/docs/manual/reference/bson-types/#date), and definitely not strings?"", 'created_at': datetime.datetime(2024, 6, 26, 20, 59, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200204003, 'issue_id': 2373193587, 'author': 'paoliniluis', 'body': '@calherries here are the exact reproduction steps:\r\n1) set up a MongoDB server (e.g. v7) and Metabase\r\n2) run the following code to insert documents to your MongoDB db:\r\n```\r\nconst { MongoClient, ServerApiVersion } = require(""mongodb"");\r\n\r\nconst uri = ""mongodb://metabase:metasample123@localhost:27021/admin"";\r\n\r\nconst client = new MongoClient(uri);\r\n\r\nasync function run() {\r\n  try {\r\n    // Connect the client to the server (optional starting in v4.7)\r\n    await client.connect();\r\n    // loop a million times and create documents in the sample.people collection\r\n    for (let i = 0; i < 1000000; i++) {\r\n      await client.db(""sample"").collection(""whatever"").insertOne({\r\n        ""id"": i + 1,\r\n        // generate a random address key\r\n        ""address"": ""address"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random email address key\r\n        ""email"": ""email"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random password key\r\n        ""password"": ""password"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random name key\r\n        ""name"": ""name"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random phone city key\r\n        ""phone"": ""phone"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random city key\r\n        ""city"": ""city"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random longitude\r\n        ""longitude"": Math.floor(Math.random() * 1000000),\r\n        // generate a random US state\r\n        ""state"": ""state"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random latitude\r\n        ""latitude"": Math.floor(Math.random() * 1000000),\r\n        // generate a random source\r\n        ""source"": ""source"" + Math.floor(Math.random() * 1000000),\r\n        // generate a random birth date\r\n        ""birth_date"": new Date(),\r\n        // generate a random zip code\r\n        ""zip"": Math.floor(Math.random() * 1000000),\r\n        // generate a random created at date\r\n        // ""created_at"": new Date().toISOString().split(\'T\')[0],\r\n      });\r\n      console.log(""Inserted "" + i + "" documents into the \'whatever\' collection."");\r\n    }\r\n  } finally {\r\n    // Ensures that the client will close when you finish/error\r\n    await client.close();\r\n  }\r\n}\r\nrun().catch(console.dir);\r\n```\r\n\r\n(let it run for a few thousand records)\r\n\r\n2) then uncomment the line for the created_at key, run it again\r\n3) force a sync\r\n\r\nyou\'ll get \r\n![image](https://github.com/metabase/metabase/assets/1711649/c718c44d-02b2-49cd-94ac-943862387130)', 'created_at': datetime.datetime(2024, 7, 1, 13, 45, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245935045, 'issue_id': 2373193587, 'author': 'calherries', 'body': '@paoliniluis I can reproduce using your script but since you\'re using `new Date().toISOString().split(\'T\')[0]` the base type will be `type/Text` regardless of the number of null values. Here\'s a minimal reproduction using `mongosh`:\r\n```\r\ndb.createCollection(""test"")\r\ndb.test.insertOne({ ""created_at"": new Date().toISOString().split(\'T\')[0] })\r\n```\r\nSo the issue is not that the `base_type` is being inferred incorrectly, because the correct base type is `type/Text`, the problem is that we don\'t infer that this column is a date string and set an appropriate coercion automatically.\r\n\r\nThe available workaround is to set the field setting ""Cast to a specific data type"" to ""Coercion/ISO8601->DateTime"", like so:\r\n![image](https://github.com/user-attachments/assets/81f5a9b1-69e9-4bcf-bc00-0f70a5d78f37)\r\n\r\nIn that case you can query the field as if it were a [BSON Date](https://www.mongodb.com/docs/manual/reference/bson-types/#date) type.', 'created_at': datetime.datetime(2024, 7, 23, 18, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2246710099, 'issue_id': 2373193587, 'author': 'paoliniluis', 'body': ""@calherries but Mongo has no types, so at some point in the process we're setting that field as a text"", 'created_at': datetime.datetime(2024, 7, 24, 1, 53, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248841541, 'issue_id': 2373193587, 'author': 'calherries', 'body': '@paoliniluis Mongo has a [Date type](https://www.mongodb.com/docs/manual/reference/bson-types/#date) and we\'re using that type to infer the base type during sync. We\'re not doing any parsing of string values to detect whether something looks like a date or not.\r\n\r\nSo I see two issues here:\r\n1. If there are many `null` values, we can incorrectly infer the base-type as `type/*`, meaning ""we don\'t know what the type is"". There\'s no workaround for this because there\'s no way to change the base type from the API and it will be overridden by sync anyway.\r\n2. If there are text values that represent dates in MongoDB, we don\'t automatically detect the value should be coerced to a date in queries. This has a workaround: set this manually using the ""Cast to a specific data type"" field setting.', 'created_at': datetime.datetime(2024, 7, 24, 20, 27, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2255411298, 'issue_id': 2373193587, 'author': 'calherries', 'body': '@paoliniluis can you confirm whether the customer can solve their issue by setting ""Cast to a specific data type"" to `Coercion/ISO8601->DateTime` as in the screenshot above?', 'created_at': datetime.datetime(2024, 7, 29, 9, 13, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2338464890, 'issue_id': 2373193587, 'author': 'snoe', 'body': '@paoliniluis has not had an answer from the customer, but based on @calherries comments, it seems the workaround for text typed coercion should be possible.\r\nMarked as P2 to handle the possibility of sync overriding with `type/*` if it sees too many nulls', 'created_at': datetime.datetime(2024, 9, 9, 15, 43, 16, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-25 18:06:16 UTC): @paoliniluis do you mean specify the semantic type? The base type is never updated from fingerprinting, only the semantic type is.

paoliniluis (Issue Creator) on (2024-06-25 18:24:11 UTC): my bad, it's the sync process replacing the field type

calherries on (2024-06-25 23:48:16 UTC): I'm not sure how the base type could be inferred as `type/Text`, but I can reproduce a similar problem where the base type will be set as `type/*`. 

Here's a script to create a test collection where `dateField` will have `:base-type = :type/*`:
```
// Create a new collection
db.createCollection(""testCollection"")
// Insert 1000 documents without dateField
for (let i = 0; i < 1000; i++) {
  db.testCollection.insertOne({ ""otherField"": ""value"" + i, ""dateField"": null })
}
// Insert 1 document with dateField
db.testCollection.insertOne({ ""dateField"": new Date(), ""otherField"": ""value with date"" })
// Insert another 1000 documents without dateField
for (let i = 1000; i < 2000; i++) {
  db.testCollection.insertOne({ ""otherField"": ""value"" + i, ""dateField"": null })
}
```

To calculate the `base-type`, we look at the first 500 and last 500 documents inserted into the collection. One idea would be to increase the sample size from 1000 to a much larger number if there are any fields with only null values.

calherries on (2024-06-26 02:31:48 UTC): [Slack discussion](https://metaboat.slack.com/archives/C0641E4PB9B/p1719336193648249)

calherries on (2024-06-26 20:59:42 UTC): @paoliniluis do you know how to reproduce this issue exactly? I'm getting `type/*` using the steps above, not `type/Text`, so I'm worried there is something else going wrong with inferring the base type. If the customer is getting `type/Text`, that implies that there is a string value in the data, or something that we don't detect as a datetime type. Can you confirm what type the dates values are? Are they [BSON Date objects](https://www.mongodb.com/docs/manual/reference/bson-types/#date), and definitely not strings?

paoliniluis (Issue Creator) on (2024-07-01 13:45:40 UTC): @calherries here are the exact reproduction steps:
1) set up a MongoDB server (e.g. v7) and Metabase
2) run the following code to insert documents to your MongoDB db:
```
const { MongoClient, ServerApiVersion } = require(""mongodb"");

const uri = ""mongodb://metabase:metasample123@localhost:27021/admin"";

const client = new MongoClient(uri);

async function run() {
  try {
    // Connect the client to the server (optional starting in v4.7)
    await client.connect();
    // loop a million times and create documents in the sample.people collection
    for (let i = 0; i < 1000000; i++) {
      await client.db(""sample"").collection(""whatever"").insertOne({
        ""id"": i + 1,
        // generate a random address key
        ""address"": ""address"" + Math.floor(Math.random() * 1000000),
        // generate a random email address key
        ""email"": ""email"" + Math.floor(Math.random() * 1000000),
        // generate a random password key
        ""password"": ""password"" + Math.floor(Math.random() * 1000000),
        // generate a random name key
        ""name"": ""name"" + Math.floor(Math.random() * 1000000),
        // generate a random phone city key
        ""phone"": ""phone"" + Math.floor(Math.random() * 1000000),
        // generate a random city key
        ""city"": ""city"" + Math.floor(Math.random() * 1000000),
        // generate a random longitude
        ""longitude"": Math.floor(Math.random() * 1000000),
        // generate a random US state
        ""state"": ""state"" + Math.floor(Math.random() * 1000000),
        // generate a random latitude
        ""latitude"": Math.floor(Math.random() * 1000000),
        // generate a random source
        ""source"": ""source"" + Math.floor(Math.random() * 1000000),
        // generate a random birth date
        ""birth_date"": new Date(),
        // generate a random zip code
        ""zip"": Math.floor(Math.random() * 1000000),
        // generate a random created at date
        // ""created_at"": new Date().toISOString().split('T')[0],
      });
      console.log(""Inserted "" + i + "" documents into the 'whatever' collection."");
    }
  } finally {
    // Ensures that the client will close when you finish/error
    await client.close();
  }
}
run().catch(console.dir);
```

(let it run for a few thousand records)

2) then uncomment the line for the created_at key, run it again
3) force a sync

you'll get 
![image](https://github.com/metabase/metabase/assets/1711649/c718c44d-02b2-49cd-94ac-943862387130)

calherries on (2024-07-23 18:14:06 UTC): @paoliniluis I can reproduce using your script but since you're using `new Date().toISOString().split('T')[0]` the base type will be `type/Text` regardless of the number of null values. Here's a minimal reproduction using `mongosh`:
```
db.createCollection(""test"")
db.test.insertOne({ ""created_at"": new Date().toISOString().split('T')[0] })
```
So the issue is not that the `base_type` is being inferred incorrectly, because the correct base type is `type/Text`, the problem is that we don't infer that this column is a date string and set an appropriate coercion automatically.

The available workaround is to set the field setting ""Cast to a specific data type"" to ""Coercion/ISO8601->DateTime"", like so:
![image](https://github.com/user-attachments/assets/81f5a9b1-69e9-4bcf-bc00-0f70a5d78f37)

In that case you can query the field as if it were a [BSON Date](https://www.mongodb.com/docs/manual/reference/bson-types/#date) type.

paoliniluis (Issue Creator) on (2024-07-24 01:53:03 UTC): @calherries but Mongo has no types, so at some point in the process we're setting that field as a text

calherries on (2024-07-24 20:27:09 UTC): @paoliniluis Mongo has a [Date type](https://www.mongodb.com/docs/manual/reference/bson-types/#date) and we're using that type to infer the base type during sync. We're not doing any parsing of string values to detect whether something looks like a date or not.

So I see two issues here:
1. If there are many `null` values, we can incorrectly infer the base-type as `type/*`, meaning ""we don't know what the type is"". There's no workaround for this because there's no way to change the base type from the API and it will be overridden by sync anyway.
2. If there are text values that represent dates in MongoDB, we don't automatically detect the value should be coerced to a date in queries. This has a workaround: set this manually using the ""Cast to a specific data type"" field setting.

calherries on (2024-07-29 09:13:33 UTC): @paoliniluis can you confirm whether the customer can solve their issue by setting ""Cast to a specific data type"" to `Coercion/ISO8601->DateTime` as in the screenshot above?

snoe on (2024-09-09 15:43:16 UTC): @paoliniluis has not had an answer from the customer, but based on @calherries comments, it seems the workaround for text typed coercion should be possible.
Marked as P2 to handle the possibility of sync overriding with `type/*` if it sees too many nulls

"
2372844520,issue,closed,completed,Visual indicator that a download is happening,"**Is your feature request related to a problem? Please describe.**
The visual indicators in the browser are not enough when a download is happening. This is specially important on big downloads e.g. a million rows on tables of 100 columns which take a long itme

**Describe the solution you'd like**
A visual indicator on Metabase that we're still streaming the file, so the user doesn't close the tab

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer that allows users to download very big tables

**Additional context**
Check ticket 28269
",paoliniluis,2024-06-25 14:24:37+00:00,[],2024-07-31 00:14:13+00:00,2024-07-30 00:01:50+00:00,https://github.com/metabase/metabase/issues/44686,"[('Type:New Feature', ''), ('.Needs Triage', '')]",[],
2372828332,issue,closed,not_planned,"[BE] When there are multiple temporal-unit parameters mapped to the same column, the value of the last parameter should take priority",Please fix these lines in the corresponding e2e test when the issue is fixed https://github.com/metabase/metabase/blob/70b606b8f2e380bf8731fd06e3a1089c9394ecb8/e2e/test/scenarios/dashboard-filters/temporal-unit-parameters.cy.spec.js#L415,ranquild,2024-06-25 14:18:36+00:00,[],2024-07-29 11:00:37+00:00,2024-07-29 11:00:37+00:00,https://github.com/metabase/metabase/issues/44684,[],[],
2372515920,issue,open,,Sidebar item outline has different shape than the item,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/533a341e-5b2d-4862-8b4a-afbc61c86d3a)


### To Reproduce

1. Open the sidebar
2. Click any item in the sidebar (e.g. a collection)
3. Hit F12 to open developer tools in your browser
4. Hit F12 to close developer tools

_I experienced the issue in many ways, but this one is the only one I found that reproduces it every time._

### Expected behavior

Items should either have no outline, or the outline should match the shape of the element


### Information about your Metabase installation

master, f43a15076d


### Severity

P3
",kamilmielnik,2024-06-25 12:02:58+00:00,[],2025-02-04 20:26:39+00:00,,https://github.com/metabase/metabase/issues/44674,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Design System', 'Overall UI patterns and components, not specific to a single part of the product')]",[],
2372481273,issue,closed,completed,Regression: y-axis minimum is ignored for stacked histograms,"### Describe the bug

A regression was introduced in the last few versions of Metabase.
For stacked histgrams the y-axis **minimum** value is now ignored. It used to work.
It still works for other types of visualization, including non-stacked histograms.
Also, the maximum value of y-axis still works.

### To Reproduce

1. Create a new SQL question with the code below:
```sql
select 10 as y, 'xx' as x, 'a' as split
union all 
select 15, 'xx', 'b';
```
2. Click on Run, set the vizualization to ""Histogram""
3. Configure the series as below

![image](https://github.com/metabase/metabase/assets/242172/507fffe4-c26b-49a5-b3a8-7f20a20974f3)

4. Now go to the ""Axis"" tab, uncheck the automatic Y-axis scaling. Set a Minimum of 5, a maximum of 20. This will work OK.

![image](https://github.com/metabase/metabase/assets/242172/00a5ffe2-cf21-4cae-a47b-a5d206611bd1)

5. Don't change anything then go to the ""Display"" tab and select the middle stacking option (""Empiler (Diagramme Ã  bandes en effectifs)"" in this screenshot).
What should happen : the Y-axis should start at 5, NOT 0.

![image](https://github.com/metabase/metabase/assets/242172/176d9aa1-5269-4e58-a575-e8e402aeb164)


### Expected behavior

The Y-axis MINIMUM configuration of the Histogram should work with all three stacking settings. Currently it only works with the first (don't stack). It used to work in all three.

Note that there is no problem with the MAXIMUM setting.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:126.0) Gecko/20100101 Firefox/126.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

low
",Caerbannog,2024-06-25 11:44:59+00:00,['alxnddr'],2024-07-15 14:04:03+00:00,2024-07-09 20:51:17+00:00,https://github.com/metabase/metabase/issues/44672,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2228586365, 'issue_id': 2372481273, 'author': 'Caerbannog', 'body': 'Part of the problem persists.\r\n\r\nI have tested Metabase v0.50.12.\r\nThe fix works for stacked histograms.\r\nThe fix does **NOT** work for ""stacked - 100%"" histograms.\r\n\r\n\r\n### To Reproduce (steps 1-3 are the same as before)\r\n\r\n1. Create a new SQL question with the code below:\r\n```sql\r\nselect 10 as y, \'xx\' as x, \'a\' as split\r\nunion all \r\nselect 15, \'xx\', \'b\';\r\n```\r\n2. Click on Run, set the vizualization to ""Histogram""\r\n3. Configure the series as below\r\n\r\n![image](https://github.com/metabase/metabase/assets/242172/507fffe4-c26b-49a5-b3a8-7f20a20974f3)\r\n\r\n4. Now go to the ""Axis"" tab, uncheck the automatic Y-axis scaling. Set a Minimum of **0.5,** a maximum of **1.5**.\r\n\r\n5. Go to the ""Display"" tab and select the last stacking option (""Empiler - 100 % (Diagramme Ã  bandes en frÃ©quence)"" in this screenshot).\r\nWhat should happen : the Y-axis should start at 50%, NOT 0%. This used to work.\r\n\r\n![image](https://github.com/user-attachments/assets/3326d663-b144-4bb9-a214-69301a573ede)', 'created_at': datetime.datetime(2024, 7, 15, 14, 4, 2, tzinfo=datetime.timezone.utc)}]","Caerbannog (Issue Creator) on (2024-07-15 14:04:02 UTC): Part of the problem persists.

I have tested Metabase v0.50.12.
The fix works for stacked histograms.
The fix does **NOT** work for ""stacked - 100%"" histograms.


### To Reproduce (steps 1-3 are the same as before)

1. Create a new SQL question with the code below:
```sql
select 10 as y, 'xx' as x, 'a' as split
union all 
select 15, 'xx', 'b';
```
2. Click on Run, set the vizualization to ""Histogram""
3. Configure the series as below

![image](https://github.com/metabase/metabase/assets/242172/507fffe4-c26b-49a5-b3a8-7f20a20974f3)

4. Now go to the ""Axis"" tab, uncheck the automatic Y-axis scaling. Set a Minimum of **0.5,** a maximum of **1.5**.

5. Go to the ""Display"" tab and select the last stacking option (""Empiler - 100 % (Diagramme Ã  bandes en frÃ©quence)"" in this screenshot).
What should happen : the Y-axis should start at 50%, NOT 0%. This used to work.

![image](https://github.com/user-attachments/assets/3326d663-b144-4bb9-a214-69301a573ede)

"
2372263589,issue,closed,completed,Support multiple instances of interactive questions in embedding SDK,"Currently, we can only have a single instance of an interactive question when using the embedding sdk, as they are sharing the same Redux state. We want to provide an ability to embed multiple independent interactive questions, with the ability to independently configure each of them.

As the query builder is very complex, let's try a proof-of-concept to see if refactoring the store to support multiple entities is possible. If not, we abandon this approach and explore other solutions (e.g. separate Redux providers per interactive questions?)",heypoom,2024-06-25 10:08:06+00:00,['heypoom'],2024-10-08 17:04:37+00:00,2024-07-11 17:23:30+00:00,https://github.com/metabase/metabase/issues/44670,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2372124757,issue,closed,completed,Visualization error with a custom column,"### Describe the bug

Adding a custom column breaks visualization

<img width=""1272"" alt=""Screenshot 2024-06-25 at 5 04 50â€¯AM"" src=""https://github.com/metabase/metabase/assets/127636/2ff9d32c-d33a-49e3-8b9e-612a5bdde793"">
<img width=""1983"" alt=""Screenshot 2024-06-25 at 5 05 21â€¯AM"" src=""https://github.com/metabase/metabase/assets/127636/5aec083c-b8f1-4119-bb5c-c381c32a731a"">


### To Reproduce

1. Start with https://stats.metabase.com/question/18346-top-5-states
2. Add a custom column `concat([Count],"""")` and call it `Count 2`
3. Sort by `Count 2` asc
4. Click on Visualize

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
stats
```


### Severity

P1

### Additional context

_No response_",perivamsi,2024-06-25 09:06:21+00:00,['kulyk'],2024-06-27 10:20:07+00:00,2024-06-27 10:19:57+00:00,https://github.com/metabase/metabase/issues/44668,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Chart Settings', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2188961134, 'issue_id': 2372124757, 'author': 'ccalby', 'body': 'Related to #44584 ?', 'created_at': datetime.datetime(2024, 6, 25, 13, 23, 50, tzinfo=datetime.timezone.utc)}]","ccalby on (2024-06-25 13:23:50 UTC): Related to #44584 ?

"
2372102960,issue,closed,completed,Multiple values can be used as a default value for single-value dashboard filters,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/55bfcadf-b5a2-4555-bd45-1cacb1aeece7



### To Reproduce

1. Create a dashboard and edit it
2. Add a ""Text or Category"" filter
3. Verify that it's configured to use ""Multiple values""
4. Set 2 or more values as the default value
5. Change the type to ""A single value""

Multiple values are still selected as the default value

### Expected behavior

It's not possible to have a single-value filter with multiple values applied


### Information about your Metabase installation

master, 70eea1167b


### Severity

P2
",kamilmielnik,2024-06-25 08:56:07+00:00,['ranquild'],2024-06-27 15:39:40+00:00,2024-06-27 12:20:38+00:00,https://github.com/metabase/metabase/issues/44666,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2372087131,issue,closed,completed,"""Dropdown list"" input used for default filter widget value when ""Search box"" is chosen","### Describe the bug

https://github.com/metabase/metabase/assets/6830683/9e4e740a-9f8b-46b9-97af-5571ebe8499c



### To Reproduce

1. Start a new native question
2. Type `select {{param}}`
3. In the parameter sidebar choose ""Dropdown list"", then ""Edit""
4. Provide few values for the ""Custom list"" and hit ""Done""
5. Verify that dropdown component is used for both parameter value input (above query editor) and ""Default filter widget value"" (in the parameter sidebar)
6. Change ""Dropdown list"" to ""Search box""

Search box is correctly used for parameter value input (above query editor) but dropdown component is used for ""Default filter widget value"" (sidebar).

### Expected behavior

The same component is used for default value input as for parameter value input


### Information about your Metabase installation

master, 70eea1167b


### Severity

P2
",kamilmielnik,2024-06-25 08:49:16+00:00,['romeovs'],2024-11-26 18:51:30+00:00,2024-11-12 11:37:33+00:00,https://github.com/metabase/metabase/issues/44665,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2372043069,issue,closed,not_planned,Get empty page when running in local,"### Describe the bug

Follow the installation guide.
```
yarn install
yarn dev
```
but got an empty page, the log in terminal shows server is runed
<img width=""1723"" alt=""image"" src=""https://github.com/metabase/metabase/assets/5860999/02a63926-6659-4590-9531-9ce75ad35c8e"">
Error msg in console 
```
{
    ""name"": ""n"",
    ""httpError"": false,
    ""httpStatus"": 0,
    ""httpStatusText"": ""TypeError: Failed to fetch"",
    ""code"": 0,
    ""message"": ""network error(Failed to fetch)"",
    ""data"": null,
    ""originalError"": {
        ""name"": ""TypeError"",
        ""message"": ""Failed to fetch"",
        ""stack"": ""TypeError: Failed to fetch\n    at $S.request (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:464:9174)\n    at pa.handleSendRequest (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:464:22390)\n    at pa.sendRequest (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:464:21974)\n    at pa.staticConfig (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:464:85874)\n    at chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:657:18533\n    at s (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:542:20936)\n    at Nb._fetchWithCache (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:542:21069)\n    at Nb.getStaticConfig (chrome-extension://ofpnmcalabcbjgholdjcjblkibolbppb/background.js:657:18469)""
    },
    ""handled"": false,
    ""reqInfo"": {
        ""id"": 2,
        ""pathPrefix"": ""/user"",
        ""method"": ""GET"",
        ""path"": ""/static_config"",
        ""cmd"": null,
        ""otherParams"": [],
        ""isLowLevelResp"": false,
        ""config"": {},
        ""cacheKey"": null
    }
}
```

err in terminal
```
ERROR middleware.log :: GET /api/health 503 215.5 Âµs (0 DB calls) {:metabase-user-id nil} 
[backend] {:status ""initializing"", :progress 0.95}
[backend] 
[backend] 2024-06-25 16:40:24,627 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_MMDC02FP00BMD6V1719304824269 paused.
[backend] 2024-06-25 16:40:24,628 INFO metabase.task :: Task sched
```
Do I need to do more to run it in locally?

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

got a normal page 

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome: Version 126.0.6478.116 (Official Build) (x86_64)
- OS: MACOS 14.5
- Metabase version: latest code from master
```


### Severity

0

### Additional context

_No response_",alanlong9278,2024-06-25 08:28:58+00:00,[],2024-07-01 12:55:09+00:00,2024-06-26 01:45:12+00:00,https://github.com/metabase/metabase/issues/44664,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2189425737, 'issue_id': 2372043069, 'author': 'calherries', 'body': '@alanlong9278 The error in the console mentions a chrome extension. Does the same error happen in incognito mode?', 'created_at': datetime.datetime(2024, 6, 25, 16, 36, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190374985, 'issue_id': 2372043069, 'author': 'alanlong9278', 'body': '> @alanlong9278 The error in the console mentions a chrome extension. Does the same error happen in incognito mode?\r\n\r\nFixed, thanks', 'created_at': datetime.datetime(2024, 6, 26, 1, 44, 55, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-25 16:36:58 UTC): @alanlong9278 The error in the console mentions a chrome extension. Does the same error happen in incognito mode?

alanlong9278 (Issue Creator) on (2024-06-26 01:44:55 UTC): Fixed, thanks

"
2371848076,issue,open,,Rework cross-version tests to use release branch tests,"It's pretty confusing to have tests on a branch that don't actually test the code on that branch. Instead of the current approach for cross version testing, instead, we should commit cross-version tests to relevant release branches.

Each test should have two parts that can and should be run either together or independently.
- Source (e.g. `@cross-version-setup`)
- Target (e.g. `@cross-version-target`)

Such that you should be able to run the source part of a test on any branch, and then run the target version on any other branch. You can also run them together on the same branch for ease of development. For example:
- Source: create a question with complex viz settings
- Target: open a question and change the viz settings

",iethree,2024-06-25 06:58:06+00:00,[],2025-01-17 20:29:46+00:00,,https://github.com/metabase/metabase/issues/44662,[],[],
2371847950,issue,closed,completed,Fix Cross-version tests,,iethree,2024-06-25 06:58:02+00:00,['iethree'],2024-10-08 17:04:46+00:00,2024-07-10 11:57:36+00:00,https://github.com/metabase/metabase/issues/44661,"[('.CI & Tests', '')]",[],
2371540605,issue,open,,Defective fields from JSON array values still exist and can be used in questions,"### Describe the bug

Fields with duplicate names could be added if the app DB is MySQL or H2, and a database with JSON array fields was synced between https://github.com/metabase/metabase/pull/43812 and https://github.com/metabase/metabase/pull/44465.

[Related slack discussion about how this is blocking load-from-h2.](https://metaboat.slack.com/archives/C013VC33N95/p1718877409134089?thread_ts=1718814222.803569&cid=C013VC33N95)
[Original issue that was closed when the root cause was fixed.](https://github.com/metabase/metabase/issues/44459)

### The plan

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/44866
- [ ] https://github.com/metabase/metabase/pull/45151
- [ ] [UPDATE: WONT FIX] Replace defective fields in questions with actual fields while trying not to change their results
- [ ] [UPDATE: WON'T FIX] Drop or rename the defective fields, remove the is_defective_duplicate column and reintroduce the unique constraint we have now
```

### To Reproduce

1. Start from https://github.com/metabase/metabase/pull/43812 with `git checkout 33df115`
2. Use MB with a MySQL app DB
3. Create a postgres DB with this table
```
CREATE TABLE my_table (
    id serial PRIMARY KEY,
    data jsonb
);

INSERT INTO my_table (data)
VALUES ('[1, 2, 3]'::jsonb);
```
4. Sync the created DB.
5. Create a question that selects from both ""Data"" fields.
![image](https://github.com/metabase/metabase/assets/39073188/cf2aefee-1a48-4df8-a6cf-4991e4c5c02b)
Note the compiled native SQL is valid:
```
SELECT
  ""public"".""my_table"".""id"" AS ""id"",
  ""public"".""my_table"".""data"" AS ""data"",
  (""public"".""my_table"".""data"" #>> array [ ] :: text [ ]) :: jsonb AS ""data_2""
FROM
  ""public"".""my_table""
LIMIT
  1048575
```
7. Checkout the commit from https://github.com/metabase/metabase/pull/44465 with `git checkout 4a03070`
8. Sync the created DB again, and observe both ""Data"" fields are still there, and still works in the question.

### Expected behavior

There should not be any extra fields created for JSON columns containing arrays.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

High, this is blocking load-from-h2 for some customers, and therefore migration to cloud. Also if you try to filter or join with these columns in the GUI editor it will result in an exception. But JSON columns aren't very useful from the GUI editor anyway.

### Additional context

_No response_",calherries,2024-06-25 03:13:08+00:00,[],2025-02-04 20:29:48+00:00,,https://github.com/metabase/metabase/issues/44659,"[('Type:Tech Debt', 'or Refactoring'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2188213859, 'issue_id': 2371540605, 'author': 'qnkhuat', 'body': 'My 2 cents is that we fix this during dump time: if an instance has defective fields, we let users know about it and ask for permission to delete those fields.\r\n\r\nWe can be fancy and write a query to find all of the effected questions.', 'created_at': datetime.datetime(2024, 6, 25, 7, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190379916, 'issue_id': 2371540605, 'author': 'calherries', 'body': 'I would really suggest this to be a migration so we can enforce uniqueness in MySQL and H2. If we leave duplicate fields around that\'s a footgun for the future IMO. I\'m pretty sure sync relies on fields having unique names per table and there might be other places too we haven\'t caught yet.\r\n\r\nI originally thought we could replace field references in `dataset_query` with this:\r\n```clojure\r\n(defn replace-field [s from to]\r\n  (-> s\r\n      (str/replace (re-pattern (str ""\\""source-field\\"":"" from ""(,|})""))\r\n                   (str ""\\""source-field\\"":"" to ""$1""))\r\n      (str/replace (re-pattern (str ""\\\\[\\""field\\"","" from "",""))\r\n                   (str ""[\\""field\\"","" to "",""))))\r\n```\r\nHere are some test cases:\r\n```clojure\r\n(let [from 62 to 71]\r\n  (testing ""\\""source-field\\"":62 and \\""field\\"",62 gets replaced""\r\n    (is (= ""\\""breakout\\"":[[\\""field\\"",71,{\\""base-type\\"":\\""type/Text\\"",\\""source-field\\"":71}]]""\r\n           (replace-field ""\\""breakout\\"":[[\\""field\\"",62,{\\""base-type\\"":\\""type/Text\\"",\\""source-field\\"":62}]]"" from to))))\r\n  (testing ""\\""source-field\\"":621 or \\""field\\"",621 does not get replaced""\r\n    (is (= ""\\""breakout\\"":[[\\""field\\"",621,{\\""base-type\\"":\\""type/Text\\"",\\""source-field\\"":621}]]""\r\n           (replace-field ""\\""breakout\\"":[[\\""field\\"",621,{\\""base-type\\"":\\""type/Text\\"",\\""source-field\\"":621}]]"" from to)))))\r\n```\r\n\r\nThe problem is, if there\'s a question that uses both the defective field and the actual field in the same query, we\'d still have to de-duplicate the fields. Now this seems increasingly unlikely to me. There are edge-cases on top of edge-cases here, so much so that there\'s a real chance there are no customers that will actually have any questions that use both fields. I\'m wondering whether we might have to create a migration that soft-deletes the defective fields, potentially breaking any questions that used both fields.', 'created_at': datetime.datetime(2024, 6, 26, 1, 50, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190721959, 'issue_id': 2371540605, 'author': 'qnkhuat', 'body': ""Fixing this doesn't immediately let us add the index back, we already have a unique index on (table_id, parent_id, name) on h2 and MySQL. It's just that multiple null values are allowed in a unique index.\r\n\r\nOn pg, it supports partial index so we can have an unique for (table_id, name) if parent_id is null.\r\n\r\nOne solution proposed by @piranha is to add a dummy value for parent_id, like 0, so that the existing index on (table_id, parent_id, name) will take effect on these types of defective columns."", 'created_at': datetime.datetime(2024, 6, 26, 5, 12, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190757490, 'issue_id': 2371540605, 'author': 'qnkhuat', 'body': 'related https://discourse.metabase.com/t/migrating-h2-to-mysql-fails-on-copying-instances-of-field/128034/2', 'created_at': datetime.datetime(2024, 6, 26, 5, 45, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190795582, 'issue_id': 2371540605, 'author': 'qnkhuat', 'body': 'slack [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1719380668675549)', 'created_at': datetime.datetime(2024, 6, 26, 6, 8, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192902017, 'issue_id': 2371540605, 'author': 'calherries', 'body': 'I have a new hypothesis: we can soft-delete the defective fields setting `metabase_field.active=false`, and it will not cause any questions to have different results. It will only cause aesthetic changes on the FE that can be solved manually by users that know what they are doing.\r\n\r\nThis satisfies the strictest definition of not ""breaking any questions"". It will instead put the questions in a state that a user might find confusing to see, but can clean up manually. The tricky part is proving that this claim is true now, and also making sure it is true in the future.\r\n\r\nI\'ve tested this hypothesis with a Postgres DB and set up various questions, and observed what they were after the migration to soft-delete the fields.\r\n\r\nHere are the steps to repro:\r\n1. Start from\xa0[[sync] parse naked json values\xa0#43812](https://github.com/metabase/metabase/pull/43812)\xa0with\xa0`git checkout 33df115`\r\n2. Create a database with a few tables, JSON column and at least one other column. (The reason why I created multiple tables is because there is undeterministic behaviour in which the defective field can be synced either before or after the actual field. Depending on the order, the base type of the fields will be either `:type/JSON` or `:type/Array`.)\r\n```sql\r\nCREATE TABLE table_1 (id serial PRIMARY KEY, data jsonb);\r\nINSERT INTO table_1 (data) VALUES (\'[1, 2, 3]\'::jsonb);\r\nCREATE TABLE table_2 (id serial PRIMARY KEY, data jsonb);\r\nINSERT INTO table_2 (data) VALUES (\'[1, 2, 3]\'::jsonb);\r\nCREATE TABLE table_3 (id serial PRIMARY KEY, data jsonb);\r\nINSERT INTO table_3 (data) VALUES (\'[1, 2, 3]\'::jsonb);\r\n```\r\n\r\n3. In Admin > Table Metadata, set â€œVisiblityâ€ to â€œEverywhereâ€ any JSON field (`metabase_field.visibility=\'normal\'`)\r\n4. Create various questions:\r\n- Select both defective Data field and actual Data field, not selecting the ID field\r\n- Select only the defective Data field\r\n- Sort by the defective Data field (not possible if the type is type/Array)\r\n- Join the table with itself on the defective Data field\r\n- Summarize by the defective Data field (not possible if the type is type/Array)\r\n- Summarize by then combine the Data column with the count (not possible if the type is type/Array)\r\n\r\n5. Checkout the commit from the fix https://github.com/metabase/metabase/pull/44465 with `git checkout 4a03070`\r\n6. Run the migration to set `metabase_field.active=false`. For MySQL that looks like this:\r\n```sql\r\nUPDATE metabase_field mf1\r\nINNER JOIN metabase_field mf2 ON mf1.name = mf2.name \r\n    AND mf1.table_id = mf2.table_id\r\n    AND mf1.parent_id IS NULL\r\n    AND mf2.parent_id IS NULL\r\nSET mf1.active = FALSE\r\nWHERE mf1.nfc_path IS NOT NULL\r\n    AND mf2.nfc_path IS NULL\r\n    AND mf1.active = TRUE;\r\n```\r\n7. Observe the questions again.\r\n\r\n**Results:**\r\nIn all cases the SQL from the QP and the question\'s results were identical before and after the migration. However, there are some differences in the way the fields are displayed on the FE, because metadata is not sent to the FE other than the field ID.\r\n\r\ne.g. for a question with a ""summarize by"" clause and a custom column involving the defective field:\r\n<img width=""964"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/8cfc2520-33ca-4fa1-996a-d3a0497b73ea"">\r\n\r\nDespite the aesthetic differences, in all cases you could repair the questions by replacing the defective field with the actual one:\r\n<img width=""857"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/81149703-b705-44c6-9352-4d5530b01e32"">\r\n\r\nSee an explanation for this behaviour [here](https://metaboat.slack.com/archives/C0645JP1W81/p1719451265414969). It seems like we can rely on the fact that inactive field IDs will still be sent to the FE in the future, and that the query processor will continue to compile queries that use inactive fields.\r\n\r\n**We\'ve deactivated defective fields. What next?**\r\n\r\nThe above solution doesn\'t work if we rename the defective fields. The questions break. So without a solution to replace the fields, we are still stuck with inactive fields that have the same `name` as active ones. We need another solution to unblock `load-from-h2`. One possibility is to add another column to `metabase_field` like `defective_duplicate` and set it to `true` in the above migration. Then we can expand the unique constraint on `metabase_field` to allow duplicate fields to coexist with a Postgres app DB, but ensure that they are unique on `(name, parent_id, table_id, defective_duplicate)`', 'created_at': datetime.datetime(2024, 6, 27, 1, 50, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192932023, 'issue_id': 2371540605, 'author': 'calherries', 'body': ""We might even not need to solve this problem to unblock `load-from-h2` though.\r\n\r\nWe can approach all these problems in steps, solving the `load-from-h2` issue separately from this one. Here's a proposal:\r\n1. Create a migration to add a new boolean column `is_defective_duplicate` and mark the defective fields.\r\n2. Expand the unique constraint on `metabase_field` to allow inactive defective duplicate fields to co-exist with the actual active fields of the same name, i.e. a unique constraint on `(name, parent_id, table_id, is_defective_duplicate)`. Also update toucan select hooks to dissoc `is_defective_duplicate`. After this point, `load-from-h2` works again.\r\n3. Create a migration to deactivate these fields. After this point, users can not use defective fields in new questions.\r\n4. Replace defective fields in questions with actual fields while trying not to change their results.\r\n5. Drop or rename the defective fields, remove the `is_defective_duplicate` column and reintroduce the unique constraint we have now.\r\n\r\nStep 3 can be done before steps 1 and 2, but is probably less important."", 'created_at': datetime.datetime(2024, 6, 27, 2, 22, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195279566, 'issue_id': 2371540605, 'author': 'calherries', 'body': ""When creating the new constraint we need to be careful about two things:\r\n1. `parent_id` is nullable so can't be in the composite index. We need a generated column which replaces NULL values.\r\n2. There can be more than one duplicate from unknown bugs in the past. For every set of duplicate fields we need to set all but one of them to have `is_defective_column=TRUE`.\r\n\r\nHere is the SQL to add such a constraint for H2:\r\n```sql\r\nALTER TABLE metabase_field ADD COLUMN IF NOT EXISTS is_defective_column BOOLEAN NOT NULL DEFAULT TRUE;\r\nALTER TABLE metabase_field ADD COLUMN IF NOT EXISTS unique_name_filter BOOLEAN NOT NULL AS (\r\n    CASE WHEN is_defective_column = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END\r\n);\r\nCREATE UNIQUE INDEX IF NOT EXISTS idx_unique_field_name ON metabase_field (name, table_id, unique_name_filter);\r\n```"", 'created_at': datetime.datetime(2024, 6, 27, 17, 30, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2211183465, 'issue_id': 2371540605, 'author': 'calherries', 'body': 'Changing the priority level of this from P1 to P2 as https://github.com/metabase/metabase/pull/44866 is being backported, which will solve the problems with `load-from-h2`.', 'created_at': datetime.datetime(2024, 7, 5, 17, 20, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269443136, 'issue_id': 2371540605, 'author': 'luizarakaki', 'body': ""I think we should handle this as tech debt now... This isn't really a bug anymore. And it will be possible to find and replace these invalid references with the query validator."", 'created_at': datetime.datetime(2024, 8, 5, 16, 17, 37, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-06-25 07:48:00 UTC): My 2 cents is that we fix this during dump time: if an instance has defective fields, we let users know about it and ask for permission to delete those fields.

We can be fancy and write a query to find all of the effected questions.

calherries (Issue Creator) on (2024-06-26 01:50:03 UTC): I would really suggest this to be a migration so we can enforce uniqueness in MySQL and H2. If we leave duplicate fields around that's a footgun for the future IMO. I'm pretty sure sync relies on fields having unique names per table and there might be other places too we haven't caught yet.

I originally thought we could replace field references in `dataset_query` with this:
```clojure
(defn replace-field [s from to]
  (-> s
      (str/replace (re-pattern (str ""\""source-field\"":"" from ""(,|})""))
                   (str ""\""source-field\"":"" to ""$1""))
      (str/replace (re-pattern (str ""\\[\""field\"","" from "",""))
                   (str ""[\""field\"","" to "",""))))
```
Here are some test cases:
```clojure
(let [from 62 to 71]
  (testing ""\""source-field\"":62 and \""field\"",62 gets replaced""
    (is (= ""\""breakout\"":[[\""field\"",71,{\""base-type\"":\""type/Text\"",\""source-field\"":71}]]""
           (replace-field ""\""breakout\"":[[\""field\"",62,{\""base-type\"":\""type/Text\"",\""source-field\"":62}]]"" from to))))
  (testing ""\""source-field\"":621 or \""field\"",621 does not get replaced""
    (is (= ""\""breakout\"":[[\""field\"",621,{\""base-type\"":\""type/Text\"",\""source-field\"":621}]]""
           (replace-field ""\""breakout\"":[[\""field\"",621,{\""base-type\"":\""type/Text\"",\""source-field\"":621}]]"" from to)))))
```

The problem is, if there's a question that uses both the defective field and the actual field in the same query, we'd still have to de-duplicate the fields. Now this seems increasingly unlikely to me. There are edge-cases on top of edge-cases here, so much so that there's a real chance there are no customers that will actually have any questions that use both fields. I'm wondering whether we might have to create a migration that soft-deletes the defective fields, potentially breaking any questions that used both fields.

qnkhuat on (2024-06-26 05:12:48 UTC): Fixing this doesn't immediately let us add the index back, we already have a unique index on (table_id, parent_id, name) on h2 and MySQL. It's just that multiple null values are allowed in a unique index.

On pg, it supports partial index so we can have an unique for (table_id, name) if parent_id is null.

One solution proposed by @piranha is to add a dummy value for parent_id, like 0, so that the existing index on (table_id, parent_id, name) will take effect on these types of defective columns.

qnkhuat on (2024-06-26 05:45:03 UTC): related https://discourse.metabase.com/t/migrating-h2-to-mysql-fails-on-copying-instances-of-field/128034/2

qnkhuat on (2024-06-26 06:08:32 UTC): slack [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1719380668675549)

calherries (Issue Creator) on (2024-06-27 01:50:56 UTC): I have a new hypothesis: we can soft-delete the defective fields setting `metabase_field.active=false`, and it will not cause any questions to have different results. It will only cause aesthetic changes on the FE that can be solved manually by users that know what they are doing.

This satisfies the strictest definition of not ""breaking any questions"". It will instead put the questions in a state that a user might find confusing to see, but can clean up manually. The tricky part is proving that this claim is true now, and also making sure it is true in the future.

I've tested this hypothesis with a Postgres DB and set up various questions, and observed what they were after the migration to soft-delete the fields.

Here are the steps to repro:
1. Start fromÂ [[sync] parse naked json valuesÂ #43812](https://github.com/metabase/metabase/pull/43812)Â withÂ `git checkout 33df115`
2. Create a database with a few tables, JSON column and at least one other column. (The reason why I created multiple tables is because there is undeterministic behaviour in which the defective field can be synced either before or after the actual field. Depending on the order, the base type of the fields will be either `:type/JSON` or `:type/Array`.)
```sql
CREATE TABLE table_1 (id serial PRIMARY KEY, data jsonb);
INSERT INTO table_1 (data) VALUES ('[1, 2, 3]'::jsonb);
CREATE TABLE table_2 (id serial PRIMARY KEY, data jsonb);
INSERT INTO table_2 (data) VALUES ('[1, 2, 3]'::jsonb);
CREATE TABLE table_3 (id serial PRIMARY KEY, data jsonb);
INSERT INTO table_3 (data) VALUES ('[1, 2, 3]'::jsonb);
```

3. In Admin > Table Metadata, set â€œVisiblityâ€ to â€œEverywhereâ€ any JSON field (`metabase_field.visibility='normal'`)
4. Create various questions:
- Select both defective Data field and actual Data field, not selecting the ID field
- Select only the defective Data field
- Sort by the defective Data field (not possible if the type is type/Array)
- Join the table with itself on the defective Data field
- Summarize by the defective Data field (not possible if the type is type/Array)
- Summarize by then combine the Data column with the count (not possible if the type is type/Array)

5. Checkout the commit from the fix https://github.com/metabase/metabase/pull/44465 with `git checkout 4a03070`
6. Run the migration to set `metabase_field.active=false`. For MySQL that looks like this:
```sql
UPDATE metabase_field mf1
INNER JOIN metabase_field mf2 ON mf1.name = mf2.name 
    AND mf1.table_id = mf2.table_id
    AND mf1.parent_id IS NULL
    AND mf2.parent_id IS NULL
SET mf1.active = FALSE
WHERE mf1.nfc_path IS NOT NULL
    AND mf2.nfc_path IS NULL
    AND mf1.active = TRUE;
```
7. Observe the questions again.

**Results:**
In all cases the SQL from the QP and the question's results were identical before and after the migration. However, there are some differences in the way the fields are displayed on the FE, because metadata is not sent to the FE other than the field ID.

e.g. for a question with a ""summarize by"" clause and a custom column involving the defective field:
<img width=""964"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/8cfc2520-33ca-4fa1-996a-d3a0497b73ea"">

Despite the aesthetic differences, in all cases you could repair the questions by replacing the defective field with the actual one:
<img width=""857"" alt=""image"" src=""https://github.com/metabase/metabase/assets/39073188/81149703-b705-44c6-9352-4d5530b01e32"">

See an explanation for this behaviour [here](https://metaboat.slack.com/archives/C0645JP1W81/p1719451265414969). It seems like we can rely on the fact that inactive field IDs will still be sent to the FE in the future, and that the query processor will continue to compile queries that use inactive fields.

**We've deactivated defective fields. What next?**

The above solution doesn't work if we rename the defective fields. The questions break. So without a solution to replace the fields, we are still stuck with inactive fields that have the same `name` as active ones. We need another solution to unblock `load-from-h2`. One possibility is to add another column to `metabase_field` like `defective_duplicate` and set it to `true` in the above migration. Then we can expand the unique constraint on `metabase_field` to allow duplicate fields to coexist with a Postgres app DB, but ensure that they are unique on `(name, parent_id, table_id, defective_duplicate)`

calherries (Issue Creator) on (2024-06-27 02:22:11 UTC): We might even not need to solve this problem to unblock `load-from-h2` though.

We can approach all these problems in steps, solving the `load-from-h2` issue separately from this one. Here's a proposal:
1. Create a migration to add a new boolean column `is_defective_duplicate` and mark the defective fields.
2. Expand the unique constraint on `metabase_field` to allow inactive defective duplicate fields to co-exist with the actual active fields of the same name, i.e. a unique constraint on `(name, parent_id, table_id, is_defective_duplicate)`. Also update toucan select hooks to dissoc `is_defective_duplicate`. After this point, `load-from-h2` works again.
3. Create a migration to deactivate these fields. After this point, users can not use defective fields in new questions.
4. Replace defective fields in questions with actual fields while trying not to change their results.
5. Drop or rename the defective fields, remove the `is_defective_duplicate` column and reintroduce the unique constraint we have now.

Step 3 can be done before steps 1 and 2, but is probably less important.

calherries (Issue Creator) on (2024-06-27 17:30:40 UTC): When creating the new constraint we need to be careful about two things:
1. `parent_id` is nullable so can't be in the composite index. We need a generated column which replaces NULL values.
2. There can be more than one duplicate from unknown bugs in the past. For every set of duplicate fields we need to set all but one of them to have `is_defective_column=TRUE`.

Here is the SQL to add such a constraint for H2:
```sql
ALTER TABLE metabase_field ADD COLUMN IF NOT EXISTS is_defective_column BOOLEAN NOT NULL DEFAULT TRUE;
ALTER TABLE metabase_field ADD COLUMN IF NOT EXISTS unique_name_filter BOOLEAN NOT NULL AS (
    CASE WHEN is_defective_column = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
);
CREATE UNIQUE INDEX IF NOT EXISTS idx_unique_field_name ON metabase_field (name, table_id, unique_name_filter);
```

calherries (Issue Creator) on (2024-07-05 17:20:21 UTC): Changing the priority level of this from P1 to P2 as https://github.com/metabase/metabase/pull/44866 is being backported, which will solve the problems with `load-from-h2`.

luizarakaki on (2024-08-05 16:17:37 UTC): I think we should handle this as tech debt now... This isn't really a bug anymore. And it will be possible to find and replace these invalid references with the query validator.

"
2371448942,issue,closed,completed,Unable to sort by the breakout column,"### Describe the bug

Stats, see the link below, I get this error ""ERROR: column ""source.created_at"" must appear in the GROUP BY clause or be used in an aggregate function Position: 2383""

<img width=""1336"" alt=""Screenshot 2024-06-24 at 9 48 24â€¯PM"" src=""https://github.com/metabase/metabase/assets/127636/d3f77ae3-6adf-4495-a980-2a954ac5dc7e"">


### To Reproduce

https://stats.metabase.com/question/18343-repro-for-44653

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
stats
```


### Severity

P1 - can't sort 

### Additional context

_No response_",perivamsi,2024-06-25 01:49:36+00:00,['lbrdnk'],2024-08-28 02:08:53+00:00,2024-06-27 15:34:27+00:00,https://github.com/metabase/metabase/issues/44653,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Team/Querying', '')]",[],
2371062806,issue,open,,"I can't see the ""Surface individual records in search by matching against this column"" setting (model indexing) while creating a new model","### Describe the bug

The model indexing setting is only visible after saving a model, which means you wouldn't know this feature exists when creating a model.

### To Reproduce

1. Create a new model, like from the Products table
2. Click on any and every column to notice the absence of the toggle setting with the label, ""Surface individual records in search by matching against this column"" in the metadata settings column on the right.



### Expected behavior

When creating a new model, I should see the setting, ""Surface individual records in search by matching against this column"", in the metadata sidebar when clicking on a column, like this:

<img width=""1432"" alt=""image"" src=""https://github.com/metabase/metabase/assets/2223916/8ddf80be-2c1d-4492-bb95-1116635e3ddc"">


### Logs

_No response_

### Information about your Metabase installation

```JSON
This info below never seems right to me. I'm on `origin/44136-indexed-entities-command-palette`, 16c59dd95e4a7935c92c6e657762cf83dc2dc515.

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15"",
    ""vendor"": ""Apple Computer, Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.11+9"",
    ""java.vendor"": ""AdoptOpenJDK"",
    ""java.vendor.url"": ""https://adoptopenjdk.net/"",
    ""java.version"": ""11.0.11"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.11+9"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""11.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Los_Angeles""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2022-11-18"",
      ""src_hash"": ""09f4ec50c4b6096192e18c140068ce8a7e67434d"",
      ""tag"": ""v0.45.1-SNAPSHOT"",
      ""branch"": ""maz-make-saving-a-question-less-fear-inducing"",
      ""hash"": ""f694966""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2

### Additional context

When creating the model:
<img width=""1547"" alt=""image"" src=""https://github.com/metabase/metabase/assets/2223916/c0f71c2e-c096-4887-80a9-9cb8f8933f49"">

When editing the model:
<img width=""1432"" alt=""image"" src=""https://github.com/metabase/metabase/assets/2223916/8ddf80be-2c1d-4492-bb95-1116635e3ddc"">
",mazameli,2024-06-24 20:46:34+00:00,[],2024-06-25 00:13:35+00:00,,https://github.com/metabase/metabase/issues/44644,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Search', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2371024471,issue,closed,completed,non-admin unable to find sample db tables in search,"### Describe the bug

a non-admin on stats was unable to find the sample db tables on stats

https://metaboat.slack.com/archives/C01LQQ2UW03/p1719259034032299

### To Reproduce

unknown

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
master / stats
```


### Severity

p2

### Additional context

_No response_",dpsutton,2024-06-24 20:20:48+00:00,"['johnswanson', 'noahmoss']",2024-07-15 21:01:23+00:00,2024-07-12 15:44:18+00:00,https://github.com/metabase/metabase/issues/44643,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Organization/Search', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2229427744, 'issue_id': 2371024471, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 1, 22, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-07-15 21:01:22 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2370947855,issue,closed,completed,"Duplicated dashboard does not save ""Full width"" setting","### Describe the bug

When you duplicate a dashboard, if the original dashbaord has ""Full width"" toggle set to on, the new duplicated dashboard still has the toggle set to off.

### To Reproduce

1. Create a dashboard and set the ""Full width"" toggle to ON.
2. Duplicate the dashboard
3. See that the new duplicated dashboard has the ""Full width"" OFF. 


### Expected behavior

Customers expect this setting is saved when duplicating a dashboard.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 50.x
```


### Severity

p3

### Additional context

_No response_",ignacio-mb,2024-06-24 19:30:22+00:00,[],2025-01-21 20:13:00+00:00,2025-01-17 21:23:03+00:00,https://github.com/metabase/metabase/issues/44640,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2370784252,issue,closed,completed,Can't display line or bar chart for empty result set,"### Describe the bug

After updating from 0.49 to to v0.50.6, some questions give an error when opened. After some investigation it seems that it's questions with empty resultset and a ""line"" or ""bar"" visualization.

### To Reproduce

1. Go to '+ New' => 'SQL Query', select a Postgres database
2. Enter a query with a date column and an integer columns which returns no results (example with Postgres)
```sql
SELECT '2023-01-01'::date, 2
FROM pg_type
WHERE false;
```
3. Select Visualization => Bar (or Line)
4. See error. It either shows an eternal spinner or shows ""Somethingâ€™s gone wrong""

### Expected behavior

It should show the usual empty results placeholder, and let you edit the question, instead of crashing.

### Logs

Sometimes I don't get any error and it just shows an eternal spinner (despite the network request completing successfully)
Sometimes I get this in the console (sometimes with includes sometimes with clone, apologies that this probably is not very useful, I hope you can easily reproduce)

![image](https://github.com/metabase/metabase/assets/6978200/a35b4163-c7e4-4b7b-b7ce-b2f4ed9d92fc)

Since the POST to `/api/dataset` completes successfully I don't think server logs are relevant, but happy to provide them if you can't reproduce.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1058-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""googleanalytics""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

This would be blocking a dashboard we share with users, but we have a workaround for now

### Additional context


https://github.com/metabase/metabase/assets/6978200/4ba8f4dc-cd70-4f1f-9074-327e1ae248f2",Recursing,2024-06-24 17:49:15+00:00,['kulyk'],2024-06-27 07:50:15+00:00,2024-06-27 07:26:06+00:00,https://github.com/metabase/metabase/issues/44637,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2187276820, 'issue_id': 2370784252, 'author': 'calherries', 'body': 'I can reproduce this on the release-x.50.x branch (7c779882be). \r\n\r\n1. Using the sample database:\r\n```\r\nSELECT 1 from people WHERE false;\r\n```\r\n2. Select Visualization => Bar', 'created_at': datetime.datetime(2024, 6, 24, 19, 40, 8, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-24 19:40:08 UTC): I can reproduce this on the release-x.50.x branch (7c779882be). 

1. Using the sample database:
```
SELECT 1 from people WHERE false;
```
2. Select Visualization => Bar

"
2370719178,issue,closed,not_planned,Can't deny table permissions anymore in v50.x,"### Describe the bug

You could make granular table permissions <50 but now you can't do it anymore

### To Reproduce

1) in v50, add a new group
2) go to permissions
3) try to give a specific group access to only a specific table (you'll see only sandboxed and ""can view""
![image](https://github.com/metabase/metabase/assets/1711649/35b23989-7208-4c34-81a1-6c076baa7160)


### Expected behavior

You should be able to give table level permission if the user does not have SQL access

### Logs

NA

### Information about your Metabase installation

```JSON
- 50
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-06-24 17:10:46+00:00,[],2024-06-24 18:12:00+00:00,2024-06-24 18:12:00+00:00,https://github.com/metabase/metabase/issues/44635,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2187061517, 'issue_id': 2370719178, 'author': 'dpsutton', 'body': '@paoliniluis Can you show how you would configure this in 1.49.x?', 'created_at': datetime.datetime(2024, 6, 24, 17, 25, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187105973, 'issue_id': 2370719178, 'author': 'paoliniluis', 'body': 'The old ""no self service"" is now\r\n![image](https://github.com/metabase/metabase/assets/1711649/deb8769d-6cb9-4d3c-b14a-37a88432d310)\r\n\r\nwe should reflect that on the UI or on the documentation. It\'s confusing that the permission is ""can view"" while the user can\'t see the table', 'created_at': datetime.datetime(2024, 6, 24, 17, 52, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187136662, 'issue_id': 2370719178, 'author': 'luizarakaki', 'body': ""The permission is that the user `can view` the data. If there is a question querying that table, they can view the data but can't create queries themselves.\r\n\r\nThe setup flow is indeed weird. We are working on small changes to make it more intuitive https://github.com/metabase/metabase/issues/43193"", 'created_at': datetime.datetime(2024, 6, 24, 18, 11, 41, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-06-24 17:25:52 UTC): @paoliniluis Can you show how you would configure this in 1.49.x?

paoliniluis (Issue Creator) on (2024-06-24 17:52:38 UTC): The old ""no self service"" is now
![image](https://github.com/metabase/metabase/assets/1711649/deb8769d-6cb9-4d3c-b14a-37a88432d310)

we should reflect that on the UI or on the documentation. It's confusing that the permission is ""can view"" while the user can't see the table

luizarakaki on (2024-06-24 18:11:41 UTC): The permission is that the user `can view` the data. If there is a question querying that table, they can view the data but can't create queries themselves.

The setup flow is indeed weird. We are working on small changes to make it more intuitive https://github.com/metabase/metabase/issues/43193

"
2370407810,issue,open,,Bug on create query using date on database BigQuery,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/42574195/1c4a712b-4f9d-4e7f-ad8d-fd051098e335)

![image](https://github.com/metabase/metabase/assets/42574195/53e37f69-74e1-4a88-8925-2b895e9023b4)

When i'm search with date, on not add name project (`enviabybus-271020`), before a table, it on erro.

For success i have use timestamp_trunc(`enviabybus-271020.airbyte.SyncShippingEvents`.`createdAt`, day, 'America/Sao_Paulo')) add name project

`SELECT   count(DISTINCT `enviabybus-271020.airbyte.SyncShippingEvents`.`id`) FROM `enviabybus-271020.airbyte.SyncShippingEvents`LEFT JOIN`enviabybus-271020.airbyte.zordon_Shipments` ON CAST(`enviabybus-271020.airbyte.SyncShippingEvents`.`dataId`AS STRING) =`enviabybus-271020.airbyte.zordon_Shipments`.`carrierCode`LEFT JOIN`enviabybus-271020.airbyte.Entities`ON`enviabybus-271020.airbyte.zordon_Shipments`.`senderId`=`enviabybus-271020.airbyte.Entities`.`id`where`enviabybus-271020.airbyte.SyncShippingEvents`.`dataType`= 'Minuta' and`enviabybus-271020.airbyte.zordon_Shipments`.`consigneeId`= 6207 and CASE WHEN 'ENTREGA REALIZADA NORMALMENTE' = 'ENTREGA REALIZADA NORMALMENTE' THEN`enviabybus-271020.airbyte.SyncShippingEvents`.`code` = 1 END and timestamp_trunc(`enviabybus-271020.airbyte.SyncShippingEvents`.`createdAt`, day, 'America/Sao_Paulo') = timestamp ""2024-06-24 00:00:00 America/Sao_Paulo""`

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

### Expected behavior

*No response*

### Logs

*No response*

### Information about your Metabase installation

```JSON
- Metabase version 0.47.8
```

### Severity

Very

### Additional context

*No response*",Militao36,2024-06-24 14:29:42+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/44626,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2187125691, 'issue_id': 2370407810, 'author': 'calherries', 'body': 'Based on the error message the dataset name `enviabybus-271020` is not being added to the start of `airbyte.SyncShippingEvents` in the native query.', 'created_at': datetime.datetime(2024, 6, 24, 18, 5, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187570280, 'issue_id': 2370407810, 'author': 'Militao36', 'body': ""@calherries that's right"", 'created_at': datetime.datetime(2024, 6, 24, 22, 59, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2253344503, 'issue_id': 2370407810, 'author': 'ixipixi', 'body': ""@Militao36 you can work around this for now by removing the project name from the fields in the select statements, etc. As long as it's consistent (all fields either call in project ID or not) then it should execute without error.\r\n\r\nThis becomes a problem if your service account has access to multiple GCP projects and you're querying across them, though. In that instance you have to define the project. You'd never be able to use field filters in that specific case."", 'created_at': datetime.datetime(2024, 7, 26, 19, 28, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405227171, 'issue_id': 2370407810, 'author': 's-diehl', 'body': ""@ixipixi your suggested workaround doesn't work for me. Removing the project name in the select statement results in the same error.\n\nIs there any progress on this? I'm using Metabase `v1.50.24`"", 'created_at': datetime.datetime(2024, 10, 10, 14, 19, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464208521, 'issue_id': 2370407810, 'author': 'J-Reichardt', 'body': 'Is there any progress on this? The proposed workaround doesnt work on metabase `v1.51.0.1-beta`', 'created_at': datetime.datetime(2024, 11, 8, 9, 19, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575239440, 'issue_id': 2370407810, 'author': 'SNickel23', 'body': 'Same for us. ;-(', 'created_at': datetime.datetime(2025, 1, 7, 12, 58, 11, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-24 18:05:02 UTC): Based on the error message the dataset name `enviabybus-271020` is not being added to the start of `airbyte.SyncShippingEvents` in the native query.

Militao36 (Issue Creator) on (2024-06-24 22:59:30 UTC): @calherries that's right

ixipixi on (2024-07-26 19:28:46 UTC): @Militao36 you can work around this for now by removing the project name from the fields in the select statements, etc. As long as it's consistent (all fields either call in project ID or not) then it should execute without error.

This becomes a problem if your service account has access to multiple GCP projects and you're querying across them, though. In that instance you have to define the project. You'd never be able to use field filters in that specific case.

s-diehl on (2024-10-10 14:19:02 UTC): @ixipixi your suggested workaround doesn't work for me. Removing the project name in the select statement results in the same error.

Is there any progress on this? I'm using Metabase `v1.50.24`

J-Reichardt on (2024-11-08 09:19:35 UTC): Is there any progress on this? The proposed workaround doesnt work on metabase `v1.51.0.1-beta`

SNickel23 on (2025-01-07 12:58:11 UTC): Same for us. ;-(

"
2370381500,issue,open,,Not possible to remove the semantic type from a column in model metadata overrides,"### Describe the bug

When mapping a column on a SQL model to a database field that has a semantic type, setting the semantic type to ""No semantic type"" is not reflected in query results.

### To Reproduce

1. Open this model https://stats.metabase.com/model/18332
2. Edit metadata
3. Set the semantic type of ""Feature"" column to ""No semantic type"".
4. Save the model
5. See that in `/dataset` response the semantic type is unchanged.

### Expected behavior

The semantic type setting of the model column should not be dropped - it should be `semantic_type: null`.

### Logs

No relevant logs

### Information about your Metabase installation

```JSON
v50
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-06-24 14:18:57+00:00,[],2025-02-04 20:27:54+00:00,,https://github.com/metabase/metabase/issues/44623,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2370242012,issue,closed,completed,Using filter + within group is not supported,"Here is a minimally reproducing query:

```sql
  select
    e.instance_id
   -- this next one is fine
    , percentile_cont(0.75) within group (order by e.running_time) / 1000.0 as p75_time
   -- this is also fine
    , avg(e.running_time) filter (where e.error = '') / 1000.0 as avg_success_time
   -- this one causes a parse error
    , percentile_cont(0.75) within group (order by e.running_time) filter (where e.error = '') / 1000.0 as p75_success_time
  from execution e
  group by 1
```",crisptrutski,2024-06-24 13:20:11+00:00,[],2024-06-24 13:23:40+00:00,2024-06-24 13:23:40+00:00,https://github.com/metabase/metabase/issues/44619,[],"[{'comment_id': 2186576139, 'issue_id': 2370242012, 'author': 'crisptrutski', 'body': 'Moved to Macaw repo https://github.com/metabase/macaw/issues/75', 'created_at': datetime.datetime(2024, 6, 24, 13, 23, 40, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-06-24 13:23:40 UTC): Moved to Macaw repo https://github.com/metabase/macaw/issues/75

"
2370240892,issue,open,,Focus state cut off in table name input,"### Describe the bug

Bottom edge of the focus decoration is not visible:

![image](https://github.com/metabase/metabase/assets/6830683/5e8bc607-9925-40b2-8719-e4438775f92e)


### To Reproduce

1. Go to Admin > Table Metadata and pick a table
2. Focus the table name input


### Expected behavior

All 4 edges of the focus decoration should be visible
### Information about your Metabase installation

master, 2f6e5d7


### Severity

P3
",kamilmielnik,2024-06-24 13:19:40+00:00,[],2025-02-04 20:24:41+00:00,,https://github.com/metabase/metabase/issues/44618,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Table Metadata', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2370119556,issue,closed,completed,Can't change binning in GUI editor on mobile,"### Describe the bug

When using mobile, you can't edit the binning of dates/number/etc fields

https://github.com/metabase/metabase/assets/132273646/adf7d286-fb85-4738-ac8c-df28cbc76182




### To Reproduce

1. Open metabase on mobile
2. Open the GUI editor
3. Select a field in the Summarization section that can be binned
4. Try to modify the binning


### Expected behavior

Should let you

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Mobile (iphone)
- Safari
- 50.4/master
```


### Severity

p2

### Additional context

_No response_",ignacio-mb,2024-06-24 12:25:36+00:00,['romeovs'],2024-11-08 04:42:24+00:00,2024-11-08 03:59:22+00:00,https://github.com/metabase/metabase/issues/44612,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Client:Mobile Web', 'and tablets and smaller screens'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2369456070,issue,open,,Sidebar gets automatically closed twice when navigating bookmarked entities,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/026c3835-0840-489f-9343-5f19a11c9ee3



### To Reproduce

_It's very easy to reproduce this in stats instance (because it's slow)_

1. Create a question and bookmark it
2. Visit another question
3. Enable network throttling if you're trying to reproduce this locally
4. Open sidebar
5. Click the question bookmarked in step 1
6. Sidebar will automatically close (a bit annoying, but ok)
7. Open the sidebar before the question has loaded
8. Sidebar will automatically close once again (very annoying)


### Expected behavior

Sidebar should not automatically close twice


### Information about your Metabase installation

master, 2f6e5d7fcd


### Severity

P3
",kamilmielnik,2024-06-24 07:27:23+00:00,[],2024-06-24 07:28:18+00:00,,https://github.com/metabase/metabase/issues/44602,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2369442088,issue,open,,Misaligned bookmark icon in the sidebar when bookmarked entity has a long name,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/f0a73747-4a16-4c8d-9b46-486bad2d4919)


### To Reproduce

1. Create a question/model/dashboard/collection with a long name, e.g. `Kamil Mielnik's Personal Collection`
2. Bookmark it
3. Hover it in the sidebar


### Expected behavior

There should be padding on the left and right of the icon.
All bookmark icons in the sidebar should be aligned vertically.


### Information about your Metabase installation

master, 2f6e5d7fcd


### Severity

P3
",kamilmielnik,2024-06-24 07:19:50+00:00,[],2024-06-24 07:20:57+00:00,,https://github.com/metabase/metabase/issues/44601,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2369350756,issue,closed,completed,[Flaky Test]: scenarios > collection items listing sorting should allow to sort unpinned items by columns asc and desc,"Last Flake: https://github.com/metabase/metabase/actions/runs/9613383629
Last Flake Time: 2024-06-21T05:44:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",iethree,2024-06-24 06:33:34+00:00,['kamilmielnik'],2024-07-12 09:43:30+00:00,2024-07-12 09:43:30+00:00,https://github.com/metabase/metabase/issues/44599,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2202220027, 'issue_id': 2369350756, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9740970200\nLast Flake Time: 2024-07-01T02:23:00-07:00\nFlakes in the last day: 1\nFlakes in the last 3d: 1\nFlakes in the last 7d: 1', 'created_at': datetime.datetime(2024, 7, 2, 7, 51, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225211722, 'issue_id': 2369350756, 'author': 'kamilmielnik', 'body': 'Fixed by #45370', 'created_at': datetime.datetime(2024, 7, 12, 9, 43, 30, tzinfo=datetime.timezone.utc)}]","github-automation-metabase on (2024-07-02 07:51:18 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9740970200
Last Flake Time: 2024-07-01T02:23:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 1

kamilmielnik (Assginee) on (2024-07-12 09:43:30 UTC): Fixed by #45370

"
2369350736,issue,closed,not_planned,[Flaky Test]: should display the `Change permissions` menu for admin users,"Last Flake: https://github.com/metabase/metabase/actions/runs/9613161289
Last Flake Time: 2024-06-21T05:19:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",iethree,2024-06-24 06:33:34+00:00,[],2024-12-13 16:45:40+00:00,2024-12-13 16:45:40+00:00,https://github.com/metabase/metabase/issues/44598,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2369350725,issue,closed,not_planned,[Flaky Test]: describe-fields-or-table-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9615919843
Last Flake Time: 2024-06-22T01:03:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",iethree,2024-06-24 06:33:33+00:00,[],2024-12-13 16:43:40+00:00,2024-12-13 16:43:40+00:00,https://github.com/metabase/metabase/issues/44597,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]","[{'comment_id': 2233644815, 'issue_id': 2369350725, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9965186377\nLast Flake Time: 2024-07-16T16:39:00-07:00\nFlakes in the last day: 1\nFlakes in the last 3d: 1\nFlakes in the last 7d: 1', 'created_at': datetime.datetime(2024, 7, 17, 15, 50, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233646805, 'issue_id': 2369350725, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9965186377\nLast Flake Time: 2024-07-16T16:39:00-07:00\nFlakes in the last day: 1\nFlakes in the last 3d: 1\nFlakes in the last 7d: 1', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 4, tzinfo=datetime.timezone.utc)}]","github-automation-metabase on (2024-07-17 15:50:11 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9965186377
Last Flake Time: 2024-07-16T16:39:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 1

github-automation-metabase on (2024-07-17 15:51:04 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9965186377
Last Flake Time: 2024-07-16T16:39:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 1

"
2369350708,issue,closed,not_planned,[Flaky Test]: have-select-privilege?-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9618857072
Last Flake Time: 2024-06-21T14:02:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",iethree,2024-06-24 06:33:32+00:00,[],2024-12-13 16:43:40+00:00,2024-12-13 16:43:39+00:00,https://github.com/metabase/metabase/issues/44596,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2369350685,issue,closed,not_planned,[Flaky Test]: sandboxing-rollback-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9604515027
Last Flake Time: 2024-06-21T00:56:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 2",iethree,2024-06-24 06:33:31+00:00,[],2024-12-13 16:43:39+00:00,2024-12-13 16:43:39+00:00,https://github.com/metabase/metabase/issues/44595,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2369350665,issue,closed,not_planned,[Flaky Test]: New Collection should open new collection modal on click,"Last Flake: https://github.com/metabase/metabase/actions/runs/9618791643
Last Flake Time: 2024-06-21T13:05:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 2
Flakes in the last 7d: 2",iethree,2024-06-24 06:33:30+00:00,[],2024-12-13 16:45:40+00:00,2024-12-13 16:45:40+00:00,https://github.com/metabase/metabase/issues/44594,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2369169121,issue,closed,completed,Information icon (i) on collection screen scales in size based on the length of the question's name,"### Describe the bug

The displayed size of the ""i"" icon on the collection screen changes based on the length of the content of the ""Name"" field for that question. I think it's only noticeable when the question name is truncated and uses the ellipsis.

![image](https://github.com/metabase/metabase/assets/4504437/960cc5b6-92f4-4782-b9df-585b4e1e65e1)


### To Reproduce

1. Create questions with various lend names
2. shrink the browser width until ellipsis are displayed
3. see issue as per screenshot

### Expected behavior

These ""i"" would be consistent size

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows Server 2012 R2"",
    ""os.version"": ""6.3"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""10.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-22"",
      ""tag"": ""v0.49.7"",
      ""hash"": ""f0ff786""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Auckland""
    }
  }
}
```


### Severity

Very low

### Additional context

_No response_",notrom,2024-06-24 04:23:33+00:00,[],2025-01-22 14:32:04+00:00,2025-01-22 14:32:04+00:00,https://github.com/metabase/metabase/issues/44591,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Tusk', 'Tusk will try and create a pull request')]","[{'comment_id': 2250049987, 'issue_id': 2369169121, 'author': 'use-tusk[bot]', 'body': ""I'm working on this issue. Will comment once I have an update. ðŸ¤”\n      \nSee [activity logs](https://usetusk.ai/app/task/fb74d305-0337-4798-a2ed-18ef3bfa90be?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info."", 'created_at': datetime.datetime(2024, 7, 25, 10, 57, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250139806, 'issue_id': 2369169121, 'author': 'use-tusk[bot]', 'body': 'I created a [pull request](https://github.com/metabase/metabase/pull/46129) for this issue. ðŸ§‘\u200dðŸ’»\n\nPlease approve and merge the PR once you\'ve verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I\'ll address it.', 'created_at': datetime.datetime(2024, 7, 25, 11, 51, 2, tzinfo=datetime.timezone.utc)}]","use-tusk[bot] on (2024-07-25 10:57:46 UTC): I'm working on this issue. Will comment once I have an update. ðŸ¤”
      
See [activity logs](https://usetusk.ai/app/task/fb74d305-0337-4798-a2ed-18ef3bfa90be?client=3086848b-0d35-4181-be6a-28e39c94ef4d) for more info.

use-tusk[bot] on (2024-07-25 11:51:02 UTC): I created a [pull request](https://github.com/metabase/metabase/pull/46129) for this issue. ðŸ§‘â€ðŸ’»

Please approve and merge the PR once you've verified that the changes work. If you have any feedback, leave a ""Request Changes"" review on the PR and I'll address it.

"
2368933713,issue,closed,not_planned,Issue with Apache Druid Filtering,"### Describe the bug

Adding a filter after a Summarize while using an Apache Druid datasource (not reproducable on Sample Database) will break the Native query. See Additional Context for screenshots of the issue

### To Reproduce

- Create a Question
- Add a Summarize stage (i.e. Count by Timestamp: Hour)
![CleanShot 2024-06-24 at 00 14 38](https://github.com/metabase/metabase/assets/5119107/dfa0ab43-c0f1-47d0-9c32-a82e76a18926)
- Add a filter stage using something from the Summarize
![CleanShot 2024-06-24 at 00 14 48](https://github.com/metabase/metabase/assets/5119107/e53bf420-f6bd-455a-a4f7-535246ab4848)
- Note the Native query has changed
- Click Visualize to see error

### Expected behavior

It should filter the data after Summarizing it and not break the Native query.

### Logs

```
{
            ""status"": ""failed"",
            ""class"": ""class clojure.lang.ExceptionInfo"",
            ""error"": ""Error executing query: Cannot construct instance of `org.apache.druid.query.scan.ScanQuery`, problem: dataSource can't be null\n at [Source: (org.eclipse.jetty.server.HttpInputOverHTTP); line: 1, column: 347]"",
            ""stacktrace"": [
                ""--> driver.druid.execute$execute_reducible_query$fn__121092.invoke(execute.clj:165)"",
                ""driver.druid.execute$execute_reducible_query.invokeStatic(execute.clj:162)"",
                ""driver.druid.execute$execute_reducible_query.invoke(execute.clj:148)"",
                ""driver.druid$fn__121534.invokeStatic(druid.clj:54)"",
                ""driver.druid$fn__121534.invoke(druid.clj:52)"",
                ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)"",
                ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)"",
                ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:88)"",
                ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:81)"",
                ""query_processor.execute$run.invokeStatic(execute.clj:60)"",
                ""query_processor.execute$run.invoke(execute.clj:54)"",
                ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__69569.invoke(update_used_cards.clj:40)"",
                ""query_processor.execute$add_native_form_to_result_metadata$fn__69578.invoke(execute.clj:23)"",
                ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__69583.invoke(execute.clj:34)"",
                ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___69555.invoke(cache.clj:242)"",
                ""query_processor.middleware.permissions$check_query_permissions$fn__63714.invoke(permissions.clj:118)"",
                ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64290.invoke(enterprise.clj:51)"",
                ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64300.invoke(enterprise.clj:64)"",
                ""query_processor.execute$execute$fn__69610.invoke(execute.clj:92)"",
                ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)"",
                ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)"",
                ""query_processor.execute$execute.invokeStatic(execute.clj:91)"",
                ""query_processor.execute$execute.invoke(execute.clj:87)"",
                ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)"",
                ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)"",
                ""query_processor.middleware.enterprise$fn__64317$handle_audit_app_internal_queries__64318$fn__64320.invoke(enterprise.clj:96)"",
                ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64328.invoke(enterprise.clj:103)"",
                ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75428.invoke(process_userland_query.clj:182)"",
                ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75497.invoke(catch_exceptions.clj:128)"",
                ""query_processor$process_query$fn__75534.invoke(query_processor.clj:78)"",
                ""query_processor.setup$do_with_canceled_chan$fn__64732.invoke(setup.clj:189)"",
                ""query_processor.setup$do_with_database_local_settings$fn__64727.invoke(setup.clj:181)"",
                ""query_processor.setup$do_with_driver$fn__64722$fn__64723.invoke(setup.clj:166)"",
                ""driver$do_with_driver.invokeStatic(driver.clj:104)"",
                ""driver$do_with_driver.invoke(driver.clj:99)"",
                ""query_processor.setup$do_with_driver$fn__64722.invoke(setup.clj:165)"",
                ""query_processor.setup$do_with_metadata_provider$fn__64715$fn__64718.invoke(setup.clj:151)"",
                ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)"",
                ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",
                ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)"",
                ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)"",
                ""query_processor.setup$do_with_metadata_provider$fn__64715.invoke(setup.clj:150)"",
                ""query_processor.setup$do_with_resolved_database$fn__64709.invoke(setup.clj:128)"",
                ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)"",
                ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)"",
                ""query_processor$process_query.invokeStatic(query_processor.clj:76)"",
                ""query_processor$process_query.invoke(query_processor.clj:69)"",
                ""api.dataset$run_streaming_query$fn__97116.invoke(dataset.clj:84)"",
                ""query_processor.streaming$_streaming_response$fn__68041$fn__68042$fn__68043.invoke(streaming.clj:175)"",
                ""query_processor.streaming$_streaming_response$fn__68041$fn__68042.invoke(streaming.clj:174)"",
                ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)"",
                ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)"",
                ""query_processor.streaming$_streaming_response$fn__68041.invoke(streaming.clj:171)"",
                ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)"",
                ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)"",
                ""async.streaming_response$do_f_async$task__52153.invoke(streaming_response.clj:87)""
            ],
            ""error_type"": ""db"",
            ""ex-data"": {
                ""type"": ""db"",
                ""query"": {
                    ""intervals"": [
                        ""1900-01-01/2100-01-01""
                    ],
                    ""granularity"": ""all"",
                    ""context"": {
                        ""queryId"": ""3229af72-ac37-41c0-bdd7-8adcbcefc5ed"",
                        ""timeout"": 1200000
                    },
                    ""queryType"": ""scan"",
                    ""limit"": 2000,
                    ""dataSource"": null,
                    ""filter"": {
                        ""type"": ""bound"",
                        ""ordering"": ""numeric"",
                        ""dimension"": ""count"",
                        ""lower"": 100,
                        ""upper"": null,
                        ""lowerStrict"": true,
                        ""upperStrict"": true
                    },
                    ""columns"": [
                        ""count"",
                        ""__time""
                    ]
                }
            }
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-19-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/London""
  },
  ""metabase-info"": {
    ""databases"": [
      ""druid"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"", // Kubernetes (Docker)
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking internal migration path to Metabase

### Additional context

Before adding filter:
![CleanShot 2024-06-24 at 00 12 45](https://github.com/metabase/metabase/assets/5119107/0a8ef6f3-13bb-4e7c-8472-d408101251b9)

```
{
  ""queryType"": ""topN"",
  ""threshold"": 1000,
  ""granularity"": ""all"",
  ""dataSource"": ""widgetbot"",
  ""dimension"": {
    ""type"": ""extraction"",
    ""dimension"": ""__time"",
    ""outputName"": ""timestamp"",
    ""extractionFn"": {
      ""type"": ""timeFormat"",
      ""format"": ""yyyy-MM-dd'T'HH:00:00ZZ"",
      ""timeZone"": ""UTC"",
      ""locale"": ""en-US""
    }
  },
  ""context"": {
    ""queryId"": ""9e91867a-7f31-42ea-ba9d-6b30b3c9eed6""
  },
  ""intervals"": [
    ""1900-01-01/2100-01-01""
  ],
  ""metric"": {
    ""type"": ""alphaNumeric""
  },
  ""aggregations"": [
    {
      ""type"": ""count"",
      ""name"": ""count""
    }
  ]
}
```

After adding filter:
![CleanShot 2024-06-24 at 00 12 02](https://github.com/metabase/metabase/assets/5119107/4c10508c-1940-4b26-b618-70be2db2ba88)
```
{
  ""intervals"": [
    ""1900-01-01/2100-01-01""
  ],
  ""granularity"": ""all"",
  ""context"": {
    ""queryId"": ""e436aeb4-1e60-4726-894b-b61349030f0e""
  },
  ""queryType"": ""scan"",
  ""limit"": 1048576,
  ""dataSource"": null,
  ""filter"": {
    ""type"": ""bound"",
    ""ordering"": ""numeric"",
    ""dimension"": ""count"",
    ""lower"": 100,
    ""upper"": null,
    ""lowerStrict"": true,
    ""upperStrict"": true
  },
  ""columns"": [
    ""count"",
    ""__time""
  ]
}
```",Yomanz,2024-06-23 23:16:31+00:00,[],2024-08-28 02:08:53+00:00,2024-06-26 12:17:42+00:00,https://github.com/metabase/metabase/issues/44590,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('Database/Druid', None), ('.Team/Querying', '')]","[{'comment_id': 2185436367, 'issue_id': 2368933713, 'author': 'perivamsi', 'body': 'Please use `druid-jdbc` and not `druid` driver.\r\n\r\n<img width=""371"" alt=""Screenshot 2024-06-23 at 9 46 12\u202fPM"" src=""https://github.com/metabase/metabase/assets/127636/1bbc9f2e-5107-43d2-9cde-571a740e1c45"">', 'created_at': datetime.datetime(2024, 6, 24, 1, 46, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186524544, 'issue_id': 2368933713, 'author': 'Yomanz', 'body': '> Please use `druid-jdbc` and not `druid` driver.\r\n> \r\n> <img alt=""Screenshot 2024-06-23 at 9 46 12\u202fPM"" width=""371"" src=""https://private-user-images.githubusercontent.com/127636/342177459-1bbc9f2e-5107-43d2-9cde-571a740e1c45.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTkyMzQxOTksIm5iZiI6MTcxOTIzMzg5OSwicGF0aCI6Ii8xMjc2MzYvMzQyMTc3NDU5LTFiYmM5ZjJlLTUxMDctNDNkMi05Y2RlLTU3MWE3NDBlMWM0NS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYyNFQxMjU4MTlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02MDQxMjI4Njg2ZmZlNTg2MmY4OTdhYjA1YzE1N2ZkOWQ0NzAzNGFjYTk4ZmFmNTJjZjJlNmU3ODEzMjY3ODFjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.C3R7P0a68RJ-xRf8YnMcyuWX-QGr2MX-fxUJ96zfKhg"">\r\n\r\nThanks will give that a go, is that just a temporary solution for now or is it generally recommended to use the Druid JDBC driver instead of the Druid one?', 'created_at': datetime.datetime(2024, 6, 24, 12, 58, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187207923, 'issue_id': 2368933713, 'author': 'perivamsi', 'body': 'It is generally recommend to migrate to Druid JDBC. We will deprecate the other Druid driver after a few releases.', 'created_at': datetime.datetime(2024, 6, 24, 18, 56, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187493438, 'issue_id': 2368933713, 'author': 'Yomanz', 'body': '> It is generally recommend to migrate to Druid JDBC. We will deprecate the other Druid driver after a few releases.\r\n\r\nAh ok cheers for that.', 'created_at': datetime.datetime(2024, 6, 24, 22, 7, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191163932, 'issue_id': 2368933713, 'author': 'perivamsi', 'body': '@Yomanz please let me know if that fixed the issue', 'created_at': datetime.datetime(2024, 6, 26, 8, 51, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191546025, 'issue_id': 2368933713, 'author': 'Yomanz', 'body': '> @Yomanz please let me know if that fixed the issue\r\n\r\nYeah using the other Driver works, thanks.', 'created_at': datetime.datetime(2024, 6, 26, 12, 17, 42, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-06-24 01:46:27 UTC): Please use `druid-jdbc` and not `druid` driver.

<img width=""371"" alt=""Screenshot 2024-06-23 at 9 46 12â€¯PM"" src=""https://github.com/metabase/metabase/assets/127636/1bbc9f2e-5107-43d2-9cde-571a740e1c45"">

Yomanz (Issue Creator) on (2024-06-24 12:58:58 UTC): Thanks will give that a go, is that just a temporary solution for now or is it generally recommended to use the Druid JDBC driver instead of the Druid one?

perivamsi on (2024-06-24 18:56:19 UTC): It is generally recommend to migrate to Druid JDBC. We will deprecate the other Druid driver after a few releases.

Yomanz (Issue Creator) on (2024-06-24 22:07:38 UTC): Ah ok cheers for that.

perivamsi on (2024-06-26 08:51:41 UTC): @Yomanz please let me know if that fixed the issue

Yomanz (Issue Creator) on (2024-06-26 12:17:42 UTC): Yeah using the other Driver works, thanks.

"
2368843580,issue,open,,"Unable to download the query result, metabase connected with spark SQL","Description
Unable to download the query result, metabase connected with spark SQL. I tried running a spark sql to fetch aggregated data of 5 columns, 3 rows. All the elements are integer values.

**Logs**
Metabase Troubleshoot logs:
```
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected Exception in API request handler,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
[81c69c9d-bd43-4961-b28b-523ee69ef358] 2024-06-23T23:45:51+05:30 ERROR metabase.server Unexpected exception in endpoint,org.eclipse.jetty.io.EofException: Early EOF,	at org.eclipse.jetty.server.HttpChannelOverHttp.markEarlyEOF(HttpChannelOverHttp.java:287),	at org.eclipse.jetty.server.HttpChannelOverHttp.earlyEOF(HttpChannelOverHttp.java:266),	at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:1634),	at org.eclipse.jetty.server.HttpConnection.parseRequestBuffer(HttpConnection.java:403),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:275),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Thread.java:829)
```

Please include javascript console and server logs around the time this bug occurred. 
api.js:267 
 
 POST http://xx.xxx.xxx.xx:3000/api/dataset/xlsx?format_rows=false net::ERR_CONNECTION_RESET
_makeRequestWithFetch	@	api.js:267
_makeRequest	@	api.js:187
_makeRequestWithRetries	@	api.js:161
(anonymous)	@	api.js:137
nv	@	downloading.ts:180
ng	@	downloading.ts:54
(anonymous)	@	downloading.ts:42
(anonymous)	@	index.js:16
n.<computed>	@	bindActionCreators.js:8
(anonymous)	@	QueryDownloadWidget.tsx:54
(anonymous)	@	useAsyncFn.js:19
onDownload	@	QueryDownloadWidget.tsx:94
v	@	QueryDownloadPopover.tsx:84
onClick	@	QueryDownloadPopover.tsx:138
eZ	@	react-dom.production.min.js:52
e1	@	react-dom.production.min.js:52
(anonymous)	@	react-dom.production.min.js:53
n5	@	react-dom.production.min.js:53
n4	@	react-dom.production.min.js:101
(anonymous)	@	react-dom.production.min.js:113
eY	@	react-dom.production.min.js:292
(anonymous)	@	react-dom.production.min.js:50
rt	@	react-dom.production.min.js:50
t$	@	react-dom.production.min.js:75
tX	@	react-dom.production.min.js:74
t.unstable_runWithPriority	@	scheduler.production.min.js:18
ir	@	react-dom.production.min.js:122
eB	@	react-dom.production.min.js:292
tF	@	react-dom.production.min.js:73
Show less


**To Reproduce**
Steps to reproduce the behavior:
1. Go to SPARK SQL DB
2. Run a query to get aggregated data on already created views.
3. After we get the result. Click on download option and select json/xlx/csv download option
4. Nothing happens and you see above errors in the application

**Expected behavior**
Query result should have been downloaded

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
Annoying and makes user unable to download query result.
Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
When I download after creating a public sharing link, I was able to download the query result, 
like after creating public sharing link got this link: http://xx.xxx.xxx.xx:3000/public/question/c44c3468-94e3-45db-89cb-eb1b105c264a.json
and I was able to download json. Similarly with xlsx and csv

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-post-Ubuntu-1ubuntu120.04.2"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-post-Ubuntu-1ubuntu120.04.2"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-174-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Los_Angeles""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""sparksql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",Uttejch,2024-06-23 19:35:24+00:00,[],2025-02-04 20:31:32+00:00,,https://github.com/metabase/metabase/issues/44588,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Download', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2368725467,issue,open,,Error when setting custom cron expression for Model Persistence,"### Describe the bug

When setting custom cron expression in Model Persistence, the input gives a confusing error while the gray text is as expected.
![CleanShot 2024-06-23 at 12 24 08@2x](https://github.com/metabase/metabase/assets/60936/7b26326a-02e6-470e-a9b7-31fd752f06ee)

The explainer understands the cron correctly, the input validation says it's invalid an won't persist.


### To Reproduce

1. Go to 'admin/performance/models'
2. Refresh models every... ""custom""
3. Type a cron expression that would be valid in Unix but invalid in Quartz.
4. See validation error, do not point you in the right drection.

Examples on invalid entries:
* 0 9-18 * * MON-FRI
* 0 9-18 * * 1-5

### Expected behavior

Error message should be more clear, in Quartz you either specify day of month OR weekday, you can't specify both, so it needs to be either `? * weekday` or `dayofmonth * ?`, from the error message is unclear that this is the problem.

### Logs

Not applicable.

### Information about your Metabase installation

```JSON
- Metabase version: 0.50.6
```


### Severity

low - annoying

### Additional context

So, it turns out that Metabase uses Quartz cron and not Linux cron syntax, although the UI doesn't allow to set seconds, somewhere in the codebase it must be prefixing with 0 for seconds as I found that the library being used is https://github.com/anushaihalapathirana/cron-expression-validator which requires seconds, upon writing a few new tests and inspecting the code I found a valid expression for what I wanted `0 9-18 ? * 1-5`
The `1-5` means Monday to Friday, the `?` means the day of the month doesn't matter as long as in between the weekday range.
Turns out I was speaking the wrong language (wrong spec) to Metabase.
However it seems the error validates using the library while the explainer (gray text) uses something else as it was always returning something useful to me.

I found this validator to be quite useful: https://www.freeformatter.com/cron-expression-generator-quartz.html

When using `0 0 9-18 * * 1-5` => `Support for specifying both a day-of-week AND a day-of-month parameter is not implemented.`",cabello,2024-06-23 17:04:05+00:00,[],2025-02-04 20:28:23+00:00,,https://github.com/metabase/metabase/issues/44587,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2367732813,issue,closed,completed,Custom Column Case Expression Doesn't Save,"### Describe the bug

Upgraded Metabase to latest and a question no longer functions.

Appears to be due to a custom column.
This column should be
```
case([Assigned Type] = ""App\Models\User"", concat([Assigned To â†’ First Name], "" "", [Assigned To â†’ Last Name]), ""Stock/Location"")
```

However when attempting to save, Metabase overwrites the expression to:
```
case([Assigned Type] = ""App\Models\User"", concat(, "" "", ), ""Stock/Location"")
```

### To Reproduce

Attempt to create a nested concat within the case statment.

### Expected behavior

_No response_

### Logs

``
""Invalid query: {:stages [{:expressions [nil [nil nil [[[nil nil [\""arguments should be comparable\""]]] [[nil nil [\""arguments should be comparable\""]]]]]]}]}"",
``

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-56-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.37-0ubuntu0.22.04.3""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High

### Additional context

_No response_",ccalby,2024-06-22 10:27:46+00:00,['metamben'],2024-08-28 02:08:52+00:00,2024-07-20 12:57:53+00:00,https://github.com/metabase/metabase/issues/44584,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Team/Querying', '')]","[{'comment_id': 2186517115, 'issue_id': 2367732813, 'author': 'ranquild', 'body': 'Based on the issue it should be this https://github.com/metabase/metabase/blob/fb4b8ca2a60fede819fff9362956941ccccadbcb/frontend/src/metabase-lib/v1/expressions/format.ts#L102 - i.e. where we cannot find the column by the field ref stored in the expression.', 'created_at': datetime.datetime(2024, 6, 24, 12, 55, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186518985, 'issue_id': 2367732813, 'author': 'ranquild', 'body': '@ccalby does the issue occur if you re-create this custom expression? Could you show the list of columns you get when typing the expression? Are there any duplicates? Is your question based on a model?', 'created_at': datetime.datetime(2024, 6, 24, 12, 56, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2188785746, 'issue_id': 2367732813, 'author': 'ccalby', 'body': '> @ccalby does the issue occur if you re-create this custom expression? Could you show the list of columns you get when typing the expression? Are there any duplicates? Is your question based on a model?\r\n\r\n@ranquild If I delete the custom column, save the question and then add the custom column back, the issue remains. The custom column is overwritten.\r\nRegarding the columns displayed when typing the expression, the right columns come up as a selectable option - with no duplicate options.\r\n![image](https://github.com/metabase/metabase/assets/680553/aec12f5e-8719-475e-994e-871683b0c6e9)\r\n\r\nQuestion is based on a database table, not a model within Metabase :)', 'created_at': datetime.datetime(2024, 6, 25, 12, 18, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197384933, 'issue_id': 2367732813, 'author': 'ranquild', 'body': 'Repro (internal):\r\n- Open https://stats.metabase.com/model/6759\r\n- Go to notebook\r\n- Add custom column `concat([Assignee â†’ ID] , ""A"")`\r\n- On blur this will be converted to `concat(, ""A"")`\r\n\r\nCause `expressionClauseForLegacyExpression` -> `legacyExpressionForExpressionClause` breaks `base-type` in MBQL and `findColumnIndexesFromLegacyRefs` can\'t find the column by ref here https://github.com/metabase/metabase/blob/e5e0c2ccd03428c622ffa3d1bc468dd98201c3cd/frontend/src/metabase-lib/v1/expressions/format.ts#L103\r\n<img width=""621"" alt=""Screenshot 2024-06-28 at 13 38 26"" src=""https://github.com/metabase/metabase/assets/8542534/36a28ca2-4a31-4739-8976-f6fbe1897379"">\r\n<img width=""431"" alt=""Screenshot 2024-06-28 at 13 41 01"" src=""https://github.com/metabase/metabase/assets/8542534/23f8a376-43f3-4f3e-9b0d-b5bb8a277da3"">', 'created_at': datetime.datetime(2024, 6, 28, 17, 41, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197388793, 'issue_id': 2367732813, 'author': 'ranquild', 'body': 'Related to https://github.com/metabase/metabase/issues/44767', 'created_at': datetime.datetime(2024, 6, 28, 17, 45, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208725573, 'issue_id': 2367732813, 'author': 'Jerrylovescoding', 'body': 'We have the same issues as well. After upgrading metabase from v0.49.17 to v0.50.* (even the latest v0.50.9), many custom columns in other custom columns disappear. Like this:\r\nIn v0.49.17, it is fine:\r\n![image](https://github.com/metabase/metabase/assets/25549512/66ecc750-026d-466a-ae32-e9661f84badd)\r\n\r\nBut in v0.50.9, it is broken:\r\n![image](https://github.com/metabase/metabase/assets/25549512/caf9750f-22a4-411e-b56a-b828d37aecfc)', 'created_at': datetime.datetime(2024, 7, 4, 11, 20, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208766055, 'issue_id': 2367732813, 'author': 'Jerrylovescoding', 'body': '> @ccalby does the issue occur if you re-create this custom expression? Could you show the list of columns you get when typing the expression? Are there any duplicates? Is your question based on a model?\r\n\r\n@ranquild  For us, we have another weird issue. In v0.50.9, if we re-create the custom expression with a different display name, the custom column ""[Net Fee]"" doesn\'t disappear. Like this:\r\n\r\n![image](https://github.com/metabase/metabase/assets/25549512/175034e8-7c53-426a-9897-ddb6f377a0d3)\r\n\r\nBut after changing the display name to the original name, the custom column ""[Net Fee]"" disappear. Like this:\r\n\r\n![image](https://github.com/metabase/metabase/assets/25549512/0a9d9a56-774b-4695-a297-291b426d7685)', 'created_at': datetime.datetime(2024, 7, 4, 11, 46, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2218595453, 'issue_id': 2367732813, 'author': 'metamben', 'body': ""@ranquild's repro is caused by remapped columns incorrectly handled in saved question and model based questions. @ccalby can you tell if there are remapped fields in your setup?\n\nFixing the problem with remapped columns is not enough, the issue with reference mentioned by @ranquild has to be fixed separately."", 'created_at': datetime.datetime(2024, 7, 9, 20, 0, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227633308, 'issue_id': 2367732813, 'author': 'Jerrylovescoding', 'body': '@ranquild @metamben After upgrading to v0.50.12, this issue still exists.\r\n![image](https://github.com/user-attachments/assets/060da105-874c-4fb3-bbb4-e776d20dcb2e)\r\n![image](https://github.com/user-attachments/assets/af5a8d68-244f-42bd-bbef-196717221594)', 'created_at': datetime.datetime(2024, 7, 15, 3, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228635453, 'issue_id': 2367732813, 'author': 'metamben', 'body': '@Jerrylovescoding do you have any errors or warning in the browser console when the custom column name disappears? (I suppose you have a problem different from what has been fixed but producing the same symptoms.)', 'created_at': datetime.datetime(2024, 7, 15, 14, 25, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229423033, 'issue_id': 2367732813, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236000693, 'issue_id': 2367732813, 'author': 'Jerrylovescoding', 'body': ""@metamben The first snapshot below displays the errors and warnings that we get. I don't know if they are related to this issue.\r\n![image](https://github.com/user-attachments/assets/038e6881-73b1-4172-bfaa-6def020aaa5c)\r\n\r\n\r\nAnd by the way, we found the custom columns in custom column would disappear when adding the ninth custom column. (in Metabase v0.50.12)\r\n\r\nBefore adding the ninth custom column, it is normal:\r\n\r\n![image](https://github.com/user-attachments/assets/560342cc-0e42-4648-a9f7-26afc67b888f)\r\n\r\nBut after adding the ninth custom column, the custom columns in custom column disappear:\r\n\r\n![image](https://github.com/user-attachments/assets/178b0646-1765-4268-933c-e470aa9f2520)\r\n\r\n\r\n\r\n> @Jerrylovescoding do you have any errors or warning in the browser console when the custom column name disappears? (I suppose you have a problem different from what has been fixed but producing the same symptoms.)"", 'created_at': datetime.datetime(2024, 7, 18, 9, 3, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236931484, 'issue_id': 2367732813, 'author': 'metamben', 'body': ""> And by the way, we found the custom columns in custom column would disappear when adding the ninth custom column. (in Metabase v0.50.12)\r\n\r\nThanks, @Jerrylovescoding, that's helpful."", 'created_at': datetime.datetime(2024, 7, 18, 16, 0, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241195187, 'issue_id': 2367732813, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 20, 16, 11, 13, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-06-24 12:55:31 UTC): Based on the issue it should be this https://github.com/metabase/metabase/blob/fb4b8ca2a60fede819fff9362956941ccccadbcb/frontend/src/metabase-lib/v1/expressions/format.ts#L102 - i.e. where we cannot find the column by the field ref stored in the expression.

ranquild on (2024-06-24 12:56:24 UTC): @ccalby does the issue occur if you re-create this custom expression? Could you show the list of columns you get when typing the expression? Are there any duplicates? Is your question based on a model?

ccalby (Issue Creator) on (2024-06-25 12:18:32 UTC): @ranquild If I delete the custom column, save the question and then add the custom column back, the issue remains. The custom column is overwritten.
Regarding the columns displayed when typing the expression, the right columns come up as a selectable option - with no duplicate options.
![image](https://github.com/metabase/metabase/assets/680553/aec12f5e-8719-475e-994e-871683b0c6e9)

Question is based on a database table, not a model within Metabase :)

ranquild on (2024-06-28 17:41:50 UTC): Repro (internal):
- Open https://stats.metabase.com/model/6759
- Go to notebook
- Add custom column `concat([Assignee â†’ ID] , ""A"")`
- On blur this will be converted to `concat(, ""A"")`

Cause `expressionClauseForLegacyExpression` -> `legacyExpressionForExpressionClause` breaks `base-type` in MBQL and `findColumnIndexesFromLegacyRefs` can't find the column by ref here https://github.com/metabase/metabase/blob/e5e0c2ccd03428c622ffa3d1bc468dd98201c3cd/frontend/src/metabase-lib/v1/expressions/format.ts#L103
<img width=""621"" alt=""Screenshot 2024-06-28 at 13 38 26"" src=""https://github.com/metabase/metabase/assets/8542534/36a28ca2-4a31-4739-8976-f6fbe1897379"">
<img width=""431"" alt=""Screenshot 2024-06-28 at 13 41 01"" src=""https://github.com/metabase/metabase/assets/8542534/23f8a376-43f3-4f3e-9b0d-b5bb8a277da3"">

ranquild on (2024-06-28 17:45:18 UTC): Related to https://github.com/metabase/metabase/issues/44767

Jerrylovescoding on (2024-07-04 11:20:31 UTC): We have the same issues as well. After upgrading metabase from v0.49.17 to v0.50.* (even the latest v0.50.9), many custom columns in other custom columns disappear. Like this:
In v0.49.17, it is fine:
![image](https://github.com/metabase/metabase/assets/25549512/66ecc750-026d-466a-ae32-e9661f84badd)

But in v0.50.9, it is broken:
![image](https://github.com/metabase/metabase/assets/25549512/caf9750f-22a4-411e-b56a-b828d37aecfc)

Jerrylovescoding on (2024-07-04 11:46:02 UTC): @ranquild  For us, we have another weird issue. In v0.50.9, if we re-create the custom expression with a different display name, the custom column ""[Net Fee]"" doesn't disappear. Like this:

![image](https://github.com/metabase/metabase/assets/25549512/175034e8-7c53-426a-9897-ddb6f377a0d3)

But after changing the display name to the original name, the custom column ""[Net Fee]"" disappear. Like this:

![image](https://github.com/metabase/metabase/assets/25549512/0a9d9a56-774b-4695-a297-291b426d7685)

metamben (Assginee) on (2024-07-09 20:00:09 UTC): @ranquild's repro is caused by remapped columns incorrectly handled in saved question and model based questions. @ccalby can you tell if there are remapped fields in your setup?

Fixing the problem with remapped columns is not enough, the issue with reference mentioned by @ranquild has to be fixed separately.

Jerrylovescoding on (2024-07-15 03:11:46 UTC): @ranquild @metamben After upgrading to v0.50.12, this issue still exists.
![image](https://github.com/user-attachments/assets/060da105-874c-4fb3-bbb4-e776d20dcb2e)
![image](https://github.com/user-attachments/assets/af5a8d68-244f-42bd-bbef-196717221594)

metamben (Assginee) on (2024-07-15 14:25:51 UTC): @Jerrylovescoding do you have any errors or warning in the browser console when the custom column name disappears? (I suppose you have a problem different from what has been fixed but producing the same symptoms.)

github-actions[bot] on (2024-07-15 20:59:00 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

Jerrylovescoding on (2024-07-18 09:03:56 UTC): @metamben The first snapshot below displays the errors and warnings that we get. I don't know if they are related to this issue.
![image](https://github.com/user-attachments/assets/038e6881-73b1-4172-bfaa-6def020aaa5c)


And by the way, we found the custom columns in custom column would disappear when adding the ninth custom column. (in Metabase v0.50.12)

Before adding the ninth custom column, it is normal:

![image](https://github.com/user-attachments/assets/560342cc-0e42-4648-a9f7-26afc67b888f)

But after adding the ninth custom column, the custom columns in custom column disappear:

![image](https://github.com/user-attachments/assets/178b0646-1765-4268-933c-e470aa9f2520)

metamben (Assginee) on (2024-07-18 16:00:14 UTC): Thanks, @Jerrylovescoding, that's helpful.

github-actions[bot] on (2024-07-20 16:11:13 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2367251807,issue,closed,not_planned,Issue upgrading Metabase from v0.41.7 to v0.50.6,"### Describe the bug

I'm working with Metabase in an openshift cluster, I already have Metabase v0.41.7 and I would like to upgrade to v0.50.6 but I get an error. I try with Metabase v0.42.0 and it didn't work either.

### To Reproduce

Try the upgrade, I mean maybe the problem is that the tables in the base changed a lot.

### Expected behavior

Normal start.

### Logs

2024-06-21 20:44:24,535 INFO metabase.plugins :: Loading plugins in /plugins...
2024-06-21 20:44:24,733 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-06-21 20:44:24,836 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-06-21 20:44:24,852 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-06-21 20:44:25,401 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-06-21 20:44:25,451 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-06-21 20:44:25,472 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-06-21 20:44:25,474 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-06-21 20:44:25,575 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-06-21 20:44:25,585 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-06-21 20:44:25,652 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-06-21 20:44:25,940 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-06-21 20:44:25,945 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-06-21 20:44:25,947 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-06-21 20:44:26,385 INFO plugins.classloader :: Added URL file:/plugins/databricks.metabase-driver.jar to classpath
2024-06-21 20:44:26,388 INFO plugins.classloader :: Added URL file:/plugins/ojdbc8.jar to classpath
2024-06-21 20:44:26,483 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-06-21 20:44:26,484 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,485 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-06-21 20:44:26,485 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš
2024-06-21 20:44:26,494 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-06-21 20:44:26,494 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,636 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-06-21 20:44:26,637 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,650 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-06-21 20:44:26,650 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,666 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-06-21 20:44:26,666 INFO driver.impl :: Registered driver :mongo  ðŸšš
2024-06-21 20:44:26,701 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? true
2024-06-21 20:44:26,702 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
2024-06-21 20:44:26,703 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,717 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-06-21 20:44:26,717 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,723 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-06-21 20:44:26,723 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš
2024-06-21 20:44:26,741 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-06-21 20:44:26,742 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,769 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-06-21 20:44:26,770 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš
2024-06-21 20:44:26,775 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-06-21 20:44:26,775 INFO driver.impl :: Registered driver :druid  ðŸšš
2024-06-21 20:44:26,780 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-06-21 20:44:26,780 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-06-21 20:44:26,781 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Vertica Driver""]
2024-06-21 20:44:26,784 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-06-21 20:44:26,784 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,789 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :db2...
2024-06-21 20:44:26,790 INFO driver.impl :: Registered driver :db2 (parents: [:sql-jdbc]) ðŸšš
2024-06-21 20:44:26,800 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-06-21 20:44:26,803 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-21 20:44:27,483 INFO db.setup :: Successfully verified PostgreSQL 13.14 application database connection. âœ…
2024-06-21 20:44:27,484 INFO db.setup :: Checking if a database downgrade is required...
2024-06-21 20:44:28,871 INFO db.setup :: Running Database Migrations...
2024-06-21 20:44:28,872 INFO db.setup :: Setting up Liquibase...
2024-06-21 20:44:29,724 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-06-21 20:44:31,745 WARN util.jvm :: auto-retry metabase.db.liquibase$wait_for_migration_lock$fn__44387@204fbb43: Database has migration lock; cannot run migrations. You can force-release these locks by running `java -jar metabase.jar migrate release-locks`.
2024-06-21 20:44:31,790 WARN db.liquibase :: Migration lock was acquired after 1 retries.
2024-06-21 20:44:31,812 INFO db.setup :: Liquibase is ready.
2024-06-21 20:44:31,812 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-21 20:44:33,123 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-06-21 20:44:33,146 INFO db.liquibase :: No migration lock found.
2024-06-21 20:44:33,147 INFO db.liquibase :: Migration lock acquired.
2024-06-21 20:44:33,808 INFO db.liquibase :: Running 426 migrations ...
2024-06-21 20:44:34,407 ERROR liquibase.changelog :: ChangeSet migrations/000_legacy_migrations.yaml::v42.00-065::dpsutton encountered an exception.
liquibase.exception.DatabaseException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists [Failed SQL: (0) ALTER TABLE ""public"".""core_user"" ADD ""is_datasetnewb"" BOOLEAN DEFAULT TRUE NOT NULL]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44426.invoke(liquibase.clj:359)
	at metabase.db.liquibase$run_in_scope_locked$reify__44422.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:348)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:341)
	at metabase.db.setup$migrate_BANG_$fn__53352.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44363.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53380$fn__53381.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53380.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53405.invoke(db.clj:82)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more

UPDATE SUMMARY
Run:                        426
Previously run:             374
Filtered out:                50
-------------------------------
Total change sets:          850


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               50

2024-06-21 20:44:34,503 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/000_legacy_migrations.yaml::v42.00-065::dpsutton:
     Reason: liquibase.exception.DatabaseException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists [Failed SQL: (0) ALTER TABLE ""public"".""core_user"" ADD ""is_datasetnewb"" BOOLEAN DEFAULT TRUE NOT NULL]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44426.invoke(liquibase.clj:359)
	at metabase.db.liquibase$run_in_scope_locked$reify__44422.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:348)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:341)
	at metabase.db.setup$migrate_BANG_$fn__53352.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44363.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53380$fn__53381.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53380.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53405.invoke(db.clj:82)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:77)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:64)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/000_legacy_migrations.yaml::v42.00-065::dpsutton:
     Reason: liquibase.exception.DatabaseException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists [Failed SQL: (0) ALTER TABLE ""public"".""core_user"" ADD ""is_datasetnewb"" BOOLEAN DEFAULT TRUE NOT NULL]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 58 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/000_legacy_migrations.yaml::v42.00-065::dpsutton:
     Reason: liquibase.exception.DatabaseException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists [Failed SQL: (0) ALTER TABLE ""public"".""core_user"" ADD ""is_datasetnewb"" BOOLEAN DEFAULT TRUE NOT NULL]
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists [Failed SQL: (0) ALTER TABLE ""public"".""core_user"" ADD ""is_datasetnewb"" BOOLEAN DEFAULT TRUE NOT NULL]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 81 more
Caused by: org.postgresql.util.PSQLException: ERROR: column ""is_datasetnewb"" of relation ""core_user"" already exists
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
2024-06-21 20:44:34,509 INFO metabase.core :: Metabase Shutting Down ...
2024-06-21 20:44:34,510 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-06-21 20:44:34,520 WARN db.liquibase :: ()
2024-06-21 20:44:34,521 INFO metabase.core :: Metabase Shutdown COMPLETE

### Information about your Metabase installation

```JSON
My openshift cluster is 4.12.25 version.
```


### Severity

the pods just don't start

### Additional context

_No response_",antonio-tg,2024-06-21 21:07:48+00:00,[],2024-06-21 22:22:45+00:00,2024-06-21 22:22:45+00:00,https://github.com/metabase/metabase/issues/44577,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2183538252, 'issue_id': 2367251807, 'author': 'paoliniluis', 'body': 'Database has migration lock; cannot run migrations. You can force-release these locks by running java -jar metabase.jar migrate release-locks', 'created_at': datetime.datetime(2024, 6, 21, 22, 22, 45, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-21 22:22:45 UTC): Database has migration lock; cannot run migrations. You can force-release these locks by running java -jar metabase.jar migrate release-locks

"
2367222671,issue,closed,completed,Add automated tests for implicit joins on Mongo,"Automated testing is missing for implicit joins on Mongo. For context see the PR's https://github.com/metabase/metabase/pull/44572 description. As mentioned in the PR, stub from [`tx-post-sync-hook`](https://github.com/metabase/metabase/tree/tx-post-sync-hook) could be used as a starting point.",lbrdnk,2024-06-21 20:44:10+00:00,[],2024-10-08 16:20:17+00:00,2024-07-19 11:55:12+00:00,https://github.com/metabase/metabase/issues/44573,"[('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.CI & Tests', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2367059586,issue,open,,Question Builder: Custom Expression in Aggregate Cannot Share the Same Name as the Column It's Aggregating,"### Describe the bug

When aggregating a field with a custom expression if you name the expression the same thing as the column that it is aggregating, the field is no longer recognized.

### To Reproduce

1. Start a question with the Order table form the Sample DB
2. In the ""Summarize"" box create a custom expression named ""Total"" that Sums the ""Total"" column
3. After saving it open it back up to edit it
4. Note field within the expression is no longer recognized with the error ""Unknown Field: Total""

Loom: https://www.loom.com/share/5566e9649a444ee685c219fb0d5fca4d

### Expected behavior

The field should be recognized in the expression editor or naming the expression after the column should be disallowed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.49.17"",
      ""hash"": ""7e2b7bb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

Verified this behavior still occurs in v50",ixipixi,2024-06-21 18:32:24+00:00,[],2025-02-04 20:27:16+00:00,,https://github.com/metabase/metabase/issues/44567,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2367053720,issue,closed,completed,Field Filters in Embedded Dashboard Are No Longer Working,"**Describe the bug**
We have 2 embedded dashboards that leverage field filters. 
Today we noticed the drop down does not populate any values on the embedded view. 
When editing the dashboard the filters work; however, when viewing the embedded view or previewing it the filters do no work.

**Logs**
```
Dimension.ts:679 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:679
w @ query-time.js:184
g @ query-time.js:119
w @ date-formatting.ts:103
(anonymous) @ date-formatting.ts:121
(anonymous) @ date-formatting.ts:122
(anonymous) @ date-formatting.ts:193
v @ date-formatting.ts:167
(anonymous) @ formatting.ts:48
et @ formatting.ts:75
o6 @ react-dom.production.min.js:153
iF @ react-dom.production.min.js:175
l @ react-dom.production.min.js:263
aH @ react-dom.production.min.js:246
(anonymous) @ react-dom.production.min.js:246
aW @ react-dom.production.min.js:246
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
oi @ react-dom.production.min.js:123
oo @ react-dom.production.min.js:122
aT @ react-dom.production.min.js:240
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
o @ Subscription.js:93
b @ redux.js:296
(anonymous) @ session-middleware.js:59
(anonymous) @ middleware.js:22
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
(anonymous) @ redux-toolkit.esm.js:1270
(anonymous) @ redux-toolkit.esm.js:38
(anonymous) @ redux-toolkit.esm.js:41
n @ redux-toolkit.esm.js:72
Promise.then (async)
o @ redux-toolkit.esm.js:86
(anonymous) @ redux-toolkit.esm.js:87
(anonymous) @ redux-toolkit.esm.js:69
(anonymous) @ redux-toolkit.esm.js:1276
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
_initialize @ PublicDashboard.jsx:78
componentDidMount @ PublicDashboard.jsx:99
(anonymous) @ react-dom.production.min.js:212
a$ @ react-dom.production.min.js:213
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
aX @ react-dom.production.min.js:248
aW @ react-dom.production.min.js:239
aq @ react-dom.production.min.js:230
si @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
aD @ react-dom.production.min.js:240
sp @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
x2 @ app.js:75
x3 @ app.js:106
57505 @ app-embed.js:12
a @ bootstrap:19
(anonymous) @ app-embed.597d5f04c8339ca58844.js:168
a.O @ chunk loaded:25
(anonymous) @ app-embed.597d5f04c8339ca58844.js:168
i @ jsonp chunk loading:73
(anonymous) @ app-embed.597d5f04c8339ca58844.js:7
```

**To Reproduce**
Filters working in dashboard editor
![image](https://github.com/metabase/metabase/assets/10537213/b1da581c-a3b7-4a3b-9744-78ea402ab8ea)



Filters missing in embedded view
![image](https://github.com/metabase/metabase/assets/10537213/3a1e3ec6-751d-4284-93cb-280f6e7a8143)



Filters missing in embedded preview
![image](https://github.com/metabase/metabase/assets/10537213/c4736785-f0cf-4101-87bc-5058f6efbb97)


**Expected behavior**
The filters should display options to choose in all views

**Screenshots**
See Above

**Severity**
This is impacting our customers' ability to accurately view reporting information

**Additional context**
We have tried rescanning the field, clearing cache, etc and nothing has changed

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.218-208.862.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""snowflake"",
      ""mongo"",
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.49.17"",
      ""hash"": ""7e2b7bb""
    },
    ""settings"": {
      ""report-timezone"": ""America/Chicago""
    }
  }
}
```",JacobAtchley,2024-06-21 18:28:25+00:00,['ranquild'],2024-06-25 18:30:12+00:00,2024-06-25 18:30:06+00:00,https://github.com/metabase/metabase/issues/44565,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Querying', '')]","[{'comment_id': 2189691301, 'issue_id': 2367053720, 'author': 'ranquild', 'body': 'Fixed by https://github.com/metabase/metabase/pull/44440', 'created_at': datetime.datetime(2024, 6, 25, 18, 30, 6, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-06-25 18:30:06 UTC): Fixed by https://github.com/metabase/metabase/pull/44440

"
2366865518,issue,closed,completed,Big Pivot Tables export breaks or fail silently,"### Describe the bug

While trying to export a pivot table ""Download full results"" button fails silently without any errors shown (both formatted and unformatted options doesn't work). Metabase is running on Kubernetes on 2vcpu and 8 GB memory. On one try I also got a 502 error and Metabase crashed and restarted (doesn't show in the logs).

### To Reproduce

Pivot table size: 42000 rows
row columns: 5 (300 total rows)
pivot columns: 2 (that expand to 70 columns when pivoted)

### Expected behavior

Pivot table CSV file is exported succesfully

### Logs

Didn't find relevant logs.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.216-204.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v1.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P1

### Additional context
",felipe-curebase,2024-06-21 16:24:07+00:00,['adam-james-v'],2024-10-15 16:59:27+00:00,2024-10-15 16:16:04+00:00,https://github.com/metabase/metabase/issues/44556,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2183110005, 'issue_id': 2366865518, 'author': 'perivamsi', 'body': '@felipe-curebase I am sorry for this experience. We will work on providing you a fix as soon as possible.', 'created_at': datetime.datetime(2024, 6, 21, 16, 56, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183193147, 'issue_id': 2366865518, 'author': 'adam-james-v', 'body': ""@felipe-curebase , as we work on a fix, if you really need a possible workaround and are staying on 50.6, the .xlsx downloads do not behave the same was as the csv downloads. \r\nIf you can temporarily use .xlsx exports for your needs, you should see the data shape you're used to in those downloads. \r\n\r\nTo be clear, we're still working on a proper reversion/fix for the issue, I'm just offering a potential temporary workaround."", 'created_at': datetime.datetime(2024, 6, 21, 17, 56, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183472585, 'issue_id': 2366865518, 'author': 'felipe-curebase', 'body': ""@adam-james-v appreciate the quick feedback, thank you. \r\nI can confirm that I was able to successfully download a pivot table file using xlsx format. I was hoping to have a file that has the same formatting that shows up in the screen but looks like the data is not pivoted. \r\nAlso the xlsx file exported looks odd,  it has an additional pivot-grouping column and at the end of the file looks like there are some data that doesn't exist in the source data where some of the pivot columns are empty. maybe because it is calculating permutations of the groupings?"", 'created_at': datetime.datetime(2024, 6, 21, 21, 14, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183510814, 'issue_id': 2366865518, 'author': 'adam-james-v', 'body': ""@felipe-curebase , yes that's what I expected, and in fact that is how our pivot exports have always behaved.\r\n\r\nI'll try to explain a little bit, I know it can be a little confusing :) \r\n\r\nPrior to 50, even the csv downloads would appear in this 'unpivoted' state with the pivot-grouping column and the 'odd' rows at the end (those rows correspond to row/column and grand totals).\r\n\r\nUnfortunately, the bug you're reporting here is actually a consequence of a change that tries to address what you expected, which is an export that IS pivoted. The PR for that change is here: https://github.com/metabase/metabase/pull/41668\r\n\r\nTo understand what I mean, if you create for yourself a much simpler pivot table (that has fewer total rows/columns) and download a .csv of that, you should see something that indeed looks pivoted.\r\n\r\nSince our code paths for .csv and .xlsx exports differ, this 'looks pivoted' download was not implemented for .xlsx. \r\nInstead, this PR: https://github.com/metabase/metabase/pull/43791 is merged into the next minor release and it produces an excel file that:\r\n 1. has the 'unpivoted' rows in 1 sheet and \r\n 2. a 'native' (real, editable) pivot table referencing said rows in the sheet.\r\n\r\nBUT, to set your expectations: because of this issue you've reported, the next minor release will have both csv and .xlsx downloads 'looking pivoted' *disabled*. So, for the time being, if you update to the next minor version (once it's released), your downloads are more likely to succeed, but the data shape will be as you see it in your excel file (not pivoted).\r\n\r\nThe goal, and in my opinion, proper fix for this issue is not to just revert to the old behaviour indefinitely, but to more gracefully handle the use case of yours, which are quite large pivot tables \r\n\r\nIf you play around with smaller pivot tables on your instance, you might find that in many cases things work alright, if you're in the mood to play around a bit ;)\r\n\r\nI underestimated the size of pivot tables that users would realistically be using. To be clear, that's not me dismissing the problem, I'm interested in fixing this properly, I'm just acknowledging that you *might* still find success with your current version for some of your other (smaller) pivot tables.\r\n\r\nI hope that is a little bit helpful. Please ask any other clarifying questions if you need."", 'created_at': datetime.datetime(2024, 6, 21, 21, 52, 9, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-06-21 16:56:57 UTC): @felipe-curebase I am sorry for this experience. We will work on providing you a fix as soon as possible.

adam-james-v (Assginee) on (2024-06-21 17:56:08 UTC): @felipe-curebase , as we work on a fix, if you really need a possible workaround and are staying on 50.6, the .xlsx downloads do not behave the same was as the csv downloads. 
If you can temporarily use .xlsx exports for your needs, you should see the data shape you're used to in those downloads. 

To be clear, we're still working on a proper reversion/fix for the issue, I'm just offering a potential temporary workaround.

felipe-curebase (Issue Creator) on (2024-06-21 21:14:04 UTC): @adam-james-v appreciate the quick feedback, thank you. 
I can confirm that I was able to successfully download a pivot table file using xlsx format. I was hoping to have a file that has the same formatting that shows up in the screen but looks like the data is not pivoted. 
Also the xlsx file exported looks odd,  it has an additional pivot-grouping column and at the end of the file looks like there are some data that doesn't exist in the source data where some of the pivot columns are empty. maybe because it is calculating permutations of the groupings?

adam-james-v (Assginee) on (2024-06-21 21:52:09 UTC): @felipe-curebase , yes that's what I expected, and in fact that is how our pivot exports have always behaved.

I'll try to explain a little bit, I know it can be a little confusing :) 

Prior to 50, even the csv downloads would appear in this 'unpivoted' state with the pivot-grouping column and the 'odd' rows at the end (those rows correspond to row/column and grand totals).

Unfortunately, the bug you're reporting here is actually a consequence of a change that tries to address what you expected, which is an export that IS pivoted. The PR for that change is here: https://github.com/metabase/metabase/pull/41668

To understand what I mean, if you create for yourself a much simpler pivot table (that has fewer total rows/columns) and download a .csv of that, you should see something that indeed looks pivoted.

Since our code paths for .csv and .xlsx exports differ, this 'looks pivoted' download was not implemented for .xlsx. 
Instead, this PR: https://github.com/metabase/metabase/pull/43791 is merged into the next minor release and it produces an excel file that:
 1. has the 'unpivoted' rows in 1 sheet and 
 2. a 'native' (real, editable) pivot table referencing said rows in the sheet.

BUT, to set your expectations: because of this issue you've reported, the next minor release will have both csv and .xlsx downloads 'looking pivoted' *disabled*. So, for the time being, if you update to the next minor version (once it's released), your downloads are more likely to succeed, but the data shape will be as you see it in your excel file (not pivoted).

The goal, and in my opinion, proper fix for this issue is not to just revert to the old behaviour indefinitely, but to more gracefully handle the use case of yours, which are quite large pivot tables 

If you play around with smaller pivot tables on your instance, you might find that in many cases things work alright, if you're in the mood to play around a bit ;)

I underestimated the size of pivot tables that users would realistically be using. To be clear, that's not me dismissing the problem, I'm interested in fixing this properly, I'm just acknowledging that you *might* still find success with your current version for some of your other (smaller) pivot tables.

I hope that is a little bit helpful. Please ask any other clarifying questions if you need.

"
2366793784,issue,open,,Relative date with an offset is not reflected in the timeseries chrome or in the filter modal,"### Describe the bug

When you apply a relative date filter and give it an offset, the result of that action is not reflected in the timeseries chrome component or in the filter modal. The root cause lies in the MLv2 function `Lib.filterArgsDisplayName` returning `nil`.

![image](https://github.com/metabase/metabase/assets/31325167/89e17c06-190f-4852-9aad-e6365328057c)


### To Reproduce

1. Open Orders, Count broken down by Created At: month
2. Click on 'Created At' column header > Filter by this column > Relative dates
3. Choose either Previous or Next
4. Click on ""<-"" icon (Starting from) to add an offset
![image](https://github.com/metabase/metabase/assets/31325167/fa7db997-d5b6-4267-8d04-c214bb77a55c)
5. Add the filter
Notice that the timeseries chrome is still showing ""All time"" instead of ""previous 30 days, 7 days ago""
![image](https://github.com/metabase/metabase/assets/31325167/09730432-a642-415c-8b2c-b3005ede0b30)
6. Open a filter modal by clicking on a large ""Filter"" pill
7. Notice that no value is selected for the ""Created At"" column
![image](https://github.com/metabase/metabase/assets/31325167/3742af75-4800-43ab-a5aa-7d87d69da800)


### Expected behavior

The currently selected filter should be displayed in both TS Chrome and in the Filter Modal.

### Logs

N/A

### Information about your Metabase installation

local dev, `master`, 0637fef, Sample Database, H2



### Severity

P2

### Additional context

_No response_",nemanjaglumac,2024-06-21 15:39:49+00:00,[],2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/44550,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]",[],
2366634887,issue,open,,Support Actions on Public Dashboards,"**Is your feature request related to a problem? Please describe.**
I want to share actions publicly 

**Describe the solution you'd like**
Allow a publicly accessible dashboard to support actions

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Customers have been asking for the public availability of Actions

**Additional context**
Related to https://github.com/metabase/metabase/issues/30266",Tony-metabase,2024-06-21 14:11:25+00:00,[],2025-02-04 20:31:10+00:00,,https://github.com/metabase/metabase/issues/44546,"[('Type:New Feature', ''), ('Embedding/Public', 'Simple public iframe embeds'), ('Querying/Actions', ''), ('.Team/Embedding', ''), ('Sharing/Public', '')]",[],
2366539840,issue,open,,"undo toast shouldn't go down after clicking ""auto-connect""",,uladzimirdev,2024-06-21 13:21:00+00:00,[],2024-06-21 13:21:00+00:00,,https://github.com/metabase/metabase/issues/44542,[],[],
2366449360,issue,closed,completed,[0.49.2->v0.50.3] query joining metabase_table and metabase_field overwhelms our PG instance,"### Describe the bug

Right after upgrading to v0.50.3, we encountered massive perf issues. 

![image](https://github.com/metabase/metabase/assets/91955383/165b4c25-022a-4c5d-a293-fed5d1b1f942)

We identified that the CPU was completely consumed by these queries:
```
SELECT *
FROM ""metabase_field"" AS ""f""
INNER JOIN ""metabase_table"" AS ""t"" ON ""table_id"" = ""t"".""id""
WHERE (""t"".""db_id"" = $1) AND (((LOWER(""f"".""name"") = $2) AND ((LOWER(""t"".""name"") = $3) OR (LOWER(""t"".""name"") = $4) OR -- ... with hundreds of other conditions
```

### ðŸ’¡ What we understood
- In v50, a new table named `query_field` has been introduced and a background job aims at backfilling the table (the job starts when Metabase boots).
- This job is especially slow in our setup because our `metabase_table` and `metabase_field` tables are massive (136k resp. 3.5M rows)
- Once the job was done, we though our instance would get back on its feet, but then the queries mentioned above started (SQL analysis queries) 
- The SQL analysis code is executed on every Metabase card (and we have 40k of them)
- In addition we suspect a performance regression on the [underlying code](https://github.com/metabase/metabase/blob/93334133eabd167bbde56aa63db9b399a1a00184/src/metabase/native_query_analyzer.clj#L107C8-L115) that has been introduced in [this PR](https://github.com/metabase/metabase/pull/41781/files) (also for v50) because it breaks usage of existing indexes

### ðŸ‘©ðŸ»â€ðŸ’» What we did
- Huge clean-up of `metabase_table` (we removed all our dead tables, we went from 136k to 24k rows)
- Re-indexed `metabase_field` with simple btree indexes on `name` and `LOWER(name)` 
This worked and we are now back to our usual load. 

### ðŸ¤” Why do we report a bug if it works now ?
We're still opening this report because:
- We think the fat WHERE clause of the SQL analysis query is sub-optimal
- We think the lack of indexes for `metabase_table` and `metabase_field` is sub-optimal
and we suspect other users of big DBs could encounter a similar issue

### To Reproduce

1. Have 136k rows in `metabase_table`, 3.5M rows in `metabase_field`, and 40k Metabase cards
2. Upgrade from 0.49.2 to v0.50.3

### Expected behavior

The backfilling of `query_field` and then the SQL analysis queries happen seamlessly without impacting perf

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.345-262.561.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-12"",
      ""tag"": ""v0.50.2"",
      ""hash"": ""1a2c2da""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking usage of Metabase entirely

### Additional context

_No response_",CeliaMonstro,2024-06-21 12:31:17+00:00,[],2024-06-21 15:40:15+00:00,2024-06-21 13:08:40+00:00,https://github.com/metabase/metabase/issues/44537,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Database/Postgres', None), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2182723784, 'issue_id': 2366449360, 'author': 'piranha', 'body': ""Hello! Wow, fantastic bug report! Thanks a lot for the analysis and for your numbers, we certainly underestimated what could be out there, I'm really sorry for this and for the time it took from you.\r\n\r\nWe've disabled SQL analysis by default in [v0.50.6](https://github.com/metabase/metabase/releases/tag/v0.50.6), so if you update there it should not bother you. We have plans re-enabling it, but we'll be more aware of the load it generates and will make sure it's contained better."", 'created_at': datetime.datetime(2024, 6, 21, 13, 8, 41, tzinfo=datetime.timezone.utc)}]","piranha on (2024-06-21 13:08:41 UTC): Hello! Wow, fantastic bug report! Thanks a lot for the analysis and for your numbers, we certainly underestimated what could be out there, I'm really sorry for this and for the time it took from you.

We've disabled SQL analysis by default in [v0.50.6](https://github.com/metabase/metabase/releases/tag/v0.50.6), so if you update there it should not bother you. We have plans re-enabling it, but we'll be more aware of the load it generates and will make sure it's contained better.

"
2366408104,issue,closed,completed,Chart dimensions are not updated when adding breakouts one-by-one,"### Describe the bug

When adding breakouts to a query one-by-one via the summarization sidebar, the chart doesn't pick up the new dimension. Things work as expected if breakouts are added together (with the notebook editor)

### To Reproduce

1. New > Question > Tables > Sample Database > Products > Visualize
2. Click ""Summarize"" in the top right
3. Hover the ""Category"" column and click the ""+"" button
4. Hover the ""Created At"" column and click the ""+"" button
5. The query reruns and the breakout is added (in MBQL), but the chart doesn't pick up the time dimension


### Expected behavior

Metabase should display a Count by Category/Created At line chart

### Logs

N/A

### Information about your Metabase installation

```JSON
v50.4
```


### Severity

P1

### Additional context

_No response_",kulyk,2024-06-21 12:07:22+00:00,['kulyk'],2024-06-21 13:34:07+00:00,2024-06-21 13:34:07+00:00,https://github.com/metabase/metabase/issues/44532,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Chart Settings', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2366218634,issue,closed,completed,"[v0.48.13 --> v0.49.17] Migration stuck with ""Running 8 migrations ...""","### Describe the bug

In a Kubernetes context, I upgraded Metabase from v0.48.13 to v0.49.17 (with PostgreSQL 13 database). The readiness/liveness probes were a bit short so I had to remove the Liquibase lock 2 or 3 times. It is now stuck with 8 migrations remaining. No error appears in the log. :-(

In ""databasechangelog"", the last one ""EXECUTED"" is ""v49.2024-03-26T10:23:12"". So it seems to be stuck on ""v49.2024-03-26T20:27:58 / metabase.db.custom_migrations.DeleteTruncateAuditLogTask"" (https://github.com/metabase/metabase/blob/release-x.49.x/resources/migrations/001_update_migrations.yaml#L5751)?

### To Reproduce

Upgrade from v0.48.13 to v0.49.17 --> 8 remaining Liquibase migrations. The Kubernetes readiness probe was raised to 5+ minutes, there is barely any data (very low activity on this env) in this PostgreSQL 13 database.

### Expected behavior

_No response_

### Logs

```Picked up JAVA_TOOL_OPTIONS: -XX:MaxRAMPercentage=40
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-21 11:55:24,058 INFO metabase.util :: Maximum memory available to JVM: 820.0 MB
2024-06-21 11:55:27,035 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-06-21 11:55:35,605 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
2024-06-21 11:55:35,616 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-06-21 11:55:35,622 INFO metabase.util :: Load driver :sql-jdbc took 91.0 ms
2024-06-21 11:55:35,622 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:35,813 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:35,852 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:38,428 INFO metabase.core ::
Metabase v0.49.17 (7e2b7bb)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-21 11:55:38,441 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-06-21 11:55:38,547 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

2024-06-21 11:55:38,652 INFO metabase.core :: Starting Metabase version v0.49.17 (7e2b7bb) ...
2024-06-21 11:55:38,656 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Linux"",
 ""os.version"" ""3.10.0-1160.108.1.el7.x86_64"",
 ""user.language"" ""en"",
 ""user.timezone"" ""Europe/Paris""}

2024-06-21 11:55:38,658 INFO metabase.plugins :: Loading plugins in /plugins...
2024-06-21 11:55:38,943 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-06-21 11:55:39,154 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-06-21 11:55:39,164 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-06-21 11:55:39,682 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-06-21 11:55:39,703 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-06-21 11:55:39,705 INFO util.files :: Extract file /modules/googleanalytics.metabase-driver.jar -> /plugins/googleanalytics.metabase-driver.jar
2024-06-21 11:55:39,718 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-06-21 11:55:39,811 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-06-21 11:55:39,819 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-06-21 11:55:39,880 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-06-21 11:55:40,065 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-06-21 11:55:40,070 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-06-21 11:55:40,071 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-06-21 11:55:40,523 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,525 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) ðŸšš
2024-06-21 11:55:40,532 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,624 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,647 INFO driver.impl :: Registered driver :mongo  ðŸšš
2024-06-21 11:55:40,660 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-06-21 11:55:40,661 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-06-21 11:55:40,662 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]
2024-06-21 11:55:40,726 INFO driver.impl :: Registered driver :googleanalytics  ðŸšš
2024-06-21 11:55:40,738 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,742 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) ðŸšš
2024-06-21 11:55:40,751 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,831 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) ðŸšš
2024-06-21 11:55:40,837 INFO driver.impl :: Registered driver :druid  ðŸšš
2024-06-21 11:55:40,841 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-06-21 11:55:40,842 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-06-21 11:55:40,842 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""]
2024-06-21 11:55:40,845 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) ðŸšš
2024-06-21 11:55:40,852 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-06-21 11:55:40,854 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-21 11:55:41,928 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…
2024-06-21 11:55:41,929 INFO db.setup :: Checking if a database downgrade is required...
2024-06-21 11:55:42,991 INFO db.setup :: Running Database Migrations...
2024-06-21 11:55:42,992 INFO db.setup :: Setting up Liquibase...
2024-06-21 11:55:43,420 INFO db.setup :: Liquibase is ready.
2024-06-21 11:55:43,422 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-21 11:55:44,255 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-06-21 11:55:44,264 INFO db.liquibase :: No migration lock found.
2024-06-21 11:55:44,735 INFO db.liquibase :: Running 8 migrations ...
2024-06-21 11:55:45,261 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-21 11:55:45,310 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-21 11:55:45,311 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-21 11:55:45,312 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-21 11:55:45,313 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-21 11:55:45,315 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec2-6596dcb48c-grrcg1718963745263'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-21 11:55:45,315 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-21 11:55:45,315 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-21 11:56:03,650 ERROR middleware.log :: GET /api/health 503 2.7 ms (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 11:56:03,651 ERROR middleware.log :: GET /api/health 503 2.7 ms (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 11:56:13,584 ERROR middleware.log :: GET /api/health 503 381.2 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 11:56:13,587 ERROR middleware.log :: GET /api/health 503 255.7 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 11:56:23,601 ERROR middleware.log :: GET /api/health 503 581.2 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

[...]

2024-06-21 12:04:03,577 ERROR middleware.log :: GET /api/health 503 315.0 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 12:04:03,578 ERROR middleware.log :: GET /api/health 503 200.6 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 12:04:03,584 ERROR middleware.log :: GET /api/health 503 184.2 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 12:04:03,595 INFO metabase.core :: Metabase Shutting Down ...
2024-06-21 12:04:03,596 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-06-21 12:04:03,630 WARN db.liquibase :: ()
2024-06-21 12:04:03,631 INFO metabase.core :: Metabase Shutdown COMPLETE
```

### Information about your Metabase installation

```JSON
- Metabase from the official Docker Image (running in Kubernetes)
- PostgreSQL 13
```


### Severity

Blocking an upgrade

### Additional context

_No response_",placaze,2024-06-21 10:18:56+00:00,['noahmoss'],2024-06-26 17:15:20+00:00,2024-06-26 14:17:08+00:00,https://github.com/metabase/metabase/issues/44528,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Postgres', None), ('.Unable to Reproduce', ''), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2182874555, 'issue_id': 2366218634, 'author': 'noahmoss', 'body': 'Hi @placaze - could you please enable trace logging for the Liquibase namespace?\r\n\r\n[Here are the docs](https://www.metabase.com/docs/latest/configuring-metabase/log-configuration#configuring-logging-level) for configuring logging. You can copy the default `log4j2.xml` file from those docs and add the line `<Logger name=""metabase.db.liquibase"" level=""TRACE""/>`. That should show us which migrations exactly it\'s trying to run when starting up.', 'created_at': datetime.datetime(2024, 6, 21, 14, 34, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182900255, 'issue_id': 2366218634, 'author': 'placaze', 'body': 'Hi!\r\n\r\nHere are the logs:\r\n```\r\n2024-06-21 16:43:33,340 INFO db.setup :: Verifying postgres Database Connection ...\r\n2024-06-21 16:43:35,193 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…\r\n2024-06-21 16:43:35,196 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-06-21 16:43:36,959 INFO db.setup :: Running Database Migrations...\r\n2024-06-21 16:43:36,960 INFO db.setup :: Setting up Liquibase...\r\n2024-06-21 16:43:37,741 INFO db.setup :: Liquibase is ready.\r\n2024-06-21 16:43:37,742 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-06-21 16:43:39,244 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-06-21 16:43:39,283 INFO db.liquibase :: No migration lock found.\r\n2024-06-21 16:43:40,042 INFO db.liquibase :: Running 8 migrations ...\r\n2024-06-21 16:43:40,043 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58\r\n2024-06-21 16:43:40,043 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00\r\n2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01\r\n2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02\r\n2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03\r\n2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00\r\n2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55\r\n2024-06-21 16:43:40,045 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34\r\n2024-06-21 16:43:40,996 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-21 16:43:41,074 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-21 16:43:41,075 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-21 16:43:41,076 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-21 16:43:41,079 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-21 16:43:41,080 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'metabase-pilotage-rec2-7bd89878d4-nwdqf1718981021000\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-21 16:43:41,080 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-21 16:43:41,080 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-21 16:43:42,609 ERROR middleware.log :: GET /api/health 503 295.2 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:43:42,610 ERROR middleware.log :: GET /api/health 503 278.8 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:43:51,546 ERROR middleware.log :: GET /api/health 503 380.6 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:43:52,611 ERROR middleware.log :: GET /api/health 503 422.3 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:43:52,612 ERROR middleware.log :: GET /api/health 503 228.5 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:44:02,611 ERROR middleware.log :: GET /api/health 503 475.5 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:44:02,611 ERROR middleware.log :: GET /api/health 503 448.8 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-21 16:44:12,609 ERROR middleware.log :: GET /api/health 503 311.3 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n```', 'created_at': datetime.datetime(2024, 6, 21, 14, 49, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183119348, 'issue_id': 2366218634, 'author': 'noahmoss', 'body': ""@placaze Thanks! Could you also upload the contents of the `databasechangelog` table if you're able? (Something like `\\COPY databasechangelog TO 'filename' CSV HEADER` would be fine, and then attach the file to a GH comment.) That'll help me understand the state of the migrations and to try to reproduce.\r\n\r\nI'm fairly puzzled by the fact that it's failing without an error. Sorry I don't have a quick fix for you."", 'created_at': datetime.datetime(2024, 6, 21, 17, 3, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183151624, 'issue_id': 2366218634, 'author': 'placaze', 'body': '@noahmoss I did it the quick way with DBeaver. If the `\\COPY` way is easier for you, just tell me.\r\n[databasechangelog_202406211921_metabase.csv](https://github.com/user-attachments/files/15930996/databasechangelog_202406211921_metabase.csv)', 'created_at': datetime.datetime(2024, 6, 21, 17, 25, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183359141, 'issue_id': 2366218634, 'author': 'noahmoss', 'body': '@placaze Is Metabase shutting down automatically or does it just hang and continue printing the `/api/health` calls until you shut it down? (edit - or is Kubernetes shutting it down after a timeout?)', 'created_at': datetime.datetime(2024, 6, 21, 19, 47, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183404818, 'issue_id': 2366218634, 'author': 'noahmoss', 'body': ""My best guess right now is that starting the Quartz scheduler ([this line](https://github.com/metabase/metabase/blob/master/src/metabase/db/custom_migrations.clj#L1323)) in that migration is hanging for some reason. The only way I can reproduce a similar log output is by having the thread sleep right before that call.\r\n\r\nI wouldn't recommend this for most migrations, but this one isn't particularly important (it's just a cleanup job). So if we don't have any more knowledge about the root cause, I'd try manually adding this to the `databasechangelog` so that Liquibase skips trying to execute it on startup. \r\n\r\nSomething like this:\r\n\r\n<details>\r\n<summary>SQL to run</summary>\r\n\r\n```\r\nINSERT INTO databasechangelog (\r\n    id, \r\n    author, \r\n    filename, \r\n    dateexecuted, \r\n    orderexecuted, \r\n    exectype, \r\n    md5sum, \r\n    description, \r\n    comments, \r\n    tag, \r\n    liquibase, \r\n    contexts, \r\n    labels, \r\n    deployment_id\r\n) VALUES (\r\n    'v49.2024-03-26T20:27:58', \r\n    'noahmoss', \r\n    'migrations/001_update_migrations.yaml', \r\n    CURRENT_TIMESTAMP, \r\n    (SELECT MAX(orderexecuted) + 1 FROM databasechangelog), \r\n    'MARK_RAN', \r\n    '9:469ae1b8af4545f2f48d9505fd34059d', \r\n    'customChange', \r\n    'Added 0.46.0 - Delete the truncate audit log task (renamed to truncate audit tables)', \r\n    '', \r\n    '4.25.1', \r\n    '', \r\n    '', \r\n    '8905042950'\r\n);\r\n```\r\n\r\n</details>\r\n\r\nIf you try that, let me know if it starts up successfully or not. There's at least one subsequent migration that also relies on being able to start the Quartz scheduler so if it still fails, that's a sign that there's a deeper issue."", 'created_at': datetime.datetime(2024, 6, 21, 20, 23, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183554706, 'issue_id': 2366218634, 'author': 'placaze', 'body': '> Is Metabase shutting down automatically or does it just hang and continue printing the `/api/health` calls until you shut it down? (edit - or is Kubernetes shutting it down after a timeout?)\r\n\r\nIt\'s Kubernetes that shut it down after 50 attempts with the readiness probe (50*10sec = 500sec = more than 8min).\r\n\r\n> If you try that, let me know if it starts up successfully or not. There\'s at least one subsequent migration that also relies on being able to start the Quartz scheduler so if it still fails, that\'s a sign that there\'s a deeper issue.\r\n\r\nYes, it works! ðŸ¥³ \r\n\r\n```\r\n2024-06-22 00:28:53,918 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-06-22 00:28:53,919 INFO db.setup :: Verifying postgres Database Connection ...\r\n2024-06-22 00:28:55,132 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…\r\n2024-06-22 00:28:55,132 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-06-22 00:28:56,125 INFO db.setup :: Running Database Migrations...\r\n2024-06-22 00:28:56,126 INFO db.setup :: Setting up Liquibase...\r\n2024-06-22 00:28:56,412 INFO db.setup :: Liquibase is ready.\r\n2024-06-22 00:28:56,413 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-06-22 00:28:57,191 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-06-22 00:28:57,199 INFO db.liquibase :: No migration lock found.\r\n2024-06-22 00:28:57,632 INFO db.liquibase :: Running 7 migrations ...\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55\r\n2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34\r\n\r\nUPDATE SUMMARY\r\nRun:                          7\r\nPreviously run:             265\r\nFiltered out:                49\r\n-------------------------------\r\nTotal change sets:          321\r\n\r\n\r\nFILTERED CHANGE SETS SUMMARY\r\nDBMS mismatch:               49\r\n\r\n2024-06-22 00:28:58,435 INFO db.liquibase :: Migration complete in 803.0 ms\r\n2024-06-22 00:28:58,436 INFO db.setup :: Database Migrations Current ...  âœ…\r\n2024-06-22 00:28:58,437 INFO metabase.util :: Database setup took 4.5 s\r\n2024-06-22 00:28:58,724 INFO driver.impl :: Initialisation du pilote :sql\r\n2024-06-22 00:28:58,725 INFO driver.impl :: Initialisation du pilote :sql-jdbc\r\n2024-06-22 00:28:58,725 INFO driver.impl :: Initialisation du pilote :h2\r\n2024-06-22 00:28:58,907 INFO util.files :: Extraire le fichier /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db\r\n2024-06-22 00:28:59,029 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-22 00:28:59,095 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-22 00:28:59,096 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-22 00:28:59,096 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-22 00:28:59,098 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-22 00:28:59,099 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'metabase-pilotage-rec2-7bd89878d4-5r9qv1719008939030\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-22 00:28:59,099 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-22 00:28:59,099 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-22 00:28:59,409 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec2-7bd89878d4-5r9qv1719008939030 paused.\r\n2024-06-22 00:28:59,409 INFO metabase.task :: Task scheduler initialized into standby mode.\r\n2024-06-22 00:28:59,410 INFO metabase.task :: Initializing task SyncDatabases\r\n2024-06-22 00:28:59,498 INFO task.sync-databases :: Updated default schedules for %d databases 0\r\n2024-06-22 00:28:59,499 INFO metabase.task :: Initializing task PersistRefresh\r\n2024-06-22 00:28:59,513 INFO driver.impl :: Initialisation du pilote :postgres\r\n```\r\n\r\n----\r\n\r\nI have a 2nd staging environment, and guess what? Same issue with this one. ðŸ™ \r\n\r\n**2nd environment**, stuck on ""v49.2024-03-26T20:27:58 / metabase.db.custom_migrations.DeleteTruncateAuditLogTask"" too:\r\n```\r\n2024-06-22 00:34:26,906 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n2024-06-22 00:34:26,908 INFO db.setup :: Verifying postgres Database Connection ...\r\n2024-06-22 00:34:28,098 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…\r\n2024-06-22 00:34:28,099 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-06-22 00:34:29,101 INFO db.setup :: Running Database Migrations...\r\n2024-06-22 00:34:29,101 INFO db.setup :: Setting up Liquibase...\r\n2024-06-22 00:34:29,311 INFO db.setup :: Liquibase is ready.\r\n2024-06-22 00:34:29,312 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-06-22 00:34:30,301 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-06-22 00:34:30,308 INFO db.liquibase :: No migration lock found.\r\n2024-06-22 00:34:30,796 INFO db.liquibase :: Running 62 migrations ...\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-000\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-003\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-004\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-005\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-006\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-007\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-008\r\n2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-009\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-010\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-011\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-012\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-013\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-014\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-015\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-017\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-018\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-020\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-021\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-023\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-024\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-026\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-027\r\n2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-029\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-030\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-032\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-033\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-036\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-037\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-039\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-040\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-042\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-043\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-045\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-046\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-048\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-049\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-059\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.2023-01-24T12:00:00\r\n2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.2024-01-22T11:50:00\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-22T11:51:00\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-22T11:52:00\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:26:40\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:30:00\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:56:40\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:59:12\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-02T11:27:49\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-02T11:28:36\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:01\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:02\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:03\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:04\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:05\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-09T13:55:26\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-03-26T10:23:12\r\n2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55\r\n2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34\r\n2024-06-22 00:34:33,211 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-22 00:34:33,221 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-22 00:34:33,221 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-22 00:34:33,222 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-22 00:34:33,225 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-22 00:34:33,225 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'metabase-pilotage-rec1-64fb9dd9fc-6fv571719009273212\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-22 00:34:33,226 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-22 00:34:33,226 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-22 00:34:48,704 ERROR middleware.log :: GET /api/health 503 2.6 ms (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-22 00:34:48,704 ERROR middleware.log :: GET /api/health 503 2.6 ms (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-22 00:34:58,639 ERROR middleware.log :: GET /api/health 503 750.9 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n\r\n2024-06-22 00:34:58,641 ERROR middleware.log :: GET /api/health 503 137.3 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\n```', 'created_at': datetime.datetime(2024, 6, 21, 22, 48, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183569523, 'issue_id': 2366218634, 'author': 'placaze', 'body': 'I don\'t know if it can help, but here is a threaddump of the JVM of my 2nd environment when it\'s stucked:\r\n[threaddump_metabase_stuck_liquibase.txt](https://github.com/user-attachments/files/15934363/threaddump_metabase_stuck_liquibase.txt)\r\n\r\nAnd the environment variables we are using:\r\n```\r\nMB_DB_CONNECTION_URI: ""postgresql://database.mycompany.fr:32000/database-rec2?ApplicationName=metabase-pilotage-rec2&currentSchema=metabase_pilotage,public&user=user_rec2&password=redacted&sslmode=verify-full&sslfactory=org.postgresql.ssl.DefaultJavaSSLFactory&socketTimeout=30""\r\nMB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 3\r\nMB_JDBC_DATA_WAREHOUSE_MAX_CONNECTION_POOL_SIZE: 10\r\n```', 'created_at': datetime.datetime(2024, 6, 21, 23, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183584117, 'issue_id': 2366218634, 'author': 'placaze', 'body': 'Oh, I think I just solved it! `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 3` is probably too low for this migration. I just changed to `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 10` and it now passed.\r\n\r\n<details>\r\n<summary><b>Logs with ""MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 10""</b></summary>\r\n\r\n```\r\n2024-06-22 01:25:19,555 INFO db.setup :: Verifying postgres Database Connection ...\r\n2024-06-22 01:25:20,871 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…\r\n2024-06-22 01:25:20,872 INFO db.setup :: Checking if a database downgrade is required...\r\n2024-06-22 01:25:22,488 INFO db.setup :: Running Database Migrations...\r\n2024-06-22 01:25:22,493 INFO db.setup :: Setting up Liquibase...\r\n2024-06-22 01:25:22,935 INFO db.setup :: Liquibase is ready.\r\n2024-06-22 01:25:22,936 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-06-22 01:25:23,695 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...\r\n2024-06-22 01:25:23,707 INFO db.liquibase :: No migration lock found.\r\n2024-06-22 01:25:24,238 INFO db.liquibase :: Running 8 migrations ...\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55\r\n2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34\r\n2024-06-22 01:25:24,728 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-22 01:25:24,765 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-22 01:25:24,765 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-22 01:25:24,766 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-22 01:25:24,768 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-22 01:25:24,772 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-22 01:25:24,772 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-22 01:25:24,772 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-22 01:25:24,879 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 started.\r\n2024-06-22 01:25:25,093 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 shutting down.\r\n2024-06-22 01:25:25,094 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 paused.\r\n2024-06-22 01:25:25,098 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 shutdown complete.\r\n\r\nUPDATE SUMMARY\r\nRun:                          8\r\nPreviously run:             264\r\nFiltered out:                49\r\n-------------------------------\r\nTotal change sets:          321\r\n\r\n\r\nFILTERED CHANGE SETS SUMMARY\r\nDBMS mismatch:               49\r\n\r\n2024-06-22 01:25:25,743 INFO db.liquibase :: Migration complete in 1.5 s\r\n2024-06-22 01:25:25,747 INFO db.setup :: Database Migrations Current ...  âœ…\r\n2024-06-22 01:25:25,747 INFO metabase.util :: Database setup took 6.2 s\r\n2024-06-22 01:25:26,067 INFO driver.impl :: Initialisation du pilote :sql\r\n2024-06-22 01:25:26,068 INFO driver.impl :: Initialisation du pilote :sql-jdbc\r\n2024-06-22 01:25:26,068 INFO driver.impl :: Initialisation du pilote :h2\r\n2024-06-22 01:25:26,244 INFO util.files :: Extraire le fichier /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db\r\n2024-06-22 01:25:26,281 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor\r\n2024-06-22 01:25:26,286 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl\r\n2024-06-22 01:25:26,286 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.\r\n2024-06-22 01:25:26,286 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).\r\n2024-06-22 01:25:26,286 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.\r\n2024-06-22 01:25:26,287 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) \'MetabaseScheduler\' with instanceId \'metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281\'\r\n  Scheduler class: \'org.quartz.core.QuartzScheduler\' - running locally.\r\n  NOT STARTED.\r\n  Currently in standby mode.\r\n  Number of jobs executed: 0\r\n  Using thread pool \'org.quartz.simpl.SimpleThreadPool\' - with 10 threads.\r\n  Using job-store \'org.quartz.impl.jdbcjobstore.JobStoreTX\' - which supports persistence. and is clustered.\r\n\r\n2024-06-22 01:25:26,287 INFO impl.StdSchedulerFactory :: Quartz scheduler \'MetabaseScheduler\' initialized from default resource file in Quartz package: \'quartz.properties\'\r\n2024-06-22 01:25:26,287 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2\r\n2024-06-22 01:25:26,764 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281 paused.\r\n2024-06-22 01:25:26,764 INFO metabase.task :: Task scheduler initialized into standby mode.\r\n2024-06-22 01:25:26,765 INFO metabase.task :: Initializing task SyncDatabases\r\n2024-06-22 01:25:26,937 INFO task.sync-databases :: Updated default schedules for %d databases 0\r\n2024-06-22 01:25:26,937 INFO metabase.task :: Initializing task PersistRefresh\r\n2024-06-22 01:25:26,993 INFO driver.impl :: Initialisation du pilote :postgres\r\n2024-06-22 01:25:27,012 INFO metabase.task :: Initializing task CheckForNewVersions\r\n2024-06-22 01:25:27,175 INFO metabase.task :: Initializing task PersistPrune\r\n2024-06-22 01:25:27,194 INFO metabase.task :: Initializing task SendAnonymousUsageStats\r\n2024-06-22 01:25:27,261 INFO metabase.task :: Initializing task ModelIndexValues\r\n2024-06-22 01:25:27,274 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers\r\n2024-06-22 01:25:27,411 INFO metabase.task :: Initializing task TruncateAuditTables\r\n2024-06-22 01:25:27,455 INFO metabase.task :: Initializing task SendPulses\r\n2024-06-22 01:25:27,500 INFO metabase.task :: Initializing task SendFollowUpEmails\r\n2024-06-22 01:25:27,624 INFO metabase.task :: Initializing task SendCreatorSentimentEmails\r\n2024-06-22 01:25:27,667 INFO metabase.task :: Initializing task TaskHistoryCleanup\r\n2024-06-22 01:25:27,760 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail\r\n2024-06-22 01:25:27,805 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281 started.\r\n2024-06-22 01:25:27,806 INFO metabase.task :: Task scheduler started\r\n2024-06-22 01:25:27,806 INFO metabase.core :: Initialisation de la base de donnÃ©es COMPLETE en 32.9 s\r\n```\r\n\r\n</details>\r\n\r\nI never had problems with a max pool size set to \'3\' before.\r\n\r\nDo you want me to close the issue or do you think it\'s interesting to investigate why so many connections to the database are needed for this migration?', 'created_at': datetime.datetime(2024, 6, 21, 23, 41, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186604260, 'issue_id': 2366218634, 'author': 'noahmoss', 'body': ""@placaze Good find! Definitely sounds plausible that a small collection pool would cause that to stall out. Did you have a specific reason for setting it to 3 originally?\r\n\r\nLet's keep the issue open for now â€”\xa0I'll have Metabase fully skip that migration going forward since it's not necessary starting in v50 (we're auto-deleting Quartz jobs that aren't found, instead of cleaning them up via migrations). I'll close this once I'm done with that."", 'created_at': datetime.datetime(2024, 6, 24, 13, 37, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191821628, 'issue_id': 2366218634, 'author': 'akashagarwal7', 'body': 'I had to increase the `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE` as well! Thanks @placaze.', 'created_at': datetime.datetime(2024, 6, 26, 14, 14, 13, tzinfo=datetime.timezone.utc)}]","noahmoss (Assginee) on (2024-06-21 14:34:24 UTC): Hi @placaze - could you please enable trace logging for the Liquibase namespace?

[Here are the docs](https://www.metabase.com/docs/latest/configuring-metabase/log-configuration#configuring-logging-level) for configuring logging. You can copy the default `log4j2.xml` file from those docs and add the line `<Logger name=""metabase.db.liquibase"" level=""TRACE""/>`. That should show us which migrations exactly it's trying to run when starting up.

placaze (Issue Creator) on (2024-06-21 14:49:01 UTC): Hi!

Here are the logs:
```
2024-06-21 16:43:33,340 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-21 16:43:35,193 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…
2024-06-21 16:43:35,196 INFO db.setup :: Checking if a database downgrade is required...
2024-06-21 16:43:36,959 INFO db.setup :: Running Database Migrations...
2024-06-21 16:43:36,960 INFO db.setup :: Setting up Liquibase...
2024-06-21 16:43:37,741 INFO db.setup :: Liquibase is ready.
2024-06-21 16:43:37,742 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-21 16:43:39,244 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-06-21 16:43:39,283 INFO db.liquibase :: No migration lock found.
2024-06-21 16:43:40,042 INFO db.liquibase :: Running 8 migrations ...
2024-06-21 16:43:40,043 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58
2024-06-21 16:43:40,043 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00
2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01
2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02
2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03
2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00
2024-06-21 16:43:40,044 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55
2024-06-21 16:43:40,045 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34
2024-06-21 16:43:40,996 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-21 16:43:41,074 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-21 16:43:41,075 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-21 16:43:41,076 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-21 16:43:41,079 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-21 16:43:41,080 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec2-7bd89878d4-nwdqf1718981021000'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-21 16:43:41,080 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-21 16:43:41,080 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-21 16:43:42,609 ERROR middleware.log :: GET /api/health 503 295.2 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:43:42,610 ERROR middleware.log :: GET /api/health 503 278.8 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:43:51,546 ERROR middleware.log :: GET /api/health 503 380.6 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:43:52,611 ERROR middleware.log :: GET /api/health 503 422.3 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:43:52,612 ERROR middleware.log :: GET /api/health 503 228.5 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:44:02,611 ERROR middleware.log :: GET /api/health 503 475.5 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:44:02,611 ERROR middleware.log :: GET /api/health 503 448.8 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-21 16:44:12,609 ERROR middleware.log :: GET /api/health 503 311.3 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}
```

noahmoss (Assginee) on (2024-06-21 17:03:13 UTC): @placaze Thanks! Could you also upload the contents of the `databasechangelog` table if you're able? (Something like `\COPY databasechangelog TO 'filename' CSV HEADER` would be fine, and then attach the file to a GH comment.) That'll help me understand the state of the migrations and to try to reproduce.

I'm fairly puzzled by the fact that it's failing without an error. Sorry I don't have a quick fix for you.

placaze (Issue Creator) on (2024-06-21 17:25:12 UTC): @noahmoss I did it the quick way with DBeaver. If the `\COPY` way is easier for you, just tell me.
[databasechangelog_202406211921_metabase.csv](https://github.com/user-attachments/files/15930996/databasechangelog_202406211921_metabase.csv)

noahmoss (Assginee) on (2024-06-21 19:47:34 UTC): @placaze Is Metabase shutting down automatically or does it just hang and continue printing the `/api/health` calls until you shut it down? (edit - or is Kubernetes shutting it down after a timeout?)

noahmoss (Assginee) on (2024-06-21 20:23:23 UTC): My best guess right now is that starting the Quartz scheduler ([this line](https://github.com/metabase/metabase/blob/master/src/metabase/db/custom_migrations.clj#L1323)) in that migration is hanging for some reason. The only way I can reproduce a similar log output is by having the thread sleep right before that call.

I wouldn't recommend this for most migrations, but this one isn't particularly important (it's just a cleanup job). So if we don't have any more knowledge about the root cause, I'd try manually adding this to the `databasechangelog` so that Liquibase skips trying to execute it on startup. 

Something like this:

<details>
<summary>SQL to run</summary>

```
INSERT INTO databasechangelog (
    id, 
    author, 
    filename, 
    dateexecuted, 
    orderexecuted, 
    exectype, 
    md5sum, 
    description, 
    comments, 
    tag, 
    liquibase, 
    contexts, 
    labels, 
    deployment_id
) VALUES (
    'v49.2024-03-26T20:27:58', 
    'noahmoss', 
    'migrations/001_update_migrations.yaml', 
    CURRENT_TIMESTAMP, 
    (SELECT MAX(orderexecuted) + 1 FROM databasechangelog), 
    'MARK_RAN', 
    '9:469ae1b8af4545f2f48d9505fd34059d', 
    'customChange', 
    'Added 0.46.0 - Delete the truncate audit log task (renamed to truncate audit tables)', 
    '', 
    '4.25.1', 
    '', 
    '', 
    '8905042950'
);
```

</details>

If you try that, let me know if it starts up successfully or not. There's at least one subsequent migration that also relies on being able to start the Quartz scheduler so if it still fails, that's a sign that there's a deeper issue.

placaze (Issue Creator) on (2024-06-21 22:48:17 UTC): It's Kubernetes that shut it down after 50 attempts with the readiness probe (50*10sec = 500sec = more than 8min).


Yes, it works! ðŸ¥³ 

```
2024-06-22 00:28:53,918 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-06-22 00:28:53,919 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-22 00:28:55,132 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…
2024-06-22 00:28:55,132 INFO db.setup :: Checking if a database downgrade is required...
2024-06-22 00:28:56,125 INFO db.setup :: Running Database Migrations...
2024-06-22 00:28:56,126 INFO db.setup :: Setting up Liquibase...
2024-06-22 00:28:56,412 INFO db.setup :: Liquibase is ready.
2024-06-22 00:28:56,413 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-22 00:28:57,191 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-06-22 00:28:57,199 INFO db.liquibase :: No migration lock found.
2024-06-22 00:28:57,632 INFO db.liquibase :: Running 7 migrations ...
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55
2024-06-22 00:28:57,633 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34

UPDATE SUMMARY
Run:                          7
Previously run:             265
Filtered out:                49
-------------------------------
Total change sets:          321


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               49

2024-06-22 00:28:58,435 INFO db.liquibase :: Migration complete in 803.0 ms
2024-06-22 00:28:58,436 INFO db.setup :: Database Migrations Current ...  âœ…
2024-06-22 00:28:58,437 INFO metabase.util :: Database setup took 4.5 s
2024-06-22 00:28:58,724 INFO driver.impl :: Initialisation du pilote :sql
2024-06-22 00:28:58,725 INFO driver.impl :: Initialisation du pilote :sql-jdbc
2024-06-22 00:28:58,725 INFO driver.impl :: Initialisation du pilote :h2
2024-06-22 00:28:58,907 INFO util.files :: Extraire le fichier /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db
2024-06-22 00:28:59,029 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-22 00:28:59,095 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-22 00:28:59,096 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-22 00:28:59,096 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-22 00:28:59,098 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-22 00:28:59,099 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec2-7bd89878d4-5r9qv1719008939030'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-22 00:28:59,099 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-22 00:28:59,099 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-22 00:28:59,409 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec2-7bd89878d4-5r9qv1719008939030 paused.
2024-06-22 00:28:59,409 INFO metabase.task :: Task scheduler initialized into standby mode.
2024-06-22 00:28:59,410 INFO metabase.task :: Initializing task SyncDatabases
2024-06-22 00:28:59,498 INFO task.sync-databases :: Updated default schedules for %d databases 0
2024-06-22 00:28:59,499 INFO metabase.task :: Initializing task PersistRefresh
2024-06-22 00:28:59,513 INFO driver.impl :: Initialisation du pilote :postgres
```

----

I have a 2nd staging environment, and guess what? Same issue with this one. ðŸ™ 

**2nd environment**, stuck on ""v49.2024-03-26T20:27:58 / metabase.db.custom_migrations.DeleteTruncateAuditLogTask"" too:
```
2024-06-22 00:34:26,906 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-06-22 00:34:26,908 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-22 00:34:28,098 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…
2024-06-22 00:34:28,099 INFO db.setup :: Checking if a database downgrade is required...
2024-06-22 00:34:29,101 INFO db.setup :: Running Database Migrations...
2024-06-22 00:34:29,101 INFO db.setup :: Setting up Liquibase...
2024-06-22 00:34:29,311 INFO db.setup :: Liquibase is ready.
2024-06-22 00:34:29,312 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-22 00:34:30,301 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-06-22 00:34:30,308 INFO db.liquibase :: No migration lock found.
2024-06-22 00:34:30,796 INFO db.liquibase :: Running 62 migrations ...
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-000
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-003
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-004
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-005
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-006
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-007
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-008
2024-06-22 00:34:30,796 TRACE db.liquibase :: To run migration v49.00-009
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-010
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-011
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-012
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-013
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-014
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-015
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-017
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-018
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-020
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-021
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-023
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-024
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-026
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-027
2024-06-22 00:34:30,797 TRACE db.liquibase :: To run migration v49.00-029
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-030
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-032
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-033
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-036
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-037
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-039
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-040
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-042
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-043
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-045
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-046
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-048
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-049
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.00-059
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.2023-01-24T12:00:00
2024-06-22 00:34:30,798 TRACE db.liquibase :: To run migration v49.2024-01-22T11:50:00
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-22T11:51:00
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-22T11:52:00
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:26:40
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:30:00
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:56:40
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-01-29T19:59:12
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-02T11:27:49
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-02T11:28:36
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:01
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:02
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:03
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:04
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-07T21:52:05
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-02-09T13:55:26
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-03-26T10:23:12
2024-06-22 00:34:30,799 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55
2024-06-22 00:34:30,800 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34
2024-06-22 00:34:33,211 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-22 00:34:33,221 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-22 00:34:33,221 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-22 00:34:33,222 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-22 00:34:33,225 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-22 00:34:33,225 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec1-64fb9dd9fc-6fv571719009273212'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-22 00:34:33,226 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-22 00:34:33,226 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-22 00:34:48,704 ERROR middleware.log :: GET /api/health 503 2.6 ms (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-22 00:34:48,704 ERROR middleware.log :: GET /api/health 503 2.6 ms (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-22 00:34:58,639 ERROR middleware.log :: GET /api/health 503 750.9 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}

2024-06-22 00:34:58,641 ERROR middleware.log :: GET /api/health 503 137.3 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}
```

placaze (Issue Creator) on (2024-06-21 23:14:06 UTC): I don't know if it can help, but here is a threaddump of the JVM of my 2nd environment when it's stucked:
[threaddump_metabase_stuck_liquibase.txt](https://github.com/user-attachments/files/15934363/threaddump_metabase_stuck_liquibase.txt)

And the environment variables we are using:
```
MB_DB_CONNECTION_URI: ""postgresql://database.mycompany.fr:32000/database-rec2?ApplicationName=metabase-pilotage-rec2&currentSchema=metabase_pilotage,public&user=user_rec2&password=redacted&sslmode=verify-full&sslfactory=org.postgresql.ssl.DefaultJavaSSLFactory&socketTimeout=30""
MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 3
MB_JDBC_DATA_WAREHOUSE_MAX_CONNECTION_POOL_SIZE: 10
```

placaze (Issue Creator) on (2024-06-21 23:41:05 UTC): Oh, I think I just solved it! `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 3` is probably too low for this migration. I just changed to `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 10` and it now passed.

<details>
<summary><b>Logs with ""MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE: 10""</b></summary>

```
2024-06-22 01:25:19,555 INFO db.setup :: Verifying postgres Database Connection ...
2024-06-22 01:25:20,871 INFO db.setup :: Successfully verified PostgreSQL 13.9 application database connection. âœ…
2024-06-22 01:25:20,872 INFO db.setup :: Checking if a database downgrade is required...
2024-06-22 01:25:22,488 INFO db.setup :: Running Database Migrations...
2024-06-22 01:25:22,493 INFO db.setup :: Setting up Liquibase...
2024-06-22 01:25:22,935 INFO db.setup :: Liquibase is ready.
2024-06-22 01:25:22,936 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-06-22 01:25:23,695 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-06-22 01:25:23,707 INFO db.liquibase :: No migration lock found.
2024-06-22 01:25:24,238 INFO db.liquibase :: Running 8 migrations ...
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-03-26T20:27:58
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:00
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:01
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:02
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-04-09T10:00:03
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-07T10:00:00
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-20T20:37:55
2024-06-22 01:25:24,239 TRACE db.liquibase :: To run migration v49.2024-05-20T20:38:34
2024-06-22 01:25:24,728 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-22 01:25:24,765 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-22 01:25:24,765 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-22 01:25:24,766 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-22 01:25:24,768 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-22 01:25:24,772 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-22 01:25:24,772 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-22 01:25:24,772 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-22 01:25:24,879 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 started.
2024-06-22 01:25:25,093 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 shutting down.
2024-06-22 01:25:25,094 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 paused.
2024-06-22 01:25:25,098 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012324729 shutdown complete.

UPDATE SUMMARY
Run:                          8
Previously run:             264
Filtered out:                49
-------------------------------
Total change sets:          321


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               49

2024-06-22 01:25:25,743 INFO db.liquibase :: Migration complete in 1.5 s
2024-06-22 01:25:25,747 INFO db.setup :: Database Migrations Current ...  âœ…
2024-06-22 01:25:25,747 INFO metabase.util :: Database setup took 6.2 s
2024-06-22 01:25:26,067 INFO driver.impl :: Initialisation du pilote :sql
2024-06-22 01:25:26,068 INFO driver.impl :: Initialisation du pilote :sql-jdbc
2024-06-22 01:25:26,068 INFO driver.impl :: Initialisation du pilote :h2
2024-06-22 01:25:26,244 INFO util.files :: Extraire le fichier /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db
2024-06-22 01:25:26,281 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-06-22 01:25:26,286 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-06-22 01:25:26,286 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-06-22 01:25:26,286 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-06-22 01:25:26,286 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-06-22 01:25:26,287 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-06-22 01:25:26,287 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-06-22 01:25:26,287 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-06-22 01:25:26,764 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281 paused.
2024-06-22 01:25:26,764 INFO metabase.task :: Task scheduler initialized into standby mode.
2024-06-22 01:25:26,765 INFO metabase.task :: Initializing task SyncDatabases
2024-06-22 01:25:26,937 INFO task.sync-databases :: Updated default schedules for %d databases 0
2024-06-22 01:25:26,937 INFO metabase.task :: Initializing task PersistRefresh
2024-06-22 01:25:26,993 INFO driver.impl :: Initialisation du pilote :postgres
2024-06-22 01:25:27,012 INFO metabase.task :: Initializing task CheckForNewVersions
2024-06-22 01:25:27,175 INFO metabase.task :: Initializing task PersistPrune
2024-06-22 01:25:27,194 INFO metabase.task :: Initializing task SendAnonymousUsageStats
2024-06-22 01:25:27,261 INFO metabase.task :: Initializing task ModelIndexValues
2024-06-22 01:25:27,274 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers
2024-06-22 01:25:27,411 INFO metabase.task :: Initializing task TruncateAuditTables
2024-06-22 01:25:27,455 INFO metabase.task :: Initializing task SendPulses
2024-06-22 01:25:27,500 INFO metabase.task :: Initializing task SendFollowUpEmails
2024-06-22 01:25:27,624 INFO metabase.task :: Initializing task SendCreatorSentimentEmails
2024-06-22 01:25:27,667 INFO metabase.task :: Initializing task TaskHistoryCleanup
2024-06-22 01:25:27,760 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail
2024-06-22 01:25:27,805 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_metabase-pilotage-rec1-6585f48cdf-tfr4d1719012326281 started.
2024-06-22 01:25:27,806 INFO metabase.task :: Task scheduler started
2024-06-22 01:25:27,806 INFO metabase.core :: Initialisation de la base de donnÃ©es COMPLETE en 32.9 s
```

</details>

I never had problems with a max pool size set to '3' before.

Do you want me to close the issue or do you think it's interesting to investigate why so many connections to the database are needed for this migration?

noahmoss (Assginee) on (2024-06-24 13:37:04 UTC): @placaze Good find! Definitely sounds plausible that a small collection pool would cause that to stall out. Did you have a specific reason for setting it to 3 originally?

Let's keep the issue open for now â€”Â I'll have Metabase fully skip that migration going forward since it's not necessary starting in v50 (we're auto-deleting Quartz jobs that aren't found, instead of cleaning them up via migrations). I'll close this once I'm done with that.

akashagarwal7 on (2024-06-26 14:14:13 UTC): I had to increase the `MB_APPLICATION_DB_MAX_CONNECTION_POOL_SIZE` as well! Thanks @placaze.

"
2366087833,issue,open,,"Static embedding: Drag selection available on charts, but shouldn't be, since there is no drill-down.","### Describe the bug

Static embeds and public dashboards don't support drill-down. Drag selection should not be available. 

### To Reproduce

1. Go to https://www.metabase.com/gallery/uefa-euro-2024-stats-dashboard
2. Open 2nd tab (Game Stats)
3. Scroll down to Game Pressure
4. Drag select on the chart

<img width=""1265"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24216/2d95086a-76a5-43a3-b8d4-c1cd9bf3306e"">



### Expected behavior

No drag selection:



### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 50.6
```


### Severity

Confusing, but not blocking

### Additional context

_No response_",albertoperdomo,2024-06-21 09:09:19+00:00,[],2024-06-24 15:08:45+00:00,,https://github.com/metabase/metabase/issues/44525,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Sharing/Public', '')]","[{'comment_id': 2186798888, 'issue_id': 2366087833, 'author': 'deniskaber', 'body': ""This looks like echarts migration issue (#37306). Most likely logic in [canBrush](https://github.com/metabase/metabase/blob/172c7cc3afae69dad0a47a85227467cc63b995b5/frontend/src/metabase/visualizations/visualizations/CartesianChart/events.ts#L329) function gives a wrong result for provided [example dashboard](https://metabase-public.metabaseapp.com/public/dashboard/20b887fc-4ebf-47f7-95d7-8e907c338059?tab=133-overview&game=19032613&team=18706&season=22842) in public sharing context.\r\n\r\nReassigning this to DashViz.\r\n\r\nAlso brushing this chart leads to uncaught exeption:\r\n```\r\nevents.ts:535 Uncaught \r\nTypeError: Cannot read properties of undefined (reading 'coordRange')\r\n    at ms (events.ts:535:32)\r\n    at t.handler (use-chart-events.ts:170:29)\r\n    at e.trigger (Eventful.js:103:33)\r\n    at t.<anonymous> (echarts.js:778:14)\r\n    at e.trigger (Eventful.js:103:33)\r\n    at t.f (echarts.js:1418:23)\r\n    at t.dispatchAction (echarts.js:949:22)\r\n    at t._onBrush (BrushView.js:101:34)\r\n    at e.trigger (Eventful.js:103:33)\r\n    at W (BrushController.js:329:14)\r\n```"", 'created_at': datetime.datetime(2024, 6, 24, 15, 5, 25, tzinfo=datetime.timezone.utc)}]","deniskaber on (2024-06-24 15:05:25 UTC): This looks like echarts migration issue (#37306). Most likely logic in [canBrush](https://github.com/metabase/metabase/blob/172c7cc3afae69dad0a47a85227467cc63b995b5/frontend/src/metabase/visualizations/visualizations/CartesianChart/events.ts#L329) function gives a wrong result for provided [example dashboard](https://metabase-public.metabaseapp.com/public/dashboard/20b887fc-4ebf-47f7-95d7-8e907c338059?tab=133-overview&game=19032613&team=18706&season=22842) in public sharing context.

Reassigning this to DashViz.

Also brushing this chart leads to uncaught exeption:
```
events.ts:535 Uncaught 
TypeError: Cannot read properties of undefined (reading 'coordRange')
    at ms (events.ts:535:32)
    at t.handler (use-chart-events.ts:170:29)
    at e.trigger (Eventful.js:103:33)
    at t.<anonymous> (echarts.js:778:14)
    at e.trigger (Eventful.js:103:33)
    at t.f (echarts.js:1418:23)
    at t.dispatchAction (echarts.js:949:22)
    at t._onBrush (BrushView.js:101:34)
    at e.trigger (Eventful.js:103:33)
    at W (BrushController.js:329:14)
```

"
2365310520,issue,closed,completed,v50: Foreign keys no longer work with MongoDB,"### Describe the bug

Questions that leverage foreign keys are no longer working as of Metabase 50, but were working well in Metabase 49.



### To Reproduce

Repro steps:
- create two collections
  - collectionA: `{ _id: ObjectId, bID: ObjectId, value: string }`
  - collectionB: `{ _id: ObjectId, value: string }`
- in metabase admin, set `collectionA.bID` as a foreign key to `collectionB._id`
- ask a new question: count of rows for collectionA where collectionB.value == 'foo'

### Expected behavior

This worked well in Metabase 49, but regressed in Metabase 50. It would answer the question.

Now I'm getting: `:mongo driver does not support foreign keys.`

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-LTS"",
    ""java.vendor"": ""Red Hat, Inc."",
    ""java.vendor.url"": ""https://www.redhat.com/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.109-99.92.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

pretty darn significant for mongodb users

### Additional context

_No response_",arasmussen,2024-06-20 21:29:51+00:00,['lbrdnk'],2024-08-28 02:08:52+00:00,2024-07-11 15:42:07+00:00,https://github.com/metabase/metabase/issues/44511,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2181609463, 'issue_id': 2365310520, 'author': 'paoliniluis', 'body': ""hey sorry about that. I'm flagging this as a regression"", 'created_at': datetime.datetime(2024, 6, 20, 21, 43, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181620082, 'issue_id': 2365310520, 'author': 'arasmussen', 'body': 'thanks for the quick response! I also tried downgrading back to v49 with `migrate down` and it corrupted my database file ðŸ˜“ but that\'s on me for not backing it up\r\n\r\ncould be good to add an ""are you sure? have you backed up your db?"" step to migrate down if migrating down isn\'t well supported', 'created_at': datetime.datetime(2024, 6, 20, 21, 53, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181956361, 'issue_id': 2365310520, 'author': 'qnkhuat', 'body': '@arasmussen downgrade should work. Could you file a bug describing how corrupted your db is after the downgrade?\r\n\r\nBut yeah, you should backup before doing any kind of migration.', 'created_at': datetime.datetime(2024, 6, 21, 3, 58, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229421695, 'issue_id': 2365310520, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 20, 58, 20, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-20 21:43:32 UTC): hey sorry about that. I'm flagging this as a regression

arasmussen (Issue Creator) on (2024-06-20 21:53:24 UTC): thanks for the quick response! I also tried downgrading back to v49 with `migrate down` and it corrupted my database file ðŸ˜“ but that's on me for not backing it up

could be good to add an ""are you sure? have you backed up your db?"" step to migrate down if migrating down isn't well supported

qnkhuat on (2024-06-21 03:58:50 UTC): @arasmussen downgrade should work. Could you file a bug describing how corrupted your db is after the downgrade?

But yeah, you should backup before doing any kind of migration.

github-actions[bot] on (2024-07-15 20:58:20 UTC): ðŸš€ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2365218158,issue,closed,completed,Set `useLocalSessionState` and/or `alwaysSendSetIsolation` connection properties for MySQL/MariaDB,"https://dev.mysql.com/doc/connector-j/en/connector-j-connp-props-performance-extensions.html#cj-conn-prop_alwaysSendSetIsolation

If we enable this then the driver, when you call `setTransactionIsolation()` (which we do every time we use a DW connection, i.e. every time we run a query) the driver records the value you set it to in memory and subsequent calls are no-ops if the value won't change. 

This avoids having to actually hit the database and execute `SET TRANSACTION ISOLATION ...` on every single query we run",camsaul,2024-06-20 20:34:24+00:00,[],2024-06-24 11:45:08+00:00,2024-06-21 17:04:23+00:00,https://github.com/metabase/metabase/issues/44507,"[('.Performance', ''), ('Database/MySQL', None), ('Querying/Processor', ''), ('.Backend', '')]",[],
2365217144,issue,closed,completed,Issue processing Mongo BigDecimal when values are less than 0,"### Describe the bug

I'm working on a collection that contains several BigDecimal columns. Occasionally, there are negative values, for example -0.02. This results in a the following error:  :error ""Negative zero can not be converted to a BigDecimal"". The error occurs during the initial table analysis, as well as attempting to visualize the data.



### To Reproduce

Load the following records into a mongodb collection:
{""_id"":{""$oid"":""765f669ee10537b1f9251821""},""recType"":""driver"",""status"":""active"",""rate"":{""rateType"":""driver"",""basePerMinRate"":{""$numberDecimal"":""0.72""},""day"":{""percentage"":{""$numberDecimal"":""-0.01""}},""evening"":{""percentage"":{""$numberDecimal"":""0.02""}},""night"":{""percentage"":{""$numberDecimal"":""1.87""}},""blocked"":{""percentage"":{""$numberDecimal"":""1.33""}}},""audit"":{""createdTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedBy"":{""$oid"":""4461766566467265656d616e""}}}
{""_id"":{""$oid"":""765f669ee10537b1f9251822""},""recType"":""driver"",""status"":""active"",""rate"":{""rateType"":""driver"",""basePerMinRate"":{""$numberDecimal"":""0.63""},""day"":{""percentage"":{""$numberDecimal"":""0.03""}},""evening"":{""percentage"":{""$numberDecimal"":""0.0""}},""night"":{""percentage"":{""$numberDecimal"":""2.66""}},""blocked"":{""percentage"":{""$numberDecimal"":""1.04""}}},""audit"":{""createdTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedBy"":{""$oid"":""4461766566467265656d616e""}}}
{""_id"":{""$oid"":""765f669ee10537b1f9251823""},""recType"":""driver"",""status"":""active"",""rate"":{""rateType"":""driver"",""basePerMinRate"":{""$numberDecimal"":""0.44""},""day"":{""percentage"":{""$numberDecimal"":""-0.12""}},""evening"":{""percentage"":{""$numberDecimal"":""0.09""}},""night"":{""percentage"":{""$numberDecimal"":""2.87""}},""blocked"":{""percentage"":{""$numberDecimal"":""1.25""}}},""audit"":{""createdTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedBy"":{""$oid"":""4461766566467265656d616e""}}}
{""_id"":{""$oid"":""765f669ee10537b0b2b4b061""},""recType"":""driver"",""status"":""active"",""rate"":{""rateType"":""driver"",""basePerMinRate"":{""$numberDecimal"":""0.51""},""day"":{""percentage"":{""$numberDecimal"":""-0.07""}},""evening"":{""percentage"":{""$numberDecimal"":""-0.03""}},""night"":{""percentage"":{""$numberDecimal"":""2.09""}},""blocked"":{""percentage"":{""$numberDecimal"":""1.21""}}},""audit"":{""createdTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedBy"":{""$oid"":""4461766566467265656d616e""}}}
{""_id"":{""$oid"":""765f669ee10537b0b2b4b062""},""recType"":""driver"",""status"":""active"",""rate"":{""rateType"":""driver"",""basePerMinRate"":{""$numberDecimal"":""0.61""},""day"":{""percentage"":{""$numberDecimal"":""0.01""}},""evening"":{""percentage"":{""$numberDecimal"":""0.09""}},""night"":{""percentage"":{""$numberDecimal"":""1.75""}},""blocked"":{""percentage"":{""$numberDecimal"":""1.03""}}},""audit"":{""createdTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedTS"":{""$date"":""2024-05-13T00:00:00.000Z""},""updatedBy"":{""$oid"":""4461766566467265656d616e""}}}

Attempt to create the metadata and you will see the error

### Expected behavior

The system should be able to use a BigDecimal value of -0.02 for example.

### Logs

.41baa84f-a01f-4586-ac50-d00ca1b24dc1] 2024-06-20T16:08:34-04:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Negative zero can not be converted to a BigDecimal
{:database_id 2,
 :started_at #t ""2024-06-20T16:08:33.877420-04:00[America/New_York]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error reducing result rows: Negative zero can not be converted to a BigDecimal"",
   :stacktrace
   [""--> query_processor.pipeline$_STAR_reduce_STAR_$fn__56619.invoke(pipeline.clj:65)""
    ""query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:62)""
    ""query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49)""
    ""query_processor.pipeline$_STAR_run_STAR_$respond__56626.invoke(pipeline.clj:86)""
    ""driver.mongo.execute$reduce_results.invokeStatic(execute.clj:177)""
    ""driver.mongo.execute$reduce_results.invoke(execute.clj:171)""
    ""driver.mongo.execute$execute_reducible_query.invokeStatic(execute.clj:207)""
    ""driver.mongo.execute$execute_reducible_query.invoke(execute.clj:182)""
    ""driver.mongo$fn__118236$f__114486__auto____118237.invoke(mongo.clj:314)""
    ""driver.mongo.connection$do_with_mongo_client$fn__114477.invoke(connection.clj:94)""
    ""util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)""
    ""util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)""
    ""driver.mongo.connection$do_with_mongo_client.invokeStatic(connection.clj:89)""
    ""driver.mongo.connection$do_with_mongo_client.invoke(connection.clj:85)""
    ""driver.mongo$fn__118236.invokeStatic(mongo.clj:313)""
    ""driver.mongo$fn__118236.invoke(mongo.clj:310)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:88)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:81)""
    ""query_processor.execute$run.invokeStatic(execute.clj:60)""
    ""query_processor.execute$run.invoke(execute.clj:54)""
    

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""22.0.1"",
    ""java.vendor"": ""Homebrew"",
    ""java.vendor.url"": ""https://github.com/Homebrew/homebrew-core/issues"",
    ""java.version"": ""22.0.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""22.0.1"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/New_York""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking my usage of Metabase entirely

### Additional context

If you remove the negative sign from the sample data I provided, metabase will work fine.",yohfreeman,2024-06-20 20:33:40+00:00,['lbrdnk'],2024-08-28 02:08:51+00:00,2024-06-27 15:33:39+00:00,https://github.com/metabase/metabase/issues/44506,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('Querying/Processor', ''), ('.Team/Querying', '')]","[{'comment_id': 2186045430, 'issue_id': 2365217144, 'author': 'lbrdnk', 'body': 'Hey [yohfreeman](https://github.com/yohfreeman)! Thanks for the report.\r\n\r\nI\'m unable to reproduce with the provided data. I have a clue what could be causing the issue, but I\'d like to make sure the error you are seeing is an instance of what I suspect.\r\n\r\n_Could you confirm that you are hitting the exception on the provided data?_ I\'ve found no problem working with the negative close to zero values. I\'ve even tried to add minus to `0.02` in the data provided, as the `-0.02` is not present.\r\n\r\n---\r\n\r\nIn case of answer to my question is negative, could you confirm the data you have, or rather the query that you run, may contain _negative zero_, ie. `{""$numberDecimal"":""-0.0""}}`, in the results?', 'created_at': datetime.datetime(2024, 6, 24, 9, 33, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186845295, 'issue_id': 2365217144, 'author': 'yohfreeman', 'body': '@lbrdnk : My apologies, you are correct there was a ""-0.0"" in my original dataset. I do appreciate you pointing me in the correct direction.', 'created_at': datetime.datetime(2024, 6, 24, 15, 27, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186961505, 'issue_id': 2365217144, 'author': 'lbrdnk', 'body': 'Thanks for the confirmation. When the linked PR is merged and released, you should be able to work also with data containing negative zero.', 'created_at': datetime.datetime(2024, 6, 24, 16, 26, 4, tzinfo=datetime.timezone.utc)}]","lbrdnk (Assginee) on (2024-06-24 09:33:33 UTC): Hey [yohfreeman](https://github.com/yohfreeman)! Thanks for the report.

I'm unable to reproduce with the provided data. I have a clue what could be causing the issue, but I'd like to make sure the error you are seeing is an instance of what I suspect.

_Could you confirm that you are hitting the exception on the provided data?_ I've found no problem working with the negative close to zero values. I've even tried to add minus to `0.02` in the data provided, as the `-0.02` is not present.

---

In case of answer to my question is negative, could you confirm the data you have, or rather the query that you run, may contain _negative zero_, ie. `{""$numberDecimal"":""-0.0""}}`, in the results?

yohfreeman (Issue Creator) on (2024-06-24 15:27:21 UTC): @lbrdnk : My apologies, you are correct there was a ""-0.0"" in my original dataset. I do appreciate you pointing me in the correct direction.

lbrdnk (Assginee) on (2024-06-24 16:26:04 UTC): Thanks for the confirmation. When the linked PR is merged and released, you should be able to work also with data containing negative zero.

"
2365129819,issue,open,,Pivot Table With No 'Rows' Does Not Render,"### Describe the bug

Moving all fields out of Rows and into Columns (leaving the Measures alone) results in no table being rendered.
![image](https://github.com/metabase/metabase/assets/21064735/751deb36-4fc3-4a71-ace8-679316ad6ce7)


### To Reproduce

1. Create a new question with:
- Products
- Summarize Count of Rows
- By 'Category' and 'Created At: Year'
2. Change the visualization to 'Pivot'
3. In the Pivot Table Options, move the field from Rows to Columns

### Expected behavior

The Table should render, as it does when you have all of the fields in Rows and none in Columns.
eg:
![image](https://github.com/metabase/metabase/assets/21064735/ad14d4f4-e493-4beb-bbd6-82d0742b3d6b)

Or, it should present a warning explaining why it will not render (perhaps this is somewhat expected behaviour, as the table could become very large horizontally in such a configuration).


### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest from Master (after v50), though it's highly likely this exists in many versions back.
```


### Severity

P2

### Additional context

_No response_",adam-james-v,2024-06-20 19:42:08+00:00,[],2025-02-04 20:31:55+00:00,,https://github.com/metabase/metabase/issues/44500,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2273959821, 'issue_id': 2365129819, 'author': 'cdeweyx', 'body': 'Reproduced [in stats](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoxLCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJzb3VyY2UtdGFibGUiOjMsImFnZ3JlZ2F0aW9uIjpbWyJjb3VudCJdXSwiYnJlYWtvdXQiOltbImZpZWxkIiwxNix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSxbImZpZWxkIiwyOSx7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWUiLCJ0ZW1wb3JhbC11bml0IjoibW9udGgifV1dfX0sImRpc3BsYXkiOiJwaXZvdCIsImRpc3BsYXlJc0xvY2tlZCI6dHJ1ZSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6eyJwaXZvdF90YWJsZS5jb2x1bW5fc3BsaXQiOnsicm93cyI6W10sImNvbHVtbnMiOltbImZpZWxkIiwyOSx7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWUiLCJ0ZW1wb3JhbC11bml0IjoibW9udGgifV0sWyJmaWVsZCIsMTYseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV1dLCJ2YWx1ZXMiOltbImFnZ3JlZ2F0aW9uIiwwXV19LCJwaXZvdF90YWJsZS5jb2x1bW5fd2lkdGhzIjp7ImxlZnRIZWFkZXJXaWR0aHMiOltdLCJ0b3RhbExlZnRIZWFkZXJXaWR0aHMiOjAsInZhbHVlSGVhZGVyV2lkdGhzIjp7fX19LCJ0eXBlIjoicXVlc3Rpb24ifQ==).', 'created_at': datetime.datetime(2024, 8, 7, 17, 21, 48, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-07 17:21:48 UTC): Reproduced [in stats](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoxLCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJzb3VyY2UtdGFibGUiOjMsImFnZ3JlZ2F0aW9uIjpbWyJjb3VudCJdXSwiYnJlYWtvdXQiOltbImZpZWxkIiwxNix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSxbImZpZWxkIiwyOSx7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWUiLCJ0ZW1wb3JhbC11bml0IjoibW9udGgifV1dfX0sImRpc3BsYXkiOiJwaXZvdCIsImRpc3BsYXlJc0xvY2tlZCI6dHJ1ZSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6eyJwaXZvdF90YWJsZS5jb2x1bW5fc3BsaXQiOnsicm93cyI6W10sImNvbHVtbnMiOltbImZpZWxkIiwyOSx7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWUiLCJ0ZW1wb3JhbC11bml0IjoibW9udGgifV0sWyJmaWVsZCIsMTYseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV1dLCJ2YWx1ZXMiOltbImFnZ3JlZ2F0aW9uIiwwXV19LCJwaXZvdF90YWJsZS5jb2x1bW5fd2lkdGhzIjp7ImxlZnRIZWFkZXJXaWR0aHMiOltdLCJ0b3RhbExlZnRIZWFkZXJXaWR0aHMiOjAsInZhbHVlSGVhZGVyV2lkdGhzIjp7fX19LCJ0eXBlIjoicXVlc3Rpb24ifQ==).

"
2365126089,issue,open,,Bookmark list is not updated when you archive a collection containing a bookmarked item,"### Describe the bug

When moving a collection to the trash that contains a bookmarked item, the bookmarks list on the Side Nav does not get updated. However, after a refresh the list will no longer contain the archived item. The inverse is true for restoring

### To Reproduce

1. Go to a collection containing a question
2. Bookmark the question
3. Archive the collection
4. Note that the question is still in the bookmark list. It will disappear after you refresh the page
5. Restoring the collection does not restore the bookmark either, until a page refresh


### Expected behavior

The bookmark list should be kept up to date while archiving / restoring collections

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current Master
```


### Severity

p2

### Additional context

_No response_",npfitz,2024-06-20 19:39:23+00:00,[],2025-02-05 19:18:25+00:00,,https://github.com/metabase/metabase/issues/44499,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2243254960, 'issue_id': 2365126089, 'author': 'rafpaf', 'body': 'Note: maybe this is a P3', 'created_at': datetime.datetime(2024, 7, 22, 15, 35, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429371905, 'issue_id': 2365126089, 'author': 'rafpaf', 'body': ""I think there is a clear workaround for this (refresh the page), so I'm lowering the priority of this bug to P3."", 'created_at': datetime.datetime(2024, 10, 22, 13, 59, 37, tzinfo=datetime.timezone.utc)}]","rafpaf on (2024-07-22 15:35:30 UTC): Note: maybe this is a P3

rafpaf on (2024-10-22 13:59:37 UTC): I think there is a clear workaround for this (refresh the page), so I'm lowering the priority of this bug to P3.

"
2364887630,issue,closed,completed,Loading state blinks during question loading,"**Context**

open any question and reload the page, notice a button blink in the top left corner

the reason is a quick change between states in `frontend/src/metabase/query_builder/components/QueryVisualization.jsx` 

https://github.com/metabase/metabase/assets/125459446/6e1e4ab4-14e2-411b-b37a-6a106beb2774

`b3749f8fe515021dda2a878488df4885a0fae33a` and v50.6
",uladzimirdev,2024-06-20 17:03:05+00:00,['uladzimirdev'],2024-10-08 17:04:39+00:00,2024-07-11 14:39:52+00:00,https://github.com/metabase/metabase/issues/44495,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2364682641,issue,closed,completed,Implement new `EntityListLoader` that uses RTK Query hooks,"Make it work for 1 or 2 entities: databases and/or tables.

There is a separate issue to port the rest of entities.",kamilmielnik,2024-06-20 15:06:35+00:00,['kamilmielnik'],2025-01-27 22:13:05+00:00,2024-12-18 10:44:07+00:00,https://github.com/metabase/metabase/issues/44492,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2364682531,issue,closed,completed,Implement new `EntityObjectLoaderRtkQuery` that uses RTK Query hooks,"Make it work for 1 or 2 entities: databases and/or tables.

There is a separate issue to port the lest of entities: #50323",kamilmielnik,2024-06-20 15:06:32+00:00,['kamilmielnik'],2025-01-27 22:14:14+00:00,2024-12-03 08:28:57+00:00,https://github.com/metabase/metabase/issues/44491,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2364677783,issue,open,,Easier bug surfacing for stats ðŸª²,"**Context**
[Slack Link](https://metaboat.slack.com/archives/C01LQQ2UW03/p1718885367305229)

Add the ability to easily surface bugs internally. Initial thoughts: 
- This could be done via slack on stats using our existing slack integration, and possibly hidden via a feature token?. 
- Good use for the command palette to expose the action
- Payload should include a screenshot (without the command palette window), as well as optional steps to reproduce
- API sends a message to a dedicated slack channel, where items vetted and can be manually added into GH



",npfitz,2024-06-20 15:04:07+00:00,[],2024-06-21 05:44:48+00:00,,https://github.com/metabase/metabase/issues/44489,"[('Misc/API', ''), ('Notifications/Slack', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2182042149, 'issue_id': 2364677783, 'author': 'Somtom', 'body': '@npfitz Do we have some automatic tracking of the last actions a user did and can include that? I am wondering whether we could make this ""how to reproduce"" more automatic since often you ran into the bug and then its like ""Ok what did I actually do to get here"".', 'created_at': datetime.datetime(2024, 6, 21, 5, 44, 47, tzinfo=datetime.timezone.utc)}]","Somtom on (2024-06-21 05:44:47 UTC): @npfitz Do we have some automatic tracking of the last actions a user did and can include that? I am wondering whether we could make this ""how to reproduce"" more automatic since often you ran into the bug and then its like ""Ok what did I actually do to get here"".

"
2364613021,issue,closed,completed,rework `DashCardCardParameterMapper.tsx` into multiple components to reduce complexity,,uladzimirdev,2024-06-20 14:33:47+00:00,['uladzimirdev'],2024-10-08 17:06:24+00:00,2024-06-24 10:16:44+00:00,https://github.com/metabase/metabase/issues/44486,[],[],
2364586633,issue,closed,completed,Create a Loom video to introduce the embedding sdk,"Let's create a short Loom video to introduce the React embedding SDK, and add it to the README.",heypoom,2024-06-20 14:21:34+00:00,['heypoom'],2024-10-08 17:06:33+00:00,2024-06-21 13:18:15+00:00,https://github.com/metabase/metabase/issues/44485,"[('Embedding/SDK', 'Embedding SDK for React')]",[],
2364432675,issue,closed,completed,Add e2e tests of the Admin / Performance policy form's ability to save and display saved data,,rafpaf,2024-06-20 13:18:43+00:00,[],2024-06-20 14:14:46+00:00,2024-06-20 14:14:45+00:00,https://github.com/metabase/metabase/issues/44478,"[('.CI & Tests', '')]",[],
2364420297,issue,closed,completed,Implement the Clean-up Modal,"Figma: https://www.figma.com/design/qdE1bj1DsK6ffDOfP0lqdy/Auto-delete-unused-items?node-id=95-15129&t=OctAqDbod5MalCME-4

Implement the manual clean up modal",sloansparger,2024-06-20 13:13:21+00:00,['sloansparger'],2024-10-08 16:18:52+00:00,2024-08-02 19:10:08+00:00,https://github.com/metabase/metabase/issues/44477,[],[],
2364407900,issue,closed,completed,Update Light theme CSS to match the design when background is transparent,,WiNloSt,2024-06-20 13:08:05+00:00,['WiNloSt'],2024-07-03 12:20:41+00:00,2024-07-03 12:20:41+00:00,https://github.com/metabase/metabase/issues/44476,"[('.CSS', '')]",[],
2364365305,issue,closed,completed,CI: Make it clear what input is used to release embedding SDK,"Now, after triggering the SDK build, there's not an easy way to see what input we've used. This could be helpful as a it helps us spot if we use the right input to trigger the job or not.",WiNloSt,2024-06-20 12:50:27+00:00,[],2024-11-06 14:01:41+00:00,2024-11-06 14:01:41+00:00,https://github.com/metabase/metabase/issues/44475,"[('.CI & Tests', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2459835274, 'issue_id': 2364365305, 'author': 'WiNloSt', 'body': 'Completed in https://github.com/metabase/metabase/issues/48727', 'created_at': datetime.datetime(2024, 11, 6, 14, 1, 39, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-11-06 14:01:39 UTC): Completed in https://github.com/metabase/metabase/issues/48727

"
2364362001,issue,open,,CI: Automatically tag the commit merged into master from docs/changelog PR.,We want to allow users who visit our npm's older version page to be able to see the exact changelog for that particular version.,WiNloSt,2024-06-20 12:49:04+00:00,[],2024-06-20 12:51:54+00:00,,https://github.com/metabase/metabase/issues/44474,"[('.CI & Tests', '')]",[],
2364356652,issue,closed,completed,CI: Add the ability to automatically update the patch version,"We deploy our embedding SDK quite often, and when doing so, the current workflow needs us to provide the exact version we want to deploy/publish.

This could be cumbersome as we need to figure out what's the current version and set the correct patch version.",WiNloSt,2024-06-20 12:46:23+00:00,[],2024-11-06 14:01:57+00:00,2024-11-06 14:01:57+00:00,https://github.com/metabase/metabase/issues/44472,"[('.CI & Tests', '')]","[{'comment_id': 2459835946, 'issue_id': 2364356652, 'author': 'WiNloSt', 'body': 'Completed in https://github.com/metabase/metabase/issues/48727', 'created_at': datetime.datetime(2024, 11, 6, 14, 1, 55, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-11-06 14:01:55 UTC): Completed in https://github.com/metabase/metabase/issues/48727

"
2364309491,issue,closed,completed,Support template tags for SQL find-and-replace,"Query analysis makes use of `nqa.sub/replace-tags` to remove metabase specific markup from native queries before processing them with Macaw, but for replace we currently just feed the raw query in, which could lead to explosions.

The tricky part here will be undoings these replacements.

Most likely this will work by pushing down the modifications into the `replacements` map inside Macaw, rather than doing any `str/replace` within Metabase.",crisptrutski,2024-06-20 12:22:49+00:00,[],2024-06-26 05:16:59+00:00,2024-06-26 05:16:59+00:00,https://github.com/metabase/metabase/issues/44471,"[('Querying/Native', 'The SQL/native query editor'), ('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2180552637, 'issue_id': 2364309491, 'author': 'crisptrutski', 'body': 'I see this compilation uses QP directly, so we will need to do something smarter. Unfortunately we cannot insert comments within the `tag-default` values. Perhaps we need a flag to QP to inject these on our behalf.', 'created_at': datetime.datetime(2024, 6, 20, 12, 30, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190726022, 'issue_id': 2364309491, 'author': 'crisptrutski', 'body': ""I can't remember what I was thinking when I opened this, but I suspect I was just confused by the fact that analysis uses QP compilation. Replace does not reuse the same analysis wrapper, and *does* reverse its modifications already. Pushing down `replacements` would still be a nice optimization, but the behavior we want is already captured in passing tests."", 'created_at': datetime.datetime(2024, 6, 26, 5, 16, 59, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-06-20 12:30:03 UTC): I see this compilation uses QP directly, so we will need to do something smarter. Unfortunately we cannot insert comments within the `tag-default` values. Perhaps we need a flag to QP to inject these on our behalf.

crisptrutski (Issue Creator) on (2024-06-26 05:16:59 UTC): I can't remember what I was thinking when I opened this, but I suspect I was just confused by the fact that analysis uses QP compilation. Replace does not reuse the same analysis wrapper, and *does* reverse its modifications already. Pushing down `replacements` would still be a nice optimization, but the behavior we want is already captured in passing tests.

"
2364150288,issue,closed,not_planned,DBT & Metabase,"I am using the DBT to transform data in my DB (PostgreSQL). It DROPs and CREATEs tables for update.
My tables in Metabase (v 0.49.12) automatically take wrong ""Field type"". I change it, but after updating the tables in DBT, the ""Field type"" automatically changes back to the wrong one.

Metabase needs to remember the table with columns by names and not change the ""Field type"".

Thank you!",Dillbearer,2024-06-20 10:58:29+00:00,[],2024-08-01 13:58:02+00:00,2024-08-01 13:58:00+00:00,https://github.com/metabase/metabase/issues/44467,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2182188503, 'issue_id': 2364150288, 'author': 'qnkhuat', 'body': 'Could you show us how to repro this?\r\n\r\n> My tables in Metabase (v 0.49.12) automatically take wrong ""Field type"". I change it, but after updating the tables in DBT, the ""Field type"" automatically changes back to the wrong one.\r\n\r\nWhat\'s the wrong field type? and when you say you change it, what exactly does it mean?', 'created_at': datetime.datetime(2024, 6, 21, 7, 41, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189705648, 'issue_id': 2364150288, 'author': 'calherries', 'body': '@Dillbearer I\'m guessing that you mean by changing the ""Field type"", you mean changing the value for ""Field type"" on the Table Metadata > Table > Field settings page:\r\n\r\n![image](https://github.com/metabase/metabase/assets/39073188/f574b991-4f4c-4d0f-b16d-25ca59d3a67b)\r\n\r\n\r\n\r\nRelated: https://github.com/metabase/metabase/issues/44698', 'created_at': datetime.datetime(2024, 6, 25, 18, 37, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192276683, 'issue_id': 2364150288, 'author': 'calherries', 'body': ""@Dillbearer can you tell us a bit more about the column, so we can figure out what's happening? Your answers to these questions will help us narrow it down:\r\n1. What type you were changing it to? \r\n2. What type did it revert back to?\r\n3. Does the column have many NULL values?\r\n4. What the Postgres type of the column is?\r\n5. What semantic category of values are stored in the column? (example answer: the values are all URLs)"", 'created_at': datetime.datetime(2024, 6, 26, 17, 37, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217547307, 'issue_id': 2364150288, 'author': 'darksciencebase', 'body': '@Dillbearer have you had a chance to read the questions @calherries posted?', 'created_at': datetime.datetime(2024, 7, 9, 12, 30, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227789539, 'issue_id': 2364150288, 'author': 'darksciencebase', 'body': '@Dillbearer we need to narrow this down to reproduce and fix the issue, could you please answer the questions above?', 'created_at': datetime.datetime(2024, 7, 15, 6, 36, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263145952, 'issue_id': 2364150288, 'author': 'darksciencebase', 'body': 'closing for the lack of leads. will reopen if more information comes in', 'created_at': datetime.datetime(2024, 8, 1, 13, 58, 1, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-06-21 07:41:38 UTC): Could you show us how to repro this?


What's the wrong field type? and when you say you change it, what exactly does it mean?

calherries on (2024-06-25 18:37:26 UTC): @Dillbearer I'm guessing that you mean by changing the ""Field type"", you mean changing the value for ""Field type"" on the Table Metadata > Table > Field settings page:

![image](https://github.com/metabase/metabase/assets/39073188/f574b991-4f4c-4d0f-b16d-25ca59d3a67b)



Related: https://github.com/metabase/metabase/issues/44698

calherries on (2024-06-26 17:37:03 UTC): @Dillbearer can you tell us a bit more about the column, so we can figure out what's happening? Your answers to these questions will help us narrow it down:
1. What type you were changing it to? 
2. What type did it revert back to?
3. Does the column have many NULL values?
4. What the Postgres type of the column is?
5. What semantic category of values are stored in the column? (example answer: the values are all URLs)

darksciencebase on (2024-07-09 12:30:16 UTC): @Dillbearer have you had a chance to read the questions @calherries posted?

darksciencebase on (2024-07-15 06:36:34 UTC): @Dillbearer we need to narrow this down to reproduce and fix the issue, could you please answer the questions above?

darksciencebase on (2024-08-01 13:58:01 UTC): closing for the lack of leads. will reopen if more information comes in

"
2363880617,issue,closed,completed,Missing schema name in data picker,"### Describe the bug

In Metabase 49, when starting a question and searching for a table, the schema name was displayed so that tables that exist with the same name in more than one schema were easy to identify.


### To Reproduce

1.  Have a Postgres data source with two schemas
2. Have a table with the same name in both schemas
3. Create a new question, enter the name of the table in the search box
4. Try to tell apart the two tables

![Screenshot 2024-06-20 at 10 36 58](https://github.com/metabase/metabase/assets/4743303/1fd31fed-dfdd-47ad-abff-0c61267f4fb9)


### Expected behavior

Metabase 49 would show the schema name under the table name, I would expect the same here.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-28-cloud-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Amsterdam""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Amsterdam""
    }
  }
}
```


### Severity

Blocking for some users

### Additional context

We have two schemas with mostly the same table names but containing completely different data. This makes it very difficult to make new questions.",attaxia,2024-06-20 08:43:59+00:00,['npfitz'],2024-08-29 11:55:29+00:00,2024-08-28 18:17:42+00:00,https://github.com/metabase/metabase/issues/44460,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Search', ''), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2196755413, 'issue_id': 2363880617, 'author': 'kamilmielnik', 'body': 'Reopening, see https://github.com/metabase/metabase/pull/44468#issuecomment-2196623087', 'created_at': datetime.datetime(2024, 6, 28, 12, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196860284, 'issue_id': 2363880617, 'author': 'kamilmielnik', 'body': 'We need to display table schema in at least these 4 cases:\r\n- Tables in Search results in Data Picker (done in #44468)\r\n- Tables in Search results in Command Palette (todo)\r\n- Tables in Recents in Data Picker (todo)\r\n- Tables in Recents in Command Palette (todo)\r\n\r\n`api/activity/recents` does not return table schema, we need to add it there (see [`SearchResult[""table_schema""]`](https://github.com/metabase/metabase/blob/95adc26b34f7d9ab1efb36d0723ccbed2a299e4f/frontend/src/metabase-types/api/search.ts#L98))', 'created_at': datetime.datetime(2024, 6, 28, 13, 4, 38, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-06-28 12:03:21 UTC): Reopening, see https://github.com/metabase/metabase/pull/44468#issuecomment-2196623087

kamilmielnik on (2024-06-28 13:04:38 UTC): We need to display table schema in at least these 4 cases:
- Tables in Search results in Data Picker (done in #44468)
- Tables in Search results in Command Palette (todo)
- Tables in Recents in Data Picker (todo)
- Tables in Recents in Command Palette (todo)

`api/activity/recents` does not return table schema, we need to add it there (see [`SearchResult[""table_schema""]`](https://github.com/metabase/metabase/blob/95adc26b34f7d9ab1efb36d0723ccbed2a299e4f/frontend/src/metabase-types/api/search.ts#L98))

"
2363851591,issue,closed,completed,Can't sync array columns,"### Describe the bug

Unable to sync jsonb columns with value is an array

### To Reproduce

1. Use MB with appdb is PG
2. Create a postgres db with this table
```sql
CREATE TABLE my_table (
    id serial PRIMARY KEY,
    data jsonb
);

INSERT INTO my_table (data)
VALUES ('[1, 2, 3]'::jsonb);
```

3. Try to sync the created DB
4. Go to table metadata, you won't see this table has any fields

### Expected behavior

The table should be synced correctly with 2 columns: id, data

### Logs
```
2024-06-20 08:28:18,784 WARN sync.util :: Error checking if Fields (""data"" ""id"" ""data"") need to be created or reactivated
clojure.lang.ExceptionInfo: ERROR: duplicate key value violates unique constraint ""idx_uniq_field_table_id_parent_id_name_2col""
  Detail: Key (table_id, name)=(22, data) already exists. {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""INSERT INTO \""metabase_field\"" (\""description\"", \""database_type\"", \""semantic_type\"", \""table_id\""
, \""coercion_strategy\"", \""name\"", \""updated_at\"", \""effective_type\"", \""nfc_path\"", \""parent_id\"", \""database_partitioned\"", \""database_is_auto_increment\"", \""json_unfolding\"", \""position\"", \""visibility_type\"", \""display_name\"", \""database_position\"", \""database_required\"", \""created_at\"", \""base_type\"") VALUES (NULL, ?, ?, ?, NULL, ?, NOW(), ?, NULL, NULL, NULL, FALSE, TRUE, ?, ?, ?, ?, FALSE, NOW(), ?), (NULL, ?, ?, ?, NULL, ?, NOW(), ?, NULL, NULL, NULL, TRUE, FALSE, ?, ?, ?, ?, FALSE, NOW(), ?), (NULL, ?, NULL, ?, NULL, ?, NOW(), ?, ?, NULL, NULL, FALSE, F
ALSE, ?, ?, ?, ?, FALSE, NOW(), ?)"" ""jsonb"" ""type/SerializedJSON"" 22 ""data"" ""type/JSON"" 1 ""details-only"" ""Data"" 1 ""type/JSON"" ""serial"" ""type/PK"" 22 ""id"" ""type/Integer"" 0 ""normal"" ""ID"" 0 ""type/Integer"" ""text"" 22 ""data"" ""type/Array"" ""[\""data\""]"" 0 ""normal"" ""Data"" 0 ""type/Array""]}] [""resolve connection"" {:toucan2.connection/connectable org.postgresql.jdbc.PgConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #function[clojure.core/map/fn--5931/fn--5932]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""INSERT IN
TO \""metabase_field\"" (\""description\"", \""database_type\"", \""semantic_type\"", \""table_id\"", \""coercion_strategy\"", \""name\"", \""updated_at\"", \""effective_type\"", \""nfc_path\"", \""parent_id\"", \""database_partitioned\"", \""database_is_auto_increment\"", \""json_unfolding\"", \""position\"", \""visibility_type\"", \""display_name\"", \""database_position\"", \""database_required\"", \""created_at\"", \""base_type\"") VALUES (NULL, ?, ?, ?, NULL, ?, NOW(), ?, NULL, NULL, NULL, FALSE, TRUE, ?, ?, ?, ?, FALSE, NOW(), ?), (NULL, ?, ?, ?, NULL, ?, NOW(), ?, NULL, NULL, NULL, TRUE, FALSE, ?
, ?, ?, ?, FALSE, NOW(), ?), (NULL, ?, NULL, ?, NULL, ?, NOW(), ?, ?, NULL, NULL, FALSE, FALSE, ?, ?, ?, ?, FALSE, NOW(), ?)"" ""jsonb"" ""type/SerializedJSON"" 22 ""data"" ""type/JSON"" 1 ""details-only"" ""Data"" 1 ""type/JSON"" ""serial"" ""type/PK"" 22 ""id"" ""type/Integer"" 0 ""normal"" ""ID"" 0 ""type/Integer"" ""text"" 22 ""data"" ""type/Array"" ""[\""data\""]"" 0 ""normal"" ""Data"" 0 ""type/Array""]}] [""with built query"" {:toucan2.pipeline/built-query {:insert-into [:metabase_field], :values ((toucan2.instance/instance :model/Field {:description nil, :database_type ""jsonb"", :semantic_type ""type/S
erializedJSON"", :table_id 22, :coercion_strategy nil, :name ""data"", :updated_at [:metabase.util.honey-sql-2/typed :%now {:database-type ""timestamptz""}], :effective_type ""type/JSON"", :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment false, :json_unfolding true, :position 1, :visibility_type ""details-only"", :display_name ""Data"", :database_position 1, :database_required false, :created_at [:metabase.util.honey-sql-2/typed :%now {:database-type ""timestamptz""}], :base_type ""type/JSON""}) (toucan2.instance/instance :model/Field {:des
cription nil, :database_type ""serial"", :semantic_type ""type/PK"", :table_id 22, :coercion_strategy nil, :name ""id"", :updated_at [:metabase.util.honey-sql-2/typed :%now {:database-type ""timestamptz""}], :effective_type ""type/Integer"", :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment true, :json_unfolding false, :position 0, :visibility_type ""normal"", :display_name ""ID"", :database_position 0, :database_required false, :created_at [:metabase.util.honey-sql-2/typed :%now {:database-type ""timestamptz""}], :base_type ""type/Integer""})
(toucan2.instance/instance :model/Field {:description nil, :database_type ""text"", :semantic_type nil, :table_id 22, :coercion_strategy nil, :name ""data"", :updated_at [:metabase.util.honey-sql-2/typed :%now {:database-type ""timestamptz""}], :effective_type ""type/Array"", :nfc_path ""[\""data\""]"", :parent_id nil, :database_partitioned nil, :database_is_auto_increment false, :json_unfolding false, :position 0, :visibility_type ""normal"", :display_name ""Data"", :database_position 0, :database_required false, :created_at [:metabase.util.honey-sql-2/typed :%now {:database-t
ype ""timestamptz""}], :base_type ""type/Array""}))}}] [""resolve connection"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}] [""resolve connection"" {:toucan2.connection/connectable :default}] [""resolve connection"" {:toucan2.connection/connectable nil}] [""with resolved query"" {:toucan2.pipeline/resolved-query {}}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.query-type/insert.pks, :toucan2.pipeline/parsed-args {:rows [{:description nil, :database_type ""jsonb"", :semantic_type :type/SerializedJSON, :table_id 22, :coercion_strategy ni
l, :name ""data"", :effective_type :type/JSON, :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment false, :json_unfolding true, :position 1, :visibility_type :details-only, :display_name ""Data"", :database_position 1, :database_required false, :base_type :type/JSON} {:description nil, :database_type ""serial"", :semantic_type :type/PK, :table_id 22, :coercion_strategy nil, :name ""id"", :effective_type :type/Integer, :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment true, :json_unfolding false, :posi
tion 0, :visibility_type :normal, :display_name ""ID"", :database_position 0, :database_required false, :base_type :type/Integer} {:description nil, :database_type ""text"", :semantic_type nil, :table_id 22, :coercion_strategy nil, :name ""data"", :effective_type :type/Array, :nfc_path [:data], :parent_id nil, :database_partitioned nil, :database_is_auto_increment false, :json_unfolding false, :position 0, :visibility_type :normal, :display_name ""Data"", :database_position 0, :database_required false, :base_type :type/Array}]}}] [""with model"" {:toucan2.pipeline/model :
model/Field}] [""with unparsed args"" {:toucan2.pipeline/query-type :toucan.query-type/insert.pks, :toucan2.pipeline/unparsed-args (:model/Field ({:description nil, :database_type ""jsonb"", :semantic_type :type/SerializedJSON, :table_id 22, :coercion_strategy nil, :name ""data"", :effective_type :type/JSON, :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment false, :json_unfolding true, :position 1, :visibility_type :details-only, :display_name ""Data"", :database_position 1, :database_required false, :base_type :type/JSON} {:descripti
on nil, :database_type ""serial"", :semantic_type :type/PK, :table_id 22, :coercion_strategy nil, :name ""id"", :effective_type :type/Integer, :nfc_path nil, :parent_id nil, :database_partitioned nil, :database_is_auto_increment true, :json_unfolding false, :position 0, :visibility_type
:normal, :display_name ""ID"", :database_position 0, :database_required false, :base_type :type/Integer} {:description nil, :database_type ""text"", :semantic_type nil, :table_id 22, :coercion_strategy nil, :name ""data"", :effective_type :type/Array, :nfc_path [:data], :parent_id nil, :da
tabase_partitioned nil, :database_is_auto_increment false, :json_unfolding false, :position 0, :visibility_type :normal, :display_name ""Data"", :database_position 0, :database_required false, :base_type :type/Array}))}]]}
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
        at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
        at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)
        at org.postgresql.jdbc.PgPreparedStatement.execute(PgPreparedStatement.java:180)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
        at toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:40)
        at toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:482)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan_result_type_pks_default.invokeStatic(pipeline.clj:30)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan_result_type_pks_default.invoke(pipeline.clj:22)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$eval14915$fn__14916$fn__14917$fn__14924.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__14883$fn__14887.invoke(threaded.clj:23)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__14883.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__14893.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_execute$with_connection_STAR___57873$with_transaction_STAR___57874.invoke(pipeline.clj:75)
        at toucan2.connection$bind_current_connectable_fn$fn__57458.invoke(connection.clj:104)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:180)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:162)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.combo.threaded$eval14915$fn__14916$fn__14917$fn__14920.invoke(threaded.clj:71)
        at methodical.impl.combo.threaded$reducer_fn$fn__14883$fn__14887.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__14883.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2588)
        at methodical.impl.combo.threaded$combine_with_threader$fn__14893.invoke(threaded.clj:44)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
```
### Information about your Metabase installation

```JSON
master
```


### Severity

P1

### Additional context

_No response_",qnkhuat,2024-06-20 08:29:12+00:00,[],2024-06-21 03:22:09+00:00,2024-06-20 14:05:01+00:00,https://github.com/metabase/metabase/issues/44459,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Postgres', None), ('Administration/Metadata & Sync', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2180116257, 'issue_id': 2363851591, 'author': 'qnkhuat', 'body': 'Introduced by https://github.com/metabase/metabase/pull/43812', 'created_at': datetime.datetime(2024, 6, 20, 8, 29, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180122449, 'issue_id': 2363851591, 'author': 'qnkhuat', 'body': 'We need to add a test to sync an e2e to test to sync a db json columns where value is an array.', 'created_at': datetime.datetime(2024, 6, 20, 8, 32, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181929721, 'issue_id': 2363851591, 'author': 'qnkhuat', 'body': 'Fixed in #44465', 'created_at': datetime.datetime(2024, 6, 21, 3, 22, 8, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-06-20 08:29:45 UTC): Introduced by https://github.com/metabase/metabase/pull/43812

qnkhuat (Issue Creator) on (2024-06-20 08:32:55 UTC): We need to add a test to sync an e2e to test to sync a db json columns where value is an array.

qnkhuat (Issue Creator) on (2024-06-21 03:22:08 UTC): Fixed in #44465

"
2363668804,issue,closed,completed,Some caching improvements,"- `updated_at` is not updated or communicated correctly to frontend
- `nocache` strategy should prevent using cache (even when cache already exists)
- think about adding something to adjust date for e2e tests

[Context](https://metaboat.slack.com/archives/C06KX7QECN4/p1718624152579009)",piranha,2024-06-20 06:54:42+00:00,['piranha'],2024-06-26 09:38:28+00:00,2024-06-26 08:10:20+00:00,https://github.com/metabase/metabase/issues/44458,"[('Querying/Cache', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]",[],
2363366738,issue,open,,Allow overriding functions related to the `:window-functions/offset` HSQL in the drivers,"**Is your feature request related to a problem? Please describe.**

Most of the logic related to the `:window-functions/offset` feature is in the private functions, and it is not possible to properly override it in the driver. 

For example, https://github.com/metabase/metabase/blob/v1.50.3/src/metabase/driver/sql/query_processor.clj#L806-L816

See that the `:lag`/`:lead` part is hardcoded, as well as the `window-aggregation-over-rows` function with a lot of logic. 

The issue here is that in the ClickHouse driver, we need (case-sensitive) `:'lagInFrame` and `:'leadInFrame` instead of the default ones; on top of that, we need to add `rows between unbounded preceding and unbounded following` to match the ""default"" expected behavior (see [the docs](https://clickhouse.com/docs/en/sql-reference/window-functions#standard-window-functions)).

Currently, this is not possible without re-implementing most of the logic.

See also: https://github.com/ClickHouse/metabase-clickhouse-driver/issues/245

**Describe the solution you'd like**

Make more of those functions public or add another driver method for generating the Honey SQL.
",slvrtrn,2024-06-20 02:11:28+00:00,[],2025-02-04 20:30:56+00:00,,https://github.com/metabase/metabase/issues/44457,"[('Database/', ''), ('Querying/Processor', ''), ('Type:New Feature', ''), ('.Team/Drivers', '')]",[],
2363268181,issue,closed,completed,Migrate down between 50 and 49 fails when you had sandboxing configured on 49,"### Describe the bug

just try to do a migrate down after you configured sandboxing

### To Reproduce

1) start Metabase on 49 and mysql as the app db (I think this is key, I haven't tried with H2)
2) configure sandboxing
3) then migrate down
4) see the error

### Expected behavior

It should migrate down

### Logs

```
2024-06-19 23:59:41,717 INFO db.liquibase :: Rolling back app database schema to version 49
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE) [Failed SQL: (1452) ALTER TABLE `metabase`.`sandboxes` ADD CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `metabase`.`permissions` (`id`) ON DELETE CASCADE]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$rollback$7(Liquibase.java:579)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.rollback(Liquibase.java:568)
	at liquibase.Liquibase.rollback(Liquibase.java:551)
	at liquibase.Liquibase.rollback(Liquibase.java:542)
	at metabase.db.liquibase$rollback_major_version$fn__44512.invoke(liquibase.clj:485)
	at metabase.db.liquibase$run_in_scope_locked$reify__44426.run(liquibase.clj:324)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:317)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:300)
	at metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:478)
	at metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)
	at metabase.db.liquibase$rollback_major_version.invokeStatic(liquibase.clj:470)
	at metabase.db.liquibase$rollback_major_version.invoke(liquibase.clj:465)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:671)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.db.setup$migrate_BANG_$fn__53357.invoke(setup.clj:86)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44367.invoke(liquibase.clj:139)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:142)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:130)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.cmd.migrate$migrate_BANG_.invokeStatic(migrate.clj:8)
	at metabase.cmd.migrate$migrate_BANG_.invoke(migrate.clj:5)
	at clojure.lang.Var.invoke(Var.java:384)
	at metabase.cmd$migrate.invokeStatic(cmd.clj:66)
	at metabase.cmd$migrate.invoke(cmd.clj:62)
	at clojure.lang.AFn.applyToHelper(AFn.java:154)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.cmd$run_cmd$fn__111564.invoke(cmd.clj:301)
	at metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)
	at metabase.cmd$run_cmd.invoke(cmd.clj:290)
	at clojure.lang.Var.invoke(Var.java:388)
	at metabase.core$run_cmd.invokeStatic(core.clj:192)
	at metabase.core$run_cmd.invoke(core.clj:190)
	at metabase.core$entrypoint.invokeStatic(core.clj:214)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE) [Failed SQL: (1452) ALTER TABLE `metabase`.`sandboxes` ADD CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `metabase`.`permissions` (`id`) ON DELETE CASCADE]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:112)
	at liquibase.command.core.AbstractRollbackCommandStep.doRollback(AbstractRollbackCommandStep.java:82)
	at liquibase.command.core.RollbackCountCommandStep.lambda$run$0(RollbackCountCommandStep.java:48)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.RollbackCountCommandStep.run(RollbackCountCommandStep.java:48)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 57 more
Caused by: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE) [Failed SQL: (1452) ALTER TABLE `metabase`.`sandboxes` ADD CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `metabase`.`permissions` (`id`) ON DELETE CASCADE]
	at liquibase.changelog.ChangeSet.rollback(ChangeSet.java:956)
	at liquibase.changelog.visitor.RollbackVisitor.visit(RollbackVisitor.java:63)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE) [Failed SQL: (1452) ALTER TABLE `metabase`.`sandboxes` ADD CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `metabase`.`permissions` (`id`) ON DELETE CASCADE]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.database.AbstractJdbcDatabase.execute(AbstractJdbcDatabase.java:1303)
	at liquibase.database.AbstractJdbcDatabase.executeRollbackStatements(AbstractJdbcDatabase.java:1327)
	at liquibase.changelog.ChangeSet.rollback(ChangeSet.java:921)
	... 80 more
Caused by: java.sql.SQLIntegrityConstraintViolationException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE)
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:70)
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
	at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
	at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 85 more
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE)
	at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
	... 88 more
Caused by: java.sql.SQLException: Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
	... 89 more
Command failed with exception: liquibase.exception.LiquibaseException: liquibase.exception.RollbackFailedException: liquibase.exception.DatabaseException: (conn=20) Cannot add or update a child row: a foreign key constraint fails (`metabase`.`#sql-1_14`, CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `permissions` (`id`) ON DELETE CASCADE) [Failed SQL: (1452) ALTER TABLE `metabase`.`sandboxes` ADD CONSTRAINT `fk_sandboxes_ref_permissions` FOREIGN KEY (`permission_id`) REFERENCES `metabase`.`permissions` (`id`) ON DELETE CASCADE]
```

### Information about your Metabase installation

```JSON
v50, but maybe this happens also in previous versions?
```


### Severity

P1

### Additional context

The fact that you can't remove the sandboxing to move back to an older version makes it a P1",paoliniluis,2024-06-20 00:03:22+00:00,['noahmoss'],2024-06-20 19:03:32+00:00,2024-06-20 18:24:27+00:00,https://github.com/metabase/metabase/issues/44455,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2179647456, 'issue_id': 2363268181, 'author': 'noahmoss', 'body': 'Workaround: Run `UPDATE sandboxes SET permission_id = NULL;` on the app DB prior to migrating down', 'created_at': datetime.datetime(2024, 6, 20, 1, 18, 26, tzinfo=datetime.timezone.utc)}]","noahmoss (Assginee) on (2024-06-20 01:18:26 UTC): Workaround: Run `UPDATE sandboxes SET permission_id = NULL;` on the app DB prior to migrating down

"
2363216887,issue,open,,[Browse] Remove lone nav ghost,,rafpaf,2024-06-19 22:47:24+00:00,[],2024-06-19 22:47:24+00:00,,https://github.com/metabase/metabase/issues/44450,[],[],
2363084438,issue,open,,Better error handling in the sandboxing modal,"### Describe the bug

When opening the modal to edit details about a sandbox, if the `/api/dataset/query_metadata` call is slow or fails, it shows the sandboxed column as an empty dropdown. This can mislead the user into thinking that sandboxing is improperly configured, even if it's just a transient network issue.

### To Reproduce

1. Set up a sandbox that filters a column of a table based on a user attribute
2. Block `/api/dataset/query_metadata` in the network tab
3. Open the sandboxing modal and see that everything renders but the dropdown is blank

### Expected behavior

If we can't show the entire sandboxing config, we should show a loading and/or error state, rather than an incomplete config.

### Logs

_No response_

### Information about your Metabase installation

Current master (v50)


### Severity

UX issue, but can cause confusion around permissions

### Additional context

_No response_",noahmoss,2024-06-19 20:31:53+00:00,[],2024-06-19 20:38:25+00:00,,https://github.com/metabase/metabase/issues/44443,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2363034616,issue,closed,completed,Dashboard Filters Saving over defaults from last opened version of dashboard,"### Describe the bug

When i open a link to a dashboard with a filter that is not the dashboard default filter, Then if i close the browser (with non default browsers selected) and reopen the same dashboard from the folder link which previously opened only with default filters, The last saved filters override the default filters. This also happens cross dashboard for duplicated dashboards with different filters defaulted (with intention)

### To Reproduce

1. Go to '...'one dashboard with default filters
2. Click on '....'a random extra filter
3. Scroll down to '....; a new browser with the same original dashboard 
4. See error filters in step two applied to step 3 without manually doing this and overriding default filters


### Expected behavior

If you manually add filters to a dashboard that has different default filters, close a browser and open the base dashboard, only the default filters will open when you reopen the base dashboard. Similarly if you create duplicated dashboards with different defualt filters opening and closing one dashboard would not auto apply the the original default filters into a different dashboard.

### Logs

i dont know how to do this. this behavior was reproduced by multiple colleagues, so i know im not special - please contact averill.roberto@affecttherapeutics.com (me) or David.Svensen@affecttherapeutics.com (our metabase expert)

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-1125-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.8 (Debian 13.8-1.pgdg90+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-19"",
      ""tag"": ""v0.50.6"",
      ""hash"": ""a5fbebf""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}


Message David Svensen
```


### Severity

Blocking billing error correction and therefore affecting AR (financials)

### Additional context

Cant send screen shots because it has PHI",AR123AFF,2024-06-19 19:47:56+00:00,['kamilmielnik'],2024-08-05 15:04:02+00:00,2024-08-05 15:03:50+00:00,https://github.com/metabase/metabase/issues/44438,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2179377069, 'issue_id': 2363034616, 'author': 'paoliniluis', 'body': 'Can you give us more information? the dashboard still has the default filters, but in v50 we decided to also keep what the users select and we save that in the browser', 'created_at': datetime.datetime(2024, 6, 19, 19, 49, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179395544, 'issue_id': 2363034616, 'author': 'AR123AFF', 'body': 'Is there a way that we can NOT cache the most recent filters and only use\r\ndefault filters and empty filters upon dashboard loading? We use\r\ncomplicated filtering for different audiences in a workflow and even\r\ndifferent providers due to separate email setup of reports based on\r\ncoverage.\r\n\r\nAverill\r\n\r\nOn Wed, Jun 19, 2024 at 3:49\u202fPM Luis Paolini ***@***.***>\r\nwrote:\r\n\r\n> Can you give us more information? the dashboard still has the default\r\n> filters, but in v50 we decided to also keep what the users select and we\r\n> save that in the browser\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/44438#issuecomment-2179377069>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BJKGQTZZUNUEXXJE3KDFCYDZIHOE7AVCNFSM6AAAAABJSTXQEOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCNZZGM3TOMBWHE>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 6, 19, 20, 6, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179453036, 'issue_id': 2363034616, 'author': 'uladzimirdev', 'body': ""@AR123AFF the last used filter values are saved per user, so another user will have everything blank. if you use different values often, maybe it's a point to update default values?\r\n\r\ncould you please explain why do you want default values to be kept instead of last used?"", 'created_at': datetime.datetime(2024, 6, 19, 21, 2, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180368759, 'issue_id': 2363034616, 'author': 'uladzimirdev', 'body': 'related issue https://github.com/metabase/metabase/issues/43001, covers ""duplicate dashboard"" part', 'created_at': datetime.datetime(2024, 6, 20, 10, 43, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180659852, 'issue_id': 2363034616, 'author': 'AR123AFF', 'body': 'Hello,\r\n\r\nWe have many dashboards that identify billing ""Errors"" detected by the\r\nsystem. Different default filters on duplicated dashboards are intended for\r\ndifferent audiences. For example, one set of filters may be for health care\r\nproviders completing documentation defaulted if that person provides\r\ncoverage for a particular state. We then have the providers specific\r\ndashboard sent to them regularly. Another version of that dashboard may be\r\ndefault to a different provider or a different state. Similarly the type of\r\nvisit may be relevant for medical staff and a different type of visit\r\nfilter for the therapists.\r\n\r\nBy having different default filters as an administrator, i can look how\r\nprovider X is doing with their personnel completion of work and maintain\r\nonly one base report. This creates a lot of complication for\r\nsupervisors and for administrators when default filters are overridden by\r\nlast filtered.\r\n\r\nCan we turn off the feature?\r\n\r\nAverill\r\n\r\nOn Thu, Jun 20, 2024 at 6:43\u202fAM Uladzimir Havenchyk <\r\n***@***.***> wrote:\r\n\r\n> related issue #43001 <https://github.com/metabase/metabase/issues/43001>\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/44438#issuecomment-2180368759>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BJKGQT7WXQGCZFSI2QCRONTZIKW6HAVCNFSM6AAAAABJSTXQEOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDCOBQGM3DQNZVHE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 6, 20, 13, 15, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180823782, 'issue_id': 2363034616, 'author': 'paoliniluis', 'body': 'We should have a reset button to clean the filters to the ""default"" state (asked by one of our customers)', 'created_at': datetime.datetime(2024, 6, 20, 14, 16, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180987163, 'issue_id': 2363034616, 'author': 'AR123AFF', 'body': 'Thank you, when will this button be available? FWIW this is not ideal for\nus given the rapid nature of our work and the extra clicking.\n\nBest,\nAverill\n\n> Message ID: ***@***.***>\n>', 'created_at': datetime.datetime(2024, 6, 20, 15, 30, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181408937, 'issue_id': 2363034616, 'author': 'uladzimirdev', 'body': '@AR123AFF it already exists, but you\'ll see it only when ""always require a value"" is selected\r\n\r\n<img width=""1198"" alt=""Screenshot 2024-06-20 at 22 43 40"" src=""https://github.com/metabase/metabase/assets/125459446/f89d2852-b5ff-4cec-aabc-017bbffdff12"">\r\n\r\nhttps://github.com/metabase/metabase/assets/125459446/50b08f9e-2a14-4ea6-b077-09345b9e1b98', 'created_at': datetime.datetime(2024, 6, 20, 19, 45, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269295078, 'issue_id': 2363034616, 'author': 'kamilmielnik', 'body': '> Thank you, when will this button be available? \r\n\r\n@AR123AFF The new button is going to be released in Metabase v50.19 which is planned for tomorrow.\r\n\r\n![image](https://github.com/user-attachments/assets/1970c0f6-e65a-4c72-9944-46deb811f09d)\r\n\r\n\r\n-----\r\n\r\nClosed by #45935', 'created_at': datetime.datetime(2024, 8, 5, 15, 3, 50, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-19 19:49:14 UTC): Can you give us more information? the dashboard still has the default filters, but in v50 we decided to also keep what the users select and we save that in the browser

AR123AFF (Issue Creator) on (2024-06-19 20:06:27 UTC): Is there a way that we can NOT cache the most recent filters and only use
default filters and empty filters upon dashboard loading? We use
complicated filtering for different audiences in a workflow and even
different providers due to separate email setup of reports based on
coverage.

Averill

On Wed, Jun 19, 2024 at 3:49â€¯PM Luis Paolini ***@***.***>
wrote:

uladzimirdev on (2024-06-19 21:02:42 UTC): @AR123AFF the last used filter values are saved per user, so another user will have everything blank. if you use different values often, maybe it's a point to update default values?

could you please explain why do you want default values to be kept instead of last used?

uladzimirdev on (2024-06-20 10:43:24 UTC): related issue https://github.com/metabase/metabase/issues/43001, covers ""duplicate dashboard"" part

AR123AFF (Issue Creator) on (2024-06-20 13:15:41 UTC): Hello,

We have many dashboards that identify billing ""Errors"" detected by the
system. Different default filters on duplicated dashboards are intended for
different audiences. For example, one set of filters may be for health care
providers completing documentation defaulted if that person provides
coverage for a particular state. We then have the providers specific
dashboard sent to them regularly. Another version of that dashboard may be
default to a different provider or a different state. Similarly the type of
visit may be relevant for medical staff and a different type of visit
filter for the therapists.

By having different default filters as an administrator, i can look how
provider X is doing with their personnel completion of work and maintain
only one base report. This creates a lot of complication for
supervisors and for administrators when default filters are overridden by
last filtered.

Can we turn off the feature?

Averill

On Thu, Jun 20, 2024 at 6:43â€¯AM Uladzimir Havenchyk <
***@***.***> wrote:

paoliniluis on (2024-06-20 14:16:25 UTC): We should have a reset button to clean the filters to the ""default"" state (asked by one of our customers)

AR123AFF (Issue Creator) on (2024-06-20 15:30:26 UTC): Thank you, when will this button be available? FWIW this is not ideal for
us given the rapid nature of our work and the extra clicking.

Best,
Averill

uladzimirdev on (2024-06-20 19:45:33 UTC): @AR123AFF it already exists, but you'll see it only when ""always require a value"" is selected

<img width=""1198"" alt=""Screenshot 2024-06-20 at 22 43 40"" src=""https://github.com/metabase/metabase/assets/125459446/f89d2852-b5ff-4cec-aabc-017bbffdff12"">

https://github.com/metabase/metabase/assets/125459446/50b08f9e-2a14-4ea6-b077-09345b9e1b98

kamilmielnik (Assginee) on (2024-08-05 15:03:50 UTC): @AR123AFF The new button is going to be released in Metabase v50.19 which is planned for tomorrow.

![image](https://github.com/user-attachments/assets/1970c0f6-e65a-4c72-9944-46deb811f09d)


-----

Closed by #45935

"
2362975321,issue,open,,Large inputs on text filters will add a scroll bar on the page to the right,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/1711649/ca1f1ed0-b4ce-4d57-bd6e-d1c7573d15bf)


### To Reproduce

1) just go to a table and add a long long long string
2) see the scrollbar

### Expected behavior

We should detect these inputs and add a few letters in the beginning, 3 dots and a few letters on the back
(check how we do it on the filter component)
![image](https://github.com/metabase/metabase/assets/1711649/0170d3ae-23cb-4b05-b3b4-f1137703db49)


### Logs

NA

### Information about your Metabase installation

```JSON
I think it has been like this forever
```


### Severity

P3

### Additional context

NA",paoliniluis,2024-06-19 18:58:47+00:00,[],2025-02-04 20:27:32+00:00,,https://github.com/metabase/metabase/issues/44435,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]","[{'comment_id': 2208997560, 'issue_id': 2362975321, 'author': 'kamilmielnik', 'body': 'Reproducible in `master` at 638d79c457.\r\n\r\nAdditionally the `x` button within the filter pill can be too small ([image](https://github.com/metabase/metabase/assets/6830683/c73bad62-13dd-4a7e-93c2-bfe047f16023)).', 'created_at': datetime.datetime(2024, 7, 4, 13, 31, 31, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-07-04 13:31:31 UTC): Reproducible in `master` at 638d79c457.

Additionally the `x` button within the filter pill can be too small ([image](https://github.com/metabase/metabase/assets/6830683/c73bad62-13dd-4a7e-93c2-bfe047f16023)).

"
2362957451,issue,closed,completed,convert redux/undo and UndoListing.jsx to TS,,uladzimirdev,2024-06-19 18:43:12+00:00,['uladzimirdev'],2024-10-08 17:06:26+00:00,2024-06-22 07:22:47+00:00,https://github.com/metabase/metabase/issues/44433,[],[],
2362896730,issue,closed,completed,Cannot use aggregations with numbers stored as strings in MySQL in v50,"### Describe the bug

Hello,
Since the v50 i am getting errors when trying to sum values/dates saved as string in db (mysql/snowflake) even though i changed table metadata to quantity. It was working fine before now i get this error:
`Invalid query: {:stages [{:aggregation [[nil nil [nil nil [""expression returning a number""]]]]}]}`
`Invalid query: {:stages [{:filters [nil [nil nil [""expression returning a date, time, or date time""]]]}]}`
### To Reproduce

1. data (numbers) saved as varchar in database table (mysql or snowflake)
2. set table metadata in metabase admin to quantity for the given field
3. trying to sum/aggregate values (icon remains as [T] before field name in UI when selecting the field)
![CleanShot 2024-06-19 at 19 52 25@2x](https://github.com/metabase/metabase/assets/96686504/b1469b1a-a872-49fc-96dd-d30de21106d9)
![CleanShot 2024-06-19 at 19 54 41@2x](https://github.com/metabase/metabase/assets/96686504/d0aceb4d-431a-40f2-94e2-e969e0a88202)
![CleanShot 2024-06-19 at 19 55 22@2x](https://github.com/metabase/metabase/assets/96686504/e053f407-e72c-446a-948d-c3cb3036a8c3)



### Expected behavior

sum of text fields set to number in metabase metadata worked fine in v.0.49.x

### Logs

_No response_

### Information about your Metabase installation

```JSON
metabase v0.50.6
```


### Severity

high

### Additional context

_No response_",martin-knap,2024-06-19 17:57:12+00:00,['bshepherdson'],2024-08-27 13:08:55+00:00,2024-08-26 21:44:19+00:00,https://github.com/metabase/metabase/issues/44431,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('Querying/Processor', ''), ('Administration/Table Metadata', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2179288091, 'issue_id': 2362896730, 'author': 'paoliniluis', 'body': 'This implies that you were able to sum strings before?', 'created_at': datetime.datetime(2024, 6, 19, 18, 30, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179290756, 'issue_id': 2362896730, 'author': 'martin-knap', 'body': 'yes it worked when you changed type in table metadata in admin or in model', 'created_at': datetime.datetime(2024, 6, 19, 18, 32, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179297592, 'issue_id': 2362896730, 'author': 'paoliniluis', 'body': ""maybe I'm not seeing something but why do you save numbers as strings in the database?"", 'created_at': datetime.datetime(2024, 6, 19, 18, 37, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179314223, 'issue_id': 2362896730, 'author': 'martin-knap', 'body': 'some ETL tools (e.g. Keboola) save all data in Snowflake as varchar and i cant change the setting or update metadata in storage :(', 'created_at': datetime.datetime(2024, 6, 19, 18, 52, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182301561, 'issue_id': 2362896730, 'author': 'armetiz', 'body': 'Same problem here after upgrade to latest metabase OSS release. Also have a VARCHAR', 'created_at': datetime.datetime(2024, 6, 21, 8, 46, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182945583, 'issue_id': 2362896730, 'author': 'armetiz', 'body': 'I\'ve solved the problem, but I\'m not sure I\'m dealing with exactly the same issue as the author.\r\n\r\nThe problem was still present after changing the column type from VARCHAR to FLOAT. \r\nI checked the metabase error-log, and observed several information messages about type conversions. So I checked the correspondence of my model. The field had no specific category, so I associated my field with a ""price"", after which it worked.\r\n\r\nRegards.', 'created_at': datetime.datetime(2024, 6, 21, 15, 15, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2212902561, 'issue_id': 2362896730, 'author': 'jkohlbach', 'body': ""We tried the fix @armetiz suggested but it didn't work out. Probably because we kept the columns as varchar, I'm guessing.\r\n\r\nThis seems like a regression, we're also in a situation where the column needs to be varchar and this has broken a ton of custom expressions. You can no longer sum or sumif for example.\r\n\r\nAny chance this will be fixed on the next release or should we downgrade?"", 'created_at': datetime.datetime(2024, 7, 8, 3, 13, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244171457, 'issue_id': 2362896730, 'author': 'salman2learn', 'body': 'Same issue with OSS version using sqlite number data type.\r\nThanks.', 'created_at': datetime.datetime(2024, 7, 23, 3, 17, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259607700, 'issue_id': 2362896730, 'author': 'SeshTiliRest', 'body': 'I have a similar problem with my multiple replacement after updating from v0.49.14 to v0.50.18.\r\nMS SQL with TINYINT datatype.\r\n\r\n![invalid](https://github.com/user-attachments/assets/5b6af0b7-36b2-4c98-891b-2bb272baa9d5)\r\n`replace(replace(replace([Accept], ""1"", ""Ð""), ""0"", ""Ð’""), ""2"", ""Ðš"")`\r\n\r\n![problem](https://github.com/user-attachments/assets/38037bc2-1aec-47fb-a66f-9795a9066855)\r\n`Invalid query: {:stages [{:expressions [[nil nil [nil nil [nil nil [""expression returning a string""]]]]]}]}`\r\n\r\nAfter deleting custom column with dat replace function - error is gone.\r\nLooks related to #44807', 'created_at': datetime.datetime(2024, 7, 31, 4, 12, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2275629025, 'issue_id': 2362896730, 'author': 'douglas-regatieri', 'body': ""I encountered a similar error after updating to v0.50. I'm using Redshift, and the issue occurs with a SUM on a float8 datatype"", 'created_at': datetime.datetime(2024, 8, 8, 11, 50, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285538383, 'issue_id': 2362896730, 'author': 'martin-knap', 'body': 'this is also affecting columns formatted as number and trying to do `substring([Date Key], 1, 4)`', 'created_at': datetime.datetime(2024, 8, 13, 7, 26, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296791161, 'issue_id': 2362896730, 'author': 'MarleTangible', 'body': 'I have a similar issue filtering varchar columns with MSSQL. There are similar columns with the same data type (varchar 15) but there are no issues with other columns. One thing that got my attention is that the table metadata shows the original schema as `type/*` while others are `type/Text`. Look like there\'s an issue with the table scan. Here\'s the error I get when I try to rescan the table.\r\n\r\n```\r\n2024-08-19 14:57:55,590 ERROR models.field-values :: Error fetching field values\r\nclojure.lang.ExceptionInfo: Error executing query: The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator. {:driver :sqlserver, :sql [""-- Metabase"" ""SELECT"" ""  TOP(1000) \\""dbo\\"".\\""Job\\"".\\""Comment\\"" AS \\""Comment\\"""" ""FROM"" ""  \\""dbo\\"".\\""Job\\"""" ""GROUP BY"" ""  \\""dbo\\"".\\""Job\\"".\\""Comment\\"""" ""ORDER BY"" ""  \\""dbo\\"".\\""Job\\"".\\""Comment\\"" ASC""], :params nil, :type :invalid-query}\r\n...\r\nCaused by: com.microsoft.sqlserver.jdbc.SQLServerException: The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator.\r\n...\r\n```', 'created_at': datetime.datetime(2024, 8, 19, 14, 59, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303539964, 'issue_id': 2362896730, 'author': 'Gourds', 'body': '+1', 'created_at': datetime.datetime(2024, 8, 22, 2, 8, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303589016, 'issue_id': 2362896730, 'author': 'musojames', 'body': ""I've had the same issue with BigQuery. Downgrading back to 49 has unblocked existing charts for me. Note that you need to run the migrations downgrade command with version 50, before launching 49 again to rollback."", 'created_at': datetime.datetime(2024, 8, 22, 3, 9, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304275889, 'issue_id': 2362896730, 'author': 'MarleTangible', 'body': ""@musojames I know that I need to run the following command but could you advise me and anyone who'll find this thread on how to downgrade with Docker?\r\n\r\n``` Shell\r\njava -jar metabase.jar migrate down\r\n```"", 'created_at': datetime.datetime(2024, 8, 22, 10, 5, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2305888231, 'issue_id': 2362896730, 'author': 'musojames', 'body': 'I did it running in docker. If you have an environment where you can connect to the DB directly run \r\n``` \r\ndocker run \\\r\n    -it \\\r\n    --entrypoint ""/bin/sh"" \\\r\n    -e MB_DB_CONNECTION_URI =""db connection string here"" \\\r\n    -e MB_ENCRYPTION_SECRET_KEY = ""Your encryption secret if you set one"" \\\r\n    metabase/metabase:v0.50.X # X here is the version you deployed. I had issues when my bug fix version didn\'t match the deployed.\r\n```\r\n\r\nthis will get you a Metabase container running with a shell session. \r\n\r\nOnce in the shell session run\r\n``` \r\ncd /app\r\njava -jar metabase.jar migrate down\r\n```` \r\n\r\nOnce you have successfully run the migration down, then deploy a `v0.49.*` version instead. \r\n\r\n\r\nIf you can\'t get direct access to your metabase DB. You can do the same as above by deploying a container in a location where it does have access to the db, with a script that does the above as the entrypoint.', 'created_at': datetime.datetime(2024, 8, 22, 23, 2, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310239615, 'issue_id': 2362896730, 'author': 'ranquild', 'body': ""We're going to fix this very soon. The queries that worked in v49 with numbers stored as strings will be working in v50 as long as the database supports it."", 'created_at': datetime.datetime(2024, 8, 26, 13, 37, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311006713, 'issue_id': 2362896730, 'author': 'MarleTangible', 'body': ""@ranquild \r\nShall I create a separate issue for the text filtering issue or do you think it's covered in this one? Currently we're not able to use the contains function if the automatic type discovery thought a column is `type/*` even though it is in fact `type/Text`."", 'created_at': datetime.datetime(2024, 8, 26, 20, 15, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312518688, 'issue_id': 2362896730, 'author': 'paoliniluis', 'body': '@MarleTangible please create a separate issue', 'created_at': datetime.datetime(2024, 8, 27, 13, 8, 54, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-19 18:30:30 UTC): This implies that you were able to sum strings before?

martin-knap (Issue Creator) on (2024-06-19 18:32:29 UTC): yes it worked when you changed type in table metadata in admin or in model

paoliniluis on (2024-06-19 18:37:29 UTC): maybe I'm not seeing something but why do you save numbers as strings in the database?

martin-knap (Issue Creator) on (2024-06-19 18:52:02 UTC): some ETL tools (e.g. Keboola) save all data in Snowflake as varchar and i cant change the setting or update metadata in storage :(

armetiz on (2024-06-21 08:46:33 UTC): Same problem here after upgrade to latest metabase OSS release. Also have a VARCHAR

armetiz on (2024-06-21 15:15:15 UTC): I've solved the problem, but I'm not sure I'm dealing with exactly the same issue as the author.

The problem was still present after changing the column type from VARCHAR to FLOAT. 
I checked the metabase error-log, and observed several information messages about type conversions. So I checked the correspondence of my model. The field had no specific category, so I associated my field with a ""price"", after which it worked.

Regards.

jkohlbach on (2024-07-08 03:13:01 UTC): We tried the fix @armetiz suggested but it didn't work out. Probably because we kept the columns as varchar, I'm guessing.

This seems like a regression, we're also in a situation where the column needs to be varchar and this has broken a ton of custom expressions. You can no longer sum or sumif for example.

Any chance this will be fixed on the next release or should we downgrade?

salman2learn on (2024-07-23 03:17:42 UTC): Same issue with OSS version using sqlite number data type.
Thanks.

SeshTiliRest on (2024-07-31 04:12:23 UTC): I have a similar problem with my multiple replacement after updating from v0.49.14 to v0.50.18.
MS SQL with TINYINT datatype.

![invalid](https://github.com/user-attachments/assets/5b6af0b7-36b2-4c98-891b-2bb272baa9d5)
`replace(replace(replace([Accept], ""1"", ""Ð""), ""0"", ""Ð’""), ""2"", ""Ðš"")`

![problem](https://github.com/user-attachments/assets/38037bc2-1aec-47fb-a66f-9795a9066855)
`Invalid query: {:stages [{:expressions [[nil nil [nil nil [nil nil [""expression returning a string""]]]]]}]}`

After deleting custom column with dat replace function - error is gone.
Looks related to #44807

douglas-regatieri on (2024-08-08 11:50:43 UTC): I encountered a similar error after updating to v0.50. I'm using Redshift, and the issue occurs with a SUM on a float8 datatype

martin-knap (Issue Creator) on (2024-08-13 07:26:50 UTC): this is also affecting columns formatted as number and trying to do `substring([Date Key], 1, 4)`

MarleTangible on (2024-08-19 14:59:48 UTC): I have a similar issue filtering varchar columns with MSSQL. There are similar columns with the same data type (varchar 15) but there are no issues with other columns. One thing that got my attention is that the table metadata shows the original schema as `type/*` while others are `type/Text`. Look like there's an issue with the table scan. Here's the error I get when I try to rescan the table.

```
2024-08-19 14:57:55,590 ERROR models.field-values :: Error fetching field values
clojure.lang.ExceptionInfo: Error executing query: The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator. {:driver :sqlserver, :sql [""-- Metabase"" ""SELECT"" ""  TOP(1000) \""dbo\"".\""Job\"".\""Comment\"" AS \""Comment\"""" ""FROM"" ""  \""dbo\"".\""Job\"""" ""GROUP BY"" ""  \""dbo\"".\""Job\"".\""Comment\"""" ""ORDER BY"" ""  \""dbo\"".\""Job\"".\""Comment\"" ASC""], :params nil, :type :invalid-query}
...
Caused by: com.microsoft.sqlserver.jdbc.SQLServerException: The text, ntext, and image data types cannot be compared or sorted, except when using IS NULL or LIKE operator.
...
```

Gourds on (2024-08-22 02:08:33 UTC): +1

musojames on (2024-08-22 03:09:57 UTC): I've had the same issue with BigQuery. Downgrading back to 49 has unblocked existing charts for me. Note that you need to run the migrations downgrade command with version 50, before launching 49 again to rollback.

MarleTangible on (2024-08-22 10:05:23 UTC): @musojames I know that I need to run the following command but could you advise me and anyone who'll find this thread on how to downgrade with Docker?

``` Shell
java -jar metabase.jar migrate down
```

musojames on (2024-08-22 23:02:01 UTC): I did it running in docker. If you have an environment where you can connect to the DB directly run 
``` 
docker run \
    -it \
    --entrypoint ""/bin/sh"" \
    -e MB_DB_CONNECTION_URI =""db connection string here"" \
    -e MB_ENCRYPTION_SECRET_KEY = ""Your encryption secret if you set one"" \
    metabase/metabase:v0.50.X # X here is the version you deployed. I had issues when my bug fix version didn't match the deployed.
```

this will get you a Metabase container running with a shell session. 

Once in the shell session run
``` 
cd /app
java -jar metabase.jar migrate down
```` 

Once you have successfully run the migration down, then deploy a `v0.49.*` version instead. 


If you can't get direct access to your metabase DB. You can do the same as above by deploying a container in a location where it does have access to the db, with a script that does the above as the entrypoint.

ranquild on (2024-08-26 13:37:43 UTC): We're going to fix this very soon. The queries that worked in v49 with numbers stored as strings will be working in v50 as long as the database supports it.

MarleTangible on (2024-08-26 20:15:47 UTC): @ranquild 
Shall I create a separate issue for the text filtering issue or do you think it's covered in this one? Currently we're not able to use the contains function if the automatic type discovery thought a column is `type/*` even though it is in fact `type/Text`.

paoliniluis on (2024-08-27 13:08:54 UTC): @MarleTangible please create a separate issue

"
2362787588,issue,closed,completed,Change auto-wiring undo timeout to 8s,[context](https://metaboat.slack.com/archives/C0645JP1W81/p1718800875524429?thread_ts=1718746656.589749&cid=C0645JP1W81),uladzimirdev,2024-06-19 16:47:05+00:00,['uladzimirdev'],2024-10-08 17:06:48+00:00,2024-06-20 08:48:48+00:00,https://github.com/metabase/metabase/issues/44423,"[('.Team/Querying', '')]",[],
2362704475,issue,closed,completed,Query changes are not accepted by the QB for some table questions if the query wasn't run before that,"### Describe the bug

If you open a table question in notebook mode without running it, changes to the query won't persist because of the FE error. The question must have a `table.columns` viz setting defined (e.g. if the order of columns was changed) Caused by #44053

### To Reproduce

1. New > Question > Orders > Visualize
2. Move around or resize table columns
3. Save the question, the open it with a link like `/quesiton/:id/notebook`
4. Try to update the query (e.g. add/update/remove an aggregation/breakout/filter)
5. The FE doesn't react visually, and there's an error in the console

### Expected behavior

It should be possible to update the query without running it first

### Logs

```
sync-settings.ts:116 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'cols')
    at sync-settings.ts:116:21
    at ee (sync-settings.ts:150:1)
    at updateQuestion.ts:142:7
    at Object.dispatch (redux-thunk.mjs:5:14)
    at dispatch (<anonymous>:6:7384)
    at n.<computed> (react-redux.mjs:356:47)
    at updateQuestion (Notebook.tsx:74:12)
    at NotebookSteps.tsx:77:13
    at a (NotebookSteps.tsx:96:17)
    at onRemove (FilterStep.tsx:62:5)
```

### Information about your Metabase installation

```JSON
v50.4
```


### Severity

P1

### Additional context

Workaround: run the query first and then do the update",kulyk,2024-06-19 15:54:21+00:00,['kulyk'],2024-06-19 17:33:04+00:00,2024-06-19 17:33:03+00:00,https://github.com/metabase/metabase/issues/44415,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2362474116,issue,closed,not_planned,[Flaky Test]: field settings should allow to rescan field values,"Last Flake: https://github.com/metabase/metabase/actions/runs/9569015651
Last Flake Time: 2024-06-18T10:15:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-06-19 14:02:32+00:00,[],2024-12-13 16:44:01+00:00,2024-12-13 16:44:01+00:00,https://github.com/metabase/metabase/issues/44409,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2362474067,issue,closed,completed,[Flaky Test]: should show columns available in the model (metabase#35039) (metabase#37009),"Last Flake: https://github.com/metabase/metabase/actions/runs/9557474309
Last Flake Time: 2024-06-17T19:08:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-06-19 14:02:31+00:00,[],2024-07-26 08:19:33+00:00,2024-07-26 08:19:33+00:00,https://github.com/metabase/metabase/issues/44408,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]","[{'comment_id': 2252221286, 'issue_id': 2362474067, 'author': 'nemanjaglumac', 'body': 'Fixed by #46038', 'created_at': datetime.datetime(2024, 7, 26, 8, 19, 33, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-26 08:19:33 UTC): Fixed by #46038

"
2362474012,issue,closed,not_planned,[Flaky Test]: can add/remove bookmark from pinned Question in collection,"Last Flake: https://github.com/metabase/metabase/actions/runs/9561812464
Last Flake Time: 2024-06-18T01:40:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 2
Flakes in the last 7d: 2",github-automation-metabase,2024-06-19 14:02:29+00:00,[],2024-12-13 16:45:40+00:00,2024-12-13 16:45:40+00:00,https://github.com/metabase/metabase/issues/44407,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2362473978,issue,closed,not_planned,[Flaky Test]: Modal should switch back to the default tab when the search query is cleared,"Last Flake: https://github.com/metabase/metabase/actions/runs/9571310892
Last Flake Time: 2024-06-18T13:09:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 2
Flakes in the last 7d: 3",github-automation-metabase,2024-06-19 14:02:28+00:00,[],2024-12-13 16:44:01+00:00,2024-12-13 16:44:01+00:00,https://github.com/metabase/metabase/issues/44406,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2362473949,issue,closed,not_planned,[Flaky Test]: should set utm_source,"Last Flake: https://github.com/metabase/metabase/actions/runs/9548035338
Last Flake Time: 2024-06-17T05:53:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 2
Flakes in the last 7d: 4",github-automation-metabase,2024-06-19 14:02:27+00:00,[],2024-12-13 16:45:39+00:00,2024-12-13 16:45:39+00:00,https://github.com/metabase/metabase/issues/44405,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2362455036,issue,open,,"""is not empty"" filter generates incorrect SQL","### Describe the bug

I set a ""is not empty"" filter option or a field in a Question and expect it to return not empty results, however the query times out on me. (the underlying table is rather huge in redshift).

When looking at the generated SQL this is what is built (
```
 AND (
    ""table"".""field"" IS NOT NULL
  )
  AND (
    (
      ""table"".""field"" <> ''
    )
    OR (
      ""table"".""field"" IS NULL
    )
  )
```

Which seems completely incorrect as it should be like this

```
 AND (
   (
    ""table"".""field"" IS NOT NULL
  )
 OR (
    ""table"".""field"" <> ''
  )
)
```
(the second one actually completes and does not time out.  Though just doing is not null works even faster)

### To Reproduce

1. start a new question
2. add a ""not empty"" field filter for a field that is text/varchar and nullable.
3. look at the generated SQL

### Expected behavior

More correct SQL should be generated.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- metabase version 0.49.6 (and tested on 0.50.6 as well)
- browser: n/a
- underlying DB for queries irrelevant (tested against redshfit and postgres)
```


### Severity

annoying

### Additional context

_No response_",urkle,2024-06-19 13:53:40+00:00,[],2025-02-04 20:28:34+00:00,,https://github.com/metabase/metabase/issues/44403,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Redshift', None), ('Querying/Processor', ''), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', '')]",[],
2362421206,issue,open,,The no-op rollback log on custom migrations is misleading,"### Describe the bug

Migrations defined in `metabase.db.custom-migrations` sometimes have a custom rollback using `define-reversible-migration`  (`AddJoinAliasToVisualizationSettingsFieldRefs`, `DowngradeDashboardTab`, etc). But some do not need a reverse migration like `CreateInternalUser`, which does not want to remove the user when downgrading. 

The migration without a reverse is constructed with a reverse migration that is a no-op, logging implementation:

```clojure
(defn no-op
  ""No-op logging rollback function""
  [n]
  (log/info ""No rollback for: "" n))

(defmacro define-migration
  ""Define a custom migration without a reverse migration.""
  [name & migration-body]
  `(define-reversible-migration ~name (do ~@migration-body) (no-op ~(str name))))```

This logs:

```
Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-16 04:50:53,352 INFO db.setup :: Setting up Liquibase...
2024-06-16 04:50:54,002 INFO db.setup :: Liquibase is ready.
2024-06-16 04:50:54,006 INFO db.liquibase :: Rolling back app database schema to version 48
2024-06-16 04:50:54,499 INFO db.custom-migrations :: No rollback for:  DeleteScanFieldValuesTriggerForDBThatTurnItOff
2024-06-16 04:50:54,513 INFO db.custom-migrations :: No rollback for:  DeleteTruncateAuditLogTask
```

These logs are misleading to customers and to engineers alike as it seems like the rollback mechanism is unable to find a rollback rather than the rollback works as intended but just has nothing to do.

### To Reproduce

```
# instantiate to 50
MB_JETTY_PORT=3006 java -jar 0.50.5.jar
... [ lots of logs]
# migrate down a version
MB_JETTY_PORT=3006 java -jar 0.50.5.jar migrate down
... [ lots of logs]
2024-06-19 08:38:38,985 INFO db.custom-migrations :: No rollback for:  DeleteSendPulsesTask
2024-06-19 08:38:39,025 INFO db.custom-migrations :: No rollback for:  CreateInternalUser
```

### Expected behavior

we should not appear as if we don't recognize the down migrations

### Logs

_No response_

### Information about your Metabase installation

```JSON
50.x
```


### Severity

p2

### Additional context

_No response_",dpsutton,2024-06-19 13:40:58+00:00,[],2024-06-20 14:32:04+00:00,,https://github.com/metabase/metabase/issues/44400,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2361986509,issue,closed,completed,Support using custom fonts from the host app in embedding sdk,"Enable SDK customers to use fonts from the host application (e.g. external fonts instead of using the custom font defined in the Metabase instance.

A key limitation is that there can only be one single custom font configured in the Metabase instance, so we cannot use multiple fonts for different viz elements.

There are places where we query the font from the settings directly instead of using the front from the theme, which we have to fix. One example is [the Visualization component](https://github.com/metabase/metabase/blob/dcc6aad57a43cd819005c457b8e6fd85aa69fb62/frontend/src/metabase/visualizations/components/Visualization/Visualization.jsx#L69).
",heypoom,2024-06-19 10:29:24+00:00,[],2024-11-07 17:28:47+00:00,2024-11-07 17:28:47+00:00,https://github.com/metabase/metabase/issues/44394,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2462831575, 'issue_id': 2361986509, 'author': 'heypoom', 'body': 'Custom fonts are already supported - I tested with every viz. Here are some screenshots:\n\n![Image](https://github.com/user-attachments/assets/04e21b5b-1a9d-4d4c-a99e-53d820d32121)\n\n![Image](https://github.com/user-attachments/assets/c324d8b3-9d1f-4be4-930c-c651aa29fb19)\n\n![Image](https://github.com/user-attachments/assets/fdc55496-bb0f-424c-80c6-4b59c77802e3)', 'created_at': datetime.datetime(2024, 11, 7, 17, 28, 34, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-07 17:28:34 UTC): Custom fonts are already supported - I tested with every viz. Here are some screenshots:

![Image](https://github.com/user-attachments/assets/04e21b5b-1a9d-4d4c-a99e-53d820d32121)

![Image](https://github.com/user-attachments/assets/c324d8b3-9d1f-4be4-930c-c651aa29fb19)

![Image](https://github.com/user-attachments/assets/fdc55496-bb0f-424c-80c6-4b59c77802e3)

"
2361971393,issue,open,,[Epic] Rework Bookmarks,"Bookmarks could use some love.
- they are their own entities on the FE that contain duplicate information about the bookmarked item. IE: if a card is bookmarked, it's name is stored in 2 separate places, but must be kept in sync
- entities don't know that they are bookmarked.
- archived items aren't returned in the bookmark list. This (coupled with the above) means that we don't know if an item is bookmarked or not when it's restored
- they don't have their own ids, they're purely derived, e.g. (`dashboard-343` and `question-575`)
- they get updated by other entity actions - renaming a dashboard should also update the bookmark
- they don't use RTK query
- the ""Specialness"" of bookmarks couples them to a lot of things in ways that are non-obvious, and is likely to continue producing bugs.

Bookmarks themselves are a pretty small feature, so it might be hard to justify the user impact here.


See:
- https://github.com/metabase/metabase/pull/44384
- https://github.com/metabase/metabase/pull/38443",iethree,2024-06-19 10:21:30+00:00,[],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/44393,"[('Type:Tech Debt', 'or Refactoring')]","[{'comment_id': 2363696704, 'issue_id': 2361971393, 'author': 'paulg66', 'body': 'Something to add to this - In situations where a user has access to a dashboard, bookmarks it, but the access to the collection is revoked, the bookmark is still shown in the bookmarks tab for that user.', 'created_at': datetime.datetime(2024, 9, 20, 13, 6, 22, tzinfo=datetime.timezone.utc)}]","paulg66 on (2024-09-20 13:06:22 UTC): Something to add to this - In situations where a user has access to a dashboard, bookmarks it, but the access to the collection is revoked, the bookmark is still shown in the bookmarks tab for that user.

"
2361967493,issue,closed,completed,Update D3.js to a newer version for Vite compatibility in embedding sdk,"We want to unblock embedding SDK customers who are using Vite, which uses Rollup and ESBuild under the hood.

The incompability with Vite was caused by the very old version of D3.js that cannot be bundled by Rollup, the bundler used by Vite under the hood, which results in a [runtime error](https://stackoverflow.com/questions/56400413/d3-js-runtime-error-after-upgrade-to-angular-8). We're using D3.js version 3.5.17, released 8 years ago.

> [StackOverflow](https://stackoverflow.com/questions/35560305/d3-js-uncaught-typeerror-cannot-read-property-document-of-undefined): It sounds like [[Rollup](https://github.com/evanw/esbuild/issues/2264)] is inserting ""use strict""; at the beginning of the D3 script file or combining it into another file with ""use strict"" at the top. That means this at global scope (or in a function called without a specific this) is no longer a reference to the global object, it's undefined. Whereas in ""loose"" mode or in a function called with no specific this value, this at global scope is a reference to the global object, which is also accessible via the global variable `window1.

### The most minimal version possible to upgrade

D3 version 4.0 changes to ES6 Strict Mode, so 4.0 is the lowest possible version that enables Vite to work.

> D3 now ships as pure ES modules and requires Node.js 12 or higher. For more, please read [Sindre Sorhusâ€™s FAQ](https://gist.github.com/sindresorhus/a39789f98801d908bbc7ff3ecc99d99c). [snip] The adoption of ES6 modules also means that D3 is now written exclusively in [strict mode](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Strict_mode) and has better readability. Refer to https://github.com/d3/d3/blob/main/CHANGES.md",heypoom,2024-06-19 10:19:41+00:00,['heypoom'],2024-10-08 17:06:06+00:00,2024-06-26 07:06:58+00:00,https://github.com/metabase/metabase/issues/44392,"[('Embedding/SDK', 'Embedding SDK for React')]",[],
2361929128,issue,closed,completed,Embedding SDK components has missing CSS variables when rendering in a React portal,"- When adding the embedding SDK components such as an Interactive Question to a modal, the filter colors from the theme settings are not applied. See (1)

![CleanShot 2567-06-20 at 19 02 43@2x](https://github.com/metabase/metabase/assets/4714175/564e5e29-9f22-4bd7-86dc-74c40c4675a4)
",heypoom,2024-06-19 10:02:13+00:00,['heypoom'],2024-10-08 17:06:15+00:00,2024-06-25 05:51:53+00:00,https://github.com/metabase/metabase/issues/44391,"[('Embedding/SDK', 'Embedding SDK for React')]",[],
2361789567,issue,closed,not_planned,Displayed table path is not consistent,"### Describe the bug

When I browse a table from the ""Browse"" page, then click on the database I want to navigate to, then navigate folders and finally click on a table to view it, the correct path is shown on the top left corner:

<img width=""241"" alt=""Screenshot 2024-06-19 at 10 47 24"" src=""https://github.com/metabase/metabase/assets/69579602/e3a5b7e4-084f-4842-911a-8ca1714e1a0f"">

However if I use the new search box popup to look for the same table, the path shown on the corner is missing the folder(s) name(s) in which the table is located:

<img width=""221"" alt=""Screenshot 2024-06-19 at 10 48 33"" src=""https://github.com/metabase/metabase/assets/69579602/1c2eee89-9d07-456d-8e0c-3bbd57ff7e0a"">

This creates inconsistency and in the case we have a database in which different folders have tables with same names, it's ambiguous to know which table is which.

### To Reproduce

1. Go to Metabase
2. Click on the search box or press Command/Ctrl + K
3. Type the name of table which is in a folder inside a database (not at the root of the database)
4. Click on the result to open the table
5. See the missing folder(s) name(s) on the top left corner


### Expected behavior

I should see the full path of the table just as when I access it via the Browse page.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.11+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.11"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.11+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.58+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",Timelessprod,2024-06-19 09:01:18+00:00,[],2024-10-22 15:34:29+00:00,2024-10-22 15:19:11+00:00,https://github.com/metabase/metabase/issues/44389,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Browse Data', '')]","[{'comment_id': 2284815847, 'issue_id': 2361789567, 'author': 'luizarakaki', 'body': ""@Timelessprod I'm not able to reproduce this. Can you check if this is still happening on the latest release?"", 'created_at': datetime.datetime(2024, 8, 12, 20, 6, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285517342, 'issue_id': 2361789567, 'author': 'Timelessprod', 'body': 'I will check once we will update yes', 'created_at': datetime.datetime(2024, 8, 13, 7, 15, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296206842, 'issue_id': 2361789567, 'author': 'Timelessprod', 'body': '@luizarakaki It\'s still happening on v0.50.20 on my side.\r\n\r\nEverytime I have tables pairs like:\r\n- `Database_1/Folder_1/Table_1`\r\n- `Database_1/Folder_2/Table_1`\r\n- ...\r\n- `Database_1/Folder_n/Table_1`\r\n\r\nand I start a search from the searchbox, Metabase will list all n tables with just their name (so I can\'t tell which table is from which folder cf. my feature request https://github.com/metabase/metabase/issues/44388). When I open any of these results from the search popup, Metabase will show the table name as ""Database_1 / Table_1"" on the top left corner, so I don\'t know if it\'s from folder 1 or 2 or 3 ... or n. This means I don\'t know what data I\'m looking at and have to go to browse section and manually find it myself in the end, thus time consuming.', 'created_at': datetime.datetime(2024, 8, 19, 10, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429576486, 'issue_id': 2361789567, 'author': 'rafpaf', 'body': ""Thanks @Timelessprod for your patience. I'm also struggling to reproduce this issue. I'm using a postgres db with multiple schemas (I'm assuming what you call folders are schemas). The names of the schemas appear next to the table names in the Command Palette (the new search box). When I click a table name in the Command Palette, I next see a page that contains the name of the table, along with the name of its schema. If you're able to share a little more about how your database is configured, I can take a second look.\n\nFor now I'm closing this issue, but I'll gladly re-open it later if you can show me more about how this bug arose for you."", 'created_at': datetime.datetime(2024, 10, 22, 15, 19, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429614084, 'issue_id': 2361789567, 'author': 'Timelessprod', 'body': '@rafpaf FYI I am using BigQuery thus the folders are folders not schemas.\n\nIndeed now the search pop up is showing the folder name which helps a lot but I still notice the inconsistency bug on the table name when going via the search pop up or via the browse tab.', 'created_at': datetime.datetime(2024, 10, 22, 15, 34, 27, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-08-12 20:06:05 UTC): @Timelessprod I'm not able to reproduce this. Can you check if this is still happening on the latest release?

Timelessprod (Issue Creator) on (2024-08-13 07:15:54 UTC): I will check once we will update yes

Timelessprod (Issue Creator) on (2024-08-19 10:13:05 UTC): @luizarakaki It's still happening on v0.50.20 on my side.

Everytime I have tables pairs like:
- `Database_1/Folder_1/Table_1`
- `Database_1/Folder_2/Table_1`
- ...
- `Database_1/Folder_n/Table_1`

and I start a search from the searchbox, Metabase will list all n tables with just their name (so I can't tell which table is from which folder cf. my feature request https://github.com/metabase/metabase/issues/44388). When I open any of these results from the search popup, Metabase will show the table name as ""Database_1 / Table_1"" on the top left corner, so I don't know if it's from folder 1 or 2 or 3 ... or n. This means I don't know what data I'm looking at and have to go to browse section and manually find it myself in the end, thus time consuming.

rafpaf on (2024-10-22 15:19:11 UTC): Thanks @Timelessprod for your patience. I'm also struggling to reproduce this issue. I'm using a postgres db with multiple schemas (I'm assuming what you call folders are schemas). The names of the schemas appear next to the table names in the Command Palette (the new search box). When I click a table name in the Command Palette, I next see a page that contains the name of the table, along with the name of its schema. If you're able to share a little more about how your database is configured, I can take a second look.

For now I'm closing this issue, but I'll gladly re-open it later if you can show me more about how this bug arose for you.

Timelessprod (Issue Creator) on (2024-10-22 15:34:27 UTC): @rafpaf FYI I am using BigQuery thus the folders are folders not schemas.

Indeed now the search pop up is showing the folder name which helps a lot but I still notice the inconsistency bug on the table name when going via the search pop up or via the browse tab.

"
2361748477,issue,closed,not_planned,Add table path on the new search popup,"**Is your feature request related to a problem? Please describe.**
The new search popup looks great (congrats for adding it!) but it needs some adjustments.

In the case where a database has multiple folders and those folders contain tables which have the same names (alice/path/to/mytable/my_table and bob/path/to/mytable/my_table for example), the search popup will show all tables with the same name and database name but no other information to distinguish them:

<img width=""705"" alt=""Screenshot 2024-06-19 at 10 35 08"" src=""https://github.com/metabase/metabase/assets/69579602/19c6ed9f-da80-463e-920d-092d909a5d6a"">

Thus I am unable to know which table is which. There's no more information shown when hovering the results too.

**Describe the solution you'd like**
I would like the full path to the table displayed and not only the database name. Or at minimal show a hovering information bubble with the path.

<img width=""706"" alt=""Screenshot 2024-06-19 at 10 36 09"" src=""https://github.com/metabase/metabase/assets/69579602/a3732867-e06a-43a2-9dd1-1b7cc5f9336d"">

**Describe alternatives you've considered**
The only alternative for now is to open all results and hope to find the one we are looking for

**How important is this feature to you?**
Very important since our architecture is meant to have tables with the same names across different folders on a same database, and the current situation could confuse users and especially admins which have access to all tables.

**Additional context**
None.
",Timelessprod,2024-06-19 08:41:45+00:00,[],2024-10-23 07:43:09+00:00,2024-10-22 15:20:54+00:00,https://github.com/metabase/metabase/issues/44388,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Needs Triage', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2296210054, 'issue_id': 2361748477, 'author': 'Timelessprod', 'body': 'Any follow up on this please? From my side it makes the search engine useless and I always have to go through the browse section.', 'created_at': datetime.datetime(2024, 8, 19, 10, 14, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429580638, 'issue_id': 2361748477, 'author': 'rafpaf', 'body': ""I'm closing this for now, with an explanation at https://github.com/metabase/metabase/issues/44389. I wasn't able to reproduce the problem, but @Timelessprod, feel free to provide more detailed information and I'll gladly re-open it."", 'created_at': datetime.datetime(2024, 10, 22, 15, 20, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429617110, 'issue_id': 2361748477, 'author': 'Timelessprod', 'body': 'It has been fixed with recent updates, the path (or at least the first folder) is shown next to the DB name in parenthesis. Thanks for that !', 'created_at': datetime.datetime(2024, 10, 22, 15, 35, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429636941, 'issue_id': 2361748477, 'author': 'dpsutton', 'body': '![Image](https://github.com/user-attachments/assets/5a16fe63-3cb7-4343-8a09-d98dbf8a9613)\n\n\nThis is the view i have with the following two tables named `foo`:\n\n```sql\ntesting=# create schema s1;\nCREATE SCHEMA\ntesting=# create schema s2;\nCREATE SCHEMA\ntesting=# create table s1.foo(id text);\nCREATE TABLE\ntesting=# create table s2.foo(id text);\nCREATE TABLE\n```\n\nThe tables are distinguishable. This means we are good?', 'created_at': datetime.datetime(2024, 10, 22, 15, 43, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431171326, 'issue_id': 2361748477, 'author': 'Timelessprod', 'body': 'I rely on bigquery so folders are equivalent to schemas in postgres in Metabase UI and indeed with an architecture like this:\n```\ndatabase1\n    folder1\n        foo\n        bar\n    folder2\n        foo\n```\n\nI now get something like this:\n![Image](https://github.com/user-attachments/assets/1373bc0e-c5e6-4112-946d-2f18c49ccaa1)\n\nSo now indeed we are able to distinguish tables with the same name across different folders/schemas within the same database! ðŸ«¶', 'created_at': datetime.datetime(2024, 10, 23, 7, 43, 7, tzinfo=datetime.timezone.utc)}]","Timelessprod (Issue Creator) on (2024-08-19 10:14:30 UTC): Any follow up on this please? From my side it makes the search engine useless and I always have to go through the browse section.

rafpaf on (2024-10-22 15:20:54 UTC): I'm closing this for now, with an explanation at https://github.com/metabase/metabase/issues/44389. I wasn't able to reproduce the problem, but @Timelessprod, feel free to provide more detailed information and I'll gladly re-open it.

Timelessprod (Issue Creator) on (2024-10-22 15:35:44 UTC): It has been fixed with recent updates, the path (or at least the first folder) is shown next to the DB name in parenthesis. Thanks for that !

dpsutton on (2024-10-22 15:43:25 UTC): ![Image](https://github.com/user-attachments/assets/5a16fe63-3cb7-4343-8a09-d98dbf8a9613)


This is the view i have with the following two tables named `foo`:

```sql
testing=# create schema s1;
CREATE SCHEMA
testing=# create schema s2;
CREATE SCHEMA
testing=# create table s1.foo(id text);
CREATE TABLE
testing=# create table s2.foo(id text);
CREATE TABLE
```

The tables are distinguishable. This means we are good?

Timelessprod (Issue Creator) on (2024-10-23 07:43:07 UTC): I rely on bigquery so folders are equivalent to schemas in postgres in Metabase UI and indeed with an architecture like this:
```
database1
    folder1
        foo
        bar
    folder2
        foo
```

I now get something like this:
![Image](https://github.com/user-attachments/assets/1373bc0e-c5e6-4112-946d-2f18c49ccaa1)

So now indeed we are able to distinguish tables with the same name across different folders/schemas within the same database! ðŸ«¶

"
2360891941,issue,closed,not_planned,If you archive the dashboard you get in /api/activity/most_recently_viewed_dashboard then the modal to add a question gets weird,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/1711649/d94d44b7-54ea-447f-8384-c2be1f7348f4)


### To Reproduce

1) create an x-ray
2) archive it
3) now create a new question and then click to save it and add it do a dashboard
4) see the modal with ""The object has been archived.""

### Expected behavior

Product needed for this

### Logs

NA

### Information about your Metabase installation

```JSON
v50.x
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-06-18 23:11:32+00:00,[],2024-07-12 23:41:30+00:00,2024-07-12 23:41:30+00:00,https://github.com/metabase/metabase/issues/44382,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/', ''), ('.Backend', ''), ('.Product Input Needed', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2177240864, 'issue_id': 2360891941, 'author': 'ranquild', 'body': ""I'm pretty sure that `most_recently_viewed_dashboard` shouldn't return an archived dashboard"", 'created_at': datetime.datetime(2024, 6, 18, 23, 19, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2209073024, 'issue_id': 2360891941, 'author': 'kamilmielnik', 'body': ""Reproducible in 0.50.0 and 0.50.6. Can't reproduce in `master` at 638d79c457.\r\nReassigning to AdminWebapp (because it's Entity Picker + Trash + Recents API) to provide a repro."", 'created_at': datetime.datetime(2024, 7, 4, 14, 0, 11, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-06-18 23:19:12 UTC): I'm pretty sure that `most_recently_viewed_dashboard` shouldn't return an archived dashboard

kamilmielnik on (2024-07-04 14:00:11 UTC): Reproducible in 0.50.0 and 0.50.6. Can't reproduce in `master` at 638d79c457.
Reassigning to AdminWebapp (because it's Entity Picker + Trash + Recents API) to provide a repro.

"
2360891470,issue,closed,not_planned,Missing filter in dashboard chart,"### Describe the bug

In the dashboard of one of our customers, Metabase is dropping one of the filters defined in a chart question when the chart is opened by clicking on its title. This issue leads to incorrect data being displayed, which undermines the reliability of the dashboard.

See video: https://www.loom.com/share/c94966bfe4c845e992c59e736858e632?sid=d8573159-52c0-4dc7-b234-25da7992a9e8

When opening the chart's question directly by clicking on ""Edit Question,"" the filter ""Max out_of_sla is equal to 1"" is present and the data displayed is correct. The issue only occurs when accessing the chart through the dashboard.

### To Reproduce

1. Navigate to the dashboard.
2. Locate the chart in question.
3. Click on the chart's title to open it.
4. In the chart view, click on ""Show Editor.""


### Expected behavior

The filter defined in the chart question, `Max out_of_sla is equal to 1`, should be retained and applied when opening the chart through the dashboard.



### Logs

_No response_

### Information about your Metabase installation

```JSON

v48.10

```


### Severity

blocking

### Additional context

_No response_",meldiner,2024-06-18 23:11:01+00:00,[],2024-08-28 02:08:51+00:00,2024-06-18 23:17:14+00:00,https://github.com/metabase/metabase/issues/44381,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/MBQL', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 2177235274, 'issue_id': 2360891470, 'author': 'paoliniluis', 'body': ""version? we need the version to see what's going on and the context"", 'created_at': datetime.datetime(2024, 6, 18, 23, 12, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177237760, 'issue_id': 2360891470, 'author': 'meldiner', 'body': 'v48.10', 'created_at': datetime.datetime(2024, 6, 18, 23, 15, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177239299, 'issue_id': 2360891470, 'author': 'paoliniluis', 'body': '@meldiner ok, upgrade to, at least, 49.15 and then we can see if this is an issue or not. Closing the issue till then', 'created_at': datetime.datetime(2024, 6, 18, 23, 17, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177745021, 'issue_id': 2360891470, 'author': 'tovbinm', 'body': 'Are there any fixes in the latest version that address this issue?', 'created_at': datetime.datetime(2024, 6, 19, 4, 58, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2178586274, 'issue_id': 2360891470, 'author': 'ranquild', 'body': '@tovbinm yes - we fixed some bugs with filter application in v50', 'created_at': datetime.datetime(2024, 6, 19, 12, 30, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181372648, 'issue_id': 2360891470, 'author': 'meldiner', 'body': ""This reproduces with the same chart on a newly created clean dashboard.\r\n\r\nI'm going to try reproducing this locally with a newer Metabase version."", 'created_at': datetime.datetime(2024, 6, 20, 19, 21, 7, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-18 23:12:15 UTC): version? we need the version to see what's going on and the context

meldiner (Issue Creator) on (2024-06-18 23:15:18 UTC): v48.10

paoliniluis on (2024-06-18 23:17:14 UTC): @meldiner ok, upgrade to, at least, 49.15 and then we can see if this is an issue or not. Closing the issue till then

tovbinm on (2024-06-19 04:58:04 UTC): Are there any fixes in the latest version that address this issue?

ranquild on (2024-06-19 12:30:40 UTC): @tovbinm yes - we fixed some bugs with filter application in v50

meldiner (Issue Creator) on (2024-06-20 19:21:07 UTC): This reproduces with the same chart on a newly created clean dashboard.

I'm going to try reproducing this locally with a newer Metabase version.

"
2360885019,issue,closed,completed,Don't infer wildcard usage for expressions like COUNT(*),"We can falsely believe that a whole bunch of fields are being referenced, when in bunch none are.

```sql
SELECT COUNT(*) FROM bar
```
Could result in the following `QueryField` instances in Metabase:

```edn
[{:table ""bar"" :column ""foo""}
 {:table ""bar"" :column ""goo""}]
```",crisptrutski,2024-06-18 23:04:30+00:00,['crisptrutski'],2024-06-20 09:21:31+00:00,2024-06-20 09:21:31+00:00,https://github.com/metabase/metabase/issues/44380,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2360878140,issue,closed,completed,Making a model that joins a table 2 times will generate wrong x-rays,"### Describe the bug

A query that is extremely wrong formed is made out of an x-ray
![image](https://github.com/metabase/metabase/assets/1711649/84ab2ef5-e912-4855-a31c-4b12f6aec774)

### To Reproduce

1) do new question: orders join people join people
2) save it as a model
3) x-ray the model

see the queries that are being generated

### Expected behavior

It should generate correct queries

### Logs

NA

### Information about your Metabase installation

```JSON
v50.x
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-06-18 22:57:44+00:00,['piranha'],2024-06-24 08:36:20+00:00,2024-06-24 07:13:17+00:00,https://github.com/metabase/metabase/issues/44379,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/X-rays', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2178585681, 'issue_id': 2360878140, 'author': 'bshepherdson', 'body': ""This smells like the sort of thing that's seen in #36185 symptoms, though in this case outside the QP/QB stack.\r\n\r\nWatch out for treating field IDs, or indeed almost anything about columns, as unique keys."", 'created_at': datetime.datetime(2024, 6, 19, 12, 30, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180178260, 'issue_id': 2360878140, 'author': 'piranha', 'body': 'From what I\'ve learned so far it seems like x-rays try to apply `created_at > last 30 days` filter on top of model definition - and model, after aggregation, just has not enough data (only id and count, no created_at) to make this work. This has nothing to do with two joins - removing one of the joins will not make this work, removing aggregation makes x-rays work even with two joins.\r\n\r\nSeems like a logic bug in the x-rays generation â€” how and why do they find this filter and try to apply it on top of a model (which has it applied already)?\r\n\r\nExample query x-rays generate:\r\n\r\n```\r\n@imai ~/dev/misc/reelsnap> pbpaste | edn\r\n{:database 1,\r\n :query {:aggregation [[""count""]],\r\n         :breakout [],\r\n         :filter [""time-interval""\r\n                  [""field"" 41 {:base-type ""type/DateTime""}]\r\n                  -30\r\n                  ""day""],\r\n         :joins [{:alias ""People - User"",\r\n                  :condition [""=""\r\n                              [""field"" 43 {:base-type ""type/Integer""}]\r\n                              [""field""\r\n                               46\r\n                               {:base-type ""type/BigInteger"",\r\n                                :join-alias ""People - User""}]],\r\n                  :fields ""all"",\r\n                  :source-table 3}],\r\n         :source-table ""card__111""},\r\n :type ""query""}\r\n```\r\n\r\nNotice the filter, which is *already* applied to the `card__111`, so having it changes absolutely nothing.', 'created_at': datetime.datetime(2024, 6, 20, 9, 1, 28, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-06-19 12:30:21 UTC): This smells like the sort of thing that's seen in #36185 symptoms, though in this case outside the QP/QB stack.

Watch out for treating field IDs, or indeed almost anything about columns, as unique keys.

piranha (Assginee) on (2024-06-20 09:01:28 UTC): From what I've learned so far it seems like x-rays try to apply `created_at > last 30 days` filter on top of model definition - and model, after aggregation, just has not enough data (only id and count, no created_at) to make this work. This has nothing to do with two joins - removing one of the joins will not make this work, removing aggregation makes x-rays work even with two joins.

Seems like a logic bug in the x-rays generation â€” how and why do they find this filter and try to apply it on top of a model (which has it applied already)?

Example query x-rays generate:

```
@imai ~/dev/misc/reelsnap> pbpaste | edn
{:database 1,
 :query {:aggregation [[""count""]],
         :breakout [],
         :filter [""time-interval""
                  [""field"" 41 {:base-type ""type/DateTime""}]
                  -30
                  ""day""],
         :joins [{:alias ""People - User"",
                  :condition [""=""
                              [""field"" 43 {:base-type ""type/Integer""}]
                              [""field""
                               46
                               {:base-type ""type/BigInteger"",
                                :join-alias ""People - User""}]],
                  :fields ""all"",
                  :source-table 3}],
         :source-table ""card__111""},
 :type ""query""}
```

Notice the filter, which is *already* applied to the `card__111`, so having it changes absolutely nothing.

"
2360656419,issue,open,,[MBQL lib] `filter-parts` wrongly assumes the first argument is always a `:field`-like clause,"That assumption is true in the GUI but other features can add queries which don't fit this pattern.

In particular, sandboxing adds filters where the LHS is a `[:!= {} [:field ...] 0]` subexpression. `filter-parts` tries to pass that as `a-ref` to `lib.equality/find-matching-column` and it throws because `:!=` is not `:field`, `:expression` or `:aggregation`.

It's not clear whether this is the cause of the performance regression reported in #44359.",bshepherdson,2024-06-18 20:30:50+00:00,['bshepherdson'],2025-02-04 20:27:11+00:00,,https://github.com/metabase/metabase/issues/44376,"[('Querying/MBQL', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]","[{'comment_id': 2394420271, 'issue_id': 2360656419, 'author': 'appleby', 'body': 'This also crops up when calculating field usages in `filter->field-usage` if your filter expression is a compound expression like `[:or x y]` where `x` is a subexpression rather than a ref.', 'created_at': datetime.datetime(2024, 10, 4, 19, 19, 36, tzinfo=datetime.timezone.utc)}]","appleby on (2024-10-04 19:19:36 UTC): This also crops up when calculating field usages in `filter->field-usage` if your filter expression is a compound expression like `[:or x y]` where `x` is a subexpression rather than a ref.

"
2360544577,issue,open,,Migration - remove parameter mappings to native models,"Bug https://github.com/metabase/metabase/issues/44288
FE PR https://github.com/metabase/metabase/pull/44372

We decided to disable parameter mapping to native models https://github.com/metabase/metabase/issues/44288#issuecomment-2173737837 but there could be existing mappings that we need to handle. To not come to this again we need to run a migration and remove broken mappings at once.",ranquild,2024-06-18 19:24:50+00:00,[],2024-06-18 19:27:21+00:00,,https://github.com/metabase/metabase/issues/44374,"[('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2360508775,issue,closed,completed,Don't sort official collections first in the trash,,johnswanson,2024-06-18 19:02:48+00:00,[],2024-10-08 17:06:39+00:00,2024-06-20 21:17:39+00:00,https://github.com/metabase/metabase/issues/44373,[],[],
2360329112,issue,closed,not_planned,Distinct([...]) * -1 results in invalid query with MongoDB,"### Describe the bug

Using MongoDB, attempting to combine arithmetic operations with the output of `Distinct([...])` will lead to an invalid query.

A possible workaround is to use a custom column after aggregation, however, the presence of a custom column would not allow binding dashboard filters to columns in the pre-aggregation stage.

### To Reproduce

1. Use the mongodb sample database
2. Create a GUI question: Products, 
Group by: Category, Summarize by a custom expression: `Distinct([ID]) * -1`
3. Visualize
4. See the error: 
`Command failed with error 14 (TypeMismatch): 'PlanExecutor error during aggregation :: caused by :: $multiply only supports numeric types, not array' on server host.docker.internal:27017. The full response is {""ok"": 0.0, ""errmsg"": ""PlanExecutor error during aggregation :: caused by :: $multiply only supports numeric types, not array"", ""code"": 14, ""codeName"": ""TypeMismatch""}`

Native query for the question:

```
[
  {
    ""$group"": {
      ""_id"": {
        ""category"": ""$category""
      },
      ""NegativeDistinct~count"": {
        ""$addToSet"": ""$_id""
      }
    }
  },
  {
    ""$addFields"": {
      ""NegativeDistinct"": {
        ""$multiply"": [
          ""$NegativeDistinct~count"",
          -1
        ]
      }
    }
  },
  {
    ""$sort"": {
      ""_id"": 1
    }
  },
  {
    ""$project"": {
      ""_id"": false,
      ""category"": ""$_id.category"",
      ""NegativeDistinct"": true
    }
  }
]

```

### Expected behavior

It should work.

### Logs

n/a

### Information about your Metabase installation

```JSON
1.49.16
```


### Severity

Reported by a priority customer

### Additional context

_No response_",zbodi74,2024-06-18 17:09:53+00:00,[],2024-06-18 17:28:25+00:00,2024-06-18 17:28:25+00:00,https://github.com/metabase/metabase/issues/44371,"[('Type:Bug', 'Product defects'), ('Database/Mongo', None), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Needs Triage', '')]","[{'comment_id': 2176618240, 'issue_id': 2360329112, 'author': 'zbodi74', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/35425 .', 'created_at': datetime.datetime(2024, 6, 18, 17, 28, 25, tzinfo=datetime.timezone.utc)}]","zbodi74 (Issue Creator) on (2024-06-18 17:28:25 UTC): Duplicate of https://github.com/metabase/metabase/issues/35425 .

"
2360315489,issue,closed,completed,Custom font families are not loading in embedding sdk,"The custom font families are not loading in the embedding sdk. I configured the families in the MB instance and the custom fonts show in the main Metabase app, but it seems like the font declaration is not loading even when the font family is set to Custom.

I suspect it has to do with `fontFiles.map` line in `SdkContentWrapper`.",heypoom,2024-06-18 17:01:34+00:00,['heypoom'],2024-10-08 17:06:46+00:00,2024-06-20 11:26:44+00:00,https://github.com/metabase/metabase/issues/44370,"[('Embedding/SDK', 'Embedding SDK for React')]",[],
2360251952,issue,closed,completed,"""Relative Date"" filter should support more flexible date ranges","**Is your feature request related to a problem? Please describe.**
The ""Relative Date"" filter currently only supports a limited number of relative dates.  7d or a 30d filter, ""This month"" or ""Last month"", etc... It would be desirable to be able to specify other relative date ranges, such as a 14 day filter, etc... 

**Describe the solution you'd like**
Make it possible to specify other ""relative date"" filters. 

**Describe alternatives you've considered**
You can use specific date ranges, but this is inconvenient.  

**How important is this feature to you?**
Moderate importance

**Additional context**
<img width=""462"" alt=""Screenshot 2024-06-18 at 10 21 21 AM"" src=""https://github.com/metabase/metabase/assets/1548549/bd302bd2-a1a6-45fa-a6ee-acb7d17067e8"">
",ronrlin,2024-06-18 16:23:35+00:00,[],2025-01-02 16:24:49+00:00,2025-01-02 16:24:44+00:00,https://github.com/metabase/metabase/issues/44369,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]","[{'comment_id': 2568036320, 'issue_id': 2360251952, 'author': 'brunobergher', 'body': '@ronrlin , you can do this by clicking on ""Relative Dates..."" towards the bottom of the default list, and then choose any arbitrary time range you may want.\n\nI\'ll close this for now assuming I caught your request, but if not, let me know.', 'created_at': datetime.datetime(2025, 1, 2, 16, 24, 44, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 16:24:44 UTC): @ronrlin , you can do this by clicking on ""Relative Dates..."" towards the bottom of the default list, and then choose any arbitrary time range you may want.

I'll close this for now assuming I caught your request, but if not, let me know.

"
2360079066,issue,closed,completed,Investigate blockers on using the embedding sdk with Vite,"Investigate on what is blocking SDK customers from using the embedding SDK in their Vite projects, including Rollup and ESBuild.",heypoom,2024-06-18 14:58:47+00:00,['heypoom'],2024-06-18 16:28:54+00:00,2024-06-18 16:28:53+00:00,https://github.com/metabase/metabase/issues/44366,"[('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2176514046, 'issue_id': 2360079066, 'author': 'heypoom', 'body': 'done, see branch `migrate-to-vite` in Shoppy and the conversations in Slack', 'created_at': datetime.datetime(2024, 6, 18, 16, 28, 53, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-06-18 16:28:53 UTC): done, see branch `migrate-to-vite` in Shoppy and the conversations in Slack

"
2360035954,issue,closed,completed,Move cloverage to a nightly run,"We don't need to collect test coverage data on every commit, and cloverage hogs a lot of CI resources. Nightly should be sufficient.",iethree,2024-06-18 14:40:11+00:00,['iethree'],2024-10-08 17:06:36+00:00,2024-06-21 06:54:22+00:00,https://github.com/metabase/metabase/issues/44364,"[('.CI & Tests', '')]",[],
2359970524,issue,closed,completed,[BE] Add `temporal_units` to the malli schema for parameters,For dashboard parameters there is new optional property `temporal_units` with a list of units of this type https://github.com/metabase/metabase/blob/c27b67692137ebd7641e80e1c19174920c71cc14/src/metabase/lib/schema/temporal_bucketing.cljc#L114. The BE should add a schema check to make sure the list is correct.,ranquild,2024-06-18 14:11:13+00:00,[],2024-10-08 17:02:17+00:00,2024-06-24 21:52:11+00:00,https://github.com/metabase/metabase/issues/44361,"[('.Backend', '')]",[],
2359924363,issue,closed,completed,(Metabase 0.50.5 is unavailable) +CrashOnOutOfMemoryError cpu problem,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/38505390/0ddbd2a9-e0d2-4dee-b7a1-24d9fc766287)


### Information about your Metabase installation

```JSON
Docker

POSTGRESQL
METABASE
```

444002525bab   metabase/metabase:latest   ""/app/run_metabase.sh""   2 hours ago     Up 27 minutes (healthy)   0.0.0.0:8080->3000/tcp, :::8080->3000/tcp   metabase
2b09134d6196   postgres:latest            ""docker-entrypoint.sâ€¦""   10 months ago   Up 27 minutes             5432/tcp                                    postgres



### Severity

10
",alperengunes,2024-06-18 13:51:35+00:00,['bshepherdson'],2024-08-28 02:09:57+00:00,2024-08-15 14:28:24+00:00,https://github.com/metabase/metabase/issues/44359,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2176164742, 'issue_id': 2359924363, 'author': 'uladzimirdev', 'body': '@alperengunes could you please add more details about your configuration?', 'created_at': datetime.datetime(2024, 6, 18, 13, 53, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176167601, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""@alperengunes please post the logs, specs... at least you're not running Metabase correctly there since you're not probably tweaking the heap limit"", 'created_at': datetime.datetime(2024, 6, 18, 13, 54, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176174811, 'issue_id': 2359924363, 'author': 'alperengunes', 'body': ""In 49.x updates I don't have this problem, but in 50.x updates I have this problem. There are no different changes I have made."", 'created_at': datetime.datetime(2024, 6, 18, 13, 57, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176178281, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""@alperengunes if you don't send us what we need, we won't be able to identify the problem"", 'created_at': datetime.datetime(2024, 6, 18, 13, 59, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176312528, 'issue_id': 2359924363, 'author': 'alperengunes', 'body': 'not only this but I have been getting expression error since I updated metabase 50.x\r\n\r\n\r\n![image](https://github.com/metabase/metabase/assets/38505390/d9c79323-0668-4678-b8b5-bc484c6ad069)\r\n![image](https://github.com/metabase/metabase/assets/38505390/33fe077b-010e-47ba-b4c4-f720c70ee898)', 'created_at': datetime.datetime(2024, 6, 18, 14, 55, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176555461, 'issue_id': 2359924363, 'author': 'rob-pomelo', 'body': 'also seeing significant performance regression since going from 0.49 -> 0.50, cpu usage spiking, will try get some logs', 'created_at': datetime.datetime(2024, 6, 18, 16, 52, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176617708, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@alperengunes could you click on the ""download diagnostics info"" and send over that file to us after reviewing that there is no sensitive information there?', 'created_at': datetime.datetime(2024, 6, 18, 17, 28, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176649763, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': 'Also seeing performance regression and CPU spikes.', 'created_at': datetime.datetime(2024, 6, 18, 17, 47, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176671794, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@LukeAbell any diagnostics you can share with us that can help debug this?', 'created_at': datetime.datetime(2024, 6, 18, 18, 1, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176682605, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""What can I share? It seems like it's mostly affecting large dashboards with a lot of questions. Looks like it's the metadata endpoint mostly.\r\n\r\n![Screenshot 2024-06-18 at 02 05 30 PM@2x](https://github.com/metabase/metabase/assets/3343530/89d9c67e-9a7d-4a50-ab8a-c213b930b02a)\r\n![Screenshot 2024-06-18 at 02 07 23 PM@2x](https://github.com/metabase/metabase/assets/3343530/cc272018-8ac1-4b3b-b18c-757b9d7ab54f)\r\n\r\nEven loading the dashboard spikes CPU usage of our pods:\r\n![Screenshot 2024-06-18 at 02 08 05 PM@2x](https://github.com/metabase/metabase/assets/3343530/dc86598c-c431-4f7d-ac98-4af13724e50e)"", 'created_at': datetime.datetime(2024, 6, 18, 18, 7, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176707411, 'issue_id': 2359924363, 'author': 'rob-pomelo', 'body': 'also running in gke and have had similar cpu spike on upversion just like ^', 'created_at': datetime.datetime(2024, 6, 18, 18, 23, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176734737, 'issue_id': 2359924363, 'author': 'uladzimirdev', 'body': '@rob-pomelo https://www.metabase.com/docs/latest/troubleshooting-guide/diagnostic-info', 'created_at': datetime.datetime(2024, 6, 18, 18, 40, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176746676, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': '@perivamsi Just emailed support logs for the dashboard.', 'created_at': datetime.datetime(2024, 6, 18, 18, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176766969, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@LukeAbell @rob-pomelo and @alperengunes can you add MB_SQL_PARSING_ENABLED=false, reboot and then let us know if this keeps happening?\r\n\r\n@alperengunes \r\n2024-06-18 14:33:00,039 WARN malli.fn :: Invalid output\r\nERROR middleware.add-source-metadata :: Error determining expected columns for query\r\nclojure.lang.ExceptionInfo: Error preprocessing query in metabase.query_processor.preprocess\r\nCaused by: clojure.lang.ExceptionInfo: Invalid query\r\n\r\nplease post the questions that spit those lines', 'created_at': datetime.datetime(2024, 6, 18, 19, 1, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176783346, 'issue_id': 2359924363, 'author': 'matotias', 'body': 'Not sure if it\'s the same issue, but we started seeing huge spikes in the database after updating, these updates seem to be the problem \r\n<img width=""1095"" alt=""image"" src=""https://github.com/metabase/metabase/assets/29378537/95a6c509-0651-428a-8ff0-d2feaa8366a4"">', 'created_at': datetime.datetime(2024, 6, 18, 19, 11, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176787551, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@matotias what version did you upgrade from?', 'created_at': datetime.datetime(2024, 6, 18, 19, 13, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176800273, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@matotias and what engine/sizing are you using as well', 'created_at': datetime.datetime(2024, 6, 18, 19, 21, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176805826, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""@paoliniluis Didn't seem to change much. I think it's permission or sandbox related because it's much faster as a super admin vs a normal user that's sandboxed using full app embed."", 'created_at': datetime.datetime(2024, 6, 18, 19, 25, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176808606, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': 'Check out the difference in time between sandboxed (right) and super admin (left).\r\n![Screenshot 2024-06-18 at 03 26 53 PM@2x](https://github.com/metabase/metabase/assets/3343530/8c005d26-37ee-40d2-8447-f0d934730157)', 'created_at': datetime.datetime(2024, 6, 18, 19, 27, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176815956, 'issue_id': 2359924363, 'author': 'matotias', 'body': ""> @matotias and what engine/sizing are you using as well\r\n\r\nWe went from `0.49.12` to `0.50.4` and the spikes started, then we updated again to `0.50.5` but we're still seeing them\r\n\r\nWe use postgres, 4 cpu 16 gigs of ram"", 'created_at': datetime.datetime(2024, 6, 18, 19, 31, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176842041, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""@LukeAbell I'm trying to reproduce what you're seeing and I'm wondering how it's taking 4 seconds to get a 30kb response. Can you describe a little more the queries? how are queries built (based on questions or models?). Are tables big? many joins?"", 'created_at': datetime.datetime(2024, 6, 18, 19, 49, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176843411, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""> > @matotias and what engine/sizing are you using as well\r\n> \r\n> We went from `0.49.12` to `0.50.4` and the spikes started, then we updated again to `0.50.5` but we're still seeing them\r\n> \r\n> We use postgres, 4 cpu 16 gigs of ram\r\n\r\n4 cpu and 16 gigs of ram is the postgres sizing right?"", 'created_at': datetime.datetime(2024, 6, 18, 19, 49, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176844162, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': '@paoliniluis want to hop on a quick video chat?', 'created_at': datetime.datetime(2024, 6, 18, 19, 50, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176854612, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@LukeAbell give me a couple of hours to try to go to the call with some answers, can you make it tomorrow first time in the morning?', 'created_at': datetime.datetime(2024, 6, 18, 19, 56, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176859790, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': '@paoliniluis Tomorrow at 10am EST work?', 'created_at': datetime.datetime(2024, 6, 18, 19, 59, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176873666, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""> @LukeAbell I'm trying to reproduce what you're seeing and I'm wondering how it's taking 4 seconds to get a 30kb response. Can you describe a little more the queries? how are queries built (based on questions or models?). Are tables big? many joins?\r\n\r\nQueries are based on questions (no models involved). Not a ton of joins. Using bigquery- table has about 800k rows.\r\n\r\nOnly 6 tables are returned in that query_metadata call."", 'created_at': datetime.datetime(2024, 6, 18, 20, 4, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176875229, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""Thanks @LukeAbell, do you have observability in the app db to see if there's something weird there?"", 'created_at': datetime.datetime(2024, 6, 18, 20, 5, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176878236, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""Yep- doesn't seem like anything weird there. Less than 20% utilization. Running MySQL."", 'created_at': datetime.datetime(2024, 6, 18, 20, 7, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176901069, 'issue_id': 2359924363, 'author': 'matotias', 'body': ""> > > @matotias and what engine/sizing are you using as well\r\n> > \r\n> > \r\n> > We went from `0.49.12` to `0.50.4` and the spikes started, then we updated again to `0.50.5` but we're still seeing them\r\n> > We use postgres, 4 cpu 16 gigs of ram\r\n> \r\n> 4 cpu and 16 gigs of ram is the postgres sizing right?\r\n\r\nYes!"", 'created_at': datetime.datetime(2024, 6, 18, 20, 20, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176911685, 'issue_id': 2359924363, 'author': 'alperengunes', 'body': '> @alperengunes could you click on the ""download diagnostics info"" and send over that file to us after reviewing that there is no sensitive information there?\r\n\r\nchecking', 'created_at': datetime.datetime(2024, 6, 18, 20, 26, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177161209, 'issue_id': 2359924363, 'author': 'matotias', 'body': 'Update on our case: we went back to v0.49.12 and the database load is normal again', 'created_at': datetime.datetime(2024, 6, 18, 22, 9, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177213489, 'issue_id': 2359924363, 'author': 'alperengunes', 'body': ""> @LukeAbell @rob-pomelo and @alperengunes can you add MB_SQL_PARSING_ENABLED=false, reboot and then let us know if this keeps happening?\r\n> \r\n> @alperengunes 2024-06-18 14:33:00,039 WARN malli.fn :: Invalid output ERROR middleware.add-source-metadata :: Error determining expected columns for query clojure.lang.ExceptionInfo: Error preprocessing query in metabase.query_processor.preprocess Caused by: clojure.lang.ExceptionInfo: Invalid query\r\n> \r\n> please post the questions that spit those lines\r\n\r\nnot working :'( same"", 'created_at': datetime.datetime(2024, 6, 18, 22, 49, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177237018, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@matotias is your app db a postgres or mysql?', 'created_at': datetime.datetime(2024, 6, 18, 23, 14, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177238130, 'issue_id': 2359924363, 'author': 'matotias', 'body': 'postgres', 'created_at': datetime.datetime(2024, 6, 18, 23, 15, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177347253, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': 'ok we have some strings to pull from now', 'created_at': datetime.datetime(2024, 6, 19, 1, 23, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2177422438, 'issue_id': 2359924363, 'author': 'naveenthontepu', 'body': 'Metabase is crashing every 3 to 4 hours in our case also. There is no significant jump in the CPU utilisation but the RAM utilisation has significantly increased and is consuming the complete 4 gb ram we have on the metabase server. \r\n\r\nLooking at the tasks running on our server by running ""htop"" we are seeing that there are too many tasks metabase is keeping active even when there is nobody using metabase.', 'created_at': datetime.datetime(2024, 6, 19, 2, 29, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2178074009, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@naveenthontepu could you send us the output of `htop` and logs of the tasks that Metabase is keeping active?', 'created_at': datetime.datetime(2024, 6, 19, 8, 26, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2178476618, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': 'Also: any specific environment variable that youâ€™re using?', 'created_at': datetime.datetime(2024, 6, 19, 11, 35, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2178528693, 'issue_id': 2359924363, 'author': 'naveenthontepu', 'body': '![Screenshot 2024-06-19 at 5 29 24 PM](https://github.com/metabase/metabase/assets/13089476/d53db817-59ac-4ebb-9a23-35f47c7a530f)\r\n\r\nThere are no environment variables that we are using. \r\n\r\nthe command we are using to run metabase specifically mentions to use only 2gb of the 4gb ram but it is not being considered and using it 4gb and crashing. In the above screenshot also we can see that metabase is consuming 71% memory which is ~3gb.', 'created_at': datetime.datetime(2024, 6, 19, 12, 4, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179016378, 'issue_id': 2359924363, 'author': 'noahmoss', 'body': '@LukeAbell what version of MySQL are you on?', 'created_at': datetime.datetime(2024, 6, 19, 15, 47, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179025234, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': '@noahmoss 8.0.31', 'created_at': datetime.datetime(2024, 6, 19, 15, 51, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180314450, 'issue_id': 2359924363, 'author': 'psneha716', 'body': ""Hi, \r\nI tried disabling query parsing using MB_SQL_PARSING_ENABLED=false but it's of no help. Metabase is still crashing with OOM.\r\nVersion: v0.50.1\r\n\r\nContext:\r\n\r\nMetabase deployed on ECS with EC2. \r\n**CPU per task**: 3800 units (3.711 vCPU)\r\n**Memory per task:** 3700 MiB (3.613 GB)\r\n\r\n2 tasks deployed currently"", 'created_at': datetime.datetime(2024, 6, 20, 10, 12, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180427490, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': 'Weâ€™re working on this as we speak', 'created_at': datetime.datetime(2024, 6, 20, 11, 18, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187411940, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@LukeAbell we have some changes coming that that might improve the performance. would you be able to upgrade to 50.7 and test? which version are you on right now? is it easy for you to downgrade if 50.7 is still slow for you?', 'created_at': datetime.datetime(2024, 6, 24, 21, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187417077, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""@perivamsi yep just let me know when there's a tagged release. Or do I need to test on a custom branch?"", 'created_at': datetime.datetime(2024, 6, 24, 21, 16, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187417733, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': ""no need to test a custom branch, I'll give you a proper release link once ready"", 'created_at': datetime.datetime(2024, 6, 24, 21, 17, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187868793, 'issue_id': 2359924363, 'author': 'shrey-locad', 'body': 'exactly same problem since the upgrade to 0.50. memory and cpu spiking intermittently bringing down the whole container every 3-4 hours. We will give it 1-2 more days before downgrading back to 0.49', 'created_at': datetime.datetime(2024, 6, 25, 3, 8, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2188246682, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@shrey-locad sorry about that! are you open to having a call that can help us debug this better? as I said, we are working on this but it would be helpful to have additional data points around the memory and CPU spikes. also, hi from another IITB alum!', 'created_at': datetime.datetime(2024, 6, 25, 8, 5, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189107729, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': 'Similar issue with CPU spikes after upgrading from 0.49.x to 0.50.6. \r\nUsing Postgres 14 as a DB. Metabase is deployed on 2CPU-12GB in GCE and DB is in CloudSQL.\r\n\r\nUpgrade was in the end of 06/24.\r\n \r\n<img width=""1102"" alt=""Screenshot 2024-06-25 at 11 12 36"" src=""https://github.com/metabase/metabase/assets/6412917/7254ce97-41d1-451a-8e07-fd2effa4c6b0"">', 'created_at': datetime.datetime(2024, 6, 25, 14, 23, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189162198, 'issue_id': 2359924363, 'author': 'shrey-locad', 'body': ""@perivamsi - haha, that's a pleasant surprise. Hi ðŸ‘‹ðŸ½ \n\nIt might be hard to debug over a call, especially since the crashes are unpredictable and intermittent. We have been unable to identify a specific trigger either. The latest crash was in the middle of the night where we're pretty sure none of our users were online. How about we gave you ssh access to the instance instead? Call works too. Either way. shrey.jain@golocad.com"", 'created_at': datetime.datetime(2024, 6, 25, 14, 45, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189165581, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': ""That works, we just need to look at the logs. I'll email you."", 'created_at': datetime.datetime(2024, 6, 25, 14, 47, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189830287, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@LukeAbell @shrey-locad @cheyuriy can you all please upgrade to 50.7 which has some fixes for the performance issues?\r\n\r\nhttps://github.com/metabase/metabase/releases/tag/v0.50.7', 'created_at': datetime.datetime(2024, 6, 25, 19, 38, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189847398, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""@perivamsi I upgraded but had to quickly downgrade because it completely broke the application. Downgrading back to v1.50.6 fixed the issue. I tried clearing our CDN cache and flushing browser cache but it didn't help.\r\n\r\nAssets wouldn't load giving an error:\r\n\r\n```\r\nRefused to execute script from 'HOST/app/dist/runtime.ba18610064ff9fba6745.js' because its MIME type ('') is not executable, and strict MIME type checking is enabled.\r\n```"", 'created_at': datetime.datetime(2024, 6, 25, 19, 48, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189850580, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': ""We're on it"", 'created_at': datetime.datetime(2024, 6, 25, 19, 50, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189867142, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""That sounds like https://github.com/metabase/metabase/issues/39449. If force-refresh doesn't work, try another browser?\r\n\r\nIt does seem like it was a transitory issue in the past."", 'created_at': datetime.datetime(2024, 6, 25, 20, 2, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189987013, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': '@perivamsi  @bshepherdson Completely cleared cache and that worked. Unfortunately not much of an improvement in performance (if any) ðŸ˜”\r\n\r\n- Query metadata taking 4-6 seconds sandboxed \r\n- Queries taking 3-5 seconds sandboxed\r\n- CPU usage still spiking like crazy loading a single dashboard', 'created_at': datetime.datetime(2024, 6, 25, 21, 18, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189988676, 'issue_id': 2359924363, 'author': 'uladzimirdev', 'body': ""@LukeAbell just for the record, what kind of cache have you cleared? what CDN do you use? we're struggling to reproduce the issue, so any info would be helpful (some users had it during upgrades from older versions)"", 'created_at': datetime.datetime(2024, 6, 25, 21, 19, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189989465, 'issue_id': 2359924363, 'author': 'LukeAbell', 'body': ""@uladzimirdev I had to clear my local browser cache to resolve the issue. We have metabase behind a google cloud CDN but that didn't be the issue."", 'created_at': datetime.datetime(2024, 6, 25, 21, 20, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191777360, 'issue_id': 2359924363, 'author': 'psneha716', 'body': 'Hi folks,\r\nCould someone who has already downgraded their metabase version, help me out with the downgrading process? Tried downgrading, but it isn\'t working. Any help would be greatly appreciated. Thanks!\r\n\r\n**Cluster configuration:**\r\n\r\nECS cluster with 2 tasks.\r\nTask CPU: 3800 units (3.711 vCPU)\r\nTask memory: 3700 MiB (3.613 GB)\r\n\r\n\r\n**Steps that I followed for downgrading** (followed instructions from [here](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade)):\r\n\r\n- Stopped the container running v0.50.1 metabase instance\r\n\r\n- Ran the following on the EC2 instance directly:\r\n\r\n```\r\n$docker run --rm metabase/metabase:v0.50.1 ""migrate down""\r\nWarning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23\r\n2024-06-12 21:08:25,427 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB\r\n2024-06-12 21:08:27,762 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-06-12 21:08:28,566 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For production deployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database file regularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html\r\n2024-06-12 21:08:32,573 INFO driver.impl :: Registered abstract driver :sql  ðŸšš\r\n2024-06-12 21:08:32,579 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš\r\n2024-06-12 21:08:32,585 INFO metabase.util :: Load driver :sql-jdbc took 32.7 ms\r\n2024-06-12 21:08:32,586 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-12 21:08:32,717 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-12 21:08:32,744 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš\r\n2024-06-12 21:08:34,401 INFO metabase.core ::\r\nMetabase v0.50.1 (cc4ca82)\r\n\r\nCopyright Â© 2024 Metabase, Inc.\r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-06-12 21:08:34,657 INFO db.setup :: Setting up Liquibase...\r\n2024-06-12 21:08:35,245 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames\r\n2024-06-12 21:08:35,254 INFO db.liquibase :: No migration lock found.\r\n2024-06-12 21:08:35,255 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-12 21:08:35,259 INFO db.setup :: Liquibase is ready.\r\n2024-06-12 21:08:35,262 INFO db.liquibase :: No migration lock found.\r\n2024-06-12 21:08:35,263 INFO db.liquibase :: Migration lock acquired.\r\n2024-06-12 21:08:35,264 INFO db.liquibase :: Rolling back app database schema to version 49\r\n```\r\n\r\n- Tried spinning up a container using v0.49.15, but getting the following error:\r\n\r\n```\r\n2024-06-12 21:10:56,380 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...\r\n--\r\n2024-06-12 21:10:56,382 INFO db.setup :: ï¿½[36mVerifying postgres Database Connection ...ï¿½[0m\r\n2024-06-12 21:10:56,724 INFO db.setup :: Successfully verified PostgreSQL 13.13 application database connection. âœ…\r\n2024-06-12 21:10:56,725 INFO db.setup :: ï¿½[36mChecking if a database downgrade is required...ï¿½[0m\r\n2024-06-12 21:10:56,834 ERROR middleware.log :: ï¿½[31mGET /api/health 503 287.2 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\nï¿½[0m\r\n2024-06-12 21:10:56,844 ERROR middleware.log :: ï¿½[31mGET /api/health 503 182.0 Âµs (0 DB calls)\r\n{:status ""initializing"", :progress 0.3}\r\nï¿½[0m\r\n2024-06-12 21:10:57,344 ERROR metabase.core :: Metabase Initialization FAILED\r\nclojure.lang.ExceptionInfo: ï¿½[31mERROR: Downgrade detected.ï¿½[0m\r\nYour metabase instance appears to have been downgraded without a corresponding database downgrade.\r\nYou must run `java -jar metabase.jar migrate down` from version 50.\r\nOnce your database has been downgraded, try running the application again.\r\n```', 'created_at': datetime.datetime(2024, 6, 26, 13, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2191806383, 'issue_id': 2359924363, 'author': 'noahmoss', 'body': ""Hi @psneha716 â€”\xa0I don't see any errors in the downgrading logs that indicate specifically why it didn't work. But I did fix an issue related to downgrading in Metabase 50.7, the latest release. Could you try starting that version up, and then running the downgrade command with it?\r\n\r\nIf that doesn't work could you open a new issue with the full logs?"", 'created_at': datetime.datetime(2024, 6, 26, 14, 7, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2192492341, 'issue_id': 2359924363, 'author': 'psneha716', 'body': 'Hi @noahmoss ,\r\nIt did not work. Created a new issue [here](https://github.com/metabase/metabase/issues/44784).', 'created_at': datetime.datetime(2024, 6, 26, 19, 37, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194015899, 'issue_id': 2359924363, 'author': 'psneha716', 'body': ""Seeing frequent OOM crashes in v0.50.7 too. Don't see any improvement."", 'created_at': datetime.datetime(2024, 6, 27, 7, 43, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194659706, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""@psneha716 have you got metrics that show whether there's a slow climb in usage until OOM, or a spike?\r\n\r\nThere are fixes in flight for a few things that might help, but I don't have any clear link to either a slow leak or spike in memory use.\r\n\r\n(Those fixes specifically: better batching of TCP traffic while streaming query results; fixing an N+1 problem during dashboard loads; and fixing another N+1 problem with sandboxing enabled on dashboard loads. But I don't think any of those have significant memory use overhead. They are definitely spike-y though, hence my question about spikes vs. leaks.)"", 'created_at': datetime.datetime(2024, 6, 27, 13, 11, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194749905, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': '@bshepherdson it\'s a slow climb till the limit \r\ngraphs for virtual and resident memory usage for today with 2 restarts\r\n<img width=""1122"" alt=""Screenshot 2024-06-27 at 10 48 24"" src=""https://github.com/metabase/metabase/assets/6412917/7738b706-ea54-4599-866a-541e661f9a9c"">\r\n<img width=""1108"" alt=""Screenshot 2024-06-27 at 10 49 13"" src=""https://github.com/metabase/metabase/assets/6412917/821bfcdb-6f8c-4d6d-968b-3a1094979353"">\r\n\r\nAlso I can see constantly increasing number of ""total active threads"" in logs. Both time it climbed from 0 to ~16500 before fail.\r\n`2024-06-27 06:14:26,632 DEBUG middleware.log :: \x1b[32mPOST /api/dashboard/242/dashcard/8869/card/9623/query 202 [ASYNC: completed] 4.1 s (22 DB calls) App DB connections: 1/100 Jetty threads: 3/100 (15 idle, 0 queued) (16,637 total active threads) Queries in flight: 7 (0 queued) {:metabase-user-id 910}\x1b[0m`', 'created_at': datetime.datetime(2024, 6, 27, 13, 54, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194769635, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""Ah, thanks for those! Good catch with the runaway thread count, that's a strong signal."", 'created_at': datetime.datetime(2024, 6, 27, 14, 2, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194946833, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""Just to keep these dots connected: there's a fix which only applies to users of MySQL (for querying, not as Metabase's appdb) that **greatly** reduces thread pool pressure while querying MySQL. It was fixed in #44719 which merged a short while ago and will be in 50.8.\r\n\r\nIf everyone with this OOM issue is querying MySQL, then I think that's highly likely to be the issue. If some here are seeing OOMs without talking to MySQL, then there's more to find. I'm still investigating in any case, but please chime in about MySQL!"", 'created_at': datetime.datetime(2024, 6, 27, 14, 56, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195043976, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""@bshepherdson we don't query MySQL. Only postgres and BigQuery"", 'created_at': datetime.datetime(2024, 6, 27, 15, 39, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195064555, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""@cheyuriy okay, thanks. I'll keep digging for what the runaway threads might be coming from."", 'created_at': datetime.datetime(2024, 6, 27, 15, 48, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195516580, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""Anyone who is having this issue who is able to send CLI commands to your instance, can you run `jstack -l PID` and send the output? That should give a dump of all the threads in the running process with names and stacks, which might be huge with 16k but should illuminate which source of threads is leaking, how they got created, and what's holding them open.\r\n\r\n(@cheyuriy since I know you specifically have runaway thread spawns)"", 'created_at': datetime.datetime(2024, 6, 27, 19, 28, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195522112, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""@bshepherdson sry, we've restarted it minutes ago. I'll run this command later, when it will be close to this number again"", 'created_at': datetime.datetime(2024, 6, 27, 19, 32, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195606641, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': 'Never mind! We managed to find one of our cloud instances on 50.x with a runaway thread pool, and get that thread dump from it. This is an issue with dangling timeout futures when querying Bigquery. This should be fixed tomorrow (Friday).', 'created_at': datetime.datetime(2024, 6, 27, 20, 22, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196268443, 'issue_id': 2359924363, 'author': 'psneha716', 'body': 'Hey Guys,\r\nEven after downgrading to v0.49.12, I\'m seeing a lot of crashes due to OOM. Is there any stable version that I can go back to?\r\n\r\nCurrently it\'s crashing at 45% utilisation.\r\n\r\n<img width=""1304"" alt=""image"" src=""https://github.com/metabase/metabase/assets/152379423/26e0e61e-5a90-4870-bc4a-2680c11dba79"">', 'created_at': datetime.datetime(2024, 6, 28, 6, 58, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2196952808, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""Unless there was a sharp spike to 100% there that was missed by the metrics, why would it crash at 44%? The right side of that graph looks like a major GC to me.\r\n\r\nAre you still seeing runaway thread counts? I don't know when the (BigQuery-specific) thread leak that's causing these OOMs was introduced, but given how many people are seeing it on 50.x it's hard to believe it's also been in 49.12 for months but it hasn't been reported until now.\r\n\r\nIf it is happening in 49.x we can backport the fix (#44860) to the 49 branch as well. It should land in the 50 branch in 30m or less and we'll get a 50.8 release out today. (Fixing this OOM issue plus some dashboard load time slowness, especially for sandboxing users.)"", 'created_at': datetime.datetime(2024, 6, 28, 13, 44, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2198551862, 'issue_id': 2359924363, 'author': 'psneha716', 'body': '@bshepherdson How do I diagnose the issue?', 'created_at': datetime.datetime(2024, 6, 30, 12, 47, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2199243815, 'issue_id': 2359924363, 'author': 'psneha716', 'body': 'I increased the heap space of the application to 70% of the total RAM, it hasn\'t crashed since then but the memory utilisation is just consistently going up. It\'s just a matter of time before it crashes.\r\n\r\n<img width=""1318"" alt=""image"" src=""https://github.com/metabase/metabase/assets/152379423/920566e0-14d8-4eef-a4e6-10b65c68b0cf"">', 'created_at': datetime.datetime(2024, 7, 1, 5, 5, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202396180, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': 'Everyone who reported OOM crashes (especially if you are using BigQuery), we released a fix for this issue with v50.8. Please upgrade: https://github.com/metabase/metabase/releases/tag/v0.50.8', 'created_at': datetime.datetime(2024, 7, 2, 9, 2, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202602645, 'issue_id': 2359924363, 'author': 'alperengunes', 'body': '> Everyone who reported OOM crashes (especially if you are using BigQuery), we released a fix for this issue with v50.8. Please upgrade: https://github.com/metabase/metabase/releases/tag/v0.50.8\r\n\r\nThank you @perivamsi', 'created_at': datetime.datetime(2024, 7, 2, 9, 56, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202950219, 'issue_id': 2359924363, 'author': 'shrey-locad', 'body': 'upgraded to 0.50.8. Will keep you posted', 'created_at': datetime.datetime(2024, 7, 2, 11, 47, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205424929, 'issue_id': 2359924363, 'author': 'MathiasGr', 'body': 'Hi there, we upgraded to 0.50.8 yesterday and just experienced the CPU craziness this morning again.\r\n\r\nThe CPU usage seems to exponentially increase until everything is stalling. The memory usage is stable though, nothing to report on that front.\r\n\r\nWe are mostly using BigQuery.\r\n\r\n<img width=""507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/18528990/ed1b8a34-3c7d-427f-8cb6-f9e0ae8e2b0e"">', 'created_at': datetime.datetime(2024, 7, 3, 8, 36, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205919415, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': 'Memory issues are less severe with 0.50.8, however they are still present. And yes, we can observe CPU spikes too.', 'created_at': datetime.datetime(2024, 7, 3, 12, 5, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205927400, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@cheyuriy can you share more details about the memory issues? Can you do a thread dump and send it to us? `jstack -l <pid>`', 'created_at': datetime.datetime(2024, 7, 3, 12, 9, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206029776, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""@perivamsi it requires JDK to be installed, as i know. And we're using docker image which includes JRE..."", 'created_at': datetime.datetime(2024, 7, 3, 13, 3, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206033558, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': ""Understood. Any insights you can provide into the resource usage?\r\n\r\nOn Wed, Jul 3, 2024 at 9:03\u202fAM Yury Cheremushkin ***@***.***>\r\nwrote:\r\n\r\n> @perivamsi <https://github.com/perivamsi> it requires JDK to be\r\n> installed, as i know. And we're using docker image which includes JRE...\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/44359#issuecomment-2206029776>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAA7FFF72TPBSJTICXUV4ATZKPZDFAVCNFSM6AAAAABJQC36MKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMBWGAZDSNZXGY>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 7, 3, 13, 5, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206234568, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@MathiasGr are you able to provide a thread dump? anything that helps us see what is going on during the CPU spikes will be helpful.', 'created_at': datetime.datetime(2024, 7, 3, 14, 14, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206236966, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@shrey-locad how is your resource usage looking after the upgrade?', 'created_at': datetime.datetime(2024, 7, 3, 14, 15, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206254815, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@MathiasGr ~the CPU graph you showed is that of the Metabase process or the BigQuery database?~\r\n\r\nI understand It is Metabase', 'created_at': datetime.datetime(2024, 7, 3, 14, 19, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206624361, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""Looks like it's possible to get thread dump by sending `kill -3` to the java process inside the container. I'll try to do it later, when it will spawn a lot of threads"", 'created_at': datetime.datetime(2024, 7, 3, 15, 45, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206907631, 'issue_id': 2359924363, 'author': 'MathiasGr', 'body': ""> @MathiasGr ~the CPU graph you showed is that of the Metabase process or the BigQuery database?~\r\n> \r\n> I understand It is Metabase\r\n\r\nIndeed, it's Metabase"", 'created_at': datetime.datetime(2024, 7, 3, 17, 59, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206913728, 'issue_id': 2359924363, 'author': 'MathiasGr', 'body': ""I can try but these events happen randomly and when they do the entire pod stalls so it's almost impossible to get anything from it. It even starts failing healthchecks until it's killed by kube."", 'created_at': datetime.datetime(2024, 7, 3, 18, 3, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207181085, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': '[dump.txt](https://github.com/user-attachments/files/16090472/dump.txt)\r\nThread dump after ~9 hours uptime', 'created_at': datetime.datetime(2024, 7, 3, 20, 21, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207269022, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""@cheyuriy thanks! Quick analysis: 8000+ threads in the `clojure-agent-send-off-pool-NNN` group, all blocking inside the `execute-bigquery` logic. That tracks with our theory that the fix in 50.8 #44860 only got some of the cases. Dan's #45105 seems to address the remaining cases in his load testing.\r\n\r\nThat doesn't explain the CPU utilization spikes, though, at least not directly.\r\n\r\nSome questions for anyone seeing the CPU spikes:\r\n- Do they occur on some rhythm, or at random times?\r\n- If a rhythm, does it track with some other event?\r\n    - Especially with Metabase's sync process, which is scheduled in your admin settings.\r\n- Does memory usage correlate with the spikes at all? (If so, the spikes could really be a burst of GC thrashing, ending with an OOM crash and recovery after a restart.)"", 'created_at': datetime.datetime(2024, 7, 3, 20, 55, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207275506, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': '@MathiasGr See my questions [above](https://github.com/metabase/metabase/issues/44359#issuecomment-2207269022). You say ""randomly"", but the graph shows they happen pretty consistently around the same time every day, which makes me suspect they\'re linked with some event such as syncing, or certain requests to Metabase. Of course that timing may just be a coincidence, too.', 'created_at': datetime.datetime(2024, 7, 3, 20, 57, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2210561688, 'issue_id': 2359924363, 'author': 'MathiasGr', 'body': '> @MathiasGr See my questions [above](https://github.com/metabase/metabase/issues/44359#issuecomment-2207269022). You say ""randomly"", but the graph shows they happen pretty consistently around the same time every day, which makes me suspect they\'re linked with some event such as syncing, or certain requests to Metabase. Of course that timing may just be a coincidence, too.\r\n\r\nSorry Im currently on holiday but will take a look next week', 'created_at': datetime.datetime(2024, 7, 5, 9, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2211271877, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""> Some questions for anyone seeing the CPU spikes:\r\n> \r\n> Do they occur on some rhythm, or at random times?\r\n> If a rhythm, does it track with some other event?\r\n> Especially with Metabase's sync process, which is scheduled in your admin settings.\r\n> Does memory usage correlate with the spikes at all? (If so, the spikes could really be a burst of GC thrashing, ending with an OOM crash and recovery after a restart.)\r\n\r\nCan't see any pattern here. It happens when it has already consumed a lot of memory, but not correlated with anything else. It's even not the peak hour of Metabase usage in our company."", 'created_at': datetime.datetime(2024, 7, 5, 18, 36, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2211333814, 'issue_id': 2359924363, 'author': 'calherries', 'body': '@MathiasGr @cheyuriy You could help us narrow down the issue by disabling fingerprinting and field value scanning for all databases, and seeing if the issue persists. These have been the source of similar issues in the past. You can do this by going to Admin > Databases and setting one of these options:\r\n![image](https://github.com/metabase/metabase/assets/39073188/e1c25d7e-1f66-49b7-a53f-ea88bb3d98c1)', 'created_at': datetime.datetime(2024, 7, 5, 19, 38, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2217590820, 'issue_id': 2359924363, 'author': 'cheyuriy', 'body': ""> @MathiasGr @cheyuriy You could help us narrow down the issue by disabling fingerprinting and field value scanning for all databases, and seeing if the issue persists. These have been the source of similar issues in the past. \r\n\r\nDidn't affect anything"", 'created_at': datetime.datetime(2024, 7, 9, 12, 39, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219255333, 'issue_id': 2359924363, 'author': 'calherries', 'body': ""Thanks, that helps. @bshepherdson that implies it's not fingerprinting or field value scanning that's causing their issue."", 'created_at': datetime.datetime(2024, 7, 10, 0, 57, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221167844, 'issue_id': 2359924363, 'author': 'bshepherdson', 'body': ""#45253 will fix the thread leak that leads to OOMs. I hope that it will also fix the unresponsive Metabase issues, because it appears the CPU spike and unresponsiveness may be due to GC thrashing as memory is nearly exhausted.\r\n\r\nI'm doing a bit more profiling of general CPU usage with BigQuery before and after #45253; it removes some CPU/allocation overhead while processing individual queries, but I'm not sure how significant the impact is. Last week I wasn't able to reproduce any significant CPU usage while eg. loading a dashboard full of BQ queries, but I'm going to try a couple more approaches now."", 'created_at': datetime.datetime(2024, 7, 10, 18, 24, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228110142, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': 'With https://github.com/metabase/metabase/pull/45536, I would like to close this issue and open any new specific issues as needed.', 'created_at': datetime.datetime(2024, 7, 15, 9, 51, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228240951, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@MathiasGr can you test the new release?', 'created_at': datetime.datetime(2024, 7, 15, 11, 5, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228406952, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': 'same @alperengunes @cheyuriy @matotias @shrey-locad @psneha716 @rob-pomelo, please all upgrade to 50.13 and post your results', 'created_at': datetime.datetime(2024, 7, 15, 12, 37, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229835744, 'issue_id': 2359924363, 'author': 'shrey-locad', 'body': 'upgraded to 50.13. No issues since last 16 hours.', 'created_at': datetime.datetime(2024, 7, 16, 1, 50, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229895903, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""We found that the queries in 50 are taking longer, and probably there's also more memory pressure than on previous versions. We'll start working on those 2 as soon as we can"", 'created_at': datetime.datetime(2024, 7, 16, 2, 46, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233299035, 'issue_id': 2359924363, 'author': 'rob-pomelo', 'body': '50.13 actually been worse for us than 50.10 (have been okay on 50.10 but still worse than 49 perf), have some dashboards we can\'t even load at all on 50.13 so had to rollback\r\n\r\nExample error from logs\r\n```\r\nERROR metabase.server.middleware.log GET /api/dashboard/190/query_metadata 500 4.2 mins (283 DB calls) {:metabase-user-id 88} \r\n{:via\r\n [{:type java.io.IOException,\r\n   :message ""java.util.concurrent.TimeoutException: Idle timeout expired: 200000/200000 ms"",\r\n   :at [org.eclipse.jetty.util.SharedBlockingCallback$Blocker block ""SharedBlockingCallback.java"" 221]}\r\n  {:type java.util.concurrent.TimeoutException,\r\n   :message ""Idle timeout expired: 200000/200000 ms"",\r\n   :at [org.eclipse.jetty.io.IdleTimeout checkIdleTimeout ""IdleTimeout.java"" 170]}],\r\n :trace\r\n [[org.eclipse.jetty.io.IdleTimeout checkIdleTimeout ""IdleTimeout.java"" 170]\r\n  [org.eclipse.jetty.io.IdleTimeout idleCheck ""IdleTimeout.java"" 112]\r\n  [java.util.concurrent.Executors$RunnableAdapter call nil -1]\r\n  [java.util.concurrent.FutureTask run nil -1]\r\n  [java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask run nil -1]\r\n  [java.util.concurrent.ThreadPoolExecutor runWorker nil -1]\r\n  [java.util.concurrent.ThreadPoolExecutor$Worker run nil -1]\r\n  [java.lang.Thread run nil -1]],\r\n :cause ""Idle timeout expired: 200000/200000 ms"",\r\n :message ""java.util.concurrent.TimeoutException: Idle timeout expired: 200000/200000 ms""}\r\n```', 'created_at': datetime.datetime(2024, 7, 17, 13, 15, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233829510, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@rob-pomelo could you please email me at vamsi@metabase.com? would like to get more details from you so we can fix your issue. ideally if you have time to meet and screen share, that would help a lot.', 'created_at': datetime.datetime(2024, 7, 17, 17, 27, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2240807254, 'issue_id': 2359924363, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/45881', 'created_at': datetime.datetime(2024, 7, 20, 0, 53, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248909374, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': 'Just my 2 cents after our Metabase upgrade today.\r\n\r\nWe updated from 0.49.21 to 0.50.15 and observed significantly higher CPU usage along with a decrease in performance. Metabase is deployed in Kubernetes using a configuration of 2 pods with 12 CPU and 8GB memory limit. Is started hitting the CPU limit, becoming unresponsive and triggering restarts due to the liveness probe.\r\n\r\nWe rolled back to version 0.49.21, and it started working perfectly fine again.\r\n\r\n<img width=""1303"" alt=""Screenshot 2024-07-24 at 1 46 04 PM"" src=""https://github.com/user-attachments/assets/a1302efb-a829-4467-9d0e-e50955fa28d6"">', 'created_at': datetime.datetime(2024, 7, 24, 21, 13, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248933364, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@dmeremyanin can you contact us to our support email? We would like you test specific versions of the product if thatâ€™s fine with you. We would like to profile your deployment to find the causes of this', 'created_at': datetime.datetime(2024, 7, 24, 21, 29, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249217084, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': 'Should be fixed by https://github.com/metabase/metabase/pull/46108', 'created_at': datetime.datetime(2024, 7, 25, 2, 1, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249233657, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@dmeremyanin we will release v50.16 with a fix for the performance issue. please test against that version and let us know if if you are still facing the CPU spikes.', 'created_at': datetime.datetime(2024, 7, 25, 2, 19, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249517327, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': 'Apologies for the delayed response and thank you for the prompt reaction. We will definitely test v50.16 and get back here with feedback. Thanks', 'created_at': datetime.datetime(2024, 7, 25, 5, 54, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249899899, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@dmeremyanin 50.16 is out. Could you please test?', 'created_at': datetime.datetime(2024, 7, 25, 9, 34, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250619857, 'issue_id': 2359924363, 'author': 'MikitaKurlovich', 'body': 'Hi there! Still have the issue on v50.16\r\n\r\ndocker compose:\r\n```\r\n  metabase-postgres:\r\n    image: postgres:16.3\r\n    container_name: metabase-postgres\r\n    environment:\r\n      POSTGRES_DB: metabase\r\n      POSTGRES_USER: <metabase_user>\r\n      POSTGRES_PASSWORD: <metabase_password>\r\n    volumes:\r\n      - metabase-postgres-data:/var/lib/postgresql/data\r\n    ports:\r\n      - ""5432:5432â€\r\n\r\n  metabase:\r\n    restart: unless-stopped\r\n    image: metabase/metabase:v0.50.16\r\n    ports:\r\n      - 3001:3000\r\n    environment:\r\n      MB_DB_TYPE: postgres\r\n      MB_DB_DBNAME: metabase\r\n      MB_DB_PORT: 5432\r\n      MB_DB_USER: <metabase_user>\r\n      MB_DB_PASS: <metabase_password>\r\n      MB_DB_HOST: metabase-postgres\r\n    volumes:\r\n      - ./metabase-data:/metabase-data\r\n    depends_on:\r\n      - metabase-postgres\r\n```      \r\nDiagnostic Info:\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""en-US"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.24+8"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.24"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.24+8"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""4.15.0-213-generic"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""GMT""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.3""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""plan-alias"": """",\r\n    ""version"": {\r\n      ""date"": ""2024-07-25"",\r\n      ""tag"": ""v0.50.16"",\r\n      ""hash"": ""28de9df""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": null\r\n    }\r\n  }\r\n}\r\n```\r\n      \r\n<img width=""1470"" alt=""Screenshot 2024-07-25 at 16 50 23"" src=""https://github.com/user-attachments/assets/a073585b-ae14-4cec-bcce-0aa48fbf6644"">', 'created_at': datetime.datetime(2024, 7, 25, 15, 7, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250791875, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': ""hi @MikitaKurlovich your screenshot doesn't show cpu or memory pressure, can you please specify your problem?"", 'created_at': datetime.datetime(2024, 7, 25, 15, 58, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251384369, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': ""@perivamsi we've updated to v50.16. There's no traffic on it at the moment, but we are monitoring the load."", 'created_at': datetime.datetime(2024, 7, 25, 20, 58, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251411329, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': 'Thanks @dmeremyanin, keep me posted!', 'created_at': datetime.datetime(2024, 7, 25, 21, 17, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251580072, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@dmeremyanin any news?', 'created_at': datetime.datetime(2024, 7, 25, 23, 44, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251593361, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': 'Everything looks good so far, but there is still not much traffic.', 'created_at': datetime.datetime(2024, 7, 25, 23, 57, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2252982681, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': 'Overall, the same issues: very high CPU utilization, which leads to freezing. We\'ve rolled back to v0.49.21. Is there anything I can share that can help debug the problem?\r\n\r\n<img width=""1301"" alt=""Screenshot 2024-07-26 at 8 02 53 AM"" src=""https://github.com/user-attachments/assets/ecf4899e-f035-4032-9c23-734ac4501c9e"">', 'created_at': datetime.datetime(2024, 7, 26, 15, 17, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2253001504, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@dmeremyanin mind emailing me at vamsi@metabase.com? would like to meet and debug if possible.', 'created_at': datetime.datetime(2024, 7, 26, 15, 27, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2253051885, 'issue_id': 2359924363, 'author': 'dmeremyanin', 'body': '@perivamsi sure, I just sent you an email.', 'created_at': datetime.datetime(2024, 7, 26, 15, 57, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260028103, 'issue_id': 2359924363, 'author': 'V-Legendre', 'body': 'Hey guys, I am observing the same problems with version v1.50.17.\r\nHad to rollback to v49 to make Metabase available again.\r\n\r\n![Screenshot 2024-07-31 at 11 02 44](https://github.com/user-attachments/assets/d95d049b-50c4-48d7-93f6-5f37549727f4)\r\n\r\n\r\nAlso, one SQL query executed by MB migrations was hanging indefinitely (+2hours) during the upgrade. I had to kill by hand and MB started nonetheless.', 'created_at': datetime.datetime(2024, 7, 31, 9, 8, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260086571, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@V-Legendre are you open to sharing more diagnostic info over email or slack to help us fix the CPU spike issue? Please email me at vamsi@metabase.com if you are.', 'created_at': datetime.datetime(2024, 7, 31, 9, 34, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265153555, 'issue_id': 2359924363, 'author': 'apostoltego', 'body': 'Hey just to add to this thread as we\'re seeing similar complaints. One thing that we observed was that admin users don\'t experience slowness. As an experiment I worked with a user that wasn\'t an admin and we were seeing CPU spikes on all dashboards and after making them an admin the issue went away. \r\n![Screenshot 2024-08-02 at 13 17 16](https://github.com/user-attachments/assets/b552f7cb-0f80-4106-a870-7c9f4a57e2c9)\r\n\r\n\r\nDiagnostics ingo:\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""en-GB"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.24+8"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.24"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.24+8"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""UTC""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres"",\r\n      ""clickhouse""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""13.10 (Ubuntu 13.10-1.pgdg22.04+1)""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.3""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""plan-alias"": """",\r\n    ""version"": {\r\n      ""date"": ""2024-07-26"",\r\n      ""tag"": ""v0.50.17"",\r\n      ""hash"": ""afd6b17""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": ""UTC""\r\n    }\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 8, 2, 11, 24, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265175208, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@apostoltego are the non-admin users sandboxed or not?', 'created_at': datetime.datetime(2024, 8, 2, 11, 39, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265181439, 'issue_id': 2359924363, 'author': 'apostoltego', 'body': '@perivamsi apologies - what do you mean by sandboxed in this case?', 'created_at': datetime.datetime(2024, 8, 2, 11, 44, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265192906, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': 'It is a feature for pro customers, you are running open source version so it does not apply. Sorry for the confusion!', 'created_at': datetime.datetime(2024, 8, 2, 11, 52, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265378137, 'issue_id': 2359924363, 'author': 'perivamsi', 'body': '@apostoltego could you please run these sqls in the app db and tell us the results?\r\n\r\n```\r\nselect count(*) from data_permissions\r\nselect count(*), active from metabase_table group by active\r\n```', 'created_at': datetime.datetime(2024, 8, 2, 13, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265478575, 'issue_id': 2359924363, 'author': 'apostoltego', 'body': 'Sure here you go @perivamsi \r\nFirst one is: `113,541` \r\n\r\nSecond one is:\r\n```\r\ncount | active\r\n15,388 | false\r\n1,287 | true\r\n```', 'created_at': datetime.datetime(2024, 8, 2, 14, 7, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291389046, 'issue_id': 2359924363, 'author': 'NevRA', 'body': 'Resolved all related issues to this. If you have any other CPU-related issues please create a new issue', 'created_at': datetime.datetime(2024, 8, 15, 14, 28, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304728255, 'issue_id': 2359924363, 'author': 'apostoltego', 'body': ""hey @NevRA Tried with 0.50.20  & .21 just now the performance difference for end users vs admins seems to persist however overall utilisation doesn't seem to spike as much. Should this be opened as a separate issue? Or maybe there's a way to trim the overall data_permissions to speed things up?"", 'created_at': datetime.datetime(2024, 8, 22, 13, 50, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304769175, 'issue_id': 2359924363, 'author': 'paoliniluis', 'body': '@apostoltego open a new issue please with all details', 'created_at': datetime.datetime(2024, 8, 22, 14, 8, 22, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-06-18 13:53:26 UTC): @alperengunes could you please add more details about your configuration?

paoliniluis on (2024-06-18 13:54:43 UTC): @alperengunes please post the logs, specs... at least you're not running Metabase correctly there since you're not probably tweaking the heap limit

alperengunes (Issue Creator) on (2024-06-18 13:57:46 UTC): In 49.x updates I don't have this problem, but in 50.x updates I have this problem. There are no different changes I have made.

paoliniluis on (2024-06-18 13:59:19 UTC): @alperengunes if you don't send us what we need, we won't be able to identify the problem

alperengunes (Issue Creator) on (2024-06-18 14:55:38 UTC): not only this but I have been getting expression error since I updated metabase 50.x


![image](https://github.com/metabase/metabase/assets/38505390/d9c79323-0668-4678-b8b5-bc484c6ad069)
![image](https://github.com/metabase/metabase/assets/38505390/33fe077b-010e-47ba-b4c4-f720c70ee898)

rob-pomelo on (2024-06-18 16:52:03 UTC): also seeing significant performance regression since going from 0.49 -> 0.50, cpu usage spiking, will try get some logs

perivamsi on (2024-06-18 17:28:06 UTC): @alperengunes could you click on the ""download diagnostics info"" and send over that file to us after reviewing that there is no sensitive information there?

LukeAbell on (2024-06-18 17:47:54 UTC): Also seeing performance regression and CPU spikes.

perivamsi on (2024-06-18 18:01:01 UTC): @LukeAbell any diagnostics you can share with us that can help debug this?

LukeAbell on (2024-06-18 18:07:47 UTC): What can I share? It seems like it's mostly affecting large dashboards with a lot of questions. Looks like it's the metadata endpoint mostly.

![Screenshot 2024-06-18 at 02 05 30 PM@2x](https://github.com/metabase/metabase/assets/3343530/89d9c67e-9a7d-4a50-ab8a-c213b930b02a)
![Screenshot 2024-06-18 at 02 07 23 PM@2x](https://github.com/metabase/metabase/assets/3343530/cc272018-8ac1-4b3b-b18c-757b9d7ab54f)

Even loading the dashboard spikes CPU usage of our pods:
![Screenshot 2024-06-18 at 02 08 05 PM@2x](https://github.com/metabase/metabase/assets/3343530/dc86598c-c431-4f7d-ac98-4af13724e50e)

rob-pomelo on (2024-06-18 18:23:18 UTC): also running in gke and have had similar cpu spike on upversion just like ^

uladzimirdev on (2024-06-18 18:40:49 UTC): @rob-pomelo https://www.metabase.com/docs/latest/troubleshooting-guide/diagnostic-info

LukeAbell on (2024-06-18 18:48:50 UTC): @perivamsi Just emailed support logs for the dashboard.

paoliniluis on (2024-06-18 19:01:31 UTC): @LukeAbell @rob-pomelo and @alperengunes can you add MB_SQL_PARSING_ENABLED=false, reboot and then let us know if this keeps happening?

@alperengunes 
2024-06-18 14:33:00,039 WARN malli.fn :: Invalid output
ERROR middleware.add-source-metadata :: Error determining expected columns for query
clojure.lang.ExceptionInfo: Error preprocessing query in metabase.query_processor.preprocess
Caused by: clojure.lang.ExceptionInfo: Invalid query

please post the questions that spit those lines

matotias on (2024-06-18 19:11:17 UTC): Not sure if it's the same issue, but we started seeing huge spikes in the database after updating, these updates seem to be the problem 
<img width=""1095"" alt=""image"" src=""https://github.com/metabase/metabase/assets/29378537/95a6c509-0651-428a-8ff0-d2feaa8366a4"">

paoliniluis on (2024-06-18 19:13:55 UTC): @matotias what version did you upgrade from?

paoliniluis on (2024-06-18 19:21:45 UTC): @matotias and what engine/sizing are you using as well

LukeAbell on (2024-06-18 19:25:31 UTC): @paoliniluis Didn't seem to change much. I think it's permission or sandbox related because it's much faster as a super admin vs a normal user that's sandboxed using full app embed.

LukeAbell on (2024-06-18 19:27:23 UTC): Check out the difference in time between sandboxed (right) and super admin (left).
![Screenshot 2024-06-18 at 03 26 53 PM@2x](https://github.com/metabase/metabase/assets/3343530/8c005d26-37ee-40d2-8447-f0d934730157)

matotias on (2024-06-18 19:31:50 UTC): We went from `0.49.12` to `0.50.4` and the spikes started, then we updated again to `0.50.5` but we're still seeing them

We use postgres, 4 cpu 16 gigs of ram

paoliniluis on (2024-06-18 19:49:04 UTC): @LukeAbell I'm trying to reproduce what you're seeing and I'm wondering how it's taking 4 seconds to get a 30kb response. Can you describe a little more the queries? how are queries built (based on questions or models?). Are tables big? many joins?

paoliniluis on (2024-06-18 19:49:34 UTC): 4 cpu and 16 gigs of ram is the postgres sizing right?

LukeAbell on (2024-06-18 19:50:06 UTC): @paoliniluis want to hop on a quick video chat?

paoliniluis on (2024-06-18 19:56:46 UTC): @LukeAbell give me a couple of hours to try to go to the call with some answers, can you make it tomorrow first time in the morning?

LukeAbell on (2024-06-18 19:59:43 UTC): @paoliniluis Tomorrow at 10am EST work?

LukeAbell on (2024-06-18 20:04:46 UTC): Queries are based on questions (no models involved). Not a ton of joins. Using bigquery- table has about 800k rows.

Only 6 tables are returned in that query_metadata call.

paoliniluis on (2024-06-18 20:05:43 UTC): Thanks @LukeAbell, do you have observability in the app db to see if there's something weird there?

LukeAbell on (2024-06-18 20:07:42 UTC): Yep- doesn't seem like anything weird there. Less than 20% utilization. Running MySQL.

matotias on (2024-06-18 20:20:46 UTC): Yes!

alperengunes (Issue Creator) on (2024-06-18 20:26:55 UTC): checking

matotias on (2024-06-18 22:09:07 UTC): Update on our case: we went back to v0.49.12 and the database load is normal again

alperengunes (Issue Creator) on (2024-06-18 22:49:35 UTC): not working :'( same

paoliniluis on (2024-06-18 23:14:21 UTC): @matotias is your app db a postgres or mysql?

matotias on (2024-06-18 23:15:46 UTC): postgres

paoliniluis on (2024-06-19 01:23:27 UTC): ok we have some strings to pull from now

naveenthontepu on (2024-06-19 02:29:22 UTC): Metabase is crashing every 3 to 4 hours in our case also. There is no significant jump in the CPU utilisation but the RAM utilisation has significantly increased and is consuming the complete 4 gb ram we have on the metabase server. 

Looking at the tasks running on our server by running ""htop"" we are seeing that there are too many tasks metabase is keeping active even when there is nobody using metabase.

perivamsi on (2024-06-19 08:26:32 UTC): @naveenthontepu could you send us the output of `htop` and logs of the tasks that Metabase is keeping active?

paoliniluis on (2024-06-19 11:35:54 UTC): Also: any specific environment variable that youâ€™re using?

naveenthontepu on (2024-06-19 12:04:35 UTC): ![Screenshot 2024-06-19 at 5 29 24 PM](https://github.com/metabase/metabase/assets/13089476/d53db817-59ac-4ebb-9a23-35f47c7a530f)

There are no environment variables that we are using. 

the command we are using to run metabase specifically mentions to use only 2gb of the 4gb ram but it is not being considered and using it 4gb and crashing. In the above screenshot also we can see that metabase is consuming 71% memory which is ~3gb.

noahmoss on (2024-06-19 15:47:20 UTC): @LukeAbell what version of MySQL are you on?

LukeAbell on (2024-06-19 15:51:54 UTC): @noahmoss 8.0.31

psneha716 on (2024-06-20 10:12:53 UTC): Hi, 
I tried disabling query parsing using MB_SQL_PARSING_ENABLED=false but it's of no help. Metabase is still crashing with OOM.
Version: v0.50.1

Context:

Metabase deployed on ECS with EC2. 
**CPU per task**: 3800 units (3.711 vCPU)
**Memory per task:** 3700 MiB (3.613 GB)

2 tasks deployed currently

paoliniluis on (2024-06-20 11:18:18 UTC): Weâ€™re working on this as we speak

perivamsi on (2024-06-24 21:13:03 UTC): @LukeAbell we have some changes coming that that might improve the performance. would you be able to upgrade to 50.7 and test? which version are you on right now? is it easy for you to downgrade if 50.7 is still slow for you?

LukeAbell on (2024-06-24 21:16:42 UTC): @perivamsi yep just let me know when there's a tagged release. Or do I need to test on a custom branch?

perivamsi on (2024-06-24 21:17:11 UTC): no need to test a custom branch, I'll give you a proper release link once ready

shrey-locad on (2024-06-25 03:08:44 UTC): exactly same problem since the upgrade to 0.50. memory and cpu spiking intermittently bringing down the whole container every 3-4 hours. We will give it 1-2 more days before downgrading back to 0.49

perivamsi on (2024-06-25 08:05:23 UTC): @shrey-locad sorry about that! are you open to having a call that can help us debug this better? as I said, we are working on this but it would be helpful to have additional data points around the memory and CPU spikes. also, hi from another IITB alum!

cheyuriy on (2024-06-25 14:23:01 UTC): Similar issue with CPU spikes after upgrading from 0.49.x to 0.50.6. 
Using Postgres 14 as a DB. Metabase is deployed on 2CPU-12GB in GCE and DB is in CloudSQL.

Upgrade was in the end of 06/24.
 
<img width=""1102"" alt=""Screenshot 2024-06-25 at 11 12 36"" src=""https://github.com/metabase/metabase/assets/6412917/7254ce97-41d1-451a-8e07-fd2effa4c6b0"">

shrey-locad on (2024-06-25 14:45:51 UTC): @perivamsi - haha, that's a pleasant surprise. Hi ðŸ‘‹ðŸ½ 

It might be hard to debug over a call, especially since the crashes are unpredictable and intermittent. We have been unable to identify a specific trigger either. The latest crash was in the middle of the night where we're pretty sure none of our users were online. How about we gave you ssh access to the instance instead? Call works too. Either way. shrey.jain@golocad.com

perivamsi on (2024-06-25 14:47:19 UTC): That works, we just need to look at the logs. I'll email you.

perivamsi on (2024-06-25 19:38:06 UTC): @LukeAbell @shrey-locad @cheyuriy can you all please upgrade to 50.7 which has some fixes for the performance issues?

https://github.com/metabase/metabase/releases/tag/v0.50.7

LukeAbell on (2024-06-25 19:48:20 UTC): @perivamsi I upgraded but had to quickly downgrade because it completely broke the application. Downgrading back to v1.50.6 fixed the issue. I tried clearing our CDN cache and flushing browser cache but it didn't help.

Assets wouldn't load giving an error:

```
Refused to execute script from 'HOST/app/dist/runtime.ba18610064ff9fba6745.js' because its MIME type ('') is not executable, and strict MIME type checking is enabled.
```

perivamsi on (2024-06-25 19:50:45 UTC): We're on it

bshepherdson (Assginee) on (2024-06-25 20:02:13 UTC): That sounds like https://github.com/metabase/metabase/issues/39449. If force-refresh doesn't work, try another browser?

It does seem like it was a transitory issue in the past.

LukeAbell on (2024-06-25 21:18:16 UTC): @perivamsi  @bshepherdson Completely cleared cache and that worked. Unfortunately not much of an improvement in performance (if any) ðŸ˜”

- Query metadata taking 4-6 seconds sandboxed 
- Queries taking 3-5 seconds sandboxed
- CPU usage still spiking like crazy loading a single dashboard

uladzimirdev on (2024-06-25 21:19:28 UTC): @LukeAbell just for the record, what kind of cache have you cleared? what CDN do you use? we're struggling to reproduce the issue, so any info would be helpful (some users had it during upgrades from older versions)

LukeAbell on (2024-06-25 21:20:07 UTC): @uladzimirdev I had to clear my local browser cache to resolve the issue. We have metabase behind a google cloud CDN but that didn't be the issue.

psneha716 on (2024-06-26 13:56:32 UTC): Hi folks,
Could someone who has already downgraded their metabase version, help me out with the downgrading process? Tried downgrading, but it isn't working. Any help would be greatly appreciated. Thanks!

**Cluster configuration:**

ECS cluster with 2 tasks.
Task CPU: 3800 units (3.711 vCPU)
Task memory: 3700 MiB (3.613 GB)


**Steps that I followed for downgrading** (followed instructions from [here](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade)):

- Stopped the container running v0.50.1 metabase instance

- Ran the following on the EC2 instance directly:

```
$docker run --rm metabase/metabase:v0.50.1 ""migrate down""
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-06-12 21:08:25,427 INFO metabase.util :: Maximum memory available to JVM: 1.9 GB
2024-06-12 21:08:27,762 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. ðŸ”“
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-06-12 21:08:28,566 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For production deployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database file regularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html
2024-06-12 21:08:32,573 INFO driver.impl :: Registered abstract driver :sql  ðŸšš
2024-06-12 21:08:32,579 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) ðŸšš
2024-06-12 21:08:32,585 INFO metabase.util :: Load driver :sql-jdbc took 32.7 ms
2024-06-12 21:08:32,586 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) ðŸšš
2024-06-12 21:08:32,717 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) ðŸšš
2024-06-12 21:08:32,744 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) ðŸšš
2024-06-12 21:08:34,401 INFO metabase.core ::
Metabase v0.50.1 (cc4ca82)

Copyright Â© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-06-12 21:08:34,657 INFO db.setup :: Setting up Liquibase...
2024-06-12 21:08:35,245 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-06-12 21:08:35,254 INFO db.liquibase :: No migration lock found.
2024-06-12 21:08:35,255 INFO db.liquibase :: Migration lock acquired.
2024-06-12 21:08:35,259 INFO db.setup :: Liquibase is ready.
2024-06-12 21:08:35,262 INFO db.liquibase :: No migration lock found.
2024-06-12 21:08:35,263 INFO db.liquibase :: Migration lock acquired.
2024-06-12 21:08:35,264 INFO db.liquibase :: Rolling back app database schema to version 49
```

- Tried spinning up a container using v0.49.15, but getting the following error:

```
2024-06-12 21:10:56,380 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
--
2024-06-12 21:10:56,382 INFO db.setup :: ï¿½[36mVerifying postgres Database Connection ...ï¿½[0m
2024-06-12 21:10:56,724 INFO db.setup :: Successfully verified PostgreSQL 13.13 application database connection. âœ…
2024-06-12 21:10:56,725 INFO db.setup :: ï¿½[36mChecking if a database downgrade is required...ï¿½[0m
2024-06-12 21:10:56,834 ERROR middleware.log :: ï¿½[31mGET /api/health 503 287.2 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}
ï¿½[0m
2024-06-12 21:10:56,844 ERROR middleware.log :: ï¿½[31mGET /api/health 503 182.0 Âµs (0 DB calls)
{:status ""initializing"", :progress 0.3}
ï¿½[0m
2024-06-12 21:10:57,344 ERROR metabase.core :: Metabase Initialization FAILED
clojure.lang.ExceptionInfo: ï¿½[31mERROR: Downgrade detected.ï¿½[0m
Your metabase instance appears to have been downgraded without a corresponding database downgrade.
You must run `java -jar metabase.jar migrate down` from version 50.
Once your database has been downgraded, try running the application again.
```

noahmoss on (2024-06-26 14:07:33 UTC): Hi @psneha716 â€”Â I don't see any errors in the downgrading logs that indicate specifically why it didn't work. But I did fix an issue related to downgrading in Metabase 50.7, the latest release. Could you try starting that version up, and then running the downgrade command with it?

If that doesn't work could you open a new issue with the full logs?

psneha716 on (2024-06-26 19:37:32 UTC): Hi @noahmoss ,
It did not work. Created a new issue [here](https://github.com/metabase/metabase/issues/44784).

psneha716 on (2024-06-27 07:43:44 UTC): Seeing frequent OOM crashes in v0.50.7 too. Don't see any improvement.

bshepherdson (Assginee) on (2024-06-27 13:11:53 UTC): @psneha716 have you got metrics that show whether there's a slow climb in usage until OOM, or a spike?

There are fixes in flight for a few things that might help, but I don't have any clear link to either a slow leak or spike in memory use.

(Those fixes specifically: better batching of TCP traffic while streaming query results; fixing an N+1 problem during dashboard loads; and fixing another N+1 problem with sandboxing enabled on dashboard loads. But I don't think any of those have significant memory use overhead. They are definitely spike-y though, hence my question about spikes vs. leaks.)

cheyuriy on (2024-06-27 13:54:09 UTC): @bshepherdson it's a slow climb till the limit 
graphs for virtual and resident memory usage for today with 2 restarts
<img width=""1122"" alt=""Screenshot 2024-06-27 at 10 48 24"" src=""https://github.com/metabase/metabase/assets/6412917/7738b706-ea54-4599-866a-541e661f9a9c"">
<img width=""1108"" alt=""Screenshot 2024-06-27 at 10 49 13"" src=""https://github.com/metabase/metabase/assets/6412917/821bfcdb-6f8c-4d6d-968b-3a1094979353"">

Also I can see constantly increasing number of ""total active threads"" in logs. Both time it climbed from 0 to ~16500 before fail.
`2024-06-27 06:14:26,632 DEBUG middleware.log :: [32mPOST /api/dashboard/242/dashcard/8869/card/9623/query 202 [ASYNC: completed] 4.1 s (22 DB calls) App DB connections: 1/100 Jetty threads: 3/100 (15 idle, 0 queued) (16,637 total active threads) Queries in flight: 7 (0 queued) {:metabase-user-id 910}[0m`

bshepherdson (Assginee) on (2024-06-27 14:02:48 UTC): Ah, thanks for those! Good catch with the runaway thread count, that's a strong signal.

bshepherdson (Assginee) on (2024-06-27 14:56:27 UTC): Just to keep these dots connected: there's a fix which only applies to users of MySQL (for querying, not as Metabase's appdb) that **greatly** reduces thread pool pressure while querying MySQL. It was fixed in #44719 which merged a short while ago and will be in 50.8.

If everyone with this OOM issue is querying MySQL, then I think that's highly likely to be the issue. If some here are seeing OOMs without talking to MySQL, then there's more to find. I'm still investigating in any case, but please chime in about MySQL!

cheyuriy on (2024-06-27 15:39:42 UTC): @bshepherdson we don't query MySQL. Only postgres and BigQuery

bshepherdson (Assginee) on (2024-06-27 15:48:41 UTC): @cheyuriy okay, thanks. I'll keep digging for what the runaway threads might be coming from.

bshepherdson (Assginee) on (2024-06-27 19:28:31 UTC): Anyone who is having this issue who is able to send CLI commands to your instance, can you run `jstack -l PID` and send the output? That should give a dump of all the threads in the running process with names and stacks, which might be huge with 16k but should illuminate which source of threads is leaking, how they got created, and what's holding them open.

(@cheyuriy since I know you specifically have runaway thread spawns)

cheyuriy on (2024-06-27 19:32:31 UTC): @bshepherdson sry, we've restarted it minutes ago. I'll run this command later, when it will be close to this number again

bshepherdson (Assginee) on (2024-06-27 20:22:28 UTC): Never mind! We managed to find one of our cloud instances on 50.x with a runaway thread pool, and get that thread dump from it. This is an issue with dangling timeout futures when querying Bigquery. This should be fixed tomorrow (Friday).

psneha716 on (2024-06-28 06:58:53 UTC): Hey Guys,
Even after downgrading to v0.49.12, I'm seeing a lot of crashes due to OOM. Is there any stable version that I can go back to?

Currently it's crashing at 45% utilisation.

<img width=""1304"" alt=""image"" src=""https://github.com/metabase/metabase/assets/152379423/26e0e61e-5a90-4870-bc4a-2680c11dba79"">

bshepherdson (Assginee) on (2024-06-28 13:44:57 UTC): Unless there was a sharp spike to 100% there that was missed by the metrics, why would it crash at 44%? The right side of that graph looks like a major GC to me.

Are you still seeing runaway thread counts? I don't know when the (BigQuery-specific) thread leak that's causing these OOMs was introduced, but given how many people are seeing it on 50.x it's hard to believe it's also been in 49.12 for months but it hasn't been reported until now.

If it is happening in 49.x we can backport the fix (#44860) to the 49 branch as well. It should land in the 50 branch in 30m or less and we'll get a 50.8 release out today. (Fixing this OOM issue plus some dashboard load time slowness, especially for sandboxing users.)

psneha716 on (2024-06-30 12:47:18 UTC): @bshepherdson How do I diagnose the issue?

psneha716 on (2024-07-01 05:05:34 UTC): I increased the heap space of the application to 70% of the total RAM, it hasn't crashed since then but the memory utilisation is just consistently going up. It's just a matter of time before it crashes.

<img width=""1318"" alt=""image"" src=""https://github.com/metabase/metabase/assets/152379423/920566e0-14d8-4eef-a4e6-10b65c68b0cf"">

perivamsi on (2024-07-02 09:02:04 UTC): Everyone who reported OOM crashes (especially if you are using BigQuery), we released a fix for this issue with v50.8. Please upgrade: https://github.com/metabase/metabase/releases/tag/v0.50.8

alperengunes (Issue Creator) on (2024-07-02 09:56:09 UTC): Thank you @perivamsi

shrey-locad on (2024-07-02 11:47:07 UTC): upgraded to 0.50.8. Will keep you posted

MathiasGr on (2024-07-03 08:36:43 UTC): Hi there, we upgraded to 0.50.8 yesterday and just experienced the CPU craziness this morning again.

The CPU usage seems to exponentially increase until everything is stalling. The memory usage is stable though, nothing to report on that front.

We are mostly using BigQuery.

<img width=""507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/18528990/ed1b8a34-3c7d-427f-8cb6-f9e0ae8e2b0e"">

cheyuriy on (2024-07-03 12:05:10 UTC): Memory issues are less severe with 0.50.8, however they are still present. And yes, we can observe CPU spikes too.

perivamsi on (2024-07-03 12:09:37 UTC): @cheyuriy can you share more details about the memory issues? Can you do a thread dump and send it to us? `jstack -l <pid>`

cheyuriy on (2024-07-03 13:03:23 UTC): @perivamsi it requires JDK to be installed, as i know. And we're using docker image which includes JRE...

perivamsi on (2024-07-03 13:05:08 UTC): Understood. Any insights you can provide into the resource usage?

On Wed, Jul 3, 2024 at 9:03â€¯AM Yury Cheremushkin ***@***.***>
wrote:

perivamsi on (2024-07-03 14:14:35 UTC): @MathiasGr are you able to provide a thread dump? anything that helps us see what is going on during the CPU spikes will be helpful.

perivamsi on (2024-07-03 14:15:08 UTC): @shrey-locad how is your resource usage looking after the upgrade?

perivamsi on (2024-07-03 14:19:20 UTC): @MathiasGr ~the CPU graph you showed is that of the Metabase process or the BigQuery database?~

I understand It is Metabase

cheyuriy on (2024-07-03 15:45:26 UTC): Looks like it's possible to get thread dump by sending `kill -3` to the java process inside the container. I'll try to do it later, when it will spawn a lot of threads

MathiasGr on (2024-07-03 17:59:16 UTC): Indeed, it's Metabase

MathiasGr on (2024-07-03 18:03:17 UTC): I can try but these events happen randomly and when they do the entire pod stalls so it's almost impossible to get anything from it. It even starts failing healthchecks until it's killed by kube.

cheyuriy on (2024-07-03 20:21:57 UTC): [dump.txt](https://github.com/user-attachments/files/16090472/dump.txt)
Thread dump after ~9 hours uptime

bshepherdson (Assginee) on (2024-07-03 20:55:58 UTC): @cheyuriy thanks! Quick analysis: 8000+ threads in the `clojure-agent-send-off-pool-NNN` group, all blocking inside the `execute-bigquery` logic. That tracks with our theory that the fix in 50.8 #44860 only got some of the cases. Dan's #45105 seems to address the remaining cases in his load testing.

That doesn't explain the CPU utilization spikes, though, at least not directly.

Some questions for anyone seeing the CPU spikes:
- Do they occur on some rhythm, or at random times?
- If a rhythm, does it track with some other event?
    - Especially with Metabase's sync process, which is scheduled in your admin settings.
- Does memory usage correlate with the spikes at all? (If so, the spikes could really be a burst of GC thrashing, ending with an OOM crash and recovery after a restart.)

bshepherdson (Assginee) on (2024-07-03 20:57:47 UTC): @MathiasGr See my questions [above](https://github.com/metabase/metabase/issues/44359#issuecomment-2207269022). You say ""randomly"", but the graph shows they happen pretty consistently around the same time every day, which makes me suspect they're linked with some event such as syncing, or certain requests to Metabase. Of course that timing may just be a coincidence, too.

MathiasGr on (2024-07-05 09:47:04 UTC): Sorry Im currently on holiday but will take a look next week

cheyuriy on (2024-07-05 18:36:01 UTC): Can't see any pattern here. It happens when it has already consumed a lot of memory, but not correlated with anything else. It's even not the peak hour of Metabase usage in our company.

calherries on (2024-07-05 19:38:58 UTC): @MathiasGr @cheyuriy You could help us narrow down the issue by disabling fingerprinting and field value scanning for all databases, and seeing if the issue persists. These have been the source of similar issues in the past. You can do this by going to Admin > Databases and setting one of these options:
![image](https://github.com/metabase/metabase/assets/39073188/e1c25d7e-1f66-49b7-a53f-ea88bb3d98c1)

cheyuriy on (2024-07-09 12:39:53 UTC): Didn't affect anything

calherries on (2024-07-10 00:57:58 UTC): Thanks, that helps. @bshepherdson that implies it's not fingerprinting or field value scanning that's causing their issue.

bshepherdson (Assginee) on (2024-07-10 18:24:10 UTC): #45253 will fix the thread leak that leads to OOMs. I hope that it will also fix the unresponsive Metabase issues, because it appears the CPU spike and unresponsiveness may be due to GC thrashing as memory is nearly exhausted.

I'm doing a bit more profiling of general CPU usage with BigQuery before and after #45253; it removes some CPU/allocation overhead while processing individual queries, but I'm not sure how significant the impact is. Last week I wasn't able to reproduce any significant CPU usage while eg. loading a dashboard full of BQ queries, but I'm going to try a couple more approaches now.

perivamsi on (2024-07-15 09:51:48 UTC): With https://github.com/metabase/metabase/pull/45536, I would like to close this issue and open any new specific issues as needed.

paoliniluis on (2024-07-15 11:05:49 UTC): @MathiasGr can you test the new release?

paoliniluis on (2024-07-15 12:37:36 UTC): same @alperengunes @cheyuriy @matotias @shrey-locad @psneha716 @rob-pomelo, please all upgrade to 50.13 and post your results

shrey-locad on (2024-07-16 01:50:27 UTC): upgraded to 50.13. No issues since last 16 hours.

paoliniluis on (2024-07-16 02:46:02 UTC): We found that the queries in 50 are taking longer, and probably there's also more memory pressure than on previous versions. We'll start working on those 2 as soon as we can

rob-pomelo on (2024-07-17 13:15:07 UTC): 50.13 actually been worse for us than 50.10 (have been okay on 50.10 but still worse than 49 perf), have some dashboards we can't even load at all on 50.13 so had to rollback

Example error from logs
```
ERROR metabase.server.middleware.log GET /api/dashboard/190/query_metadata 500 4.2 mins (283 DB calls) {:metabase-user-id 88} 
{:via
 [{:type java.io.IOException,
   :message ""java.util.concurrent.TimeoutException: Idle timeout expired: 200000/200000 ms"",
   :at [org.eclipse.jetty.util.SharedBlockingCallback$Blocker block ""SharedBlockingCallback.java"" 221]}
  {:type java.util.concurrent.TimeoutException,
   :message ""Idle timeout expired: 200000/200000 ms"",
   :at [org.eclipse.jetty.io.IdleTimeout checkIdleTimeout ""IdleTimeout.java"" 170]}],
 :trace
 [[org.eclipse.jetty.io.IdleTimeout checkIdleTimeout ""IdleTimeout.java"" 170]
  [org.eclipse.jetty.io.IdleTimeout idleCheck ""IdleTimeout.java"" 112]
  [java.util.concurrent.Executors$RunnableAdapter call nil -1]
  [java.util.concurrent.FutureTask run nil -1]
  [java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask run nil -1]
  [java.util.concurrent.ThreadPoolExecutor runWorker nil -1]
  [java.util.concurrent.ThreadPoolExecutor$Worker run nil -1]
  [java.lang.Thread run nil -1]],
 :cause ""Idle timeout expired: 200000/200000 ms"",
 :message ""java.util.concurrent.TimeoutException: Idle timeout expired: 200000/200000 ms""}
```

perivamsi on (2024-07-17 17:27:23 UTC): @rob-pomelo could you please email me at vamsi@metabase.com? would like to get more details from you so we can fix your issue. ideally if you have time to meet and screen share, that would help a lot.

ranquild on (2024-07-20 00:53:28 UTC): Closed by https://github.com/metabase/metabase/pull/45881

dmeremyanin on (2024-07-24 21:13:39 UTC): Just my 2 cents after our Metabase upgrade today.

We updated from 0.49.21 to 0.50.15 and observed significantly higher CPU usage along with a decrease in performance. Metabase is deployed in Kubernetes using a configuration of 2 pods with 12 CPU and 8GB memory limit. Is started hitting the CPU limit, becoming unresponsive and triggering restarts due to the liveness probe.

We rolled back to version 0.49.21, and it started working perfectly fine again.

<img width=""1303"" alt=""Screenshot 2024-07-24 at 1 46 04 PM"" src=""https://github.com/user-attachments/assets/a1302efb-a829-4467-9d0e-e50955fa28d6"">

paoliniluis on (2024-07-24 21:29:46 UTC): @dmeremyanin can you contact us to our support email? We would like you test specific versions of the product if thatâ€™s fine with you. We would like to profile your deployment to find the causes of this

perivamsi on (2024-07-25 02:01:39 UTC): Should be fixed by https://github.com/metabase/metabase/pull/46108

perivamsi on (2024-07-25 02:19:52 UTC): @dmeremyanin we will release v50.16 with a fix for the performance issue. please test against that version and let us know if if you are still facing the CPU spikes.

dmeremyanin on (2024-07-25 05:54:19 UTC): Apologies for the delayed response and thank you for the prompt reaction. We will definitely test v50.16 and get back here with feedback. Thanks

perivamsi on (2024-07-25 09:34:18 UTC): @dmeremyanin 50.16 is out. Could you please test?

MikitaKurlovich on (2024-07-25 15:07:05 UTC): Hi there! Still have the issue on v50.16

docker compose:
```
  metabase-postgres:
    image: postgres:16.3
    container_name: metabase-postgres
    environment:
      POSTGRES_DB: metabase
      POSTGRES_USER: <metabase_user>
      POSTGRES_PASSWORD: <metabase_password>
    volumes:
      - metabase-postgres-data:/var/lib/postgresql/data
    ports:
      - ""5432:5432â€

  metabase:
    restart: unless-stopped
    image: metabase/metabase:v0.50.16
    ports:
      - 3001:3000
    environment:
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 5432
      MB_DB_USER: <metabase_user>
      MB_DB_PASS: <metabase_password>
      MB_DB_HOST: metabase-postgres
    volumes:
      - ./metabase-data:/metabase-data
    depends_on:
      - metabase-postgres
```      
Diagnostic Info:
```
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.15.0-213-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-25"",
      ""tag"": ""v0.50.16"",
      ""hash"": ""28de9df""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```
      
<img width=""1470"" alt=""Screenshot 2024-07-25 at 16 50 23"" src=""https://github.com/user-attachments/assets/a073585b-ae14-4cec-bcce-0aa48fbf6644"">

paoliniluis on (2024-07-25 15:58:46 UTC): hi @MikitaKurlovich your screenshot doesn't show cpu or memory pressure, can you please specify your problem?

dmeremyanin on (2024-07-25 20:58:27 UTC): @perivamsi we've updated to v50.16. There's no traffic on it at the moment, but we are monitoring the load.

perivamsi on (2024-07-25 21:17:01 UTC): Thanks @dmeremyanin, keep me posted!

paoliniluis on (2024-07-25 23:44:19 UTC): @dmeremyanin any news?

dmeremyanin on (2024-07-25 23:57:40 UTC): Everything looks good so far, but there is still not much traffic.

dmeremyanin on (2024-07-26 15:17:53 UTC): Overall, the same issues: very high CPU utilization, which leads to freezing. We've rolled back to v0.49.21. Is there anything I can share that can help debug the problem?

<img width=""1301"" alt=""Screenshot 2024-07-26 at 8 02 53 AM"" src=""https://github.com/user-attachments/assets/ecf4899e-f035-4032-9c23-734ac4501c9e"">

perivamsi on (2024-07-26 15:27:48 UTC): @dmeremyanin mind emailing me at vamsi@metabase.com? would like to meet and debug if possible.

dmeremyanin on (2024-07-26 15:57:42 UTC): @perivamsi sure, I just sent you an email.

V-Legendre on (2024-07-31 09:08:29 UTC): Hey guys, I am observing the same problems with version v1.50.17.
Had to rollback to v49 to make Metabase available again.

![Screenshot 2024-07-31 at 11 02 44](https://github.com/user-attachments/assets/d95d049b-50c4-48d7-93f6-5f37549727f4)


Also, one SQL query executed by MB migrations was hanging indefinitely (+2hours) during the upgrade. I had to kill by hand and MB started nonetheless.

perivamsi on (2024-07-31 09:34:09 UTC): @V-Legendre are you open to sharing more diagnostic info over email or slack to help us fix the CPU spike issue? Please email me at vamsi@metabase.com if you are.

apostoltego on (2024-08-02 11:24:10 UTC): Hey just to add to this thread as we're seeing similar complaints. One thing that we observed was that admin users don't experience slowness. As an experiment I worked with a user that wasn't an admin and we were seeing CPU spikes on all dashboards and after making them an admin the issue went away. 
![Screenshot 2024-08-02 at 13 17 16](https://github.com/user-attachments/assets/b552f7cb-0f80-4106-a870-7c9f4a57e2c9)


Diagnostics ingo:
```
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.10 (Ubuntu 13.10-1.pgdg22.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-26"",
      ""tag"": ""v0.50.17"",
      ""hash"": ""afd6b17""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```

perivamsi on (2024-08-02 11:39:22 UTC): @apostoltego are the non-admin users sandboxed or not?

apostoltego on (2024-08-02 11:44:02 UTC): @perivamsi apologies - what do you mean by sandboxed in this case?

perivamsi on (2024-08-02 11:52:19 UTC): It is a feature for pro customers, you are running open source version so it does not apply. Sorry for the confusion!

perivamsi on (2024-08-02 13:11:55 UTC): @apostoltego could you please run these sqls in the app db and tell us the results?

```
select count(*) from data_permissions
select count(*), active from metabase_table group by active
```

apostoltego on (2024-08-02 14:07:09 UTC): Sure here you go @perivamsi 
First one is: `113,541` 

Second one is:
```
count | active
15,388 | false
1,287 | true
```

NevRA on (2024-08-15 14:28:24 UTC): Resolved all related issues to this. If you have any other CPU-related issues please create a new issue

apostoltego on (2024-08-22 13:50:56 UTC): hey @NevRA Tried with 0.50.20  & .21 just now the performance difference for end users vs admins seems to persist however overall utilisation doesn't seem to spike as much. Should this be opened as a separate issue? Or maybe there's a way to trim the overall data_permissions to speed things up?

paoliniluis on (2024-08-22 14:08:22 UTC): @apostoltego open a new issue please with all details

"
2359775679,issue,closed,completed,New dashboard filters no longer query for enumerated values as as of 0.50.x ,"### Describe the bug

As of the 0.50.x branch (don't know if it's 0.50.0 or a later version), **some** new dashboard filters no longer query for their enumerated values.

![Screenshot 2024-06-18 at 9 00 32â€¯AM](https://github.com/metabase/metabase/assets/634835/37ab396f-556b-4ad8-8df1-62489670fb61)


### To Reproduce

- Stand up a fresh install with version 1.50.5, including example data
- Navigate to the `/dashboard/1-e-commerce-insights` example dashboard
- Edit the dashboard, and add a new ""Text or Category"" filter
- Select ""Users > Email"" in any of the cards to attach the field to the filter
- Click ""Done"" in the filters drawer, and save the dashboard
- After the dashboard saves, open the browser developer tools, then the network tab, and refresh the page (to get a clean slate)
- Once loaded, click the new filter
- Observer that there is no network traffic to get the enumerated set of values for this filter

Note: if you select ""User > Source"" as the connected field, the filter works as expected.

### Expected behavior

The filter should make an HTTP request to get the list of enumerated values for the field, and the field should display as a drop-down-type-ahead field.

### Logs

From the browser console:
![Screenshot 2024-06-18 at 8 30 29â€¯AM](https://github.com/metabase/metabase/assets/634835/3d9df239-b889-4471-b084-c763718fd4c3)

```
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ convert.cljc:226
n1.g.h @ core.cljs:11497
(anonymous) @ convert.cljc:620
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:63
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ query.cljc:178
n1.g.g @ core.cljs:11503
i.Y3 @ query.cljc:233
e4 @ core.cljs:3996
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
t @ core.cljc:75
(anonymous) @ js.cljs:181
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:63
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ convert.cljc:226
n1.g.h @ core.cljs:11497
(anonymous) @ convert.cljc:620
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:77
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ query.cljc:178
n1.g.g @ core.cljs:11503
i.Y3 @ query.cljc:233
e4 @ core.cljs:3996
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
t @ core.cljc:75
(anonymous) @ js.cljs:181
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:77
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ convert.cljc:226
n1.g.h @ core.cljs:11497
(anonymous) @ convert.cljc:620
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:63
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ query.cljc:178
n1.g.g @ core.cljs:11503
i.Y3 @ query.cljc:233
e4 @ core.cljs:3996
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
t @ core.cljc:75
(anonymous) @ js.cljs:181
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:63
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ convert.cljc:226
n1.g.h @ core.cljs:11497
(anonymous) @ convert.cljc:620
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:77
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""
overrideMethod @ console.js:273
e9 @ core.cljs:4009
e6 @ core.cljs:4003
e4 @ core.cljs:3997
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
(anonymous) @ console.cljs:33
n @ glogi.cljs:199
(anonymous) @ log.js:702
r @ log.js:701
a @ log.js:994
x.wU @ glogi.cljs:26
y @ normalize.cljc:46
n1.g.h @ core.cljs:1183
(anonymous) @ core.cljc:2227
l @ normalize.cljc:85
f.E1.j @ normalize.cljc:91
f.E1.g @ normalize.cljc:80
f.E1.h @ normalize.cljc:77
(anonymous) @ query.cljc:178
n1.g.g @ core.cljs:11503
i.Y3 @ query.cljc:233
e4 @ core.cljs:3996
e7 @ core.cljs:3991
n1.Me.g @ core.cljs:3985
t @ core.cljc:75
(anonymous) @ js.cljs:181
el.T_ @ cache.cljc:71
N.j @ cache.cljc:117
e @ js.cljs:145
P @ query.ts:22
query @ Question.ts:760
_serializeForUrl @ Question.ts:690
u @ urls.ts:36
h @ questions.ts:105
(anonymous) @ NewItemMenu.tsx:77
oq @ react-dom.production.min.js:168
t.useMemo @ react.production.min.js:23
(anonymous) @ NewItemMenu.tsx:56
ol @ react-dom.production.min.js:157
oX @ react-dom.production.min.js:180
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
aJ @ react-dom.production.min.js:244
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ rtk-query.esm.js:2023
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
n.type @ utils.js:204
await in n.type (async)
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:112
componentDidMount @ EntityListLoader.jsx:131
(anonymous) @ react-dom.production.min.js:219
a9 @ react-dom.production.min.js:221
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
a7 @ react-dom.production.min.js:252
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 86 more frames
Show lessUnderstand this warning
metadata.js:15 DEPRECATED: metabase/redux/metadata addParamValues
overrideMethod @ console.js:273
f @ metadata.js:15
M @ metadata.js:106
(anonymous) @ data-fetching-typed.ts:146
await in (anonymous) (async)
(anonymous) @ redux-toolkit.esm.js:1237
(anonymous) @ redux-toolkit.esm.js:38
(anonymous) @ redux-toolkit.esm.js:41
(anonymous) @ redux-toolkit.esm.js:87
(anonymous) @ redux-toolkit.esm.js:69
(anonymous) @ redux-toolkit.esm.js:1276
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
(anonymous) @ Dashboard.tsx:256
(anonymous) @ Dashboard.tsx:308
sn @ react-dom.production.min.js:262
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
se @ react-dom.production.min.js:261
aK @ react-dom.production.min.js:243
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:18
ir @ react-dom.production.min.js:122
ia @ react-dom.production.min.js:123
io @ react-dom.production.min.js:122
a$ @ react-dom.production.min.js:237
enqueueSetState @ react-dom.production.min.js:133
g.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:19
(anonymous) @ AsyncUtils.js:79
(anonymous) @ AsyncUtils.js:78
S @ AsyncUtils.js:83
u @ createTransitionManager.js:77
c @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
onEnter @ routes.jsx:106
await in onEnter (async)
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
c @ AsyncUtils.js:34
_ @ AsyncUtils.js:49
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
c @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
c @ AsyncUtils.js:41
_ @ AsyncUtils.js:49
N @ matchRoutes.js:231
l @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
iE @ react-dom.production.min.js:138
o$ @ react-dom.production.min.js:181
l @ react-dom.production.min.js:269
a6 @ react-dom.production.min.js:250
(anonymous) @ react-dom.production.min.js:250
a4 @ react-dom.production.min.js:250
aK @ react-dom.production.min.js:243
a$ @ react-dom.production.min.js:237
sm @ react-dom.production.min.js:285
(anonymous) @ react-dom.production.min.js:289
aQ @ react-dom.production.min.js:244
s_ @ react-dom.production.min.js:289
t.render @ react-dom.production.min.js:296
jF @ app.js:68
jH @ app.js:99
22070 @ app-main.js:24
a @ runtime.7663de615ace3aaafba3.js:7
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
a.O @ chunk loaded:25
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:263
i @ jsonp chunk loading:73
(anonymous) @ app-main.9ddadafd1c100baf59b6.js:7
Show 67 more frames
Show lessUnderstand this warning
metadata.js:15 DEPRECATED: metabase/redux/metadata addFields
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.31-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.2 (Debian 15.2-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v1.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking your usage of Metabase entirely

### Additional context

This reproduction was done via Docker on MacOS 14.5. 

We have seen this issue in 1.50.3, on a production Postgres DB, when adding a filter to a new test dashboard, as well as an existing dashboard.

Possibly related, in 1.50.3, the ""From connected fields"" option for a filter has vanished, even though it has been connected to card fields.",kfriend,2024-06-18 12:43:21+00:00,[],2024-09-01 01:26:32+00:00,2024-09-01 01:26:31+00:00,https://github.com/metabase/metabase/issues/44354,"[('Querying/MBQL', ''), ('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2176169931, 'issue_id': 2359775679, 'author': 'kamilmielnik', 'body': 'Thanks for the report @kfriend!\r\n\r\nI can reproduce the behavior.\r\n\r\n> Note: if you select ""User > Source"" as the connected field, the filter works as expected.\r\n\r\nThe behavior depends on the [""Filtering on this field"" setting in Admin > Table Metadata](https://www.metabase.com/docs/latest/data-modeling/metadata-editing#changing-the-filter-widget).\r\nBy default User > Source is set as ""A list of all values""\r\nUser > Email however is by default set as ""Search box"".\r\n\r\nWould changing this setting work for you?\r\n\r\n----\r\n\r\n> As of the 0.50.x branch (don\'t know if it\'s 0.50.0 or a later version), **some** new dashboard filters no longer query for their enumerated values.\r\n\r\nBTW I tried both 0.48.7 and 0.49.11 and it behaves in the same way.', 'created_at': datetime.datetime(2024, 6, 18, 13, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260247636, 'issue_id': 2359775679, 'author': 'FilipSwiatczak', 'body': '@kamilmielnik I was actually about to raise this as a separate feature/request. What @kfriend observed was what looks like a recent change where the DEFAULT ""Filtering on this field"" option for a Category type column \r\nCHANGED from : \r\n- A list of all values\r\nTO:\r\n- Search box\r\n\r\nFor this issue @kfriend I understand it means the request will fire in filter only when a value is entered - to then return matches. \r\n\r\n_For us,_ we have recently moved our cloud warehouse snowflake account (source DB for Metabase data) and all new Schemas, though perfect clones - have the Category columns with Search box as default. \r\n\r\n**My plea**: I get product development and all, but PLEASE add **a global option to set Default ""Filtering on this field"" per column** type. We have hundreds if not thousands of those columns.', 'created_at': datetime.datetime(2024, 7, 31, 11, 0, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283611594, 'issue_id': 2359775679, 'author': 'FilipSwiatczak', 'body': '> @kamilmielnik I was actually about to raise this as a separate feature/request. What @kfriend observed was what looks like a recent change where the DEFAULT ""Filtering on this field"" option for a Category type column CHANGED from :\r\n> \r\n> * A list of all values\r\n>   TO:\r\n> * Search box\r\n> \r\n> For this issue @kfriend I understand it means the request will fire in filter only when a value is entered - to then return matches.\r\n> \r\n> _For us,_ we have recently moved our cloud warehouse snowflake account (source DB for Metabase data) and all new Schemas, though perfect clones - have the Category columns with Search box as default.\r\n> \r\n> **My plea**: I get product development and all, but PLEASE add **a global option to set Default ""Filtering on this field"" per column** type. We have hundreds if not thousands of those columns.\r\n\r\nQuick update, this behaviour reverted (fixed itself) when our instance upgraded to version 0.50.17 (it may have leaped 1 or 2 minor versions). All Category columns are back to displaying ""A list of all values"".\r\nHappy days!', 'created_at': datetime.datetime(2024, 8, 12, 10, 31, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-06-18 13:55:43 UTC): Thanks for the report @kfriend!

I can reproduce the behavior.


The behavior depends on the [""Filtering on this field"" setting in Admin > Table Metadata](https://www.metabase.com/docs/latest/data-modeling/metadata-editing#changing-the-filter-widget).
By default User > Source is set as ""A list of all values""
User > Email however is by default set as ""Search box"".

Would changing this setting work for you?

----


BTW I tried both 0.48.7 and 0.49.11 and it behaves in the same way.

FilipSwiatczak on (2024-07-31 11:00:01 UTC): @kamilmielnik I was actually about to raise this as a separate feature/request. What @kfriend observed was what looks like a recent change where the DEFAULT ""Filtering on this field"" option for a Category type column 
CHANGED from : 
- A list of all values
TO:
- Search box

For this issue @kfriend I understand it means the request will fire in filter only when a value is entered - to then return matches. 

_For us,_ we have recently moved our cloud warehouse snowflake account (source DB for Metabase data) and all new Schemas, though perfect clones - have the Category columns with Search box as default. 

**My plea**: I get product development and all, but PLEASE add **a global option to set Default ""Filtering on this field"" per column** type. We have hundreds if not thousands of those columns.

FilipSwiatczak on (2024-08-12 10:31:00 UTC): Quick update, this behaviour reverted (fixed itself) when our instance upgraded to version 0.50.17 (it may have leaped 1 or 2 minor versions). All Category columns are back to displaying ""A list of all values"".
Happy days!

"
2359726607,issue,open,,[Custom-map] Impossible to modify or add new geojson map if one existing map is not reacheable,"### Describe the bug

After a migration of metabase from a windows host to an ubuntu/docker host,
Several custom maps stop working.  With some digging, we did found that the issue is coming from docker that don't use our private dns to resolve the hostname used in the url of the geojson.
Our server is disconnected of internet, so we use a private local server to host the geojson of the map. 

Anyway, because we are not sure how to fixe this issues, we decide to use the ip address of the geojson server.

We can change one map url, but we cannot save the change. Same with adding a new map.
In the log of metabase, we see that when we try to save the new url, some validation is done on all the other custom map. 
![image](https://github.com/metabase/metabase/assets/156833955/511e0970-5cda-402b-98d4-9ad70e1c612d)


We have several of them that use our geojson server.  
What we understand so far is that we can't save because the other url are not resolved.
 
By looking in the database, we see that all map url are save in the same field custom-geojson of the settings table.
![image](https://github.com/metabase/metabase/assets/156833955/5f436f53-f506-4600-a355-d2380f57517c)

Witch seem to confirm our analyse, before commit the change, metabase check all the map url. 

The only way to fixe the issue, for now, would be to modify directly in the database the url of each geojson.

This only happen when at least 2 map urls are not working.

### To Reproduce

1. Go to admin/settings/maps
2. Add at least 2 working urls for a geojson map.
3. After validate that both are working
4. Some how, make at least one of the url impossible to resolve. For example by overloading one of the hostname in the host file to a wrong ip.
5. Try to add a new map from a working url, and save. Nothing should happen from the UI when clicking save.
6. In the log file, an entry about an exception for the wrong url should be show.


### Expected behavior

Each map url should be modifiable individually. 

### Logs

[25042258-e8a8-447b-8a27-814eeaa0d7ff] 2024-06-18T14:06:41+02:00 DEBUG metabase.server.middleware.log PUT /api/setting/custom-geojson 400 5.0 s (0 appels de DB) {:metabase-user-id 1} 
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message
   ""Emplacement du fichier GeoJSON non valide : doit commencer par http:// ou https:// ou Ãªtre un chemin d'accÃ¨s relatif Ã  un fichier sur le classpath. Les URL faisant rÃ©fÃ©rence Ã  des hÃ´tes qui fournissent des mÃ©tadonnÃ©es d'hÃ©bergement interne sont interdites."",
   :data {:status-code 400, :url ""http://srv-dd-carto/geojson/fr-regions.geojson""},
   :at [metabase.api.geojson$valid_url_QMARK_ invokeStatic ""geojson.clj"" 92]}
  {:type java.net.UnknownHostException,
   :message ""srv-dd-carto"",
   :at [java.net.InetAddress$CachedAddresses get nil -1]}],
 :trace
 [[java.net.InetAddress$CachedAddresses get nil -1]
  [java.net.InetAddress getAllByName0 nil -1]
  [java.net.InetAddress getAllByName nil -1]
  [java.net.InetAddress getAllByName nil -1]
  [java.net.InetAddress getByName nil -1]
  [metabase.api.geojson$valid_host_QMARK_ invokeStatic ""geojson.clj"" 79]
  [metabase.api.geojson$valid_host_QMARK_ invoke ""geojson.clj"" 72]
  [metabase.api.geojson$valid_url_QMARK_ invokeStatic ""geojson.clj"" 90]
  [metabase.api.geojson$valid_url_QMARK_ invoke ""geojson.clj"" 85]
  [metabase.api.geojson$valid_geojson_url_QMARK_ invokeStatic ""geojson.clj"" 97]
  [metabase.api.geojson$valid_geojson_url_QMARK_ invoke ""geojson.clj"" 94]
  [metabase.api.geojson$valid_geojson_urls_QMARK_$fn__85934 invoke ""geojson.clj"" 101]
  [clojure.core$every_QMARK_ invokeStatic ""core.clj"" 2698]
  [clojure.core$every_QMARK_ invoke ""core.clj"" 2689]
  [metabase.api.geojson$valid_geojson_urls_QMARK_ invokeStatic ""geojson.clj"" 101]
  [metabase.api.geojson$valid_geojson_urls_QMARK_ invoke ""geojson.clj"" 99]
  [metabase.api.geojson$validate_geojson invokeStatic ""geojson.clj"" 109]
  [metabase.api.geojson$validate_geojson invoke ""geojson.clj"" 104]
  [metabase.api.geojson$fn__85944$fn__85947 invoke ""geojson.clj"" 120]
  [metabase.models.setting$set_with_audit_logging_BANG_ invokeStatic ""setting.clj"" 922]
  [metabase.models.setting$set_with_audit_logging_BANG_ invoke ""setting.clj"" 910]
  [metabase.models.setting$set_BANG_ invokeStatic ""setting.clj"" 950]
  [metabase.models.setting$set_BANG_ doInvoke ""setting.clj"" 926]
  [clojure.lang.RestFn invoke ""RestFn.java"" 425]
  [metabase.api.setting$fn__99941$fn__99944 invoke ""setting.clj"" 59]
  [metabase.api.setting$do_with_setting_access_control invokeStatic ""setting.clj"" 14]
  [metabase.api.setting$do_with_setting_access_control invoke ""setting.clj"" 10]
  [metabase.api.setting$fn__99941 invokeStatic ""setting.clj"" 58]
  [metabase.api.setting$fn__99941 invoke ""setting.clj"" 53]
  [compojure.core$wrap_response$fn__52891 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__52875 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__52880 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__97195 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52931 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [metabase.api.routes$fn__103634$fn__103637 invoke ""routes.clj"" 73]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__103914$fn__103915 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52931 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52935 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52884 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903$f__52904$respond_SINGLEQUOTE___52905 invoke ""core.clj"" 197]
  [metabase.server.routes$fn__103897$fn__103899 invoke ""routes.clj"" 47]
  [compojure.core$routes$fn__52903$f__52904 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52903 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100064 invoke ""exceptions.clj"" 107]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__100061 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__104194$fn__104195$fn__104196 invoke ""log.clj"" 236]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__104194$fn__104195 invoke ""log.clj"" 227]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__104194 invoke ""log.clj"" 226]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__107482 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__100020 invoke ""security.clj"" 238]
  [ring.middleware.json$wrap_json_body$fn__107741 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__86504 invoke ""offset_paging.clj"" 43]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54346 invoke ""json.clj"" 83]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__107830 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__107849 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__69791 invoke ""misc.clj"" 60]
  [metabase.server.middleware.session$reset_session_timeout$fn__76935 invoke ""session.clj"" 552]
  [metabase.server.middleware.session$bind_current_user$fn__76901$fn__76902 invoke ""session.clj"" 446]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 425]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 408]
  [metabase.server.middleware.session$bind_current_user$fn__76901 invoke ""session.clj"" 445]
  [metabase.server.middleware.session$wrap_current_user_info$fn__76882 invoke ""session.clj"" 383]
  [metabase.server.middleware.session$wrap_session_id$fn__76854 invoke ""session.clj"" 259]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__97203 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__107669 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__69773 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__69799 invoke ""misc.clj"" 77]
  [ring.middleware.gzip$wrap_gzip$fn__107711 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__69802 invoke ""misc.clj"" 94]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__107498 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__70137 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause ""srv-dd-carto"",
 :message
 ""Emplacement du fichier GeoJSON non valide : doit commencer par http:// ou https:// ou Ãªtre un chemin d'accÃ¨s relatif Ã  un fichier sur le classpath. Les URL faisant rÃ©fÃ©rence Ã  des hÃ´tes qui fournissent des mÃ©tadonnÃ©es d'hÃ©bergement interne sont interdites."",
 :url ""http://srv-dd-carto/geojson/fr-regions.geojson""}


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-112-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""oracle"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",Iska13FR,2024-06-18 12:18:42+00:00,[],2025-02-04 20:24:42+00:00,,https://github.com/metabase/metabase/issues/44353,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2359600451,issue,closed,completed,Database role is (still) not respected when private key is used in Snowflake,"### Describe the bug

I read the following issues and related PRs:
[Issues connecting to Snowflake using RSA Keypair Authentication](https://github.com/metabase/metabase/issues/41852)
[Database role is not respected when private key is used in Snowflake](https://github.com/metabase/metabase/issues/43600)
[Add connection string parsing to Snowflake](https://github.com/metabase/metabase/pull/43923)

I upgraded to:

```
""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
```

but I'm still facing the same issue: the database role is not respected when a private key is used, and the only way to make it work is to add it as a URL parameter explicitly.

Note: I couldn't reproduce the issue using the default user's role, but if I use (and I need it :) ) another role, it doesn't work.

### To Reproduce

1. Go to Database admin and create or modify an existing one
2. Upload the private key
3. In the field ""_Role (optional, required for connection impersonation)_"", set a different role than the user's default role
4. Save changes
5. If you check Snowflake's query history, you will see that the role used is the user's default role and not the one indicated in the Role field.


### Expected behavior

Metabase should use the database role value to connect to Snowflake. I shouldn't need to add it as a JDBC connection string option.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.58+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.30-google""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Workaround available

### Additional context

_No response_",fabiomx,2024-06-18 11:13:26+00:00,['lbrdnk'],2024-08-28 02:09:56+00:00,2024-06-24 10:12:38+00:00,https://github.com/metabase/metabase/issues/44351,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2186289052, 'issue_id': 2359600451, 'author': 'github-actions[bot]', 'body': 'ðŸš€ This should also be released by [v0.50.7](https://github.com/metabase/metabase/milestone/243)', 'created_at': datetime.datetime(2024, 6, 24, 10, 59, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-06-24 10:59:00 UTC): ðŸš€ This should also be released by [v0.50.7](https://github.com/metabase/metabase/milestone/243)

"
2359471005,issue,closed,completed,Trendline moves on refresh on aggregated timeseries data,"### Describe the bug

I have a small dataset containing timeseries data. When i create a bar chart for the sums of the numerical data, aggregated by week, and enable the trend line. The trendline will sometimes move on refresh, as show on the attached screenshots. When i aggregate by day, there doesn't seem to be a problem.


### To Reproduce

Create a question for a date, number dataset. 
X-axis = date, Y-axis = sum of number
Enable trend-line under the ""display"" options.

Look at your bar chart with trend line, and refresh a couple of times.

### Expected behavior

I expect the trendline to not move

### Logs

_No response_

### Information about your Metabase installation

```JSON
Firefox 128.0b4 (64-bit)
Metabase 0.50.5, experienced the same problem with 0.48.6
Postgresql 15
Container in K8s on gcloud.
```


### Severity

Harms trust

### Additional context


![image](https://github.com/metabase/metabase/assets/86304937/c242e9e4-0ecf-493c-8a7b-19d0ba20616d)
![image](https://github.com/metabase/metabase/assets/86304937/990502d4-0858-4227-a350-fd382899abad)

The dataset contains 2 colums, one date and one number.

Am i misunderstanding something or is this a issue?",monneyboi,2024-06-18 10:06:40+00:00,['adam-james-v'],2024-08-15 20:57:26+00:00,2024-08-12 17:00:36+00:00,https://github.com/metabase/metabase/issues/44349,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2175914487, 'issue_id': 2359471005, 'author': 'Tony-metabase', 'body': 'Is the data changing as well? Like is the bar here changing values?\r\n\r\n<img width=""913"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/5d1df81f-69ca-47eb-b481-8acc5deccd17"">', 'created_at': datetime.datetime(2024, 6, 18, 11, 51, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2176925736, 'issue_id': 2359471005, 'author': 'JesseSDevaney', 'body': 'Hi @monneyboi! \r\n\r\nI tried to reproduce this locally, but could not get the trend-line to move as it does in your chart. There may be an edge case for your dataset specifically (different date formatting, values, etc.).\r\n\r\nIn order for me to be able to resolve this issue, it would really help if you were able to share the data. \r\n- _As long as there is nothing sensitive in the data that you are not comfortable with sharing_\r\n\r\n**Specifically:** Would you be able to share the `/api/dataset` response for your trend charts in at least two of the different trend line scenarios?\r\n- One where it is in one location and another where it is in a different location\r\n\r\n---\r\n**Demonstration for how to retrieve the data**\r\n\r\nhttps://github.com/metabase/metabase/assets/22608765/5a50a2b2-c0c3-46ce-9fff-c333f9d7932e', 'created_at': datetime.datetime(2024, 6, 18, 20, 35, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180497157, 'issue_id': 2359471005, 'author': 'monneyboi', 'body': 'Thanks for looking into this!\r\n\r\nHere\'s the `/api/dataset` responses.\r\n[response_up.json](https://github.com/user-attachments/files/15913202/response_up.json)\r\n[response_down.json](https://github.com/user-attachments/files/15913204/response_down.json)\r\n\r\nThe only meaningful difference is in the `insights`, the data is exactly the same.\r\n```\r\n424,425c424,425\r\n<           ""*"",\r\n<           309193.57441625773,\r\n---\r\n>           ""+"",\r\n>           -62547.458657534145,\r\n427,432c427,429\r\n<             ""exp"",\r\n<             [\r\n<               ""*"",\r\n<               -0.00009509785331076283,\r\n<               ""x""\r\n<             ]\r\n---\r\n>             ""*"",\r\n>             5.7833110464025825,\r\n>             ""x""\r\n```', 'created_at': datetime.datetime(2024, 6, 20, 11, 59, 25, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-06-18 11:51:29 UTC): Is the data changing as well? Like is the bar here changing values?

<img width=""913"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/5d1df81f-69ca-47eb-b481-8acc5deccd17"">

JesseSDevaney on (2024-06-18 20:35:15 UTC): Hi @monneyboi! 

I tried to reproduce this locally, but could not get the trend-line to move as it does in your chart. There may be an edge case for your dataset specifically (different date formatting, values, etc.).

In order for me to be able to resolve this issue, it would really help if you were able to share the data. 
- _As long as there is nothing sensitive in the data that you are not comfortable with sharing_

**Specifically:** Would you be able to share the `/api/dataset` response for your trend charts in at least two of the different trend line scenarios?
- One where it is in one location and another where it is in a different location

---
**Demonstration for how to retrieve the data**

https://github.com/metabase/metabase/assets/22608765/5a50a2b2-c0c3-46ce-9fff-c333f9d7932e

monneyboi (Issue Creator) on (2024-06-20 11:59:25 UTC): Thanks for looking into this!

Here's the `/api/dataset` responses.
[response_up.json](https://github.com/user-attachments/files/15913202/response_up.json)
[response_down.json](https://github.com/user-attachments/files/15913204/response_down.json)

The only meaningful difference is in the `insights`, the data is exactly the same.
```
424,425c424,425
<           ""*"",
<           309193.57441625773,
---
427,432c427,429
<             ""exp"",
<             [
<               ""*"",
<               -0.00009509785331076283,
<               ""x""
<             ]
---
```

"
2359256883,issue,closed,completed,Unify the copy for the previous dates in date filters,"We're currently using both the terms `Past` and `Previous` for the date filters (in different parts of the application).
The design and product teams decided to go with the `Previous` everywhere.

Relative date picker
![image](https://github.com/metabase/metabase/assets/31325167/0e09578a-5240-4ea8-b3fc-15cb38e04547)

Timeseries chrome
![image](https://github.com/metabase/metabase/assets/31325167/6ac9efb3-8400-414a-8737-0d2e4d2c00a4)

Dashboard filters
![image](https://github.com/metabase/metabase/assets/31325167/5ac26c08-ee6b-427b-ad8d-08c97ac97ed1)

[Slack context](https://metaboat.slack.com/archives/C02H619CJ8K/p1718358798489699)",nemanjaglumac,2024-06-18 08:22:17+00:00,['nemanjaglumac'],2024-06-18 13:55:56+00:00,2024-06-18 13:55:55+00:00,https://github.com/metabase/metabase/issues/44340,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2359067355,issue,closed,not_planned,[Flaky Test]: should trigger onChangeClause if expression is valid,"Last Flake: https://github.com/metabase/metabase/actions/runs/9452853739
Last Flake Time: 2024-06-10T11:34:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 0
Flakes in the last 7d: 1",iethree,2024-06-18 06:45:43+00:00,[],2024-12-13 16:44:00+00:00,2024-12-13 16:44:00+00:00,https://github.com/metabase/metabase/issues/44336,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2359067339,issue,closed,not_planned,[Flaky Test]: haveDashboardCardsChanged should perform reasonably well for 1000 cards,"Last Flake: https://github.com/metabase/metabase/actions/runs/9497643434
Last Flake Time: 2024-06-13T03:18:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 0
Flakes in the last 7d: 1",iethree,2024-06-18 06:45:41+00:00,[],2024-12-13 16:45:39+00:00,2024-12-13 16:45:39+00:00,https://github.com/metabase/metabase/issues/44335,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2178799460, 'issue_id': 2359067339, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9566404708\nLast Flake Time: 2024-06-18T07:23:00-07:00\nFlakes in the last day: 1\nFlakes in the last 3d: 1\nFlakes in the last 7d: 2', 'created_at': datetime.datetime(2024, 6, 19, 14, 2, 30, tzinfo=datetime.timezone.utc)}]","github-automation-metabase on (2024-06-19 14:02:30 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9566404708
Last Flake Time: 2024-06-18T07:23:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 2

"
2359067313,issue,closed,not_planned,[Flaky Test]: should be able to successfully go through migration flow,"Last Flake: https://github.com/metabase/metabase/actions/runs/9508742095
Last Flake Time: 2024-06-13T18:03:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 0
Flakes in the last 7d: 1",iethree,2024-06-18 06:45:41+00:00,[],2024-12-13 16:45:39+00:00,2024-12-13 16:45:39+00:00,https://github.com/metabase/metabase/issues/44334,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2359067281,issue,closed,completed,[Flaky Test]: two-cards-in-one-pulse-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9528897878
Last Flake Time: 2024-06-15T08:35:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",iethree,2024-06-18 06:45:39+00:00,['qnkhuat'],2024-06-21 03:28:46+00:00,2024-06-21 03:28:45+00:00,https://github.com/metabase/metabase/issues/44333,"[('.CI & Tests', ''), ('flaky-test-fix', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2175948856, 'issue_id': 2359067281, 'author': 'darksciencebase', 'body': ""we suspect it's gonna get closed by https://github.com/metabase/metabase/pull/43924 but will verify first"", 'created_at': datetime.datetime(2024, 6, 18, 12, 10, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181934017, 'issue_id': 2359067281, 'author': 'qnkhuat', 'body': 'Fixed by reworking how test setup works in https://github.com/metabase/metabase/pull/43924', 'created_at': datetime.datetime(2024, 6, 21, 3, 28, 46, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-06-18 12:10:42 UTC): we suspect it's gonna get closed by https://github.com/metabase/metabase/pull/43924 but will verify first

qnkhuat (Assginee) on (2024-06-21 03:28:46 UTC): Fixed by reworking how test setup works in https://github.com/metabase/metabase/pull/43924

"
2358435207,issue,closed,completed,Start of 51 Cycle Routine Clojure Dependency Bump,"[Notion doc about dependency bumping](https://www.notion.so/metabase/Dependency-Bumping-8ab452bbfc1f4131addd1653235c1b0f?pvs=4)

Subtasks:

- [x] Update all minor and patch versions and test. Revert breakage.
- [x] Update minor versions in modules ",adam-james-v,2024-06-17 23:00:34+00:00,['adam-james-v'],2025-01-27 22:14:25+00:00,2024-11-27 17:13:05+00:00,https://github.com/metabase/metabase/issues/44330,"[('backend-deps', '')]",[],
2358154467,issue,closed,completed,[Testing Plan] Elevate â€œinclude this periodâ€ in time filters,"# Testing plan for #44096 

## Relative Date Picker
This should already be covered with the existing unit and E2E tests.
The only thing left to do is to update the tests to reflect the new position of the UI elements in the picker. The functionality stays the same.

## Timeseries Chrome

### Dimensions
- Date type
    - Relative (it should only work for this, when it is not ""current"")
    - Exclude
    - Specific
- Interval
    - Previous (Past)
    - Next
- Time granularity
    - minutes
    - hours
    - days
    - weeks
    - months
    - quarters
    - years

### Actions
- Clicking on the toggle and making sure it toggles on/off
- Changing time granularity and making sure that the string ""include this ..."" matches
- Selecting ""include current"", then changing the interval
    - Make sure ""include"" toggle state is preserved
- Applying the filter in the relative date picker, and then making sure the timeseries chrome reflects that faithfully
- Switching away from the relative date type to specific, or exclude and then coming back to the relative
    - Make sure ""include"" toggle always reset to unset
",nemanjaglumac,2024-06-17 20:02:14+00:00,['nemanjaglumac'],2024-10-08 17:06:53+00:00,2024-06-19 20:14:48+00:00,https://github.com/metabase/metabase/issues/44323,"[('.CI & Tests', '')]",[],
2357764592,issue,closed,completed,"If you don't have access to the root collection but inner collections, you get permission errors in QuestionPicker","### Describe the bug

If you have mixed collection access you won't be able to select a collection if you don't have access to all parent collections.

### To Reproduce

1. Create several subcollections in Our analytics, like A -> B -> C
2. Go to Admin -> Permissions and revoke access from Our analytics collection; grant access to B
3. Log in as a regular user
4. Try selecting any descendant collection of Our analytics in the product now and see permission errors (QuestionPicker)

Note - the collection sidebar on the left handles this case correctly.

<img width=""889"" alt=""Screenshot 2024-06-17 at 12 30 26"" src=""https://github.com/metabase/metabase/assets/8542534/4272023b-80d1-40c5-a262-a97898a21e6c"">
<img width=""749"" alt=""Screenshot 2024-06-17 at 12 30 22"" src=""https://github.com/metabase/metabase/assets/8542534/1f503ffc-954f-4c12-a1d2-cb2696c971bc"">
<img width=""1416"" alt=""Screenshot 2024-06-17 at 13 58 55"" src=""https://github.com/metabase/metabase/assets/8542534/da7bbf63-38fe-42b4-b404-a923a53ed8ee"">
<img width=""704"" alt=""Screenshot 2024-06-17 at 12 32 32"" src=""https://github.com/metabase/metabase/assets/8542534/5de622df-7f68-4d4f-9255-c3f4896b9845"">



### Expected behavior

I should be able to select collections that I have access to without permission errors.

### Logs

No relevant logs

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

_No response_",ranquild,2024-06-17 16:35:08+00:00,['npfitz'],2024-06-18 13:59:16+00:00,2024-06-18 13:59:15+00:00,https://github.com/metabase/metabase/issues/44316,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Organization/Collections', ''), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2357622262,issue,closed,not_planned,Make the bulk find-and-replace query tool an EE-only feature,,tsmacdonald,2024-06-17 15:23:32+00:00,[],2024-08-06 14:17:19+00:00,2024-08-06 14:17:19+00:00,https://github.com/metabase/metabase/issues/44311,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2271411255, 'issue_id': 2357622262, 'author': 'tsmacdonald', 'body': ""F&R in general is on pause; this issue isn't part of things any more."", 'created_at': datetime.datetime(2024, 8, 6, 14, 17, 19, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-08-06 14:17:19 UTC): F&R in general is on pause; this issue isn't part of things any more.

"
2357622190,issue,closed,not_planned,Make lineage (Query Validator Tool) an EE-only feature,,tsmacdonald,2024-06-17 15:23:29+00:00,[],2024-06-19 12:17:13+00:00,2024-06-17 15:24:01+00:00,https://github.com/metabase/metabase/issues/44310,[],"[{'comment_id': 2173706274, 'issue_id': 2357622190, 'author': 'tsmacdonald', 'body': 'Dupe of #44118.', 'created_at': datetime.datetime(2024, 6, 17, 15, 24, 1, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-06-17 15:24:01 UTC): Dupe of #44118.

"
2357586321,issue,open,,[BE] Use auth-provider everywhere necessary.,,snoe,2024-06-17 15:07:57+00:00,['snoe'],2024-08-16 13:24:24+00:00,,https://github.com/metabase/metabase/issues/44308,"[('.Backend', ''), ('.Team/Querying', '')]",[],
2357579546,issue,open,,[BE] Allow fetching provider fields in db details,,snoe,2024-06-17 15:04:49+00:00,['snoe'],2024-08-16 13:24:23+00:00,,https://github.com/metabase/metabase/issues/44306,"[('.Backend', ''), ('.Team/Querying', '')]",[],
2357579114,issue,open,,[BE] Allow saving provider fields in db details,,snoe,2024-06-17 15:04:37+00:00,['snoe'],2024-08-16 13:24:22+00:00,,https://github.com/metabase/metabase/issues/44305,"[('.Backend', ''), ('.Team/Querying', '')]",[],
2357500127,issue,closed,completed,FE - Upgrade RTK to v2,"https://github.com/reduxjs/redux-toolkit/releases/tag/v2.0.0

> We've had a number of reports where RTK Query had issues around usage of dispatch(endpoint.initiate(arg, {subscription: false})). There were also reports that multiple triggered lazy queries were resolving the promises at the wrong time. Both of these had the same underlying issue, which was that RTKQ wasn't tracking cache entries in these cases (intentionally). We've reworked the logic to always track cache entries (and remove them as needed), which should resolve those behavior issues.

----

This should help with #44301
",kamilmielnik,2024-06-17 14:29:42+00:00,['kamilmielnik'],2024-06-19 11:05:51+00:00,2024-06-19 11:04:35+00:00,https://github.com/metabase/metabase/issues/44301,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2357487996,issue,closed,completed,Rework measure search performance events,"RE-implement Add Search Events, but with the a minor version change to the search analytics event",npfitz,2024-06-17 14:24:10+00:00,['npfitz'],2024-06-18 11:47:50+00:00,2024-06-17 21:33:01+00:00,https://github.com/metabase/metabase/issues/44300,[],[],
2357473014,issue,closed,completed,Query builder does not reflect what's displayed on screen (columns get hidden),"### Describe the bug

Seems like a state bug where we show stuff on the query builder that's not displayed in the table view

### To Reproduce

1) new question -> orders
![image](https://github.com/metabase/metabase/assets/1711649/269f3a53-76e2-4ca3-b0cb-7340427f71bf)

2) join with people and then visualize
![image](https://github.com/metabase/metabase/assets/1711649/1d561f63-a884-4485-863b-c1f9c6b7d41d)

3) click on summarize, count is selected when there's no count there
![image](https://github.com/metabase/metabase/assets/1711649/a594593d-f215-4eae-88ef-70b82c195f81)

4) remove the count, the order people table only is shown
![image](https://github.com/metabase/metabase/assets/1711649/38fbf4d5-cac4-40e1-86d9-f75238589b30)

5) go to the query builder, you still have the 2 tables shown
![image](https://github.com/metabase/metabase/assets/1711649/85339bce-a05f-45a8-8a5a-a7b595beed24)

6) click again on visualize, you still see the orders table
![image](https://github.com/metabase/metabase/assets/1711649/d7a97ce9-9372-4f8f-8eed-ebec7dddcb7a)

7) even the columns of people are not there
![image](https://github.com/metabase/metabase/assets/1711649/01d2b68e-3065-4b54-abf5-4d0dc5f68784)



### Expected behavior

We should reflect on the table view what's selected in the query builder

### Logs

NA

### Information about your Metabase installation

```JSON
v50 (but most probably coming from a while ago)
```


### Severity

P2 (edit to P2 as it seems that removing the count will hide the people table entirely)

### Additional context

EDIT: the columns of the people table get hidden
![image](https://github.com/metabase/metabase/assets/1711649/9516b946-638f-44b3-b03e-08843f4ac1ae)
",paoliniluis,2024-06-17 14:17:22+00:00,['ranquild'],2024-07-16 02:42:01+00:00,2024-07-15 13:15:51+00:00,https://github.com/metabase/metabase/issues/44298,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2173578345, 'issue_id': 2357473014, 'author': 'ranquild', 'body': 'Looks like an MBQL lib issue. Removing the aggregation clause from the query (with `Lib.removeClause`) for some reason removes all fields from the join.', 'created_at': datetime.datetime(2024, 6, 17, 14, 29, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173698485, 'issue_id': 2357473014, 'author': 'bshepherdson', 'body': ""That is a strange outcome. I'll take a look at this."", 'created_at': datetime.datetime(2024, 6, 17, 15, 20, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173889206, 'issue_id': 2357473014, 'author': 'bshepherdson', 'body': ""## Count aggregation\r\n\r\nThe `Count` aggregation being selected by default seems to be intentional? See [this](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/query_builder/components/view/sidebars/SummarizeSidebar/SummarizeSidebar.tsx#L32-L33) and where it gets [used](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/query_builder/components/view/sidebars/SummarizeSidebar/SummarizeSidebar.tsx#L165-L178).\r\n\r\n@ranquild assuming that logic is doing what we want, perhaps we should skip the `Lib.removeClause` altogether when removing the default aggregation? It's a waste of effort, and it actually re-runs the query needlessly.\r\n\r\n## Join fields\r\n\r\nThere is an MLv2 bug in removing the last aggregation/breakout:\r\n- A new join clause has `:fields :all`, to select all the fields.\r\n- When a stage has aggregations or breakouts, the `:fields` lists are dropped from the stage and each join, since they're ignored and the aggregations and breakouts are returned.\r\n- On removing the last aggregation/breakout, the main source and each join still have no `:fields` clauses. That's fine for the main source (which defaults to everything) but is broken for joins (which default to `:none`).\r\n\r\nI'll fix this issue; we want to select `:all` fields from the joins when deleting the last aggregation."", 'created_at': datetime.datetime(2024, 6, 17, 16, 52, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2174312132, 'issue_id': 2357473014, 'author': 'bshepherdson', 'body': 'With my PR #44321 the actual bug here is resolved.\r\n\r\nAssuming that the default `Count` aggregation on opening the Summarize sidebar is the intended UX, this bug will be fixed by that PR.', 'created_at': datetime.datetime(2024, 6, 17, 19, 56, 4, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-06-17 14:29:36 UTC): Looks like an MBQL lib issue. Removing the aggregation clause from the query (with `Lib.removeClause`) for some reason removes all fields from the join.

bshepherdson on (2024-06-17 15:20:49 UTC): That is a strange outcome. I'll take a look at this.

bshepherdson on (2024-06-17 16:52:09 UTC): ## Count aggregation

The `Count` aggregation being selected by default seems to be intentional? See [this](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/query_builder/components/view/sidebars/SummarizeSidebar/SummarizeSidebar.tsx#L32-L33) and where it gets [used](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/query_builder/components/view/sidebars/SummarizeSidebar/SummarizeSidebar.tsx#L165-L178).

@ranquild assuming that logic is doing what we want, perhaps we should skip the `Lib.removeClause` altogether when removing the default aggregation? It's a waste of effort, and it actually re-runs the query needlessly.

## Join fields

There is an MLv2 bug in removing the last aggregation/breakout:
- A new join clause has `:fields :all`, to select all the fields.
- When a stage has aggregations or breakouts, the `:fields` lists are dropped from the stage and each join, since they're ignored and the aggregations and breakouts are returned.
- On removing the last aggregation/breakout, the main source and each join still have no `:fields` clauses. That's fine for the main source (which defaults to everything) but is broken for joins (which default to `:none`).

I'll fix this issue; we want to select `:all` fields from the joins when deleting the last aggregation.

bshepherdson on (2024-06-17 19:56:04 UTC): With my PR #44321 the actual bug here is resolved.

Assuming that the default `Count` aggregation on opening the Summarize sidebar is the intended UX, this bug will be fixed by that PR.

"
2357299398,issue,closed,completed,Add RTK query endpoints for parameter values,,romeovs,2024-06-17 13:03:02+00:00,[],2024-10-08 17:07:07+00:00,2024-06-18 16:02:08+00:00,https://github.com/metabase/metabase/issues/44290,[],[],
2357296000,issue,closed,completed,Allow editing labels for filters,,romeovs,2024-06-17 13:01:31+00:00,[],2024-10-08 17:05:10+00:00,2024-07-05 12:05:27+00:00,https://github.com/metabase/metabase/issues/44289,[],[],
2357295438,issue,closed,completed,Disable parameter mapping with native models,"### Describe the bug

When a dashboard filter is connected to a SQL model, adding a filter doesn't actually filter data.

### To Reproduce

1. New -> Model -> SQL -> `SELECT * FROM PRODUCTS` - run and save
2. Add to a dashboard
3. Add a text filter and connect to the `CATEGORY` field
4. Set the filter value to `Widget` 
5. See that after the filter is applied the query results are the same and obviously not filtered
6. The same seems to happen with any other filter type or column


### Expected behavior

It should not be possible to add a parameter that doesn't work.

### Logs

No relevant FE or BE logs. It seems that the BE silently ignores some error.

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1/P2

### Additional context

_No response_",ranquild,2024-06-17 13:01:20+00:00,['ranquild'],2024-06-19 21:36:12+00:00,2024-06-19 21:35:18+00:00,https://github.com/metabase/metabase/issues/44288,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2173737837, 'issue_id': 2357295438, 'author': 'cdeweyx', 'body': 'The fix here is not to support filtering for SQL models on dashboards, but rather to make it clear that this limitation exists. We should add the following message to both GUI and SQL models when in parameter mapping mode on dashboards:\r\n\r\n> Models are data sources and thus canâ€™t have parameters mapped. [Learn more](https://www.metabase.com/learn/data-modeling/models#:~:text=If%20you%20add%20a%20model%20to%20a%20dashboard%2C%20you%E2%80%99ll%20notice%20that%20you%20can%E2%80%99t%20map%20any%20of%20its%20columns%20to%20a%20dashboard%20filter%2C%20even%20after%20you%E2%80%99ve%20set%20the%20types%20for%20those%20filters.%20To%20get%20those%20same%20results%20with%20models%2C%20you%20can%3A)\r\n\r\nExample design pattern for a different limiting case: \r\n\r\n<img width=""331"" alt=""Screenshot 2024-06-17 at 11 33 20"" src=""https://github.com/metabase/metabase/assets/16455495/440591b5-27a8-4090-a6e0-3e290ca9ce61"">\r\n\r\n[More Slack context](https://metaboat.slack.com/archives/C05NXACAG1G/p1718638141251419?thread_ts=1718629292.335359&cid=C05NXACAG1G).\r\n\r\nThe main thing still to figure out is how to handle existing GUI models that are already wired up to parameters.', 'created_at': datetime.datetime(2024, 6, 17, 15, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179484091, 'issue_id': 2357295438, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/44372', 'created_at': datetime.datetime(2024, 6, 19, 21, 35, 18, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-06-17 15:37:54 UTC): The fix here is not to support filtering for SQL models on dashboards, but rather to make it clear that this limitation exists. We should add the following message to both GUI and SQL models when in parameter mapping mode on dashboards:


Example design pattern for a different limiting case: 

<img width=""331"" alt=""Screenshot 2024-06-17 at 11 33 20"" src=""https://github.com/metabase/metabase/assets/16455495/440591b5-27a8-4090-a6e0-3e290ca9ce61"">

[More Slack context](https://metaboat.slack.com/archives/C05NXACAG1G/p1718638141251419?thread_ts=1718629292.335359&cid=C05NXACAG1G).

The main thing still to figure out is how to handle existing GUI models that are already wired up to parameters.

ranquild (Issue Creator) on (2024-06-19 21:35:18 UTC): Closed by https://github.com/metabase/metabase/pull/44372

"
2357207603,issue,closed,completed,"Support ""downloads"" URL parameter + test it along with ""hide_download_button""",,npretto,2024-06-17 12:19:20+00:00,['npretto'],2024-07-08 09:02:56+00:00,2024-07-08 09:02:56+00:00,https://github.com/metabase/metabase/issues/44285,"[('.Team/Embedding', '')]",[],
2357015821,issue,closed,completed,Goal lines displayed incorrectly when axis scale is not linear,"### Describe the bug

When adding a goal line to a question, the position in the graphic is squared.

This happened when migrating from 0.49 to 0.50

### To Reproduce

Create a question.
Set the y-axis to power scale.
Add a goal value, for example ""20"".

The goal shows at 20Â² = 400 rather than 20


### Expected behavior

The goal line is displayed correctly, as it was before. This is a regression.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:126.0) Gecko/20100101 Firefox/126.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.17""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-15"",
      ""tag"": ""v0.50.5"",
      ""hash"": ""48f6978""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",clanog,2024-06-17 10:43:04+00:00,['JesseSDevaney'],2024-06-18 20:40:16+00:00,2024-06-18 20:40:09+00:00,https://github.com/metabase/metabase/issues/44278,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2176546174, 'issue_id': 2357015821, 'author': 'JesseSDevaney', 'body': 'Re-opening until backport is merged:\r\n- https://github.com/metabase/metabase/pull/44325', 'created_at': datetime.datetime(2024, 6, 18, 16, 46, 44, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Assginee) on (2024-06-18 16:46:44 UTC): Re-opening until backport is merged:
- https://github.com/metabase/metabase/pull/44325

"
2356763380,issue,closed,not_planned,Cannot connect a number filter to a native card,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/051766a8-80ad-4e8d-bb55-44c6beb70f41



### To Reproduce

1. Create a new native question `select {{x}};` and save it
2. Add it to a dashboard when asked
3. Add number > equal to filter to the dashboard

> A number variable in this card can only be connected to a number filter with Equal to operator.

There's an error in JS console: 

```
TypeError: Cannot read properties of null (reading 'map')
    at getDatasetQueryParams (app-main.hot.bundle.js:431998:28)
    at app-main.hot.bundle.js:431761:84
    at type (app-main.hot.bundle.js:443135:35)
    at vendor.hot.bundle.js:335156:18
    at dispatch (vendor.hot.bundle.js:335885:28)
    at app-main.hot.bundle.js:431915:14
    at Array.map (<anonymous>)
    at app-main.hot.bundle.js:431910:49
    at vendor.hot.bundle.js:335156:18
    at dispatch (vendor.hot.bundle.js:335885:28)
```

### Expected behavior

User is able to connect this filter to the card


### Information about your Metabase installation

`master`, 93334133ea


### Severity

P1

### Additional info

Possibly related to #44266",kamilmielnik,2024-06-17 08:44:16+00:00,[],2024-06-17 09:00:20+00:00,2024-06-17 08:58:41+00:00,https://github.com/metabase/metabase/issues/44276,[],"[{'comment_id': 2172723010, 'issue_id': 2356763380, 'author': 'Tony-metabase', 'body': 'Hey @kamilmielnik I might be missing something but isn\'t the filter a TEXT? So i would expect a NUMBER filter to not work\r\n\r\n<img width=""735"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/af18a028-a356-4c91-b100-2c5d4a74a000"">', 'created_at': datetime.datetime(2024, 6, 17, 8, 51, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2172737388, 'issue_id': 2356763380, 'author': 'kamilmielnik', 'body': ""> Hey @kamilmielnik I might be missing something but isn't the filter a TEXT? So i would expect a NUMBER filter to not work\r\n\r\nAbsolutely, thanks!\r\nClosing."", 'created_at': datetime.datetime(2024, 6, 17, 8, 58, 41, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-06-17 08:51:28 UTC): Hey @kamilmielnik I might be missing something but isn't the filter a TEXT? So i would expect a NUMBER filter to not work

<img width=""735"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/af18a028-a356-4c91-b100-2c5d4a74a000"">

kamilmielnik (Issue Creator) on (2024-06-17 08:58:41 UTC): Absolutely, thanks!
Closing.

"
2356573132,issue,closed,not_planned,Cannot connect to MongoDB with differente authenticationDatabase,"### Describe the bug

Can't connect to MongoDB on version 0.49.7 setting different database than admin.

Command failed with error 13 (Unauthorized): 'not authorized on admin to execute command { listDatabases: 1, nameOnly: true, $db: ""admin""...

Seems weird because the error says that I'm trying to reach admin database but it is not true, I have other database as authSource. In this case db and authSource are the same db, but it is not admin db.

Thanks!

### To Reproduce

1. Add database
2. Add database name
3. Add authenticationDatabase name (different than admin)
4. See error Unauthorized pointing admin database

### Expected behavior

Authorize through authentication database

### Logs

Command failed with error 13 (Unauthorized): 'not authorized on admin to execute command { listDatabases: 1, nameOnly: true, $db: ""admin""...

### Information about your Metabase installation

```JSON
- MongoDB
- 0.49.7
```


### Severity

Blocking database usage

### Additional context

_No response_",ArnauKokoro,2024-06-17 07:15:43+00:00,[],2024-06-17 11:14:24+00:00,2024-06-17 10:24:58+00:00,https://github.com/metabase/metabase/issues/44274,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Backend', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2172739579, 'issue_id': 2356573132, 'author': 'Tony-metabase', 'body': '@Varunram  Can you share a screenshot of the DB settings?', 'created_at': datetime.datetime(2024, 6, 17, 8, 59, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2172991575, 'issue_id': 2356573132, 'author': 'paoliniluis', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/33879', 'created_at': datetime.datetime(2024, 6, 17, 10, 24, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173049732, 'issue_id': 2356573132, 'author': 'ArnauKokoro', 'body': ""Yes, I'll attach it\r\n\r\n![image](https://github.com/metabase/metabase/assets/80262126/be24396e-a4ae-4d4a-b4d3-06e090a35a54)"", 'created_at': datetime.datetime(2024, 6, 17, 10, 45, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173059192, 'issue_id': 2356573132, 'author': 'ArnauKokoro', 'body': '@Tony-metabase I just saw it is closed because duplicated. I can share it also on the other issue if you wish.', 'created_at': datetime.datetime(2024, 6, 17, 10, 46, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173108943, 'issue_id': 2356573132, 'author': 'Tony-metabase', 'body': ""No it's fine, it's jsut not supported right now. There is the same info on the other issue!"", 'created_at': datetime.datetime(2024, 6, 17, 11, 14, 23, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-06-17 08:59:50 UTC): @Varunram  Can you share a screenshot of the DB settings?

paoliniluis on (2024-06-17 10:24:58 UTC): Duplicate of https://github.com/metabase/metabase/issues/33879

ArnauKokoro (Issue Creator) on (2024-06-17 10:45:37 UTC): Yes, I'll attach it

![image](https://github.com/metabase/metabase/assets/80262126/be24396e-a4ae-4d4a-b4d3-06e090a35a54)

ArnauKokoro (Issue Creator) on (2024-06-17 10:46:41 UTC): @Tony-metabase I just saw it is closed because duplicated. I can share it also on the other issue if you wish.

Tony-metabase on (2024-06-17 11:14:23 UTC): No it's fine, it's jsut not supported right now. There is the same info on the other issue!

"
2356529573,issue,closed,completed,Move `Transparent` option from `Theme` to its own toggle option,,WiNloSt,2024-06-17 06:50:45+00:00,['WiNloSt'],2024-06-20 12:57:15+00:00,2024-06-20 12:57:15+00:00,https://github.com/metabase/metabase/issues/44273,[],[],
2355962635,issue,open,,Option for Compact Label and Rotated 45 degrees,"Currently we have option for compact label or rotate 45 degrees, but not both at the same time, i.e. compact label AND rotated 45 degrees. (same issue for compact and rotate 90 degrees).

![Screenshot 2024-06-16 131832](https://github.com/metabase/metabase/assets/15974735/745232ee-462c-4f22-bdad-d407189b2686)

v0.49.16

",vvaezian,2024-06-16 20:24:08+00:00,[],2025-02-05 14:54:39+00:00,,https://github.com/metabase/metabase/issues/44272,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2355856671,issue,closed,completed,Use a loading indicator-agnostic testid,,rafpaf,2024-06-16 16:12:41+00:00,[],2024-08-20 19:58:47+00:00,2024-06-20 00:32:17+00:00,https://github.com/metabase/metabase/issues/44271,[],[],
2355833875,issue,closed,not_planned,Maridb Rocksdb engine support,"When i connect to a Mariadb databse and sync the tables, tables that use Rocksdb engine are not being detected, seems like Metabase mysql connector is unable to read these tables.
",hemmat,2024-06-16 15:16:03+00:00,[],2024-06-17 10:27:06+00:00,2024-06-17 10:27:06+00:00,https://github.com/metabase/metabase/issues/44270,"[('Database/MySQL', None), ('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2172994558, 'issue_id': 2355833875, 'author': 'paoliniluis', 'body': 'I think this is a duplicate of https://github.com/metabase/metabase/issues/42734', 'created_at': datetime.datetime(2024, 6, 17, 10, 26, 38, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-17 10:26:38 UTC): I think this is a duplicate of https://github.com/metabase/metabase/issues/42734

"
2355735833,issue,closed,not_planned,Add e2e test that checks the equivalent thing for dashboards,,rafpaf,2024-06-16 12:35:24+00:00,[],2024-06-16 12:36:44+00:00,2024-06-16 12:36:44+00:00,https://github.com/metabase/metabase/issues/44269,[],[],
2355735806,issue,open,,Add e2e test that checks that invalidating the cache makes /api/query (and the equivalent endpoint for dashboards) respond with {cached: false}.,,rafpaf,2024-06-16 12:35:19+00:00,[],2024-06-16 12:37:44+00:00,,https://github.com/metabase/metabase/issues/44268,"[('.CI & Tests', '')]",[],
2355393892,issue,closed,not_planned,Avoid the main handler for statics on ring (use wrap-file),"**Is your feature request related to a problem? Please describe.**
Seems that ring has a way to avoid passing a file through the handler if it exists https://github.com/ring-clojure/ring/wiki/Static-Resources. If we can use wrap-file on the code, we will save a lot of CPU resources since the request will avoid all of our handlers (and most probably the transmission will also be way faster)

**Describe the solution you'd like**
Implement wrap-file function for sending our css and js files

**Describe alternatives you've considered**
None

**How important is this feature to you?**
I have a strong feeling that this is the reason why Metabase takes 30 seconds on my 100MB symmetric connection to send a 6MB file from the US

**Additional context**
I don't know if this has any collateral damage, it should not I guess since statics are always the same (we just send the ones for embedding in case we detect that the user is going through that flow, but that shouldn't cause any weird scenario)",paoliniluis,2024-06-16 03:00:19+00:00,[],2024-07-25 09:57:48+00:00,2024-07-25 09:57:48+00:00,https://github.com/metabase/metabase/issues/44267,"[('Type:New Feature', ''), ('.Backend', ''), ('.Needs Triage', '')]",[],
2355330425,issue,closed,completed,Unable to connect dashboard number filter to number variable of SQL query card,"### Describe the bug

I have a dashboard with multiple cards.
Some of them have a number variable called ""Days"".
My dashboard has a number filter called ""Days"" as well that is connected to all my query cards.
Today I tried adding a new SQL query card with a number variable, but I was unable to connect it to the card.
I also noticed that when I disconnect that number filter from a card I previously connected to the filter, I'm unable to re-connect it afterwards, so I don't think it's an issue of the SQL query, but rather something was changed regarding the connection process between the filter and the cards.

Video example:
https://github.com/metabase/metabase/assets/69360073/bd404400-5881-43cb-8a54-1e717c425788




### To Reproduce

1. Have a dashboard with an SQL query card that contains a number variable.
2. Edit the dashboard and add a number filter.
3. Connect the number filter to the number variable of the SQL query card.
4. See error in console.


### Expected behavior

The number filter should connect to the number variable of the SQL query card.

### Logs

```js
app-main.3617â€¦.js:35 Uncaught (in promise) 
n1.$h {message: 'Unknown type of ref', data: n1.h, cause: null, name: 'Error', description: undefined, â€¦}
cause: null
columnNumber: undefined
data: n1.h {M: null, N: 1, D: Array(2), J: null, C: 16647951, â€¦}
description: undefined
fileName: undefined
lineNumber: undefined
message: ""Unknown type of ref""
name: ""Error""
number: undefined
stack: ""Error: Unknown type of ref\n    at new n1.$h (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:92504)\n    at n1.ai (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:92814)\n    at n1.bi (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:92771)\n    at Function.n [as j] (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:886095)\n    at Function.e [as K] (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:885176)\n    at Function.t [as v] (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:885670)\n    at http://<reducted>/app/dist/app-main.3617<reducted>.js:262:967478\n    at eW (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:61674)\n    at n1.g.fa (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:138554)\n    at n1.y (http://<reducted>/app/dist/app-main.3617<reducted>.js:262:50551)""
[[Prototype]]: Error
da: Æ’ (e,t,n)
pa: {}
toString: Æ’ ()
constructor: Æ’ (e,t,n)
[[Prototype]]: Object
```

### Information about your Metabase installation

```JSON
You're on version v0.50.4
Built on 2024-06-13
```


### Severity

annoying

### Additional context

_No response_",amit-sides,2024-06-15 23:42:20+00:00,"['ranquild', 'uladzimirdev']",2024-06-22 03:57:00+00:00,2024-06-19 13:57:47+00:00,https://github.com/metabase/metabase/issues/44266,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2173528809, 'issue_id': 2355330425, 'author': 'ranquild', 'body': '@amit-sides I couldn\'t reproduce this issue with a new SQL query and a number variable. Could you reproduce the issue using the ""Sample Database""?', 'created_at': datetime.datetime(2024, 6, 17, 14, 9, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173591295, 'issue_id': 2355330425, 'author': 'uladzimirdev', 'body': ""@amit-sides could you please share more details about your configuration?\r\nwe'd like to know:\r\n- filter configuration\r\n- sql for a query (a screenshot from editor)\r\n- network responses from `/dashboard/*` and `/card/*`"", 'created_at': datetime.datetime(2024, 6, 17, 14, 35, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173653399, 'issue_id': 2355330425, 'author': 'paoliniluis', 'body': '@amit-sides this question comes from an old version of Metabase, is that correct? can you give us the question metadata? you need to hit /api/card/<id>', 'created_at': datetime.datetime(2024, 6, 17, 15, 1, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173699054, 'issue_id': 2355330425, 'author': 'ranquild', 'body': 'One thing is that `Column to filter on` is only shown for questions/models and not for SQL queries. So it looks like a GUI question and not a SQL query, i.e. not what is in the description.', 'created_at': datetime.datetime(2024, 6, 17, 15, 21, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173816451, 'issue_id': 2355330425, 'author': 'paoliniluis', 'body': ""ok so I wasn't able to repro with a question coming back from v38... so I guess that we really need to figure out how to hit this one"", 'created_at': datetime.datetime(2024, 6, 17, 16, 12, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2174606882, 'issue_id': 2355330425, 'author': 'amit-sides', 'body': 'Sorry for the delay people, thanks for the help! @ranquild @paoliniluis @uladzimirdev \r\nI managed to minimize my query to ensure this isn\'t caused by other factors in it, here is my query right now (I\'m using sqlite db, I think):\r\n```sql\r\nselect registration_datetime\r\nfrom BALANCE\r\nWHERE 1=1\r\n[[AND registration_datetime > date(\'now\', ""-"" || {{d}} || "" days"")]]\r\nlimit 10\r\n```\r\nHere is a video showing the same problem with this query:\r\nhttps://github.com/metabase/metabase/assets/69360073/b3601585-7601-41e1-883b-6ac5b5ebd302\r\n\r\n\r\nIt took me some time, but I managed to create a similar query with the sample data db, as @ranquild requested:\r\n```sql\r\nSELECT\r\n  ""PUBLIC"".""FEEDBACK"".""ID"" AS ""ID"",\r\n  ""PUBLIC"".""FEEDBACK"".""ACCOUNT_ID"" AS ""ACCOUNT_ID"",\r\n  ""PUBLIC"".""FEEDBACK"".""EMAIL"" AS ""EMAIL"",\r\n  ""PUBLIC"".""FEEDBACK"".""DATE_RECEIVED"" AS ""DATE_RECEIVED"",\r\n  ""PUBLIC"".""FEEDBACK"".""RATING"" AS ""RATING"",\r\n  ""PUBLIC"".""FEEDBACK"".""RATING_MAPPED"" AS ""RATING_MAPPED"",\r\n  ""PUBLIC"".""FEEDBACK"".""BODY"" AS ""BODY""\r\nFROM\r\n  ""PUBLIC"".""FEEDBACK""\r\nWhere 1=1\r\n[[AND ""DATE_RECEIVED"" > NOW() + INTERVAL \'-{{d}}\' day]]\r\norder by ""DATE_RECEIVED"" asc\r\nLIMIT\r\n  10\r\n```\r\nand again, video showing the same problem with this one:\r\nhttps://github.com/metabase/metabase/assets/69360073/d817accd-1846-4484-8daf-77ea559dcf8d', 'created_at': datetime.datetime(2024, 6, 17, 23, 20, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2174610319, 'issue_id': 2355330425, 'author': 'amit-sides', 'body': ""> @amit-sides this question comes from an old version of Metabase, is that correct? can you give us the question metadata? you need to hit /api/card/\r\n\r\nNot sure what you meant by it, but: If you mean that I created the question in an older version, then I'm not sure but I think it's irrelevant since I created today the `feedback test` question (second video in my comment above) and it still happens with it."", 'created_at': datetime.datetime(2024, 6, 17, 23, 23, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2174614536, 'issue_id': 2355330425, 'author': 'amit-sides', 'body': ""> One thing is that `Column to filter on` is only shown for questions/models and not for SQL queries. So it looks like a GUI question and not a SQL query, i.e. not what is in the description.\r\n\r\nYou are probably right, I don't fully understand the naming of things in metabase. I wanted to emphasize I use SQL query and not the UX builder for questions.\r\nEither way, hopefully my videos explain it better :)"", 'created_at': datetime.datetime(2024, 6, 17, 23, 27, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2174618180, 'issue_id': 2355330425, 'author': 'amit-sides', 'body': ""> @amit-sides could you please share more details about your configuration? we'd like to know:\r\n> \r\n> * filter configuration\r\n> * sql for a query (a screenshot from editor)\r\n> * network responses from `/dashboard/*` and `/card/*`\r\n\r\nI added videos and queries. I prefer not to share network responses right now because it might leak my IP and other things, but if all the info I provided isn't enough I will try to capture the responses and censor them as last option"", 'created_at': datetime.datetime(2024, 6, 17, 23, 30, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2175992991, 'issue_id': 2355330425, 'author': 'uladzimirdev', 'body': ""@amit-sides thanks, really helpful! it should be enough for a fix, we'll let you know if we need more data"", 'created_at': datetime.datetime(2024, 6, 18, 12, 34, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2179013942, 'issue_id': 2355330425, 'author': 'uladzimirdev', 'body': '@amit-sides the fix will be released in 0.50.7', 'created_at': datetime.datetime(2024, 6, 19, 15, 45, 52, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-06-17 14:09:47 UTC): @amit-sides I couldn't reproduce this issue with a new SQL query and a number variable. Could you reproduce the issue using the ""Sample Database""?

uladzimirdev (Assginee) on (2024-06-17 14:35:14 UTC): @amit-sides could you please share more details about your configuration?
we'd like to know:
- filter configuration
- sql for a query (a screenshot from editor)
- network responses from `/dashboard/*` and `/card/*`

paoliniluis on (2024-06-17 15:01:56 UTC): @amit-sides this question comes from an old version of Metabase, is that correct? can you give us the question metadata? you need to hit /api/card/<id>

ranquild (Assginee) on (2024-06-17 15:21:04 UTC): One thing is that `Column to filter on` is only shown for questions/models and not for SQL queries. So it looks like a GUI question and not a SQL query, i.e. not what is in the description.

paoliniluis on (2024-06-17 16:12:56 UTC): ok so I wasn't able to repro with a question coming back from v38... so I guess that we really need to figure out how to hit this one

amit-sides (Issue Creator) on (2024-06-17 23:20:05 UTC): Sorry for the delay people, thanks for the help! @ranquild @paoliniluis @uladzimirdev 
I managed to minimize my query to ensure this isn't caused by other factors in it, here is my query right now (I'm using sqlite db, I think):
```sql
select registration_datetime
from BALANCE
WHERE 1=1
[[AND registration_datetime > date('now', ""-"" || {{d}} || "" days"")]]
limit 10
```
Here is a video showing the same problem with this query:
https://github.com/metabase/metabase/assets/69360073/b3601585-7601-41e1-883b-6ac5b5ebd302


It took me some time, but I managed to create a similar query with the sample data db, as @ranquild requested:
```sql
SELECT
  ""PUBLIC"".""FEEDBACK"".""ID"" AS ""ID"",
  ""PUBLIC"".""FEEDBACK"".""ACCOUNT_ID"" AS ""ACCOUNT_ID"",
  ""PUBLIC"".""FEEDBACK"".""EMAIL"" AS ""EMAIL"",
  ""PUBLIC"".""FEEDBACK"".""DATE_RECEIVED"" AS ""DATE_RECEIVED"",
  ""PUBLIC"".""FEEDBACK"".""RATING"" AS ""RATING"",
  ""PUBLIC"".""FEEDBACK"".""RATING_MAPPED"" AS ""RATING_MAPPED"",
  ""PUBLIC"".""FEEDBACK"".""BODY"" AS ""BODY""
FROM
  ""PUBLIC"".""FEEDBACK""
Where 1=1
[[AND ""DATE_RECEIVED"" > NOW() + INTERVAL '-{{d}}' day]]
order by ""DATE_RECEIVED"" asc
LIMIT
  10
```
and again, video showing the same problem with this one:
https://github.com/metabase/metabase/assets/69360073/d817accd-1846-4484-8daf-77ea559dcf8d

amit-sides (Issue Creator) on (2024-06-17 23:23:11 UTC): Not sure what you meant by it, but: If you mean that I created the question in an older version, then I'm not sure but I think it's irrelevant since I created today the `feedback test` question (second video in my comment above) and it still happens with it.

amit-sides (Issue Creator) on (2024-06-17 23:27:12 UTC): You are probably right, I don't fully understand the naming of things in metabase. I wanted to emphasize I use SQL query and not the UX builder for questions.
Either way, hopefully my videos explain it better :)

amit-sides (Issue Creator) on (2024-06-17 23:30:29 UTC): I added videos and queries. I prefer not to share network responses right now because it might leak my IP and other things, but if all the info I provided isn't enough I will try to capture the responses and censor them as last option

uladzimirdev (Assginee) on (2024-06-18 12:34:15 UTC): @amit-sides thanks, really helpful! it should be enough for a fix, we'll let you know if we need more data

uladzimirdev (Assginee) on (2024-06-19 15:45:52 UTC): @amit-sides the fix will be released in 0.50.7

"
2354428192,issue,closed,completed,Add skeletons to sidebar,,rafpaf,2024-06-15 02:40:55+00:00,[],2024-10-08 17:06:50+00:00,2024-06-19 22:38:07+00:00,https://github.com/metabase/metabase/issues/44262,[],[],
2354222261,issue,closed,completed,Reverting on dashboard results in internal server error for certain changes,"### Describe the bug

When reverting change on dashboard, it is getting 500 internal server error. This seems to be the case for certain changes. If a change can't be reverted, it will result in the error. I would imagine all changes should be revertible? If there are irreversible changes, then a proper error should be shown to the user. 

### To Reproduce

1. Go to any dashboard. **Edit**: Seems to happen to certain changes on dashboards that aren't revertible (maybe card modifications?). E.g. Stats Homepage or Piespace Revenue
2. Open info sidebar and click on revert 
3. Nothing happens / check console log to see internal server error 


### Expected behavior

Revert to selected version no matter what

### Logs

POST .../api/revision/revert 500 (Internal Server Error)

### Information about your Metabase installation

```JSON
master on Postgres
```


### Severity

Can't revert automatically so gotta manually do it

### Additional context

_No response_",maxzheng,2024-06-14 23:14:59+00:00,['adam-james-v'],2024-07-19 16:54:40+00:00,2024-07-19 16:39:04+00:00,https://github.com/metabase/metabase/issues/44259,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Unable to Reproduce', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2239612903, 'issue_id': 2354222261, 'author': 'maxzheng', 'body': ""Can't seem to reproduce this anymore. Closing it."", 'created_at': datetime.datetime(2024, 7, 19, 16, 39, 4, tzinfo=datetime.timezone.utc)}]","maxzheng (Issue Creator) on (2024-07-19 16:39:04 UTC): Can't seem to reproduce this anymore. Closing it.

"
2354161117,issue,closed,completed,"In Admin/Performance/Database caching, 12:00PM cannot be used as a time in the Schedule component",,rafpaf,2024-06-14 21:52:24+00:00,[],2024-06-24 09:36:40+00:00,2024-06-19 22:53:05+00:00,https://github.com/metabase/metabase/issues/44257,[],[],
2354028797,issue,closed,completed,Find items to auto-archive with a modal,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/44923
- [x] Expose that backend API in a new endpoint
- [ ] https://github.com/metabase/metabase/issues/44477
- [x] Backend API emits events
- [x] add collection info into the stale API endpoint
- [x] JSON schema for snowflake events
```
",johnswanson,2024-06-14 20:16:02+00:00,['johnswanson'],2024-08-02 19:10:29+00:00,2024-08-02 19:10:29+00:00,https://github.com/metabase/metabase/issues/44253,[],[],
2354013087,issue,closed,completed,Auto-archive: prerequisite work,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/44251
- [ ] https://github.com/metabase/metabase/issues/44373
- [ ] https://github.com/metabase/metabase/issues/44817
```

Some motivation:
Official collections are always sorted first in the collection view. This means they are here always first since we're reusing that. And if you have 25 or more, they dominate the first page and it seems like the sorting doesn't work.

For ""last_edited_at"" for collections, probably the principal way you would sort this list is by recency. And since we don't have this information for collections, if you trash a collection you cannot find it by ""last edited at"" or ""trashed at"" (as we show last edit at in the trash). Backfilling this makes collections findable.
",johnswanson,2024-06-14 20:05:50+00:00,['johnswanson'],2024-07-22 16:03:23+00:00,2024-07-22 16:03:23+00:00,https://github.com/metabase/metabase/issues/44252,[],[],
2353998129,issue,closed,completed,Add a `last_viewed_at` timestamp to dashboards,,johnswanson,2024-06-14 19:55:47+00:00,['johnswanson'],2024-10-08 16:20:13+00:00,2024-07-19 13:55:25+00:00,https://github.com/metabase/metabase/issues/44251,[],[],
2353995848,issue,closed,completed,Remove FE code that checks `enable-query-caching`,"> This setting is deprecated. Unfortunately, it is set to false by default, there is no way to set it to true through the UI. On master, if it is false, certain features are switched off in the FE. ",rafpaf,2024-06-14 19:53:52+00:00,[],2024-06-19 08:11:36+00:00,2024-06-17 15:06:53+00:00,https://github.com/metabase/metabase/issues/44250,[],[],
2353995579,issue,closed,completed,"In Admin/Performance/Database caching, when a minimum query duration is saved for an adaptive policy, the new value does not appear in the form",https://www.loom.com/share/35fe0eeb6d5045049e5a93e6d634cab8?sid=f4de67c4-2983-432d-ae3d-a812c939f571,rafpaf,2024-06-14 19:53:39+00:00,[],2024-06-24 09:36:24+00:00,2024-06-19 22:53:05+00:00,https://github.com/metabase/metabase/issues/44249,[],[],
2353842525,issue,open,,+0 more attachments is wrong,"### Describe the bug

When you send a dashboard to Slack with many pictures, it says that there are ""0 more attachments"", while there are plenty

### To Reproduce

1) do an x-ray, save it as a dashboard
2) send it to slack

### Expected behavior

The count should be correct

### Logs

NA

### Information about your Metabase installation

```JSON
v50.3
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-06-14 18:00:53+00:00,[],2024-06-14 18:29:53+00:00,,https://github.com/metabase/metabase/issues/44238,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('Notifications/Slack', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2168529610, 'issue_id': 2353842525, 'author': 'noahmoss', 'body': 'This is a known and long-standing Slack bug. c.f. some discussion here: https://metaboat.slack.com/archives/C010L1Z4F9S/p1665414924045689', 'created_at': datetime.datetime(2024, 6, 14, 18, 12, 42, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-06-14 18:12:42 UTC): This is a known and long-standing Slack bug. c.f. some discussion here: https://metaboat.slack.com/archives/C010L1Z4F9S/p1665414924045689

"
2353796082,issue,closed,not_planned,Make the maximum value of the filter dropdown field values configurable,"I propose to make the maximum value of the filter dropdown field values configurable in the global settings menu, maybe on a table or even field basis.

The current setting is hardcoded to 1000. 
See https://www.metabase.com/docs/latest/data-modeling/metadata-editing#changing-a-search-box-filter-to-a-dropdown-filter

It was increased from 300 to 1000 some time ago, according to https://github.com/metabase/metabase/issues/7603 , but I believe there is a case to making this entirely configurable and up to the metabase admin, since it would greatly improve usability for ""average"" users.


**Is your feature request related to a problem? Please describe.**
We have a database with more than 1000 products (distinct values), and would need the dropdown to support that. It would improve usability, since the users could instantly filter and not have to copy and paste values.

**Describe the solution you'd like**
Please let the maximum number of field values in the filter dropdown be customizable, so that we can choose to raise it, if we deem it necessary. The setting could be on a DB, table or field scope.

**How important is this feature to you?**
Very important

",elburro1887,2024-06-14 17:26:58+00:00,[],2024-06-14 17:33:21+00:00,2024-06-14 17:33:21+00:00,https://github.com/metabase/metabase/issues/44235,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Needs Triage', '')]","[{'comment_id': 2168474290, 'issue_id': 2353796082, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/35631', 'created_at': datetime.datetime(2024, 6, 14, 17, 33, 21, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-14 17:33:21 UTC): duplicate of https://github.com/metabase/metabase/issues/35631

"
