id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2147492144,issue,open,,Print/export functionality for tables at the question level,"**Is your feature request related to a problem? Please describe.**
Currently, you can only set up exports to PDF at a dashboard level, but users may want to export/print a table at the question level, but don't want to get an xlsx/csv/json file, but the Metabase formatted table itself in a PDF.

**Describe alternatives you've considered**
Adding to a dashboard and then exporting to PDF, but it takes more clicks, you need to manually set the table height to the size of the rows, and we also have this bug https://github.com/metabase/metabase/issues/34868 that actually will prevent you from getting a good report

**How important is this feature to you?**
Requested by a customer as very important, as it's a functionality that other competitors from them have.

**Additional context**
N/A
",ignacio-mb,2024-02-21 19:06:22+00:00,[],2025-02-05 14:54:58+00:00,,https://github.com/metabase/metabase/issues/39022,"[('Type:New Feature', ''), ('Reporting/Export', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2147450432,issue,open,,Links to cards in dashboard subscription emails do not preserve filters set in the subscription,"### Describe the bug

When a dashboard subscription is set with filters applied, visualizations are filtered and rendered accordingly in the email.
The link to the dashboard in the email functions properly and directs the browser to the filtered dashboard in Metabase. 

However, the links to individual cards of the dashboard lead to the unfiltered versions of those cards.

### To Reproduce

1. Create a dashboard with some questions and dashboard filters wired to the questions
2. Set up an email subscription, and set filter values in the subscription settings
3. Send a test email
4. Follow the links to the cards in the email, they will lead to the cards without filter values applied

### Expected behavior

Similarly to the dashboard link, the card links should lead to cards with the proper filtered content

### Logs

n/a

### Information about your Metabase installation

```JSON
Reproduced it in 1.47 and 1.48.
```


### Severity

P2 - reported by a customer

### Additional context

_No response_",zbodi74,2024-02-21 18:40:48+00:00,['tsplude'],2025-02-04 20:29:33+00:00,,https://github.com/metabase/metabase/issues/39021,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2147362182,issue,open,,[Epic] Find and replace data reference in MBQL queries API,"**Links**
- [product doc](https://www.notion.so/metabase/Find-and-replace-data-reference-in-MBQL-queries-API-464bacba066a49d19438f50a9b696846)

```[tasklist]
### Tasks
- [ ] Add a draft title or issue reference here
```


",luizarakaki,2024-02-21 17:53:31+00:00,[],2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/39019,"[('Querying/MBQL', ''), ('.Backend', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2147355088,issue,closed,completed,Metabase renders the result but the query does not finish in the DB,"### Describe the bug

Queries in the DB seem to continue in the background, while the query has already been finished for Metabase

### To Reproduce

1) add the Redshift dev DW to a Metabase (sample DB)
2) do the following query:
```
SELECT
  ""public"".""random_data"".""text_column1"" AS ""text_column1"",
  FLOOR((""public"".""random_data"".""numeric_column1"" / 125.0)) * 125.0 AS ""numeric_column1"",
  FLOOR((""public"".""random_data"".""numeric_column4"" / 125.0)) * 125.0 AS ""numeric_column4"",
  FLOOR((""public"".""random_data"".""numeric_column5"" / 125.0)) * 125.0 AS ""numeric_column5"",
  FLOOR((""public"".""random_data"".""numeric_column8"" / 125.0)) * 125.0 AS ""numeric_column8"",
  FLOOR((""public"".""random_data"".""numeric_column9"" / 125.0)) * 125.0 AS ""numeric_column9"",
  FLOOR(
    (""public"".""random_data"".""numeric_column10"" / 125.0)
  ) * 125.0 AS ""numeric_column10"",
  FLOOR(
    (""public"".""random_data"".""numeric_column13"" / 125.0)
  ) * 125.0 AS ""numeric_column13"",
  COUNT(*) AS ""count""
FROM
  ""public"".""random_data""
GROUP BY
  ""public"".""random_data"".""text_column1"",
  FLOOR((""public"".""random_data"".""numeric_column1"" / 125.0)) * 125.0,
  FLOOR((""public"".""random_data"".""numeric_column4"" / 125.0)) * 125.0,
  FLOOR((""public"".""random_data"".""numeric_column5"" / 125.0)) * 125.0,
  FLOOR((""public"".""random_data"".""numeric_column8"" / 125.0)) * 125.0,
  FLOOR((""public"".""random_data"".""numeric_column9"" / 125.0)) * 125.0,
  FLOOR(
    (""public"".""random_data"".""numeric_column10"" / 125.0)
  ) * 125.0,
  FLOOR(
    (""public"".""random_data"".""numeric_column13"" / 125.0)
  ) * 125.0
ORDER BY
  ""public"".""random_data"".""text_column1"" ASC,
  FLOOR((""public"".""random_data"".""numeric_column1"" / 125.0)) * 125.0 ASC,
  FLOOR((""public"".""random_data"".""numeric_column4"" / 125.0)) * 125.0 ASC,
  FLOOR((""public"".""random_data"".""numeric_column5"" / 125.0)) * 125.0 ASC,
  FLOOR((""public"".""random_data"".""numeric_column8"" / 125.0)) * 125.0 ASC,
  FLOOR((""public"".""random_data"".""numeric_column9"" / 125.0)) * 125.0 ASC,
  FLOOR(
    (""public"".""random_data"".""numeric_column10"" / 125.0)
  ) * 125.0 ASC,
  FLOOR(
    (""public"".""random_data"".""numeric_column13"" / 125.0)
  ) * 125.0 ASC
```
3) wait till it finishes and then...
4) go to Redshift and check the status of `select * from STV_INFLIGHT`, you'll see that the query is still running while in Metabase it has finished

### Expected behavior

The connection and query should finish if Metabase finishes

### Logs

NA

### Information about your Metabase installation

```JSON
v48.6
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-02-21 17:50:46+00:00,[],2024-08-28 02:12:18+00:00,2024-07-22 11:47:19+00:00,https://github.com/metabase/metabase/issues/39018,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Redshift', None), ('.Team/Querying', '')]","[{'comment_id': 2057318649, 'issue_id': 2147355088, 'author': 'lbrdnk', 'body': 'It seems that we actually close the connection, but it takes much longer than returning the results back to the browser. I believe its a result of limiting rows to 2k.\r\n\r\nAfter starting the query execution from GUI, we are able to check its status eg. using `select * from sys_query_history where end_time is null;`\r\n\r\nThat way we could acquire its id. We can further check its status using `select * from sys_query_history where query_id = <that id>;`\r\n\r\nQuery completes in the GUI in less than 30 seconds. Then there is a 30+ seconds window until the query\'s `end_time` column gets its value -- query completes on the Redshift\'s side.\r\n\r\nAlso executing this query through psql takes _those_ 60+ seconds.\r\n\r\n---\r\n\r\n_Now why is that?_ My hyphotesis: In limit postprocessing middleware we reduce only the `limit` number of rows ([limit.clj](https://github.com/metabase/metabase/blob/e9256fda39a3df843efacf4ce981f478317f7d6b/src/metabase/query_processor/middleware/limit.clj#L57)) -- in this case 2k. I believe that result set is batched, thus we are able to take those 2k rows and return those to the FE, while query is still running on the Redshift side.\r\n\r\nAfterwards, during the qp machinery\'s return phase, result set is closed indeed, but the closing takes the delta between the time of seemingly completion in GUI and the actual completion on the Redshift side.\r\n\r\nIf I\'m correct here, closing the result set (`with-open`\'s finally) in `metabase.driver.sql-jdbc.execute/execute-reducible-query` ([execute.clj](https://github.com/metabase/metabase/blob/e9256fda39a3df843efacf4ce981f478317f7d6b/src/metabase/driver/sql_jdbc/execute.clj#L701)) blocks until the remaining results are computed, even though we reduce only first 2k.\r\n\r\nTo back that, measurements of `metabase.driver.sql-jdbc.execute/execute-reducible-query` follow:\r\n\r\n```\r\n""Elapsed time: 10037.283041 msecs""   -- timing of the statement execution\r\n""Elapsed time: 513.398333 msecs""     -- timing of the respond call\r\n""Elapsed time: 62449.817709 msecs""   -- timing of the call to with-open\r\n```\r\n\r\nThen, following is the log snippet, that\'s rendered _after the with-open returns_ -- long after FE has the results and considers the query completed.\r\n\r\n```\r\n2024-04-15 15:54:17,190 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.0 mins (2 DB calls) App DB connections: 2/10 Jetty threads: 4/50 (2 idle, 0 queued) (101 total active threads) Queries in flight: 0 (0 queued); redshift DB 2 connections: 0/2 (0 threads blocked) {:metabase-user-id 1}\r\n```\r\n\r\n---\r\n\r\n_What can we do about that?_ We could (1) either kill the query instead of an attempt to close the result set or (2) we could modify the limit middleware to be applied also to native queries (by eg. wrapping those in sub select) or (3) find a way to notify the user about still running query.\r\n\r\nI\'m leaning towards solution 2. If there\'s some blocker along the way, 1 could be also feasible.', 'created_at': datetime.datetime(2024, 4, 15, 16, 38, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2104656613, 'issue_id': 2147355088, 'author': 'paoliniluis', 'body': 'according to the person who reported this, it keeps happening. I need time to reproduce this', 'created_at': datetime.datetime(2024, 5, 10, 13, 56, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182424734, 'issue_id': 2147355088, 'author': 'perivamsi', 'body': '@paoliniluis do you have more info from the person who reported this? any ticket?', 'created_at': datetime.datetime(2024, 6, 21, 9, 57, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228712272, 'issue_id': 2147355088, 'author': 'mnherzz', 'body': ""@perivamsi Apologies for the late response. It looks like this ended up getting fixed after one of the Metabase updates. We haven't had an issue for the past few weeks."", 'created_at': datetime.datetime(2024, 7, 15, 15, 0, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233263788, 'issue_id': 2147355088, 'author': 'paoliniluis', 'body': 'reopening as the user reported that this still happens', 'created_at': datetime.datetime(2024, 7, 17, 12, 58, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241145235, 'issue_id': 2147355088, 'author': 'perivamsi', 'body': ""More context from the customer (copying this from an email conversation)\n\n- We're running the latest version - 50.13. \n- 4 queries were left running. It seems to be an issue with window functions. We noticed that all 4 queries used the 'first_value' function with the window frame 'unbounded preceding and unbounded following'. I modified the query to use 'row_number', which initially resolved the issue. I added a few more join clauses to one of the modified queries and now that one is hanging again. \n- This query hangs when launched in the dashboard and when the question is run separately on its own outside of the dashboard. \n- The query times out after 10 minutes in Metabase. On the Redshift side, it never completes. The query stays open indefinitely until manually terminated.\n- No, there aren't exceptions in Metabase logs"", 'created_at': datetime.datetime(2024, 7, 20, 12, 59, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242761648, 'issue_id': 2147355088, 'author': 'lbrdnk', 'body': ""Closing the issue as completed because the reproduction from the description has been addressed. I've opened the https://github.com/metabase/metabase/issues/45910 to track query not completing with use of window functions."", 'created_at': datetime.datetime(2024, 7, 22, 11, 47, 19, tzinfo=datetime.timezone.utc)}]","lbrdnk on (2024-04-15 16:38:54 UTC): It seems that we actually close the connection, but it takes much longer than returning the results back to the browser. I believe its a result of limiting rows to 2k.

After starting the query execution from GUI, we are able to check its status eg. using `select * from sys_query_history where end_time is null;`

That way we could acquire its id. We can further check its status using `select * from sys_query_history where query_id = <that id>;`

Query completes in the GUI in less than 30 seconds. Then there is a 30+ seconds window until the query's `end_time` column gets its value -- query completes on the Redshift's side.

Also executing this query through psql takes _those_ 60+ seconds.

---

_Now why is that?_ My hyphotesis: In limit postprocessing middleware we reduce only the `limit` number of rows ([limit.clj](https://github.com/metabase/metabase/blob/e9256fda39a3df843efacf4ce981f478317f7d6b/src/metabase/query_processor/middleware/limit.clj#L57)) -- in this case 2k. I believe that result set is batched, thus we are able to take those 2k rows and return those to the FE, while query is still running on the Redshift side.

Afterwards, during the qp machinery's return phase, result set is closed indeed, but the closing takes the delta between the time of seemingly completion in GUI and the actual completion on the Redshift side.

If I'm correct here, closing the result set (`with-open`'s finally) in `metabase.driver.sql-jdbc.execute/execute-reducible-query` ([execute.clj](https://github.com/metabase/metabase/blob/e9256fda39a3df843efacf4ce981f478317f7d6b/src/metabase/driver/sql_jdbc/execute.clj#L701)) blocks until the remaining results are computed, even though we reduce only first 2k.

To back that, measurements of `metabase.driver.sql-jdbc.execute/execute-reducible-query` follow:

```
""Elapsed time: 10037.283041 msecs""   -- timing of the statement execution
""Elapsed time: 513.398333 msecs""     -- timing of the respond call
""Elapsed time: 62449.817709 msecs""   -- timing of the call to with-open
```

Then, following is the log snippet, that's rendered _after the with-open returns_ -- long after FE has the results and considers the query completed.

```
2024-04-15 15:54:17,190 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.0 mins (2 DB calls) App DB connections: 2/10 Jetty threads: 4/50 (2 idle, 0 queued) (101 total active threads) Queries in flight: 0 (0 queued); redshift DB 2 connections: 0/2 (0 threads blocked) {:metabase-user-id 1}
```

---

_What can we do about that?_ We could (1) either kill the query instead of an attempt to close the result set or (2) we could modify the limit middleware to be applied also to native queries (by eg. wrapping those in sub select) or (3) find a way to notify the user about still running query.

I'm leaning towards solution 2. If there's some blocker along the way, 1 could be also feasible.

paoliniluis (Issue Creator) on (2024-05-10 13:56:02 UTC): according to the person who reported this, it keeps happening. I need time to reproduce this

perivamsi on (2024-06-21 09:57:16 UTC): @paoliniluis do you have more info from the person who reported this? any ticket?

mnherzz on (2024-07-15 15:00:11 UTC): @perivamsi Apologies for the late response. It looks like this ended up getting fixed after one of the Metabase updates. We haven't had an issue for the past few weeks.

paoliniluis (Issue Creator) on (2024-07-17 12:58:45 UTC): reopening as the user reported that this still happens

perivamsi on (2024-07-20 12:59:14 UTC): More context from the customer (copying this from an email conversation)

- We're running the latest version - 50.13. 
- 4 queries were left running. It seems to be an issue with window functions. We noticed that all 4 queries used the 'first_value' function with the window frame 'unbounded preceding and unbounded following'. I modified the query to use 'row_number', which initially resolved the issue. I added a few more join clauses to one of the modified queries and now that one is hanging again. 
- This query hangs when launched in the dashboard and when the question is run separately on its own outside of the dashboard. 
- The query times out after 10 minutes in Metabase. On the Redshift side, it never completes. The query stays open indefinitely until manually terminated.
- No, there aren't exceptions in Metabase logs

lbrdnk on (2024-07-22 11:47:19 UTC): Closing the issue as completed because the reproduction from the description has been addressed. I've opened the https://github.com/metabase/metabase/issues/45910 to track query not completing with use of window functions.

"
2147274511,issue,open,,Request for ability to share link to specific part of a dashboard,"**Is your feature request related to a problem? Please describe.**
My team and I regularly build dashboards. We often use textboxes to build sections on the dash. When sharing the dash, i would love the ability to share a specific section of the dash e.g. hyperlink to textbox X that is halfway down the dash.

**Describe the solution you'd like**
When sharing a dash i've just made with stakeholders, i would love the ability to share a specific section of the dash e.g. hyperlink to textbox X that is halfway down the dash. I want to say ""hey, look down here at this part of the dash""

**Describe alternatives you've considered**
Workaround is sharing 2 links- 1) link to full dash, 2) link to specific chart on the dash. But im trying to get them to read and discover dashes a bit better.

**How important is this feature to you?**
It is not breaking but i think this could be pretty big in getting more people to use metabase, push adoption of my dashbaords and thus metabase. 

**Additional context**
Add any other context or screenshots about the feature request here.
",aarthi-subramanian,2024-02-21 17:11:13+00:00,[],2024-02-23 18:19:49+00:00,,https://github.com/metabase/metabase/issues/39014,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2147221023,issue,closed,completed,Stacked bar chart showing wrong percentage when total value is negative,"### Describe the bug

When using the Stacked Bar Chart on Metabase and the total value of a grouping is negative, the percentage shown in the summary is wrong. In the below image, it is possible to see the total value being -R$89k and the first category being -R$98k, which is a negative contribution to the total sum. The categories with positive values appear in the image contributing negatively to the total. 

![image](https://github.com/metabase/metabase/assets/22264236/fff082cc-43b4-4bc8-a99a-83eafc96c69e)

### To Reproduce

1. Create a question that groups positive and negative values for a category. The total negative value must be greater than the total positive value.
2. Click on Display and select the Bar chart.
3. In the Bar chart configurations, select Exhibition > Stacked.
4. Pass the mouse through a bar and see the error.


### Expected behavior

Positive values should contribute positively to the total value. And negative values should contribute negatively. So their percentages should follow this pattern.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser Chrome Versão 122.0
- OS Ubuntu 22.04 LTS
- Database Google BigQuery
- Metabase v1.48.4
```


### Severity

The issue is causing some users to be confused with the numbers.

### Additional context

_No response_",tamiriscrepalde,2024-02-21 16:44:24+00:00,['JesseSDevaney'],2024-06-10 03:01:21+00:00,2024-06-10 03:01:21+00:00,https://github.com/metabase/metabase/issues/39012,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Correctness', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2146918861,issue,closed,not_planned,Question breaking after source column drop / rename,"### Describe the bug

Question breaking after source column drop / rename

![telegram-cloud-photo-size-2-5382109736247350706-y](https://github.com/metabase/metabase/assets/18265924/ebd4e62d-4b55-41e0-91ae-9303caa77110)

Question don't self-rebuild a list of fields even after manually opening the dropdown and changing something.

<img width=""382"" alt=""image"" src=""https://github.com/metabase/metabase/assets/18265924/b58a9d28-b338-4ee8-82de-fd6a0395162b"">


### I suggest

- Automatically fix Question Definition (SQL) for all Questions, if the column isn't used in Question while syncing the database
- Give options in broken queries: remove column, choose another column, sync database (if u decide to return the field3)

### To Reproduce

1. Create table `tmp(field1, field2, field3, field4)`
2. Create a Question in the Metabase interface. Select **Field 1**, **Field 2** and **Field 3**
3. Remove column `field3` from table `tmp`. Add `field5` to table `tmp`
4. Sync schema
5. Open Question in the Metabase and see the error `...column field3 does not exists...`
6. Open Question Editor, and press dropdown on the table. You will see **Field 1**, **Field 2**, **Field 4** and **Field 5**
7. There is no obvious way to do something to fix the Question
8. The only way to fix, this is to press ""Select all"" and then manually uncheck **Field 4** and **Field 5**

### Expected behavior
_Product team update:_
The expected behavior is to ignore inactive fields in the query processor pipeline but **keep** it in the query definition.
It is important to keep the field in the query definition because if we implement a tool to let users ""find and replace"" fields, the reference must still be there. [Slack discussion](https://metaboat.slack.com/archives/C04DN5VRQM6/p1708527955950719)


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""ru-RU"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.19+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.19"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.19+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-169-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""googleanalytics""
    ],
    ""hosting-env"": ""heroku"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.6 (Debian 11.6-1.pgdg90+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.1""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-07-24"",
      ""tag"": ""v0.46.6.2"",
      ""branch"": ""patch-google-sso-button"",
      ""hash"": ""a4c740a""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

I was almost fired with the words “you broke our working tool”

### Additional context

_No response_",rrr2rrr,2024-02-21 14:39:15+00:00,[],2024-06-26 03:22:56+00:00,2024-06-26 03:20:27+00:00,https://github.com/metabase/metabase/issues/39008,"[('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', '')]","[{'comment_id': 1957683675, 'issue_id': 2146918861, 'author': 'luizarakaki', 'body': 'Updated the issue with the expected behavior', 'created_at': datetime.datetime(2024, 2, 21, 18, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190472704, 'issue_id': 2146918861, 'author': 'camsaul', 'body': 'Duplicate of #12721', 'created_at': datetime.datetime(2024, 6, 26, 3, 20, 27, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-02-21 18:48:50 UTC): Updated the issue with the expected behavior

camsaul on (2024-06-26 03:20:27 UTC): Duplicate of #12721

"
2146712965,issue,closed,completed,Interactive embedding dashboard with multiple tabs and parameter `header=false` will not load,"### Describe the bug

I found this bug while reproducing https://github.com/metabase/metabase/issues/38429

In interactive embedding, if you visit a dashboard that has multiple tabs **and** has the parameter `header=false`, the dashboard will not finish loading

![image](https://github.com/metabase/metabase/assets/1937582/eb11be78-2264-423b-8a47-c941f5c6ea67)


### To Reproduce

0. Set up interactive embedding
1. Create a dashboard with multiple tabs
2. Visit the interactive embedding page where the iframe URL has this parameter `?header=false`
3. Visit the dashboard we created in 1)
4. See that the card will not stop spinning. In fact the card requests will never be initiated.


### Expected behavior

The dashboard loads normally

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.14.1+1-LTS"",
    ""java.vendor"": ""Azul Systems, Inc."",
    ""java.vendor.url"": ""http://www.azul.com/"",
    ""java.version"": ""11.0.14.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.14.1+1-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.2.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Bangkok""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-02-20"",
      ""src_hash"": ""e3b554bc3d8e4448572d8fdde9681523aca052d8"",
      ""tag"": ""v0.48.1-SNAPSHOT"",
      ""hash"": ""11823a5""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Almost blocking? Users can remove `header=false` to mitigate the issue.

### Additional context

_No response_",WiNloSt,2024-02-21 13:05:33+00:00,['WiNloSt'],2024-03-18 11:51:10+00:00,2024-02-22 07:22:01+00:00,https://github.com/metabase/metabase/issues/39002,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]","[{'comment_id': 1956639781, 'issue_id': 2146712965, 'author': 'albertoperdomo', 'body': 'P2 as it prevents people from using tabs together w/ interactive embedding.', 'created_at': datetime.datetime(2024, 2, 21, 13, 21, 11, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-02-21 13:21:11 UTC): P2 as it prevents people from using tabs together w/ interactive embedding.

"
2146668366,issue,closed,completed,Too eager unsaved changes warning when editing native questions,"See [Slack discussion](https://metaboat.slack.com/archives/C0645JP1W81/p1708447869136439).

----

When editing native questions, change behavior to show the unsaved changes warning only when the native query has been modified.",kamilmielnik,2024-02-21 12:43:06+00:00,['kamilmielnik'],2024-02-28 14:00:06+00:00,2024-02-28 14:00:06+00:00,https://github.com/metabase/metabase/issues/39001,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2146133919,issue,closed,completed,Cannot group by date when building a question from a model that relies on a field with UnixSeconds->DateTime casting,"### Describe the bug

Video recording
--------------
A full video recording of a bug:
https://www.loom.com/share/9c1c68e15d59457b8006cef4f9dc6347?sid=687d29e0-49b1-4345-8544-89acbdb4565d

Bug description
-------------

**Given** 
- a MySQL (MariaDB) database table ""Orders"" with an integer field ""Created At"" that is set to be cast to UnixSeconds->DateTime via Admin / Table Metadata

**When** 
- the ""Orders"" table is used as data source for a Model (with no other interventions on the model), 
- and the Model is used to build a Question that summarizes data & groups by the ""Created Date"" field

**Then**
- the grouping results in an empty date group

**Root cause:**
It appears the query generated is attempting to convert the date twice - once in the inner query where the date field gets selected, and then another time in the outer query when doing the grouping. See the logs section for output.

**SQL CLI result:**
Running the generated SQL via MySQL command line results in a series of warnings such as `Warning: Truncated incorrect unixtime value: '20101230115041'`.   Looking at the values themselves, it is clear they are already dates, not timestamps.

Note that the above issue **does not** occur if the database table is used as a Question data source directly, only when going through a model.


### To Reproduce

1. In MariaDB, create a database ""Test"" and connect it to Metabase
2. Create a table ""Orders"" with an auto-increment ID field, and an ""Order Created"" field set to int(10) type
3. Populate the field with Unix timestamp values (seconds), such as `1293709841`, `1294259996`, etc.
4. In Metabase, go to Admin Settings > Table Metadata
5. Locate the Orders table and configure the ""Order Created"" field to cast to a specific data type. Choose ""UnixSeconds->DateTime""
6. Exit Admin and click ""+New"", then select ""Model""
7. Choose Notebook editor
8. For Starting Data, choose ""Raw"" data, then select the ""Test"" database and finally your ""Orders"" table
9. Click ""Play"" icon at the bottom of the page to check the data from the table loads.  Verify the ""Order Created"" field displays as a proper date (it should, based on the casting set in step 4)
10. Click Save to save the model (do not make any other changes to it).  Name it ""Test Model""
11. Metabase should display a table view of the model data so you can build a question from it.  Click Summarize, then choose ""Count of rows"" for Summarize By, and ""Order Created: Day"" for group by
12. At the bottom of the screen, click the table icon to switch to table view (by default, Metabase switches to a graph view after doing the grouping)

**Expected result:**
A table with multiple rows showing different days, and matching order counts next to them.

**Actual Result:**
A table with a single row, counting all orders regardless of date, with the Order Created: Day being empty.



### Expected behavior

A table with multiple rows showing different days, and matching order counts next to them.

### Logs


Here is the SQL query produced by the steps above with real-world database.  Notice the `FROM_UNIXTIME` being used both in the inner query and the outer query.  For comparison, I'm adding the correct query generated when you build the same question from a database table instead of a model.

**Problematic query - built with a model:**

```
SELECT
  DATE(FROM_UNIXTIME(`source`.`order_created`)) AS `order_created`,
  COUNT(*) AS `count`
FROM
  (
    SELECT
      `skf0d_hikashop_order`.`order_id` AS `order_id`,
      `skf0d_hikashop_order`.`order_billing_address_id` AS `order_billing_address_id`,
      `skf0d_hikashop_order`.`order_shipping_address_id` AS `order_shipping_address_id`,
      `skf0d_hikashop_order`.`order_user_id` AS `order_user_id`,
      `skf0d_hikashop_order`.`order_status` AS `order_status`,
      `skf0d_hikashop_order`.`order_type` AS `order_type`,
      `skf0d_hikashop_order`.`order_number` AS `order_number`,
      FROM_UNIXTIME(`skf0d_hikashop_order`.`order_created`) AS `order_created`,
      FROM_UNIXTIME(`skf0d_hikashop_order`.`order_modified`) AS `order_modified`,
      `skf0d_hikashop_order`.`order_invoice_id` AS `order_invoice_id`,
      `skf0d_hikashop_order`.`order_invoice_number` AS `order_invoice_number`,
      `skf0d_hikashop_order`.`order_invoice_created` AS `order_invoice_created`,
      `skf0d_hikashop_order`.`order_currency_id` AS `order_currency_id`,
      `skf0d_hikashop_order`.`order_full_price` AS `order_full_price`,
      `skf0d_hikashop_order`.`order_tax_info` AS `order_tax_info`,
      `skf0d_hikashop_order`.`order_discount_code` AS `order_discount_code`,
      `skf0d_hikashop_order`.`order_discount_price` AS `order_discount_price`,
      `skf0d_hikashop_order`.`order_discount_tax` AS `order_discount_tax`,
      `skf0d_hikashop_order`.`order_payment_id` AS `order_payment_id`,
      `skf0d_hikashop_order`.`order_payment_method` AS `order_payment_method`,
      `skf0d_hikashop_order`.`order_payment_price` AS `order_payment_price`,
      `skf0d_hikashop_order`.`order_payment_params` AS `order_payment_params`,
      `skf0d_hikashop_order`.`order_shipping_id` AS `order_shipping_id`,
      `skf0d_hikashop_order`.`order_shipping_method` AS `order_shipping_method`,
      `skf0d_hikashop_order`.`order_shipping_price` AS `order_shipping_price`,
      `skf0d_hikashop_order`.`order_shipping_tax` AS `order_shipping_tax`,
      `skf0d_hikashop_order`.`order_shipping_params` AS `order_shipping_params`,
      `skf0d_hikashop_order`.`order_partner_id` AS `order_partner_id`,
      `skf0d_hikashop_order`.`order_partner_price` AS `order_partner_price`,
      `skf0d_hikashop_order`.`order_partner_paid` AS `order_partner_paid`,
      `skf0d_hikashop_order`.`order_partner_currency_id` AS `order_partner_currency_id`,
      `skf0d_hikashop_order`.`order_ip` AS `order_ip`,
      `skf0d_hikashop_order`.`order_site_id` AS `order_site_id`,
      `skf0d_hikashop_order`.`order_vm_id` AS `order_vm_id`,
      `skf0d_hikashop_order`.`order_currency_info` AS `order_currency_info`,
      `skf0d_hikashop_order`.`order_payment_tax` AS `order_payment_tax`,
      `skf0d_hikashop_order`.`order_subtotal` AS `order_subtotal`,
      `skf0d_hikashop_order`.`order_subtotal_no_vat` AS `order_subtotal_no_vat`,
      `skf0d_hikashop_order`.`order_shipping` AS `order_shipping`,
      `skf0d_hikashop_order`.`order_lang` AS `order_lang`,
      `skf0d_hikashop_order`.`order_token` AS `order_token`,
      `skf0d_hikashop_order`.`order_parent_id` AS `order_parent_id`,
      `skf0d_hikashop_order`.`order_reminded` AS `order_reminded`,
      `skf0d_hikashop_order`.`order_weight` AS `order_weight`,
      `skf0d_hikashop_order`.`order_weight_unit` AS `order_weight_unit`,
      `skf0d_hikashop_order`.`order_volume` AS `order_volume`,
      `skf0d_hikashop_order`.`order_dimension_unit` AS `order_dimension_unit`,
      `skf0d_hikashop_order`.`order_serial_params` AS `order_serial_params`
    FROM
      `skf0d_hikashop_order`
  ) AS `source`
GROUP BY
  DATE(FROM_UNIXTIME(`source`.`order_created`))
ORDER BY
  DATE(FROM_UNIXTIME(`source`.`order_created`)) ASC
```

**Working query - built by using the database table directly in the question**

```
SELECT
  DATE(
   
FROM_UNIXTIME(`skf0d_hikashop_order`.`order_created`)
  ) AS `order_created`,
  COUNT(*) AS `count`
FROM
  `skf0d_hikashop_order`
GROUP BY
  DATE(
    FROM_UNIXTIME(`skf0d_hikashop_order`.`order_created`)
  )
ORDER BY
  DATE(
    FROM_UNIXTIME(`skf0d_hikashop_order`.`order_created`)
  ) ASC
```

### Information about your Metabase installation

```JSON
- Browser: Chrome: Version 121.0.6167.184 (Official Build) (x86_64)
- System: macOS 14.2.1 (23C71)
- Database: MySQL (MariaDB)
- Metabase Version:  0.48.6
- Hosting Environment:  Docker
- Metabase Internal Database:  MySQL (MariaDB)
```


### Severity

Annoying. I cannot reuse models to build similar questions, I have to repeat all of the filters and custom columns in each question.

### Additional context

_No response_",petervukovic,2024-02-21 08:43:02+00:00,[],2025-01-27 17:48:25+00:00,2025-01-27 17:48:17+00:00,https://github.com/metabase/metabase/issues/38994,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Wanted: MLv2', 'Issues that will be fixed (or easier to fix, or possible to fix) when we have MLv2'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Dimensions', ''), ('Semantic Model/Units', '')]","[{'comment_id': 2616499184, 'issue_id': 2146133919, 'author': 'lbrdnk', 'body': ""Reproduced on `48.6` but not on today's master. Closing as completed."", 'created_at': datetime.datetime(2025, 1, 27, 17, 48, 17, tzinfo=datetime.timezone.utc)}]","lbrdnk on (2025-01-27 17:48:17 UTC): Reproduced on `48.6` but not on today's master. Closing as completed.

"
2145860584,issue,closed,completed,Replace toucan2 simple hydrations with batched hydrations,"A batched hydration works for both single entity or a seq of entities, so we should use batched hydration in most cases because it saves us from running into N+1 problems like [this](https://metaboat.slack.com/archives/C064EB1UE5P/p1708387795469919?thread_ts=1708358454.946419&cid=C064EB1UE5P).

From Cam
> The main use case of the simple hydration stuff was for adding calculated columns like :full_name to User (first_name + last_name), fetching additional stuff from the DB is obviously a no-no. We could easily have Toucan 2 warn or even error if you're hitting the app DB inside a simple hydration method if we don't want to eliminate them altogether.

E.g: you want to write a `:fields` hydration for `:table`
```clojure
(mi/define-batched-hydration-method with-fields
  :fields
  ""Efficiently hydrate the Fields for a collection of `tables`.""
  [tables]
  (let [table-id->fields (group-by :table_id (t2/select :model/Field
                                                        :table_id [:in (map :id tables)]
                                                        :active true))]
    (for [table tables]
      (assoc table :fields (get table-id->fields (:id table))))))

(t2/hydrate (t2/select-one :model/Table) :fields)
;; => (toucan2.instance/instance
;;     :model/Table
;;     {:name ""v_users"",
;;      :fields
;;      [(toucan2.instance/instance
;;        :model/Field
;;        {:name ""user_id"", ...})
;;       ...]})

(t2/hydrate (t2/select :model/Table {:limit 2}) :fields)
;; => [(toucan2.instance/instance
;;      :model/Table
;;      {:name ""v_users"",
;;       :fields
;;       [(toucan2.instance/instance
;;         :model/Field
;;         {:name ""user_id"", ...})
;;        ...]})
;;     (toucan2.instance/instance
;;      :model/Table
;;      {:name ""v_log"",
;;       :fields
;;       [(toucan2.instance/instance
;;         :model/Field
;;         {:name ""user_id"", ...})
;;        ...]})]

```",qnkhuat,2024-02-21 05:19:30+00:00,[],2024-03-20 05:36:33+00:00,2024-03-20 05:36:33+00:00,https://github.com/metabase/metabase/issues/38993,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]",[],
2145591708,issue,closed,not_planned,API returns HTTP 500 when calling email-reply-to,"**Describe the bug**
I get an HTTP 500 error when I try to set the reply-to address via API endpoint /api/email-reply-to
The email address is valid, and all other attributes on that page can be set in the same way ( I use Ansible):
The email is definitively correct.

```
- name: Setup email_reply_to ""{{system.setup.email_reply_to.params.value}}""
  uri:
    url: ""{{ system.metabase_url }}/api/setting/email-reply-to""
    method: PUT
    headers:  
      Content-Type: ""application/json""
      X-Metabase-Session: ""{{ metabase_session }}""
    body_format: json
    body: 
      value: ""{{system.setup.email_reply_to.params.value}}""
    status_code: [200, 204]            
  register: email_reply_to_results
  when: system.setup.email_reply_to.apply
```

**Logs**

```
{
    ""cache_control"": ""max-age=0, no-cache, must-revalidate, proxy-revalidate"",
    ""changed"": false,
    ""connection"": ""close"",
    ""content_length"": ""19067"",
    ""content_security_policy"": ""default-src 'none'; script-src 'self' https://maps.google.com https://accounts.google.com    'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=' 'sha256-ib2/2v5zC6gGM6Ety7iYgBUvpy/caRX9xV/pzzV7hf0=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE='; child-src 'self' https://accounts.google.com; style-src 'self' 'nonce-SY0I2jDRsE'   https://accounts.google.com; font-src *; img-src * 'self' data:; connect-src 'self' https://accounts.google.com metabase.us10.list-manage.com    ; manifest-src 'self';  frame-ancestors 'none';"",
    ""content_type"": ""application/json;charset=utf-8"",
    ""date"": ""Wed, 21 Feb 2024 00:52:24 GMT"",
    ""elapsed"": 0,
    ""expires"": ""Tue, 03 Jul 2001 06:00:00 GMT"",
    ""json"": {
        ""cause"": ""Invalid reply-to address"",
        ""data"": {
            ""value"": ""exactly@my-email.address""
        },
        ""message"": ""Invalid reply-to address"",
        ""trace"": [
            [
                ""metabase.email$fn__74233$fn__74234"",
                ""invoke"",
                ""email.clj"",
                55
            ],
            [
                ""metabase.models.setting$set_with_audit_logging_BANG_"",
                ""invokeStatic"",
                ""setting.clj"",
                941
            ],
            [
                ""metabase.models.setting$set_with_audit_logging_BANG_"",
                ""invoke"",
                ""setting.clj"",
                929
            ],
            [
                ""metabase.models.setting$set_BANG_"",
                ""invokeStatic"",
                ""setting.clj"",
                967
            ],
            [
                ""metabase.models.setting$set_BANG_"",
                ""doInvoke"",
                ""setting.clj"",
                945
            ],
            [
                ""clojure.lang.RestFn"",
                ""invoke"",
                ""RestFn.java"",
                425
            ],
            [
                ""metabase.api.setting$fn__98784$fn__98787"",
                ""invoke"",
                ""setting.clj"",
                59
            ],
            [
                ""metabase.api.setting$do_with_setting_access_control"",
                ""invokeStatic"",
                ""setting.clj"",
                14
            ],
            [
                ""metabase.api.setting$do_with_setting_access_control"",
                ""invoke"",
                ""setting.clj"",
                10
            ],
            [
                ""metabase.api.setting$fn__98784"",
                ""invokeStatic"",
                ""setting.clj"",
                58
            ],
            [
                ""metabase.api.setting$fn__98784"",
                ""invoke"",
                ""setting.clj"",
                53
            ],
            [
                ""compojure.core$wrap_response$fn__43795"",
                ""invoke"",
                ""core.clj"",
                160
            ],
            [
                ""compojure.core$wrap_route_middleware$fn__43779"",
                ""invoke"",
                ""core.clj"",
                132
            ],
            [
                ""compojure.core$wrap_route_info$fn__43784"",
                ""invoke"",
                ""core.clj"",
                139
            ],
            [
                ""compojure.core$wrap_route_matches$fn__43788"",
                ""invoke"",
                ""core.clj"",
                151
            ],
            [
                ""clojure.lang.Var"",
                ""invoke"",
                ""Var.java"",
                393
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""metabase.server.middleware.auth$enforce_authentication$fn__94181"",
                ""invoke"",
                ""auth.clj"",
                17
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$make_context$handler__43835"",
                ""invoke"",
                ""core.clj"",
                290
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                300
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""metabase.api.routes$fn__101607$fn__101608"",
                ""invoke"",
                ""routes.clj"",
                64
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""clojure.lang.AFn"",
                ""applyToHelper"",
                ""AFn.java"",
                160
            ],
            [
                ""clojure.lang.AFn"",
                ""applyTo"",
                ""AFn.java"",
                144
            ],
            [
                ""clojure.core$apply"",
                ""invokeStatic"",
                ""core.clj"",
                667
            ],
            [
                ""clojure.core$apply"",
                ""invoke"",
                ""core.clj"",
                662
            ],
            [
                ""metabase.server.routes$fn__101770$fn__101771"",
                ""doInvoke"",
                ""routes.clj"",
                72
            ],
            [
                ""clojure.lang.RestFn"",
                ""invoke"",
                ""RestFn.java"",
                436
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$make_context$handler__43835"",
                ""invoke"",
                ""core.clj"",
                290
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                300
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$wrap_route_matches$fn__43788"",
                ""invoke"",
                ""core.clj"",
                153
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$wrap_route_matches$fn__43788"",
                ""invoke"",
                ""core.clj"",
                153
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$wrap_route_matches$fn__43788"",
                ""invoke"",
                ""core.clj"",
                153
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                199
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$make_context$handler__43835"",
                ""invoke"",
                ""core.clj"",
                290
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                300
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808$respond_SINGLEQUOTE___43809"",
                ""invoke"",
                ""core.clj"",
                197
            ],
            [
                ""compojure.core$make_context$fn__43839"",
                ""invoke"",
                ""core.clj"",
                301
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""compojure.core$routes$fn__43807$f__43808"",
                ""invoke"",
                ""core.clj"",
                198
            ],
            [
                ""compojure.core$routes$fn__43807"",
                ""invoke"",
                ""core.clj"",
                200
            ],
            [
                ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98831"",
                ""invoke"",
                ""exceptions.clj"",
                108
            ],
            [
                ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__98828"",
                ""invoke"",
                ""exceptions.clj"",
                96
            ],
            [
                ""metabase.server.middleware.log$log_api_call$fn__103771$fn__103772$fn__103773"",
                ""invoke"",
                ""log.clj"",
                216
            ],
            [
                ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
                ""invokeStatic"",
                ""diagnostic.clj"",
                18
            ],
            [
                ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
                ""invoke"",
                ""diagnostic.clj"",
                12
            ],
            [
                ""metabase.server.middleware.log$log_api_call$fn__103771$fn__103772"",
                ""invoke"",
                ""log.clj"",
                208
            ],
            [
                ""toucan2.execute$do_with_call_counts"",
                ""invokeStatic"",
                ""execute.clj"",
                112
            ],
            [
                ""toucan2.execute$do_with_call_counts"",
                ""invoke"",
                ""execute.clj"",
                103
            ],
            [
                ""metabase.server.middleware.log$log_api_call$fn__103771"",
                ""invoke"",
                ""log.clj"",
                207
            ],
            [
                ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__108449"",
                ""invoke"",
                ""browser_cookie.clj"",
                42
            ],
            [
                ""metabase.server.middleware.security$add_security_headers$fn__85097"",
                ""invoke"",
                ""security.clj"",
                180
            ],
            [
                ""metabase.server.middleware.json$wrap_json_body$fn__45153"",
                ""invoke"",
                ""json.clj"",
                67
            ],
            [
                ""metabase.server.middleware.offset_paging$handle_paging$fn__85121"",
                ""invoke"",
                ""offset_paging.clj"",
                45
            ],
            [
                ""metabase.server.middleware.json$wrap_streamed_json_response$fn__45171"",
                ""invoke"",
                ""json.clj"",
                103
            ],
            [
                ""ring.middleware.keyword_params$wrap_keyword_params$fn__108716"",
                ""invoke"",
                ""keyword_params.clj"",
                55
            ],
            [
                ""ring.middleware.params$wrap_params$fn__108735"",
                ""invoke"",
                ""params.clj"",
                77
            ],
            [
                ""metabase.server.middleware.misc$maybe_set_site_url$fn__65458"",
                ""invoke"",
                ""misc.clj"",
                61
            ],
            [
                ""metabase.server.middleware.session$reset_session_timeout$fn__71253"",
                ""invoke"",
                ""session.clj"",
                488
            ],
            [
                ""metabase.server.middleware.session$bind_current_user$fn__71219$fn__71220"",
                ""invoke"",
                ""session.clj"",
                383
            ],
            [
                ""metabase.server.middleware.session$do_with_current_user"",
                ""invokeStatic"",
                ""session.clj"",
                362
            ],
            [
                ""metabase.server.middleware.session$do_with_current_user"",
                ""invoke"",
                ""session.clj"",
                346
            ],
            [
                ""metabase.server.middleware.session$bind_current_user$fn__71219"",
                ""invoke"",
                ""session.clj"",
                382
            ],
            [
                ""metabase.server.middleware.session$wrap_current_user_info$fn__71202"",
                ""invoke"",
                ""session.clj"",
                321
            ],
            [
                ""metabase.server.middleware.session$wrap_session_id$fn__71185"",
                ""invoke"",
                ""session.clj"",
                253
            ],
            [
                ""metabase.server.middleware.auth$wrap_api_key$fn__94189"",
                ""invoke"",
                ""auth.clj"",
                30
            ],
            [
                ""ring.middleware.cookies$wrap_cookies$fn__108636"",
                ""invoke"",
                ""cookies.clj"",
                216
            ],
            [
                ""metabase.server.middleware.misc$add_content_type$fn__65440"",
                ""invoke"",
                ""misc.clj"",
                29
            ],
            [
                ""metabase.server.middleware.misc$disable_streaming_buffering$fn__65466"",
                ""invoke"",
                ""misc.clj"",
                78
            ],
            [
                ""ring.middleware.gzip$wrap_gzip$fn__108678"",
                ""invoke"",
                ""gzip.clj"",
                86
            ],
            [
                ""metabase.server.middleware.misc$bind_request$fn__65469"",
                ""invoke"",
                ""misc.clj"",
                95
            ],
            [
                ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__108465"",
                ""invoke"",
                ""ssl.clj"",
                41
            ],
            [
                ""metabase.server$async_proxy_handler$fn__65643"",
                ""invoke"",
                ""server.clj"",
                78
            ],
            [
                ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
                ""handle"",
                null,
                -1
            ],
            [
                ""org.eclipse.jetty.server.handler.StatisticsHandler"",
                ""handle"",
                ""StatisticsHandler.java"",
                173
            ],
            [
                ""org.eclipse.jetty.server.handler.HandlerWrapper"",
                ""handle"",
                ""HandlerWrapper.java"",
                122
            ],
            [
                ""org.eclipse.jetty.server.Server"",
                ""handle"",
                ""Server.java"",
                563
            ],
            [
                ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
                ""dispatch"",
                ""HttpChannel.java"",
                1598
            ],
            [
                ""org.eclipse.jetty.server.HttpChannel"",
                ""dispatch"",
                ""HttpChannel.java"",
                753
            ],
            [
                ""org.eclipse.jetty.server.HttpChannel"",
                ""handle"",
                ""HttpChannel.java"",
                501
            ],
            [
                ""org.eclipse.jetty.server.HttpConnection"",
                ""onFillable"",
                ""HttpConnection.java"",
                287
            ],
            [
                ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
                ""succeeded"",
                ""AbstractConnection.java"",
                314
            ],
            [
                ""org.eclipse.jetty.io.FillInterest"",
                ""fillable"",
                ""FillInterest.java"",
                100
            ],
            [
                ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
                ""run"",
                ""SelectableChannelEndPoint.java"",
                53
            ],
            [
                ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
                ""runTask"",
                ""AdaptiveExecutionStrategy.java"",
                421
            ],
            [
                ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
                ""consumeTask"",
                ""AdaptiveExecutionStrategy.java"",
                390
            ],
            [
                ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
                ""tryProduce"",
                ""AdaptiveExecutionStrategy.java"",
                277
            ],
            [
                ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
                ""run"",
                ""AdaptiveExecutionStrategy.java"",
                199
            ],
            [
                ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
                ""run"",
                ""ReservedThreadExecutor.java"",
                411
            ],
            [
                ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
                ""runJob"",
                ""QueuedThreadPool.java"",
                969
            ],
            [
                ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
                ""doRunJob"",
                ""QueuedThreadPool.java"",
                1194
            ],
            [
                ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
                ""run"",
                ""QueuedThreadPool.java"",
                1149
            ],
            [
                ""java.lang.Thread"",
                ""run"",
                null,
                -1
            ]
        ],
        ""value"": ""martin.jahr@isr.de"",
        ""via"": [
            {
                ""at"": [
                    ""metabase.email$fn__74233$fn__74234"",
                    ""invoke"",
                    ""email.clj"",
                    55
                ],
                ""data"": {
                    ""value"": ""martin.jahr@isr.de""
                },
                ""message"": ""Invalid reply-to address"",
                ""type"": ""clojure.lang.ExceptionInfo""
            }
        ]
    },
    ""last_modified"": ""Wed, 21 Feb 2024 00:52:24 GMT"",
    ""msg"": ""Status code was 500 and not [200, 204]: HTTP Error 500: Server Error"",
    ""redirected"": false,
    ""server"": ""Jetty(11.0.17)"",
    ""set_cookie"": ""metabase.DEVICE=06ef78ba-364e-4aab-ac15-408eda7644c0;HttpOnly;Path=/;Expires=Sun, 21 Feb 2044 00:52:24 GMT;SameSite=Lax"",
    ""status"": 500,
    ""strict_transport_security"": ""max-age=31536000"",
    ""url"": ""http://internal-nbmmetabase-lb-1150736026.eu-central-1.elb.amazonaws.com:3000/api/setting/email-reply-to"",
    ""x_content_type_options"": ""nosniff"",
    ""x_frame_options"": ""DENY"",
    ""x_permitted_cross_domain_policies"": ""none"",
    ""x_xss_protection"": ""1; mode=block""
}

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""de"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.209-198.812.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-12"",
      ""tag"": ""v1.48.6"",
      ""hash"": ""b8818f9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

```",selfscrum,2024-02-21 01:27:09+00:00,[],2024-06-05 13:53:54+00:00,2024-06-05 13:53:54+00:00,https://github.com/metabase/metabase/issues/38992,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Misc/API', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2027143886, 'issue_id': 2145591708, 'author': 'paoliniluis', 'body': 'Hi, did you solve this?', 'created_at': datetime.datetime(2024, 3, 29, 11, 49, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133559306, 'issue_id': 2145591708, 'author': 'bshepherdson', 'body': 'We have our own `u/email?` function for validating this - it looks like that might not be comprehensive enough.\r\n\r\n@selfscrum it would be useful to know either the real email address with the issue, or a similar one that also fails [this regex](https://github.com/metabase/metabase/blob/master/src/metabase/util.cljc#L283).', 'created_at': datetime.datetime(2024, 5, 27, 14, 6, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2133682922, 'issue_id': 2145591708, 'author': 'selfscrum', 'body': '@bshepherdson the real email is in the log excerpt near the bottom. It says there invalid reply-to address.', 'created_at': datetime.datetime(2024, 5, 27, 15, 17, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2135394445, 'issue_id': 2145591708, 'author': 'paoliniluis', 'body': '@selfscrum I\'m wondering if we\'re hiding the true response there. According to the frontend the payload to change that is\r\n{""placeholder"":""metabase-replies@yourcompany.com"",""value"":null,""is_env_setting"":false,""env_name"":""MB_EMAIL_REPLY_TO"",""description"":""The email address you want the replies to go to, if different from the from address."",""default"":null,""originalValue"":[""some_testing_mail@metabase.com""],""display_name"":""Reply-To Address"",""type"":""string"",""required"":false,""validations"":[[""email_list"",""That\'s not a valid email address""]]}', 'created_at': datetime.datetime(2024, 5, 28, 14, 35, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150033696, 'issue_id': 2145591708, 'author': 'paoliniluis', 'body': 'closing due to non-response', 'created_at': datetime.datetime(2024, 6, 5, 13, 53, 54, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-29 11:49:47 UTC): Hi, did you solve this?

bshepherdson on (2024-05-27 14:06:31 UTC): We have our own `u/email?` function for validating this - it looks like that might not be comprehensive enough.

@selfscrum it would be useful to know either the real email address with the issue, or a similar one that also fails [this regex](https://github.com/metabase/metabase/blob/master/src/metabase/util.cljc#L283).

selfscrum (Issue Creator) on (2024-05-27 15:17:47 UTC): @bshepherdson the real email is in the log excerpt near the bottom. It says there invalid reply-to address.

paoliniluis on (2024-05-28 14:35:44 UTC): @selfscrum I'm wondering if we're hiding the true response there. According to the frontend the payload to change that is
{""placeholder"":""metabase-replies@yourcompany.com"",""value"":null,""is_env_setting"":false,""env_name"":""MB_EMAIL_REPLY_TO"",""description"":""The email address you want the replies to go to, if different from the from address."",""default"":null,""originalValue"":[""some_testing_mail@metabase.com""],""display_name"":""Reply-To Address"",""type"":""string"",""required"":false,""validations"":[[""email_list"",""That's not a valid email address""]]}

paoliniluis on (2024-06-05 13:53:54 UTC): closing due to non-response

"
2145423903,issue,closed,completed,Accurate Error Messaging for Cross DB Joins in Notebook Editor,"**Is your feature request related to a problem? Please describe.**
In Metabase you can presently select tables or models from multiple databases and join them together in the GUI query builder. This behavior is not supported so it fails. The error provided is ""Card does not exists"".

**Describe the solution you'd like**
A more clear error message should be presented. Something like, ""Questions cannot be created using different database connections"".

**Additional context**
This is a common point of confusion because the error message is ambiguous.
",ixipixi,2024-02-20 22:49:33+00:00,['romeovs'],2024-07-02 11:39:22+00:00,2024-07-02 11:30:16+00:00,https://github.com/metabase/metabase/issues/38989,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 1998325487, 'issue_id': 2145423903, 'author': 'ixipixi', 'body': 'Related to:\r\n\r\n- https://github.com/metabase/metabase/issues/3953\r\n- https://github.com/metabase/metabase/issues/28699', 'created_at': datetime.datetime(2024, 3, 14, 20, 1, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2070982901, 'issue_id': 2145423903, 'author': 'mazameli', 'body': 'The fix here is that the user should not be presented with questions, models, or tables to join with except for ones originating from the same database as the initial data source.', 'created_at': datetime.datetime(2024, 4, 22, 21, 28, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2077351894, 'issue_id': 2145423903, 'author': 'ixipixi', 'body': ""@mazameli Totally agree. If it's going to be a while before that's done it would still be really valuable to present a useful error message in the interim, though."", 'created_at': datetime.datetime(2024, 4, 25, 14, 32, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200197903, 'issue_id': 2145423903, 'author': 'romeovs', 'body': ""I've put @mazameli's suggestion into a [separate issue](https://github.com/metabase/metabase/issues/44974) so we can keep this issue to be about the error message being vague.\r\n\r\nMoreover this issue was fixed in v50."", 'created_at': datetime.datetime(2024, 7, 1, 13, 42, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2202879338, 'issue_id': 2145423903, 'author': 'uladzimirdev', 'body': ""@romeovs could you please link the new issue with @mazameli's suggestions?"", 'created_at': datetime.datetime(2024, 7, 2, 11, 30, 16, tzinfo=datetime.timezone.utc)}]","ixipixi (Issue Creator) on (2024-03-14 20:01:22 UTC): Related to:

- https://github.com/metabase/metabase/issues/3953
- https://github.com/metabase/metabase/issues/28699

mazameli on (2024-04-22 21:28:23 UTC): The fix here is that the user should not be presented with questions, models, or tables to join with except for ones originating from the same database as the initial data source.

ixipixi (Issue Creator) on (2024-04-25 14:32:02 UTC): @mazameli Totally agree. If it's going to be a while before that's done it would still be really valuable to present a useful error message in the interim, though.

romeovs (Assginee) on (2024-07-01 13:42:45 UTC): I've put @mazameli's suggestion into a [separate issue](https://github.com/metabase/metabase/issues/44974) so we can keep this issue to be about the error message being vague.

Moreover this issue was fixed in v50.

uladzimirdev on (2024-07-02 11:30:16 UTC): @romeovs could you please link the new issue with @mazameli's suggestions?

"
2145393991,issue,open,,Results of MongoDB (version 6.0) joins between collections are different based whether primary keys or individual fields are used,"### Describe the bug

Joins between a nested field in the one collection, to the primary key in the second collection will not present the data of the second collection in Metabase.

### To Reproduce

Testing this on Mongo 6.0, not sure about other versions
<br />

1.) Let’s say you have two tables

**Customer Status**
<img width=""701"" alt=""Customer Status table"" src=""https://github.com/metabase/metabase/assets/17398657/e8653ba7-f396-4f6f-9c07-02eac96173ee"">


**Customers**
<img width=""906"" alt=""Customers table"" src=""https://github.com/metabase/metabase/assets/17398657/5af9e303-ec80-4af0-9616-26f8196c75d5"">



This is a representation of an object in the **Customers** collection to show the nested structure.
<img width=""456"" alt=""Customers object"" src=""https://github.com/metabase/metabase/assets/17398657/4bbe470f-03af-4cd8-9d8a-60504543632a"">


<br />
<br />


2.) Let's join the two tables on **Customers.Userid** and **CustomerStatus.ID**.
**CustomerStatus.ID** is the primary key for this object.

<img width=""324"" alt=""objectID1"" src=""https://github.com/metabase/metabase/assets/17398657/5a1da8c7-d7fc-41a6-83da-b1c6233fbeb9"">

<img width=""984"" alt=""JoinOne"" src=""https://github.com/metabase/metabase/assets/17398657/c974fe7f-3302-4025-8ab8-798f272d8f9e"">

<img width=""1419"" alt=""JoinsBlank"" src=""https://github.com/metabase/metabase/assets/17398657/ef14b503-6926-4009-8ded-328ec76b94f7"">

<br />
<br />

3.) Now, let’s join the tables again but on the **Customers.Userid** and **CustomerStatus.ItemID** column.
**CustomerStatus.ItemID** is a field which contains the same value as primary key.

<img width=""324"" alt=""ObjectID2"" src=""https://github.com/metabase/metabase/assets/17398657/c5c251bd-97d1-4985-9b24-3b584d37a1e5"">

<img width=""998"" alt=""JoinTwo"" src=""https://github.com/metabase/metabase/assets/17398657/c662e379-5e12-4622-bcbb-34760b4b433b"">

<img width=""1320"" alt=""JoinsFull"" src=""https://github.com/metabase/metabase/assets/17398657/ea1746ae-fc4c-41fb-9139-9d9fe8b2433d"">








### Expected behavior

Expecting the joins to return the same results but not sure if it's a limitation of MongoDB and drivers

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-12"",
      ""tag"": ""v1.48.6"",
      ""hash"": ""b8818f9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3 - I came across this while troubleshooting an issue for a customer and wanted to confirm whether it's a bug

### Additional context

_No response_",FilmonK,2024-02-20 22:24:24+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/38987,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Mongo', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2145007266,issue,open,,initial_sync_status is not updated per table on the initial sync and makes the tables inacessible for a long time,"### Describe the bug

When you try to sync a massive DB, the initial_sync_status field is not set to 'complete' till the end of the sync, which leads to tables not being available till the end of the sync (which can take hours)

### To Reproduce

1) add the massive database in the dev redshift cluster
2) see the app db on the metabase_table table (this query will show you the ones that are ready)
```
SELECT t.*
                 FROM public.metabase_table t
                 WHERE initial_sync_status='complete'
                 ORDER BY initial_sync_status
```

### Expected behavior

We should mark as ""completed"" the tables as soon as they're ready (sync'd, field sync'd, fingerprinted)

### Logs

NA

### Information about your Metabase installation

```JSON
it's been like this since... forever if I'm not mistaken
```


### Severity

P2

### Additional context

NA",paoliniluis,2024-02-20 18:23:21+00:00,[],2024-07-10 20:24:05+00:00,,https://github.com/metabase/metabase/issues/38973,"[('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Product/Pothole', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1954815465, 'issue_id': 2145007266, 'author': 'paoliniluis', 'body': ""@brunobergher I found this which might hit the testing of the product on big db's"", 'created_at': datetime.datetime(2024, 2, 20, 18, 24, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007829783, 'issue_id': 2145007266, 'author': 'calherries', 'body': 'spoke to Luiggi offline, we agreed this would be better than the status quo:\r\n1. a table should appear in the QB as soon as all their fields are synced, even without FKs being synced\r\n2. we should tell users that FK-enabled magic may not be working yet if they\'re using a database that hasn\'t finished syncing\r\n\r\nThe difficulty right now is that tables are set to be ""completed"" when their FKs are synced, but not every table has an FK.', 'created_at': datetime.datetime(2024, 3, 19, 18, 9, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007835407, 'issue_id': 2145007266, 'author': 'calherries', 'body': '@luizarakaki point (1) above is easy for me to do but (2) needs some product input.', 'created_at': datetime.datetime(2024, 3, 19, 18, 11, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2116531703, 'issue_id': 2145007266, 'author': 'calherries', 'body': 'worth noting this problem is eliminated by making sync faster by more DBs, similar to how we did for redshift https://github.com/metabase/metabase/issues/39986', 'created_at': datetime.datetime(2024, 5, 17, 2, 45, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221374556, 'issue_id': 2145007266, 'author': 'luizarakaki', 'body': ""Agreed that this should be better with faster sync.\n\nThis isn't really a bug. Updating sync_status per table would actually create a bug (missing FKs).\n\nI'll leave this as context for #45179, but I don't think we should update statuses per table."", 'created_at': datetime.datetime(2024, 7, 10, 20, 23, 57, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-20 18:24:30 UTC): @brunobergher I found this which might hit the testing of the product on big db's

calherries on (2024-03-19 18:09:15 UTC): spoke to Luiggi offline, we agreed this would be better than the status quo:
1. a table should appear in the QB as soon as all their fields are synced, even without FKs being synced
2. we should tell users that FK-enabled magic may not be working yet if they're using a database that hasn't finished syncing

The difficulty right now is that tables are set to be ""completed"" when their FKs are synced, but not every table has an FK.

calherries on (2024-03-19 18:11:29 UTC): @luizarakaki point (1) above is easy for me to do but (2) needs some product input.

calherries on (2024-05-17 02:45:44 UTC): worth noting this problem is eliminated by making sync faster by more DBs, similar to how we did for redshift https://github.com/metabase/metabase/issues/39986

luizarakaki on (2024-07-10 20:23:57 UTC): Agreed that this should be better with faster sync.

This isn't really a bug. Updating sync_status per table would actually create a bug (missing FKs).

I'll leave this as context for #45179, but I don't think we should update statuses per table.

"
2144735917,issue,open,,Custom homepage will not be dumped in serialization,"### Describe the bug

The new feature to pin a dashboard to the homepage won't be included in the serialization export

### To Reproduce

1) set up a dashboard as the home page
2) do an export
3) see the files

### Expected behavior

the setting should be dumped

### Logs

NA

### Information about your Metabase installation

```JSON
v47.x+, pretty sure we haven't added that to the serialization process
```


### Severity

P2

### Additional context

NA",paoliniluis,2024-02-20 16:09:33+00:00,[],2025-02-04 20:26:37+00:00,,https://github.com/metabase/metabase/issues/38969,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]",[],
2144635241,issue,open,,Optionally disable remarks on databases,"**Is your feature request related to a problem? Please describe.**
E.g. Some postgres extensions use the comments to signal the extension something https://github.com/ossc-db/pg_hint_plan, but as we send the remarks, then that tool becomes useless

**Describe the solution you'd like**
optionally disable the remarks, as we do with bigquery and athena

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a user

**Additional context**
NA
",paoliniluis,2024-02-20 15:23:53+00:00,[],2024-02-20 15:23:54+00:00,,https://github.com/metabase/metabase/issues/38968,"[('Database/', ''), ('Type:New Feature', '')]",[],
2144586908,issue,closed,completed,Illegal hex characters in escape (%) pattern - error at index 0 in: R6,"### Describe the bug

Seems there's some escaping issue in the new mongo driver
![image](https://github.com/metabase/metabase/assets/1711649/f13fd1bd-2a1f-4432-aaca-7a6d00f4ffee)


### To Reproduce

I don't know how to reproduce this, but popped up on a customer instance, but you can see the logs in the customer instance on the 20th of feb in our grafana instance

### Expected behavior

Should connect?

### Logs

```
2024-02-20 14:55:30.175	
2024-02-20 14:55:30,175 DEBUG middleware.log :: GET /api/embed/dashboard/XXX/dashcard/17/card/16 202 [ASYNC: completed] 44.0 ms (20 chamadas ao banco de dados) Conexões com o banco de dados: 2 / 15 Threads do Jetty: 3 / 50 (12 ocioso, 0 na fila) (137 total de threads ativas) Consultas ativas: 1 (0 na fila)

2024-02-20 14:55:30.175	

2024-02-20 14:55:30.175	
 :data {:rows [], :cols []}}
2024-02-20 14:55:30.175	
  :async? true},
2024-02-20 14:55:30.175	
   :order-by [[:asc [:field 4958 nil]]]},
2024-02-20 14:55:30.175	
       :name ""CompanyId""}]]],
2024-02-20 14:55:30.175	
       :database_type ""org.bson.types.ObjectId"",
2024-02-20 14:55:30.175	
       :semantic_type :type/Category,
2024-02-20 14:55:30.175	
       :coercion_strategy nil,
2024-02-20 14:55:30.175	
       :effective_type :type/MongoBSONID,
2024-02-20 14:55:30.175	
      {:base_type :type/MongoBSONID,
2024-02-20 14:55:30.175	
      ""588f2e77ba57d02cc837589d""
2024-02-20 14:55:30.175	
     [:value
2024-02-20 14:55:30.175	
     [:field 5007 nil]
2024-02-20 14:55:30.175	
    [:=
2024-02-20 14:55:30.175	
        :name ""Status""}]]]
2024-02-20 14:55:30.175	
        :database_type ""java.lang.Integer"",
2024-02-20 14:55:30.175	
        :semantic_type :type/Category,
2024-02-20 14:55:30.175	
        :coercion_strategy nil,
2024-02-20 14:55:30.175	
        :effective_type :type/Integer,
2024-02-20 14:55:30.175	
       {:base_type :type/Integer,
2024-02-20 14:55:30.175	
       1
2024-02-20 14:55:30.175	
      [:value
2024-02-20 14:55:30.175	
      [:field 4958 nil]
2024-02-20 14:55:30.174	
     [:=
2024-02-20 14:55:30.174	
        :name ""Status""}]]
2024-02-20 14:55:30.174	
        :database_type ""java.lang.Integer"",
2024-02-20 14:55:30.174	
        :semantic_type :type/Category,
2024-02-20 14:55:30.174	
        :coercion_strategy nil,
2024-02-20 14:55:30.174	
        :effective_type :type/Integer,
2024-02-20 14:55:30.174	
       {:base_type :type/Integer,
2024-02-20 14:55:30.174	
       7
2024-02-20 14:55:30.174	
      [:value
2024-02-20 14:55:30.174	
      [:field 4958 nil]
2024-02-20 14:55:30.174	
     [:=
2024-02-20 14:55:30.174	
        :name ""Status""}]]
2024-02-20 14:55:30.174	
        :database_type ""java.lang.Integer"",
2024-02-20 14:55:30.174	
        :semantic_type :type/Category,
2024-02-20 14:55:30.174	
        :coercion_strategy nil,
2024-02-20 14:55:30.174	
        :effective_type :type/Integer,
2024-02-20 14:55:30.174	
       {:base_type :type/Integer,
2024-02-20 14:55:30.174	
       9
2024-02-20 14:55:30.174	
      [:value
2024-02-20 14:55:30.174	
      [:field 4958 nil]
2024-02-20 14:55:30.174	
     [:=
2024-02-20 14:55:30.174	
        :name ""Status""}]]
2024-02-20 14:55:30.174	
        :database_type ""java.lang.Integer"",
2024-02-20 14:55:30.174	
        :semantic_type :type/Category,
2024-02-20 14:55:30.174	
        :coercion_strategy nil,
2024-02-20 14:55:30.174	
        :effective_type :type/Integer,
2024-02-20 14:55:30.174	
       {:base_type :type/Integer,
2024-02-20 14:55:30.174	
       0
2024-02-20 14:55:30.174	
      [:value
2024-02-20 14:55:30.174	
      [:field 4958 nil]
2024-02-20 14:55:30.174	
     [:=
2024-02-20 14:55:30.174	
    [:or
2024-02-20 14:55:30.174	
   [:and
2024-02-20 14:55:30.174	
   :filter
2024-02-20 14:55:30.174	
   :breakout [[:field 4958 nil]],
2024-02-20 14:55:30.174	
   :aggregation [[:aggregation-options [:count] {:name ""count""}]],
2024-02-20 14:55:30.174	
  {:source-table 72,
2024-02-20 14:55:30.174	
  :query
2024-02-20 14:55:30.174	
  :database 2,
2024-02-20 14:55:30.174	
    :pie.percent-visibility ""inside""}},
2024-02-20 14:55:30.174	
    :series-settings {:count {:display ""bar""}},
2024-02-20 14:55:30.174	
    :graph.show-values true,
2024-02-20 14:55:30.174	
    :graph.y-axis.labels-enabled false,
2024-02-20 14:55:30.174	
    :pie.show-legend true,
2024-02-20 14:55:30.174	
    :graph.show-goal false,
2024-02-20 14:55:30.174	
    :pie.slice-threshold 2.5,
2024-02-20 14:55:30.174	
    :graph.x-axis.labels-enabled true,
2024-02-20 14:55:30.174	
   {:graph.y-axis.auto-range true,
2024-02-20 14:55:30.174	
   :visualization-settings
2024-02-20 14:55:30.174	
   :dashboard-id 2,
2024-02-20 14:55:30.174	
   :card-name ""Total em andamento"",
2024-02-20 14:55:30.174	
   :card-id 16,
2024-02-20 14:55:30.174	
  {:context :embedded-dashboard,
2024-02-20 14:55:30.174	
  :info
2024-02-20 14:55:30.174	
   :graph.y_axis.auto_range true},
2024-02-20 14:55:30.174	
   :series_settings {:count {:display ""bar"", :axis nil}},
2024-02-20 14:55:30.174	
   :pie.show_legend true,
2024-02-20 14:55:30.174	
   :card.title ""Em Andamento"",
2024-02-20 14:55:30.174	
   :graph.y_axis.labels_enabled false,
2024-02-20 14:55:30.174	
   :graph.x_axis.labels_enabled true,
2024-02-20 14:55:30.174	
   :pie.percent_visibility ""inside"",
2024-02-20 14:55:30.174	
   :pie.slice_threshold 2.5,
2024-02-20 14:55:30.174	
   :graph.show_values true,
2024-02-20 14:55:30.174	
  {:graph.show_goal false,
2024-02-20 14:55:30.174	
  :viz-settings
2024-02-20 14:55:30.174	
  :middleware {:js-int-to-string? true, :ignore-cached-results? false},
2024-02-20 14:55:30.174	
  :type :query,
2024-02-20 14:55:30.174	
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
2024-02-20 14:55:30.174	
 :preprocessed
2024-02-20 14:55:30.174	
 :running_time 0,
2024-02-20 14:55:30.174	
 :row_count 0,
2024-02-20 14:55:30.174	
 :error ""URLDecoder: Illegal hex characters in escape (%) pattern - Error at index 0 in: \""R6\"""",
2024-02-20 14:55:30.174	
 :context :embedded-dashboard,
2024-02-20 14:55:30.174	
 :card_id 16,
2024-02-20 14:55:30.174	
  ""query_processor.reducible$async_qp$qp_STAR___60724$fn__60728.invoke(reducible.clj:131)""],
2024-02-20 14:55:30.174	
  ""query_processor.reducible$async_qp$qp_STAR___60724$thunk__60726.invoke(reducible.clj:126)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__71579.invoke(catch_exceptions.clj:171)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__70989.invoke(process_userland_query.clj:156)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__69628.invoke(constraints.clj:102)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__70704.invoke(enterprise.clj:103)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.enterprise$fn__70693$handle_audit_app_internal_queries__70694$fn__70696.invoke(enterprise.clj:96)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.normalize_query$normalize$fn__71058.invoke(normalize_query.clj:38)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__70753.invoke(resolve_database_and_driver.clj:60)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.store$initialize_store$fn__65543.invoke(store.clj:13)""
2024-02-20 14:55:30.174	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-02-20 14:55:30.174	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
2024-02-20 14:55:30.174	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-02-20 14:55:30.174	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.store$initialize_store$fn__65543$fn__65544.invoke(store.clj:14)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70756.invoke(resolve_database_and_driver.clj:76)""
2024-02-20 14:55:30.174	
  ""driver$do_with_driver.invoke(driver.clj:89)""
2024-02-20 14:55:30.174	
  ""driver$do_with_driver.invokeStatic(driver.clj:94)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70756$fn__70760.invoke(resolve_database_and_driver.clj:77)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65151.invoke(fetch_source_query.clj:303)""
2024-02-20 14:55:30.174	
  ""query_processor$fn__71979$combined_pre_process__71980$combined_pre_process_STAR___71981.invoke(query_processor.clj:259)""
2024-02-20 14:55:30.174	
  ""query_processor$fn__71979$combined_post_process__71984$combined_post_process_STAR___71985.invoke(query_processor.clj:262)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__69913.invoke(mbql_to_native.clj:24)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__70676.invoke(enterprise.clj:64)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__70666.invoke(enterprise.clj:51)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.permissions$check_query_permissions$fn__65054.invoke(permissions.clj:140)""
2024-02-20 14:55:30.174	
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70845.invoke(cache.clj:229)""
2024-02-20 14:55:30.174	
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
2024-02-20 14:55:30.174	
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
2024-02-20 14:55:30.174	
  ""query_processor.context$runf.invoke(context.clj:40)""
2024-02-20 14:55:30.174	
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
2024-02-20 14:55:30.174	
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
2024-02-20 14:55:30.174	
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
2024-02-20 14:55:30.174	
  ""query_processor.context$executef.invoke(context.clj:49)""
2024-02-20 14:55:30.174	
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
2024-02-20 14:55:30.174	
  ""driver.mongo$fn__126856.invoke(mongo.clj:296)""
2024-02-20 14:55:30.174	
  ""driver.mongo$fn__126856.invokeStatic(mongo.clj:298)""
2024-02-20 14:55:30.174	
  ""driver.mongo.connection$do_with_mongo_client.invoke(connection.clj:81)""
2024-02-20 14:55:30.174	
  ""driver.mongo.connection$do_with_mongo_client.invokeStatic(connection.clj:85)""
2024-02-20 14:55:30.174	
  ""util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:151)""
2024-02-20 14:55:30.174	
  ""util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:162)""
2024-02-20 14:55:30.174	
  ""driver.mongo.connection$do_with_mongo_client$fn__123107.invoke(connection.clj:86)""
2024-02-20 14:55:30.174	
  ""driver.mongo.connection$db_details__GT_mongo_client_settings.invoke(connection.clj:66)""
2024-02-20 14:55:30.174	
  ""--> driver.mongo.connection$db_details__GT_mongo_client_settings.invokeStatic(connection.clj:72)""
2024-02-20 14:55:30.174	
  ""com.mongodb.ConnectionString.<init>(ConnectionString.java:321)""
2024-02-20 14:55:30.174	
  ""com.mongodb.ConnectionString.<init>(ConnectionString.java:387)""
2024-02-20 14:55:30.174	
  ""com.mongodb.ConnectionString.urldecode(ConnectionString.java:1239)""
2024-02-20 14:55:30.174	
  ""java.base/java.net.URLDecoder.decode(Unknown Source)""
2024-02-20 14:55:30.174	
 [""java.base/java.net.URLDecoder.decode(Unknown Source)""
2024-02-20 14:55:30.174	
 :stacktrace
2024-02-20 14:55:30.174	
 :class java.lang.IllegalArgumentException,
2024-02-20 14:55:30.174	
 :status :failed,
2024-02-20 14:55:30.174	
  :mbql? true},
2024-02-20 14:55:30.174	
  :collection ""ServiceOrder"",
2024-02-20 14:55:30.174	
   {""$project"" {""_id"" false, ""Status"" ""$_id.Status"", ""count"" true}}],
2024-02-20 14:55:30.174	
   {""$sort"" {""_id"" 1}}
2024-02-20 14:55:30.174	
   {""$group"" {""_id"" {""Status"" ""$Status""}, ""count"" {""$sum"" 1}}}
2024-02-20 14:55:30.174	
      {""CompanyId"" #object[org.bson.types.ObjectId 0x55887226 ""588f2e77ba57d02cc837589d""]}]}}
2024-02-20 14:55:30.174	
     [{""$or"" [{""Status"" 0} {""Status"" 9} {""Status"" 7} {""Status"" 1}]}
2024-02-20 14:55:30.174	
    {""$and""
2024-02-20 14:55:30.174	
  [{""$match""
2024-02-20 14:55:30.174	
  :query
2024-02-20 14:55:30.174	
 {:projections [""Status"" ""count""],
2024-02-20 14:55:30.174	
 :native
2024-02-20 14:55:30.174	
  :cache-ttl nil},
2024-02-20 14:55:30.174	
  :async? true,
2024-02-20 14:55:30.174	
  :parameters [],
2024-02-20 14:55:30.174	
   :filter [:and [:= [:field 4958 nil] 0 9 7 1] [:= [:field 5007 nil] ""588f2e77ba57d02cc837589d""]]},
2024-02-20 14:55:30.174	
   :breakout [[:field 4958 nil]],
2024-02-20 14:55:30.174	
   :aggregation [[:count]],
2024-02-20 14:55:30.174	
  {:source-table 72,
2024-02-20 14:55:30.174	
  :query
2024-02-20 14:55:30.174	
  :database 2,
2024-02-20 14:55:30.174	
   :graph.y_axis.auto_range true},
2024-02-20 14:55:30.174	
   :series_settings {:count {:display ""bar"", :axis nil}},
2024-02-20 14:55:30.174	
   :pie.show_legend true,
2024-02-20 14:55:30.174	
   :card.title ""Em Andamento"",
2024-02-20 14:55:30.174	
   :graph.y_axis.labels_enabled false,
2024-02-20 14:55:30.174	
   :graph.x_axis.labels_enabled true,
2024-02-20 14:55:30.174	
   :pie.percent_visibility ""inside"",
2024-02-20 14:55:30.174	
   :pie.slice_threshold 2.5,
2024-02-20 14:55:30.174	
   :graph.show_values true,
2024-02-20 14:55:30.174	
  {:graph.show_goal false,
2024-02-20 14:55:30.174	
  :viz-settings
2024-02-20 14:55:30.174	
  :middleware {:js-int-to-string? true, :ignore-cached-results? false},
2024-02-20 14:55:30.174	
  :type :query,
2024-02-20 14:55:30.174	
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
2024-02-20 14:55:30.174	
 :json_query
2024-02-20 14:55:30.174	
 :action_id nil,
2024-02-20 14:55:30.174	
 :started_at #t ""2024-02-20T14:55:30.148703Z[GMT]"",
2024-02-20 14:55:30.174	
{:database_id 2,
2024-02-20 14:55:30.174	
2024-02-20 14:55:30,174 ERROR middleware.catch-exceptions :: Erro ao processar a consulta: URLDecoder: Illegal hex characters in escape (%) pattern - Error at index 0 in: ""R6""
```

### Information about your Metabase installation

```JSON
v48.6
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-02-20 15:02:08+00:00,['lbrdnk'],2024-04-19 16:12:07+00:00,2024-04-19 16:12:06+00:00,https://github.com/metabase/metabase/issues/38966,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.')]","[{'comment_id': 1954407434, 'issue_id': 2144586908, 'author': 'paoliniluis', 'body': 'tagging @lbrdnk', 'created_at': datetime.datetime(2024, 2, 20, 15, 2, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1980471055, 'issue_id': 2144586908, 'author': 'vviers', 'body': 'Hello ! Any update on this ? :) this happened to one of our users as well', 'created_at': datetime.datetime(2024, 3, 6, 9, 45, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 1981001480, 'issue_id': 2144586908, 'author': 'vviers', 'body': 'Reverting to 0.48.4 solved the issue for us', 'created_at': datetime.datetime(2024, 3, 6, 14, 31, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-20 15:02:25 UTC): tagging @lbrdnk

vviers on (2024-03-06 09:45:58 UTC): Hello ! Any update on this ? :) this happened to one of our users as well

vviers on (2024-03-06 14:31:41 UTC): Reverting to 0.48.4 solved the issue for us

"
2144471456,issue,closed,completed,[Epic] Add Extract action to chill mode column headings,"# Links

- [Product doc](https://www.notion.so/metabase/Add-Extract-action-to-chill-mode-column-headings-14867dac1e934ba2bde66671f845f3f9)
- [Eng doc](https://www.notion.so/metabase/Add-Extract-action-to-chill-mode-column-headings-technical-design-doc-0ca8f957d8b94d4b91159629b73ff2e4?pvs=4)
- [Figma](https://www.figma.com/file/yl8Yy4iMSpaWzjuNoEjBZu/Add-Extract-action-to-chill-mode-column-headings?type=design&node-id=5916%3A4721&mode=design&t=RD83L36AiFte8U4m-1)
- [Figma prototype](https://www.figma.com/proto/yl8Yy4iMSpaWzjuNoEjBZu/Add-Extract-action-to-chill-mode-column-headings?page-id=5916%3A13164&type=design&node-id=5916-4722&viewport=-7634%2C-1321%2C0.14&t=ny68qzp6zpbyeWLZ-1&scaling=contain&starting-point-node-id=5916%3A4722&mode=design)
- [Testing plan](https://github.com/metabase/metabase/issues/39291)
- feature branch: TBD

# Implementation Plan

## Milestone 1 - Date/time columns

Milestone 1 should only cover datetime extractions, specifically the following 6 (see [Figma](https://www.figma.com/file/yl8Yy4iMSpaWzjuNoEjBZu/Add-Extract-action-to-chill-mode-column-headings?type=design&node-id=5916-4957&mode=design&t=0TXjT9JJUxyx3k9k-4)):
- Hour of day
- Day of month
- Day of week
- Month
- Quarter
- Year

```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/pull/39162
- [ ] https://github.com/metabase/metabase/issues/40125
```

```[tasklist]
### Frontend
- [ ] https://github.com/metabase/metabase/issues/39248
- [ ] https://github.com/metabase/metabase/pull/39770
- [ ] https://github.com/metabase/metabase/issues/39982
```

## Milestone 2 - URL columns

Splitting up URLs to extract the (sub)domain(s) is not a simple task. There are libraries for it but they're complex, and we can't push those into the data warehouse anyway. I think we'll have to do the best we can with a `regexextract` so that it can be handled at the database level.

Estimate: 0.5 to 1 day to write and heavily test the regexes; plus a bit to integrate the new type into the `column-extract` drill.

```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/pull/40188
```

## Milestone 3 - Email columns

Extracting the host after the `@` is straightfoward. Going from there to the domain can reuse the regex from Milestone 2.

Estimate: 0.5 days to build the email regex and integrate into the `column-extract` drill.

```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/pull/40200
```",kamilmielnik,2024-02-20 14:11:03+00:00,"['bshepherdson', 'kamilmielnik', 'ranquild']",2024-03-19 16:19:56+00:00,2024-03-19 16:19:55+00:00,https://github.com/metabase/metabase/issues/38964,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]","[{'comment_id': 2007612416, 'issue_id': 2144471456, 'author': 'bshepherdson', 'body': 'This has all landed in master and has a :+1: from PMs.', 'created_at': datetime.datetime(2024, 3, 19, 16, 19, 55, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-03-19 16:19:55 UTC): This has all landed in master and has a :+1: from PMs.

"
2144463438,issue,open,,"move ""Custom homepage"" to whitelabelling section","**Is your feature request related to a problem? Please describe.**
I wasn't able to find that config, and then I found it was on the ""general"" section, why don't we move it to the appearance section?

**Describe the solution you'd like**
Move the custom homepage thing to the appearance section

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
NA

**Additional context**
NA
",paoliniluis,2024-02-20 14:07:07+00:00,[],2024-05-21 13:28:19+00:00,,https://github.com/metabase/metabase/issues/38963,"[('Type:New Feature', ''), ('Administration/Whitelabel', 'Enterprise white labelling'), ('.Team/Embedding', ''), ('Organization/Homepage', '')]",[],
2144392550,issue,closed,completed,Add entity-id to Serdes v1 as an optional flag,"**Context**
As we introduced entity-ids before releasing Serdes v2, some customers are facing problems to upgrade to Serdes v2.
[Thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1708378329446559)

The solutions is
1.v1 dump and load will copy the source's new entity_ids, but use v1's matching of source and target entities (which is presumably working okay for them and doesn't care about entity_ids)

now they have matching entity_ids so v2 works fine.

To make this happen, v1 must transfer entity-ids and overwrite the target entity-ids if they exist.
It should be added behind a flag --include-entity-id to both dump and load commands

This should be backported to 47 and 48.
",luizarakaki,2024-02-20 13:31:46+00:00,['piranha'],2024-03-04 17:18:16+00:00,2024-03-04 14:27:01+00:00,https://github.com/metabase/metabase/issues/38961,"[('Operation/Serialization', 'Enterprise contents migration'), ('.Escalation', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1956818047, 'issue_id': 2144392550, 'author': 'Tony-metabase', 'body': 'Leaving comment so I know about updates', 'created_at': datetime.datetime(2024, 2, 21, 14, 49, 1, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-02-21 14:49:01 UTC): Leaving comment so I know about updates

"
2144281845,issue,closed,completed,CSV upload fails on rows with float type among mostly integer values,https://metaboat.slack.com/archives/C04S696LRUM/p1707242309280519?thread_ts=1707238777.488509&cid=C04S696LRUM,calherries,2024-02-20 12:36:29+00:00,['crisptrutski'],2024-03-10 21:29:09+00:00,2024-03-08 18:02:58+00:00,https://github.com/metabase/metabase/issues/38958,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1977473169, 'issue_id': 2144281845, 'author': 'crisptrutski', 'body': 'I think that the issue here is that we infer the schema based on a [subset](https://github.com/metabase/metabase/blob/ddfd9f636072034b9bff9681f3391ad17ee39b60/src/metabase/upload.clj#L340) of the rows, and are missing the sparse float values.\r\n\r\nThe solution for this will build on https://github.com/metabase/metabase/issues/37069', 'created_at': datetime.datetime(2024, 3, 4, 21, 18, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1984620664, 'issue_id': 2144281845, 'author': 'crisptrutski', 'body': ""The issue was indeed the row sampling. \r\n\r\nWith the optimized inference method there's no longer any need to do the sampling, and the reference file loads correctly.\r\n\r\nThe merge for the fix is just waiting behind the implicit int to float column promotion PR."", 'created_at': datetime.datetime(2024, 3, 7, 22, 19, 47, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-03-04 21:18:12 UTC): I think that the issue here is that we infer the schema based on a [subset](https://github.com/metabase/metabase/blob/ddfd9f636072034b9bff9681f3391ad17ee39b60/src/metabase/upload.clj#L340) of the rows, and are missing the sparse float values.

The solution for this will build on https://github.com/metabase/metabase/issues/37069

crisptrutski (Assginee) on (2024-03-07 22:19:47 UTC): The issue was indeed the row sampling. 

With the optimized inference method there's no longer any need to do the sampling, and the reference file loads correctly.

The merge for the fix is just waiting behind the implicit int to float column promotion PR.

"
2144252080,issue,closed,completed,Uploads: 01/01/2012 is coerced to 1,"Description
Where we would silently coerce date strings to integers when parsing them as such.

https://metaboat.slack.com/archives/C04S696LRUM/p1704753306415639?thread_ts=1704728142.909629&cid=C04S696LRUM",calherries,2024-02-20 12:20:47+00:00,['crisptrutski'],2024-03-14 12:24:52+00:00,2024-03-06 13:52:58+00:00,https://github.com/metabase/metabase/issues/38956,[],[],
2144250633,issue,closed,completed,BE: better append error formatting [discussion],https://metaboat.slack.com/archives/C04S696LRUM/p1705937808084499?thread_ts=1704910787.767239&cid=C04S696LRUM,calherries,2024-02-20 12:19:58+00:00,['crisptrutski'],2024-03-08 19:24:34+00:00,2024-03-06 20:54:45+00:00,https://github.com/metabase/metabase/issues/38955,[],"[{'comment_id': 1977786364, 'issue_id': 2144250633, 'author': 'crisptrutski', 'body': 'The gist is to replace error responses with a markdown body, like the following:\r\n\r\n```markdown\r\nThe CSV file contains extra columns that are not in the table:\r\n- column_name\r\n- …\r\n\r\nThe CSV file is missing columns that are in the table:\r\n- column_name\r\n- …\r\n```', 'created_at': datetime.datetime(2024, 3, 5, 1, 39, 10, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-03-05 01:39:10 UTC): The gist is to replace error responses with a markdown body, like the following:

```markdown
The CSV file contains extra columns that are not in the table:
- column_name
- …

The CSV file is missing columns that are in the table:
- column_name
- …
```

"
2144231638,issue,closed,completed,[MLv2] fromLegacyQuery drops invalid expressions,"**Context**

`fromLegacyQuery` drops valid expression and returns incorrect result

<img width=""853"" alt=""Screenshot 2024-02-20 at 14 58 30"" src=""https://github.com/metabase/metabase/assets/125459446/dcf90d2a-bd43-4102-933a-975ec7c3807e"">

### Steps to reproduce

```
Lib.fromLegacyQuery(
        databaseId,
        metadata,
        this.datasetQuery(),
      );
```

content of `this.datasetQuery()`

```
{
    ""database"": 1,
    ""type"": ""query"",
    ""query"": {
        ""source-table"": 6,
        ""expressions"": {
            ""333"": [
                ""case"",
                [
                    [
                        [
                            ""is-empty"",
                            [
                                ""field"",
                                5,
                                {
                                    ""base-type"": ""type/Boolean""
                                }
                            ]
                        ],
                        ""true""
                    ]
                ],
                {
                    ""default"": ""false""
                }
            ]
        }
    }
}
```

and MLv2 query was 
<img width=""872"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/86ea2346-9bf9-40be-96f0-a4d965935041"">


- issue links: https://github.com/metabase/metabase/issues/38944",uladzimirdev,2024-02-20 12:09:27+00:00,"['metamben', 'uladzimirdev']",2024-08-28 02:12:18+00:00,2024-03-01 16:26:46+00:00,https://github.com/metabase/metabase/issues/38954,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Team/Querying', '')]","[{'comment_id': 1954135870, 'issue_id': 2144231638, 'author': 'uladzimirdev', 'body': '<img width=""1158"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/5e451283-b023-4e36-9acc-4627ea26f1bf"">', 'created_at': datetime.datetime(2024, 2, 20, 12, 41, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1954373673, 'issue_id': 2144231638, 'author': 'metamben', 'body': 'The issue is that for boolean expressions we don\'t like `""is-empty""`. `""is-null""` would work. MLv2 accepts `""is-empty""` for locations, text and text-like values. In many cases the `""is-null""` gets the display name `""is-empty""` anyway.\r\n\r\n@uladzimirdev is it viable for the FE to use `""is-null""` for boolean values?', 'created_at': datetime.datetime(2024, 2, 20, 14, 47, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 1957111492, 'issue_id': 2144231638, 'author': 'metamben', 'body': 'This thing has never worked properly. With MLv1, it was possible to create queries calling `isempty` on a number, but the execution would fail. Now, the invalid clause gets silently thrown away.\r\n\r\nA possible short term solution is to implement a new MLv2 function doing type checking. (The long term solution is porting the editor/parser to MLv2 completely.) The signature of the new function could be something like\r\n\r\n```typescript\r\ndiagnoseExpression(\r\n  query: Lib.Query,\r\n  stageIndex: number,\r\n  expressionMode: ""expression"" | ""aggregation"" | ""filter"",\r\n  mbql: any,\r\n  expressionPosition?: number,\r\n): ErrorWithMessage | null\r\n\r\ntype ErrorWithMessage = {\r\n  message: string; // cannot highlight \r\n};\r\n```\r\n- `mbql` is a legacy MBQL expression like `[""is-empty"", [""field"", 1, null]]`\r\n- `expressionMode` specifies what  type of thing `mbql` is: an expression (custom column), an aggregation expression, or a filter condition.\r\n- `expressionPosition` is only defined when editing an existing custom column and in that case it is the index of that expression in `expressions(query, stageIndex)`. It can be used to detect cyclic references.\r\n- the function returns `null`, if the expression is valid, otherwise it returns a message describing the problem.', 'created_at': datetime.datetime(2024, 2, 21, 16, 5, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 1965315380, 'issue_id': 2144231638, 'author': 'metamben', 'body': 'The BE change has to be integrated to solve the problem.', 'created_at': datetime.datetime(2024, 2, 26, 21, 23, 18, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-02-20 12:41:57 UTC): <img width=""1158"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/5e451283-b023-4e36-9acc-4627ea26f1bf"">

metamben (Assginee) on (2024-02-20 14:47:56 UTC): The issue is that for boolean expressions we don't like `""is-empty""`. `""is-null""` would work. MLv2 accepts `""is-empty""` for locations, text and text-like values. In many cases the `""is-null""` gets the display name `""is-empty""` anyway.

@uladzimirdev is it viable for the FE to use `""is-null""` for boolean values?

metamben (Assginee) on (2024-02-21 16:05:43 UTC): This thing has never worked properly. With MLv1, it was possible to create queries calling `isempty` on a number, but the execution would fail. Now, the invalid clause gets silently thrown away.

A possible short term solution is to implement a new MLv2 function doing type checking. (The long term solution is porting the editor/parser to MLv2 completely.) The signature of the new function could be something like

```typescript
diagnoseExpression(
  query: Lib.Query,
  stageIndex: number,
  expressionMode: ""expression"" | ""aggregation"" | ""filter"",
  mbql: any,
  expressionPosition?: number,
): ErrorWithMessage | null

type ErrorWithMessage = {
  message: string; // cannot highlight 
};
```
- `mbql` is a legacy MBQL expression like `[""is-empty"", [""field"", 1, null]]`
- `expressionMode` specifies what  type of thing `mbql` is: an expression (custom column), an aggregation expression, or a filter condition.
- `expressionPosition` is only defined when editing an existing custom column and in that case it is the index of that expression in `expressions(query, stageIndex)`. It can be used to detect cyclic references.
- the function returns `null`, if the expression is valid, otherwise it returns a message describing the problem.

metamben (Assginee) on (2024-02-26 21:23:18 UTC): The BE change has to be integrated to solve the problem.

"
2144106247,issue,open,,Metabase 0.48.6 SQL Query Issue with Temp/Derived tables,"### Describe the bug

I upgraded to Metabase 0.48.6 last night, since then a few of my dashboards are broken where I am using SQL queries. 
Editing the query and commenting an unnecessary line out returns the correct result, removing the comment, and therefore adding the line back in returns the correct result. Saving the query and going back to the dashboard yet again gives me an incorrect result. 
Copy the query into a new SQL Query (question) provides the correct result, saving it and adding it next to the other query on the dashboard shows different results for the same query. 

### To Reproduce

Please see screenshots for steps (gif files)

The query:

Select distinct
	a.ID
	,submax.LatestDate	
	,submax.MACaddress
	,Coalesce(a.Sitekey,m.Sitekey) as Sitekey
    ,m.GUID
	into #abc
    from dbo.Assets a with (NOLOCK)
    inner join 
    (
        Select distinct max(CreateDate) as LatestDate, MACAddress
        from dbo.Assets with (nolock) 
        Group by MACAddress
    ) SubMax 
    on a.CreateDate = SubMax.LatestDate
    and a.MACAddress = SubMax.MACAddress
	
	left join dbo.main m on a.id = m.id
	--left outer join Heartbeat.dbo.SoftwareProfile s with (nolock) on s.id = m.ID  and s.name = 'DXS Components'
	where Coalesce(a.Sitekey,m.Sitekey) is not null 
	and a.CreateDate > DateAdd(month, -1, getdate())
	--and s.Version = '5.7.0.26'

	Select count(distinct a.MACAddress) as '5.7.0.26'
	from #abc a
	left outer join Heartbeat.dbo.SoftwareProfile s with (nolock) on s.id = a.ID  and s.name = 'DXS Components'
	where s.Version = '5.7.0.26'		
	
	drop table #abc

### Expected behavior

When you add the SQL query, or edit the query it should display the correct number, which is approximately 1378. Instead it displays a random number approximately 110. 

### Logs

No log entries for the time that the issue occurred

### Information about your Metabase installation

```JSON
Chrome Version 121.0.6167.185 (Official Build) (64-bit)
Client OS: Windows 11
Database: MSSQL 2019
Metabase 0.48.6
Metabase internal database: Postgress
Metabase Hosted OS: Windows Server 2019
```


### Severity

Blocking usage. Results are not trusted

### Additional context

![Metabase Bug 1](https://github.com/metabase/metabase/assets/38973757/7ee793d8-37b7-4da5-8894-8b5194e98cd1)
![Metabase Bug 2](https://github.com/metabase/metabase/assets/38973757/2cfe0d5a-7c39-4787-9696-a305deeced3c)
",HentiedeVries,2024-02-20 10:58:41+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/38952,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/SQLServer', None), ('Reporting/Dashboards', ''), ('Querying/Processor', ''), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 1954245068, 'issue_id': 2144106247, 'author': 'paoliniluis', 'body': 'Why are you doing DML? Can’t you just do a select?', 'created_at': datetime.datetime(2024, 2, 20, 13, 43, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 1954259931, 'issue_id': 2144106247, 'author': 'HentiedeVries', 'body': ""I've changed the query to select ... from (select ....) and that seems to work. However, this is still a bug. (Also, no, cant do a DML ;-) )"", 'created_at': datetime.datetime(2024, 2, 20, 13, 51, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197282575, 'issue_id': 2144106247, 'author': 'perivamsi', 'body': 'Downgrading this to a P2 based on the scope and the version of the bug', 'created_at': datetime.datetime(2024, 6, 28, 16, 34, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-20 13:43:17 UTC): Why are you doing DML? Can’t you just do a select?

HentiedeVries (Issue Creator) on (2024-02-20 13:51:38 UTC): I've changed the query to select ... from (select ....) and that seems to work. However, this is still a bug. (Also, no, cant do a DML ;-) )

perivamsi on (2024-06-28 16:34:24 UTC): Downgrading this to a P2 based on the scope and the version of the bug

"
2144001211,issue,open,,Have the ability to view full table name when selecting tables in question UI editor,"**Is your feature request related to a problem? Please describe.**
We have a lot of tables with similar names, where the end part makes the difference. 
For example in the screenshot below, the two tables are about the same data. But at the end, one is having 'state_current' and one is 'state_monthly'. This is a big difference for the user.

Currently I just select the first one, see if it is the right table. And if not I try the other one.

Sometimes we have more than two tables with the same start. This makes it very frustrating for the end user.

<img width=""1211"" alt=""image"" src=""https://github.com/metabase/metabase/assets/100769490/35c327ec-502f-4295-a57b-dd4c0e845ae7"">


**Describe the solution you'd like**
It would be great if the popup is bigger, or if there is an possiblity to make it bigger. 
Another simple solution could be to show the full name when hoovering over.

**How important is this feature to you?**
It is really frustrating, but ofcourse we can work without. Just try and error everytime.
Although I think this can be fixed quite easily

",m-matthes,2024-02-20 10:04:03+00:00,[],2025-02-04 20:30:26+00:00,,https://github.com/metabase/metabase/issues/38950,"[('Type:New Feature', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder')]",[],
2143935948,issue,closed,not_planned,Added the ability to download data to publicly shared dashboards,"![image](https://github.com/metabase/metabase/assets/35259040/c4d1fea6-3903-47b0-84d8-1c215778f25e)

The dashboard of the system's public link can have the function of downloading results as shown above.",Avey777,2024-02-20 09:29:47+00:00,[],2024-02-20 17:53:58+00:00,2024-02-20 17:53:58+00:00,https://github.com/metabase/metabase/issues/38949,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 1954759119, 'issue_id': 2143935948, 'author': 'ignacio-mb', 'body': 'Dupe of https://github.com/metabase/metabase/issues/6687', 'created_at': datetime.datetime(2024, 2, 20, 17, 53, 58, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-02-20 17:53:58 UTC): Dupe of https://github.com/metabase/metabase/issues/6687

"
2143327950,issue,closed,completed,"Custom column disappears after creating with case(isempty([Some Column]), ""true"", ""false"")","### Describe the bug

Creating a custom column like:
- `case(isempty([Some Column]), ""true"", ""false"")`
- disappears after clicking Done.

### To Reproduce

1. Create a new question using the Sample Database > Accounts table
2. Add a custom column `case(isempty([Active Subscription] ),""true"",""false"")` called ""active subscription is empty""
3. Click Done
4. No custom column appears

### Expected behavior

Custom column should appear after creating it

### Logs

No errors, warnings, or messages in logs.

### Information about your Metabase installation

- `master` as of `f509213`


### Severity

P1: Major functionality not working, regression in `master`

### Additional context

_No response_",likeshumidity,2024-02-20 00:31:57+00:00,['uladzimirdev'],2024-03-05 13:18:59+00:00,2024-03-01 16:26:46+00:00,https://github.com/metabase/metabase/issues/38944,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Needs Triage', ''), ('Querying/Notebook/Custom Column', ''), ('Querying/Notebook/Custom Expression', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature')]","[{'comment_id': 1965310986, 'issue_id': 2143327950, 'author': 'metamben', 'body': '@uladzimirdev, this should be fixed along with #38954 when `diagnoseExpression` gets integrated, right?', 'created_at': datetime.datetime(2024, 2, 26, 21, 20, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 1965862068, 'issue_id': 2143327950, 'author': 'uladzimirdev', 'body': ""I'll check it out, thanks @metamben"", 'created_at': datetime.datetime(2024, 2, 27, 6, 18, 23, tzinfo=datetime.timezone.utc)}]","metamben on (2024-02-26 21:20:24 UTC): @uladzimirdev, this should be fixed along with #38954 when `diagnoseExpression` gets integrated, right?

uladzimirdev (Assginee) on (2024-02-27 06:18:23 UTC): I'll check it out, thanks @metamben

"
2143235646,issue,open,,FE doesn't send impersonations in API request when changing permissions in a specific way,"### Describe the bug

Odd edge case in the permissions admin page.

Changing perms for a DB from `Unrestricted` data access + `No` native query editing to `Impersonated` data access and `Yes` native query editing results in the new impersonation policy not being sent in the API request.

https://www.loom.com/share/f21d5e1383b647bf98f52ff6ce335165?sid=1857410b-5b34-4b79-b76c-aad5ebc2052b

### To Reproduce

See loom

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master
```


### Severity

P3

### Additional context

_No response_",noahmoss,2024-02-19 22:30:20+00:00,[],2024-02-19 22:41:29+00:00,,https://github.com/metabase/metabase/issues/38943,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Permissions', 'Collection or Data permissions'), ('Administration/Impersonation', 'Role level security'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1953234078, 'issue_id': 2143235646, 'author': 'paoliniluis', 'body': '@noahmoss but does the FE says it’s impersonated?', 'created_at': datetime.datetime(2024, 2, 19, 22, 33, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 1953239658, 'issue_id': 2143235646, 'author': 'noahmoss', 'body': '@paoliniluis No, in this situation, the FE reverts it back to ""Unrestricted"" (because no impersonations were persisted on the BE)', 'created_at': datetime.datetime(2024, 2, 19, 22, 40, 53, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-19 22:33:20 UTC): @noahmoss but does the FE says it’s impersonated?

noahmoss (Issue Creator) on (2024-02-19 22:40:53 UTC): @paoliniluis No, in this situation, the FE reverts it back to ""Unrestricted"" (because no impersonations were persisted on the BE)

"
2143225247,issue,closed,completed,"Default ""Verified Questions Only"" on for searches","**Is your feature request related to a problem? Please describe.**
Customers who have a lot of questions and dashboards could have a lot of items return in the search.   

**Describe the solution you'd like**
The ability to change ""Verified Questions Only"" defaulted to On vs. a toggle that has to be found after you go to full search results, and then click on it. 

**How important is this feature to you?**
Fairly important

**Additional context**
The customer that reported it to me said that their search results of 510 responses would only show 4 if this change were implemented.
",cbalusek,2024-02-19 22:18:56+00:00,[],2025-01-16 14:45:00+00:00,2025-01-16 14:44:18+00:00,https://github.com/metabase/metabase/issues/38942,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2595919255, 'issue_id': 2143225247, 'author': 'luizarakaki', 'body': 'With full-text search, we are elevating verified content with extra weight. We have a phased rollout plan starting on 53.', 'created_at': datetime.datetime(2025, 1, 16, 14, 44, 59, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-16 14:44:59 UTC): With full-text search, we are elevating verified content with extra weight. We have a phased rollout plan starting on 53.

"
2143202954,issue,open,,sync-fields fetches the same cursor from the app db with no reason,"### Describe the bug

For some odd reason we're fetching the same cursor on the app db on the sync of the fields. For each field I see:
```
SELECT ""metabase_field"".""name"", ""metabase_field"".""database_type"", ""metabase_field"".""base_type"", ""metabase_field"".""effective_type"", ""metabase_field"".""coercion_strategy"", ""metabase_field"".""semantic_type"", ""metabase_field"".""parent_id"", ""metabase_field"".""id"", ""metabase_field"".""description"", ""metabase_field"".""database_position"", ""metabase_field"".""nfc_path"", ""metabase_field"".""database_is_auto_increment"", ""metabase_field"".""database_required"", ""metabase_field"".""database_partitioned"", ""metabase_field"".""json_unfolding"", ""metabase_field"".""position"" FROM ""metabase_field"" WHERE (""table_id"" = $1) AND (""active"" = TRUE) ORDER BY ""position"" ASC, LOWER(""name"") ASC

SELECT EXISTS (SELECT 1 FROM ""connection_impersonations"" WHERE ""db_id"" = $1) AS ""exists""

SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
```
the last query (a cursor) is sent hundreds/thousands of times to the App DB with no reason. If the db will be always the same during a sync, why do we have to fetch the same cursor over and over?

### To Reproduce

1) add the attached DB (postgres) to Metabase. Please run your postgres with `command: -c log_statement=all`
2) see what the db sends to stdout
3) sync it
4) see in the stdout of the DB the massive amount times we fetch the same cursor when that should be in memory!


### Expected behavior

We should keep in memory a thing like the db details, which should be fetched once!

### Logs

Too big to post here
```
2024-02-19 21:30:25.309 UTC [115] LOG:  execute S_6: SELECT ""metabase_field"".""name"", ""metabase_field"".""database_type"", ""metabase_field"".""base_type"", ""metabase_field"".""effective_type"", ""metabase_field"".""coercion_strategy"", ""metabase_field"".""semantic_type"", ""metabase_field"".""parent_id"", ""metabase_field"".""id"", ""metabase_field"".""description"", ""metabase_field"".""database_position"", ""metabase_field"".""nfc_path"", ""metabase_field"".""database_is_auto_increment"", ""metabase_field"".""database_required"", ""metabase_field"".""database_partitioned"", ""metabase_field"".""json_unfolding"", ""metabase_field"".""position"" FROM ""metabase_field"" WHERE (""table_id"" = $1) AND (""active"" = TRUE) ORDER BY ""position"" ASC, LOWER(""name"") ASC
2024-02-19 21:30:25.309 UTC [115] DETAIL:  parameters: $1 = '126'
2024-02-19 21:30:25.549 UTC [115] LOG:  execute S_6: SELECT ""metabase_field"".""name"", ""metabase_field"".""database_type"", ""metabase_field"".""base_type"", ""metabase_field"".""effective_type"", ""metabase_field"".""coercion_strategy"", ""metabase_field"".""semantic_type"", ""metabase_field"".""parent_id"", ""metabase_field"".""id"", ""metabase_field"".""description"", ""metabase_field"".""database_position"", ""metabase_field"".""nfc_path"", ""metabase_field"".""database_is_auto_increment"", ""metabase_field"".""database_required"", ""metabase_field"".""database_partitioned"", ""metabase_field"".""json_unfolding"", ""metabase_field"".""position"" FROM ""metabase_field"" WHERE (""table_id"" = $1) AND (""active"" = TRUE) ORDER BY ""position"" ASC, LOWER(""name"") ASC
2024-02-19 21:30:25.549 UTC [115] DETAIL:  parameters: $1 = '126'
2024-02-19 21:30:25.784 UTC [115] LOG:  execute S_50: SELECT EXISTS (SELECT 1 FROM ""connection_impersonations"" WHERE ""db_id"" = $1) AS ""exists""
2024-02-19 21:30:25.784 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.789 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.789 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.790 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.790 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.791 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.791 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.791 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.791 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.792 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.792 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.793 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.793 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.794 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.794 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.795 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.795 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.796 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.796 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.796 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.796 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.797 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.797 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.798 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.798 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.799 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.799 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.800 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.800 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.801 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.801 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.801 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.801 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.802 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.802 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.803 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.803 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.804 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.804 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.805 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.805 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.806 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.806 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.807 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.807 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.807 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.807 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.808 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.808 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.809 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.809 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.810 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.810 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.811 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.811 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.811 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.811 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.812 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.812 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.813 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.813 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.814 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.814 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.815 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.815 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.816 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.816 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.816 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.816 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.817 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.817 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.818 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.818 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.819 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.819 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.820 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.820 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.820 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.820 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.821 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.821 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.822 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.822 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.823 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.823 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.824 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.824 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.825 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.825 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.826 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.826 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.828 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.828 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.828 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.828 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.829 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.829 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.830 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.830 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.831 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.831 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.832 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.832 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.832 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.832 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.833 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.833 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.834 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.834 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.835 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.835 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.836 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.836 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.836 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.836 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.837 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.837 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.838 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.838 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.838 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.838 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.839 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.839 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.840 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.840 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.841 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.841 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.842 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.842 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.843 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.843 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.843 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.843 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.844 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.844 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.845 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.845 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.846 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.846 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.847 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.847 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.848 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.848 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.849 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.849 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.850 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.850 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.851 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.851 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.852 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.852 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.852 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.852 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.853 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.853 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.854 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.854 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.855 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.855 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.855 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.855 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.856 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.856 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.857 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.857 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.858 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.858 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.858 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.858 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.859 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.859 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.860 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.860 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.861 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.861 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.861 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.861 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.862 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.862 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.863 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.863 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.864 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.864 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.864 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.864 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.865 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.865 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.866 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.866 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.867 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.867 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.868 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.868 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.869 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.869 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.870 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.870 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.870 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.870 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.871 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.871 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.872 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.872 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.873 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.873 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.873 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.873 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.874 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.874 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.875 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.875 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.875 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.875 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.876 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.876 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.877 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.877 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.878 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.878 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.878 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.878 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.879 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.879 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.880 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.880 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.881 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.881 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.882 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.882 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.883 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.883 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.883 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.883 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.884 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.884 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.885 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.885 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.885 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.885 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.886 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.886 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.887 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.887 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.888 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.888 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.889 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.889 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.890 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
2024-02-19 21:30:25.890 UTC [115] DETAIL:  parameters: $1 = '4'
2024-02-19 21:30:25.891 UTC [115] LOG:  execute S_3: SELECT * FROM ""metabase_database"" WHERE ""id"" = $1
....
```

### Information about your Metabase installation

```JSON
tested in v47 and it works in the same way, interesting
```


### Severity

P2

### Additional context

P2 just because it's been like that for a long time, but I'm really wondering why we're doing this, it doesn't make absolutely any sense",paoliniluis,2024-02-19 21:57:04+00:00,[],2025-02-04 20:24:40+00:00,,https://github.com/metabase/metabase/issues/38941,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1953205139, 'issue_id': 2143202954, 'author': 'paoliniluis', 'body': 'db attached\r\n[finalSQL.sql.gz](https://github.com/metabase/metabase/files/14337215/finalSQL.sql.gz)', 'created_at': datetime.datetime(2024, 2, 19, 21, 59, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-19 21:59:41 UTC): db attached
[finalSQL.sql.gz](https://github.com/metabase/metabase/files/14337215/finalSQL.sql.gz)

"
2143139549,issue,closed,completed,[dc.js migration] scatter plot missing blur styles,"http://localhost:3000/question/111-scatter-multiseries-breakout-pokedex-def-vs-sp-def-breakout-by-type

| dc.js | echarts |
|--------|--------|
| <img width=""1891"" alt=""Screenshot 2024-02-19 at 1 03 14 PM"" src=""https://github.com/metabase/metabase/assets/37751258/49be9a58-3056-4179-95d2-961959e675ab""> | <img width=""1900"" alt=""Screenshot 2024-02-19 at 1 03 27 PM"" src=""https://github.com/metabase/metabase/assets/37751258/ddf2cb96-a103-4d05-acbf-80d0091f40ed""> |
",EmmadUsmani,2024-02-19 21:04:09+00:00,['EmmadUsmani'],2024-02-22 18:39:23+00:00,2024-02-22 18:39:23+00:00,https://github.com/metabase/metabase/issues/38939,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2143130497,issue,open,,Calling Snippets with space breaks the query,"### Describe the bug

Snippets don't work anymore

### To Reproduce

Simply follow the example in the docs but add a space after the curly bracket ` }}` :

https://www.metabase.com/docs/latest/questions/native-editor/sql-snippets#how-to-create-a-snippet

You end up with the following error:

<img width=""1509"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/fc473d72-6388-4f33-8ec8-1b8a1d5c561c"">


### Expected behavior

Snippets should work or have better error messages 

### Logs

_No response_

### Information about your Metabase installation

```JSON
49-RC1
```


### Severity

Blocker

### Additional context

_No response_",Tony-metabase,2024-02-19 20:55:27+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/38938,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', ''), ('Querying/Snippets', '')]","[{'comment_id': 1956789379, 'issue_id': 2143130497, 'author': 'oleggromov', 'body': 'First, this isn\'t reproducible as in the screenshot. @Tony-metabase please confirm! \r\n\r\nSecond, the issue seems to be a bit more subtle, because _without a space before closing curlies_ it works.\r\n<img width=""1088"" alt=""Screenshot 2024-02-21 at 14 33 49"" src=""https://github.com/metabase/metabase/assets/2196347/10ebb619-4225-4d1d-83d2-cd3c983eda2a"">\r\n\r\nAnd with a space, `select * from {{snippet: Product Snippets }}` — it doesn\'t. \r\n<img width=""1084"" alt=""Screenshot 2024-02-21 at 14 34 17"" src=""https://github.com/metabase/metabase/assets/2196347/11e93e38-56be-4977-bcec-7a1bb0f356a2"">\r\n\r\nThe exception thrown by clojure in the 2nd case is the following:\r\n```\r\n2024-02-21 14:33:45,994 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 272.5 ms (5 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (9 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)\r\n2024-02-21 14:34:12,314 WARN api.common :: Unexpected parameters at [:post ""/api/dataset""]: [:type :native :parameters]\r\nPlease add them to the schema or remove them from the API client\r\n2024-02-21 14:34:12,342 ERROR middleware.catch-exceptions :: Error processing query: Cannot run the query: missing required parameters: #{""snippet: Product Snippets""}\r\n{:database_id 1,\r\n :started_at #t ""2024-02-21T14:34:12.326174Z[Europe/London]"",\r\n :action_id nil,\r\n :error_type :missing-required-parameter,\r\n :json_query\r\n {:native\r\n  {:query ""select * from {{snippet: Product Snippets }}"",\r\n   :template-tags\r\n   {:snippet: Product Snippets\r\n    {:type ""snippet"",\r\n     :name ""snippet: Product Snippets "",\r\n     :id ""7e1e419b-122b-424b-a6fb-0cb63156f908"",\r\n     :display-name ""Snippet: Product Snippets"",\r\n     :snippet-name ""Product Snippets"",\r\n     :snippet-id 160}}},\r\n  :type ""native"",\r\n  :database 1,\r\n  :parameters [],\r\n  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},\r\n :status :failed,\r\n :class clojure.lang.ExceptionInfo,\r\n :stacktrace\r\n [""--> driver.sql.parameters.substitute$substitute.invokeStatic(substitute.clj:98)""\r\n  ""driver.sql.parameters.substitute$substitute.invoke(substitute.clj:78)""\r\n  ""driver.sql$eval104697$_AMPERSAND_f__104699.invoke(sql.clj:59)""\r\n  ""driver.sql$eval104697$fn__104705.invoke(sql.clj:55)""\r\n  ""query_processor.middleware.parameters.native$expand_inner.invokeStatic(native.clj:42)""\r\n  ""query_processor.middleware.parameters.native$expand_inner.invoke(native.clj:33)""\r\n  ""query_processor.middleware.parameters$expand_one.invokeStatic(parameters.clj:50)""\r\n  ""query_processor.middleware.parameters$expand_one.invoke(parameters.clj:41)""\r\n  ""query_processor.middleware.parameters$expand_all$replace_90429__90430.invoke(parameters.clj:59)""\r\n  ""mbql.util.match.impl$replace_in_collection$iter__33578__33582$fn__33583.invoke(impl.cljc:45)""\r\n  ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""\r\n  ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""\r\n  ""query_processor.middleware.parameters$expand_all$replace_90429__90430.invoke(parameters.clj:59)""\r\n  ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:59)""\r\n  ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:53)""\r\n  ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:56)""\r\n  ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:53)""\r\n  ""query_processor.middleware.parameters$expand_parameters.invokeStatic(parameters.clj:77)""\r\n  ""query_processor.middleware.parameters$expand_parameters.invoke(parameters.clj:73)""\r\n  ""query_processor.middleware.parameters$fn__90440$_AMPERSAND_f__90441.invoke(parameters.clj:82)""\r\n  ""query_processor.middleware.parameters$fn__90440$fn__90446.invoke(parameters.clj:79)""\r\n  ""query_processor.middleware.parameters$substitute_parameters.invokeStatic(parameters.clj:109)""\r\n  ""query_processor.middleware.parameters$substitute_parameters.invoke(parameters.clj:101)""\r\n  ""query_processor$preprocess_STAR_$fn__91526.invoke(query_processor.clj:164)""\r\n  ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)""\r\n  ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)""\r\n  ""query_processor$fn__91534$combined_pre_process__91535$combined_pre_process_STAR___91536.invoke(query_processor.clj:259)""\r\n  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__89144.invoke(fetch_source_query.clj:303)""\r\n  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__90787$fn__90791.invoke(resolve_database_and_driver.clj:77)""\r\n  ""driver$do_with_driver.invokeStatic(driver.clj:97)""\r\n  ""driver$do_with_driver.invoke(driver.clj:92)""\r\n  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__90787.invoke(resolve_database_and_driver.clj:76)""\r\n  ""query_processor.middleware.store$initialize_store$fn__91349$fn__91350.invoke(store.clj:14)""\r\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""\r\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""\r\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n  ""query_processor.middleware.store$initialize_store$fn__91349.invoke(store.clj:13)""\r\n  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__90784.invoke(resolve_database_and_driver.clj:60)""\r\n  ""query_processor.middleware.normalize_query$normalize$fn__89372.invoke(normalize_query.clj:38)""\r\n  ""query_processor.middleware.enterprise$eval86638$handle_audit_app_internal_queries__86639$fn__86641.invoke(enterprise.clj:96)""\r\n  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__86649.invoke(enterprise.clj:103)""\r\n  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__86469.invoke(constraints.clj:104)""\r\n  ""query_processor.middleware.process_userland_query$process_userland_query$fn__90658.invoke(process_userland_query.clj:156)""\r\n  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__86381.invoke(catch_exceptions.clj:171)""\r\n  ""query_processor.reducible$async_qp$qp_STAR___82035$thunk__82037.invoke(reducible.clj:126)""\r\n  ""query_processor.reducible$async_qp$qp_STAR___82035.invoke(reducible.clj:132)""\r\n  ""query_processor$base_qp$fn__91546.doInvoke(query_processor.clj:280)""\r\n  ""query_processor.reducible$sync_qp$qp_STAR___82047.doInvoke(reducible.clj:153)""\r\n  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""\r\n  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""\r\n  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""\r\n  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""\r\n  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""\r\n  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""\r\n  ""api.dataset$run_query_async$fn__114989.invoke(dataset.clj:79)""\r\n  ""query_processor.streaming$streaming_response_STAR_$fn__93100$fn__93102.invoke(streaming.clj:168)""\r\n  ""query_processor.streaming$streaming_response_STAR_$fn__93100.invoke(streaming.clj:167)""\r\n  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""\r\n  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""\r\n  ""async.streaming_response$do_f_async$task__29187.invoke(streaming_response.clj:88)""],\r\n :card_id nil,\r\n :context :ad-hoc,\r\n :error ""Cannot run the query: missing required parameters: #{\\""snippet: Product Snippets\\""}"",\r\n :row_count 0,\r\n :running_time 0,\r\n :ex-data {:type :missing-required-parameter, :missing (""snippet: Product Snippets"")},\r\n :data {:rows [], :cols []}}\r\n```\r\n\r\nI believe it is some sort of a subtle parsing error.', 'created_at': datetime.datetime(2024, 2, 21, 14, 35, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 1956790258, 'issue_id': 2143130497, 'author': 'oleggromov', 'body': '@paoliniluis and @NevRA please triage to the right BE team.', 'created_at': datetime.datetime(2024, 2, 21, 14, 36, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 1957124275, 'issue_id': 2143130497, 'author': 'oleggromov', 'body': 'I can confirm this issue reproduces on:\r\n\r\n- `b8818f907b72e0077854fc1e3d9f25a269a41517` (tag: v1.48.6, tag: v0.48.6)\r\n- `f985e19088cd1e9ad86a12dd01727bf8fcd2bfd2` (tag: v1.48.0, tag: v0.48.0)', 'created_at': datetime.datetime(2024, 2, 21, 16, 8, 14, tzinfo=datetime.timezone.utc)}]","oleggromov on (2024-02-21 14:35:39 UTC): First, this isn't reproducible as in the screenshot. @Tony-metabase please confirm! 

Second, the issue seems to be a bit more subtle, because _without a space before closing curlies_ it works.
<img width=""1088"" alt=""Screenshot 2024-02-21 at 14 33 49"" src=""https://github.com/metabase/metabase/assets/2196347/10ebb619-4225-4d1d-83d2-cd3c983eda2a"">

And with a space, `select * from {{snippet: Product Snippets }}` — it doesn't. 
<img width=""1084"" alt=""Screenshot 2024-02-21 at 14 34 17"" src=""https://github.com/metabase/metabase/assets/2196347/11e93e38-56be-4977-bcec-7a1bb0f356a2"">

The exception thrown by clojure in the 2nd case is the following:
```
2024-02-21 14:33:45,994 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 272.5 ms (5 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (9 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
2024-02-21 14:34:12,314 WARN api.common :: Unexpected parameters at [:post ""/api/dataset""]: [:type :native :parameters]
Please add them to the schema or remove them from the API client
2024-02-21 14:34:12,342 ERROR middleware.catch-exceptions :: Error processing query: Cannot run the query: missing required parameters: #{""snippet: Product Snippets""}
{:database_id 1,
 :started_at #t ""2024-02-21T14:34:12.326174Z[Europe/London]"",
 :action_id nil,
 :error_type :missing-required-parameter,
 :json_query
 {:native
  {:query ""select * from {{snippet: Product Snippets }}"",
   :template-tags
   {:snippet: Product Snippets
    {:type ""snippet"",
     :name ""snippet: Product Snippets "",
     :id ""7e1e419b-122b-424b-a6fb-0cb63156f908"",
     :display-name ""Snippet: Product Snippets"",
     :snippet-name ""Product Snippets"",
     :snippet-id 160}}},
  :type ""native"",
  :database 1,
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> driver.sql.parameters.substitute$substitute.invokeStatic(substitute.clj:98)""
  ""driver.sql.parameters.substitute$substitute.invoke(substitute.clj:78)""
  ""driver.sql$eval104697$_AMPERSAND_f__104699.invoke(sql.clj:59)""
  ""driver.sql$eval104697$fn__104705.invoke(sql.clj:55)""
  ""query_processor.middleware.parameters.native$expand_inner.invokeStatic(native.clj:42)""
  ""query_processor.middleware.parameters.native$expand_inner.invoke(native.clj:33)""
  ""query_processor.middleware.parameters$expand_one.invokeStatic(parameters.clj:50)""
  ""query_processor.middleware.parameters$expand_one.invoke(parameters.clj:41)""
  ""query_processor.middleware.parameters$expand_all$replace_90429__90430.invoke(parameters.clj:59)""
  ""mbql.util.match.impl$replace_in_collection$iter__33578__33582$fn__33583.invoke(impl.cljc:45)""
  ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""
  ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
  ""query_processor.middleware.parameters$expand_all$replace_90429__90430.invoke(parameters.clj:59)""
  ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:59)""
  ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:53)""
  ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:56)""
  ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:53)""
  ""query_processor.middleware.parameters$expand_parameters.invokeStatic(parameters.clj:77)""
  ""query_processor.middleware.parameters$expand_parameters.invoke(parameters.clj:73)""
  ""query_processor.middleware.parameters$fn__90440$_AMPERSAND_f__90441.invoke(parameters.clj:82)""
  ""query_processor.middleware.parameters$fn__90440$fn__90446.invoke(parameters.clj:79)""
  ""query_processor.middleware.parameters$substitute_parameters.invokeStatic(parameters.clj:109)""
  ""query_processor.middleware.parameters$substitute_parameters.invoke(parameters.clj:101)""
  ""query_processor$preprocess_STAR_$fn__91526.invoke(query_processor.clj:164)""
  ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)""
  ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)""
  ""query_processor$fn__91534$combined_pre_process__91535$combined_pre_process_STAR___91536.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__89144.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__90787$fn__90791.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__90787.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__91349$fn__91350.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__91349.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__90784.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__89372.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$eval86638$handle_audit_app_internal_queries__86639$fn__86641.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__86649.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__86469.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__90658.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__86381.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___82035$thunk__82037.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___82035.invoke(reducible.clj:132)""
  ""query_processor$base_qp$fn__91546.doInvoke(query_processor.clj:280)""
  ""query_processor.reducible$sync_qp$qp_STAR___82047.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__114989.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__93100$fn__93102.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__93100.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__29187.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""Cannot run the query: missing required parameters: #{\""snippet: Product Snippets\""}"",
 :row_count 0,
 :running_time 0,
 :ex-data {:type :missing-required-parameter, :missing (""snippet: Product Snippets"")},
 :data {:rows [], :cols []}}
```

I believe it is some sort of a subtle parsing error.

oleggromov on (2024-02-21 14:36:02 UTC): @paoliniluis and @NevRA please triage to the right BE team.

oleggromov on (2024-02-21 16:08:14 UTC): I can confirm this issue reproduces on:

- `b8818f907b72e0077854fc1e3d9f25a269a41517` (tag: v1.48.6, tag: v0.48.6)
- `f985e19088cd1e9ad86a12dd01727bf8fcd2bfd2` (tag: v1.48.0, tag: v0.48.0)

"
2143127069,issue,closed,not_planned,[dc.js migration] missing data on timeseries charts,"https://metaboat.slack.com/archives/C06G94JTWBS/p1706201653722559

<img width=""1415"" alt=""Screenshot 2024-02-19 at 12 54 44 PM"" src=""https://github.com/metabase/metabase/assets/37751258/cef67d8c-fc9d-41e0-9313-6900d24e3a12"">

https://metaboat.slack.com/archives/C06G94JTWBS/p1706200083518489


<img width=""1638"" alt=""Screenshot 2024-02-19 at 2 11 35 PM"" src=""https://github.com/metabase/metabase/assets/37751258/0dac6eff-1e00-4f7d-83ff-ee32552c5279"">


This happens when the dataset has overlapping buckets (see this related issue: https://github.com/metabase/metabase/issues/36159). To fix it, we need to manually combine datum that overlap in the selected time bucket.


<img width=""1452"" alt=""Screenshot 2024-02-22 at 12 30 13 PM"" src=""https://github.com/metabase/metabase/assets/37751258/c0c6f6be-e1cb-46b9-ba8a-886a22fc94c4"">

In this example, if we combine these two datum into the first, the chart looks like how it used to in dc.js 

| Uncombined Datum | Combined Datum |
|--------|--------|
| <img width=""1029"" alt=""Screenshot 2024-02-22 at 12 29 29 PM"" src=""https://github.com/metabase/metabase/assets/37751258/d2eb2c0d-9de6-4a51-ad58-0685be47fef0""> | <img width=""985"" alt=""Screenshot 2024-02-22 at 12 30 18 PM"" src=""https://github.com/metabase/metabase/assets/37751258/18f33af7-36e9-42bd-95a8-b0f90486d54f""> | 


### More Examples

question/5082
https://metaboat.slack.com/archives/C06G94JTWBS/p1706193538101699

question/14597
https://metaboat.slack.com/archives/C06G94JTWBS/p1706193637425579

question/4223
https://metaboat.slack.com/archives/C06G94JTWBS/p1706193960436849

question/14597
https://metaboat.slack.com/archives/C06G94JTWBS/p1710341059082499
",EmmadUsmani,2024-02-19 20:52:14+00:00,"['kulyk', 'EmmadUsmani']",2024-04-15 17:58:03+00:00,2024-04-11 14:52:47+00:00,https://github.com/metabase/metabase/issues/38937,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2049880377, 'issue_id': 2143127069, 'author': 'alxnddr', 'body': 'Concluded it is more desirable not to fix incorrect bucketing coming from the BE becasue charts actually look more correct\r\nhttps://metaboat.slack.com/archives/C05NQSWPRMK/p1712840771548499?thread_ts=1712672954.660139&cid=C05NQSWPRMK', 'created_at': datetime.datetime(2024, 4, 11, 14, 52, 47, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-04-11 14:52:47 UTC): Concluded it is more desirable not to fix incorrect bucketing coming from the BE becasue charts actually look more correct
https://metaboat.slack.com/archives/C05NQSWPRMK/p1712840771548499?thread_ts=1712672954.660139&cid=C05NQSWPRMK

"
2143021741,issue,closed,completed,Trend chart static viz sometimes fails,"### Describe the bug

The original report: https://discourse.metabase.com/t/an-error-occurred-while-displaying-this-card-v0-49-rc1/78633
Based on the report the question existed before our recent improvements and the report is only about the static viz so we can assume the dynamic trend chart works. So we need to investigate how old trend chart questions with different set of viz settings work after the upgrade, specifically, if there is anything missing in the static trend chart settings computation

### To Reproduce

No reproduction steps yet

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-91-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Africa/Maputo""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""googleanalytics"",
      ""mysql"",
      ""clickhouse""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.11.7-MariaDB-1:10.11.7+maria~ubu2204""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-12"",
      ""tag"": ""v0.49.0-RC1"",
      ""hash"": ""8a571ac""
    },
    ""settings"": {
      ""report-timezone"": ""Africa/Harare""
    }
  }
}
```


### Severity

Significant for users of subscriptions

### Additional context

_No response_",alxnddr,2024-02-19 19:31:04+00:00,[],2025-01-30 19:47:39+00:00,2025-01-30 19:47:37+00:00,https://github.com/metabase/metabase/issues/38932,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1954429077, 'issue_id': 2143021741, 'author': 'JesseSDevaney', 'body': 'The only path to having trend be returned as null are these lines below: \r\n\r\n![image](https://github.com/metabase/metabase/assets/22608765/4aa50d2e-5acd-4c16-9e95-9b3e9957b597)\r\n(https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js#L25-L27).\r\n\r\nSo the error has to be coming from `getCurrentMetricData(...)`', 'created_at': datetime.datetime(2024, 2, 20, 15, 12, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 1963827875, 'issue_id': 2143021741, 'author': 'perivamsi', 'body': 'Discussed on [Slack](https://metaboat.slack.com/archives/C064QMXEV9N/p1708713559738409?thread_ts=1708360957.209439&cid=C064QMXEV9N) and agreed that this is not a release blocker. Removing the milestone.', 'created_at': datetime.datetime(2024, 2, 26, 10, 46, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625428244, 'issue_id': 2143021741, 'author': 'alxnddr', 'body': 'Fixed by https://github.com/metabase/metabase/pull/47963', 'created_at': datetime.datetime(2025, 1, 30, 19, 47, 38, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-02-20 15:12:41 UTC): The only path to having trend be returned as null are these lines below: 

![image](https://github.com/metabase/metabase/assets/22608765/4aa50d2e-5acd-4c16-9e95-9b3e9957b597)
(https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js#L25-L27).

So the error has to be coming from `getCurrentMetricData(...)`

perivamsi on (2024-02-26 10:46:15 UTC): Discussed on [Slack](https://metaboat.slack.com/archives/C064QMXEV9N/p1708713559738409?thread_ts=1708360957.209439&cid=C064QMXEV9N) and agreed that this is not a release blocker. Removing the milestone.

alxnddr (Issue Creator) on (2025-01-30 19:47:38 UTC): Fixed by https://github.com/metabase/metabase/pull/47963

"
2142937465,issue,closed,completed,[Epic] Download diagnostics on errors,"**Links**
- [product doc](https://www.notion.so/metabase/Download-diagnostics-on-errors-d1940849962741d5812ebd11ef8ee98f)

Issue links: 
- #34417
- maybe #37779


```[tasklist]
### Tasks
- [ ] Add a draft title or issue reference here
```


",luizarakaki,2024-02-19 18:22:53+00:00,['iethree'],2024-03-11 13:54:53+00:00,2024-03-11 13:54:53+00:00,https://github.com/metabase/metabase/issues/38930,"[('Administration/Troubleshooting', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2142868572,issue,closed,completed,ParseSQL: Figure out which fields are used in which query,Use the Field values from DB syncs,tsmacdonald,2024-02-19 17:32:04+00:00,['tsmacdonald'],2024-04-30 09:23:15+00:00,2024-04-10 12:51:14+00:00,https://github.com/metabase/metabase/issues/38926,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2047458311, 'issue_id': 2142868572, 'author': 'tsmacdonald', 'body': 'Fixed by #39707', 'created_at': datetime.datetime(2024, 4, 10, 12, 51, 14, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-04-10 12:51:14 UTC): Fixed by #39707

"
2142866577,issue,closed,completed,ParseSQL: Detect columns in a query,,tsmacdonald,2024-02-19 17:30:42+00:00,['tsmacdonald'],2024-04-30 09:23:11+00:00,2024-03-18 14:56:40+00:00,https://github.com/metabase/metabase/issues/38925,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 1952928090, 'issue_id': 2142866577, 'author': 'tsmacdonald', 'body': 'Fixed by https://github.com/metabase/macaw/pull/3/', 'created_at': datetime.datetime(2024, 2, 19, 17, 31, 33, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-02-19 17:31:33 UTC): Fixed by https://github.com/metabase/macaw/pull/3/

"
2142866450,issue,closed,completed,ParseSQL: Detect tables in a query,,tsmacdonald,2024-02-19 17:30:37+00:00,['tsmacdonald'],2024-04-30 09:22:19+00:00,2024-03-13 14:04:23+00:00,https://github.com/metabase/metabase/issues/38924,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 1952927860, 'issue_id': 2142866450, 'author': 'tsmacdonald', 'body': 'Fixed by https://github.com/metabase/macaw/pull/3/', 'created_at': datetime.datetime(2024, 2, 19, 17, 31, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 1992739391, 'issue_id': 2142866450, 'author': 'qnkhuat', 'body': 'any reasons why this issue is still open?', 'created_at': datetime.datetime(2024, 3, 12, 23, 34, 48, tzinfo=datetime.timezone.utc)}]","tsmacdonald (Issue Creator) on (2024-02-19 17:31:21 UTC): Fixed by https://github.com/metabase/macaw/pull/3/

qnkhuat on (2024-03-12 23:34:48 UTC): any reasons why this issue is still open?

"
2142834883,issue,open,,Use current filter settings as default on email subscription,"**Is your feature request related to a problem? Please describe.**
Currently, if you browse a dashboard, change the filters to your need, and then open the subscription screen, the filters from the dashboard are not automatically set. This requires additional work from the user, and it would be more logical to automatically take over the filter settings, or at least provide an easy way for the user to make that happen automatically.

**Describe the solution you'd like**
Populate the filter values from the current dashboard filters when the subscription screen is opened.
Alternatively, create a button in the subscription settings to ""take over current filter settings"" automatically.

**Describe alternatives you've considered**
There are no good alternatives currently, as users have to set up the same filter settings to get the same results in their alerts.

**How important is this feature to you?**
Really nice to have. It would improve user experience by eliminating a redundant and non-intuitive step from the flow of setting up new alerts.

**Additional context**
n/a",zbodi74,2024-02-19 17:10:54+00:00,[],2025-02-04 20:30:58+00:00,,https://github.com/metabase/metabase/issues/38922,"[('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('Misc/Emails', ''), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2142803797,issue,closed,completed,Dashboard with many slower Athena questions does not open even with timeout in 1200 seconds,"### Describe the bug

We have some dashboards with question at AWS Athena there is hitting the HTTP server upstream timed out and stop work, not even open the dashboard layout and async open each question, the dashboard is not opening.

![Screenshot from 2024-02-19 13-39-50](https://github.com/metabase/metabase/assets/6808348/5146e4e7-2956-40ab-92ec-e411464b41e7)


### To Reproduce

1. Open the dashboard URL link: https://metabase.domain.tld/dashboard/632-validacao-de-dados-staging

### Expected behavior

_No response_

### Logs

2024-02-19 16:40:34,308 DEBUG middleware.log :: GET /api/dashboard/632 200 2.2 hours (59 chamadas ao banco de dados) Conexões com o banco de dados: 1 / 15 Threads do Jetty: 6 / 256 (2 ocioso, 0 na fila) (485 total de threads ativas) Consultas ativas: 0 (0 na fila); athena DB 22 connections: 2/2 (0 threads blocked)

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""19+36"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""19"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""19+36"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-26-cloud-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""clickhouse"",
      ""mysql"",
      ""postgres"",
      ""cubejs"",
      ""sqlserver"",
      ""googleanalytics"",
      ""athena"",
      ""bigquery-cloud-sdk"",
      ""mongo"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v0.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Stopped working for these dashboards users

### Additional context

_No response_",dannyeuu,2024-02-19 16:53:50+00:00,[],2024-02-21 16:24:09+00:00,2024-02-21 16:24:08+00:00,https://github.com/metabase/metabase/issues/38921,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1952876725, 'issue_id': 2142803797, 'author': 'paoliniluis', 'body': ""I have a strong feeling we're seeing https://github.com/metabase/metabase/issues/38826, can you check @dannyeuu"", 'created_at': datetime.datetime(2024, 2, 19, 16, 55, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 1952886368, 'issue_id': 2142803797, 'author': 'dannyeuu', 'body': 'Great felling @paoliniluis, I did reproduce the steps and saw the `SELECT ""public"".""people"".""source"" AS ""source"" FROM ""public"".""people"" GROUP BY ""public"".""people"".""source"" ORDER BY ""public"".""people"".""source"" ASC LIMIT 1000` in the Athena Console\r\n\r\n\r\nDuplicated of #38826', 'created_at': datetime.datetime(2024, 2, 19, 17, 1, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 1953455437, 'issue_id': 2142803797, 'author': 'qnkhuat', 'body': ""@dannyeuu is it possible for us to get a dump of your task_history for your Athena DB?\r\n```sql\r\nselect * from task_history where db_id = [[YOUR_ATHENA_DB_ID]] and started_at > '2024-02-01'::timestamp;\r\n```"", 'created_at': datetime.datetime(2024, 2, 20, 4, 6, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 1956872758, 'issue_id': 2142803797, 'author': 'dannyeuu', 'body': 'This is the result @qnkhuat \r\n[query_result_2024-02-21T15_05_59.742805506Z.csv](https://github.com/metabase/metabase/files/14361243/query_result_2024-02-21T15_05_59.742805506Z.csv)', 'created_at': datetime.datetime(2024, 2, 21, 15, 7, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1957159004, 'issue_id': 2142803797, 'author': 'paoliniluis', 'body': '@dannyeuu is there a reason why you reopened this?', 'created_at': datetime.datetime(2024, 2, 21, 16, 16, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 1957188077, 'issue_id': 2142803797, 'author': 'dannyeuu', 'body': 'ops, sorry.', 'created_at': datetime.datetime(2024, 2, 21, 16, 24, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-19 16:55:32 UTC): I have a strong feeling we're seeing https://github.com/metabase/metabase/issues/38826, can you check @dannyeuu

dannyeuu (Issue Creator) on (2024-02-19 17:01:31 UTC): Great felling @paoliniluis, I did reproduce the steps and saw the `SELECT ""public"".""people"".""source"" AS ""source"" FROM ""public"".""people"" GROUP BY ""public"".""people"".""source"" ORDER BY ""public"".""people"".""source"" ASC LIMIT 1000` in the Athena Console


Duplicated of #38826

qnkhuat on (2024-02-20 04:06:14 UTC): @dannyeuu is it possible for us to get a dump of your task_history for your Athena DB?
```sql
select * from task_history where db_id = [[YOUR_ATHENA_DB_ID]] and started_at > '2024-02-01'::timestamp;
```

dannyeuu (Issue Creator) on (2024-02-21 15:07:09 UTC): This is the result @qnkhuat 
[query_result_2024-02-21T15_05_59.742805506Z.csv](https://github.com/metabase/metabase/files/14361243/query_result_2024-02-21T15_05_59.742805506Z.csv)

paoliniluis on (2024-02-21 16:16:16 UTC): @dannyeuu is there a reason why you reopened this?

dannyeuu (Issue Creator) on (2024-02-21 16:24:09 UTC): ops, sorry.

"
2142780284,issue,open,,Separate maps per tenant,"**Is your feature request related to a problem? Please describe.**
Different users might want to see a different version of a map due to many reasons, so we should separate the maps we offer to the customers per tenant (user group)

**Describe the solution you'd like**
Associate a map (or a set of maps) to a specific group

**Describe alternatives you've considered**
A single instance per tenant

**How important is this feature to you?**
Requested by a client that has users from all around the world

**Additional context**
NA
",paoliniluis,2024-02-19 16:39:40+00:00,[],2024-02-19 16:39:40+00:00,,https://github.com/metabase/metabase/issues/38919,"[('Type:New Feature', ''), ('Visualization/Maps', '')]",[],
2142770844,issue,closed,completed,Add hover card on visualization settings sidebar,"As part of #38394 we want to add the info icon to columns in the visualisation sidebar.

<img width=""570"" alt=""Screenshot 2024-02-28 at 17 52 21"" src=""https://github.com/metabase/metabase/assets/1250185/6c3575f6-82cb-4c19-bf65-d92bde5004aa"">
",romeovs,2024-02-19 16:34:23+00:00,['romeovs'],2024-02-29 10:53:11+00:00,2024-02-29 10:53:07+00:00,https://github.com/metabase/metabase/issues/38918,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1970880689, 'issue_id': 2142770844, 'author': 'romeovs', 'body': 'Closed by #39252 39256', 'created_at': datetime.datetime(2024, 2, 29, 10, 53, 7, tzinfo=datetime.timezone.utc)}]","romeovs (Issue Creator) on (2024-02-29 10:53:07 UTC): Closed by #39252 39256

"
2142763673,issue,closed,completed,[dc.js migration] compact x-axis does not work,"http://localhost:3000/question/85-line-aapl-stock

https://github.com/metabase/metabase/assets/37751258/5d2c4278-c901-4994-a189-4052fc337cf0

When `settings.graph.x_axis.axis_enabled` is `""compact""` we should pass `compact: true` to `renderingContext.formatValue`",EmmadUsmani,2024-02-19 16:32:21+00:00,['EmmadUsmani'],2024-02-28 18:50:29+00:00,2024-02-28 18:50:29+00:00,https://github.com/metabase/metabase/issues/38917,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2142756156,issue,open,reopened,[dc.js migration] axis labels and names on timeseries and numeric charts are not highlightable,"<img width=""1472"" alt=""Screenshot 2024-02-19 at 8 31 22 AM"" src=""https://github.com/metabase/metabase/assets/37751258/f238de47-6bb2-4fcb-82f2-23ae9b423ba3"">

Before we used to be able to highlight all text on the chart (axes ticks, labels, data labels, legend)

Now in the echarts implementation we can only highlight the legend.

Enabled brushing seems to prevent users from selecting labels so CSS can't fix this. 
",EmmadUsmani,2024-02-19 16:28:40+00:00,[],2025-02-04 20:31:41+00:00,,https://github.com/metabase/metabase/issues/38915,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation'), ('Visualization/Legend', '')]","[{'comment_id': 1960133363, 'issue_id': 2142756156, 'author': 'EmmadUsmani', 'body': 'https://github.com/apache/echarts/issues/13585\r\n\r\nSolution is to manually add the `user-select` style to the root `svg` element', 'created_at': datetime.datetime(2024, 2, 22, 19, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 1960391549, 'issue_id': 2142756156, 'author': 'EmmadUsmani', 'body': 'I tried implementing that solution but for some reason left click is not working. I can select text with right click, but cannot left click.', 'created_at': datetime.datetime(2024, 2, 22, 22, 3, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 1988997998, 'issue_id': 2142756156, 'author': 'alxnddr', 'body': 'Does not seem important to spend time on', 'created_at': datetime.datetime(2024, 3, 11, 17, 14, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007687212, 'issue_id': 2142756156, 'author': 'kulyk', 'body': 'Setting this aside for now — tried hacking something together with `user-select` and/or `pointer-events`, but no luck :(', 'created_at': datetime.datetime(2024, 3, 19, 16, 57, 56, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-02-22 19:41:55 UTC): https://github.com/apache/echarts/issues/13585

Solution is to manually add the `user-select` style to the root `svg` element

EmmadUsmani (Issue Creator) on (2024-02-22 22:03:16 UTC): I tried implementing that solution but for some reason left click is not working. I can select text with right click, but cannot left click.

alxnddr on (2024-03-11 17:14:14 UTC): Does not seem important to spend time on

kulyk on (2024-03-19 16:57:56 UTC): Setting this aside for now — tried hacking something together with `user-select` and/or `pointer-events`, but no luck :(

"
2142463850,issue,closed,completed,Unknown error in the revision history of a dashboard leads to a NullPointerException,"### Describe the bug

Dashboard 357 in our internal Metabase instance is returning when you go to the revision history:
```
{
    ""via"": [
        {
            ""type"": ""java.lang.NullPointerException"",
            ""at"": [
                ""clojure.core$name"",
                ""invokeStatic"",
                ""core.clj"",
                1610
            ]
        }
    ],
    ""trace"": [
        [
            ""clojure.core$name"",
            ""invokeStatic"",
            ""core.clj"",
            1610
        ],
        [
            ""clojure.core$name"",
            ""invoke"",
            ""core.clj"",
            1604
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406$fn__75407$fn__75408$fn__75409$fn__75410$fn__75411"",
            ""invoke"",
            ""diff.clj"",
            93
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406$fn__75407$fn__75408$fn__75409$fn__75410"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406$fn__75407$fn__75408$fn__75409"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406$fn__75407$fn__75408"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406$fn__75407"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405$fn__75406"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404$fn__75405"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401$fn__75404"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400$fn__75401"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399$fn__75400"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398$fn__75399"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397$fn__75398"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394$fn__75397"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391$fn__75394"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388$fn__75391"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385$fn__75388"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string$fn__75385"",
            ""invoke"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string"",
            ""invokeStatic"",
            ""diff.clj"",
            9
        ],
        [
            ""metabase.models.revision.diff$diff_string"",
            ""invoke"",
            ""diff.clj"",
            8
        ],
        [
            ""metabase.models.revision.diff$diff_strings_STAR_"",
            ""invokeStatic"",
            ""diff.clj"",
            133
        ],
        [
            ""metabase.models.revision.diff$diff_strings_STAR_"",
            ""invoke"",
            ""diff.clj"",
            119
        ],
        [
            ""metabase.models.revision$fn__75469"",
            ""invokeStatic"",
            ""revision.clj"",
            58
        ],
        [
            ""metabase.models.revision$fn__75469"",
            ""invoke"",
            ""revision.clj"",
            56
        ],
        [
            ""metabase.models.dashboard$fn__77125"",
            ""invokeStatic"",
            ""dashboard.clj"",
            319
        ],
        [
            ""metabase.models.dashboard$fn__77125"",
            ""invoke"",
            ""dashboard.clj"",
            302
        ],
        [
            ""clojure.lang.MultiFn"",
            ""invoke"",
            ""MultiFn.java"",
            239
        ],
        [
            ""metabase.models.revision$revision_changes"",
            ""invokeStatic"",
            ""revision.clj"",
            129
        ],
        [
            ""metabase.models.revision$revision_changes"",
            ""invoke"",
            ""revision.clj"",
            121
        ],
        [
            ""metabase.models.revision$revision_description_info"",
            ""invokeStatic"",
            ""revision.clj"",
            133
        ],
        [
            ""metabase.models.revision$revision_description_info"",
            ""invoke"",
            ""revision.clj"",
            131
        ],
        [
            ""metabase.models.revision$add_revision_details"",
            ""invokeStatic"",
            ""revision.clj"",
            149
        ],
        [
            ""metabase.models.revision$add_revision_details"",
            ""invoke"",
            ""revision.clj"",
            144
        ],
        [
            ""metabase.models.revision$revisions_PLUS_details"",
            ""invokeStatic"",
            ""revision.clj"",
            170
        ],
        [
            ""metabase.models.revision$revisions_PLUS_details"",
            ""invoke"",
            ""revision.clj"",
            162
        ],
        [
            ""metabase.api.revision$fn__101197"",
            ""invokeStatic"",
            ""revision.clj"",
            28
        ],
        [
            ""metabase.api.revision$fn__101197"",
            ""invoke"",
            ""revision.clj"",
            21
        ],
        [
            ""compojure.core$wrap_response$fn__44291"",
            ""invoke"",
            ""core.clj"",
            160
        ],
        [
            ""compojure.core$wrap_route_middleware$fn__44275"",
            ""invoke"",
            ""core.clj"",
            132
        ],
        [
            ""compojure.core$wrap_route_info$fn__44280"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44284"",
            ""invoke"",
            ""core.clj"",
            151
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.auth$enforce_authentication$fn__93571"",
            ""invoke"",
            ""auth.clj"",
            17
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44331"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.api.routes$fn__101461$fn__101462"",
            ""invoke"",
            ""routes.clj"",
            65
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            667
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""metabase.server.routes$fn__101626$fn__101627"",
            ""doInvoke"",
            ""routes.clj"",
            72
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44331"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44284"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44284"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44284"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44331"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304$respond_SINGLEQUOTE___44305"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44335"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44303$f__44304"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44303"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98255"",
            ""invoke"",
            ""exceptions.clj"",
            107
        ],
        [
            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__98252"",
            ""invoke"",
            ""exceptions.clj"",
            96
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103575$fn__103576$fn__103577"",
            ""invoke"",
            ""log.clj"",
            216
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invokeStatic"",
            ""diagnostic.clj"",
            18
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invoke"",
            ""diagnostic.clj"",
            12
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103575$fn__103576"",
            ""invoke"",
            ""log.clj"",
            208
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invokeStatic"",
            ""execute.clj"",
            112
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invoke"",
            ""execute.clj"",
            103
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103575"",
            ""invoke"",
            ""log.clj"",
            207
        ],
        [
            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__108311"",
            ""invoke"",
            ""browser_cookie.clj"",
            40
        ],
        [
            ""metabase.server.middleware.security$add_security_headers$fn__84441"",
            ""invoke"",
            ""security.clj"",
            182
        ],
        [
            ""metabase.server.middleware.json$wrap_json_body$fn__45649"",
            ""invoke"",
            ""json.clj"",
            67
        ],
        [
            ""metabase.server.middleware.offset_paging$handle_paging$fn__84465"",
            ""invoke"",
            ""offset_paging.clj"",
            45
        ],
        [
            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__45667"",
            ""invoke"",
            ""json.clj"",
            103
        ],
        [
            ""ring.middleware.keyword_params$wrap_keyword_params$fn__108578"",
            ""invoke"",
            ""keyword_params.clj"",
            55
        ],
        [
            ""ring.middleware.params$wrap_params$fn__108597"",
            ""invoke"",
            ""params.clj"",
            77
        ],
        [
            ""metabase.server.middleware.misc$maybe_set_site_url$fn__66808"",
            ""invoke"",
            ""misc.clj"",
            61
        ],
        [
            ""metabase.server.middleware.session$reset_session_timeout$fn__72252"",
            ""invoke"",
            ""session.clj"",
            542
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__72218$fn__72219"",
            ""invoke"",
            ""session.clj"",
            437
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invokeStatic"",
            ""session.clj"",
            416
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invoke"",
            ""session.clj"",
            400
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__72218"",
            ""invoke"",
            ""session.clj"",
            436
        ],
        [
            ""metabase.server.middleware.session$wrap_current_user_info$fn__72201"",
            ""invoke"",
            ""session.clj"",
            375
        ],
        [
            ""metabase.server.middleware.session$wrap_session_id$fn__72173"",
            ""invoke"",
            ""session.clj"",
            254
        ],
        [
            ""metabase.server.middleware.auth$wrap_static_api_key$fn__93579"",
            ""invoke"",
            ""auth.clj"",
            30
        ],
        [
            ""ring.middleware.cookies$wrap_cookies$fn__108498"",
            ""invoke"",
            ""cookies.clj"",
            216
        ],
        [
            ""metabase.server.middleware.misc$add_content_type$fn__66790"",
            ""invoke"",
            ""misc.clj"",
            29
        ],
        [
            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__66816"",
            ""invoke"",
            ""misc.clj"",
            78
        ],
        [
            ""ring.middleware.gzip$wrap_gzip$fn__108540"",
            ""invoke"",
            ""gzip.clj"",
            86
        ],
        [
            ""metabase.server.middleware.misc$bind_request$fn__66819"",
            ""invoke"",
            ""misc.clj"",
            95
        ],
        [
            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__108327"",
            ""invoke"",
            ""ssl.clj"",
            51
        ],
        [
            ""metabase.server$async_proxy_handler$fn__66984"",
            ""invoke"",
            ""server.clj"",
            78
        ],
        [
            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
            ""handle"",
            null,
            -1
        ],
        [
            ""org.eclipse.jetty.server.handler.StatisticsHandler"",
            ""handle"",
            ""StatisticsHandler.java"",
            173
        ],
        [
            ""org.eclipse.jetty.server.handler.HandlerWrapper"",
            ""handle"",
            ""HandlerWrapper.java"",
            122
        ],
        [
            ""org.eclipse.jetty.server.Server"",
            ""handle"",
            ""Server.java"",
            563
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
            ""dispatch"",
            ""HttpChannel.java"",
            1598
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""dispatch"",
            ""HttpChannel.java"",
            753
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""handle"",
            ""HttpChannel.java"",
            501
        ],
        [
            ""org.eclipse.jetty.server.HttpConnection"",
            ""onFillable"",
            ""HttpConnection.java"",
            287
        ],
        [
            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
            ""succeeded"",
            ""AbstractConnection.java"",
            314
        ],
        [
            ""org.eclipse.jetty.io.FillInterest"",
            ""fillable"",
            ""FillInterest.java"",
            100
        ],
        [
            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
            ""run"",
            ""SelectableChannelEndPoint.java"",
            53
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""runTask"",
            ""AdaptiveExecutionStrategy.java"",
            421
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""consumeTask"",
            ""AdaptiveExecutionStrategy.java"",
            390
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""tryProduce"",
            ""AdaptiveExecutionStrategy.java"",
            277
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""run"",
            ""AdaptiveExecutionStrategy.java"",
            199
        ],
        [
            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
            ""run"",
            ""ReservedThreadExecutor.java"",
            411
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
            ""runJob"",
            ""QueuedThreadPool.java"",
            969
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""doRunJob"",
            ""QueuedThreadPool.java"",
            1194
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""run"",
            ""QueuedThreadPool.java"",
            1149
        ],
        [
            ""java.lang.Thread"",
            ""run"",
            null,
            -1
        ]
    ],
    ""message"": null
}
```

### To Reproduce

1) go to dashboard e357
2) go to the revision history

### Expected behavior

The revision history should return

### Logs

NA

### Information about your Metabase installation

```JSON
master
```


### Severity

P1

### Additional context

Flagging as P1 as we're completely wiping the exception here",paoliniluis,2024-02-19 14:10:52+00:00,['adam-james-v'],2024-03-07 21:29:25+00:00,2024-03-07 19:08:29+00:00,https://github.com/metabase/metabase/issues/38910,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1953009744, 'issue_id': 2142463850, 'author': 'noahmoss', 'body': 'based on the stack trace, likely introduced by https://github.com/metabase/metabase/pull/38247\r\n\r\nfyi @adam-james-v', 'created_at': datetime.datetime(2024, 2, 19, 18, 42, 24, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-02-19 18:42:24 UTC): based on the stack trace, likely introduced by https://github.com/metabase/metabase/pull/38247

fyi @adam-james-v

"
2142338786,issue,closed,completed,Broken list of columns in table settings if the setting value is out of sync with the query,"### Describe the bug

When `table.columns` setting is out of sync with the query, the list of columns in the table viz settings is incomplete. It's impossible to recover from this state without updating the query or recreating the question.

### To Reproduce

https://metaboat.slack.com/archives/C01MS7DQKR6/p1708089997707009

There is no straightforward way to reproduce this without changing data via API directly. `table.columns` viz should be should be manually set to a subset of columns.

### Expected behavior

- When hiding or making columns visible, columns from the query results should be displayed (like we already do for native queries)
- In add/remove columns mode ""visible columns"" from the query should be used for the source of truth.

### Logs

_No response_

### Information about your Metabase installation

```JSON
-
```


### Severity

P1/P2

### Additional context

_No response_",ranquild,2024-02-19 13:09:02+00:00,['ranquild'],2024-02-21 12:32:10+00:00,2024-02-21 12:21:45+00:00,https://github.com/metabase/metabase/issues/38908,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2141947584,issue,closed,completed,Add hover card column metadata on Filter modal,"As part of https://github.com/metabase/metabase/issues/38394 we want to display column info in the Filter by modal.

<img width=""662"" alt=""Screenshot 2024-02-19 at 11 13 26"" src=""https://github.com/metabase/metabase/assets/1250185/791e8b29-7d55-44a4-a4a8-3c5aa239c578"">
",romeovs,2024-02-19 09:44:50+00:00,['romeovs'],2024-02-20 13:42:06+00:00,2024-02-20 13:42:06+00:00,https://github.com/metabase/metabase/issues/38902,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1954243085, 'issue_id': 2141947584, 'author': 'romeovs', 'body': 'Closed by https://github.com/metabase/metabase/pull/38916', 'created_at': datetime.datetime(2024, 2, 20, 13, 42, 6, tzinfo=datetime.timezone.utc)}]","romeovs (Issue Creator) on (2024-02-20 13:42:06 UTC): Closed by https://github.com/metabase/metabase/pull/38916

"
2140988751,issue,open,,findColumnIndexesFromLegacyRefs doesn't find legacy columns for nested queries with integer-based field refs,"### Describe the bug

```
const [fieldIndex] = Lib.findColumnIndexesFromLegacyRefs(
    query,
    stageIndex,
    fields.map(field => Lib.fromLegacyColumn(query, stageIndex, field)),
    [fieldRef],
  );
```

It doesn't find the column if the query is based on a saved question and numeric field ids are used. I believe it has something to do with ""broken integer-based"" field refs for nested queries, which seems to be handled for regular MLv2 columns (e.g. `visibleColumns`) but not when converting from a legacy column.

<img width=""923"" alt=""Screenshot 2024-02-18 at 15 21 07"" src=""https://github.com/metabase/metabase/assets/8542534/40bead4c-e64f-4982-b78d-ec4b1d1ed519"">


### To Reproduce

relevant code:
```
const [fieldIndex] = Lib.findColumnIndexesFromLegacyRefs(
    query,
    stageIndex,
    fields.map(field => Lib.fromLegacyColumn(query, stageIndex, field)),
    [fieldRef],
  );
```

See the screenshot above

### Expected behavior

`findColumnIndexesFromLegacyRefs` should find the column

### Logs

_No response_

### Information about your Metabase installation

```JSON
-
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-02-18 13:24:55+00:00,[],2025-02-04 20:27:14+00:00,,https://github.com/metabase/metabase/issues/38892,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2139634433,issue,open,,reenable #38887,"### Describe the bug

so recap: master is failing in a way that matters, but not a freakout. We should disable the failing test while we fix it. 
@camsaul ’s QP change was fantastic and welcome, but apparently doesn’t handle one very niche edge case. Sandboxes can be based on queries and it seems to fail if these queries lack metadata (the underlying question’s metadata must be [] for the repro). The streaming api throws an error but it still writes the second half of the json endpoint, so we end up with malformed json. I’m trying to get a BE test that fails but it really needs to head over the wire and not even our http handlers are having it. We have tests in metabase-enterprise.sandbox.query-processor.middleware.row-level-restrictions-test/native-fk-remapping-test that are close but don’t quite exercise it.

https://github.com/metabase/metabase/pull/38887 disables the test

### To Reproduce

![image](https://github.com/metabase/metabase/assets/6377293/5615d0b9-fcf4-441d-a083-7a0ef4166491)

sandboxing based on saved questions. Might need to ensure those questions have no result_metadata (something that can happen if someone just saves a question without running it).

if you need a bit of local help:
```clojure

(doseq [id [76 77]] ;; whatever your ids are
  (toucan2.core/update! :model/Card id {:result_metadata []}))
```

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p3

### Additional context

this feature is valuable and important. This is a rough edge that we need to come back to but in a day or two.",dpsutton,2024-02-16 23:34:49+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/38888,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2187077843, 'issue_id': 2139634433, 'author': 'camsaul', 'body': 'recategorizing as P2 since reenabling a test is not really a P1', 'created_at': datetime.datetime(2024, 6, 24, 17, 34, 55, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-06-24 17:34:55 UTC): recategorizing as P2 since reenabling a test is not really a P1

"
2139513134,issue,closed,completed,[dc.js migration] Add error boundary to the CartesianChart to show error messages,Previous line/area/bar/combo/waterfall/scatter charts gracefully propagated errors to the parent Visualization component with `this.props.onRenderError(err.message || err);` so it shows actual error messages.,alxnddr,2024-02-16 21:28:56+00:00,['EmmadUsmani'],2024-02-27 21:18:38+00:00,2024-02-27 21:18:27+00:00,https://github.com/metabase/metabase/issues/38881,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2138956575,issue,closed,completed,"Add hover card column metadata on custom expressions (custom columns, aggregations)","As part of https://github.com/metabase/metabase/issues/38394 we want surface more info on columns in the custom expression popover.
<img width=""353"" alt=""Screenshot 2024-02-16 at 17 29 41"" src=""https://github.com/metabase/metabase/assets/1250185/93bee4e1-e07c-4026-b833-d7470a3c38b2"">
",romeovs,2024-02-16 16:29:00+00:00,['romeovs'],2024-02-20 13:40:56+00:00,2024-02-20 13:40:52+00:00,https://github.com/metabase/metabase/issues/38869,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2138915193,issue,open,,Add date and time to PDF export,"**Is your feature request related to a problem? Please describe.**
You want to know when is that export from

**Describe the solution you'd like**
Users would want to have date and time in PDF exported dashboards

**Describe alternatives you've considered**
Add a text card with variable but it's a workaround

**How important is this feature to you?**
Requested by a customer

**Additional context**
N/A
",ignacio-mb,2024-02-16 16:03:16+00:00,[],2024-02-16 16:03:17+00:00,,https://github.com/metabase/metabase/issues/38868,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Reporting/Export', '')]",[],
2138914298,issue,closed,completed,[Epic] Add license activation in the initial setup,"**Links**
- product doc: [Add license activation step in /setup](https://www.notion.so/metabase/Add-license-activation-step-in-setup-c186326d2efd4467a7e9d09138fca48c)
- eng doc: [Add license activation step in /setup](https://www.notion.so/metabase/Add-license-activation-step-in-setup-77d8f3e5c2484226b8a162098b6eea5b)
- feature branch: [`license-activation-step`](https://github.com/metabase/metabase/pull/39257)

***Milestone 1***

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/38858
- [ ] https://github.com/metabase/metabase/pull/38953
- [ ] https://github.com/metabase/metabase/pull/39151
- [ ] https://github.com/metabase/metabase/pull/39103
- [ ] https://github.com/metabase/metabase/pull/39292
- [ ] https://github.com/metabase/metabase/pull/39440
- [ ] https://github.com/metabase/metabase/pull/39443
- [ ] https://github.com/metabase/metabase/pull/39257
```


***Milestone 2 - polishing***

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/39067
- [ ] https://github.com/metabase/metabase/pull/39931
- [x] ask schema change for the events
```
",npretto,2024-02-16 16:02:47+00:00,['npretto'],2024-03-25 08:26:12+00:00,2024-03-25 08:26:12+00:00,https://github.com/metabase/metabase/issues/38867,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', '')]",[],
2138910383,issue,closed,completed,`Year of Era` bucketing does not work,"### Describe the bug

Year of era bucket is not working.

### To reproduce
- Open this [model](https://stats.metabase.com/model/16582-uk-car-accidents-1)
- Try summarizing by Date: year of era
- It shows an error
<img width=""1709"" alt=""Screenshot 2024-03-22 at 8 05 18 PM"" src=""https://github.com/metabase/metabase/assets/14301985/565b10b8-bc1f-4530-a064-69998119fa1c"">

`Invalid input: {:query {:breakout [[nil nil {:temporal-unit [""datetime bucketing unit""], :malli/error [""Invalid :temporal-unit for the specified :base-type.""]}]]}}`

### Severity
Not sure if there is a huge demand for this specific bucketing. Maybe hiding it from UI is a sensible option.

Latest master.",EmmadUsmani,2024-02-16 16:01:00+00:00,['wzimrin'],2025-02-03 22:00:44+00:00,2025-01-31 20:25:34+00:00,https://github.com/metabase/metabase/issues/38866,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2202562190, 'issue_id': 2138910383, 'author': 'kamilmielnik', 'body': '> does not work on timeseries x-axis\r\n\r\nIt does not seem to work at all. I\'ve raised priority to P2.\r\n\r\nRepro steps with sample database:\r\n1. Create a question based on Orders table\r\n2. Add a breakout by User -> Birth Date -> by year of era\r\n3. Visualize\r\n\r\nError: \r\n```\r\nInvalid output: {:query {:breakout [[nil nil {:temporal-unit [""datetime bucketing unit, got: :year-of-era""], :malli/error [""Invalid :temporal-unit for the specified :base-type., got: {:base-type :type/Date, :temporal-unit :year-of-era, :source-field 43}""]}]]}}\r\n```', 'created_at': datetime.datetime(2024, 7, 2, 9, 35, 6, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-07-02 09:35:06 UTC): It does not seem to work at all. I've raised priority to P2.

Repro steps with sample database:
1. Create a question based on Orders table
2. Add a breakout by User -> Birth Date -> by year of era
3. Visualize

Error: 
```
Invalid output: {:query {:breakout [[nil nil {:temporal-unit [""datetime bucketing unit, got: :year-of-era""], :malli/error [""Invalid :temporal-unit for the specified :base-type., got: {:base-type :type/Date, :temporal-unit :year-of-era, :source-field 43}""]}]]}}
```

"
2138842408,issue,closed,completed,Add hover card column metadata on join column picker,"As part of https://github.com/metabase/metabase/issues/38394, we want to surface more information on columns in the join column picker.",romeovs,2024-02-16 15:25:40+00:00,['romeovs'],2024-02-29 10:53:38+00:00,2024-02-29 10:53:33+00:00,https://github.com/metabase/metabase/issues/38863,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1970881350, 'issue_id': 2138842408, 'author': 'romeovs', 'body': 'Closed by #38967', 'created_at': datetime.datetime(2024, 2, 29, 10, 53, 33, tzinfo=datetime.timezone.utc)}]","romeovs (Issue Creator) on (2024-02-29 10:53:33 UTC): Closed by #38967

"
2138839795,issue,closed,completed,Allow reordering of items in notebook mode,"**Is your feature request related to a problem? Please describe.**
Right now, you can't change the order of items in the notebook mode. E.g. change the sort items, or change the order of the aggregations.

**Describe the solution you'd like**
Change the order of the items via drag and drop

**Describe alternatives you've considered**
Right now you need to remove, and add again

**How important is this feature to you?**
Requested by one of our customers and I think it's a great ergonomic win

**Additional context**
NA
",paoliniluis,2024-02-16 15:24:05+00:00,['ranquild'],2024-03-14 12:32:35+00:00,2024-03-14 12:32:35+00:00,https://github.com/metabase/metabase/issues/38862,"[('Type:New Feature', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder')]",[],
2138818202,issue,closed,not_planned,Bar graph visualization fails with filtering an aggregation,"### Describe the bug

Creating a query with a second stage, filtering on the value of an aggregation in the previous stage, breaks the visualization. It shows a greyed-out ""tombstone"" placeholder instead of the real data.

The query and returned data look sound. Not sure if this is an MLv2 issue, FE issue, or both. I can reproduce on master and in 0.49.0 RC1 so this feels like an RC2 blocker.

### To Reproduce

1. Create a new GUI question
2. Orders, COUNT by Subtotal, auto binned.
3. Visualize - it works fine.
4. Reopen the editor and add a filter **after the aggregation** - COUNT > 1000.
    - Some bins meet that filter, some don't.
5. Visualize again.

### Expected behavior

Should correctly show the corresponding histogram, set the visualization to one that does work (like table) or show a meaningful error message.

### Logs

Nothing in the console.

### Information about your Metabase installation

```JSON
0.49.0 RC1 and master
```


### Severity

Seems like a pretty bad UX, blocking gold and maybe RC2

### Additional context

Tombstone viz 
![2024-02-16-093551_1867x1561_scrot](https://github.com/metabase/metabase/assets/157812/4580ffa3-ad62-49ec-abe8-bef2aca4e668)

It's perhaps even worse in a dashboard 
![2024-02-16-093732_1829x1202_scrot](https://github.com/metabase/metabase/assets/157812/4e9bcc2d-ece2-41be-80df-9ea4ca1feb92)

But it works correctly in table viz
![2024-02-16-101101_541x681_scrot](https://github.com/metabase/metabase/assets/157812/40006d9f-e8b9-4687-81fe-35be6bf3ce2a)
",bshepherdson,2024-02-16 15:11:42+00:00,['kulyk'],2024-06-05 11:54:26+00:00,2024-06-05 11:54:25+00:00,https://github.com/metabase/metabase/issues/38861,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1953082898, 'issue_id': 2138818202, 'author': 'dpsutton', 'body': ""Removed the 49 milestone as this doesn't seem to be a recent regression. @metamben noticed it also did not work in 0.48.6."", 'created_at': datetime.datetime(2024, 2, 19, 19, 53, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2149646831, 'issue_id': 2138818202, 'author': 'kulyk', 'body': 'Duplicate of #10493', 'created_at': datetime.datetime(2024, 6, 5, 11, 54, 25, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-02-19 19:53:09 UTC): Removed the 49 milestone as this doesn't seem to be a recent regression. @metamben noticed it also did not work in 0.48.6.

kulyk (Assginee) on (2024-06-05 11:54:25 UTC): Duplicate of #10493

"
2138639671,issue,closed,not_planned,Dashboard + required filter: default isn't picked up when URL param is empty,"### Describe the bug

If filter value is empty in the URL, it's not set to default for a required filter.

<img width=""1125"" alt=""Screenshot 2024-02-16 at 13 33 48"" src=""https://github.com/metabase/metabase/assets/2196347/aa1c9aaa-ff85-42ee-88ec-c7f19f1f2716"">


### To Reproduce

1. Create/get a dashboard with a required filter
2. Open it and **unset** its value from the URL
3. See that the filter appears empty

### Expected behavior

It should use default value and, possibly, even change the URL

### Logs

{}

### Information about your Metabase installation

```JSON
{}
```


### Severity

P3

### Additional context

_No response_",oleggromov,2024-02-16 13:35:50+00:00,['ranquild'],2024-07-16 02:07:17+00:00,2024-07-16 02:07:14+00:00,https://github.com/metabase/metabase/issues/38857,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 1959909573, 'issue_id': 2138639671, 'author': 'oleggromov', 'body': ""Quite likely this is related to the behavior introduced here https://github.com/metabase/metabase/pull/31891 \r\nI need to investigate furhter, as the most straightforward solution didn't work."", 'created_at': datetime.datetime(2024, 2, 22, 17, 19, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229864473, 'issue_id': 2138639671, 'author': 'ranquild', 'body': 'This is currently by design and our way to clear filters with default values.', 'created_at': datetime.datetime(2024, 7, 16, 2, 7, 14, tzinfo=datetime.timezone.utc)}]","oleggromov (Issue Creator) on (2024-02-22 17:19:06 UTC): Quite likely this is related to the behavior introduced here https://github.com/metabase/metabase/pull/31891 
I need to investigate furhter, as the most straightforward solution didn't work.

ranquild (Assginee) on (2024-07-16 02:07:14 UTC): This is currently by design and our way to clear filters with default values.

"
2138547374,issue,closed,completed,"No Access to Our Analytics will break the  ""Add to Dashboard"" in multiple ways","### Describe the bug

The bug is split into 2:

1) When you don't have a dashboard in your personal collection:

Prompt will break with `You don't have permissions to do that` after Question is saved in Personal Collection and you proceed with the  ""Add to Dashboard"" prompt

2) When you do have a dashboard in your personal collection:

The other collection options are not given as an option and only the personal collection is visible


### To Reproduce

1. Go to New ->  Collection -> Shared Collection
2. Go to Admin Settings -> Permission -> Collection -> Give Our Analytics No Access to All Users (Shared Collection should be Curate)

<img width=""1378"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/e88d39f7-d774-4674-8110-296a36244e6e"">

3. Go to People -> Invite New User -> Make sure it has All Users Group
4. Login to Metabase with this New user
5. New -> Question -> Sample Database -> Orders -> Save 

<img width=""1497"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/2641ef39-d924-486a-a900-40a9806c6855"">

6. You will notice at this point you get prompt where to Save the collection -> Save in your Personal Collection and you will get the prompt Add this Question to Dashboard -> Click Yes -> You will get a Permission Error

<img width=""1505"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/c714dabe-b638-43bf-b0e3-b5911ee2bdb9"">

Note that if on the other hand you decide to save the question in the Shared Collection then Click Yes on the ""Add Question to Dashboard"" prompt, you get both options:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/57557ea1-3f97-48b5-8aa8-20d3d5a2f972"">


You can bypass this Error by creating a Dashboard in your Personal Collection but when you do so and rerun the process above the ""Add to Dashboard"" prompt will only show your personal collection not the `Shared Collection`

<img width=""1506"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/db885c9a-45c8-4c94-94de-8e0e8beccec4"">


### Expected behavior

Remove the You don't have permission Error when you don't have a dashboard in the personal collection and when you do have a dashboard make sure all collections are given as an options

### Logs

You don't have permissions to do that

### Information about your Metabase installation

```JSON
Able to replicate in 1.48.6
```


### Severity

Annoying since you have to always add the Question directly on the Dashboard making the prompt useless

### Additional context

_No response_",Tony-metabase,2024-02-16 12:39:57+00:00,['npfitz'],2024-06-07 12:28:14+00:00,2024-06-05 15:31:14+00:00,https://github.com/metabase/metabase/issues/38856,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Organization/Collections', ''), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2013715713, 'issue_id': 2138547374, 'author': 'luizarakaki', 'body': 'this is likely related to #38759', 'created_at': datetime.datetime(2024, 3, 21, 20, 54, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150003883, 'issue_id': 2138547374, 'author': 'iethree', 'body': 'this may have been fixed by the entity picker (v50) - we did a lot of work to handle this case', 'created_at': datetime.datetime(2024, 6, 5, 13, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150039072, 'issue_id': 2138547374, 'author': 'npfitz', 'body': ""Yeah, I'm checking this now"", 'created_at': datetime.datetime(2024, 6, 5, 13, 55, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150364952, 'issue_id': 2138547374, 'author': 'Tony-metabase', 'body': 'Was too fast to escalated this! Indeed was not able to replicate this on 49.13 and also tested on 50 which changes the outlook completely. \r\n\r\nSo this is now fine on new versions', 'created_at': datetime.datetime(2024, 6, 5, 15, 31, 14, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-21 20:54:17 UTC): this is likely related to #38759

iethree on (2024-06-05 13:47:04 UTC): this may have been fixed by the entity picker (v50) - we did a lot of work to handle this case

npfitz (Assginee) on (2024-06-05 13:55:09 UTC): Yeah, I'm checking this now

Tony-metabase (Issue Creator) on (2024-06-05 15:31:14 UTC): Was too fast to escalated this! Indeed was not able to replicate this on 49.13 and also tested on 50 which changes the outlook completely. 

So this is now fine on new versions

"
2138506167,issue,open,,Add Sandboxing Support to Actions,"**Is your feature request related to a problem? Please describe.**
Currently Actions doesn't work with Sandboxing. So any Sandboxed user even though they cannot see the data of a specific model they can still delete Rows. For example 

1) The first image shows Orders Model Sandboxed by Gizmo

![image](https://github.com/metabase/metabase/assets/110378427/c3a8c5cf-3027-45d1-a263-b89e1c5dcf92)

2) You will notice ID = 10 doesn't exist in the model because its sandboxed but I am able to add 10 in the filter which shows that the ID doesn't exist (because I am sandboxed)

![image](https://github.com/metabase/metabase/assets/110378427/4b220f37-0490-46f1-839d-b67f7faace91)

3) I am able to delete .. In Fact it says Deleted Successful

![image](https://github.com/metabase/metabase/assets/110378427/779ec51f-e722-4ca8-9082-1c774eab3a0f)

4) If i go back to delete 10 it says it doesn't exist which makes sense because I just deleted it but I would expect sandboxing to work in a similar manner.

![image](https://github.com/metabase/metabase/assets/110378427/19e8f284-6da4-4f41-99a6-4a0bada185fc)

**Describe the solution you'd like**
Some error message similar to this one:

![image](https://github.com/metabase/metabase/assets/110378427/5012b281-cf1a-4674-a1e7-0a3a9714779b)

**How important is this feature to you?**
Once we decide to start supporting Actions it needs to be integrated with all other features of metabase else it's use will be pretty limited
",Tony-metabase,2024-02-16 12:20:19+00:00,[],2024-02-21 14:24:54+00:00,,https://github.com/metabase/metabase/issues/38855,"[('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Administration/Data Sandboxes', 'Enterprise Sandboxing'), ('Querying/Actions', '')]",[],
2138459389,issue,closed,completed,[Epic] CSV Append Follow-Ups,"This is an epic for the tasks left over from https://github.com/metabase/metabase/issues/35614 that didn't make it to the 49 RC1.

**Links**
- [product doc](https://www.notion.so/metabase/Allow-appends-on-existing-CSV-upload-models-f1f13864632d4cfd83522fce762890eb#58380830c6ca45df923e4cacc4af1964)
- [eng doc](https://www.notion.so/metabase/Eng-Allow-appending-more-data-to-CSV-uploads-4c40e06fa64744c699588b8d8576e5df)

```[tasklist]
### Cleanup / Misc
- [ ] https://github.com/metabase/metabase/issues/38955
- [ ] https://github.com/metabase/metabase/issues/38956
- [ ] https://github.com/metabase/metabase/issues/38958
- [ ] https://github.com/metabase/metabase/issues/37069
- [ ] https://github.com/metabase/metabase/issues/39818
- [ ] https://github.com/metabase/metabase/issues/39867
- [ ] https://github.com/metabase/metabase/issues/39868
- [ ] https://github.com/metabase/metabase/issues/34325
```",calherries,2024-02-16 11:58:31+00:00,[],2024-03-25 14:49:47+00:00,2024-03-25 14:49:47+00:00,https://github.com/metabase/metabase/issues/38853,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2138282856,issue,closed,not_planned,SQL editor formatting capability,"**Is your feature request related to a problem? Please describe.**
SQL queries behind cards go wild without proper formatting (and linting, that would be for next feat request). Unformatted SQL queries are hardly readable, make the whole management on un-versioned SQL scripts around your Metabase account a nightmare. 

**Describe the solution you'd like**
Option to enable format on save (VSCode-like). When enabling formatting, one should have the option to select SQL dialect she wants the query to be formatted along (a starting point reference could be --> https://docs.sqlfluff.com/en/stable/dialects.html). This could also be configured at database level, i.e. whenever I create a database connection to a certain DB, I can setup that all SQL queries targeting that db will be auto-formatted according to a certain dialect (consistent with chosen DB).  

**Describe alternatives you've considered**
Alternative is for me to go through each query one by one, copy-pasting it to another tool, then formatting it, then copy-pasting it back to Metabase SQL editor. Not great.

**How important is this feature to you?**
This is not a must-have but it really is a WOW-feature.
",darioprencipe,2024-02-16 10:17:51+00:00,[],2024-02-16 10:30:50+00:00,2024-02-16 10:30:49+00:00,https://github.com/metabase/metabase/issues/38851,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 1948126421, 'issue_id': 2138282856, 'author': 'paoliniluis', 'body': 'Coming in 49 if I’m not mistaken', 'created_at': datetime.datetime(2024, 2, 16, 10, 30, 49, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-16 10:30:49 UTC): Coming in 49 if I’m not mistaken

"
2138091737,issue,closed,completed,Add hover card column metadata on Notebook filters,"Add the info hovercard to the items in the filter popover.

<img width=""709"" alt=""Screenshot 2024-02-16 at 13 03 01"" src=""https://github.com/metabase/metabase/assets/1250185/b4da6835-ec83-40bb-89df-f8530b9651e5"">",romeovs,2024-02-16 08:15:06+00:00,['romeovs'],2024-02-20 13:40:43+00:00,2024-02-20 13:40:36+00:00,https://github.com/metabase/metabase/issues/38845,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2137709941,issue,closed,completed,[dc.js migration] incorrect formatting on x-axis ticks using native query date columns,"Affects all cartesian charts:
<img width=""1363"" alt=""Screenshot 2024-02-15 at 8 04 55 PM"" src=""https://github.com/metabase/metabase/assets/14301985/749daece-55cf-44cf-b2d5-a7d0b39aa7cd"">
",alxnddr,2024-02-16 01:17:06+00:00,['alxnddr'],2024-02-29 20:29:11+00:00,2024-02-29 20:29:11+00:00,https://github.com/metabase/metabase/issues/38843,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2137702645,issue,closed,completed,[dc.js migration] remove log/pow x-axis scale types for relative date x-axis values like `day-of-month`,"It does not bring much value to have log/pow x-axis that shows days of week. These options did not work correctly on bar/watefall charts since bars always had the same width while x-axis is not linear. Motivation to remove them is unreasonable effort to add them in ECharts while bringing not much value.

Discussion and explanation can be found here https://www.notion.so/metabase/Time-series-waterfall-charts-with-relative-units-a4d5346591b24813ac171e73403d1d17?pvs=4#bc5dcab5bc274ce2a9ce09ff2c069e08",alxnddr,2024-02-16 01:09:11+00:00,['alxnddr'],2024-03-25 21:06:13+00:00,2024-03-25 21:06:13+00:00,https://github.com/metabase/metabase/issues/38842,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2137697997,issue,closed,completed,[dc.js migration] time series charts with week bucketing show shifted x-axis ticks,"When data has weekly buckets x-axis tick start from the previous day of the first item:
<img width=""1360"" alt=""Screenshot 2024-02-15 at 9 44 55 PM"" src=""https://github.com/metabase/metabase/assets/14301985/c624da7b-d5df-4d8a-a1a9-60df443cd235"">

Even setting `xAxis.min: ""dataMin""` does not fix the issue.
",alxnddr,2024-02-16 01:05:33+00:00,['alxnddr'],2024-02-29 20:29:14+00:00,2024-02-29 20:29:14+00:00,https://github.com/metabase/metabase/issues/38841,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2137659264,issue,closed,completed,[dc.js migration] goal line label missing from static viz,"http://localhost:3000/question/249-combo-goal-line-goal-line-under-series-38824

<img width=""570"" alt=""Screenshot 2024-02-15 at 4 24 30 PM"" src=""https://github.com/metabase/metabase/assets/37751258/6c6e4c04-4710-403b-871b-f61a1b0f98db"">

![image](https://github.com/metabase/metabase/assets/37751258/a75488a0-8dfd-4933-a0cd-640b514b4191)

",EmmadUsmani,2024-02-16 00:24:55+00:00,['EmmadUsmani'],2024-02-21 20:04:43+00:00,2024-02-21 20:04:43+00:00,https://github.com/metabase/metabase/issues/38840,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2137635358,issue,closed,completed,Manually choosing Axis in chart settings will break subscription,"### Describe the bug

If you manually change a Y-axis position for an aggregation, the subscription of that chart will break

### To Reproduce

1. Create a GUI or SQL question, Orders, Count of rows and aggregate by Created At and Category\
2. Now add the two aggregations to the series breakout if they are not already there
3. On the Data tab in Viz Settings of the question, manually change the Y-axis position of all categories to be Right
<img width=""469"" alt=""Screenshot 2024-04-08 at 2 35 55 PM"" src=""https://github.com/metabase/metabase/assets/132273646/81560046-1406-46d0-bc43-c7e44771cf39"">

4. Set ""Split y-axis when necessary"" Toggle to off
5. Add to a dashboard, create an email subscription, and see that the subscription will fail with error: An error occurred while displaying this card. Logs below
<img width=""579"" alt=""Screenshot 2024-04-08 at 2 36 47 PM"" src=""https://github.com/metabase/metabase/assets/132273646/6c5b7013-9745-4146-a4a0-6a953061e14f"">

If you have the Y-axis to Auto, it will show correctly. But It's kind of annoying because if you have two aggregations if in the chart is set to Auto and puts the aggregations to the right, in the subscription they will appear one on the right and one on the left. Flagging as P2 as there is no workaround


### Expected behavior

should not break the subscription

### Logs


<details>
<summary>Logs</summary>
[328909f9-2595-4a0d-b1dd-59d7bb64ddab] 2024-02-15T20:49:06-03:00 ERROR metabase.pulse.render Pulse card render error
org.apache.batik.transcoder.TranscoderException: null
Enclosed Exception:
file:///fake.svg:-1
The attribute ""y"" of the element <rect> is invalid
	at org.apache.batik.transcoder.SVGAbstractTranscoder.transcode(SVGAbstractTranscoder.java:228)
	at org.apache.batik.transcoder.image.ImageTranscoder.transcode(ImageTranscoder.java:92)
	at org.apache.batik.transcoder.XMLAbstractTranscoder.transcode(XMLAbstractTranscoder.java:142)
	at org.apache.batik.transcoder.SVGAbstractTranscoder.transcode(SVGAbstractTranscoder.java:158)
	at metabase.pulse.render.js_svg$render_svg.invokeStatic(js_svg.clj:108)
	at metabase.pulse.render.js_svg$render_svg.invoke(js_svg.clj:97)
	at metabase.pulse.render.js_svg$svg_string__GT_bytes.invokeStatic(js_svg.clj:112)
	at metabase.pulse.render.js_svg$svg_string__GT_bytes.invoke(js_svg.clj:111)
	at metabase.pulse.render.js_svg$combo_chart.invokeStatic(js_svg.clj:141)
	at metabase.pulse.render.js_svg$combo_chart.invoke(js_svg.clj:133)
	at metabase.pulse.render.body$lab_image_bundle.invokeStatic(body.clj:841)
	at metabase.pulse.render.body$lab_image_bundle.invoke(body.clj:816)
	at metabase.pulse.render.body$fn__74020$render__74008__74025$fn__74026.invoke(body.clj:860)
	at metabase.pulse.render.body$fn__74020$render__74008__74025.invoke(body.clj:858)
	at clojure.lang.MultiFn.invoke(MultiFn.java:261)
	at metabase.pulse.render$fn__74764$render_pulse_card_body__74769$fn__74773.invoke(render.clj:138)
	at metabase.pulse.render$fn__74764$render_pulse_card_body__74769.invoke(render.clj:128)
	at metabase.pulse.render$fn__74804$render_pulse_card__74809$fn__74810.invoke(render.clj:167)
	at metabase.pulse.render$fn__74804$render_pulse_card__74809.invoke(render.clj:149)
	at metabase.pulse.render$fn__74836$render_pulse_section__74841$fn__74845$fn__74848.invoke(render.clj:199)
	at metabase.pulse.render$fn__74836$render_pulse_section__74841$fn__74845.invoke(render.clj:197)
	at metabase.pulse.render$fn__74836$render_pulse_section__74841.invoke(render.clj:194)
	at metabase.email.messages$render_part.invokeStatic(messages.clj:442)
	at metabase.email.messages$render_part.invoke(messages.clj:438)
	at metabase.email.messages$render_message_body$fn__75903$fn__75904.invoke(messages.clj:495)
	at clojure.core$mapv$fn__8535.invoke(core.clj:6979)
	at clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:168)
	at clojure.core.protocols$fn__8249.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6886)
	at clojure.core$mapv.invokeStatic(core.clj:6970)
	at clojure.core$mapv.invoke(core.clj:6970)
	at metabase.email.messages$render_message_body$fn__75903.invoke(messages.clj:495)
	at metabase.email.messages$render_message_body.invokeStatic(messages.clj:494)
	at metabase.email.messages$render_message_body.invoke(messages.clj:492)
	at metabase.email.messages$render_pulse_email.invokeStatic(messages.clj:521)
	at metabase.email.messages$render_pulse_email.invoke(messages.clj:518)
	at metabase.pulse$fn__101942.invokeStatic(pulse.clj:431)
	at metabase.pulse$fn__101942.invoke(pulse.clj:420)
	at clojure.lang.MultiFn.invoke(MultiFn.java:239)
	at metabase.pulse$parts__GT_notifications$iter__102016__102020$fn__102021$fn__102022.invoke(pulse.clj:502)
	at metabase.pulse$parts__GT_notifications$iter__102016__102020$fn__102021.invoke(pulse.clj:500)
	at clojure.lang.LazySeq.sval(LazySeq.java:42)
	at clojure.lang.LazySeq.seq(LazySeq.java:51)
	at clojure.lang.RT.seq(RT.java:535)
	at clojure.core$seq__5467.invokeStatic(core.clj:139)
	at clojure.core$seq__5467.invoke(core.clj:139)
	at metabase.pulse$send_notifications_BANG_.invokeStatic(pulse.clj:555)
	at metabase.pulse$send_notifications_BANG_.invoke(pulse.clj:554)
	at metabase.pulse$send_pulse_BANG_.invokeStatic(pulse.clj:582)
	at metabase.pulse$send_pulse_BANG_.doInvoke(pulse.clj:563)
	at clojure.lang.RestFn.invoke(RestFn.java:410)
	at metabase.api.pulse$fn__102950.invokeStatic(pulse.clj:322)
	at metabase.api.pulse$fn__102950.invoke(pulse.clj:308)
	at compojure.core$wrap_response$fn__43939.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__43923.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__43928.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at metabase.server.middleware.auth$enforce_authentication$fn__95771.invoke(auth.clj:17)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$make_context$handler__43979.invoke(core.clj:290)
	at compojure.core$make_context$fn__43983.invoke(core.clj:300)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at metabase.api.routes$fn__103512$fn__103513.invoke(routes.clj:64)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__103675$fn__103676.doInvoke(routes.clj:72)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$make_context$handler__43979.invoke(core.clj:290)
	at compojure.core$make_context$fn__43983.invoke(core.clj:300)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__43932.invoke(core.clj:153)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:199)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$make_context$handler__43979.invoke(core.clj:290)
	at compojure.core$make_context$fn__43983.invoke(core.clj:300)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951$f__43952$respond_SINGLEQUOTE___43953.invoke(core.clj:197)
	at compojure.core$make_context$fn__43983.invoke(core.clj:301)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at compojure.core$routes$fn__43951$f__43952.invoke(core.clj:198)
	at compojure.core$routes$fn__43951.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100576.invoke(exceptions.clj:108)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__100573.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__105658$fn__105659$fn__105660.invoke(log.clj:216)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__105658$fn__105659.invoke(log.clj:208)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__105658.invoke(log.clj:207)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__110430.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__86432.invoke(security.clj:180)
	at metabase.server.middleware.json$wrap_json_body$fn__45312.invoke(json.clj:67)
	at metabase.server.middleware.offset_paging$handle_paging$fn__86456.invoke(offset_paging.clj:45)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__45330.invoke(json.clj:103)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__110697.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__110716.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__66189.invoke(misc.clj:61)
	at metabase.server.middleware.session$reset_session_timeout$fn__72224.invoke(session.clj:488)
	at metabase.server.middleware.session$bind_current_user$fn__72190$fn__72191.invoke(session.clj:383)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:362)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:346)
	at metabase.server.middleware.session$bind_current_user$fn__72190.invoke(session.clj:382)
	at metabase.server.middleware.session$wrap_current_user_info$fn__72173.invoke(session.clj:321)
	at metabase.server.middleware.session$wrap_session_id$fn__72156.invoke(session.clj:253)
	at metabase.server.middleware.auth$wrap_api_key$fn__95779.invoke(auth.clj:30)
	at ring.middleware.cookies$wrap_cookies$fn__110617.invoke(cookies.clj:216)
	at metabase.server.middleware.misc$add_content_type$fn__66171.invoke(misc.clj:29)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__66197.invoke(misc.clj:78)
	at ring.middleware.gzip$wrap_gzip$fn__110659.invoke(gzip.clj:86)
	at metabase.server.middleware.misc$bind_request$fn__66200.invoke(misc.clj:95)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__110446.invoke(ssl.clj:51)
	at metabase.server$async_proxy_handler$fn__66374.invoke(server.clj:78)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Unknown Source)
Caused by: org.apache.batik.bridge.BridgeException: file:///fake.svg:-1 

</details>

### Information about your Metabase installation

```JSON
- 48.5
```


### Severity

p2

### Additional context

e-charts scope?",ignacio-mb,2024-02-15 23:56:33+00:00,['adam-james-v'],2024-04-08 23:33:47+00:00,2024-04-08 23:24:56+00:00,https://github.com/metabase/metabase/issues/38839,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Pulses', 'Now called Subscriptions'), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2018704297, 'issue_id': 2137635358, 'author': 'ignacio-mb', 'body': '@perivamsi would this be in the `echarts-scope`?', 'created_at': datetime.datetime(2024, 3, 25, 19, 3, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2019187839, 'issue_id': 2137635358, 'author': 'perivamsi', 'body': '@adam-james-v can you please take a look?', 'created_at': datetime.datetime(2024, 3, 26, 0, 44, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037809450, 'issue_id': 2137635358, 'author': 'ixipixi', 'body': ""@adam-james-v @perivamsi I'm wondering the same about the e-charts scope."", 'created_at': datetime.datetime(2024, 4, 4, 17, 39, 51, tzinfo=datetime.timezone.utc)}]","ignacio-mb (Issue Creator) on (2024-03-25 19:03:01 UTC): @perivamsi would this be in the `echarts-scope`?

perivamsi on (2024-03-26 00:44:44 UTC): @adam-james-v can you please take a look?

ixipixi on (2024-04-04 17:39:51 UTC): @adam-james-v @perivamsi I'm wondering the same about the e-charts scope.

"
2137449091,issue,closed,completed,Option to Globally Disable Auto-Wiring of Filters on Dashboards,"**Is your feature request related to a problem? Please describe.**
If you have a dashboard that is comprised of both filtered an unfiltered cards by design, the auto-wiring functionality can become a point of frustration. each time you edit the filter it will auto-wire to all of the cards and you have to select the toast to undo it every time.

**Describe the solution you'd like**
An option to disable auto-wiring for the instance.
",ixipixi,2024-02-15 21:07:57+00:00,[],2025-01-09 14:49:54+00:00,2025-01-09 14:49:53+00:00,https://github.com/metabase/metabase/issues/38835,"[('Type:New Feature', ''), ('Administration/Settings', ''), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 1984963152, 'issue_id': 2137449091, 'author': 'notrom', 'body': 'To add a reproduction ...\r\n\r\n1. Create a dashboard with 3 questions based on the Sample DB > Orders table\r\n2. Add a date filter to the dashboard\r\n3. Link the new filter to ""Order.Created At"" on the first question, other questions are auto wired\r\n![image](https://github.com/metabase/metabase/assets/4504437/2e62121f-6dbc-4826-a086-4415ec6d82b8)\r\n\r\n4. Remove that filter from 2 questions, only 1 question is wired to the filter\r\n![image](https://github.com/metabase/metabase/assets/4504437/723337f0-1aca-4fc8-9652-ebb103707ebf)\r\n\r\n5. Change the remaining filter field to ""User.Birth Date"", all questions are wired to the filter again, **not what I wanted**, I\'ve already said I want no filters on 2 of them.\r\n![image](https://github.com/metabase/metabase/assets/4504437/5d72d139-e815-4c11-93a2-32312b849734)\r\n\r\n6. The toast would undo the auto wiring but it\'s only displayed for limited time (maybe 4 seconds), an if you\'ve got a large dashboard with lots of questions it can be tricky to figure out what\'s changed.\r\n\r\nThe auto wiring is great, but seems a bit too aggressive in the case where filter is empty, if it\'s already selected it won\'t be changed. It also gets more complicated when questions are based on different tables and have different fields available for filtering e.g. a dashboard with both orders and invoices, all filtered by the same dashboard date filter.\r\n\r\nPersonally I wouldn\'t want to disable auto wiring completely, just be able to have questions that are explicitly not going to be impacted by that dashboard filter (but may be by others) even though their base data contains the same field as other questions.', 'created_at': datetime.datetime(2024, 3, 8, 3, 4, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251840412, 'issue_id': 2137449091, 'author': 'eaglexer', 'body': 'I completely agree with everyone, I tried to find a switch in the admin settings to disable ""Auto-connect filters"", but unfortunately there is no such function yet. I hope that in the future it will appear. At the moment, editing a dashboard, especially with a large number of tabs and filters, can be very annoying due to the constant linking of filters and the main thing is to have time to disable them before the banner disappears.', 'created_at': datetime.datetime(2024, 7, 26, 2, 18, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580463662, 'issue_id': 2137449091, 'author': 'mngr', 'body': 'We changed this to auto-connection happen only after the user clicks on the suggestion to do that [here](https://github.com/metabase/metabase/issues/43182)', 'created_at': datetime.datetime(2025, 1, 9, 14, 49, 53, tzinfo=datetime.timezone.utc)}]","notrom on (2024-03-08 03:04:29 UTC): To add a reproduction ...

1. Create a dashboard with 3 questions based on the Sample DB > Orders table
2. Add a date filter to the dashboard
3. Link the new filter to ""Order.Created At"" on the first question, other questions are auto wired
![image](https://github.com/metabase/metabase/assets/4504437/2e62121f-6dbc-4826-a086-4415ec6d82b8)

4. Remove that filter from 2 questions, only 1 question is wired to the filter
![image](https://github.com/metabase/metabase/assets/4504437/723337f0-1aca-4fc8-9652-ebb103707ebf)

5. Change the remaining filter field to ""User.Birth Date"", all questions are wired to the filter again, **not what I wanted**, I've already said I want no filters on 2 of them.
![image](https://github.com/metabase/metabase/assets/4504437/5d72d139-e815-4c11-93a2-32312b849734)

6. The toast would undo the auto wiring but it's only displayed for limited time (maybe 4 seconds), an if you've got a large dashboard with lots of questions it can be tricky to figure out what's changed.

The auto wiring is great, but seems a bit too aggressive in the case where filter is empty, if it's already selected it won't be changed. It also gets more complicated when questions are based on different tables and have different fields available for filtering e.g. a dashboard with both orders and invoices, all filtered by the same dashboard date filter.

Personally I wouldn't want to disable auto wiring completely, just be able to have questions that are explicitly not going to be impacted by that dashboard filter (but may be by others) even though their base data contains the same field as other questions.

eaglexer on (2024-07-26 02:18:52 UTC): I completely agree with everyone, I tried to find a switch in the admin settings to disable ""Auto-connect filters"", but unfortunately there is no such function yet. I hope that in the future it will appear. At the moment, editing a dashboard, especially with a large number of tabs and filters, can be very annoying due to the constant linking of filters and the main thing is to have time to disable them before the banner disappears.

mngr on (2025-01-09 14:49:53 UTC): We changed this to auto-connection happen only after the user clicks on the suggestion to do that [here](https://github.com/metabase/metabase/issues/43182)

"
2137405596,issue,open,,[Epic] Use Mantine Notification Component,"[discussion](https://metaboat.slack.com/archives/C057WD5L0JG/p1708028714904999?thread_ts=1708026596.591569&cid=C057WD5L0JG)

https://v6.mantine.dev/core/notification/

```[tasklist]
### Prep
- [ ] Design pass on notification
- [ ] implementation of notification designs
```

```[tasklist]
### Implementation
- [ ] separate notifications from undos
- [ ] Admin: saved/error notifications
- [ ] Global toast/undos
- [ ] Upload / db sync popups?
```",iethree,2024-02-15 20:36:52+00:00,[],2025-02-04 20:24:42+00:00,,https://github.com/metabase/metabase/issues/38832,"[('Administration/Settings', ''), ('.Epic', 'Feature Implementation or Project')]",[],
2137311591,issue,closed,completed,[Epic] Build Databricks driver,"**Links**
- product doc: [product doc](https://www.notion.so/metabase/Databricks-driver-136d033b41d74ef08055aefb0844f98f?pvs=4)
- eng doc: 
- feature branch: 
- issue links: https://github.com/metabase/metabase/issues/10029

```[tasklist]
### Tasks
- [ ] Add a draft title or issue reference here
```


",luizarakaki,2024-02-15 19:45:44+00:00,['lbrdnk'],2024-10-04 17:45:32+00:00,2024-10-04 17:45:31+00:00,https://github.com/metabase/metabase/issues/38830,"[('Database/', ''), ('.Backend', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2137200620,issue,closed,completed,[dc.js migration] bars become stacked in static viz,"http://localhost:3000/question/250-combo-bars-become-stacked-in-static-viz

<img width=""925"" alt=""Screenshot 2024-02-15 at 10 47 20 AM"" src=""https://github.com/metabase/metabase/assets/37751258/d144a02d-160a-4a06-9716-943c72fbbeb2"">

in dashboard

<img width=""577"" alt=""Screenshot 2024-02-15 at 10 47 33 AM"" src=""https://github.com/metabase/metabase/assets/37751258/cbb3bc22-f880-4f9a-8e34-851a9c76e720"">

in subscription
",EmmadUsmani,2024-02-15 18:46:47+00:00,['EmmadUsmani'],2024-03-05 19:54:56+00:00,2024-03-05 19:54:56+00:00,https://github.com/metabase/metabase/issues/38827,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 1979504740, 'issue_id': 2137200620, 'author': 'alxnddr', 'body': '~The fix needs to be reimplemented.\r\nhttps://github.com/metabase/metabase/pull/38988/files#diff-a996e07afd884cc1340bdeffa0eb577d7828cf4e6418c547d4dc201d1511f96dR290 card display can be `combo` and have bar/area series which would make it valid. Going to revert the PR in my branch since it broke stacking settings selector.~\r\n\r\nupd: it did not work before so we can just fix the settings toggle', 'created_at': datetime.datetime(2024, 3, 5, 19, 40, 41, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-03-05 19:40:41 UTC): ~The fix needs to be reimplemented.
https://github.com/metabase/metabase/pull/38988/files#diff-a996e07afd884cc1340bdeffa0eb577d7828cf4e6418c547d4dc201d1511f96dR290 card display can be `combo` and have bar/area series which would make it valid. Going to revert the PR in my branch since it broke stacking settings selector.~

upd: it did not work before so we can just fix the settings toggle

"
2137190661,issue,closed,completed,We should never run get-field-values on a dashboard load if the field does not have field values in the metabase_fieldvalues table,"### Describe the bug

A customer with a massive database took down many dashboards as the metabase_fieldvalues was wiped by the time they did an upgrade, so Metabase started doing field-values on the DB on production time and several dashboards didn't load at all for the following reason: if a filter is a dropdown and the metabase_fieldvalues entry does not exist for that filter, we should simply return an empty array, not fire a query to the DB to get those

### To Reproduce

1) set up Metabase from scratch
2) create a question of the people table (just a raw table)
3) add a filter connected to the source field
4) go to the app db and wipe the field values from the metabase_fieldvalues for the source field (it's the one with Google, Facebook... fields)
5) load the dashboard, see Metabase running the `SELECT ""public"".""people"".""source"" AS ""source"" FROM ""public"".""people"" GROUP BY ""public"".""people"".""source"" ORDER BY ""public"".""people"".""source"" ASC LIMIT 1000` query

this query can be extremely hard on some dwh and we're taking those dashboards (and probably the DWH) down due to this

### Expected behavior

If the field is not there just simply return an empty array, don't try to do that on a dashboard run

### Logs

NA

### Information about your Metabase installation

```JSON
v48.6, but probably been like that forever?
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-02-15 18:40:52+00:00,['adam-james-v'],2024-02-21 19:20:57+00:00,2024-02-21 13:55:28+00:00,https://github.com/metabase/metabase/issues/38826,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1947930428, 'issue_id': 2137190661, 'author': 'calherries', 'body': '[slack discussion](https://metaboat.slack.com/archives/C052ZBWRG3W/p1708062280490179?thread_ts=1708022597.711849&cid=C052ZBWRG3W)', 'created_at': datetime.datetime(2024, 2, 16, 8, 11, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 1948433941, 'issue_id': 2137190661, 'author': 'luizarakaki', 'body': ""I believe the expected behavior is to fetch field values only for fields that are assigned as dashboard filters. We don't need to get field values from all fields in the dashboard.\r\n\r\nIdeally, we should fetch field values only if the user opens the dashboard filter widget."", 'created_at': datetime.datetime(2024, 2, 16, 13, 58, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 1948437385, 'issue_id': 2137190661, 'author': 'paoliniluis', 'body': ""@luizarakaki Nope, we should never fetch those values at filter time unless it's a linked filter, as we do right now. Fetching filter values if they're not there at filter time without a WHERE clause can take down a DW if it's too big"", 'created_at': datetime.datetime(2024, 2, 16, 14, 0, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 1948457493, 'issue_id': 2137190661, 'author': 'luizarakaki', 'body': 'If fetching a single field values can take the entire DW down we can never scan field values...', 'created_at': datetime.datetime(2024, 2, 16, 14, 12, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 1948467694, 'issue_id': 2137190661, 'author': 'paoliniluis', 'body': ""It's fine if we do it when the admin specifies it (e.g. late at night), but never ever at filter time unless it's a field filter"", 'created_at': datetime.datetime(2024, 2, 16, 14, 19, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 1952888851, 'issue_id': 2137190661, 'author': 'dannyeuu', 'body': 'Hi @luizarakaki and @paoliniluis, this behavior happens in my issue at #38921 \r\n\r\nI did not know in which v0.47 or v0.48 version that started to happen this, we updated 2 times Metabase this year, because we have these dashboards for a long time.', 'created_at': datetime.datetime(2024, 2, 19, 17, 3, tzinfo=datetime.timezone.utc)}]","calherries on (2024-02-16 08:11:52 UTC): [slack discussion](https://metaboat.slack.com/archives/C052ZBWRG3W/p1708062280490179?thread_ts=1708022597.711849&cid=C052ZBWRG3W)

luizarakaki on (2024-02-16 13:58:04 UTC): I believe the expected behavior is to fetch field values only for fields that are assigned as dashboard filters. We don't need to get field values from all fields in the dashboard.

Ideally, we should fetch field values only if the user opens the dashboard filter widget.

paoliniluis (Issue Creator) on (2024-02-16 14:00:20 UTC): @luizarakaki Nope, we should never fetch those values at filter time unless it's a linked filter, as we do right now. Fetching filter values if they're not there at filter time without a WHERE clause can take down a DW if it's too big

luizarakaki on (2024-02-16 14:12:42 UTC): If fetching a single field values can take the entire DW down we can never scan field values...

paoliniluis (Issue Creator) on (2024-02-16 14:19:15 UTC): It's fine if we do it when the admin specifies it (e.g. late at night), but never ever at filter time unless it's a field filter

dannyeuu on (2024-02-19 17:03:00 UTC): Hi @luizarakaki and @paoliniluis, this behavior happens in my issue at #38921 

I did not know in which v0.47 or v0.48 version that started to happen this, we updated 2 times Metabase this year, because we have these dashboards for a long time.

"
2137139368,issue,closed,completed,[dc.js migration] goal line renders below series,"http://localhost:3000/question/249-combo-goal-line-goal-line-renders-below-series-38824

<img width=""1892"" alt=""Screenshot 2024-02-15 at 10 52 00 AM"" src=""https://github.com/metabase/metabase/assets/37751258/80df228f-f83c-4a0b-8023-59d92d394860"">
",EmmadUsmani,2024-02-15 18:09:09+00:00,['EmmadUsmani'],2024-02-16 15:37:10+00:00,2024-02-16 15:37:10+00:00,https://github.com/metabase/metabase/issues/38824,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2137022707,issue,open,,"Add a ""upload_row_data_source"", ""upload_row_timestamp_created"" columns when creating models/tables from CSV to track which upload is for which row","**Is your feature request related to a problem? Please describe.**
- When uploading data and creating appends, it is not possible to see when the row was created or what file/data source the data came from.

**Describe the solution you'd like**
- Create columns on tables/models created using CSV upload for:
  - `upload_row_data_source` which references the file-name and user who uploaded (or separate into multiple columns)
  - `upload_row_timestamp_created` which references the timestamp of the initialization of the CSV upload or includes a NOW() on INSERT.

**Describe alternatives you've considered**
- no alternatives in product currently

**How important is this feature to you?**
- very helpful for ensuring data managed consistently and avoiding/managing duplicates and clean data

",likeshumidity,2024-02-15 17:00:01+00:00,[],2024-05-10 20:02:19+00:00,,https://github.com/metabase/metabase/issues/38821,"[('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 1946676709, 'issue_id': 2137022707, 'author': 'likeshumidity', 'body': 'CC @luizarakaki', 'created_at': datetime.datetime(2024, 2, 15, 17, 26, 2, tzinfo=datetime.timezone.utc)}]","likeshumidity (Issue Creator) on (2024-02-15 17:26:02 UTC): CC @luizarakaki

"
2136629216,issue,closed,completed,Add hover card column metadata on Summarize sidebar,"Update the Chill mode summarize sidebar to add the column info icon to each column item.

This means we need to move the bucket picker too.


<img width=""664"" alt=""Screenshot 2024-02-15 at 16 56 47"" src=""https://github.com/metabase/metabase/assets/1250185/9653ee49-65e1-49a9-be6f-8ec52ca6d4b8"">
",romeovs,2024-02-15 14:11:12+00:00,['romeovs'],2024-02-20 13:41:30+00:00,2024-02-20 13:41:25+00:00,https://github.com/metabase/metabase/issues/38812,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1954241848, 'issue_id': 2136629216, 'author': 'romeovs', 'body': 'Closed by https://github.com/metabase/metabase/pull/38817', 'created_at': datetime.datetime(2024, 2, 20, 13, 41, 25, tzinfo=datetime.timezone.utc)}]","romeovs (Issue Creator) on (2024-02-20 13:41:25 UTC): Closed by https://github.com/metabase/metabase/pull/38817

"
2136576441,issue,closed,completed,[Epic] Remove global plain CSS styles,"Relates to https://github.com/metabase/metabase/issues/33854

**Links**
- Eng doc: [Link](https://www.notion.so/metabase/83-Prepare-global-css-for-migration-to-css-modules-4ab29b8589b545e0960bf032d24a11a9)
- Problem description: [Link](https://www.notion.so/metabase/Embedding-SDK-8103306366be4f0786b489ad2324235c?pvs=4#83440af594a941ee8b14aaa1e1ac742b)

**Implementation Plan**

```[tasklist]
### Milestone 1 - Migrate global CSS to CSS modules
- [x] https://github.com/metabase/metabase/pull/39020 - Migrate global CSS to CSS modules - Add "":global"" for all empty global styles; Remove "":local""
- [x] https://github.com/metabase/metabase/pull/39020 - Configure css-loader to have local scope by default
- [x] https://github.com/metabase/metabase/pull/39020 - Update css-loader dependency
- [x] https://github.com/metabase/metabase/pull/39020 - Find a way to isolate global third-party stylesheets - leaflet, ace-builds, tippy.js ...
- [x] https://github.com/metabase/metabase/pull/39220 - Remove unused classes
- [ ] https://github.com/metabase/metabase/pull/39239
```

```[tasklist]
### Milestone 2 - Get rid of global styles in Embedding SDK components
- [ ] https://github.com/metabase/metabase/issues/39123
- [ ] https://github.com/metabase/metabase/pull/39324
- [ ] https://github.com/metabase/metabase/pull/40103
- [ ] https://github.com/metabase/metabase/pull/40106
- [ ] https://github.com/metabase/metabase/pull/40007
- [ ] https://github.com/metabase/metabase/issues/40128
- [ ] https://github.com/metabase/metabase/issues/40127
- [ ] https://github.com/metabase/metabase/issues/40349
- [ ] https://github.com/metabase/metabase/issues/40722
- [ ] https://github.com/metabase/metabase/issues/40904
- [ ] https://github.com/metabase/metabase/issues/40496
- [ ] https://github.com/metabase/metabase/issues/40129
- [ ] https://github.com/metabase/metabase/issues/40910
- [ ] https://github.com/metabase/metabase/issues/41019
- [ ] https://github.com/metabase/metabase/issues/41077
- [ ] https://github.com/metabase/metabase/issues/40231
- [ ] https://github.com/metabase/metabase/issues/41256
- [ ] https://github.com/metabase/metabase/issues/41239
- [ ] https://github.com/metabase/metabase/issues/40357
- [ ] https://github.com/metabase/metabase/issues/40521
- [ ] https://github.com/metabase/metabase/issues/40444
- [ ] https://github.com/metabase/metabase/issues/40562
- [ ] https://github.com/metabase/metabase/issues/40565
- [ ] https://github.com/metabase/metabase/issues/40571
- [ ] https://github.com/metabase/metabase/issues/40585
- [ ] https://github.com/metabase/metabase/issues/40502
- [ ] https://github.com/metabase/metabase/issues/40583
- [ ] https://github.com/metabase/metabase/issues/40497
- [ ] https://github.com/metabase/metabase/issues/41356
- [ ] https://github.com/metabase/metabase/issues/40620
- [ ] https://github.com/metabase/metabase/issues/40506
- [ ] https://github.com/metabase/metabase/issues/40576
- [ ] https://github.com/metabase/metabase/issues/41364
- [ ] https://github.com/metabase/metabase/issues/41347
- [ ] https://github.com/metabase/metabase/issues/41354
- [ ] https://github.com/metabase/metabase/issues/41258
```

",deniskaber,2024-02-15 13:47:18+00:00,"['WiNloSt', 'deniskaber', 'oisincoveney']",2024-04-19 11:19:43+00:00,2024-04-19 11:19:42+00:00,https://github.com/metabase/metabase/issues/38811,"[('.Epic', 'Feature Implementation or Project')]",[],
2136389981,issue,closed,completed,FE - Migrate `dataset: true` to enum value in Card autocomplete suggestions,"Depends on #37367

See https://github.com/metabase/metabase/blob/6657c3cb754e3cb105b44596640158e3ee8ef0e4/frontend/src/metabase/query_builder/components/NativeQueryEditor/NativeQueryEditor.tsx#L84",kamilmielnik,2024-02-15 12:21:32+00:00,['kamilmielnik'],2024-02-22 14:45:25+00:00,2024-02-22 14:45:24+00:00,https://github.com/metabase/metabase/issues/38808,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1959602833, 'issue_id': 2136389981, 'author': 'kamilmielnik', 'body': 'Closed by #39054', 'created_at': datetime.datetime(2024, 2, 22, 14, 45, 24, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-02-22 14:45:24 UTC): Closed by #39054

"
2136389753,issue,closed,completed,FE - Migrate `dataset: true` to enum value in Bookmarks,"Depends on #37367

See https://github.com/metabase/metabase/blob/8b19867/frontend/src/metabase-types/api/bookmark.ts#L13

:warning: please remove `card.dataset` usage in `getIcon` in `frontend/src/metabase/entities/questions.js` as a part of this task (see https://github.com/metabase/metabase/pull/38714/commits/a1204874e8785926cf181d58ced9c9b61bfdaa62)",kamilmielnik,2024-02-15 12:21:24+00:00,['kamilmielnik'],2024-02-22 14:45:15+00:00,2024-02-22 14:45:15+00:00,https://github.com/metabase/metabase/issues/38807,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1959602553, 'issue_id': 2136389753, 'author': 'kamilmielnik', 'body': 'Closed by #39056', 'created_at': datetime.datetime(2024, 2, 22, 14, 45, 15, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-02-22 14:45:15 UTC): Closed by #39056

"
2136137678,issue,closed,completed,Improve logging for Serialization Failures,"**Is your feature request related to a problem? Please describe.**

Failures around serialisation are pretty unique and sometimes debugging them is hard. Currently the error log is not helpful when it comes to entity_id which fail to generate.

For example if a particular collection is missing (could have been deleted by mistake) you might get an error:

`ERROR v2.entity-ids :: Error updating entity ID: Assert failed: (some? entity)`

Which doesn't help in debugging 

**Describe the solution you'd like**
Better error messages, pointing to at least the object that is failing to get serialized.

**Describe alternatives you've considered**
None

**Additional context**
Enterprise customers which handle their own Application DB have unique environments ",Tony-metabase,2024-02-15 10:17:51+00:00,['piranha'],2024-02-16 09:31:20+00:00,2024-02-16 09:08:15+00:00,https://github.com/metabase/metabase/issues/38804,"[('Priority:P2', 'Average run of the mill bug'), ('Type:New Feature', ''), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1945898711, 'issue_id': 2136137678, 'author': 'paoliniluis', 'body': '@luizarakaki', 'created_at': datetime.datetime(2024, 2, 15, 11, 23, 38, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-15 11:23:38 UTC): @luizarakaki

"
2136084873,issue,closed,not_planned,Date representation on Trend visualization regressed,"### Describe the bug

After updating from 0.48.2 to 0.48.6 the date representation on a trend visualization regressed.

In earlier versions yearly comparisons were displayed simply by ""2024"", now it says ""Jan 1, 2024"". Same with monthly comparisons. It used to be ""Feb 2024"", now it is ""Feb 1, 2024"". Screenshots attached.
![0486](https://github.com/metabase/metabase/assets/55084396/e1dd5f1d-20a5-4873-9ee7-3ff71c6532e9)
![0482](https://github.com/metabase/metabase/assets/55084396/5a0ca755-9e59-4516-ab9b-2bd2a6a88ad0)


### To Reproduce

1. Create Trend visualization with monthly or yearly comparison time frames
2. Year/month is represented as date, not month or year


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.48.6
- Firefox 122.0
- Warehouse: Redshift
- Internal: PostgreSQL
- Docker
```


### Severity

annoying

### Additional context

_No response_",iggups,2024-02-15 09:50:02+00:00,[],2024-02-15 17:13:09+00:00,2024-02-15 17:13:08+00:00,https://github.com/metabase/metabase/issues/38802,"[('Type:Bug', 'Product defects'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1945754794, 'issue_id': 2136084873, 'author': 'perivamsi', 'body': 'Hi @iggups, thank you for reporting this. Are you using SQL to create the question or are you using the query builder UI?', 'created_at': datetime.datetime(2024, 2, 15, 10, 9, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1945806288, 'issue_id': 2136084873, 'author': 'iggups', 'body': 'Hi @perivamsi \r\nI am using SQL', 'created_at': datetime.datetime(2024, 2, 15, 10, 39, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1945820555, 'issue_id': 2136084873, 'author': 'perivamsi', 'body': ""The challenge with sql is that Metabase does not have enough information to correctly display the time period (2024 vs Jan 1, 2024) in all the cases. In previous versions, while we correctly displayed it for some examples, we would show [incorrect data for others](https://github.com/metabase/metabase/issues/38122). As a way to err on the side of correctness (we'd rather say Jan 1, 2024 than 2025 which is completely wrong), we decided to go with this approach.\r\n\r\nIf you use the query builder, Metabase then has enough information to correctly predict the time period with the right granularity (year vs month vs date)."", 'created_at': datetime.datetime(2024, 2, 15, 10, 44, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 1945977063, 'issue_id': 2136084873, 'author': 'iggups', 'body': 'I see. Maybe there should be an additional drop down option in the trend visualization like ""granularity"" with year/month/week for example.\r\n\r\nUnfortunately I can\'t build the question with the query builder as it is too complex.', 'created_at': datetime.datetime(2024, 2, 15, 12, 12, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 1946633853, 'issue_id': 2136084873, 'author': 'perivamsi', 'body': 'We will explore that idea as a feature request.', 'created_at': datetime.datetime(2024, 2, 15, 17, 13, 8, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-02-15 10:09:09 UTC): Hi @iggups, thank you for reporting this. Are you using SQL to create the question or are you using the query builder UI?

iggups (Issue Creator) on (2024-02-15 10:39:25 UTC): Hi @perivamsi 
I am using SQL

perivamsi on (2024-02-15 10:44:05 UTC): The challenge with sql is that Metabase does not have enough information to correctly display the time period (2024 vs Jan 1, 2024) in all the cases. In previous versions, while we correctly displayed it for some examples, we would show [incorrect data for others](https://github.com/metabase/metabase/issues/38122). As a way to err on the side of correctness (we'd rather say Jan 1, 2024 than 2025 which is completely wrong), we decided to go with this approach.

If you use the query builder, Metabase then has enough information to correctly predict the time period with the right granularity (year vs month vs date).

iggups (Issue Creator) on (2024-02-15 12:12:54 UTC): I see. Maybe there should be an additional drop down option in the trend visualization like ""granularity"" with year/month/week for example.

Unfortunately I can't build the question with the query builder as it is too complex.

perivamsi on (2024-02-15 17:13:08 UTC): We will explore that idea as a feature request.

"
2135722330,issue,closed,completed,Metabase is sending alerts half an hour after it is actually scheduled to send alerts,"### Describe the bug

Metabase keeps sending alerts half an hour after it is supposed to. It is hosted directly on an ec2 instance running linux without using docker container.
These are the configuration for the instance
`{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-post-Ubuntu-0ubuntu120.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-post-Ubuntu-0ubuntu120.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1038-gcp"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.212 (2022-04-09)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.212 (2022-04-09)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-07-28"",
      ""tag"": ""v1.46.6.4"",
      ""branch"": ""release-x.46.6.x"",
      ""hash"": ""7c60aca""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Kolkata""
    }
  }
}`

The logs also don't indicate any issues but duly post half an hour after it is configured to. I have also tried changing the timezone but the issue persists.
Please let me know if any other details are required.

### To Reproduce

1. Create an alert on any dashboard or question
2. This alert is triggered half an hour

### Expected behavior

_No response_

### Logs

1. Create an alert

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-post-Ubuntu-0ubuntu120.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-post-Ubuntu-0ubuntu120.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1038-gcp"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.212 (2022-04-09)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.212 (2022-04-09)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-07-28"",
      ""tag"": ""v1.46.6.4"",
      ""branch"": ""release-x.46.6.x"",
      ""hash"": ""7c60aca""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Kolkata""
    }
  }
}
```


### Severity

HIGH

### Additional context

_No response_",abhinav3204,2024-02-15 06:08:51+00:00,[],2024-05-15 02:44:06+00:00,2024-05-15 02:44:06+00:00,https://github.com/metabase/metabase/issues/38800,"[('Type:Bug', 'Product defects'), ('Reporting/Pulses', 'Now called Subscriptions'), ('Misc/Timezones', ''), ('Reporting/Alerts', '')]","[{'comment_id': 1953052166, 'issue_id': 2135722330, 'author': 'paoliniluis', 'body': 'Hi @abhinav3204 how much time does the query takes? have you run the query that metabase does for this alert separately to check the time?', 'created_at': datetime.datetime(2024, 2, 19, 19, 23, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 1954005726, 'issue_id': 2135722330, 'author': 'abhinav3204', 'body': 'the query is a simple select 1 which I use for testing the alert generation. It hardly takes a few milisecond', 'created_at': datetime.datetime(2024, 2, 20, 11, 22, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 1970341637, 'issue_id': 2135722330, 'author': 'abhishek-superk', 'body': ""@abhinav3204 This is a timezone issue I believe. In our setup also it's the same.\r\nPeople just got used to it over time."", 'created_at': datetime.datetime(2024, 2, 29, 3, 41, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2107634995, 'issue_id': 2135722330, 'author': 'qnkhuat', 'body': ""We're now sending pulses in parallel and prioritize fast pulses, so this problem should be mitigated."", 'created_at': datetime.datetime(2024, 5, 13, 13, 50, 53, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-19 19:23:19 UTC): Hi @abhinav3204 how much time does the query takes? have you run the query that metabase does for this alert separately to check the time?

abhinav3204 (Issue Creator) on (2024-02-20 11:22:21 UTC): the query is a simple select 1 which I use for testing the alert generation. It hardly takes a few milisecond

abhishek-superk on (2024-02-29 03:41:38 UTC): @abhinav3204 This is a timezone issue I believe. In our setup also it's the same.
People just got used to it over time.

qnkhuat on (2024-05-13 13:50:53 UTC): We're now sending pulses in parallel and prioritize fast pulses, so this problem should be mitigated.

"
2135521805,issue,open,,Document specifics about Redshift impersonation,"So Redshift is a bit different when it comes about impersonation, as we don't send a SET ROLE / REVOKE ROLE on every query as we do with postgres, but rather a SET SESSION AUTHORIZATION (https://docs.aws.amazon.com/redshift/latest/dg/r_SET_SESSION_AUTHORIZATION.html) command on the query.

this means that in Redshift we're not altering the role of the actual session, but running the query as an actual user who can have a role in the DB.

We can add how to do RLS in the DB as well. E.g. using the sample dataset on the people table
1) create user, role and grant select to the table
```
CREATE ROLE californians;
CREATE USER from_california WITH PASSWORD 'Iwishtheyallcouldbecalifornians1';
GRANT ROLE californians TO from_california;
GRANT SELECT ON public.people TO ROLE californians;
```
2) create a row level security policy on the state field and on the source field
```
CREATE RLS POLICY policy_state
WITH (state CHAR(2))
USING (state = 'CA');

CREATE RLS POLICY policy_source
WITH (source VARCHAR(255))
USING (source = 'Google');
```
3) attach these 2 rules to the californians role
```
ATTACH RLS POLICY policy_state ON people TO ROLE californians;
ATTACH RLS POLICY policy_source ON people TO ROLE californians;
```
4) activate the policy on the table
```
ALTER TABLE public.people ROW LEVEL SECURITY ON CONJUNCTION TYPE AND;
```

Note that the RLS at the redshift level brings a performance impact",paoliniluis,2024-02-15 02:30:33+00:00,[],2024-02-15 02:30:58+00:00,,https://github.com/metabase/metabase/issues/38799,"[('Type:Documentation', ''), ('Database/Redshift', None)]",[],
2135504101,issue,open,,Add documentation about masking policies,"Now that we can impersonate roles (snowflake) or users (redshift), we should have a learn article about how you can use the data masking features of both engines to provide column level security to users

E.g. Redshift:
With the sample database:
1) Create a role and a user
```
CREATE ROLE californians;
CREATE USER from_california WITH PASSWORD 'Iwishtheyallcouldbecalifornians1';
GRANT ROLE californians TO from_california;
GRANT SELECT ON public.people TO ROLE californians;
```
2) create a masking function
```
CREATE FUNCTION REDACT_EMAIL_ADDRESS(email TEXT)
RETURNS TEXT IMMUTABLE
AS $$
    import re
    # Regular expression pattern for matching email addresses
    regexp = re.compile(""^([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)\\.([a-zA-Z]{2,})$"")

    match = regexp.search(email)
    if match is not None:
        username = match.group(1)
        domain = match.group(2)
        extension = match.group(3)
        masked_username = username[0] + 'X' * (len(username) - 1)
        masked_domain = domain[0] + 'X' * (len(domain) - 1)
        return ""{}@{}.{}"".format(masked_username, masked_domain, extension)
    else:
        return ""example@example.com""  # default value if the email format is not recognized
$$ LANGUAGE plpythonu;
```

3) create a masking policy
```
CREATE MASKING POLICY mask_email_partial
WITH (email VARCHAR(256))
USING (REDACT_EMAIL_ADDRESS(email));
```

4) attach the masking policy
```
ATTACH MASKING POLICY mask_email_partial
ON people(email)
TO ROLE californians
PRIORITY 10;
```

5) configure impersonation so a user impersonates the user ""californians"" on the DB

6) see this beauty
![image](https://github.com/metabase/metabase/assets/1711649/8235bf68-8fa8-4256-b0d3-ccb2230cfd85)
",paoliniluis,2024-02-15 02:11:51+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/38798,"[('Type:Documentation', ''), ('Database/Redshift', None), ('Database/Snowflake', '')]","[{'comment_id': 1945258319, 'issue_id': 2135504101, 'author': 'paoliniluis', 'body': 'Snowflake docs around masking policies https://docs.snowflake.com/en/user-guide/security-column-ddm-use', 'created_at': datetime.datetime(2024, 2, 15, 2, 15, 30, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-15 02:15:30 UTC): Snowflake docs around masking policies https://docs.snowflake.com/en/user-guide/security-column-ddm-use

"
2135172754,issue,open,,"way to ""drag and copy + paste"" text boxes added to a dashboard","**Is your feature request related to a problem? Please describe.**
Its very time consuming creating new text boxes and then editing them all

**Describe the solution you'd like**
It would be so much nicer if I can ""copy + paste"" these textboxes 

**Describe alternatives you've considered**
way to bulk add text boxes to dashboards 

**How important is this feature to you?**
Very. These textbox features are great bc you can better tell a story in a dashboard but it is more time consuming to do it the current method.

**Additional context**
Add any other context or screenshots about the feature request here.
",OdinTallBeard,2024-02-14 20:44:00+00:00,[],2024-02-14 20:52:59+00:00,,https://github.com/metabase/metabase/issues/38793,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2135172597,issue,open,,Add the timestamp to the file name on the subscription attachment,"**Is your feature request related to a problem? Please describe.**
A lead asked to add the timestamp to the filename of the subscription. Seems reasonable that if you get a subscription and you download it, you want to know the timestamp of the file for reference

**Describe the solution you'd like**
Just add to the filename of the attachment the timestamp

**Describe alternatives you've considered**
None, unless you have a script that does this at the OS level

**How important is this feature to you?**
Requested by a trialer

**Additional context**
NA
",paoliniluis,2024-02-14 20:43:53+00:00,[],2024-02-14 20:43:53+00:00,,https://github.com/metabase/metabase/issues/38792,"[('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('Reporting/Export', '')]",[],
2135077384,issue,closed,completed,[Epic] Replace CSV data,"[product doc, milestone 2](https://www.notion.so/metabase/Allow-append-and-replace-to-existing-CSV-uploads-f1f13864632d4cfd83522fce762890eb?pvs=4#7e36dd9a56434f71941530ae516788f1)
[technical design doc](https://www.notion.so/metabase/Tech-Replace-uploaded-table-fbf87ad7c0a7485bb74abd66b7d658a5?pvs=4)

BE: BEC
FE: Admin/Webapp
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/40364
- [ ] https://github.com/metabase/metabase/issues/40365
- [ ] https://github.com/metabase/metabase/issues/40368
- [ ] https://github.com/metabase/metabase/issues/40469
- [ ] https://github.com/metabase/metabase/pull/40610
```

Closes:
https://github.com/metabase/metabase/issues/33272",luizarakaki,2024-02-14 19:42:34+00:00,['iethree'],2024-05-13 12:02:49+00:00,2024-05-13 12:02:49+00:00,https://github.com/metabase/metabase/issues/38788,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2135031966,issue,closed,not_planned,[dc.js migration] metric tick label intervals do not match old implementation,"https://metaboat.slack.com/archives/C06G94JTWBS/p1706192364885689

Will add more examples and a more detailed description later when we start working on this.",EmmadUsmani,2024-02-14 19:19:21+00:00,['EmmadUsmani'],2024-02-28 17:59:01+00:00,2024-02-28 17:59:01+00:00,https://github.com/metabase/metabase/issues/38786,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 1969541989, 'issue_id': 2135031966, 'author': 'EmmadUsmani', 'body': ""Per Kyle's [feedback](https://metaboat.slack.com/archives/C05NQSWPRMK/p1709142896883379?thread_ts=1709142583.122799&cid=C05NQSWPRMK), this is an acceptable difference in behavior and not a regression."", 'created_at': datetime.datetime(2024, 2, 28, 17, 59, 1, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-02-28 17:59:01 UTC): Per Kyle's [feedback](https://metaboat.slack.com/archives/C05NQSWPRMK/p1709142896883379?thread_ts=1709142583.122799&cid=C05NQSWPRMK), this is an acceptable difference in behavior and not a regression.

"
2135031371,issue,closed,not_planned,[dc.js migration] metric label intervals do not match,,EmmadUsmani,2024-02-14 19:19:02+00:00,[],2024-02-14 19:19:36+00:00,2024-02-14 19:19:36+00:00,https://github.com/metabase/metabase/issues/38785,[],[],
2135011982,issue,closed,completed,[dc.js migration] auto-selected `graph.x_axis.axis_enabled` setting does not match old implementation,"Similar to https://github.com/metabase/metabase/issues/38782, this was also something that came up often in [#echarts-bug-bash](https://metaboat.slack.com/archives/C06G94JTWBS), below are some examples.

https://metaboat.slack.com/archives/C06G94JTWBS/p1706193475366799

https://metaboat.slack.com/archives/C06G94JTWBS/p1706193183854899

https://metaboat.slack.com/archives/C06G94JTWBS/p1706193082481509

Below is the logic that the old implementation used

```javascript
function beforeRenderComputeXAxisLabelType(chart) {
  // treat graph.x_axis.axis_enabled === true as ""auto""
  if (chart.settings[""graph.x_axis.axis_enabled""] === true) {
    const overlaps = checkXAxisLabelOverlap(chart);
    if (overlaps) {
      if (chart.isOrdinal()) {
        const spacing = computeXAxisSpacing(chart);
        if (spacing < X_LABEL_HIDE_THRESHOLD) {
          chart.settings[""graph.x_axis.axis_enabled""] = false;
        } else if (spacing < X_LABEL_ROTATE_90_THRESHOLD) {
          if (checkLabelHeight(chart, 90)) {
            chart.settings[""graph.x_axis.axis_enabled""] = ""rotate-90"";
          } else {
            chart.settings[""graph.x_axis.axis_enabled""] = false;
          }
        } else {
          if (checkLabelHeight(chart, 45)) {
            chart.settings[""graph.x_axis.axis_enabled""] = ""rotate-45"";
          } else {
            chart.settings[""graph.x_axis.axis_enabled""] = false;
          }
        }
      } else {
        chart.settings[""graph.x_axis.axis_enabled""] = false;
      }
    }
  }
}
```

To summarize, for numeric (linear, log, power) and timeseries x-axes, if labels will overlap then the axis will be hidden. For categorical (ordinal, historgarm) x-axes, if labels overlap it will try to use 90 degree or 45 degree rotated labels, or it will hide them if those overlap as well.

### Examples

question/7769
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194101957459

question/14061
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194432975859

question/97
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194969563009",EmmadUsmani,2024-02-14 19:08:45+00:00,"['alxnddr', 'EmmadUsmani']",2024-04-05 17:05:38+00:00,2024-04-05 17:05:38+00:00,https://github.com/metabase/metabase/issues/38783,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2135010806,issue,closed,completed,[dc.js migration] dimension tick label intervals do not match old implementation,"```[tasklist]
### Tasks
- [x] Fix categorical (ordinal, histogram) tick label intervals
- [x] Fix timeseries tick label intervals
```

This was one of the most common issues that we encountered in [#echarts-bug-bash](https://metaboat.slack.com/archives/C06G94JTWBS), it impacted pretty much every cartesian (line, area, bar, combo, scatter, waterfall) chart. Below are some examples

https://metaboat.slack.com/archives/C06G94JTWBS/p1706192364885689



https://metaboat.slack.com/archives/C06G94JTWBS/p1706193183854899



The solution is to re-create the dimension tick interval logic from the old implementation, which will be described below by x-axis type.

### Numeric (linear, log, power)

Only shows some, not all ticks, for example:

<img width=""812"" alt=""Screenshot 2024-02-14 at 11 28 05 AM"" src=""https://github.com/metabase/metabase/assets/37751258/0ae7489f-e84e-4f90-8042-f9aca08722b9"">

The previous logic was a multi-step process that took place in the `applyChartQuantitativeXAxis` function in `frontend/src/metabase/visualizations/lib/apply_axis.js`

```javascript
adjustXAxisTicksIfNeeded(chart.xAxis(), chart.width(), xValues);

    chart.xAxis().tickFormat(d => {
      if (waterfallTotalX && waterfallTotalX === d) {
        return t`Total`;
      }
      // don't show ticks that aren't multiples of xInterval
      if (isMultipleOf(d, xInterval)) {
        return formatValue(d, {
          ...chart.settings.column(dimensionColumn),
          type: ""axis"",
          compact: chart.settings[""graph.x_axis.axis_enabled""] === ""compact"",
        });
      }
    });
```
    
First, `adjustXAxisTicksIfNeeded` will compute the maximum number of tick labels that can fit on the chart.

```javascript
/// adjust the number of ticks displayed on the x axis based on the average width of each xValue. We measure the
/// xValues to determine an average length and then figure out how many will be able to fit based on the width of the
/// chart.
function adjustXAxisTicksIfNeeded(axis, chartWidthPixels, xValues) {
  // The const below is the number of pixels we should devote to each character for x-axis ticks. It can be thought
  // of as an average pixel width of a single character; this number is an approximation; adjust it to taste.
  // Higher values will reduce the number of ticks show on the x axis, increasing space between them; decreasing it
  // will increase tick density.
  const APPROXIMATE_AVERAGE_CHAR_WIDTH_PIXELS = 8;

  // calculate the average length of each tick, then convert that to pixels
  const tickAverageStringLength = averageStringLengthOfValues(xValues);
  const tickAverageWidthPixels =
    tickAverageStringLength * APPROXIMATE_AVERAGE_CHAR_WIDTH_PIXELS;

  // now figure out the approximate number of ticks we'll be able to show based on the width of the chart. Round
  // down so we error on the side of more space rather than less.
  const maxTicks = Math.floor(chartWidthPixels / tickAverageWidthPixels);

  // finally, if the chart is currently showing more ticks than we think it can show, adjust it down
  if (getNumTicks(axis) > maxTicks) {
    axis.ticks(maxTicks);
  }
}
```
Then, ticks that are not a multiple of the `xInterval` will be hidden. `xInterval` is computed by `getXInterval` in `renderer_utils.js` which calls `computeNumericDataInverval` to infer the interval from the data. It will use the largest power of 10 that divides all dimension values. In the chart pictured above, that would be 10.

### Categorical (ordinal, histogram)

All dimension values are shown.

### Timeseries

`applyChartTimeseriesXAxis` in `apply_axis.js` calls `computeTimeseriesTicksInterval` in `timeseries.js`, which will essentially go through this list of intervals, and pick the smallest one that will work without any labels overlapping

```javascript
// mostly matches
// https://github.com/mbostock/d3/wiki/Time-Scales
// https://github.com/mbostock/d3/wiki/Time-Intervals
// Use UTC methods to avoid issues with daylight savings
// NOTE: smaller modulos within an interval type must be multiples of larger ones (e.x. can't do both 2 days and 7 days i.e. week)
//
// Count and time interval for axis.ticks()
//
const TIMESERIES_INTERVALS = [
  { interval: ""ms"", count: 1, testFn: d => 0 }, //  (0) millisecond
  { interval: ""second"", count: 1, testFn: d => d.milliseconds() }, //  (1) 1 second
  { interval: ""second"", count: 5, testFn: d => d.seconds() % 5 }, //  (2) 5 seconds
  { interval: ""second"", count: 15, testFn: d => d.seconds() % 15 }, //  (3) 15 seconds
  { interval: ""second"", count: 30, testFn: d => d.seconds() % 30 }, //  (4) 30 seconds
  { interval: ""minute"", count: 1, testFn: d => d.seconds() }, //  (5) 1 minute
  { interval: ""minute"", count: 5, testFn: d => d.minutes() % 5 }, //  (6) 5 minutes
  { interval: ""minute"", count: 15, testFn: d => d.minutes() % 15 }, //  (7) 15 minutes
  { interval: ""minute"", count: 30, testFn: d => d.minutes() % 30 }, //  (8) 30 minutes
  { interval: ""hour"", count: 1, testFn: d => d.minutes() }, //  (9) 1 hour
  { interval: ""hour"", count: 3, testFn: d => d.hours() % 3 }, // (10) 3 hours
  { interval: ""hour"", count: 6, testFn: d => d.hours() % 6 }, // (11) 6 hours
  { interval: ""hour"", count: 12, testFn: d => d.hours() % 12 }, // (12) 12 hours
  { interval: ""day"", count: 1, testFn: d => d.hours() }, // (13) 1 day
  { interval: ""week"", count: 1, testFn: d => d.day() }, // (14) 1 week
  { interval: ""month"", count: 1, testFn: d => d.date() }, // (15) 1 months
  { interval: ""month"", count: 3, testFn: d => d.month() % 3 }, // (16) 3 months / 1 quarter
  { interval: ""year"", count: 1, testFn: d => d.month() }, // (17) 1 year
  { interval: ""year"", count: 5, testFn: d => d.year() % 5 }, // (18) 5 year
  { interval: ""year"", count: 10, testFn: d => d.year() % 10 }, // (19) 10 year
  { interval: ""year"", count: 50, testFn: d => d.year() % 50 }, // (20) 50 year
  { interval: ""year"", count: 100, testFn: d => d.year() % 100 }, // (21) 100 year
];
```
",EmmadUsmani,2024-02-14 19:08:02+00:00,['EmmadUsmani'],2024-04-05 17:06:35+00:00,2024-04-05 17:02:02+00:00,https://github.com/metabase/metabase/issues/38782,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2135003711,issue,closed,completed,[Epic] Measure creator sentiment,"[product doc](https://www.notion.so/metabase/Measuring-Creator-Sentiment-f9b5e01e175540cf969c24b3159a29e8?pvs=4)
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/38739
```
",luizarakaki,2024-02-14 19:04:08+00:00,['qwef'],2024-03-26 17:03:07+00:00,2024-03-26 17:03:07+00:00,https://github.com/metabase/metabase/issues/38781,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2134945979,issue,closed,completed,[dc.js migration] log scale does not work when series have negative values,"Technically, logarithms are not defined on values less than or equals to zero. However, previously we still had logarithm scale working on dc.js charts:

ECharts
<img width=""1725"" alt=""Screenshot 2024-02-14 at 3 37 51 PM"" src=""https://github.com/metabase/metabase/assets/14301985/50ec246b-5e82-48e6-b6ed-38610e6f4cb2"">

dc.js
<img width=""1716"" alt=""Screenshot 2024-02-14 at 3 37 23 PM"" src=""https://github.com/metabase/metabase/assets/14301985/92f798ca-7094-47ef-b3e8-43737d476371"">

It affects log x-axis on scatter plots.
We can simulate it the same way as we simulate negative pow axis.
",alxnddr,2024-02-14 18:36:34+00:00,['EmmadUsmani'],2024-03-27 20:29:40+00:00,2024-03-27 20:29:40+00:00,https://github.com/metabase/metabase/issues/38780,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2134877753,issue,closed,completed,"""Contains"" filter types on dashboards should allow users to pick values in the same way as an ""is"" filter","**Is your feature request related to a problem? Please describe.**
If we can give the contains filter the same behavior as the ""is"" filter (picklist from pre-set values, get values from a query, etc), we could solve a very specific use case that users been having for some time:

let's say that users have an array of values in a field (comma separated or a joined string altogether):
id, value
1, luis,tony
2, bruno,conor
3, cynthia,sameer

With the contains filter it's easy to set a value like ""bruno"", but maybe you don't know that the bruno value exists from the beginning (maybe in a dashboard), so if we can pre-set values in a contains type of filter we will solve this use case. Yes, it will allow us to give a workaround for people that want to filter on arrays

**Describe the solution you'd like**
Contains type of filter should allow the same features as the ""is"" filter (why not the rest of the types as well???)

**Describe alternatives you've considered**
SQL questions, which don't let you use all the magic

**How important is this feature to you?**
Requested by a lead

**Additional context**
NA
",paoliniluis,2024-02-14 17:58:08+00:00,['ranquild'],2024-04-04 11:48:51+00:00,2024-04-04 11:48:42+00:00,https://github.com/metabase/metabase/issues/38778,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2134836078,issue,open,,Make Metabase run on my fridge,It would be _cool_.,brunobergher,2024-02-14 17:30:44+00:00,[],2025-02-04 20:30:42+00:00,,https://github.com/metabase/metabase/issues/38777,"[('Type:New Feature', ''), ('Operation/', ''), ('.Frontend', '')]","[{'comment_id': 1944379090, 'issue_id': 2134836078, 'author': 'paoliniluis', 'body': 'Why did the data scientist keep their insights in the fridge? Because they wanted cold, hard facts', 'created_at': datetime.datetime(2024, 2, 14, 18, 30, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-14 18:30:46 UTC): Why did the data scientist keep their insights in the fridge? Because they wanted cold, hard facts

"
2134670217,issue,closed,not_planned,[MLv2] [FE] Migrate getParameterTargetField to MLv2,https://github.com/metabase/metabase/blob/80b5958943ed22329cbd9a1778fc03b1bb7306dc/frontend/src/metabase-lib/parameters/utils/targets.ts#L28,ranquild,2024-02-14 15:57:16+00:00,['ranquild'],2024-02-14 16:26:03+00:00,2024-02-14 16:26:03+00:00,https://github.com/metabase/metabase/issues/38773,[],[],
2134427448,issue,closed,completed,[Epic] Let time granularity be parametrized,"**Links**
- product doc: [_link to product doc_](https://www.notion.so/metabase/Let-time-granularity-be-parametrized-41a26d41cc414806b92929e0e4c859a6)
- eng doc: _link to technical design doc, if any_
- feature branch: `branch-name` _this should be the feature branch where this work will be done in. PRs will be delivered against this branch_
- issue links: _related issues if any_

```[tasklist]
### Tasks
- [ ] Add a draft title or issue reference here
```


",luizarakaki,2024-02-14 14:02:05+00:00,[],2024-05-30 01:04:28+00:00,2024-05-30 01:04:28+00:00,https://github.com/metabase/metabase/issues/38764,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Epic', 'Feature Implementation or Project')]",[],
2134338957,issue,open,,[Epic] Abstract `Our analytics` from users and move existing content to a new collection with same permissions,"**Is your feature request related to a problem? Please describe.**
""Our analytics"" is the root collection. All other collections are inside ""Our analytics"". To simplify navigation, we show all collections that belong to ""Our analytics"" in the same level of ""Our analytics"" in the sidebar.

This creates inconsistencies in the product and require special-casing.

**Describe the solution you'd like**
- [ ] Rename ""Our analytics"" to ""All collections""
- [ ] Hide this collection from users. It will only appear in the permission panel to facilitate bulk-editing collection permissions.
- [ ] Create a new collection ""Our analytics"" inside ""All collections"". Move all content (except collections) from ""All collections"" to ""Our analytics"". Transfer ""All collections"" permissions to ""Our analytics""
- [ ] This will impact serialization, we need to check with BEC",luizarakaki,2024-02-14 13:21:09+00:00,[],2025-02-04 20:30:17+00:00,,https://github.com/metabase/metabase/issues/38759,"[('Type:Tech Debt', 'or Refactoring'), ('Type:New Feature', ''), ('Organization/Collections', ''), ('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2178232604, 'issue_id': 2134338957, 'author': 'iethree', 'body': 'I\'m not sure this is the right technical design for this, but we have a lot of unnecessary complexity arising out of the fake ""our analytics"" collection, and some inconsistent usage of it, especially its id (`root` vs `null`). Similar with the fiction of all personal collections.', 'created_at': datetime.datetime(2024, 6, 19, 9, 42, 45, tzinfo=datetime.timezone.utc)}]","iethree on (2024-06-19 09:42:45 UTC): I'm not sure this is the right technical design for this, but we have a lot of unnecessary complexity arising out of the fake ""our analytics"" collection, and some inconsistent usage of it, especially its id (`root` vs `null`). Similar with the fiction of all personal collections.

"
2134237925,issue,closed,not_planned,cannot query saved question,"### Describe the bug

trying to filter by a text field ""manufacturer name"" using ""contains"". The error message refers to date fields (which I am not filtering):

<img width=""510"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24734846/868b7989-2a26-47bf-9de1-1f501a617d50"">


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

i expect to be able to see as result of the query just the lines with the filtered manufacturer name

### Logs

<img width=""530"" alt=""image"" src=""https://github.com/metabase/metabase/assets/24734846/7d9f8b0b-4490-4cfa-8f67-4c582827c395"">


### Information about your Metabase installation

```JSON
Version 121.0.6167.160 (Official Build) (arm64)
Mac OS 14.0 (23A344)
Metabase v1.48.3
```


### Severity

medium

### Additional context

_No response_",HelenMertes,2024-02-14 12:22:27+00:00,[],2024-02-14 14:23:41+00:00,2024-02-14 13:22:57+00:00,https://github.com/metabase/metabase/issues/38756,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1943759100, 'issue_id': 2134237925, 'author': 'paoliniluis', 'body': ""Hi Helen, I think you're seeing https://github.com/metabase/metabase/issues/27486. If you're a paid customer, please contact support"", 'created_at': datetime.datetime(2024, 2, 14, 13, 22, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1943882623, 'issue_id': 2134237925, 'author': 'HelenMertes', 'body': ""I did not summarise or filter by any date field. Hence it must be a\r\ndifferent error...\r\n\r\n\r\nAm Mi., 14. Feb. 2024 um 14:23 Uhr schrieb Luis Paolini <\r\n***@***.***>:\r\n\r\n> Hi Helen, I think you're seeing #27486\r\n> <https://github.com/metabase/metabase/issues/27486>. If you're a paid\r\n> customer, please contact support\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/38756#issuecomment-1943759100>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AF4WY7VVN73GP2Z2TU5IVKTYTS3DZAVCNFSM6AAAAABDIF7AFGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSNBTG42TSMJQGA>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>\r\n\r\n\r\n-- \r\nHelen Mertes\r\nCOO\r\n\r\nMobile: +49 157 3013 4772\r\nE-Mail: ***@***.***\r\n\r\n-- \r\n*Coffee Circle*\xa0|\xa0coffeecircle.com \r\n<https://go.coffeecircle.com/signature-start>\xa0\r\n\r\n\r\nNewsletter \r\n<https://go.coffeecircle.com/signature-newsletter>\xa0|\xa0Instagram \r\n<https://go.coffeecircle.com/signature-instagram>\xa0|\xa0Videos \r\n<https://go.coffeecircle.com/signature-youtube>\xa0|\xa0Impact \r\n<https://go.coffeecircle.com/signature-foundation>\xa0|\xa0Jobs \r\n<https://go.coffeecircle.com/signature-jobs>\r\n\r\n\r\n\r\nCircle Products GmbH\xa0|\xa0\r\nLindower Straße 18, 13347\xa0Berlin | Amtsgericht Charlottenburg, HRB\xa0128185 B \r\n|\xa0Geschäftsführer: Martin Elwert, Christoph A. Müller | USt-IdNr.\xa0\r\nDE272941751"", 'created_at': datetime.datetime(2024, 2, 14, 14, 23, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-14 13:22:57 UTC): Hi Helen, I think you're seeing https://github.com/metabase/metabase/issues/27486. If you're a paid customer, please contact support

HelenMertes (Issue Creator) on (2024-02-14 14:23:39 UTC): I did not summarise or filter by any date field. Hence it must be a
different error...


Am Mi., 14. Feb. 2024 um 14:23 Uhr schrieb Luis Paolini <
***@***.***>:



-- 
Helen Mertes
COO

Mobile: +49 157 3013 4772
E-Mail: ***@***.***

-- 
*Coffee Circle* | coffeecircle.com 
<https://go.coffeecircle.com/signature-start> 


Newsletter 
<https://go.coffeecircle.com/signature-newsletter> | Instagram 
<https://go.coffeecircle.com/signature-instagram> | Videos 
<https://go.coffeecircle.com/signature-youtube> | Impact 
<https://go.coffeecircle.com/signature-foundation> | Jobs 
<https://go.coffeecircle.com/signature-jobs>



Circle Products GmbH | 
Lindower Straße 18, 13347 Berlin | Amtsgericht Charlottenburg, HRB 128185 B 
| Geschäftsführer: Martin Elwert, Christoph A. Müller | USt-IdNr. 
DE272941751

"
2134033270,issue,closed,not_planned,issue taking build ,"### Describe the bug

Downloading: org/mongodb/mongodb-driver-core/3.12.11/mongodb-driver-core-3.12.11.jar from central
{:clojure.main/message
 ""Execution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).\nCould not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name.\n"",
 :clojure.main/triage
 {:clojure.error/class java.io.FileNotFoundException,
  :clojure.error/line 1,
  :clojure.error/cause
  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
  :clojure.error/symbol metabuild-common.aws/eval1459$loading,
  :clojure.error/source ""aws.clj"",
  :clojure.error/phase :execution},
 :clojure.main/trace
 {:via
  [{:type clojure.lang.Compiler$CompilerException,
    :message
    ""Syntax error macroexpanding at (metabuild_common/aws.clj:1:1)."",
    :data
    {:clojure.error/phase :execution,
     :clojure.error/line 1,
     :clojure.error/column 1,
     :clojure.error/source ""metabuild_common/aws.clj""},
    :at [clojure.lang.Compiler load ""Compiler.java"" 7665]}
   {:type java.io.FileNotFoundException,
    :message
    ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
    :at [clojure.lang.RT load ""RT.java"" 462]}],
  :trace
  [[clojure.lang.RT load ""RT.java"" 462]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 482]
   [metabuild_common.aws$eval1459$loading__6789__auto____1460
    invoke
    ""aws.clj""
    1]
   [metabuild_common.aws$eval1459 invokeStatic ""aws.clj"" 1]
   [metabuild_common.aws$eval1459 invoke ""aws.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 805]
   [metabuild_common.core$eval1453$loading__6789__auto____1454
    invoke
    ""core.clj""
    1]
   [metabuild_common.core$eval1453 invokeStatic ""core.clj"" 1]
   [metabuild_common.core$eval1453 invoke ""core.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 421]
   [build_drivers.common$eval234$loading__6789__auto____235
    invoke
    ""common.clj""
    1]
   [build_drivers.common$eval234 invokeStatic ""common.clj"" 1]
   [build_drivers.common$eval234 invoke ""common.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 512]
   [build_drivers.build_driver$eval228$loading__6789__auto____229
    invoke
    ""build_driver.clj""
    1]
   [build_drivers.build_driver$eval228
    invokeStatic
    ""build_driver.clj""
    1]
   [build_drivers.build_driver$eval228 invoke ""build_driver.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
   [build_drivers$eval222$loading__6789__auto____223
    invoke
    ""build_drivers.clj""
    1]
   [build_drivers$eval222 invokeStatic ""build_drivers.clj"" 1]
   [build_drivers$eval222 invoke ""build_drivers.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 1096]
   [build$eval214$loading__6789__auto____215 invoke ""build.clj"" 1]
   [build$eval214 invokeStatic ""build.clj"" 1]
   [build$eval214 invoke ""build.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_
    invokeStatic
    ""exec.clj""
    36]
   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_
    invoke
    ""exec.clj""
    29]
   [clojure.run.exec$exec$fn__151 invoke ""exec.clj"" 44]
   [clojure.run.exec$exec invokeStatic ""exec.clj"" 43]
   [clojure.run.exec$exec doInvoke ""exec.clj"" 39]
   [clojure.lang.RestFn invoke ""RestFn.java"" 423]
   [clojure.run.exec$_main$fn__205 invoke ""exec.clj"" 180]
   [clojure.run.exec$_main invokeStatic ""exec.clj"" 176]
   [clojure.run.exec$_main doInvoke ""exec.clj"" 139]
   [clojure.lang.RestFn invoke ""RestFn.java"" 397]
   [clojure.lang.AFn applyToHelper ""AFn.java"" 152]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
   [clojure.lang.Var applyTo ""Var.java"" 705]
   [clojure.core$apply invokeStatic ""core.clj"" 667]
   [clojure.main$main_opt invokeStatic ""main.clj"" 514]
   [clojure.main$main_opt invoke ""main.clj"" 510]
   [clojure.main$main invokeStatic ""main.clj"" 664]
   [clojure.main$main doInvoke ""main.clj"" 616]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.lang.Var applyTo ""Var.java"" 705]
   [clojure.main main ""main.java"" 40]],
  :cause
  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
  :phase :execution}}

Execution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).
Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name

### To Reproduce

docker build -t test .  using this error to run the project


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome ---Version 121.0.6167.160 (Official Build) (64-bit)
dB--- H2
```


### Severity

can't take build and run the project 

### Additional context

_No response_",ghost,2024-02-14 10:39:06+00:00,[],2024-02-14 10:54:35+00:00,2024-02-14 10:44:12+00:00,https://github.com/metabase/metabase/issues/38754,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1943501256, 'issue_id': 2134033270, 'author': 'paoliniluis', 'body': 'Hi, opening new issues is not the way to help you more and better. We saw what you wrote on the previous ticket and as you can imagine, we can’t help you if you don’t put the changes you made. Also the error is pretty explicit: a file not found', 'created_at': datetime.datetime(2024, 2, 14, 10, 44, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1943523618, 'issue_id': 2134033270, 'author': 'ghost', 'body': '(def ^:private command-timeout-ms (* 60 60 1000))    I have changed this inline in shell.clj file', 'created_at': datetime.datetime(2024, 2, 14, 10, 54, 35, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-14 10:44:12 UTC): Hi, opening new issues is not the way to help you more and better. We saw what you wrote on the previous ticket and as you can imagine, we can’t help you if you don’t put the changes you made. Also the error is pretty explicit: a file not found

ghost (Issue Creator) on (2024-02-14 10:54:35 UTC): (def ^:private command-timeout-ms (* 60 60 1000))    I have changed this inline in shell.clj file

"
2134025161,issue,closed,completed,International characters do not display in Slack alerts,"### Describe the bug

Unicode characters not showing up in Slack alerts, known to affect at least these versions: v1.47.9, v1.48.3 and v1.48.5.
In email notifications the text displays as expected.

### To Reproduce

Create a native question that returns text with international characters, and set up a Slack alert for either the card or the  dashboard.

```SELECT 'هذا نص عربي عشوائي، يستخدم لأغراض توضيحية فقط. لا يحتوي على أي معنى محدد ومصمم ليكون غير مسيء.' AS Text, 'Arabic' AS Language
SELECT '这是一个随机的中文文本，仅用于说明目的。它没有具体的意义，旨在不冒犯。', 'Chinese'
UNION ALL
SELECT 'זהו טקסט עברי אקראי, המשמש למטרות המחשה בלבד. אינו מכיל משמעות מסוימת ומעוצב להיות לא מעליב.', 'Hebrew'
UNION ALL
SELECT 'árvíztűrő tükörfúrógép', 'Hungarian'
UNION ALL
SELECT '이것은 임의의 한국어 텍스트로, 설명 목적으로만 사용됩니다. 구체적인 의미를 포함하지 않으며 불쾌감을 주지 않도록 설계되었습니다.', 'Korean'
```

Results in the browser:
<img width=""676"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/2800a35e-fb40-43e0-8dd9-cbc6adfd453b"">

Results in Email:
<img width=""590"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/52890a6c-79ae-4db6-8401-c34a004442ee"">

Results in Slack:
<img width=""390"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/187d8699-a78c-42ba-bdf8-62dff1c64258"">

### Expected behavior

All characters should be rendered correctly

### Logs

n/a

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.209-198.812.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""bigquery-cloud-sdk"",
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v1.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```


### Severity

P1 - no workaround, reported by a customer

### Additional context

_No response_",zbodi74,2024-02-14 10:34:17+00:00,['adam-james-v'],2024-09-02 07:59:29+00:00,2024-09-02 07:59:28+00:00,https://github.com/metabase/metabase/issues/38753,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Alerts', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1943503539, 'issue_id': 2134025161, 'author': 'paoliniluis', 'body': 'Have you pulled the fonts packages in your environment?', 'created_at': datetime.datetime(2024, 2, 14, 10, 45, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 1944214574, 'issue_id': 2134025161, 'author': 'zbodi74', 'body': '@paoliniluis - yes, I reproduced this on a cloud instance as well as with Docker using the released image `metabase/metabase-enterprise:v1.48.5`.', 'created_at': datetime.datetime(2024, 2, 14, 16, 47, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1944443021, 'issue_id': 2134025161, 'author': 'camsaul', 'body': 'Regression of #2027', 'created_at': datetime.datetime(2024, 2, 14, 19, 17, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2128836596, 'issue_id': 2134025161, 'author': 'darksciencebase', 'body': ""confirmed it's still happening on master as of today (i used stats so it's not my environment)"", 'created_at': datetime.datetime(2024, 5, 24, 7, 53, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2149286786, 'issue_id': 2134025161, 'author': 'qnkhuat', 'body': ""I think this is a CSSBox's bug see: https://github.com/radkovo/CSSBox/issues/85\r\n\r\nTLDR:\r\n- We use Lato as our primary font, and Lato does not support non-Latin languages.\r\n- So when rendering a Korean text with lato, it's invalid and it should fall back to the next font family, which is defined [here](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/style.clj#L76)\r\n- In order to send charts to Slack, we render those charts from HTML to PNG using CSSBox (see [this](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/png.clj#L76) code)\r\n- CSSBox is not handling font fallback correctly\r\n\r\nThere are a couple of options:\r\n1. We should try to fix the CSSBox bug\r\n2. Change from Lato to [Noto](https://fonts.google.com/noto) - a font that supports a wide range of language"", 'created_at': datetime.datetime(2024, 6, 5, 9, 10, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2175391342, 'issue_id': 2134025161, 'author': 'yanghua-ola', 'body': ""> I think this is a CSSBox's bug see: [radkovo/CSSBox#85](https://github.com/radkovo/CSSBox/issues/85)\r\n> \r\n> TLDR:\r\n> \r\n> * We use Lato as our primary font, and Lato does not support non-Latin languages.\r\n> * So when rendering a Korean text with lato, it's invalid and it should fall back to the next font family, which is defined [here](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/style.clj#L76)\r\n> * In order to send charts to Slack, we render those charts from HTML to PNG using CSSBox (see [this](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/png.clj#L76) code)\r\n> * CSSBox is not handling font fallback correctly\r\n> \r\n> There are a couple of options:\r\n> \r\n> 1. We should try to fix the CSSBox bug\r\n> 2. Change from Lato to [Noto](https://fonts.google.com/noto) - a font that supports a wide range of language\r\n\r\nAny plans on the fix? Any workaround before it is fixed?\r\n\r\nI tried to alias Noto Sans as Lato on system level; but it appeared metabase was using an embedded font file `frontend_client/app/fonts/Lato/lato-v16-latin-%s.ttf`. Thus it didn't work."", 'created_at': datetime.datetime(2024, 6, 18, 7, 29, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183612197, 'issue_id': 2134025161, 'author': 'adam-james-v', 'body': ""@yanghua-ola , I have a fix that is up and ready for review. Hopefully we can get that rolling next week.\r\nUnfortunately, I'm not sure of a helpful workaround for you at this time, especially if loading your own fonts in the system hasn't worked"", 'created_at': datetime.datetime(2024, 6, 22, 0, 38, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296760135, 'issue_id': 2134025161, 'author': 'Tony-metabase', 'body': 'There is still a missing piece here since it works for Tables but not for other charts. Lik a Bar chart:\r\n\r\n![image](https://github.com/user-attachments/assets/e5fddcc1-a343-4c1e-9a43-30627e597dfc)\r\n\r\nSubscription:\r\n\r\n![image](https://github.com/user-attachments/assets/c30a4e5e-9e2c-46be-a0de-49fa95b644a1)', 'created_at': datetime.datetime(2024, 8, 19, 14, 46, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324068452, 'issue_id': 2134025161, 'author': 'Tony-metabase', 'body': 'Closing this one out since the fix was not properly applied to the whole library. I opened a separate issue which should take care of the charts:\r\n\r\nhttps://github.com/metabase/metabase/issues/47497', 'created_at': datetime.datetime(2024, 9, 2, 7, 59, 28, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-14 10:45:32 UTC): Have you pulled the fonts packages in your environment?

zbodi74 (Issue Creator) on (2024-02-14 16:47:12 UTC): @paoliniluis - yes, I reproduced this on a cloud instance as well as with Docker using the released image `metabase/metabase-enterprise:v1.48.5`.

camsaul on (2024-02-14 19:17:29 UTC): Regression of #2027

darksciencebase on (2024-05-24 07:53:08 UTC): confirmed it's still happening on master as of today (i used stats so it's not my environment)

qnkhuat on (2024-06-05 09:10:52 UTC): I think this is a CSSBox's bug see: https://github.com/radkovo/CSSBox/issues/85

TLDR:
- We use Lato as our primary font, and Lato does not support non-Latin languages.
- So when rendering a Korean text with lato, it's invalid and it should fall back to the next font family, which is defined [here](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/style.clj#L76)
- In order to send charts to Slack, we render those charts from HTML to PNG using CSSBox (see [this](https://github.com/metabase/metabase/blob/44fb3171f47877c5edabc2b76de466ae52a4795e/src/metabase/pulse/render/png.clj#L76) code)
- CSSBox is not handling font fallback correctly

There are a couple of options:
1. We should try to fix the CSSBox bug
2. Change from Lato to [Noto](https://fonts.google.com/noto) - a font that supports a wide range of language

yanghua-ola on (2024-06-18 07:29:42 UTC): Any plans on the fix? Any workaround before it is fixed?

I tried to alias Noto Sans as Lato on system level; but it appeared metabase was using an embedded font file `frontend_client/app/fonts/Lato/lato-v16-latin-%s.ttf`. Thus it didn't work.

adam-james-v (Assginee) on (2024-06-22 00:38:08 UTC): @yanghua-ola , I have a fix that is up and ready for review. Hopefully we can get that rolling next week.
Unfortunately, I'm not sure of a helpful workaround for you at this time, especially if loading your own fonts in the system hasn't worked

Tony-metabase on (2024-08-19 14:46:18 UTC): There is still a missing piece here since it works for Tables but not for other charts. Lik a Bar chart:

![image](https://github.com/user-attachments/assets/e5fddcc1-a343-4c1e-9a43-30627e597dfc)

Subscription:

![image](https://github.com/user-attachments/assets/c30a4e5e-9e2c-46be-a0de-49fa95b644a1)

Tony-metabase on (2024-09-02 07:59:28 UTC): Closing this one out since the fix was not properly applied to the whole library. I opened a separate issue which should take care of the charts:

https://github.com/metabase/metabase/issues/47497

"
2133454675,issue,closed,not_planned,Can't make a distribution on an audit Model,"### Describe the bug

I want to do a distribution of the activity log based on the user ID, but I get
```
Unable to bin Field without a min/max value (missing or incomplete fingerprint)
```
![image](https://github.com/metabase/metabase/assets/1711649/b70af6c0-d94f-425b-b6c0-46c0f97474d2)

### To Reproduce

1) go to browse data->activity log
2) click on the user id field, then distribution
3) see error

### Expected behavior

I should see a bar chart

### Logs

```
2024-02-14 02:48:47,409 ERROR middleware.catch-exceptions :: Error processing query: Unable to bin Field without a min/max value (missing or incomplete fingerprint)
{:database_id 13371337,
 :started_at #t ""2024-02-14T02:48:47.303360Z[Etc/UTC]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Unable to bin Field without a min/max value (missing or incomplete fingerprint)"",
   :stacktrace
   [""--> query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
    ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:48)""
    ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
    ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
    ""mbql.util.match.impl$replace_in_collection$iter__29215__29219$fn__29220.invoke(impl.cljc:45)""
    ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""
    ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
    ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
    ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invokeStatic(binning.clj:120)""
    ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invoke(binning.clj:116)""
    ""query_processor.middleware.binning$update_binning_strategy.invokeStatic(binning.clj:134)""
    ""query_processor.middleware.binning$update_binning_strategy.invoke(binning.clj:127)""
    ""query_processor$preprocess_STAR_$fn__72511.invoke(query_processor.clj:164)""
    ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)""
    ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)""
    ""query_processor$fn__72519$combined_pre_process__72520$combined_pre_process_STAR___72521.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66128.invoke(fetch_source_query.clj:299)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285$fn__71289.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__66705$fn__66706.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__66705.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71282.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71587.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__78808$handle_audit_app_internal_queries__78809$fn__78811.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71233.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70352.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71518.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72119.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62302$thunk__62304.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62302.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62314.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93615.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__52895$fn__52897.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__52895.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43513.invoke(streaming_response.clj:88)""],
   :ex-data {:clause [:field 254 {:base-type :type/Integer, :binning {:strategy :default}}]}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 13371337,
  :type ""query"",
  :query
  {:aggregation [[""count""]],
   :breakout [[""field"" 254 {:base-type ""type/Integer"", :binning {:strategy ""default""}}]],
   :source-table ""card__21""},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> query_processor.middleware.binning$extract_bounds.invokeStatic(binning.clj:56)""
  ""query_processor.middleware.binning$extract_bounds.invoke(binning.clj:35)""
  ""query_processor.middleware.binning$update_binned_field.invokeStatic(binning.clj:102)""
  ""query_processor.middleware.binning$update_binned_field.invoke(binning.clj:94)""
  ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
  ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:48)""
  ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
  ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
  ""mbql.util.match.impl$replace_in_collection$iter__29215__29219$fn__29220.invoke(impl.cljc:45)""
  ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""
  ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
  ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)""
  ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invokeStatic(binning.clj:120)""
  ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invoke(binning.clj:116)""
  ""query_processor.middleware.binning$update_binning_strategy.invokeStatic(binning.clj:134)""
  ""query_processor.middleware.binning$update_binning_strategy.invoke(binning.clj:127)""
  ""query_processor$preprocess_STAR_$fn__72511.invoke(query_processor.clj:164)""
  ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)""
  ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)""
  ""query_processor$fn__72519$combined_pre_process__72520$combined_pre_process_STAR___72521.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66128.invoke(fetch_source_query.clj:299)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285$fn__71289.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__66705$fn__66706.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__66705.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71282.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__71587.invoke(normalize_query.clj:38)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__78808$handle_audit_app_internal_queries__78809$fn__78811.invoke(handle_audit_queries.clj:142)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71233.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70352.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__71518.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72119.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62302$thunk__62304.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62302.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62314.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93615.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__52895$fn__52897.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__52895.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43513.invoke(streaming_response.clj:88)""],
 :card_id 21,
 :context :ad-hoc,
 :error ""Unable to bin Field without a min/max value (missing or incomplete fingerprint)"",
 :row_count 0,
 :running_time 0,
 :preprocessed nil,
 :ex-data {:type :invalid-query, :field-id 254, :fingerprint nil},
 :data {:rows [], :cols []}}

2024-02-14 02:48:47,415 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 128.6 ms (17 DB calls) App DB connections: 1/13 Jetty threads: 3/50 (7 idle, 0 queued) (86 total active threads) Queries in flight: 0 (0 queued)
2024-02-14 02:48:47,415 TRACE query-processor.reducible :: Port out-chan got {:database_id 13371337, :started_at #t ""2024-02-14T02:48:47.303360Z[Etc/UTC]"", :via [{:status :failed, :class clojure.lang.ExceptionInfo, :error ""Unable to bin Field without a min/max value (missing or incomplete fingerprint)"", :stacktrace [""--> query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:48)"" ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""mbql.util.match.impl$replace_in_collection$iter__29215__29219$fn__29220.invoke(impl.cljc:45)"" ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)"" ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invokeStatic(binning.clj:120)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invoke(binning.clj:116)"" ""query_processor.middleware.binning$update_binning_strategy.invokeStatic(binning.clj:134)"" ""query_processor.middleware.binning$update_binning_strategy.invoke(binning.clj:127)"" ""query_processor$preprocess_STAR_$fn__72511.invoke(query_processor.clj:164)"" ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)"" ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)"" ""query_processor$fn__72519$combined_pre_process__72520$combined_pre_process_STAR___72521.invoke(query_processor.clj:259)"" ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66128.invoke(fetch_source_query.clj:299)"" ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285$fn__71289.invoke(resolve_database_and_driver.clj:77)"" ""driver$do_with_driver.invokeStatic(driver.clj:97)"" ""driver$do_with_driver.invoke(driver.clj:92)"" ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285.invoke(resolve_database_and_driver.clj:76)"" ""query_processor.middleware.store$initialize_store$fn__66705$fn__66706.invoke(store.clj:14)"" ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)"" ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"" ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)"" ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"" ""query_processor.middleware.store$initialize_store$fn__66705.invoke(store.clj:13)"" ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71282.invoke(resolve_database_and_driver.clj:60)"" ""query_processor.middleware.normalize_query$normalize$fn__71587.invoke(normalize_query.clj:38)"" ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__78808$handle_audit_app_internal_queries__78809$fn__78811.invoke(handle_audit_queries.clj:142)"" ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71233.invoke(enterprise.clj:103)"" ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70352.invoke(constraints.clj:104)"" ""query_processor.middleware.process_userland_query$process_userland_query$fn__71518.invoke(process_userland_query.clj:156)"" ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72119.invoke(catch_exceptions.clj:171)"" ""query_processor.reducible$async_qp$qp_STAR___62302$thunk__62304.invoke(reducible.clj:126)"" ""query_processor.reducible$async_qp$qp_STAR___62302.invoke(reducible.clj:132)"" ""query_processor.reducible$sync_qp$qp_STAR___62314.doInvoke(reducible.clj:153)"" ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)"" ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)"" ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)"" ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)"" ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)"" ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)"" ""api.dataset$run_query_async$fn__93615.invoke(dataset.clj:79)"" ""query_processor.streaming$streaming_response_STAR_$fn__52895$fn__52897.invoke(streaming.clj:168)"" ""query_processor.streaming$streaming_response_STAR_$fn__52895.invoke(streaming.clj:167)"" ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)"" ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)"" ""async.streaming_response$do_f_async$task__43513.invoke(streaming_response.clj:88)""], :ex-data {:clause [:field 254 {:base-type :type/Integer, :binning {:strategy :default}}]}}], :action_id nil, :error_type :invalid-query, :json_query {:database 13371337, :type ""query"", :query {:aggregation [[""count""]], :breakout [[""field"" 254 {:base-type ""type/Integer"", :binning {:strategy ""default""}}]], :source-table ""card__21""}, :parameters [], :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}}, :native nil, :status :failed, :class clojure.lang.ExceptionInfo, :stacktrace [""--> query_processor.middleware.binning$extract_bounds.invokeStatic(binning.clj:56)"" ""query_processor.middleware.binning$extract_bounds.invoke(binning.clj:35)"" ""query_processor.middleware.binning$update_binned_field.invokeStatic(binning.clj:102)"" ""query_processor.middleware.binning$update_binned_field.invoke(binning.clj:94)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:48)"" ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""mbql.util.match.impl$replace_in_collection$iter__29215__29219$fn__29220.invoke(impl.cljc:45)"" ""mbql.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)"" ""mbql.util.match.impl$replace_in_collection.invoke(impl.cljc:39)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query$replace_57948__57949.invoke(binning.clj:120)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invokeStatic(binning.clj:120)"" ""query_processor.middleware.binning$update_binning_strategy_in_inner_query.invoke(binning.clj:116)"" ""query_processor.middleware.binning$update_binning_strategy.invokeStatic(binning.clj:134)"" ""query_processor.middleware.binning$update_binning_strategy.invoke(binning.clj:127)"" ""query_processor$preprocess_STAR_$fn__72511.invoke(query_processor.clj:164)"" ""query_processor$preprocess_STAR_.invokeStatic(query_processor.clj:162)"" ""query_processor$preprocess_STAR_.invoke(query_processor.clj:157)"" ""query_processor$fn__72519$combined_pre_process__72520$combined_pre_process_STAR___72521.invoke(query_processor.clj:259)"" ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66128.invoke(fetch_source_query.clj:299)"" ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285$fn__71289.invoke(resolve_database_and_driver.clj:77)"" ""driver$do_with_driver.invokeStatic(driver.clj:97)"" ""driver$do_with_driver.invoke(driver.clj:92)"" ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71285.invoke(resolve_database_and_driver.clj:76)"" ""query_processor.middleware.store$initialize_store$fn__66705$fn__66706.invoke(store.clj:14)"" ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)"" ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"" ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)"" ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)"" ""query_processor.middleware.store$initialize_store$fn__66705.invoke(store.clj:13)"" ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71282.invoke(resolve_database_and_driver.clj:60)"" ""query_processor.middleware.normalize_query$normalize$fn__71587.invoke(normalize_query.clj:38)"" ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__78808$handle_audit_app_internal_queries__78809$fn__78811.invoke(handle_audit_queries.clj:142)"" ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71233.invoke(enterprise.clj:103)"" ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70352.invoke(constraints.clj:104)"" ""query_processor.middleware.process_userland_query$process_userland_query$fn__71518.invoke(process_userland_query.clj:156)"" ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72119.invoke(catch_exceptions.clj:171)"" ""query_processor.reducible$async_qp$qp_STAR___62302$thunk__62304.invoke(reducible.clj:126)"" ""query_processor.reducible$async_qp$qp_STAR___62302.invoke(reducible.clj:132)"" ""query_processor.reducible$sync_qp$qp_STAR___62314.doInvoke(reducible.clj:153)"" ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)"" ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)"" ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)"" ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)"" ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)"" ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)"" ""api.dataset$run_query_async$fn__93615.invoke(dataset.clj:79)"" ""query_processor.streaming$streaming_response_STAR_$fn__52895$fn__52897.invoke(streaming.clj:168)"" ""query_processor.streaming$streaming_response_STAR_$fn__52895.invoke(streaming.clj:167)"" ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)"" ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)"" ""async.streaming_response$do_f_async$task__43513.invoke(streaming_response.clj:88)""], :card_id 21, :context :ad-hoc, :error ""Unable to bin Field without a min/max value (missing or incomplete fingerprint)"", :row_count 0, :running_time 0, :preprocessed nil, :ex-data {:type :invalid-query, :field-id 254, :fingerprint nil}, :data {:rows [], :cols []}}
2024-02-14 02:48:47,419 TRACE query-processor.reducible :: Closing out-chan.
```

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-02-14 02:51:02+00:00,[],2024-03-21 21:00:59+00:00,2024-03-21 21:00:59+00:00,https://github.com/metabase/metabase/issues/38750,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('Querying/Models', 'aka Datasets')]","[{'comment_id': 2013727895, 'issue_id': 2133454675, 'author': 'luizarakaki', 'body': 'Unable to repro on 49.1', 'created_at': datetime.datetime(2024, 3, 21, 21, 0, 59, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-21 21:00:59 UTC): Unable to repro on 49.1

"
2133452111,issue,closed,not_planned,cannot create a question from an audit model ,"### Describe the bug

For some reason, the GUI builder stays frozen and doesn't show me the steps

### To Reproduce

1) new->question-> activity log
2) see the gui builder frozen, won't show you the steps

### Expected behavior

It should be the same as all the rest of the tables/models

### Logs

NA

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P1

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/d7072c95-9bd9-4a7e-a993-3c7de9c4b0c8)
",paoliniluis,2024-02-14 02:47:05+00:00,[],2024-03-21 21:01:12+00:00,2024-03-21 21:01:12+00:00,https://github.com/metabase/metabase/issues/38749,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]","[{'comment_id': 1943005049, 'issue_id': 2133452111, 'author': 'paoliniluis', 'body': 'P.s.: if I press the play button I get a 400\r\n\r\n```\r\n{\r\n    ""via"": [\r\n        {\r\n            ""type"": ""clojure.lang.ExceptionInfo"",\r\n            ""message"": ""`database` is required for all queries whose type is not `internal`."",\r\n            ""data"": {\r\n                ""status-code"": 400,\r\n                ""query"": {\r\n                    ""type"": ""query"",\r\n                    ""query"": {\r\n                        ""limit"": 10,\r\n                        ""source-table"": ""card__21""\r\n                    },\r\n                    ""parameters"": [],\r\n                    ""middleware"": {\r\n                        ""js-int-to-string?"": true\r\n                    }\r\n                }\r\n            },\r\n            ""at"": [\r\n                ""metabase.api.dataset$run_query_async"",\r\n                ""invokeStatic"",\r\n                ""dataset.clj"",\r\n                60\r\n            ]\r\n        }\r\n    ],\r\n    ""trace"": [\r\n        [\r\n            ""metabase.api.dataset$run_query_async"",\r\n            ""invokeStatic"",\r\n            ""dataset.clj"",\r\n            60\r\n        ],\r\n        [\r\n            ""metabase.api.dataset$run_query_async"",\r\n            ""doInvoke"",\r\n            ""dataset.clj"",\r\n            49\r\n        ],\r\n        [\r\n            ""clojure.lang.RestFn"",\r\n            ""invoke"",\r\n            ""RestFn.java"",\r\n            410\r\n        ],\r\n        [\r\n            ""metabase.api.dataset$fn__93628"",\r\n            ""invokeStatic"",\r\n            ""dataset.clj"",\r\n            85\r\n        ],\r\n        [\r\n            ""metabase.api.dataset$fn__93628"",\r\n            ""invoke"",\r\n            ""dataset.clj"",\r\n            81\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_response$fn__44405"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            160\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_middleware$fn__44389"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            132\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_info$fn__44394"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            139\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_matches$fn__44398"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            151\r\n        ],\r\n        [\r\n            ""clojure.lang.Var"",\r\n            ""invoke"",\r\n            ""Var.java"",\r\n            393\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_matches$fn__44398"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            152\r\n        ],\r\n        [\r\n            ""clojure.lang.Var"",\r\n            ""invoke"",\r\n            ""Var.java"",\r\n            393\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.auth$enforce_authentication$fn__93699"",\r\n            ""invoke"",\r\n            ""auth.clj"",\r\n            17\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$handler__44445"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            290\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            300\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""metabase.api.routes$fn__101593$fn__101594"",\r\n            ""invoke"",\r\n            ""routes.clj"",\r\n            65\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""clojure.lang.AFn"",\r\n            ""applyToHelper"",\r\n            ""AFn.java"",\r\n            160\r\n        ],\r\n        [\r\n            ""clojure.lang.AFn"",\r\n            ""applyTo"",\r\n            ""AFn.java"",\r\n            144\r\n        ],\r\n        [\r\n            ""clojure.core$apply"",\r\n            ""invokeStatic"",\r\n            ""core.clj"",\r\n            667\r\n        ],\r\n        [\r\n            ""clojure.core$apply"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            662\r\n        ],\r\n        [\r\n            ""metabase.server.routes$fn__101758$fn__101759"",\r\n            ""doInvoke"",\r\n            ""routes.clj"",\r\n            72\r\n        ],\r\n        [\r\n            ""clojure.lang.RestFn"",\r\n            ""invoke"",\r\n            ""RestFn.java"",\r\n            436\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$handler__44445"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            290\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            300\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_matches$fn__44398"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            153\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_matches$fn__44398"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            153\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$wrap_route_matches$fn__44398"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            153\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            199\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$handler__44445"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            290\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            300\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            197\r\n        ],\r\n        [\r\n            ""compojure.core$make_context$fn__44449"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            301\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417$f__44418"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            198\r\n        ],\r\n        [\r\n            ""compojure.core$routes$fn__44417"",\r\n            ""invoke"",\r\n            ""core.clj"",\r\n            200\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98387"",\r\n            ""invoke"",\r\n            ""exceptions.clj"",\r\n            108\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__98384"",\r\n            ""invoke"",\r\n            ""exceptions.clj"",\r\n            96\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.log$log_api_call$fn__103703$fn__103704$fn__103705"",\r\n            ""invoke"",\r\n            ""log.clj"",\r\n            216\r\n        ],\r\n        [\r\n            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",\r\n            ""invokeStatic"",\r\n            ""diagnostic.clj"",\r\n            18\r\n        ],\r\n        [\r\n            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",\r\n            ""invoke"",\r\n            ""diagnostic.clj"",\r\n            12\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.log$log_api_call$fn__103703$fn__103704"",\r\n            ""invoke"",\r\n            ""log.clj"",\r\n            208\r\n        ],\r\n        [\r\n            ""toucan2.execute$do_with_call_counts"",\r\n            ""invokeStatic"",\r\n            ""execute.clj"",\r\n            112\r\n        ],\r\n        [\r\n            ""toucan2.execute$do_with_call_counts"",\r\n            ""invoke"",\r\n            ""execute.clj"",\r\n            103\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.log$log_api_call$fn__103703"",\r\n            ""invoke"",\r\n            ""log.clj"",\r\n            207\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__108428"",\r\n            ""invoke"",\r\n            ""browser_cookie.clj"",\r\n            40\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.security$add_security_headers$fn__84576"",\r\n            ""invoke"",\r\n            ""security.clj"",\r\n            182\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.json$wrap_json_body$fn__45763"",\r\n            ""invoke"",\r\n            ""json.clj"",\r\n            67\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.offset_paging$handle_paging$fn__84600"",\r\n            ""invoke"",\r\n            ""offset_paging.clj"",\r\n            45\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__45781"",\r\n            ""invoke"",\r\n            ""json.clj"",\r\n            103\r\n        ],\r\n        [\r\n            ""ring.middleware.keyword_params$wrap_keyword_params$fn__108695"",\r\n            ""invoke"",\r\n            ""keyword_params.clj"",\r\n            55\r\n        ],\r\n        [\r\n            ""ring.middleware.params$wrap_params$fn__108714"",\r\n            ""invoke"",\r\n            ""params.clj"",\r\n            77\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.misc$maybe_set_site_url$fn__66620"",\r\n            ""invoke"",\r\n            ""misc.clj"",\r\n            61\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$reset_session_timeout$fn__71793"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            542\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$bind_current_user$fn__71759$fn__71760"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            437\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$do_with_current_user"",\r\n            ""invokeStatic"",\r\n            ""session.clj"",\r\n            416\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$do_with_current_user"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            400\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$bind_current_user$fn__71759"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            436\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$wrap_current_user_info$fn__71742"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            375\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.session$wrap_session_id$fn__71714"",\r\n            ""invoke"",\r\n            ""session.clj"",\r\n            254\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.auth$wrap_static_api_key$fn__93707"",\r\n            ""invoke"",\r\n            ""auth.clj"",\r\n            30\r\n        ],\r\n        [\r\n            ""ring.middleware.cookies$wrap_cookies$fn__108615"",\r\n            ""invoke"",\r\n            ""cookies.clj"",\r\n            216\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.misc$add_content_type$fn__66602"",\r\n            ""invoke"",\r\n            ""misc.clj"",\r\n            29\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__66628"",\r\n            ""invoke"",\r\n            ""misc.clj"",\r\n            78\r\n        ],\r\n        [\r\n            ""ring.middleware.gzip$wrap_gzip$fn__108657"",\r\n            ""invoke"",\r\n            ""gzip.clj"",\r\n            86\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.misc$bind_request$fn__66631"",\r\n            ""invoke"",\r\n            ""misc.clj"",\r\n            95\r\n        ],\r\n        [\r\n            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__108444"",\r\n            ""invoke"",\r\n            ""ssl.clj"",\r\n            51\r\n        ],\r\n        [\r\n            ""metabase.server$async_proxy_handler$fn__66805"",\r\n            ""invoke"",\r\n            ""server.clj"",\r\n            78\r\n        ],\r\n        [\r\n            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",\r\n            ""handle"",\r\n            null,\r\n            -1\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.handler.StatisticsHandler"",\r\n            ""handle"",\r\n            ""StatisticsHandler.java"",\r\n            173\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.handler.HandlerWrapper"",\r\n            ""handle"",\r\n            ""HandlerWrapper.java"",\r\n            122\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.Server"",\r\n            ""handle"",\r\n            ""Server.java"",\r\n            563\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",\r\n            ""dispatch"",\r\n            ""HttpChannel.java"",\r\n            1598\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.HttpChannel"",\r\n            ""dispatch"",\r\n            ""HttpChannel.java"",\r\n            753\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.HttpChannel"",\r\n            ""handle"",\r\n            ""HttpChannel.java"",\r\n            501\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.server.HttpConnection"",\r\n            ""onFillable"",\r\n            ""HttpConnection.java"",\r\n            287\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",\r\n            ""succeeded"",\r\n            ""AbstractConnection.java"",\r\n            314\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.io.FillInterest"",\r\n            ""fillable"",\r\n            ""FillInterest.java"",\r\n            100\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",\r\n            ""run"",\r\n            ""SelectableChannelEndPoint.java"",\r\n            53\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",\r\n            ""runTask"",\r\n            ""AdaptiveExecutionStrategy.java"",\r\n            421\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",\r\n            ""consumeTask"",\r\n            ""AdaptiveExecutionStrategy.java"",\r\n            390\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",\r\n            ""tryProduce"",\r\n            ""AdaptiveExecutionStrategy.java"",\r\n            277\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",\r\n            ""run"",\r\n            ""AdaptiveExecutionStrategy.java"",\r\n            199\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",\r\n            ""run"",\r\n            ""ReservedThreadExecutor.java"",\r\n            411\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",\r\n            ""runJob"",\r\n            ""QueuedThreadPool.java"",\r\n            969\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",\r\n            ""doRunJob"",\r\n            ""QueuedThreadPool.java"",\r\n            1194\r\n        ],\r\n        [\r\n            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",\r\n            ""run"",\r\n            ""QueuedThreadPool.java"",\r\n            1149\r\n        ],\r\n        [\r\n            ""java.lang.Thread"",\r\n            ""run"",\r\n            ""Thread.java"",\r\n            829\r\n        ]\r\n    ],\r\n    ""cause"": ""`database` is required for all queries whose type is not `internal`."",\r\n    ""data"": {\r\n        ""status-code"": 400,\r\n        ""query"": {\r\n            ""type"": ""query"",\r\n            ""query"": {\r\n                ""limit"": 10,\r\n                ""source-table"": ""card__21""\r\n            },\r\n            ""parameters"": [],\r\n            ""middleware"": {\r\n                ""js-int-to-string?"": true\r\n            }\r\n        }\r\n    },\r\n    ""message"": ""`database` is required for all queries whose type is not `internal`."",\r\n    ""query"": {\r\n        ""type"": ""query"",\r\n        ""query"": {\r\n            ""limit"": 10,\r\n            ""source-table"": ""card__21""\r\n        },\r\n        ""parameters"": [],\r\n        ""middleware"": {\r\n            ""js-int-to-string?"": true\r\n        }\r\n    }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 2, 14, 2, 48, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013728483, 'issue_id': 2133452111, 'author': 'luizarakaki', 'body': 'Unable to repro on 49.1', 'created_at': datetime.datetime(2024, 3, 21, 21, 1, 12, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-14 02:48:08 UTC): P.s.: if I press the play button I get a 400

```
{
    ""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": ""`database` is required for all queries whose type is not `internal`."",
            ""data"": {
                ""status-code"": 400,
                ""query"": {
                    ""type"": ""query"",
                    ""query"": {
                        ""limit"": 10,
                        ""source-table"": ""card__21""
                    },
                    ""parameters"": [],
                    ""middleware"": {
                        ""js-int-to-string?"": true
                    }
                }
            },
            ""at"": [
                ""metabase.api.dataset$run_query_async"",
                ""invokeStatic"",
                ""dataset.clj"",
                60
            ]
        }
    ],
    ""trace"": [
        [
            ""metabase.api.dataset$run_query_async"",
            ""invokeStatic"",
            ""dataset.clj"",
            60
        ],
        [
            ""metabase.api.dataset$run_query_async"",
            ""doInvoke"",
            ""dataset.clj"",
            49
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            410
        ],
        [
            ""metabase.api.dataset$fn__93628"",
            ""invokeStatic"",
            ""dataset.clj"",
            85
        ],
        [
            ""metabase.api.dataset$fn__93628"",
            ""invoke"",
            ""dataset.clj"",
            81
        ],
        [
            ""compojure.core$wrap_response$fn__44405"",
            ""invoke"",
            ""core.clj"",
            160
        ],
        [
            ""compojure.core$wrap_route_middleware$fn__44389"",
            ""invoke"",
            ""core.clj"",
            132
        ],
        [
            ""compojure.core$wrap_route_info$fn__44394"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44398"",
            ""invoke"",
            ""core.clj"",
            151
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44398"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.auth$enforce_authentication$fn__93699"",
            ""invoke"",
            ""auth.clj"",
            17
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44445"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.api.routes$fn__101593$fn__101594"",
            ""invoke"",
            ""routes.clj"",
            65
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            667
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""metabase.server.routes$fn__101758$fn__101759"",
            ""doInvoke"",
            ""routes.clj"",
            72
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44445"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44398"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44398"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44398"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44445"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418$respond_SINGLEQUOTE___44419"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44449"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44417$f__44418"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44417"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98387"",
            ""invoke"",
            ""exceptions.clj"",
            108
        ],
        [
            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__98384"",
            ""invoke"",
            ""exceptions.clj"",
            96
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103703$fn__103704$fn__103705"",
            ""invoke"",
            ""log.clj"",
            216
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invokeStatic"",
            ""diagnostic.clj"",
            18
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invoke"",
            ""diagnostic.clj"",
            12
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103703$fn__103704"",
            ""invoke"",
            ""log.clj"",
            208
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invokeStatic"",
            ""execute.clj"",
            112
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invoke"",
            ""execute.clj"",
            103
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__103703"",
            ""invoke"",
            ""log.clj"",
            207
        ],
        [
            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__108428"",
            ""invoke"",
            ""browser_cookie.clj"",
            40
        ],
        [
            ""metabase.server.middleware.security$add_security_headers$fn__84576"",
            ""invoke"",
            ""security.clj"",
            182
        ],
        [
            ""metabase.server.middleware.json$wrap_json_body$fn__45763"",
            ""invoke"",
            ""json.clj"",
            67
        ],
        [
            ""metabase.server.middleware.offset_paging$handle_paging$fn__84600"",
            ""invoke"",
            ""offset_paging.clj"",
            45
        ],
        [
            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__45781"",
            ""invoke"",
            ""json.clj"",
            103
        ],
        [
            ""ring.middleware.keyword_params$wrap_keyword_params$fn__108695"",
            ""invoke"",
            ""keyword_params.clj"",
            55
        ],
        [
            ""ring.middleware.params$wrap_params$fn__108714"",
            ""invoke"",
            ""params.clj"",
            77
        ],
        [
            ""metabase.server.middleware.misc$maybe_set_site_url$fn__66620"",
            ""invoke"",
            ""misc.clj"",
            61
        ],
        [
            ""metabase.server.middleware.session$reset_session_timeout$fn__71793"",
            ""invoke"",
            ""session.clj"",
            542
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__71759$fn__71760"",
            ""invoke"",
            ""session.clj"",
            437
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invokeStatic"",
            ""session.clj"",
            416
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invoke"",
            ""session.clj"",
            400
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__71759"",
            ""invoke"",
            ""session.clj"",
            436
        ],
        [
            ""metabase.server.middleware.session$wrap_current_user_info$fn__71742"",
            ""invoke"",
            ""session.clj"",
            375
        ],
        [
            ""metabase.server.middleware.session$wrap_session_id$fn__71714"",
            ""invoke"",
            ""session.clj"",
            254
        ],
        [
            ""metabase.server.middleware.auth$wrap_static_api_key$fn__93707"",
            ""invoke"",
            ""auth.clj"",
            30
        ],
        [
            ""ring.middleware.cookies$wrap_cookies$fn__108615"",
            ""invoke"",
            ""cookies.clj"",
            216
        ],
        [
            ""metabase.server.middleware.misc$add_content_type$fn__66602"",
            ""invoke"",
            ""misc.clj"",
            29
        ],
        [
            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__66628"",
            ""invoke"",
            ""misc.clj"",
            78
        ],
        [
            ""ring.middleware.gzip$wrap_gzip$fn__108657"",
            ""invoke"",
            ""gzip.clj"",
            86
        ],
        [
            ""metabase.server.middleware.misc$bind_request$fn__66631"",
            ""invoke"",
            ""misc.clj"",
            95
        ],
        [
            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__108444"",
            ""invoke"",
            ""ssl.clj"",
            51
        ],
        [
            ""metabase.server$async_proxy_handler$fn__66805"",
            ""invoke"",
            ""server.clj"",
            78
        ],
        [
            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
            ""handle"",
            null,
            -1
        ],
        [
            ""org.eclipse.jetty.server.handler.StatisticsHandler"",
            ""handle"",
            ""StatisticsHandler.java"",
            173
        ],
        [
            ""org.eclipse.jetty.server.handler.HandlerWrapper"",
            ""handle"",
            ""HandlerWrapper.java"",
            122
        ],
        [
            ""org.eclipse.jetty.server.Server"",
            ""handle"",
            ""Server.java"",
            563
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
            ""dispatch"",
            ""HttpChannel.java"",
            1598
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""dispatch"",
            ""HttpChannel.java"",
            753
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""handle"",
            ""HttpChannel.java"",
            501
        ],
        [
            ""org.eclipse.jetty.server.HttpConnection"",
            ""onFillable"",
            ""HttpConnection.java"",
            287
        ],
        [
            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
            ""succeeded"",
            ""AbstractConnection.java"",
            314
        ],
        [
            ""org.eclipse.jetty.io.FillInterest"",
            ""fillable"",
            ""FillInterest.java"",
            100
        ],
        [
            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
            ""run"",
            ""SelectableChannelEndPoint.java"",
            53
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""runTask"",
            ""AdaptiveExecutionStrategy.java"",
            421
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""consumeTask"",
            ""AdaptiveExecutionStrategy.java"",
            390
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""tryProduce"",
            ""AdaptiveExecutionStrategy.java"",
            277
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""run"",
            ""AdaptiveExecutionStrategy.java"",
            199
        ],
        [
            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
            ""run"",
            ""ReservedThreadExecutor.java"",
            411
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
            ""runJob"",
            ""QueuedThreadPool.java"",
            969
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""doRunJob"",
            ""QueuedThreadPool.java"",
            1194
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""run"",
            ""QueuedThreadPool.java"",
            1149
        ],
        [
            ""java.lang.Thread"",
            ""run"",
            ""Thread.java"",
            829
        ]
    ],
    ""cause"": ""`database` is required for all queries whose type is not `internal`."",
    ""data"": {
        ""status-code"": 400,
        ""query"": {
            ""type"": ""query"",
            ""query"": {
                ""limit"": 10,
                ""source-table"": ""card__21""
            },
            ""parameters"": [],
            ""middleware"": {
                ""js-int-to-string?"": true
            }
        }
    },
    ""message"": ""`database` is required for all queries whose type is not `internal`."",
    ""query"": {
        ""type"": ""query"",
        ""query"": {
            ""limit"": 10,
            ""source-table"": ""card__21""
        },
        ""parameters"": [],
        ""middleware"": {
            ""js-int-to-string?"": true
        }
    }
}
```

luizarakaki on (2024-03-21 21:01:12 UTC): Unable to repro on 49.1

"
2133385622,issue,open,,Clicking on entity qualified id on the content model takes nowhere and spins forever,"### Describe the bug

1) go to the content model of the metabase analytics section
2) click on any entity qualified id
3) see the modal spinning forever
![image](https://github.com/metabase/metabase/assets/1711649/c2fcf745-6362-426c-abea-dccdd51849ae)


### To Reproduce

above

### Expected behavior

It should load the entity

### Logs

NA

### Information about your Metabase installation

```JSON
v47.x+ for sure
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-02-14 01:15:25+00:00,[],2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/38747,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/Querying', '')]","[{'comment_id': 2013740784, 'issue_id': 2133385622, 'author': 'luizarakaki', 'body': ""Fixed in the audit dev instance. The issue was that entity_qualified_id was marked as entity key.\r\nAlthough this looks a models bug, it shouldn't crash like that"", 'created_at': datetime.datetime(2024, 3, 21, 21, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244726267, 'issue_id': 2133385622, 'author': 'kamilmielnik', 'body': '`Lib.availableDrillThrus` incorrectly returns `zoom` drill (with incorrect `many-pks?: false`) when there are mutliple PKs and one of them is a string. [It should return drill-thru.pk instead](https://github.com/metabase/metabase/blob/a6039a0fcbb515f417bd6f9053e5af3708a856b2/src/metabase/lib/drill_thru/zoom.cljc#L61).\r\n\r\nRelabeling to QP.\r\n\r\nWays to reproduce:\r\n- Click any value in 2nd column in https://stats.metabase.com/model/14230\r\n- New Model > Products > Edit Metadata > Change semantic type of Vendor to ""Entity Key"" > Save > Visualize. Click any value in Vendor column.\r\n- New SQL Question > `select \'a\' as ""a"", \'b\' as ""b"";` > Save. Create a model based on this question > Metadata > Set semantic type of both columns as ""Entity Key"" > Save > Visualize. Click any value in table.', 'created_at': datetime.datetime(2024, 7, 23, 9, 36, 9, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-21 21:09:38 UTC): Fixed in the audit dev instance. The issue was that entity_qualified_id was marked as entity key.
Although this looks a models bug, it shouldn't crash like that

kamilmielnik on (2024-07-23 09:36:09 UTC): `Lib.availableDrillThrus` incorrectly returns `zoom` drill (with incorrect `many-pks?: false`) when there are mutliple PKs and one of them is a string. [It should return drill-thru.pk instead](https://github.com/metabase/metabase/blob/a6039a0fcbb515f417bd6f9053e5af3708a856b2/src/metabase/lib/drill_thru/zoom.cljc#L61).

Relabeling to QP.

Ways to reproduce:
- Click any value in 2nd column in https://stats.metabase.com/model/14230
- New Model > Products > Edit Metadata > Change semantic type of Vendor to ""Entity Key"" > Save > Visualize. Click any value in Vendor column.
- New SQL Question > `select 'a' as ""a"", 'b' as ""b"";` > Save. Create a model based on this question > Metadata > Set semantic type of both columns as ""Entity Key"" > Save > Visualize. Click any value in table.

"
2133271843,issue,closed,completed,Document MB_DISABLE_SCHEDULER?,"Seems we have an env var that takes all the async tasks down... We might want to document that one, but it's there for testing purposes. BTW, we mention it https://www.metabase.com/learn/administration/git-based-workflow#make-sure-youve-turned-off-sync",paoliniluis,2024-02-13 23:01:57+00:00,['jeff-bruemmer'],2025-01-07 18:13:58+00:00,2025-01-07 17:38:19+00:00,https://github.com/metabase/metabase/issues/38746,"[('Type:Documentation', '')]",[],
2133102588,issue,closed,completed,measuring creator sentiment (BE),"https://www.notion.so/metabase/Measuring-Creator-Sentiment-f9b5e01e175540cf969c24b3159a29e8?d=d20237da699b481f8c63f16fe95996b5#aa173b3cce3a41cf9173492d2017c0b2
```[tasklist]
### BE Tasks
- [x] monthly task to send emails
- [x] query to find users (modding by month)
- [x] setting to disable sending emails
- [x] send the email to creators
```
",dpsutton,2024-02-13 20:48:39+00:00,['qwef'],2024-02-20 18:59:52+00:00,2024-02-20 18:56:43+00:00,https://github.com/metabase/metabase/issues/38739,[],[],
2133102078,issue,open,,Convert user timezone to db timezone when filtering,"**Is your feature request related to a problem? Please describe.**
If we capture or set the user timezone, we can convert the user timezone to the reporting timezone so all users see the same data when searching for the same date/time range

**Describe the solution you'd like**
1) capture or allow to set user timezone https://github.com/metabase/metabase/issues/4284
2) convert the timezone at the query level, when there are users in different timezones

**Describe alternatives you've considered**
None, filters will convert everything at the reporting timezone

**How important is this feature to you?**
Requested probably a lot of times, so it's about time we create a feature request for this

**Additional context**
+1 to https://github.com/metabase/metabase/issues/5640
",paoliniluis,2024-02-13 20:48:14+00:00,[],2024-02-13 20:48:14+00:00,,https://github.com/metabase/metabase/issues/38738,"[('Type:New Feature', ''), ('Misc/Timezones', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2133025826,issue,closed,completed,BE - REST API constraints for saving/editing Metrics,"Depends on #37348 

We need to enforce various rules about saving and updating v2 Metrics, including but not limited to:

- [ ] The final stage of a v2 Metric **must** have exactly one aggregation. No other clauses besides joins or filters are allowed. This must be validated when creating a v2 Metric (`POST /api/card`) and when updating one (`PUT /api/card/:id`). **ACTUALLY I DON'T KNOW IF THIS IS STILL TRUE: LOOK AT UPDATED PRODUCT DOCS AND ENFORCE WHATEVER LATEST CONSTRAINTS ARE**
- [ ] You cannot change a Metric to a regular Saved Question or Model or vice versa. `PUT /api/card/:id` needs to disallow changing `:type` to and from `:metric`
- [ ] V2 Metrics should be pMBQL only (depends on #39026), error if you try to save a legacy query as a V2 Metric",camsaul,2024-02-13 19:50:01+00:00,[],2025-01-06 14:43:43+00:00,2025-01-06 14:43:43+00:00,https://github.com/metabase/metabase/issues/38733,"[('Misc/API', ''), ('Administration/Metrics & Segments', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1942340971, 'issue_id': 2133025826, 'author': 'camsaul', 'body': ""I think we should also say v2 Metrics have to be saved as pMBQL. It's our long-term goal to get rid of legacy queries entirely, probably a good time to start moving that project forward."", 'created_at': datetime.datetime(2024, 2, 13, 20, 3, 41, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-02-13 20:03:41 UTC): I think we should also say v2 Metrics have to be saved as pMBQL. It's our long-term goal to get rid of legacy queries entirely, probably a good time to start moving that project forward.

"
2132928988,issue,open,,Select multiple dashboard tabs to export as PDFs,"**Is your feature request related to a problem? Please describe.**
Currently, you have to export individual tabs manually. 

**Describe the solution you'd like**
A way to select which tab you want to export in one click. 

**Describe alternatives you've considered**
Export to PDF tab by tab manually. 

**How important is this feature to you?**
Would save manual efforts. 

**Additional context**
Requested by a potential customer. 
",dahyeik,2024-02-13 18:36:07+00:00,[],2024-02-16 15:20:40+00:00,,https://github.com/metabase/metabase/issues/38729,"[('Type:New Feature', ''), ('Reporting/Export', '')]",[],
2132703402,issue,closed,completed,BE - Support metrics in MLv2,"```[tasklist]
### Tasks
- [ ] Make sure the metadata needed for metrics is available
- [ ] Adjust API endpoints to return metrics
- [ ] Expose metrics columns in visible-columns and retrurned-columns
- [ ] Make sure filters on metric columns can be created
- [ ] Make sure the metric aggregation appears by default
- [ ] Make sure the aggregation can be edited
- [ ] Make sure the question is savable
```
",ranquild,2024-02-13 16:21:39+00:00,['metamben'],2025-01-06 14:43:29+00:00,2025-01-06 14:43:28+00:00,https://github.com/metabase/metabase/issues/38724,"[('Administration/Metrics & Segments', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2132640589,issue,closed,completed,Toast/notification after custom dashboard has invisible text,"### Describe the bug

.

### To Reproduce

1. [as admin] Click ""Customize"" on the homepage
2. select a custom dashboard
3. the toast will be like this
<img width=""612"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/5e17dba7-8791-4f01-ae80-45cd0ecd625b"">


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Tested both on master and v0.48.3
```


### Severity

If I didn't read the modal I may not know how to undo it

### Additional context

_No response_",npretto,2024-02-13 15:55:16+00:00,['kulyk'],2024-02-26 16:54:18+00:00,2024-02-26 16:52:55+00:00,https://github.com/metabase/metabase/issues/38722,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1941873346, 'issue_id': 2132640589, 'author': 'npretto', 'body': 'Not sure if this was how it was supposed to be shown, but if in https://github.com/metabase/metabase/blob/3396f7562b3f3c3850b5b5d5e1e693cc35f0440e/frontend/src/metabase/home/components/CustomHomePageModal/CustomHomePageModal.tsx#L51-L60 we make the <Text> -> <Box> then it picks up the default toast/undos colors\r\n\r\n<img width=""582"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/6a109d1e-3cd1-41c9-914c-c2dc3aa24d67"">', 'created_at': datetime.datetime(2024, 2, 13, 16, 3, 20, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-02-13 16:03:20 UTC): Not sure if this was how it was supposed to be shown, but if in https://github.com/metabase/metabase/blob/3396f7562b3f3c3850b5b5d5e1e693cc35f0440e/frontend/src/metabase/home/components/CustomHomePageModal/CustomHomePageModal.tsx#L51-L60 we make the <Text> -> <Box> then it picks up the default toast/undos colors

<img width=""582"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/6a109d1e-3cd1-41c9-914c-c2dc3aa24d67"">

"
2132268022,issue,closed,not_planned,BE - Migrate `card.dataset` to `card.type`,,ranquild,2024-02-13 12:57:11+00:00,[],2024-02-13 19:44:37+00:00,2024-02-13 19:44:37+00:00,https://github.com/metabase/metabase/issues/38709,"[('.Backend', '')]","[{'comment_id': 1942256836, 'issue_id': 2132268022, 'author': 'camsaul', 'body': 'How is this different from #37367?', 'created_at': datetime.datetime(2024, 2, 13, 19, 35, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942261893, 'issue_id': 2132268022, 'author': 'camsaul', 'body': 'Actually in #38074 I find it extremely worrisome that there were no MLv2 changes at all... I hope nothing broke as a result', 'created_at': datetime.datetime(2024, 2, 13, 19, 36, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942285119, 'issue_id': 2132268022, 'author': 'camsaul', 'body': 'Closing as duplicate of #37367', 'created_at': datetime.datetime(2024, 2, 13, 19, 44, 37, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-02-13 19:35:11 UTC): How is this different from #37367?

camsaul on (2024-02-13 19:36:53 UTC): Actually in #38074 I find it extremely worrisome that there were no MLv2 changes at all... I hope nothing broke as a result

camsaul on (2024-02-13 19:44:37 UTC): Closing as duplicate of #37367

"
2132230439,issue,closed,completed,FE - Migrate dataset flag to card.type,,ranquild,2024-02-13 12:35:31+00:00,['kamilmielnik'],2024-02-16 10:51:56+00:00,2024-02-16 10:51:55+00:00,https://github.com/metabase/metabase/issues/38706,"[('Administration/Metrics & Segments', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1948167965, 'issue_id': 2132230439, 'author': 'kamilmielnik', 'body': 'Closed by #38714', 'created_at': datetime.datetime(2024, 2, 16, 10, 51, 55, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Assginee) on (2024-02-16 10:51:55 UTC): Closed by #38714

"
2132073165,issue,closed,completed,Unable to filter by some searchable fields,"### Describe the bug

https://metaboat.slack.com/archives/C05MPF0TM3L/p1707822061007859

### To Reproduce

https://metaboat.slack.com/archives/C05MPF0TM3L/p1707822061007859

### Expected behavior

The search endpoint should return an empty array instead of 204 no content

### Logs

_No response_

### Information about your Metabase installation

```JSON
-
```


### Severity

P1

### Additional context

_No response_",ranquild,2024-02-13 11:06:12+00:00,[],2024-02-14 12:07:55+00:00,2024-02-14 12:07:54+00:00,https://github.com/metabase/metabase/issues/38702,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1943643876, 'issue_id': 2132073165, 'author': 'calherries', 'body': 'Dupe of https://github.com/metabase/metabase/issues/37492', 'created_at': datetime.datetime(2024, 2, 14, 12, 7, 55, tzinfo=datetime.timezone.utc)}]","calherries on (2024-02-14 12:07:55 UTC): Dupe of https://github.com/metabase/metabase/issues/37492

"
2131887357,issue,open,,Database privileges checks for SQL databases does not support wildcards,"When parsing the privilege grants for a SQL database, Metabase will treat wildcards as literal characters, and therefore fail to match the corresponding schemas and/or tables.

This issue was most noticeable in version `0.48.4`, where table sync was made dependent on table privileges. 

You can reproduce the issue as follows:

1. Have a MySQL database with multiple active tables synced
2. Configure table privileges to use a wildcard, e.g. ``GRANT SELECT ON `%`.* TO user``
3. Start Metabase 0.48.4
4. Notice that all of the tables have been deactivated

This is not a hot issue as in https://github.com/metabase/metabase/pull/38552 we disabled the use of privileges for MySQL, which switches sync back to the slow path, but this is a blocker for at least one customer to us switching back to the fast path.

~~It is possible that this bug may cause issues for customers using other SQL databases, and we might want to consider potential scope and apply further mitigations for now, or escalate this.~~ The other databases don't actually use the grants parser, so they are unaffected.",crisptrutski,2024-02-13 09:39:29+00:00,[],2025-02-04 20:24:34+00:00,,https://github.com/metabase/metabase/issues/38701,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2131845864,issue,closed,not_planned,Centering pin map around issues not working,"### Describe the bug

We have several maps on an embedded page where we display pins. It seems that the first map will always be centered and zoomed appropriately around the pins. The next maps underneath will not do that, they will focus on an area where there aren't any pins and will not change zoom levels. Note that I didn't draw a filter box or pinned the map on a specific location.

This is an example of a map I am seeing. Note that you do not see any pins on the map:
<img width=""1083"" alt=""Screenshot 2024-02-13 at 09 06 55"" src=""https://github.com/metabase/metabase/assets/875642/92f0b3f8-0cd8-44e5-b058-5957c88d02f7"">

If I zoom out and scroll to the correct spot, I get to see this:

<img width=""1091"" alt=""Screenshot 2024-02-13 at 09 07 07"" src=""https://github.com/metabase/metabase/assets/875642/b0086a2d-019e-4829-88a2-e8ead8e605cb"">


Note that I changed the filters and that you need to scroll to see the second map. I don't know if that could explain why it doesn't focus the map (because it was not loaded yet, something in the javascript).

### To Reproduce

1. Create a dashboard with several maps
2. Look at the second map, change your filters, see a static view

### Expected behavior

The maps should focus all pins within its bounds and zoom to the correct level

### Logs

DEPRECATED: metabase/redux/metadata addParamValues
g @ metadata.js:18
metadata.js:18 DEPRECATED: metabase/redux/metadata addFields
g @ metadata.js:18
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696
Dimension.ts:696 Unknown MBQL Field clause null
parseMBQLOrWarn @ Dimension.ts:696



### Information about your Metabase installation

```JSON
- latest chrome

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.198-187.748.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-05"",
      ""tag"": ""v1.48.2"",
      ""hash"": ""e66c075""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying / giving wrong information to users

### Additional context

_No response_",vinceve,2024-02-13 09:16:16+00:00,[],2024-08-06 21:03:04+00:00,2024-08-06 21:03:04+00:00,https://github.com/metabase/metabase/issues/38700,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2200690829, 'issue_id': 2131845864, 'author': 'JesseSDevaney', 'body': 'Hey @vinceve!\r\n\r\nI tried working on this issue, but I could not reproduce it locally.\r\n\r\nI tested adding different pin maps to a dashboard, setting it up so some of the maps have to be scrolled down to, embedding the dashboard, and altering the location filter multiple times. \r\n\r\nIn the end, I could not get a single map to display with broken centering and zoom levels.\r\n\r\n---\r\nWould you be able to provide some more information about your reproduction specifically in order to help diagnose and fix this issue?\r\n1. Is it still occurring for you?\r\n2. Is it occurring on the in-app dashboard as well? Or, is this only occurring on the embedded version of the dashboard?\r\n   - Along the same lines, can you reproduce this in the question view/query builder itself? Or is this only a dashboard related thing?\r\n3. What are the exact steps you are taking that cause this issue to occur?', 'created_at': datetime.datetime(2024, 7, 1, 17, 37, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2272147992, 'issue_id': 2131845864, 'author': 'cdeweyx', 'body': ""I'm unable to reproduce this as well. Closing this, at least until we have more information on this issue."", 'created_at': datetime.datetime(2024, 8, 6, 21, 3, 4, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-07-01 17:37:02 UTC): Hey @vinceve!

I tried working on this issue, but I could not reproduce it locally.

I tested adding different pin maps to a dashboard, setting it up so some of the maps have to be scrolled down to, embedding the dashboard, and altering the location filter multiple times. 

In the end, I could not get a single map to display with broken centering and zoom levels.

---
Would you be able to provide some more information about your reproduction specifically in order to help diagnose and fix this issue?
1. Is it still occurring for you?
2. Is it occurring on the in-app dashboard as well? Or, is this only occurring on the embedded version of the dashboard?
   - Along the same lines, can you reproduce this in the question view/query builder itself? Or is this only a dashboard related thing?
3. What are the exact steps you are taking that cause this issue to occur?

cdeweyx on (2024-08-06 21:03:04 UTC): I'm unable to reproduce this as well. Closing this, at least until we have more information on this issue.

"
2131839690,issue,closed,completed,[Epic] Appearance settings page polish,"Target release: 0.50

**Links**
- [Product doc](https://www.notion.so/metabase/Appearance-Settings-page-polish-f9b02b47a0ae427ba8be810dfa924e0d)
- [Tech doc](https://www.notion.so/metabase/Tech-Appearance-Settings-page-polish-8ad4a201747d4e0e880bc090ba1b19a5)

```[tasklist]
# Milestone 1
- [ ] https://github.com/metabase/metabase/pull/38713#top
- [ ] https://github.com/metabase/metabase/pull/38850
```


",WiNloSt,2024-02-13 09:12:32+00:00,['WiNloSt'],2024-02-21 02:59:52+00:00,2024-02-21 02:59:52+00:00,https://github.com/metabase/metabase/issues/38699,"[('.Epic', 'Feature Implementation or Project')]",[],
2131808896,issue,closed,completed,Add hover card on column picker,"As part of #38394 we want to surface relevant metadata in places where it makes sense.

Adding the metadata hovercard on the column picker is a good first step.

<img width=""630"" alt=""Screenshot 2024-02-13 at 09 56 19"" src=""https://github.com/metabase/metabase/assets/1250185/f560aaec-8678-4162-8ced-1e0d4f21e677"">
",romeovs,2024-02-13 08:53:50+00:00,['romeovs'],2024-02-16 14:46:23+00:00,2024-02-16 14:46:14+00:00,https://github.com/metabase/metabase/issues/38698,"[('.Frontend', ''), ('no-backport', 'Do not backport this PR to any branch'), ('.Team/Querying', '')]",[],
2131273501,issue,closed,completed,"After updating to 0.48.5 all of my questions encounter this error: ""The connection string contains invalid user information. If the username or password contains a colon (:) or an at-sign (@) then it must be urlencoded""","### Describe the bug

After updating to 0.48.5

All of my questions are encountering an error related to connstring encoding issues.

Here is a sample password that my connection contains:

sample: p@ssw0rd123

after researching

the fixed password: p%40ssw0rd123

On the recent metabase versions i think this is being handled automatically by Metabase's system.

### To Reproduce

1. Copy paste the username/password on your DB connections that has ""@"" or "":""
2. Check if you could see the data inside that DB

### Expected behavior

I think the special characters would be handled automatically by Metabase as this was the behavior before 0.48.5

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-post-Ubuntu-0ubuntu122.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-post-Ubuntu-0ubuntu122.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-1019-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v0.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

It is annoying because if I have multiple DB setup I need to update each one of them with the proper encoding for special characters

### Additional context

![image](https://github.com/metabase/metabase/assets/89201548/ee20e98c-40d5-43bd-ae25-0c23ddc26d98)
",jrca025,2024-02-13 01:03:08+00:00,['lbrdnk'],2024-08-28 02:12:18+00:00,2024-03-04 15:08:14+00:00,https://github.com/metabase/metabase/issues/38697,"[('Type:Bug', 'Product defects'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1953012615, 'issue_id': 2131273501, 'author': 'luizarakaki', 'body': 'Does this question source your Mongo or MySQL database?', 'created_at': datetime.datetime(2024, 2, 19, 18, 44, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 1953066914, 'issue_id': 2131273501, 'author': 'paoliniluis', 'body': ""probably an effect of https://github.com/metabase/metabase/pull/38017 @lbrdnk ? haven't had the time to repro"", 'created_at': datetime.datetime(2024, 2, 19, 19, 37, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 1953385283, 'issue_id': 2131273501, 'author': 'jrca025', 'body': '> Does this question source your Mongo or MySQL database?\r\n\r\nThis is for MongoDB', 'created_at': datetime.datetime(2024, 2, 20, 2, 25, 2, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-02-19 18:44:59 UTC): Does this question source your Mongo or MySQL database?

paoliniluis on (2024-02-19 19:37:44 UTC): probably an effect of https://github.com/metabase/metabase/pull/38017 @lbrdnk ? haven't had the time to repro

jrca025 (Issue Creator) on (2024-02-20 02:25:02 UTC): This is for MongoDB

"
2131158222,issue,closed,completed,Table/field descriptions are not sync'ed when updated in database,"### Describe the bug

When using [this feature](https://github.com/metabase/metabase/issues/3089) to sync table/field descriptions to Metabase from the database, it works on initial set or when descriptions are not set yet. Once descriptions are set, any description changes in the database table/field will no longer reflect in Metabase. 

### To Reproduce

1. Create new table/field with descriptions
2. Let Metabase scan it and see descriptions for table/fields
3. Update description for table or fields in database
4. Force Metabase to re-scan schema and see that no descriptions are updated. 


### Expected behavior

If description is updated in the db table/field, they should reflect in Metabase

### Logs

n/a

### Information about your Metabase installation

```JSON
master on Postgres
```


### Severity

Outdated metadata / can't use db as source of truth for field descriptions

### Additional context

_No response_",maxzheng,2024-02-12 23:17:37+00:00,[],2024-12-24 11:38:39+00:00,2024-03-12 09:12:04+00:00,https://github.com/metabase/metabase/issues/38694,"[('Type:Bug', 'Product defects'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1991113340, 'issue_id': 2131158222, 'author': 'calherries', 'body': ""Dupe of [A table with an existing SQL description does not get updated when it is sync'ed](https://github.com/metabase/metabase/issues/12493) and [Sync: distinguish between metadata coming from the db & user set](https://github.com/metabase/metabase/issues/12574)."", 'created_at': datetime.datetime(2024, 3, 12, 9, 12, 4, tzinfo=datetime.timezone.utc)}]","calherries on (2024-03-12 09:12:04 UTC): Dupe of [A table with an existing SQL description does not get updated when it is sync'ed](https://github.com/metabase/metabase/issues/12493) and [Sync: distinguish between metadata coming from the db & user set](https://github.com/metabase/metabase/issues/12574).

"
2131073807,issue,open,,Getting Action Field Values From Filter Widget Fails With Multiple Selections,"### Describe the bug

I attempted to create an action like this:
```
UPDATE __proc._user_uploadschedule_turnover_long_20240209220007
SET _mb_row_id = _mb_row_id
    [[, comp_expect = {{expected_completion}}]]
    [[, started = TRUE, start_actual = {{started}}]]
    [[, completed = TRUE, comp_actual = {{completed}}]]
WHERE space IN ({{spaces}}) AND task IN ({{tasks}});
```
Assuming that the filter widget would supply a csv format string of all selections. This is not the case though.  
This doesn't update anything though. I think it's providing the filter in some other format, meaning I make no match and nothing gets updated.

Here are database logs:
```
STATEMENT: UPDATE __proc._user_uploadschedule_turnover_long_20240209220007
SET _mb_row_id = _mb_row_id
, comp_expected = $1
, started = TRUE, start_actual = $2
, completed = TRUE, comp_actual = $3
WHERE space IN ($4) AND task IN ($5)
```

I attempted removing the parentheses in the WHERE clause, though the action then fails on the metabase side with 
`Error executing Action: Error executing write query: ERROR: syntax error at or near ""$1"" Position: 123`.

### To Reproduce

1. Create an action and add it to a dashboard
2. Have some fields attached to filters, not given by user.
3. Select multiple options in the filter widget
4. Attempt to use the action
5. Observe results

### Expected behavior

Expected behavior was that the filter widgets values would be provided in csv format so that I could use them i nthe action.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.55-75.123.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Low/Medium.

### Additional context

_No response_",MrChadMWood,2024-02-12 22:10:48+00:00,[],2025-02-06 10:46:37+00:00,,https://github.com/metabase/metabase/issues/38693,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Actions', ''), ('.Team/Workflows', 'aka BEC')]",[],
2130961811,issue,closed,not_planned,Quick Button to open code editor,"**Is your feature request related to a problem? Please describe.**


**Describe the solution you'd like**
The same way you have a shortcut to hide the sidebar, the same thing to open the code editor

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Unbelievably important ; speediness in code is amazing

**Additional context**
This would be a massive help ty",OdinTallBeard,2024-02-12 20:51:15+00:00,[],2024-05-29 12:48:28+00:00,2024-05-29 12:48:28+00:00,https://github.com/metabase/metabase/issues/38687,"[('Type:UX', ''), ('Organization/', '')]","[{'comment_id': 2137062437, 'issue_id': 2130961811, 'author': 'OdinTallBeard', 'body': 'Hi there may I please get an update on this?', 'created_at': datetime.datetime(2024, 5, 29, 10, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2137334469, 'issue_id': 2130961811, 'author': 'paoliniluis', 'body': 'please check the newest release that we have a command palette', 'created_at': datetime.datetime(2024, 5, 29, 12, 48, 28, tzinfo=datetime.timezone.utc)}]","OdinTallBeard (Issue Creator) on (2024-05-29 10:18:09 UTC): Hi there may I please get an update on this?

paoliniluis on (2024-05-29 12:48:28 UTC): please check the newest release that we have a command palette

"
2130849017,issue,closed,completed,[Epic] Improve API Data Fetching,"[Frontend RFC](https://www.notion.so/metabase/85-Use-a-Real-data-fetching-caching-library-afb42a65e79f449982414639668e2b06#2a6aa6c77c8f4f6995ee70907b9b88ea)


```[tasklist]
### Research / PoC Phase
- [x] Research major data fetching libraries
- [x] Prototype 1 or more libraries using for api requests for entities and non-entities
- [ ] https://github.com/metabase/metabase/issues/39481
- [ ] https://github.com/metabase/metabase/issues/39482
- [x] Present proposal to frontend guild (march 13)
```
### Proposal

[We should use RTK Query](https://www.notion.so/metabase/Picking-a-real-data-fetching-library-d38077b06b9d4b09ba15db09ad608be0)

### Goals

- have a consistent, easy-to-use, hook-based way to make cached (or non-cached) API queries
- use a library that is well maintained and documented
- find something that will eventually play nicely with our entity store



### Possible Libraries

- [SWR](https://swr.vercel.app/)
- [Tanstack Query](https://tanstack.com/query/latest)
- [RTK Query](https://redux-toolkit.js.org/rtk-query/overview)



```[tasklist]
### Implementation Phase
- [ ] https://github.com/metabase/metabase/pull/39092
- [ ] https://github.com/metabase/metabase/pull/40043
- [ ] https://github.com/metabase/metabase/pull/39179
- [ ] https://github.com/metabase/metabase/pull/39273
- [ ] https://github.com/metabase/metabase/pull/39270
- [ ] https://github.com/metabase/metabase/pull/39266
```
",iethree,2024-02-12 19:39:47+00:00,"['sloansparger', 'iethree']",2024-04-08 10:47:03+00:00,2024-04-08 10:47:02+00:00,https://github.com/metabase/metabase/issues/38686,"[('Misc/API', ''), ('.Frontend', ''), ('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2042430243, 'issue_id': 2130849017, 'author': 'iethree', 'body': 'closing in favor of the migration epic: https://github.com/metabase/metabase/issues/40788', 'created_at': datetime.datetime(2024, 4, 8, 10, 47, 2, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-04-08 10:47:02 UTC): closing in favor of the migration epic: https://github.com/metabase/metabase/issues/40788

"
2130823540,issue,open,,Order pivot tables by a field which is not visible,"**Is your feature request related to a problem? Please describe.**
The ordering in the pivot table is limited, we can see that in https://github.com/metabase/metabase/issues/16505 and https://github.com/metabase/metabase/issues/22872. A user asked to sort the pivot table results with fields that are not in the actual table, something similar to a custom sorting

**Describe the solution you'd like**
Custom sort the pivot table, either manually or with fields that are not in the actual query

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a user

**Additional context**
NA
",paoliniluis,2024-02-12 19:27:57+00:00,[],2024-06-04 11:54:51+00:00,,https://github.com/metabase/metabase/issues/38685,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]","[{'comment_id': 2147344985, 'issue_id': 2130823540, 'author': 'fabiolanza', 'body': ""Hi, this is also important for us. Custom sorting is needed for cases where columns do not follow alphabetical order but a natural order instead. Examples are columns for tickets with criticality (Critical High Medium Low). It's natural to see them in this order, but alphabetically you get Critical High Low Medium (which is not natural, and it is misleading). I hope that this gets prioritized and released soon."", 'created_at': datetime.datetime(2024, 6, 4, 11, 54, 50, tzinfo=datetime.timezone.utc)}]","fabiolanza on (2024-06-04 11:54:50 UTC): Hi, this is also important for us. Custom sorting is needed for cases where columns do not follow alphabetical order but a natural order instead. Examples are columns for tickets with criticality (Critical High Medium Low). It's natural to see them in this order, but alphabetically you get Critical High Low Medium (which is not natural, and it is misleading). I hope that this gets prioritized and released soon.

"
2130773107,issue,closed,completed,Trend Chart font is incorrect in certain email clients,"### Describe the bug

in gmail on iOS, the trend chart card renders with an incorrect font, at least some of the time. It's especially noticeable because it is a Serif font, when the expected font is Lato (a Sans-serif font), or a more similar fallback (should be whatever Sans-serif font).

For some context, there is a Slack thread [here](https://metaboat.slack.com/archives/C064QMXEV9N/p1705688410924559) (Metabase internal Slack).



### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

This should ideally render with the correct Lato font, but at least use a Sans-serif fallback.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- gmail + iOS email client
- 49-RC1?
```


### Severity

P2

### Additional context

_No response_",adam-james-v,2024-02-12 19:04:40+00:00,['adam-james-v'],2024-02-13 23:50:08+00:00,2024-02-13 22:55:24+00:00,https://github.com/metabase/metabase/issues/38684,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2130669051,issue,closed,completed,[dc.js migration] areas stacking is broken in any data that includes nulls on any axis type,"All stacked area charts that contain null y-values are broken. We encountered this issue multiple times during our bug bash, here is an example question: https://stats.metabase.com/question/4678-earned-impressions-by-channel ([screenshot attached](https://metaboat.slack.com/archives/C05NQSWPRMK/p1707493380950789)).

After we patched echarts, we need to handle the case when for a given X-axis value 1+ series have non-null values while others with linear interpolation enabled have nulls.

### Examples

question/14309
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194251461129

question/14607
https://metaboat.slack.com/archives/C06G94JTWBS/p1706193732427339

question/13718
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194079748279

question/3835
https://metaboat.slack.com/archives/C06G94JTWBS/p1706194544443529",alxnddr,2024-02-12 18:00:42+00:00,['alxnddr'],2024-03-13 02:16:50+00:00,2024-03-13 02:16:50+00:00,https://github.com/metabase/metabase/issues/38682,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2130598828,issue,open,,"[Epic] Add CSV uploads to Snowflake, BigQuery and SQL Server","### Context
[Product doc](https://www.notion.so/metabase/Add-CSV-uploads-to-SQL-Server-Snowflake-and-BigQuery-cb8ddfd2a27243c988ad1534664e5e24)

```[tasklist]
### Tasks
- [ ] BigQuery
- [ ] SQL Server
- [ ] Snowflake
```
Closes:
https://github.com/metabase/metabase/issues/35978
https://github.com/metabase/metabase/issues/35069
https://github.com/metabase/metabase/issues/35029",luizarakaki,2024-02-12 17:19:06+00:00,[],2025-02-04 20:27:29+00:00,,https://github.com/metabase/metabase/issues/38681,"[('Database/BigQuery', ''), ('Database/Snowflake', ''), ('.Epic', 'Feature Implementation or Project'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2130593855,issue,closed,completed,[Epic] Preemptive caching,[Product doc](https://www.notion.so/metabase/Preemptive-caching-for-questions-and-dashboards-1809888131014c1cb8d343ef86b23174?pvs=4),luizarakaki,2024-02-12 17:16:20+00:00,['noahmoss'],2025-01-15 19:24:22+00:00,2025-01-15 19:23:59+00:00,https://github.com/metabase/metabase/issues/38680,"[('.Epic', 'Feature Implementation or Project'), ('Querying/Cache', ''), ('.Team/Workflows', 'aka BEC'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2130553557,issue,closed,completed,BE - Metric as data source,Query execution changes described here https://www.notion.so/metabase/Metric-v2-query-changes-25385f9fed3e4f22aa7f919786c260a7,ranquild,2024-02-12 16:54:09+00:00,['metamben'],2025-01-06 14:51:55+00:00,2025-01-06 14:51:55+00:00,https://github.com/metabase/metabase/issues/38679,"[('Querying/Processor', ''), ('Administration/Metrics & Segments', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1942327093, 'issue_id': 2130553557, 'author': 'camsaul', 'body': 'I think the only thing we need to do here is have the aggregation and filter(s) (if any) from the Metric(s) get spliced into the ""consumer query"". This includes both `:source-card`, if that Card is a Metric, and joins, if their `:source-card` is a Metric. See https://metaboat.slack.com/archives/C051AG38B2S/p1707851632858039 for more discussion', 'created_at': datetime.datetime(2024, 2, 13, 19, 58, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942355293, 'issue_id': 2130553557, 'author': 'camsaul', 'body': 'We might also need to be generating `count(metric_1.*)` instead of `count(*)` -- see https://metaboat.slack.com/archives/C051AG38B2S/p1707854775072789?thread_ts=1707851632.858039&cid=C051AG38B2S -- probably need to extend the QP to support that', 'created_at': datetime.datetime(2024, 2, 13, 20, 8, 31, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-02-13 19:58:57 UTC): I think the only thing we need to do here is have the aggregation and filter(s) (if any) from the Metric(s) get spliced into the ""consumer query"". This includes both `:source-card`, if that Card is a Metric, and joins, if their `:source-card` is a Metric. See https://metaboat.slack.com/archives/C051AG38B2S/p1707851632858039 for more discussion

camsaul on (2024-02-13 20:08:31 UTC): We might also need to be generating `count(metric_1.*)` instead of `count(*)` -- see https://metaboat.slack.com/archives/C051AG38B2S/p1707854775072789?thread_ts=1707851632.858039&cid=C051AG38B2S -- probably need to extend the QP to support that

"
2130386059,issue,closed,completed,seeing scrollbars in search and admin,"We are seeing scrollbars in search and also in admin sections.

![image](https://github.com/metabase/metabase/assets/6377293/3563ebea-b89d-41a6-ae1c-39243b2a08fa)

Trying searching for a longer search term on stats.

I'm not able to reproduce in Firefox, but reports of safari and Chromium based browsers.

##### To Reproduce

search on stats for a longer search term

> I just noticed in admin settings on master After saving any settings the Saved notification will push the settings content down and create another scroll bar. Is this a recent regression?",dpsutton,2024-02-12 15:34:13+00:00,['sloansparger'],2024-02-17 00:22:36+00:00,2024-02-17 00:22:35+00:00,https://github.com/metabase/metabase/issues/38673,"[('Type:Bug', 'Product defects'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2130357144,issue,closed,completed,Update notebook data source picker dropdown to align more with other popovers,"The current data source field picker design is a bit out of place compared to other field and data pickers. We should update it to bring it in line with other popovers.
This will allow us to add more data to it later.

##### Current design
<img width=""229"" alt=""Screenshot 2024-02-12 at 16 22 11"" src=""https://github.com/metabase/metabase/assets/1250185/0eeb6a3b-d453-40c5-8ce0-ade6424ca05f"">

#### Proposed design


<img width=""306"" alt=""Screenshot 2024-02-12 at 16 46 10"" src=""https://github.com/metabase/metabase/assets/1250185/b4608572-d4fd-47f8-97f5-ef028b228ff9"">

",romeovs,2024-02-12 15:20:06+00:00,['romeovs'],2024-02-16 12:16:56+00:00,2024-02-13 08:40:48+00:00,https://github.com/metabase/metabase/issues/38670,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2130234234,issue,closed,completed,Cannot import dashboards with circular click behavior,"### Describe the bug

It is impossible to import dashboards with a circular click behavior, for example, when a dashboard links to itself, or when click behavior dashboard A has a link pointing to dashboard B which has a link pointing to dashboard A.

### To Reproduce

1. Create a DashboardA, add a QuestionA
2. Create DashboardB, add a QuestionB
3. Set up a circular click route between the dashboards:
   * DashboardA/QuestionA --> DashboardB
   * DashboardB/QuestionB --> DashboardA
4. Export everything
5. (!) Import and see the circular reference error below


### Expected behavior

The import should work, load all resources, and restore all exported links.

### Logs

clojure.lang.ExceptionInfo: Circular dependency on [{:model ""Dashboard"", :id ""GUnezeAXjrWMd8k4x8PXx""}] {:path [{:model ""Dashboard"", :id ""GUnezeAXjrWMd8k4x8PXx""}]}

### Information about your Metabase installation

```JSON
Reported in v47, also broken as of 1.48.5.
```


### Severity

Reported by a customer. No workaround, apart from removing some of the links..

### Additional context

_No response_",zbodi74,2024-02-12 14:16:42+00:00,['piranha'],2024-12-24 11:38:46+00:00,2024-05-10 13:49:04+00:00,https://github.com/metabase/metabase/issues/38665,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1938897397, 'issue_id': 2130234234, 'author': 'bshepherdson', 'body': ""Ah, someone found it! I wondered if there was a cycle opportunity anywhere in our data model, and here's one after all."", 'created_at': datetime.datetime(2024, 2, 12, 15, 28, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2035188916, 'issue_id': 2130234234, 'author': 'michael-stott', 'body': ""Good spot. I just came looking for this. It looks like I just hit the same thing using 1.49.3. Or should I say it looks very much the same. Our 'Home' dashboard has links to various other dashboards and then each of those have a link back to the 'Home'."", 'created_at': datetime.datetime(2024, 4, 3, 17, 31, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2060774594, 'issue_id': 2130234234, 'author': 'andreasenberg', 'body': ""I'm experiencing something that looks a lot like this on 1.49.5 when using link cards to handle navigation back and forth between dashboards. I'm not sure if they are represented in a similar way as a linked question in the exported yaml files so that a fix for the issue described here potentially also would resolve the issue I'm facing? \r\n\r\nRegardless, it would be great if the link card issue could be included as a scenario to adress/test together with changes intended to fix this. Let me know if you rather have these issues separated into two github issues and I'll create one for my scenario."", 'created_at': datetime.datetime(2024, 4, 17, 9, 9, 6, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-02-12 15:28:46 UTC): Ah, someone found it! I wondered if there was a cycle opportunity anywhere in our data model, and here's one after all.

michael-stott on (2024-04-03 17:31:53 UTC): Good spot. I just came looking for this. It looks like I just hit the same thing using 1.49.3. Or should I say it looks very much the same. Our 'Home' dashboard has links to various other dashboards and then each of those have a link back to the 'Home'.

andreasenberg on (2024-04-17 09:09:06 UTC): I'm experiencing something that looks a lot like this on 1.49.5 when using link cards to handle navigation back and forth between dashboards. I'm not sure if they are represented in a similar way as a linked question in the exported yaml files so that a fix for the issue described here potentially also would resolve the issue I'm facing? 

Regardless, it would be great if the link card issue could be included as a scenario to adress/test together with changes intended to fix this. Let me know if you rather have these issues separated into two github issues and I'll create one for my scenario.

"
2130191341,issue,open,,Improvement: Dashboard Sub-tabs,"In one of the latest releases from Metabase, dashboard tabs were added, which is very useful to organize information / insights.

It would be useful if tabs could be split up further into sub-tabs.

This is handy for the situation where a dashboard has a lot of different information that needs to be organized, and exceeds the amount that can be neatly organized into just the regular tabs.

Some examples where sub-tabs could come in handy:

- Sales
   - Europe
   - US
   - Overall

- Transactions
   - YTD
   - MTD
   - Overall

End-users are complaining about the lack of this functionality. The only other option is to split up into multiple dashboards, which isn't very user friendly (navigation wise).

Another option could be to give the admin the ability to add ""default"" bookmarks for user(s) / groups. With this you could for example make  a list of multiple dashboards, which then split up into tabs.",franckvandersluis,2024-02-12 13:54:42+00:00,[],2024-02-12 14:23:01+00:00,,https://github.com/metabase/metabase/issues/38663,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2130024704,issue,closed,not_planned,Unable to export xslx in v0.48.4,"### Describe the bug

When I try to create an export in Excel, I cannot open the file. If I open it with an editor, I can find the following json there:

`{
  ""via"": [
    {
      ""type"": ""java.lang.RuntimeException"",
      ""message"": ""java.nio.file.NoSuchFileException: /tmp/poifiles/poi-sxssf-sheet14675123732466397386.xml"",
      ""at"": [
        ""org.apache.poi.xssf.streaming.SXSSFWorkbook"",
        ""createAndRegisterSXSSFSheet"",
        ""SXSSFWorkbook.java"",
        728
      ]
    },
    {
      ""type"": ""java.nio.file.NoSuchFileException"",
      ""message"": ""/tmp/poifiles/poi-sxssf-sheet14675123732466397386.xml"",
      ""at"": [
        ""sun.nio.fs.UnixException"",
        ""translateToIOException"",
        ""UnixException.java"",
        92
      ]
    }
  ],
  ""trace"": [
    [
      ""sun.nio.fs.UnixException"",
      ""translateToIOException"",
      ""UnixException.java"",
      92
    ],
    [
      ""sun.nio.fs.UnixException"",
      ""rethrowAsIOException"",
      ""UnixException.java"",
      111
    ],
    [
      ""sun.nio.fs.UnixException"",
      ""rethrowAsIOException"",
      ""UnixException.java"",
      116
    ],
    [
      ""sun.nio.fs.UnixFileSystemProvider"",
      ""newByteChannel"",
      ""UnixFileSystemProvider.java"",
      219
    ],
    [
      ""java.nio.file.Files"",
      ""newByteChannel"",
      ""Files.java"",
      371
    ],
    [
      ""java.nio.file.Files"",
      ""createFile"",
      ""Files.java"",
      648
    ],
    [
      ""java.nio.file.TempFileHelper"",
      ""create"",
      ""TempFileHelper.java"",
      137
    ],
    [
      ""java.nio.file.TempFileHelper"",
      ""createTempFile"",
      ""TempFileHelper.java"",
      160
    ],
    [
      ""java.nio.file.Files"",
      ""createTempFile"",
      ""Files.java"",
      868
    ],
    [
      ""org.apache.poi.util.DefaultTempFileCreationStrategy"",
      ""createTempFile"",
      ""DefaultTempFileCreationStrategy.java"",
      102
    ],
    [
      ""org.apache.poi.util.TempFile"",
      ""createTempFile"",
      ""TempFile.java"",
      67
    ],
    [
      ""org.apache.poi.xssf.streaming.SheetDataWriter"",
      ""createTempFile"",
      ""SheetDataWriter.java"",
      99
    ],
    [
      ""org.apache.poi.xssf.streaming.SheetDataWriter"",
      ""<init>"",
      ""SheetDataWriter.java"",
      73
    ],
    [
      ""org.apache.poi.xssf.streaming.SheetDataWriter"",
      ""<init>"",
      ""SheetDataWriter.java"",
      83
    ],
    [
      ""org.apache.poi.xssf.streaming.SXSSFWorkbook"",
      ""createSheetDataWriter"",
      ""SXSSFWorkbook.java"",
      384
    ],
    [
      ""org.apache.poi.xssf.streaming.SXSSFSheet"",
      ""<init>"",
      ""SXSSFSheet.java"",
      92
    ],
    [
      ""org.apache.poi.xssf.streaming.SXSSFWorkbook"",
      ""createAndRegisterSXSSFSheet"",
      ""SXSSFWorkbook.java"",
      726
    ],
    [
      ""org.apache.poi.xssf.streaming.SXSSFWorkbook"",
      ""createSheet"",
      ""SXSSFWorkbook.java"",
      745
    ],
    [
      ""org.apache.poi.xssf.streaming.SXSSFWorkbook"",
      ""createSheet"",
      ""SXSSFWorkbook.java"",
      102
    ],
    [
      ""dk.ative.docjure.spreadsheet$add_sheet_BANG_"",
      ""invokeStatic"",
      ""spreadsheet.clj"",
      351
    ],
    [
      ""dk.ative.docjure.spreadsheet$add_sheet_BANG_"",
      ""invoke"",
      ""spreadsheet.clj"",
      347
    ],
    [
      ""metabase.query_processor.streaming.xlsx$fn__51565"",
      ""invokeStatic"",
      ""xlsx.clj"",
      504
    ],
    [
      ""metabase.query_processor.streaming.xlsx$fn__51565"",
      ""invoke"",
      ""xlsx.clj"",
      501
    ],
    [
      ""clojure.lang.MultiFn"",
      ""invoke"",
      ""MultiFn.java"",
      234
    ],
    [
      ""metabase.query_processor.streaming$streaming_context_and_rff"",
      ""invokeStatic"",
      ""streaming.clj"",
      146
    ],
    [
      ""metabase.query_processor.streaming$streaming_context_and_rff"",
      ""invoke"",
      ""streaming.clj"",
      138
    ],
    [
      ""metabase.query_processor.streaming$streaming_context_and_rff"",
      ""invokeStatic"",
      ""streaming.clj"",
      152
    ],
    [
      ""metabase.query_processor.streaming$streaming_context_and_rff"",
      ""invoke"",
      ""streaming.clj"",
      138
    ],
    [
      ""metabase.query_processor.streaming$streaming_response_STAR_$fn__51715"",
      ""invoke"",
      ""streaming.clj"",
      166
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      156
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      667
    ],
    [
      ""clojure.core$with_bindings_STAR_"",
      ""invokeStatic"",
      ""core.clj"",
      1990
    ],
    [
      ""clojure.core$with_bindings_STAR_"",
      ""doInvoke"",
      ""core.clj"",
      1990
    ],
    [
      ""clojure.lang.RestFn"",
      ""applyTo"",
      ""RestFn.java"",
      142
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      671
    ],
    [
      ""clojure.core$bound_fn_STAR_$fn__5818"",
      ""doInvoke"",
      ""core.clj"",
      2020
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      421
    ],
    [
      ""metabase.async.streaming_response$do_f_STAR_"",
      ""invokeStatic"",
      ""streaming_response.clj"",
      69
    ],
    [
      ""metabase.async.streaming_response$do_f_STAR_"",
      ""invoke"",
      ""streaming_response.clj"",
      67
    ],
    [
      ""metabase.async.streaming_response$do_f_async$task__43047"",
      ""invoke"",
      ""streaming_response.clj"",
      88
    ],
    [
      ""clojure.lang.AFn"",
      ""run"",
      ""AFn.java"",
      22
    ],
    [
      ""java.util.concurrent.Executors$RunnableAdapter"",
      ""call"",
      ""Executors.java"",
      515
    ],
    [
      ""java.util.concurrent.FutureTask"",
      ""run"",
      ""FutureTask.java"",
      264
    ],
    [
      ""java.util.concurrent.ThreadPoolExecutor"",
      ""runWorker"",
      ""ThreadPoolExecutor.java"",
      1128
    ],
    [
      ""java.util.concurrent.ThreadPoolExecutor$Worker"",
      ""run"",
      ""ThreadPoolExecutor.java"",
      628
    ],
    [
      ""java.lang.Thread"",
      ""run"",
      ""Thread.java"",
      829
    ]
  ],
  ""cause"": ""/tmp/poifiles/poi-sxssf-sheet14675123732466397386.xml"",
  ""_status"": 500
}`

Java Version:
`Linux dedi2076.your-server.de 5.10.0-27-amd64 #1 SMP Debian 5.10.205-2 (2023-12-31) x86_64
Last login: Thu Feb  8 10:05:19 2024 from 217.91.49.98`

### To Reproduce

1. Go to any table
2. Click on Download to Excel
3. Open the file with any editor
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""de-DE"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Debian-1deb11u1"",
    ""java.vendor"": ""Debian"",
    ""java.vendor.url"": ""https://tracker.debian.org/openjdk-11"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Debian-1deb11u1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-27-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Berlin""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```


### Severity

block

### Additional context

_No response_",OleeOlsen,2024-02-12 12:20:50+00:00,[],2024-02-12 12:25:56+00:00,2024-02-12 12:25:55+00:00,https://github.com/metabase/metabase/issues/38657,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1938584222, 'issue_id': 2130024704, 'author': 'paoliniluis', 'body': 'https://github.com/metabase/metabase/issues/35201#issuecomment-1788120864', 'created_at': datetime.datetime(2024, 2, 12, 12, 25, 55, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-12 12:25:55 UTC): https://github.com/metabase/metabase/issues/35201#issuecomment-1788120864

"
2129963660,issue,closed,not_planned,Unable to give decimal number for the amount field of DatetimeAdd,"### Describe the bug

As state in the documentation (https://www.metabase.com/docs/latest/questions/query-builder/expressions/datetimeadd), DatetimeAdd should allow decimal number for amount field. It appears it's not possible and if used in custom expression you don't get any error, expression looks accepted but it's ignored.

This issue is different than #33782, as it has been marked as ""Feature request"" while that one looks like a bug according to the documentation. It's a first step on the way to allow amount from other columns.

### To Reproduce

1. Create a question with whatever data (the trouble is not linked with data)
2. Add a custom field
3. In expression put datetimeAdd(now, 1, ""year"")
4. Call it ""InOneYear""
5. Click on view => OK
6. Add another custom field
7. In expression put datetimeAdd(now, 0.5, ""year"")
8. Call it ""InHalfAYear""
9. Click on view => KO
10. Add another custom field
11. In expression put datetimeAdd(now, 1/2, ""year"")
12. Call it ""InHalfAYearFraction""
13. Click on view => KO

### Expected behavior

On the 1st of January get something around the 1st of July

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase: 0.48.5
- Database : MySQL
```


### Severity

All that can't be done in metabase need to be done in datawharehouse. It's a shame.

### Additional context

#33782",e-gaulue,2024-02-12 11:45:25+00:00,[],2024-07-10 19:24:16+00:00,2024-07-10 19:23:55+00:00,https://github.com/metabase/metabase/issues/38653,"[('Querying/Processor', '')]","[{'comment_id': 2221261588, 'issue_id': 2129963660, 'author': 'ranquild', 'body': 'I think the docs should be updated. You cannot add ""half a year""', 'created_at': datetime.datetime(2024, 7, 10, 19, 23, 25, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-10 19:23:25 UTC): I think the docs should be updated. You cannot add ""half a year""

"
2129878665,issue,closed,completed,[MLv2][Epic] Clean and remove obsolete FE MLv1 methods and utilities,"This Epic serves the purpose of tracking assorted MLv2 cleanup efforts. So far, there is no specific structure to it, but all related cleanup tasks should be added to this epic.

```[tasklist]
### Cleanup
- [ ] https://github.com/metabase/metabase/pull/38570
- [ ] https://github.com/metabase/metabase/pull/38505
- [ ] https://github.com/metabase/metabase/pull/38551
- [ ] https://github.com/metabase/metabase/pull/38550
- [ ] https://github.com/metabase/metabase/pull/38525
- [ ] https://github.com/metabase/metabase/pull/38522
- [ ] https://github.com/metabase/metabase/pull/38508
- [ ] https://github.com/metabase/metabase/pull/38763
- [ ] https://github.com/metabase/metabase/pull/38774
- [ ] https://github.com/metabase/metabase/pull/38806
- [ ] https://github.com/metabase/metabase/pull/38820
- [ ] https://github.com/metabase/metabase/pull/38859
- [ ] Migrate MetabotQueryEditor to not use useStructuredQuery
- [ ] https://github.com/metabase/metabase/pull/38831
```


",nemanjaglumac,2024-02-12 10:54:33+00:00,['ranquild'],2024-06-06 13:56:07+00:00,2024-06-06 13:56:06+00:00,https://github.com/metabase/metabase/issues/38650,"[('Type:Tech Debt', 'or Refactoring'), ('.Epic', 'Feature Implementation or Project'), (':broom:', 'no-brainer cleanup issues to clear out when you have an hour left until EoD or something'), ('.Team/Querying', '')]",[],
2129821036,issue,open,,MySQL missing support for partially revoked grants,"References https://github.com/metabase/metabase/issues/38499

**Description**

Currently MySQL is not able to leverage the sync performance improvements made in #37439 due to a lack of support for certain GRANTS expressions.

The current parsing of table privileges for MySQL does not support directives which make use of [partial revokes](https://dev.mysql.com/doc/refman/8.0/en/partial-revokes.html). Since these setting require a system variable to enable them, they are not commonly used, but when they are they were sufficient to [break database sync](https://github.com/metabase/metabase/issues/38499). 

As a workaround we have [disabled](https://github.com/metabase/metabase/pull/38552) `current-user-table-privileges` for MySQL, which switches sync back to the slow path.

Note that any failure in parsing these permissions will cause the entire database sync process to fail. Perhaps this can be handled more gracefully in general, for example simply disabling the driver feature dynamically, to avoid this type of upgrade failure recurring.",crisptrutski,2024-02-12 10:21:35+00:00,[],2025-02-04 20:24:36+00:00,,https://github.com/metabase/metabase/issues/38649,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 1940933787, 'issue_id': 2129821036, 'author': 'crisptrutski', 'body': 'The following issue is also a blocker for re-enabling the fast sync for MySQL https://github.com/metabase/metabase/issues/38701', 'created_at': datetime.datetime(2024, 2, 13, 9, 40, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-02-13 09:40:00 UTC): The following issue is also a blocker for re-enabling the fast sync for MySQL https://github.com/metabase/metabase/issues/38701

"
2129776512,issue,open,,Add Autofit to columns,"**Is your feature request related to a problem? Please describe.**
When viewing a Table, it's hard to view all the columns at once especially when some have short data and others have a lot. 

**Describe the solution you'd like**
As a user, I want to be able to click somewhere (shortcut) or define an option, so the columns Autofit. 

**Example**
Imagine a Table with:
- product slug
- product version
- feedback message
- user site
- id

In this table, as a user, you want the Product Version, id and product slug to have a smaller width - since the data inside is short.
While for the feedback message and user site - I would want them to take the content width, so it's easier to read (without opening each entry).

Right 
___

**Describe alternatives you've considered**
I have to do this manually each time I open the tables: basically spend time making columns small, and extend the ones with more content (attached).

**How important is this feature to you?**
Note: the more honest and specific you are here the more we will take you seriously. 

**Additional context**
Examples from [Office](https://support.microsoft.com/en-gb/office/change-the-column-width-and-row-height-72f5e3cc-994d-43e8-ae58-9774a0905f46) and [Google](https://www.lido.app/tutorials/google-sheets-autofit-column-width) that have an utofit feature.
",mghenciu,2024-02-12 10:00:16+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/38648,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2129701042,issue,closed,completed,Archiving and unarchiving a collection leaves dashboards in the collection empty,"### Describe the bug

When unarchiving a collection the dashboards restored in it will no longer have the questions that are in the restored collection.

### To Reproduce

1. Create a dashboard with some questions, all saved into the same collection
2. Archive the collection
3. Hit Undo, or unarchive the collection manually
4. (!) All objects are restored, but the dashboard is restored empty

### Expected behavior

The dashboard should be restored in the state prior to the archival

### Logs

_No response_

### Information about your Metabase installation

```JSON
v48 as well as on master
```


### Severity

P2

### Additional context

Might be related to https://github.com/metabase/metabase/issues/26168, however this one happens when you simply try to restore the same object that was archived the first place.
The workaround is to restore the dashboard to a previous state.",zbodi74,2024-02-12 09:15:07+00:00,[],2024-05-17 18:04:17+00:00,2024-05-17 18:04:17+00:00,https://github.com/metabase/metabase/issues/38646,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Trash', 'Where deleted items go'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1939284877, 'issue_id': 2129701042, 'author': 'iethree', 'body': 'should be handled with https://github.com/metabase/metabase/issues/38063', 'created_at': datetime.datetime(2024, 2, 12, 18, 15, 38, tzinfo=datetime.timezone.utc)}]","iethree on (2024-02-12 18:15:38 UTC): should be handled with https://github.com/metabase/metabase/issues/38063

"
2129187454,issue,open,,Sync uses only 2 connections,"### Describe the bug

This one might be a question rather than a bug, but leaving it here as it doesn't make any sense: when doing sync and scan, we use just 2 connections, while we should use all the available ones in the connection pool

### To Reproduce

1) force a sync and scan in the db
2) see the connections being used
![image](https://github.com/metabase/metabase/assets/1711649/aa801f9d-2127-44f2-a0b1-d82202efeb0a)


### Expected behavior

why don't we just use all the available connections and do all those queries in parallel?

### Logs

![sync-scan](https://github.com/metabase/metabase/assets/1711649/e502be56-1e65-446b-92aa-30d0800faec3)


### Information about your Metabase installation

```JSON
has been like this forever
```


### Severity

P2

### Additional context

Discovered while doing some bug hunting",paoliniluis,2024-02-11 21:54:53+00:00,[],2024-07-10 20:21:07+00:00,,https://github.com/metabase/metabase/issues/38644,"[('.Performance', ''), ('Administration/Metadata & Sync', ''), ('Type:New Feature', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2181318203, 'issue_id': 2129187454, 'author': 'calherries', 'body': 'I came across this because of the label added above, so I thought I might just add more context to this. \r\n\r\nThis is a problem with the way sync currently works for most drivers, but not redshift. We solved this problem for redshift in https://github.com/metabase/metabase/issues/39986 by reducing each sync step to one query. The plan to extend this to more drivers is [here](https://www.notion.so/metabase/Faster-sync-for-more-drivers-d5b657aba7354a19bf89d62f1038a8ff).\r\n\r\nMaking all the sync steps parallel could be a quick win to speed up the old sync approach without having to refactor much though. Its impact is still limited by the size of the connection pool, which is 15 by default.', 'created_at': datetime.datetime(2024, 6, 20, 18, 46, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221368842, 'issue_id': 2129187454, 'author': 'luizarakaki', 'body': 'Moving to feature request and mentioning in the sync optimization epic #45179', 'created_at': datetime.datetime(2024, 7, 10, 20, 20, 58, tzinfo=datetime.timezone.utc)}]","calherries on (2024-06-20 18:46:22 UTC): I came across this because of the label added above, so I thought I might just add more context to this. 

This is a problem with the way sync currently works for most drivers, but not redshift. We solved this problem for redshift in https://github.com/metabase/metabase/issues/39986 by reducing each sync step to one query. The plan to extend this to more drivers is [here](https://www.notion.so/metabase/Faster-sync-for-more-drivers-d5b657aba7354a19bf89d62f1038a8ff).

Making all the sync steps parallel could be a quick win to speed up the old sync approach without having to refactor much though. Its impact is still limited by the size of the connection pool, which is 15 by default.

luizarakaki on (2024-07-10 20:20:58 UTC): Moving to feature request and mentioning in the sync optimization epic #45179

"
2129082291,issue,closed,completed,Table List is not visible on clicking on database name on permission tab. Data is connected to metabase through Athena,"### Describe the bug

Summary:

I have created some views on Athena and connected that with Metabase. In the data browse section, I am seeing the name of tables as well as can write SQL native queries over it. Now , i want different access to different users.
For that when accessing the permission tab in Metabase and selecting the database name, no tables are listed despite the presence of approximately 150 tables in the database.

Expected Behavior:
When clicking on the database name in the permission tab, the list of tables associated with the database should be displayed, allowing granular access control to be assigned.

Actual Behavior:
No tables are listed when clicking on the database name in the permission tab, rendering it impossible to assign granular access control to specific tables.



### To Reproduce

Log in to Metabase.
Navigate to the permission tab.
Click on the database name to view the tables.
Observe that no tables are displayed.


### Expected behavior

When clicking on the database name in the permission tab, the list of tables associated with the database should be displayed, allowing granular access control to be assigned.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.314-237.533.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""athena"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-11-07"",
      ""tag"": ""v0.47.7"",
      ""branch"": ""?"",
      ""hash"": ""dd51fd4""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Calcutta""
    }
  }
}
```


### Severity

It is quite important as well as urgent. It is blocking my usage of metabase entirely

### Additional context

Additional Information:

The database connection has been validated, and connectivity between Metabase and Athena is confirmed.
Permissions for the user account utilized for connecting to Athena from Metabase have been meticulously reviewed and deemed appropriate.
The tables are confirmed to exist within the designated database and schema.
The tables were created using SQL queries and DDL (Data Definition Language) statements executed within Athena's query editor or through automation scripts.
Attempts to refresh metadata and schema information within Metabase have been executed, but the issue persists.
There are no discernible network issues or connectivity disruptions.
Logs within Metabase do not reveal any errors or warnings pertaining to database connectivity or table discovery.",rgrip121,2024-02-11 17:19:03+00:00,['noahmoss'],2024-07-08 16:43:39+00:00,2024-07-08 16:43:39+00:00,https://github.com/metabase/metabase/issues/38643,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1937816213, 'issue_id': 2129082291, 'author': 'rgrip121', 'body': '<img width=""961"" alt=""Screenshot 2024-02-09 at 6 46 55 PM"" src=""https://github.com/metabase/metabase/assets/159687751/cffa4bb3-8c02-49a9-b9d8-44249d7951ed"">\r\nAttaching screenshot of the empty table list appearing on clicking database name in permission tab', 'created_at': datetime.datetime(2024, 2, 11, 17, 27, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 1937876952, 'issue_id': 2129082291, 'author': 'paoliniluis', 'body': ""can you show the browse data section where you're seeing the tables?"", 'created_at': datetime.datetime(2024, 2, 11, 21, 31, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938060216, 'issue_id': 2129082291, 'author': 'rgrip121', 'body': 'PFA the browsed data section where the tables are available.\r\n![Uploading Screenshot 2024-02-12 at 10.13.47 AM.png…]()', 'created_at': datetime.datetime(2024, 2, 12, 4, 45, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938586370, 'issue_id': 2129082291, 'author': 'paoliniluis', 'body': ""I can't see the attachment"", 'created_at': datetime.datetime(2024, 2, 12, 12, 27, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938589963, 'issue_id': 2129082291, 'author': 'rgrip121', 'body': '<img width=""1503"" alt=""Screenshot 2024-02-12 at 10 13 47 AM"" src=""https://github.com/metabase/metabase/assets/159687751/3e3a3dae-cdf2-4aaa-b80f-753a4c7f0407"">\r\nAttached again', 'created_at': datetime.datetime(2024, 2, 12, 12, 29, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2195010121, 'issue_id': 2129082291, 'author': 'noahmoss', 'body': 'Hi @rgrip121, sorry we were not able to resolve this when you originally reported it. Are you still seeing this issue?\r\n\r\nIf so, could you try upgrading to a newer version of Metabase?', 'created_at': datetime.datetime(2024, 6, 27, 15, 23, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2214670394, 'issue_id': 2129082291, 'author': 'dpsutton', 'body': 'Gonna close as we are not able to reproduce this on the latest releases or on the version reported. If we have more information happy to reopen this in the future.', 'created_at': datetime.datetime(2024, 7, 8, 16, 43, 39, tzinfo=datetime.timezone.utc)}]","rgrip121 (Issue Creator) on (2024-02-11 17:27:31 UTC): <img width=""961"" alt=""Screenshot 2024-02-09 at 6 46 55 PM"" src=""https://github.com/metabase/metabase/assets/159687751/cffa4bb3-8c02-49a9-b9d8-44249d7951ed"">
Attaching screenshot of the empty table list appearing on clicking database name in permission tab

paoliniluis on (2024-02-11 21:31:32 UTC): can you show the browse data section where you're seeing the tables?

rgrip121 (Issue Creator) on (2024-02-12 04:45:09 UTC): PFA the browsed data section where the tables are available.
![Uploading Screenshot 2024-02-12 at 10.13.47 AM.png…]()

paoliniluis on (2024-02-12 12:27:20 UTC): I can't see the attachment

rgrip121 (Issue Creator) on (2024-02-12 12:29:41 UTC): <img width=""1503"" alt=""Screenshot 2024-02-12 at 10 13 47 AM"" src=""https://github.com/metabase/metabase/assets/159687751/3e3a3dae-cdf2-4aaa-b80f-753a4c7f0407"">
Attached again

noahmoss (Assginee) on (2024-06-27 15:23:14 UTC): Hi @rgrip121, sorry we were not able to resolve this when you originally reported it. Are you still seeing this issue?

If so, could you try upgrading to a newer version of Metabase?

dpsutton on (2024-07-08 16:43:39 UTC): Gonna close as we are not able to reproduce this on the latest releases or on the version reported. If we have more information happy to reopen this in the future.

"
2128741931,issue,closed,completed,"""Add tab"" button is covered with a right scroll button on dashboards with many tabs","### Describe the bug

Once the number of tabs in a dashboard exceed the width of the screen, the tab bar scrolls. However, when the scroll bar is present, the > symbol presents hides the new tab button (unless you adjust the window size). 

Sufficient room, see plus symbol on second row to add a new tab:

<img width=""162"" alt=""image"" src=""https://github.com/metabase/metabase/assets/9835124/b72bd8c4-aa7e-455c-9005-520041617ff1"">


When scroll bar present, the tab insert + symbol to add a new tab is gone - it is hidden behind the > symbol, and it is not possible to scroll further to make it visible:


<img width=""65"" alt=""image"" src=""https://github.com/metabase/metabase/assets/9835124/4a190b40-b202-41f7-b87d-ad32103b8adb"">


### To Reproduce

1. Go to a dashboard
2. Add multiple tabs, until they can no longer fit on the screen and see a scroll bar appears to move between them
3. The > arrow on the scroll bar will cover the + symbol, preventing more from being added
4. If you change the dimensions of the window, making it wider, more tabs can be added - similarly making it narrow prevent new tabs from being added


### Expected behavior

The tab insert plus symbol should not be hidden by the arrow symbol.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS"",
    ""os.name"": ""Windows 11"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/New_York""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v0.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",kyrenia,2024-02-10 22:45:44+00:00,['kulyk'],2024-03-06 12:04:29+00:00,2024-03-06 12:04:24+00:00,https://github.com/metabase/metabase/issues/38641,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('.LongTerm', 'Issues we will fix in the long term, not a near term priority')]",[],
2128694424,issue,closed,completed,Custom Destination to Public Dashboard URLs is broken on Static Embeds,"### Describe the bug

When you setup a Custom Destination to a public URL it breaks on static embeds with a `Not Found` when clicking on it.

### To Reproduce

To Reproduce

1) Turn on public sharing in admin settings
2) Go to New -> Question -> Sample DB -> Orders -> Save as Question 1
3) Go to New -> Question -> Sample DB -> Products -> Save as Question 2
4) Go to New -> Dashboard -> Add Question 1 -> Save as Dashboard and make public

<img width=""1174"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/75db9da5-d4dd-4321-9c65-d312608ac587"">

5)  Go to New -> Dashboard -> Add Question 2 -> Add Click Behaviour  -> Save as Dashboard 2
---------------------------------------------> Click on Address 
---------------------------------------------> Go to Custom Destination 
--------------------------------------------->  URL
---------------------------------------------> Paste Public URL for Dashboard 1 

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/4512f8d9-996d-4ecc-b6aa-02c9e0cfac02"">

7) Enable static Embedding for Dashboard 2 -> On the preview Panel Click on Address -> You will get a Not Found

<img width=""1504"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/f32bc564-841a-4f40-88a1-6a5eae7dcfb8"">

8) If you get the embed URL and paste the JWT link on the browser you will notice this:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/9fb212e7-08db-4560-82e2-66b9ab9639fe"">

Click on the Address Column and notice that the URL changes to the public one but you get a Not Found

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/c1a0e047-4354-47b8-b2a3-584e79d1f532"">

Refreshing the browser works.


NOTE 
Directly from Metabase ->  Go to Dashboard 2 -> Click on Address -> Notice it works



### Expected behavior

Public link to Dashbaord opens from Static Embedding

### Logs

None that are relevant, even the Network Tab shows nothing only the image request

<img width=""1393"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/ddd63048-c2d0-4402-af3c-54f4d546c6eb"">


### Information about your Metabase installation

```JSON
Fails on 1.48.5 and master
```


### Severity

This broke the functionality of a customer which used to work on 47 but upgrade to 48 broke this

### Additional context

Since both logs and frontend logs (network and console) show nothing I am not sure if its a frontend or backend issue",Tony-metabase,2024-02-10 19:52:10+00:00,['WiNloSt'],2024-02-12 11:39:41+00:00,2024-02-12 11:26:39+00:00,https://github.com/metabase/metabase/issues/38640,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Needs Triage', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Escalation', ''), ('.Team/Embedding', ''), ('Sharing/Public', '')]",[],
2128680687,issue,closed,not_planned,Action buttons appear disabled on public dashboards,"### Describe the bug

Action buttons on public dashboards don't work for user. They appear with an ""Actions are not enabled for this Database"" tooltip.



### To Reproduce

To Reproduce:

1. Turn on public sharing in admin settings
2. Create a model from a table and create basic actions for the model
3. Create a dashboard, and add an action dashcard. Save.

<img width=""1511"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/2371f97d-77ea-4864-8375-08296c26e99b"">

4. Enable public sharing of the dashboard. Go to an incognito tab and observe that the action button is faded.

<img width=""1503"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/532528d9-f54f-4b9a-9671-a9bbbbcf9fd7"">

This isn't even possible because To be able to create an Action it has to be enabled!


### Expected behavior

Able to perform an Action in Public 

### Logs

None that Are relevant

### Information about your Metabase installation

```JSON
Able to replicate on 1.48.5 and even in Master
```


### Severity

Some user dashboards which are publicly shared and are using actions are currently unusable

### Additional context

I think it's related to https://github.com/metabase/metabase/issues/30929 but there is no API that points to an error. So i am not sure if its a Frontend or Backend Issue",Tony-metabase,2024-02-10 19:18:48+00:00,[],2024-06-21 08:42:38+00:00,2024-06-21 08:42:38+00:00,https://github.com/metabase/metabase/issues/38639,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Public', 'Simple public iframe embeds'), ('.Team/Embedding', ''), ('Sharing/Public', '')]","[{'comment_id': 2175991343, 'issue_id': 2128680687, 'author': 'albertoperdomo', 'body': 'I think this is no longer the case and actions no longer appear in public dashboards. Can you please confirm @Tony-metabase ?', 'created_at': datetime.datetime(2024, 6, 18, 12, 33, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2180544191, 'issue_id': 2128680687, 'author': 'Tony-metabase', 'body': '@albertoperdomo Correct that Action buttons disappear in public dashboards ... So that is the new expected behaviour? I thought it was going to be possible to use Actions on public dashboards but if that is not the case then this can be closed', 'created_at': datetime.datetime(2024, 6, 20, 12, 25, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182264749, 'issue_id': 2128680687, 'author': 'albertoperdomo', 'body': ""@Tony-metabase Do they appear disabled or do they not appear? I am confused. Expectation is they don't appear at all."", 'created_at': datetime.datetime(2024, 6, 21, 8, 27, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182268976, 'issue_id': 2128680687, 'author': 'albertoperdomo', 'body': ""AFAIK, they never worked in public shares and embeds. See https://github.com/metabase/metabase/issues/34395.\r\nThey should no longer appear on the dashboards as per PR here: https://github.com/metabase/metabase/pull/39048.\r\n\r\nCan you please confirm if they do appear disabled or don't appear? This was released in 49."", 'created_at': datetime.datetime(2024, 6, 21, 8, 29, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2182294590, 'issue_id': 2128680687, 'author': 'Tony-metabase', 'body': ""They just vanish when you make a dashboard publicly available and access the public link. If that's how it's supposed to work I will close this issue then!"", 'created_at': datetime.datetime(2024, 6, 21, 8, 42, 38, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-06-18 12:33:23 UTC): I think this is no longer the case and actions no longer appear in public dashboards. Can you please confirm @Tony-metabase ?

Tony-metabase (Issue Creator) on (2024-06-20 12:25:30 UTC): @albertoperdomo Correct that Action buttons disappear in public dashboards ... So that is the new expected behaviour? I thought it was going to be possible to use Actions on public dashboards but if that is not the case then this can be closed

albertoperdomo on (2024-06-21 08:27:22 UTC): @Tony-metabase Do they appear disabled or do they not appear? I am confused. Expectation is they don't appear at all.

albertoperdomo on (2024-06-21 08:29:45 UTC): AFAIK, they never worked in public shares and embeds. See https://github.com/metabase/metabase/issues/34395.
They should no longer appear on the dashboards as per PR here: https://github.com/metabase/metabase/pull/39048.

Can you please confirm if they do appear disabled or don't appear? This was released in 49.

Tony-metabase (Issue Creator) on (2024-06-21 08:42:38 UTC): They just vanish when you make a dashboard publicly available and access the public link. If that's how it's supposed to work I will close this issue then!

"
2128084815,issue,open,,Support static embedding in Electron apps,"### Describe the bug

In Chromium-based browsers, the frame-ancestors check will fail when the HTML is served from file://. This means Metabase embeds cannot be used in Electron. To fix this, the frame-ancestors directive should be removed entirely when allowing iframes, rather than the catch-all *. This behaviour has been observed in other projects: https://github.com/orgs/community/discussions/13406

### To Reproduce

1. Create or edit an Electron application
2. Attempt to embed an iframe in the application

### Expected behavior

The iframe should load

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.205-195.804.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-11"",
      ""tag"": ""v1.48.3"",
      ""hash"": ""80d8323""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking

### Additional context

_No response_",tasos-boxlabs,2024-02-10 04:15:48+00:00,[],2025-02-04 20:30:49+00:00,,https://github.com/metabase/metabase/issues/38637,"[('Type:New Feature', ''), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Backend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 1936852799, 'issue_id': 2128084815, 'author': 'tasos-boxlabs', 'body': 'This PR contains a fix: https://github.com/metabase/metabase/pull/38207', 'created_at': datetime.datetime(2024, 2, 10, 4, 16, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936852930, 'issue_id': 2128084815, 'author': 'tasos-boxlabs', 'body': ""For anyone looking to solve this while the PR is under review, this worked for me:\r\n\r\n```\r\n session.defaultSession.webRequest.onHeadersReceived((details, callback) => {\r\n    if (details.responseHeaders?.['content-security-policy']) {\r\n      let csp = details.responseHeaders['content-security-policy'][0];\r\n      csp = csp.replace(/frame-ancestors \\*;?/gi, '');\r\n      details.responseHeaders['content-security-policy'] = [csp];\r\n    }\r\n\r\n    callback({ responseHeaders: details.responseHeaders });\r\n  });\r\n```"", 'created_at': datetime.datetime(2024, 2, 10, 4, 16, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2424801163, 'issue_id': 2128084815, 'author': 'albertoperdomo', 'body': ""This is not a bug. I've updated the title and labels to reflect this as a feature request."", 'created_at': datetime.datetime(2024, 10, 20, 10, 8, 23, tzinfo=datetime.timezone.utc)}]","tasos-boxlabs (Issue Creator) on (2024-02-10 04:16:09 UTC): This PR contains a fix: https://github.com/metabase/metabase/pull/38207

tasos-boxlabs (Issue Creator) on (2024-02-10 04:16:34 UTC): For anyone looking to solve this while the PR is under review, this worked for me:

```
 session.defaultSession.webRequest.onHeadersReceived((details, callback) => {
    if (details.responseHeaders?.['content-security-policy']) {
      let csp = details.responseHeaders['content-security-policy'][0];
      csp = csp.replace(/frame-ancestors \*;?/gi, '');
      details.responseHeaders['content-security-policy'] = [csp];
    }

    callback({ responseHeaders: details.responseHeaders });
  });
```

albertoperdomo on (2024-10-20 10:08:23 UTC): This is not a bug. I've updated the title and labels to reflect this as a feature request.

"
2127989888,issue,open,,Allow Pivot Tables to Hide Columns,"**Is your feature request related to a problem? Please describe.**
No, it is not related to a problem. I would like to be able to format cells of a pivot table based on unseen data. 

**Describe the solution you'd like**

I would like pivot tables to have these two additional features:

* The ability to hide a ""Measures"" column
* The ability to make a conditional formatting rule for one Measure to highlight all Measures in that Row and Column.

Combining these would allow a user to include a specific measure merely for conditional formatting but also hide it from view.
This would be powerful for extending conditional formatting to other data while maintaining a simple and clean view.

**Describe alternatives you've considered**
A screenshot is shown below.

**How important is this feature to you?**
Low.

Here is an example of a pivot table that would benefit from this:
![thumbnail_image](https://github.com/metabase/metabase/assets/90083658/90dcc343-e40e-40af-954b-2a1b1ac043fa)

With the implementation I've suggested, the conditional formatting in the ""Status"" columns would also affect the ""Expected Start"" column. And formatted ""Status"" cell would spill its formatting over into the ""Expected Start"" cell. The ""Status"" cell would be hidden, and I'd be left with only a matrix of dates. Dates that are color codes based on status.",MrChadMWood,2024-02-09 23:55:05+00:00,[],2025-02-04 20:31:51+00:00,,https://github.com/metabase/metabase/issues/38636,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]","[{'comment_id': 1971473373, 'issue_id': 2127989888, 'author': 'MrChadMWood', 'body': ""Updating, it seems that there's a way to format columns based on the content of another column. There just isnt a way to hide a column in the pivot table.\r\n\r\n![image](https://github.com/metabase/metabase/assets/90083658/1f7a3399-3e3a-4045-a0b9-cd9449bad08b)"", 'created_at': datetime.datetime(2024, 2, 29, 16, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 1971487213, 'issue_id': 2127989888, 'author': 'MrChadMWood', 'body': 'Another small consideration; without ability to hide columns, it makes use of the on-click ""Pass values to ... filters"" feature more difficult to use. Any values passed must also be present in the matrix, but more values in the matrix also makes the pivot table much more unwieldy. This creates conflict.\r\n\r\nPerhaps, an alternative here would be exposing the intersecting column header and indices as values to be passed. Right now, it seems only possible to pass the matrix cell value.\r\n\r\n\r\n![image](https://github.com/metabase/metabase/assets/90083658/7ea557a4-14fa-4468-b070-a7ae4e222a83)', 'created_at': datetime.datetime(2024, 2, 29, 16, 18, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310571466, 'issue_id': 2127989888, 'author': 'meldiner', 'body': '@MrChadMWood I was trying to do something similar and was able to find a workaround.\r\n\r\nI added my chart to a dashboard and applied a filter. Then, I used cmd+click on the chart’s title within the dashboard to open the chart in a new tab. The URL includes a JWT value, which contains the MBQL for the saved chart.\r\n\r\nNext, I decoded the JWT to access the MBQL, modified the visualization settings to set the width of every other column to 0, and then re-encoded the MBQL back to JWT. I replaced the original JWT in the URL with the updated one, reloaded the chart, and saved it, overriding the previous version.\r\n\r\nThis is what I added to the json:\r\n```\r\n...\r\n ""visualization_settings"": {\r\n    ...\r\n    ""pivot_table.column_widths"": {\r\n      ""leftHeaderWidths"": [\r\n        115\r\n      ],\r\n      ""totalLeftHeaderWidths"": 115,\r\n      ""valueHeaderWidths"": {\r\n        ""1"": 0,\r\n        ""3"": 0,\r\n        ""5"": 0,\r\n        ""7"": 0,\r\n        ""9"": 0,\r\n        ""11"": 0,\r\n        ""13"": 0,\r\n        ""15"": 0,\r\n        ""17"": 0,\r\n        ""19"": 0,\r\n        ""21"": 0,\r\n        ""23"": 0,\r\n        ""25"": 0,\r\n        ""27"": 0,\r\n        ""29"": 0,\r\n        ""31"": 0,\r\n        ""33"": 0,\r\n        ""35"": 0,\r\n        ""37"": 0,\r\n        ""39"": 0,\r\n        ""41"": 0,\r\n        ""43"": 0,\r\n        ""45"": 0,\r\n        ""47"": 0,\r\n        ""49"": 0,\r\n        ""51"": 0,\r\n        ""53"": 0,\r\n        ""55"": 0,\r\n        ""57"": 0,\r\n        ""59"": 0,\r\n        ""61"": 0,\r\n        ""63"": 0,\r\n        ""65"": 0,\r\n        ""67"": 0,\r\n        ""69"": 0,\r\n        ""71"": 0,\r\n        ""73"": 0,\r\n        ""75"": 0,\r\n        ""77"": 0,\r\n        ""79"": 0,\r\n        ""81"": 0,\r\n        ""83"": 0,\r\n        ""85"": 0,\r\n        ""87"": 0,\r\n        ""89"": 0,\r\n        ""91"": 0,\r\n        ""93"": 0,\r\n        ""95"": 0,\r\n        ""97"": 0,\r\n        ""99"": 0,\r\n        ""101"": 0,\r\n        ""103"": 0,\r\n        ""105"": 0,\r\n        ""107"": 0\r\n      }\r\n    },\r\n    ...\r\n}\r\n```', 'created_at': datetime.datetime(2024, 8, 26, 16, 12, 1, tzinfo=datetime.timezone.utc)}]","MrChadMWood (Issue Creator) on (2024-02-29 16:12:06 UTC): Updating, it seems that there's a way to format columns based on the content of another column. There just isnt a way to hide a column in the pivot table.

![image](https://github.com/metabase/metabase/assets/90083658/1f7a3399-3e3a-4045-a0b9-cd9449bad08b)

MrChadMWood (Issue Creator) on (2024-02-29 16:18:59 UTC): Another small consideration; without ability to hide columns, it makes use of the on-click ""Pass values to ... filters"" feature more difficult to use. Any values passed must also be present in the matrix, but more values in the matrix also makes the pivot table much more unwieldy. This creates conflict.

Perhaps, an alternative here would be exposing the intersecting column header and indices as values to be passed. Right now, it seems only possible to pass the matrix cell value.


![image](https://github.com/metabase/metabase/assets/90083658/7ea557a4-14fa-4468-b070-a7ae4e222a83)

meldiner on (2024-08-26 16:12:01 UTC): @MrChadMWood I was trying to do something similar and was able to find a workaround.

I added my chart to a dashboard and applied a filter. Then, I used cmd+click on the chart’s title within the dashboard to open the chart in a new tab. The URL includes a JWT value, which contains the MBQL for the saved chart.

Next, I decoded the JWT to access the MBQL, modified the visualization settings to set the width of every other column to 0, and then re-encoded the MBQL back to JWT. I replaced the original JWT in the URL with the updated one, reloaded the chart, and saved it, overriding the previous version.

This is what I added to the json:
```
...
 ""visualization_settings"": {
    ...
    ""pivot_table.column_widths"": {
      ""leftHeaderWidths"": [
        115
      ],
      ""totalLeftHeaderWidths"": 115,
      ""valueHeaderWidths"": {
        ""1"": 0,
        ""3"": 0,
        ""5"": 0,
        ""7"": 0,
        ""9"": 0,
        ""11"": 0,
        ""13"": 0,
        ""15"": 0,
        ""17"": 0,
        ""19"": 0,
        ""21"": 0,
        ""23"": 0,
        ""25"": 0,
        ""27"": 0,
        ""29"": 0,
        ""31"": 0,
        ""33"": 0,
        ""35"": 0,
        ""37"": 0,
        ""39"": 0,
        ""41"": 0,
        ""43"": 0,
        ""45"": 0,
        ""47"": 0,
        ""49"": 0,
        ""51"": 0,
        ""53"": 0,
        ""55"": 0,
        ""57"": 0,
        ""59"": 0,
        ""61"": 0,
        ""63"": 0,
        ""65"": 0,
        ""67"": 0,
        ""69"": 0,
        ""71"": 0,
        ""73"": 0,
        ""75"": 0,
        ""77"": 0,
        ""79"": 0,
        ""81"": 0,
        ""83"": 0,
        ""85"": 0,
        ""87"": 0,
        ""89"": 0,
        ""91"": 0,
        ""93"": 0,
        ""95"": 0,
        ""97"": 0,
        ""99"": 0,
        ""101"": 0,
        ""103"": 0,
        ""105"": 0,
        ""107"": 0
      }
    },
    ...
}
```

"
2127656975,issue,closed,not_planned,Linked Filters: Connected fields do not show any values,"I am trying to create linked filters for State and City in the Sample DB database by metabase. As a prerequisite for linked filters, I am using connected fields to get the values of the filters. But nothing shows up in the connected fields tab even after running the 'Re-scan this table' option in Table Metadata. Could you please provide the inputs on this. @flamber",sumeetsekhon7,2024-02-09 18:30:00+00:00,[],2024-02-10 02:00:51+00:00,2024-02-10 02:00:51+00:00,https://github.com/metabase/metabase/issues/38625,[],"[{'comment_id': 1936566312, 'issue_id': 2127656975, 'author': 'sumeetsekhon7', 'body': ""I am trying to create linked filters for State and City in the Sample DB database by metabase. As a prerequisite for linked filters, I am using connected fields to get the values of the filters. But nothing shows up in the connected fields tab even after running the 'Re-scan this table' option in Table Metadata. Could you please provide the inputs on this. @flamber"", 'created_at': datetime.datetime(2024, 2, 9, 20, 33, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936810087, 'issue_id': 2127656975, 'author': 'paoliniluis', 'body': 'Please use a question in the forums', 'created_at': datetime.datetime(2024, 2, 10, 2, 0, 51, tzinfo=datetime.timezone.utc)}]","sumeetsekhon7 (Issue Creator) on (2024-02-09 20:33:52 UTC): I am trying to create linked filters for State and City in the Sample DB database by metabase. As a prerequisite for linked filters, I am using connected fields to get the values of the filters. But nothing shows up in the connected fields tab even after running the 'Re-scan this table' option in Table Metadata. Could you please provide the inputs on this. @flamber

paoliniluis on (2024-02-10 02:00:51 UTC): Please use a question in the forums

"
2127530414,issue,closed,completed,[Epic] SCIM support,"Closes https://github.com/metabase/metabase/issues/18319
[Product doc](https://www.notion.so/metabase/Support-SCIM-for-user-provisioning-and-deprovisioning-a41d6d08e965498e93fdbce99ba1d301)
[Figma](https://www.figma.com/design/E42ezp6P3kY4PJj0r5tIOM/Support-SCIM-for-user-provisioning-and-deprovisioning?node-id=2095-1152&t=7TcfCvDuJm6fcmgB-1)

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/41816/
- [x] [BE] Add `scope` to API keys and add support for a `scim` scope
- [x] [BE] Authenticate SCIM endpoints with the `scim`-scoped API key
- [x] [BE] Implement SCIM User endpoints
- [x] [BE] Imlpement SCIM Group endpoints
- [x] [BE] Filter out SCIM token from API Keys endpoints
- [ ] https://github.com/metabase/metabase/issues/43132
- [x] Test the implementation of the SCIM spec using Okta's test suite
```",luizarakaki,2024-02-09 17:03:32+00:00,['noahmoss'],2024-08-19 20:57:32+00:00,2024-08-19 20:57:26+00:00,https://github.com/metabase/metabase/issues/38621,"[('.Epic', 'Feature Implementation or Project'), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2127422218,issue,closed,completed,"X-Ray failure with message ""Cannot determine source table...""","To reproduce:

* X-Ray the Reviews table in the sample database 
* Note that ""Product → Price over time"" is broken
* Click the ""Product → Price over time"" to focus on the query to see the same behavior

See @albertoperdomo's related examples in [this Slack thread](https://metaboat.slack.com/archives/C01MS7DQKR6/p1707478852175869).

Visual repro:
![xraybroke](https://github.com/metabase/metabase/assets/8381441/e6efadc5-f74a-4f60-9580-e68bb9f53620)

When this happens, you will see a message like so in the Metabase logs:
```
 :error ""Cannot determine the source table or query for Field clause [:field 59 {:base-type :type/Float}]"",
```

Here's an example broken query:
```
(qp/process-query
  {:database 1,
   :query {:aggregation [[""sum"" [""field"" 59 {:base-type ""type/Float""}]] 
                                        [""avg"" [""field"" 59 {:base-type ""type/Float""}]]],
           :breakout [[""field"" 69 {:base-type ""type/DateTime"", :temporal-unit ""month""}]],
           :source-table 8},
   :type ""query""})
2024-02-09 16:02:29,815 WARN middleware.fix-bad-references :: Bad :field clause [:field 59 {:base-type :type/Float}] for field ""PRODUCTS.PRICE"" at [:aggregation :sum]: clause should have a :join-alias. Unable to infer an appropriate join. Query may not work as expected.
2024-02-09 16:02:29,816 WARN middleware.fix-bad-references :: Bad :field clause [:field 59 {:base-type :type/Float}] for field ""PRODUCTS.PRICE"" at [:aggregation :avg]: clause should have a :join-alias. Unable to infer an appropriate join. Query may not work as expected.
Execution error (ExceptionInfo) at metabase.query-processor.util.add-alias-info/fn$&f (add_alias_info.clj:193).
Cannot determine the source table or query for Field clause [:field 59 {:base-type :type/Float}]
```

The issue seems to be that when the breakout is added to the query in the x-ray code, it does not add in a `:source-field` or other join information since field 59 (PRICE) is from the products table, but we're querying from table 8 (REVIEWS).

When manually creating the question, the right query is:
```
{:database 1,
 :type     ""query"",
 :query    {:source-table 8,
            :aggregation  [[""sum"" [""field"" 59 {:base-type ""type/Float"", :source-field 71}]]
                           [""avg"" [""field"" 59 {:base-type ""type/Float"", :source-field 71}]]],
            :breakout     [[""field"" 69 {:base-type ""type/DateTime"", :temporal-unit ""month""}]]}}
```
Field 71 is product id.",markbastian,2024-02-09 15:58:52+00:00,['markbastian'],2024-02-12 15:30:59+00:00,2024-02-12 14:41:56+00:00,https://github.com/metabase/metabase/issues/38618,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2127380955,issue,open,,Document different networking setups,"we have a ton of people that ask how to connect Metabase cloud to their computers, or how to pierce their VPN connections to get Metabase to work on their private dbs...

we should really build a document with charts that easily explains all these situations and what you need to do to overcome the problems",paoliniluis,2024-02-09 15:37:18+00:00,[],2024-02-09 15:37:18+00:00,,https://github.com/metabase/metabase/issues/38613,"[('Type:Documentation', '')]",[],
2127306693,issue,closed,completed,Reset Password does not prevent multiple clicks,"### Describe the bug

Clicking the Reset Password button multiple times results in several password reset actions for the user.

### To Reproduce

1. Go to Admin Settings / People and try to reset the password for an existing user
<img width=""508"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/eb44ebba-531b-427a-a70e-6cc9528f073a"">

2. Click the Reset Password button several times
<img width=""1157"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/2e9fee49-ff60-4506-a183-f5bc6875d2d1"">

3. The API will be called multiple times, generating a new password reset link on each call
<img width=""1157"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/c3d1a2c6-6b24-4198-bfd7-65cb04954d18"">


### Expected behavior

The password reset should happen only once.

### Logs

_No response_

### Information about your Metabase installation

```JSON
""v1.48.3""
```


### Severity

Cosmetic. Potential confusion from the multiple password reset emails.

### Additional context

_No response_",zbodi74,2024-02-09 14:55:56+00:00,"['sloansparger', 'qwef']",2024-02-13 18:15:38+00:00,2024-02-13 18:15:38+00:00,https://github.com/metabase/metabase/issues/38610,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1936182942, 'issue_id': 2127306693, 'author': 'dpsutton', 'body': 'We can likely debounce the front-end and use `throttle.core/make-throttler` on the backend to prevent this.', 'created_at': datetime.datetime(2024, 2, 9, 15, 59, 59, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-02-09 15:59:59 UTC): We can likely debounce the front-end and use `throttle.core/make-throttler` on the backend to prevent this.

"
2127170546,issue,closed,completed,Update other places that are using raw permission paths or `*current-user-permissions-set*` to use the new perms API,,johnswanson,2024-02-09 13:35:36+00:00,['johnswanson'],2024-03-04 18:07:37+00:00,2024-03-04 18:07:37+00:00,https://github.com/metabase/metabase/issues/38606,[],[],
2127064944,issue,closed,completed,Required parameters: follow-ups ,"Once the [[Epic] Let creators make dashboard and native query filters required](https://github.com/metabase/metabase/issues/36524) lands, we need to do a bunch of follow-ups.

## Milestone 3
- [x]  https://github.com/metabase/metabase/pull/39159
## Core updates
- [x] https://github.com/metabase/metabase/pull/38906
- [x] https://github.com/metabase/metabase/pull/38997
- [x] https://github.com/metabase/metabase/pull/39128

## UI/UX updates
- [x] https://github.com/metabase/metabase/pull/38468
- [x] https://github.com/metabase/metabase/pull/39068
- [x] increase gap between the toggle and input by 4px - addressed in https://github.com/metabase/metabase/pull/38906
- [x] https://github.com/metabase/metabase/pull/39206
",oleggromov,2024-02-09 12:44:54+00:00,['oleggromov'],2024-02-28 18:30:05+00:00,2024-02-28 18:02:31+00:00,https://github.com/metabase/metabase/issues/38603,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 1969547852, 'issue_id': 2127064944, 'author': 'oleggromov', 'body': 'This round of follow-ups is merged.\r\nThe next is https://github.com/metabase/metabase/issues/39211', 'created_at': datetime.datetime(2024, 2, 28, 18, 2, 31, tzinfo=datetime.timezone.utc)}]","oleggromov (Issue Creator) on (2024-02-28 18:02:31 UTC): This round of follow-ups is merged.
The next is https://github.com/metabase/metabase/issues/39211

"
2126663528,issue,closed,completed,Jaggy scrolling in entity type picker in Admin > Table Metadata,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/886ba877-1a8b-4346-abc1-d9fa19ebeb9a



### To Reproduce

1. Go to Admin > Table Metadata -> Data -> Sample Database -> Any table
2. Open entity type picker for any column
3. Scroll down in it
4. While holding the vertical scrollbar with your cursor, slowly scroll up

The content in the dropdown will jump up and down as you scroll up.
If you release the left mouse button, sometimes it will stay in the current place, but sometimes it will scroll up all the way to the top of the dropdown.


### Expected behavior

Scrolling is smooth


### Information about your Metabase installation

7eb7cd3, v48


### Severity

P3
",kamilmielnik,2024-02-09 08:12:35+00:00,[],2024-06-03 19:25:02+00:00,2024-06-03 19:25:01+00:00,https://github.com/metabase/metabase/issues/38595,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1935513537, 'issue_id': 2126663528, 'author': 'uladzimirdev', 'body': ""it's a duplicate of or similar to https://github.com/metabase/metabase/issues/36074\r\nthere could be more similar issues reported. \r\n\r\n@iethree can it be solved by migrating to a new popover?"", 'created_at': datetime.datetime(2024, 2, 9, 8, 27, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1939253630, 'issue_id': 2126663528, 'author': 'iethree', 'body': 'I wonder if we could move this whole component to Mantine Select 🤔', 'created_at': datetime.datetime(2024, 2, 12, 17, 59, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2145954913, 'issue_id': 2126663528, 'author': 'npfitz', 'body': 'This was fixed by https://github.com/metabase/metabase/pull/40453', 'created_at': datetime.datetime(2024, 6, 3, 19, 25, 1, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-02-09 08:27:57 UTC): it's a duplicate of or similar to https://github.com/metabase/metabase/issues/36074
there could be more similar issues reported. 

@iethree can it be solved by migrating to a new popover?

iethree on (2024-02-12 17:59:35 UTC): I wonder if we could move this whole component to Mantine Select 🤔

npfitz on (2024-06-03 19:25:01 UTC): This was fixed by https://github.com/metabase/metabase/pull/40453

"
2126008277,issue,closed,completed,[dc.js migration] linear x-axis scale has duplicated values,"http://localhost:3000/question/242-38577-linear-x-axis-scale-duplicate-values

<img width=""1909"" alt=""Screenshot 2024-02-09 at 9 24 31 AM"" src=""https://github.com/metabase/metabase/assets/37751258/41dc3eb7-aa7c-44e0-ad57-ab12e775dd0f"">

http://localhost:3000/model/221-linear-x-all-null-y

<img width=""326"" alt=""Screenshot 2024-02-08 at 12 21 24 PM"" src=""https://github.com/metabase/metabase/assets/37751258/05f178c2-86e6-4cbc-b479-b69512bf6580"">

<img width=""1909"" alt=""Screenshot 2024-02-08 at 12 24 56 PM"" src=""https://github.com/metabase/metabase/assets/37751258/10d9466d-cbdd-441c-8a6e-d2bcec8413fe"">

<img width=""1918"" alt=""Screenshot 2024-02-08 at 12 21 33 PM"" src=""https://github.com/metabase/metabase/assets/37751258/b666e442-9b9c-42df-86d4-2f97965c4157"">

<img width=""1916"" alt=""Screenshot 2024-02-08 at 12 21 41 PM"" src=""https://github.com/metabase/metabase/assets/37751258/e7456cb7-74f4-408f-b37c-3a770e6b38e0"">

On the line, bar, area, and scatter charts, 1 and 2 are duplicated on the x-axis.",EmmadUsmani,2024-02-08 20:22:12+00:00,['alxnddr'],2024-03-07 00:56:28+00:00,2024-03-07 00:56:28+00:00,https://github.com/metabase/metabase/issues/38577,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2125770167,issue,closed,not_planned,Language Issue on Filters Commands,"### Describe the bug

Metabase has language setup and it works at some features. By the way while selecting some data entries for example the language remains in English (default). I changed for Portuguese-BR and some words changed at translation, but other features remain showing the English version as the print below:

![Screenshot from 2024-02-08 14-41-15](https://github.com/metabase/metabase/assets/60454486/75e98a7e-1758-4164-9dde-cc41b270ea69)

Here the default value needs to be ""Passados 30 dias"", but stead of this it displays ""Previous 7 dias"" -> It combines the 2 languages in a single text.

Further info:

![image](https://github.com/metabase/metabase/assets/60454486/1b1c647f-54b9-4857-801f-84f37038eb7e)

The error/bug happens also at settings button as shown above

### To Reproduce

1. Change the default language at Admin Settings or User Settings to a different language than English (e.g Portuguese-BR)
1. Go to any data filter (it needs to be available on all options, e.g specific dates, relative dates, etc)
2. Click on ""Últimos 7 dias"" (stands for ""previous 7 days"")
3. Scroll to the filter box
4. See error

### Expected behavior

Displays the entire text in an unique language (the selected one)

### Logs

_No response_

### Information about your Metabase installation

```JSON
- running at Brave Browser Version 1.62.156 Chromium: 121.0.6167.139 (Official Build) (64-bit)
- OS: Ubuntu 22.04.3 LTS x86_64
- DB: Postgres
- Metabase v1.48.3
```


### Severity

Urgent / High

### Additional context

_No response_",JoaoCioffi,2024-02-08 17:54:38+00:00,[],2024-02-09 14:24:05+00:00,2024-02-09 13:49:37+00:00,https://github.com/metabase/metabase/issues/38568,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1935968218, 'issue_id': 2125770167, 'author': 'paoliniluis', 'body': ""duplicate of https://github.com/metabase/metabase/issues/13188\r\n\r\nare you using Metabase Pro/enterprise? if that's the case please contact support so we can identify the user and tag it"", 'created_at': datetime.datetime(2024, 2, 9, 13, 49, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936026374, 'issue_id': 2125770167, 'author': 'JoaoCioffi', 'body': ""Thanks for the comment @paoliniluis, yes I'm using Metabase Pro."", 'created_at': datetime.datetime(2024, 2, 9, 14, 24, 3, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-09 13:49:33 UTC): duplicate of https://github.com/metabase/metabase/issues/13188

are you using Metabase Pro/enterprise? if that's the case please contact support so we can identify the user and tag it

JoaoCioffi (Issue Creator) on (2024-02-09 14:24:03 UTC): Thanks for the comment @paoliniluis, yes I'm using Metabase Pro.

"
2125711762,issue,closed,completed,Instance Analytics titles drop after page load,"### Describe the bug

Dashboards (and questions) tend to hide last edited info behind the title, and will appear on hover. IA dashboards don't have any of that information though, which causes the title to start off in the right place, but then drop lower than it should. A quick hack could be to add a min height to the `<HeaderBadges>` component, but I think the better solution is to disable that animation when there is no content in Header Badges

IA Dashboard:
![chrome_3t2DhEPaxr](https://github.com/metabase/metabase/assets/1328979/f3e3aab4-829b-458e-9b15-128dc1d6cf44)

Normal Dashboard: 
![chrome_AQMU2Qdv3L](https://github.com/metabase/metabase/assets/1328979/83961a8e-42ef-47fe-afcf-de34453ea312)


### To Reproduce

Go to any IA dashboard and observe the title



### Expected behavior

It should look right 

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current Master
```


### Severity

Not overly severe, but it looks bad

### Additional context

_No response_",npfitz,2024-02-08 17:23:13+00:00,['npfitz'],2024-02-11 14:51:39+00:00,2024-02-11 14:51:01+00:00,https://github.com/metabase/metabase/issues/38566,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2125644573,issue,open,,Allow Action fields (dropdown) to be dynamically populated by Raw Data or Model fields.,"**Is your feature request related to a problem? Please describe.**
Currently, dropdown fields in an Action can only be pre-populated with a static list of elements.

![image](https://github.com/metabase/metabase/assets/90083658/bce2620a-27ee-4115-8366-6f1c77a624f8)

**Describe the solution you'd like**
If dropdown fields in an Action can instead be pre-populated via UNIQUE() values from a field in the parent model, or from a field in the Raw Data, it would be a nice quality of life feature.

**Describe alternatives you've considered**
I'm not sure of any alternatives. The idea is to fetch the data from the database at runtime to be more dynamic so that options can update without manually being updated.

**How important is this feature to you?**
It is important for keeping dropdown fields in sync with actual options automatically. Right now, any use case where a user might run an Action twice and expect a side-effect on a dropdown field is not possible to support. This is only important I think for some concepts with forms (i.e., not a big deal, but would be nice).

",MrChadMWood,2024-02-08 16:53:45+00:00,[],2025-02-04 20:30:30+00:00,,https://github.com/metabase/metabase/issues/38565,"[('Type:New Feature', ''), ('Administration/Table Metadata', ''), ('Querying/Actions', ''), ('Querying/Forms', 'Actions')]",[],
2125610205,issue,closed,completed,Multiple Filter Selections Result In No Ability To Select Option Within Action,"### Describe the bug

When multiple selections are applied to a filter, a user would need to select only one for the Action. However, the field disappears entirely from within the Action.

With filters:
![image](https://github.com/metabase/metabase/assets/90083658/e6a71121-93d9-4a69-8485-d41b4d0f019d)
Without filters:
![image](https://github.com/metabase/metabase/assets/90083658/0bbc11dd-fd07-4918-ab1a-f1d8925fd7cd)


### To Reproduce

1. Go to a dashboard with an Action and a multi-seleciton filter. When the Action was added to the dashboard, map the field to the filter. Dont leave as ""Ask The User"".
2. Click on several options in the filter.
3. Initiate the Action
4. See the inability to select an option.


### Expected behavior

The user would be able to select one of the remaining values.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.55-75.123.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Low/Medium. 

### Additional context

Also if dropdown fields from an Action had a searchbox mechanism, similar to a Text Filters searchbox mechanism. This would offer a valid workaround for the current issue, as I'm really just trying to filter the options by using the dashboard filter. A searchbox for the Action's field would be a good alternative.",MrChadMWood,2024-02-08 16:34:35+00:00,[],2024-02-14 22:24:51+00:00,2024-02-14 22:24:51+00:00,https://github.com/metabase/metabase/issues/38563,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1944822474, 'issue_id': 2125610205, 'author': 'MrChadMWood', 'body': ""User misunderstanding. Seems that when you select a filter, it auto populates the field with the filter values. You're deciding not to let the user supply those values."", 'created_at': datetime.datetime(2024, 2, 14, 22, 24, 49, tzinfo=datetime.timezone.utc)}]","MrChadMWood (Issue Creator) on (2024-02-14 22:24:49 UTC): User misunderstanding. Seems that when you select a filter, it auto populates the field with the filter values. You're deciding not to let the user supply those values.

"
2125512485,issue,open,,[MLv2] Inconsistent metadata for models between CLJ and CLJS,"### Describe the bug

Getting the metadata for a model containing a JOIN is inconsistent between CLJ and CLJS, and mock metadata vs. real.
This might be surfacing in some of the network requests, I'm not certain.

### To Reproduce

1. Create a question with a JOIN, eg. `Products INNER JOIN Reviews ON Product.ID = Reviews.PRODUCT_ID`
2. Save it
3. Convert it to a model
4. Uncomment and run `metabase.lib.drill-thru.column-filter-test/leaky-model-ref-test` in CLJ.
5. Observe that the test fails. Examining the logic in `metabase.lib.drill-thru.column-filter` shows that it can't find the corresponding column because the incoming field ref has a `:source-alias` and therefore its disambiguated name is `Review__ID` rather than `ID_2`.

### Expected behavior

The behavior is consistent between `test-metadata` and the real thing, and between CLJ and CLJS.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

Trivial in itself, since the FE works fine - but this lurking inconsistency may be a problem for QP and API usage

### Additional context

It's likely that the flip side of this bug is the reason the change in #38047 was needed - the MLv2-generated refs had the `:source-alias` and included it in the refs, so that failed to match the columns on the FE. That makes it return `:column nil` on the drill, which causes #38034 .

Since the FE's `DatasetColumn.column_ref` field that's used in #38047 is coming from the API, it might be fruitful to examine how those refs are constructed and compare that with MLv2's logic.",bshepherdson,2024-02-08 15:52:45+00:00,[],2025-02-04 20:27:12+00:00,,https://github.com/metabase/metabase/issues/38558,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2125497761,issue,open,,Don't use search endpoint to check for existence of models,"[discussion](https://metaboat.slack.com/archives/C064EB1UE5P/p1707405431922619)

On initial page load, we fire off a bunch of API requests, the single slowest of which is to the search endpoint (`/api/search?models=dataset&limit=1`) for the sole purpose of figuring out whether the instance has any models (we need to know this because we show different UI if you don’t have any models)

This feels pretty hacky, and I’m also pretty sure it’s a pretty heavy db operation

```
2024-02-08 15:10:51,644 DEBUG middleware.log :: GET /api/search 200 223.4 ms (5 DB calls) App DB connections: 1/10 Jetty threads: 5/50 (5 idle, 0 queued) (69 total active threads) Queries in flight: 0 (0 queued)
```

What if we moved this somewhere else, maybe something like has_models  from /api/session/properties ? Would it make sense to persist this property instead of having every user run a big search query on every page load? 

",iethree,2024-02-08 15:47:07+00:00,[],2024-02-08 15:47:08+00:00,,https://github.com/metabase/metabase/issues/38557,"[('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2125453051,issue,closed,completed,Post RC1 refactors for Meet embedders,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/38669
- [ ] https://github.com/metabase/metabase/pull/38708
- [x] make sure the snowplow e2e tests all the events (specifically: at least app the steps)
- [ ] https://github.com/metabase/metabase/pull/38772
```
",npretto,2024-02-08 15:27:33+00:00,['npretto'],2024-02-15 08:39:46+00:00,2024-02-15 08:39:46+00:00,https://github.com/metabase/metabase/issues/38556,"[('.Team/Embedding', '')]",[],
2125419712,issue,open,,Unable to select a field to filter on from our data warehouse when selecting a field filter since upgrade to 1.48.5,"**Describe the bug**
We are unable to select a field to filter on from our data warehouse when selecting a field filter.

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'Variables' in a Question.
2. Create a Field Filter Variable type.
3. Click on the drop-down to select a field to map to.
4. You can filter on schemas, but can never see the table details. The spinning continues to spin for many minutes. I have waiting >10 minutes a few times.

**Expected behavior**
When I select a schema and table, I expect to be able to see a list of fields to select.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.
This is very uncomfortable because we do not know a current workaround, which makes it impossible to create new dashboards, or to edit existing filters.

**Additional context**
We recently upgraded to 1.48.5 on 2023-02-08, which is when this problem first occurred. We assumed that the indexing would have completed much faster than this.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.10+7-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""17.0.10"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.10+7-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.334-252.552.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v1.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}```",miguel-patientiq,2024-02-08 15:15:52+00:00,[],2024-04-30 23:39:33+00:00,,https://github.com/metabase/metabase/issues/38555,"[('.Needs Triage', '')]",[],
2124594654,issue,open,,Incorrect Aggregation Label After Editing Display Name in Metabase,"### Describe the bug

In the Metabase platform, I edited the display name of a field named ""value"" in the TEST model to ""DISP"" using the ""edit query definition"" function. However, after performing aggregation operations, the result displays as ""Max of Value"" instead of the expected ""Max of DISP"". This inconsistency between the edited display name of the field and the aggregation label is leading to inaccurate results.

### To Reproduce

1.Access the Metabase platform and open the TEST model.
2.edit query definition
3.Locate the field named ""value"" and edit its display name to ""DISP"".
4.Perform an aggregation operation on this field (e.g., Max).
5.Observe the result, which shows as ""Max of Value"" instead of the expected ""Max of DISP"".


### Expected behavior

After editing the display name of the field, the aggregation operation should correctly use the new display name to label the result, such as ""Max of DISP"".

### Logs

![image](https://github.com/metabase/metabase/assets/21302251/c266d560-db29-480d-8252-64054d6d5dec)


### Information about your Metabase installation

```JSON
Metabase version:v0.48.1
```


### Severity

Moderate

### Additional context

_No response_",cverdela,2024-02-08 08:18:06+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/38543,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1958463307, 'issue_id': 2124594654, 'author': 'cverdela', 'body': 'I want to ensure that my issue is clear and understandable. If there are any improvements I can make in terms of clarity or providing additional information, please let me know.', 'created_at': datetime.datetime(2024, 2, 22, 0, 48, 15, tzinfo=datetime.timezone.utc)}]","cverdela (Issue Creator) on (2024-02-22 00:48:15 UTC): I want to ensure that my issue is clear and understandable. If there are any improvements I can make in terms of clarity or providing additional information, please let me know.

"
2124412972,issue,closed,not_planned,issue when  taking build ,"Build frontend with MB_EDITION=oss
    Run 'yarn' to download javascript dependencies
      CI run: enforce the lockfile
      $ ""yarn"" ""--frozen-lockfile""
        yarn install v1.22.19
        $ echo $npm_execpath | grep -q yarn || echo '\033[0;33mSorry, npm is not supported. Please use Yarn (https://yarnpkg.com/).\033[0m'
        [1/5] Validating package.json...
        [2/5] Resolving packages...
        warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^2.0.0""
        warning Resolution field ""set-value@4.0.1"" is incompatible with requested version ""set-value@^2.0.0""
        warning Resolution field ""unset-value@2.0.1"" is incompatible with requested version ""unset-value@^1.0.0""
        warning Resolution field ""set-value@4.0.1"" is incompatible with requested version ""set-value@^2.0.1""
        warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^1.0.1""
        warning Resolution field ""nth-check@2.0.1"" is incompatible with requested version ""nth-check@^1.0.2""
        warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^2.0.0""
        warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^2.0.0""
        warning Resolution field ""json5@2.2.2"" is incompatible with requested version ""json5@^1.0.1""
        warning Resolution field ""ansi-regex@5.0.1"" is incompatible with requested version ""ansi-regex@^6.0.1""
        [3/5] Fetching packages...
        [4/5] Linking dependencies...
        warning "" > @storybook/react@6.5.15"" has unmet peer dependency ""require-from-string@^2.0.2"".
        warning "" > css-loader@1.0.1"" has incorrect peer dependency ""webpack@^4.0.0"".
        warning "" > mochawesome@7.1.3"" has unmet peer dependency ""mocha@>=7"".
        [5/5] Building fresh packages...
        $ husky install
        fatal: detected dubious ownership in repository at '/home/node'
        Done in 1113.01s.
Step failed: Running build steps for Community (OSS) Edition version UNKNOWN: version, translations, frontend, licenses, drivers, uberjar
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message
   ""Running build steps for Community (OSS) Edition version UNKNOWN: version, translations, frontend, licenses, drivers, uberjar"",
   :data {},
   :at [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 88]}
  {:type clojure.lang.ExceptionInfo,
   :message ""Build frontend with MB_EDITION=oss"",
   :data {},
   :at [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 88]}
  {:type clojure.lang.ExceptionInfo,
   :message ""Run 'yarn' to download javascript dependencies"",
   :data {},
   :at [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 88]}
  {:type clojure.lang.ExceptionInfo,
   :message ""$ \""yarn\"" \""--frozen-lockfile\"""",
   :data {},
   :at [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 88]}
  {:type clojure.lang.ExceptionInfo,
   :message ""Timed out after 900000 ms."",
   :data {},
   :at [metabuild_common.shell$deref_with_timeout invokeStatic ""shell.clj"" 22]}],
 :trace
 [[metabuild_common.shell$deref_with_timeout invokeStatic ""shell.clj"" 22]
  [metabuild_common.shell$deref_with_timeout invoke ""shell.clj"" 19]
  [metabuild_common.shell$sh_STAR_$fn__1706 invoke ""shell.clj"" 66]
  [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 85]
  [metabuild_common.steps$do_step invoke ""steps.clj"" 79]
  [metabuild_common.shell$sh_STAR_ invokeStatic ""shell.clj"" 45]
  [metabuild_common.shell$sh_STAR_ doInvoke ""shell.clj"" 27]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabuild_common.shell$sh invokeStatic ""shell.clj"" 75]
  [metabuild_common.shell$sh doInvoke ""shell.clj"" 70]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [build$build_frontend_BANG_$fn__19502$fn__19503 invoke ""build.clj"" 32]
  [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 85]
  [metabuild_common.steps$do_step invoke ""steps.clj"" 79]
  [build$build_frontend_BANG_$fn__19502 invoke ""build.clj"" 28]
  [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 85]
  [metabuild_common.steps$do_step invoke ""steps.clj"" 79]
  [build$build_frontend_BANG_ invokeStatic ""build.clj"" 27]
  [build$build_frontend_BANG_ invoke ""build.clj"" 22]
  [build$fn__19527 invokeStatic ""build.clj"" 94]
  [build$fn__19527 invoke ""build.clj"" 93]
  [build$build_BANG_$fn__19545 invoke ""build.clj"" 123]
  [metabuild_common.steps$do_step invokeStatic ""steps.clj"" 85]
  [metabuild_common.steps$do_step invoke ""steps.clj"" 79]
  [build$build_BANG_ invokeStatic ""build.clj"" 112]
  [build$build_BANG_ invoke ""build.clj"" 102]
  [build$build_cli$fn__19557 invoke ""build.clj"" 131]
  [metabuild_common.entrypoint$do_exit_when_finished_nonzero_on_exception invokeStatic ""entrypoint.clj"" 7]
  [metabuild_common.entrypoint$do_exit_when_finished_nonzero_on_exception invoke ""entrypoint.clj"" 5]
  [build$build_cli invokeStatic ""build.clj"" 130]
  [build$build_cli invoke ""build.clj"" 126]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 154]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.Var applyTo ""Var.java"" 705]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [clojure.run.exec$exec invokeStatic ""exec.clj"" 48]
  [clojure.run.exec$exec doInvoke ""exec.clj"" 39]
  [clojure.lang.RestFn invoke ""RestFn.java"" 423]
  [clojure.run.exec$_main$fn__205 invoke ""exec.clj"" 180]
  [clojure.run.exec$_main invokeStatic ""exec.clj"" 176]
  [clojure.run.exec$_main doInvoke ""exec.clj"" 139]
  [clojure.lang.RestFn invoke ""RestFn.java"" 397]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 152]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.Var applyTo ""Var.java"" 705]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.main$main_opt invokeStatic ""main.clj"" 514]
  [clojure.main$main_opt invoke ""main.clj"" 510]
  [clojure.main$main invokeStatic ""main.clj"" 664]
  [clojure.main$main doInvoke ""main.clj"" 616]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.lang.Var applyTo ""Var.java"" 705]
  [clojure.main main ""main.java"" 40]],
 :cause ""Timed out after 900000 ms."",
 :data {}}
The command '/bin/sh -c INTERACTIVE=false CI=true MB_EDITION=$MB_EDITION bin/build.sh' returned a non-zero code: 255
while taking build suddenly i'm getting this issue help me to solve this and give steps me steps to take build ",ghost,2024-02-08 05:54:03+00:00,[],2024-02-14 10:33:01+00:00,2024-02-08 11:14:47+00:00,https://github.com/metabase/metabase/issues/38539,[],"[{'comment_id': 1933860028, 'issue_id': 2124412972, 'author': 'paoliniluis', 'body': 'Reinstall nodejs', 'created_at': datetime.datetime(2024, 2, 8, 11, 14, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 1935758787, 'issue_id': 2124412972, 'author': 'marcinkoziej', 'body': '@paoliniluis I have the same issue trying to build Metabase via a Gitlab job. How would reinstalling nodejs help with this issue? Are you suggesting some yarn version is necessary for this to build?', 'created_at': datetime.datetime(2024, 2, 9, 11, 29, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 1935805726, 'issue_id': 2124412972, 'author': 'paoliniluis', 'body': '@marcinkoziej please post your entire ci file', 'created_at': datetime.datetime(2024, 2, 9, 12, 1, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 1935809127, 'issue_id': 2124412972, 'author': 'marcinkoziej', 'body': 'Here it goes! Nothing unordinary. \r\n```\r\nimage: docker:18-git\r\nservices:\r\n  - docker:18-dind\r\n\r\nvariables:\r\n  CONTAINER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME\r\n\r\nbefore_script:\r\n   - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\r\n\r\nbuild:\r\n stage: build\r\n rules:\r\n   - if: $CI_COMMIT_TAG != null\r\n     when: always\r\n script:\r\n   - docker build -t $CONTAINER_IMAGE .\r\n   - docker push $CONTAINER_IMAGE\r\n```', 'created_at': datetime.datetime(2024, 2, 9, 12, 3, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936163064, 'issue_id': 2124412972, 'author': 'marcinkoziej', 'body': '[paoliniluis](https://github.com/paoliniluis) I changed the timeout in `shell.clj` to 60 minutes, and the build completed after 43minutes. I also needed to make memory limit higher for this build as it was hitting some low memory condition.\r\n\r\nNot sure what\'s the action to be taken here? Should the default be increased?\r\n\r\n```\r\ndiff --git a/bin/build/src/metabuild_common/shell.clj b/bin/build/src/metabuild_common/shell.clj\r\nindex 1373b5843b..278e5178f4 100644\r\n--- a/bin/build/src/metabuild_common/shell.clj\r\n+++ b/bin/build/src/metabuild_common/shell.clj\r\n@@ -22,7 +22,7 @@\r\n       (throw (ex-info (format ""Timed out after %d ms."" timeout-ms) {})))\r\n     result))\r\n \r\n-(def ^:private command-timeout-ms (* 15 60 1000)) ; 15 minutes\r\n+(def ^:private command-timeout-ms (* 60 60 1000)) ; 60 minutes\r\n \r\n (defn sh*\r\n   ""Run a shell command. Like `clojure.java.shell/sh`, but prints output to stdout/stderr and returns a map with keys\r\n\r\n```', 'created_at': datetime.datetime(2024, 2, 9, 15, 47, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936319294, 'issue_id': 2124412972, 'author': 'paoliniluis', 'body': 'Definitely you need to get better runners, this process works flawlessly on our GitHub runners', 'created_at': datetime.datetime(2024, 2, 9, 17, 33, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 1943483160, 'issue_id': 2124412972, 'author': 'ghost', 'body': 'suddenly getting this error, help me to resolve .              \r\n\r\n\r\n\r\nDownloading: org/mongodb/mongodb-driver-core/3.12.11/mongodb-driver-core-3.12.11.jar from central\r\n{:clojure.main/message\r\n ""Execution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).\\nCould not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name.\\n"",\r\n :clojure.main/triage\r\n {:clojure.error/class java.io.FileNotFoundException,\r\n  :clojure.error/line 1,\r\n  :clojure.error/cause\r\n  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",\r\n  :clojure.error/symbol metabuild-common.aws/eval1459$loading,\r\n  :clojure.error/source ""aws.clj"",\r\n  :clojure.error/phase :execution},\r\n :clojure.main/trace\r\n {:via\r\n  [{:type clojure.lang.Compiler$CompilerException,\r\n    :message\r\n    ""Syntax error macroexpanding at (metabuild_common/aws.clj:1:1)."",\r\n    :data\r\n    {:clojure.error/phase :execution,\r\n     :clojure.error/line 1,\r\n     :clojure.error/column 1,\r\n     :clojure.error/source ""metabuild_common/aws.clj""},\r\n    :at [clojure.lang.Compiler load ""Compiler.java"" 7665]}\r\n   {:type java.io.FileNotFoundException,\r\n    :message\r\n    ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",\r\n    :at [clojure.lang.RT load ""RT.java"" 462]}],\r\n  :trace\r\n  [[clojure.lang.RT load ""RT.java"" 462]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 482]\r\n   [metabuild_common.aws$eval1459$loading__6789__auto____1460\r\n    invoke\r\n    ""aws.clj""\r\n    1]\r\n   [metabuild_common.aws$eval1459 invokeStatic ""aws.clj"" 1]\r\n   [metabuild_common.aws$eval1459 invoke ""aws.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 805]\r\n   [metabuild_common.core$eval1453$loading__6789__auto____1454\r\n    invoke\r\n    ""core.clj""\r\n    1]\r\n   [metabuild_common.core$eval1453 invokeStatic ""core.clj"" 1]\r\n   [metabuild_common.core$eval1453 invoke ""core.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 421]\r\n   [build_drivers.common$eval234$loading__6789__auto____235\r\n    invoke\r\n    ""common.clj""\r\n    1]\r\n   [build_drivers.common$eval234 invokeStatic ""common.clj"" 1]\r\n   [build_drivers.common$eval234 invoke ""common.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 512]\r\n   [build_drivers.build_driver$eval228$loading__6789__auto____229\r\n    invoke\r\n    ""build_driver.clj""\r\n    1]\r\n   [build_drivers.build_driver$eval228\r\n    invokeStatic\r\n    ""build_driver.clj""\r\n    1]\r\n   [build_drivers.build_driver$eval228 invoke ""build_driver.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n   [build_drivers$eval222$loading__6789__auto____223\r\n    invoke\r\n    ""build_drivers.clj""\r\n    1]\r\n   [build_drivers$eval222 invokeStatic ""build_drivers.clj"" 1]\r\n   [build_drivers$eval222 invoke ""build_drivers.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 1096]\r\n   [build$eval214$loading__6789__auto____215 invoke ""build.clj"" 1]\r\n   [build$eval214 invokeStatic ""build.clj"" 1]\r\n   [build$eval214 invoke ""build.clj"" 1]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7194]\r\n   [clojure.lang.Compiler eval ""Compiler.java"" 7183]\r\n   [clojure.lang.Compiler load ""Compiler.java"" 7653]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 381]\r\n   [clojure.lang.RT loadResourceScript ""RT.java"" 372]\r\n   [clojure.lang.RT load ""RT.java"" 459]\r\n   [clojure.lang.RT load ""RT.java"" 424]\r\n   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]\r\n   [clojure.core$load invokeStatic ""core.clj"" 6160]\r\n   [clojure.core$load doInvoke ""core.clj"" 6144]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.core$load_one invokeStatic ""core.clj"" 5933]\r\n   [clojure.core$load_one invoke ""core.clj"" 5928]\r\n   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]\r\n   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]\r\n   [clojure.core$load_lib doInvoke ""core.clj"" 5953]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]\r\n   [clojure.core$load_libs doInvoke ""core.clj"" 6000]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 669]\r\n   [clojure.core$require invokeStatic ""core.clj"" 6038]\r\n   [clojure.core$require doInvoke ""core.clj"" 6038]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 408]\r\n   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_\r\n    invokeStatic\r\n    ""exec.clj""\r\n    36]\r\n   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_\r\n    invoke\r\n    ""exec.clj""\r\n    29]\r\n   [clojure.run.exec$exec$fn__151 invoke ""exec.clj"" 44]\r\n   [clojure.run.exec$exec invokeStatic ""exec.clj"" 43]\r\n   [clojure.run.exec$exec doInvoke ""exec.clj"" 39]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 423]\r\n   [clojure.run.exec$_main$fn__205 invoke ""exec.clj"" 180]\r\n   [clojure.run.exec$_main invokeStatic ""exec.clj"" 176]\r\n   [clojure.run.exec$_main doInvoke ""exec.clj"" 139]\r\n   [clojure.lang.RestFn invoke ""RestFn.java"" 397]\r\n   [clojure.lang.AFn applyToHelper ""AFn.java"" 152]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 132]\r\n   [clojure.lang.Var applyTo ""Var.java"" 705]\r\n   [clojure.core$apply invokeStatic ""core.clj"" 667]\r\n   [clojure.main$main_opt invokeStatic ""main.clj"" 514]\r\n   [clojure.main$main_opt invoke ""main.clj"" 510]\r\n   [clojure.main$main invokeStatic ""main.clj"" 664]\r\n   [clojure.main$main doInvoke ""main.clj"" 616]\r\n   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n   [clojure.lang.Var applyTo ""Var.java"" 705]\r\n   [clojure.main main ""main.java"" 40]],\r\n  :cause\r\n  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",\r\n  :phase :execution}}\r\n\r\nExecution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).\r\nCould not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name', 'created_at': datetime.datetime(2024, 2, 14, 10, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-08 11:14:47 UTC): Reinstall nodejs

marcinkoziej on (2024-02-09 11:29:07 UTC): @paoliniluis I have the same issue trying to build Metabase via a Gitlab job. How would reinstalling nodejs help with this issue? Are you suggesting some yarn version is necessary for this to build?

paoliniluis on (2024-02-09 12:01:30 UTC): @marcinkoziej please post your entire ci file

marcinkoziej on (2024-02-09 12:03:59 UTC): Here it goes! Nothing unordinary. 
```
image: docker:18-git
services:
  - docker:18-dind

variables:
  CONTAINER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_NAME

before_script:
   - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY

build:
 stage: build
 rules:
   - if: $CI_COMMIT_TAG != null
     when: always
 script:
   - docker build -t $CONTAINER_IMAGE .
   - docker push $CONTAINER_IMAGE
```

marcinkoziej on (2024-02-09 15:47:58 UTC): [paoliniluis](https://github.com/paoliniluis) I changed the timeout in `shell.clj` to 60 minutes, and the build completed after 43minutes. I also needed to make memory limit higher for this build as it was hitting some low memory condition.

Not sure what's the action to be taken here? Should the default be increased?

```
diff --git a/bin/build/src/metabuild_common/shell.clj b/bin/build/src/metabuild_common/shell.clj
index 1373b5843b..278e5178f4 100644
--- a/bin/build/src/metabuild_common/shell.clj
+++ b/bin/build/src/metabuild_common/shell.clj
@@ -22,7 +22,7 @@
       (throw (ex-info (format ""Timed out after %d ms."" timeout-ms) {})))
     result))
 
-(def ^:private command-timeout-ms (* 15 60 1000)) ; 15 minutes
+(def ^:private command-timeout-ms (* 60 60 1000)) ; 60 minutes
 
 (defn sh*
   ""Run a shell command. Like `clojure.java.shell/sh`, but prints output to stdout/stderr and returns a map with keys

```

paoliniluis on (2024-02-09 17:33:33 UTC): Definitely you need to get better runners, this process works flawlessly on our GitHub runners

ghost (Issue Creator) on (2024-02-14 10:33:00 UTC): suddenly getting this error, help me to resolve .              



Downloading: org/mongodb/mongodb-driver-core/3.12.11/mongodb-driver-core-3.12.11.jar from central
{:clojure.main/message
 ""Execution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).\nCould not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name.\n"",
 :clojure.main/triage
 {:clojure.error/class java.io.FileNotFoundException,
  :clojure.error/line 1,
  :clojure.error/cause
  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
  :clojure.error/symbol metabuild-common.aws/eval1459$loading,
  :clojure.error/source ""aws.clj"",
  :clojure.error/phase :execution},
 :clojure.main/trace
 {:via
  [{:type clojure.lang.Compiler$CompilerException,
    :message
    ""Syntax error macroexpanding at (metabuild_common/aws.clj:1:1)."",
    :data
    {:clojure.error/phase :execution,
     :clojure.error/line 1,
     :clojure.error/column 1,
     :clojure.error/source ""metabuild_common/aws.clj""},
    :at [clojure.lang.Compiler load ""Compiler.java"" 7665]}
   {:type java.io.FileNotFoundException,
    :message
    ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
    :at [clojure.lang.RT load ""RT.java"" 462]}],
  :trace
  [[clojure.lang.RT load ""RT.java"" 462]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 482]
   [metabuild_common.aws$eval1459$loading__6789__auto____1460
    invoke
    ""aws.clj""
    1]
   [metabuild_common.aws$eval1459 invokeStatic ""aws.clj"" 1]
   [metabuild_common.aws$eval1459 invoke ""aws.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 805]
   [metabuild_common.core$eval1453$loading__6789__auto____1454
    invoke
    ""core.clj""
    1]
   [metabuild_common.core$eval1453 invokeStatic ""core.clj"" 1]
   [metabuild_common.core$eval1453 invoke ""core.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 421]
   [build_drivers.common$eval234$loading__6789__auto____235
    invoke
    ""common.clj""
    1]
   [build_drivers.common$eval234 invokeStatic ""common.clj"" 1]
   [build_drivers.common$eval234 invoke ""common.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 512]
   [build_drivers.build_driver$eval228$loading__6789__auto____229
    invoke
    ""build_driver.clj""
    1]
   [build_drivers.build_driver$eval228
    invokeStatic
    ""build_driver.clj""
    1]
   [build_drivers.build_driver$eval228 invoke ""build_driver.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
   [build_drivers$eval222$loading__6789__auto____223
    invoke
    ""build_drivers.clj""
    1]
   [build_drivers$eval222 invokeStatic ""build_drivers.clj"" 1]
   [build_drivers$eval222 invoke ""build_drivers.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 1096]
   [build$eval214$loading__6789__auto____215 invoke ""build.clj"" 1]
   [build$eval214 invokeStatic ""build.clj"" 1]
   [build$eval214 invoke ""build.clj"" 1]
   [clojure.lang.Compiler eval ""Compiler.java"" 7194]
   [clojure.lang.Compiler eval ""Compiler.java"" 7183]
   [clojure.lang.Compiler load ""Compiler.java"" 7653]
   [clojure.lang.RT loadResourceScript ""RT.java"" 381]
   [clojure.lang.RT loadResourceScript ""RT.java"" 372]
   [clojure.lang.RT load ""RT.java"" 459]
   [clojure.lang.RT load ""RT.java"" 424]
   [clojure.core$load$fn__6908 invoke ""core.clj"" 6161]
   [clojure.core$load invokeStatic ""core.clj"" 6160]
   [clojure.core$load doInvoke ""core.clj"" 6144]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.core$load_one invokeStatic ""core.clj"" 5933]
   [clojure.core$load_one invoke ""core.clj"" 5928]
   [clojure.core$load_lib$fn__6850 invoke ""core.clj"" 5975]
   [clojure.core$load_lib invokeStatic ""core.clj"" 5974]
   [clojure.core$load_lib doInvoke ""core.clj"" 5953]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 142]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6016]
   [clojure.core$load_libs doInvoke ""core.clj"" 6000]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6038]
   [clojure.core$require doInvoke ""core.clj"" 6038]
   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_
    invokeStatic
    ""exec.clj""
    36]
   [clojure.run.exec$requiring_resolve_SINGLEQUOTE_
    invoke
    ""exec.clj""
    29]
   [clojure.run.exec$exec$fn__151 invoke ""exec.clj"" 44]
   [clojure.run.exec$exec invokeStatic ""exec.clj"" 43]
   [clojure.run.exec$exec doInvoke ""exec.clj"" 39]
   [clojure.lang.RestFn invoke ""RestFn.java"" 423]
   [clojure.run.exec$_main$fn__205 invoke ""exec.clj"" 180]
   [clojure.run.exec$_main invokeStatic ""exec.clj"" 176]
   [clojure.run.exec$_main doInvoke ""exec.clj"" 139]
   [clojure.lang.RestFn invoke ""RestFn.java"" 397]
   [clojure.lang.AFn applyToHelper ""AFn.java"" 152]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
   [clojure.lang.Var applyTo ""Var.java"" 705]
   [clojure.core$apply invokeStatic ""core.clj"" 667]
   [clojure.main$main_opt invokeStatic ""main.clj"" 514]
   [clojure.main$main_opt invoke ""main.clj"" 510]
   [clojure.main$main invokeStatic ""main.clj"" 664]
   [clojure.main$main doInvoke ""main.clj"" 616]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
   [clojure.lang.Var applyTo ""Var.java"" 705]
   [clojure.main main ""main.java"" 40]],
  :cause
  ""Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name."",
  :phase :execution}}

Execution error (FileNotFoundException) at metabuild-common.aws/eval1459$loading (aws.clj:1).
Could not locate metabuild_common/shell__init.class, metabuild_common/shell.clj or metabuild_common/shell.cljc on classpath. Please check that namespaces with dashes use underscores in the Clojure file name

"
2124176248,issue,closed,not_planned,Dropping Column from Underlying Table Breaks GUI Editor,"### Describe the bug

When a question created using the GUI editor (not the native sql editor) is trying to select a column that has been been dropped from the underlying table the question breaks (this part makes sense) but the `Show editor` also breaks. Ideally one could click into the `Show editor` button so as to remove the now missing column thus fixing the query. 

### To Reproduce

1. Create a question using the custom/GUI editor which selects column A from table B
2. Drop column A from table B 
3. <img width=""729"" alt=""Screenshot 2024-02-07 at 17 56 39"" src=""https://github.com/metabase/metabase/assets/31943456/c783f55d-655d-4972-8d75-7b5871812df2"">
4. Click the show editor button on the question
<img width=""659"" alt=""Screenshot 2024-02-07 at 17 56 44"" src=""https://github.com/metabase/metabase/assets/31943456/e5643a4e-ae02-4201-969f-f340deefd14e"">



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser: Version 1.57.57 Chromium: 116.0.5845.163 (Official Build) (x86_64)
- Metabase Version: You're on version v1.48.3
```


### Severity

Medium

### Additional context

_No response_",sambradbury,2024-02-08 01:01:57+00:00,[],2024-06-26 03:13:34+00:00,2024-06-26 03:13:33+00:00,https://github.com/metabase/metabase/issues/38538,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Querying/MBQL', ''), ('.Backend', '')]","[{'comment_id': 1957168947, 'issue_id': 2124176248, 'author': 'ignacio-mb', 'body': ""Hi @sambradbury I couldn't reproduce. My steps were:\r\n\r\n1. Have a table in Postgres called Countries with fields: Id, Country\r\n2. Make a GUI query basic all from Countries.\r\n3. Save the question\r\n4. Go to the database, run `ALTER TABLE countries DROP COLUMN Country;`\r\n5. Go to the question, see the error \r\n> column countries.country does not exist\r\n6. Click Editor button, I can access the query editor. \r\n\r\nWhat am I missing?"", 'created_at': datetime.datetime(2024, 2, 21, 16, 19, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 1957170114, 'issue_id': 2124176248, 'author': 'ignacio-mb', 'body': 'related to https://github.com/metabase/metabase/issues/12721', 'created_at': datetime.datetime(2024, 2, 21, 16, 19, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119921723, 'issue_id': 2124176248, 'author': 'kamilmielnik', 'body': '> What am I missing?\r\n\r\nDatabase schema needs to be resynced in Admin > Databases after dropping the column.\r\nWith this I can reproduce the issue.\r\n\r\nThe notebook editor does not crash anymore but it\'s not possible to fix the query manually because the missing column isn\'t shown.\r\n\r\n----\r\n\r\nAutomatically fixing such cases would not always be possible due to edge cases (e.g. the only column from a query has been dropped) so it feels ok to leave it to the users to fix them.\r\n\r\nFrom technical perspective we\'d need to change MLv2 behavior a bit, so that functions like `Lib.visibleColumns` would return query columns that aren\'t present in the metadata (so all `Lib.*Columns` functions). We wouldn\'t be able to display names of those columns in UI though (since they\'re not in metadata anymore) but I think it\'s ok if we displayed them as ""Unknown column"" or something like that - just enough to let users fix the query.\r\n\r\nThis definitely needs QP changes (and possibly QC changes depending on what QP changes would look like) so I\'m sending this issue that way.', 'created_at': datetime.datetime(2024, 5, 20, 8, 17, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190467229, 'issue_id': 2124176248, 'author': 'camsaul', 'body': 'Duplicate of #38532', 'created_at': datetime.datetime(2024, 6, 26, 3, 13, 33, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-02-21 16:19:05 UTC): Hi @sambradbury I couldn't reproduce. My steps were:

1. Have a table in Postgres called Countries with fields: Id, Country
2. Make a GUI query basic all from Countries.
3. Save the question
4. Go to the database, run `ALTER TABLE countries DROP COLUMN Country;`
5. Go to the question, see the error 
6. Click Editor button, I can access the query editor. 

What am I missing?

ignacio-mb on (2024-02-21 16:19:25 UTC): related to https://github.com/metabase/metabase/issues/12721

kamilmielnik on (2024-05-20 08:17:36 UTC): Database schema needs to be resynced in Admin > Databases after dropping the column.
With this I can reproduce the issue.

The notebook editor does not crash anymore but it's not possible to fix the query manually because the missing column isn't shown.

----

Automatically fixing such cases would not always be possible due to edge cases (e.g. the only column from a query has been dropped) so it feels ok to leave it to the users to fix them.

From technical perspective we'd need to change MLv2 behavior a bit, so that functions like `Lib.visibleColumns` would return query columns that aren't present in the metadata (so all `Lib.*Columns` functions). We wouldn't be able to display names of those columns in UI though (since they're not in metadata anymore) but I think it's ok if we displayed them as ""Unknown column"" or something like that - just enough to let users fix the query.

This definitely needs QP changes (and possibly QC changes depending on what QP changes would look like) so I'm sending this issue that way.

camsaul on (2024-06-26 03:13:33 UTC): Duplicate of #38532

"
2124128501,issue,closed,completed,Add Ability For Default Value of NULL in Actions,"**Is your feature request related to a problem? Please describe.**
Currently, there doesn't seem to be a way to support optionally NULL fields for Actions that implement an INSERT statement. 

**Describe the solution you'd like**
A way to default to NULL if a value was not specified by the user. Perhaps just a checkbox that says ""Use NULL if not provided"".

**Describe alternatives you've considered**
It may also be possible to implement the functionality to just specify the default value inside the SQL somewhere.

**How important is this feature to you?**
It would increase the usefulness of actions (which are already super useful- you guys are awesome).

**Additional context**
Considering the following table:
```
CREATE TABLE rates.cost_code (
    id SERIAL            PRIMARY KEY,
    date                 DATE,
    project_id           BIGINT NOT NULL,
    project_attribute_id BIGINT NOT NULL,
    subjob_id            BIGINT,
    phase_id             BIGINT NOT NULL,
    rate                 MONEY NOT NULL,
    total_quantity       INT,
    total_cost           MONEY,
    note                 VARCHAR,

    CONSTRAINT uniq_cost_code_rates UNIQUE NULLS NOT DISTINCT (project_id, project_attribute_id, subjob_id, phase_id),
    FOREIGN KEY(project_id)           REFERENCES projects.project(id),
    FOREIGN KEY(project_attribute_id) REFERENCES projects.project_attribute(id),
    FOREIGN KEY(subjob_id)            REFERENCES wbs.subjob(id),
    FOREIGN KEY(phase_id)             REFERENCES wbs.phase(id)
);
```
This was my attempted approach to building the action:
```
INSERT INTO rates.cost_code (
    date,
    project_id,
    project_attribute_id,
    subjob_id,
    phase_id,
    rate,
    total_quantity,
    total_cost,
    note
) VALUES (
    [[ {{ date }} --]]NULL
    , (SELECT id from projects.project WHERE name = {{ project }})
    , (SELECT id from projects.attribute WHERE name = {{ project_attribute }})
    , [[ (SELECT COALESCE(id, -1) from wbs.subjob WHERE name = {{ subjob }}) --]]NULL
    , (SELECT id from wbs.phase WHERE pretty_name = {{ phase }}
    , {{ rate }}
    , [[ {{ total_quantity }} --]]NULL
    , [[ {{ total_cost }} --]]NULL
    , [[ {{ note }} --]]NULL
);
```

The idea was that values would be NULL if unspecified.

```
# outputs
Error executing Action: Error executing write query: ERROR: syntax error at or near "","" Position: 371
```

I am using Postgres.",MrChadMWood,2024-02-08 00:09:53+00:00,[],2024-02-08 16:10:29+00:00,2024-02-08 16:10:12+00:00,https://github.com/metabase/metabase/issues/38536,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 1934413617, 'issue_id': 2124128501, 'author': 'MrChadMWood', 'body': ""By the way, I didn't see anything like this in the documentation. Here's an approach that can be used to update a records fields arbitrarily. The only required value is the record `id`, which can be displayed in the model.\r\n```\r\nUPDATE rates.cost_code\r\nSET id = {{ record_id }}\r\n    [[, date = {{ date }}]]\r\n    [[, rate = {{ rate }}]]\r\n    [[, total_quantity = {{ total_quantity }}]]\r\n    [[, total_cost = {{ total_cost }}]]\r\n    [[, note = {{ note }}]]\r\nWHERE\r\n    id = {{ record_id }};\r\n```\r\n\r\nYou just take the required field and set it to its old value. `id` works good because in practice it should never need to be updated. Columns with similar logic can probably work just as good."", 'created_at': datetime.datetime(2024, 2, 8, 15, 49, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934455911, 'issue_id': 2124128501, 'author': 'MrChadMWood', 'body': 'UPDATE:\r\n\r\nThis was user error. I forgot a "")""\r\n\r\n` , (SELECT id from wbs.phase WHERE pretty_name = {{ phase }})`\r\n\r\nThis is extremely powerful. Thank you for this feature, Metabase team.', 'created_at': datetime.datetime(2024, 2, 8, 16, 10, 7, tzinfo=datetime.timezone.utc)}]","MrChadMWood (Issue Creator) on (2024-02-08 15:49:18 UTC): By the way, I didn't see anything like this in the documentation. Here's an approach that can be used to update a records fields arbitrarily. The only required value is the record `id`, which can be displayed in the model.
```
UPDATE rates.cost_code
SET id = {{ record_id }}
    [[, date = {{ date }}]]
    [[, rate = {{ rate }}]]
    [[, total_quantity = {{ total_quantity }}]]
    [[, total_cost = {{ total_cost }}]]
    [[, note = {{ note }}]]
WHERE
    id = {{ record_id }};
```

You just take the required field and set it to its old value. `id` works good because in practice it should never need to be updated. Columns with similar logic can probably work just as good.

MrChadMWood (Issue Creator) on (2024-02-08 16:10:07 UTC): UPDATE:

This was user error. I forgot a "")""

` , (SELECT id from wbs.phase WHERE pretty_name = {{ phase }})`

This is extremely powerful. Thank you for this feature, Metabase team.

"
2124093862,issue,open,,[dc.js migration] trend line is incorrect on stacked charts,"http://localhost:6006/?path=/story/static-viz-combochart--trend-multi-series-stacked-bar

<img width=""531"" alt=""Screenshot 2024-02-07 at 3 38 29 PM"" src=""https://github.com/metabase/metabase/assets/37751258/13f6f051-9de2-43b9-bd71-92c313817a3e"">

Both lines look incorrect. I think the insights object should be fixed on the backend, so that it accounts for one series being stacked on top of the other, and it knows the stack order (e.g. first series on bottom).",EmmadUsmani,2024-02-07 23:38:00+00:00,[],2024-02-12 17:52:48+00:00,,https://github.com/metabase/metabase/issues/38535,"[('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.')]","[{'comment_id': 1939242410, 'issue_id': 2124093862, 'author': 'alxnddr', 'body': '@EmmadUsmani this does not look like an echarts regression', 'created_at': datetime.datetime(2024, 2, 12, 17, 52, 47, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-02-12 17:52:47 UTC): @EmmadUsmani this does not look like an echarts regression

"
2124052456,issue,open,,"Visibility into ""Fields in Use"" across Metabase in ""Metabase Analytics""","**Is your feature request related to a problem? Please describe.**
It would be great if we could view a list of all fields currently in use in Metabase. This information would be invaluable to provide to data engineers to help prevent schema changes that could impact Metabase cards.

**Describe the solution you'd like**
A card in Metabase Analytics that displays all fields in active use, their source table and ideally a mechanism for getting to the cards that refer to them.

**Describe alternatives you've considered**
Getting this data via the API or from the application database. A custom script would need to be written to parse the API results and Cloud customers do not have access to the application database.

**Additional context**
Internal ticket #24760
",ixipixi,2024-02-07 23:06:02+00:00,[],2024-02-21 16:10:28+00:00,,https://github.com/metabase/metabase/issues/38533,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2124028348,issue,closed,not_planned,"Cannot Access Notebook Editor if ""Group By"" Field is Dropped","### Describe the bug

If  a GUI question is grouped by a field, that field is dropped from the database and DB sync is performed, you cannot modify the ""Group By"" field via the notebook editor.

### To Reproduce

Reproduced with BigQuery and MySQL:

- Create a Question that joins two tables
- Group the data by any field
- Delete the field that you grouped by from the DW
- Run a database sync
- Try to edit the question
- Sometimes the notebook will load on the first try but if you exit and come back it may not

Similarly:

- Create a Question from a single table
- Group the data by any field
- Delete the field that you grouped by from the DW
- Run a database sync
- In this case the editor loads but you cannot remove the group by field from the ""Pick a Column to Group By"" box (you can work around it by removing the entire summary and starting over)


### Expected behavior

You should be able to modify the Question and Remove the offending Field

### Logs

[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:09-06:00 DEBUG metabase.server.middleware.log GET /api/table/26/query_metadata 200 29.0 ms (9 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:10-06:00 WARN metabase.driver.sql.query-processor.deprecated Warning: Driver :bigquery-cloud-sdk is using Honey SQL 1. This method was deprecated in 0.46.0 and will be removed in a future release.
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:10-06:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: 400 Bad Request
POST https://www.googleapis.com/bigquery/v2/projects/metabase-398400/queries
{
  ""code"": 400,
  ""errors"": [
    {
      ""domain"": ""global"",
      ""location"": ""q"",
      ""locationType"": ""parameter"",
      ""message"": ""Name Created_At not found inside sample.Orders at [2:40]"",
      ""reason"": ""invalidQuery""
    }
  ],
  ""message"": ""Name Created_At not found inside sample.Orders at [2:40]"",
  ""status"": ""INVALID_ARGUMENT""
}
{:database_id 13371339,
 :started_at #t ""2024-02-07T22:46:10.277647Z[GMT]"",
 :via
 [{:status :failed,
   :class com.google.cloud.bigquery.BigQueryException,
   :error ""Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:114)""
    ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:728)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
    ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
    ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
    ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__114973.invoke(bigquery_cloud_sdk.clj:274)""]}
  {:status :failed,
   :class java.util.concurrent.ExecutionException,
   :error ""com.google.cloud.bigquery.BigQueryException: Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""java.base/java.util.concurrent.FutureTask.report(Unknown Source)""
    ""java.base/java.util.concurrent.FutureTask.get(Unknown Source)""
    ""clojure.core$deref_future.invokeStatic(core.clj:2317)""
    ""clojure.core$future_call$reify__8544.deref(core.clj:7041)""
    ""clojure.core$deref.invokeStatic(core.clj:2337)""
    ""clojure.core$deref.invoke(core.clj:2323)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:262)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:258)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:303)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:301)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__115017.invoke(bigquery_cloud_sdk.clj:351)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:359)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:344)""
    ""driver.bigquery_cloud_sdk$fn__115023.invokeStatic(bigquery_cloud_sdk.clj:379)""
    ""driver.bigquery_cloud_sdk$fn__115023.invoke(bigquery_cloud_sdk.clj:371)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71642.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65605.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__105865$check_download_permissions__105866$fn__105867.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71463.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__107530$maybe_apply_column_level_perms_check__107531$fn__107532.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71473.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70710.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__72770$combined_post_process__72775$combined_post_process_STAR___72776.invoke(query_processor.clj:261)""
    ""query_processor$fn__72770$combined_pre_process__72771$combined_pre_process_STAR___72772.invoke(query_processor.clj:258)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65702.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553$fn__71557.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__66109$fn__66110.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__66109.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71550.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71855.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__79135$handle_audit_app_internal_queries__79136$fn__79138.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71501.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$add_default_userland_constraints$fn__68599.invoke(constraints.clj:81)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71786.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72374.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___61150$thunk__61152.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___61150.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___61162.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:401)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:397)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:415)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:405)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:430)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:420)""
    ""api.dataset$run_query_async$fn__95443.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724$fn__51726.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43056.invoke(streaming_response.clj:88)""]}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: com.google.cloud.bigquery.BigQueryException: Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""--> driver.bigquery_cloud_sdk$throw_invalid_query.invokeStatic(bigquery_cloud_sdk.clj:254)""
    ""driver.bigquery_cloud_sdk$throw_invalid_query.invoke(bigquery_cloud_sdk.clj:253)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:299)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:258)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:303)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:301)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__115017.invoke(bigquery_cloud_sdk.clj:351)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:359)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:344)""
    ""driver.bigquery_cloud_sdk$fn__115023.invokeStatic(bigquery_cloud_sdk.clj:379)""
    ""driver.bigquery_cloud_sdk$fn__115023.invoke(bigquery_cloud_sdk.clj:371)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71642.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65605.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__105865$check_download_permissions__105866$fn__105867.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71463.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__107530$maybe_apply_column_level_perms_check__107531$fn__107532.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71473.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70710.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__72770$combined_post_process__72775$combined_post_process_STAR___72776.invoke(query_processor.clj:261)""
    ""query_processor$fn__72770$combined_pre_process__72771$combined_pre_process_STAR___72772.invoke(query_processor.clj:258)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65702.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553$fn__71557.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__66109$fn__66110.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__66109.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71550.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71855.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__79135$handle_audit_app_internal_queries__79136$fn__79138.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71501.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$add_default_userland_constraints$fn__68599.invoke(constraints.clj:81)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71786.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72374.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___61150$thunk__61152.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___61150.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___61162.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:401)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:397)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:415)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:405)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:430)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:420)""
    ""api.dataset$run_query_async$fn__95443.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724$fn__51726.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43056.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:type :invalid-query,
    :sql
    ""-- Metabase:: userID: 13371339 queryType: MBQL queryHash: e175b2684d5cd04ae108a704a8e991126ad61f9efcd7f811b73794db760bcbc3\nSELECT timestamp_trunc(`sample.Orders`.`Created_At`, month) AS `Created_At`, sum(`sample.Orders`.`Product_ID`) AS `sum`, sum(CASE WHEN `sample.Orders`.`User_ID` = 1 THEN `sample.Orders`.`User_ID` ELSE 0.0 END) AS `sumif_test` FROM `sample.Orders` LEFT JOIN `sample.Orders` `Orders` ON `sample.Orders`.`ID` = `Orders`.`ID` GROUP BY `Created_At` ORDER BY `Created_At` ASC"",
    :parameters nil}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 13371339,
  :query
  {:aggregation
   [[""sum"" [""field"" 276 {:base-type ""type/Integer""}]]
    [""aggregation-options""
     [""sum-where"" [""field"" 275 {:base-type ""type/Integer""}] [""="" [""field"" 275 {:base-type ""type/Integer""}] 1]]
     {:display-name ""sumif_test"", :name ""sumif_test""}]],
   :breakout [[""field"" 277 {:base-type ""type/DateTimeWithLocalTZ"", :temporal-unit ""month""}]],
   :joins
   [{:alias ""Orders"",
     :condition
     [""="" [""field"" 279 {:base-type ""type/Integer""}] [""field"" 279 {:base-type ""type/Integer"", :join-alias ""Orders""}]],
     :fields ""all"",
     :source-table 26,
     :strategy ""left-join""}],
   :source-table 26},
  :type ""query"",
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT timestamp_trunc(`sample.Orders`.`Created_At`, month) AS `Created_At`, sum(`sample.Orders`.`Product_ID`) AS `sum`, sum(CASE WHEN `sample.Orders`.`User_ID` = 1 THEN `sample.Orders`.`User_ID` ELSE 0.0 END) AS `sumif_test` FROM `sample.Orders` LEFT JOIN `sample.Orders` `Orders` ON `sample.Orders`.`ID` = `Orders`.`ID` GROUP BY `Created_At` ORDER BY `Created_At` ASC"",
  :params nil,
  :table-name ""Orders"",
  :mbql? true},
 :status :failed,
 :class com.google.api.client.googleapis.json.GoogleJsonResponseException,
 :stacktrace
 [""com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest$3.interceptResponse(AbstractGoogleClientRequest.java:466)""
  ""com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:552)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:493)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:603)""
  ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:726)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
  ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
  ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
  ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
  ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__114973.invoke(bigquery_cloud_sdk.clj:274)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""400 Bad Request\nPOST https://www.googleapis.com/bigquery/v2/projects/metabase-398400/queries\n{\n  \""code\"": 400,\n  \""errors\"": [\n    {\n      \""domain\"": \""global\"",\n      \""location\"": \""q\"",\n      \""locationType\"": \""parameter\"",\n      \""message\"": \""Name Created_At not found inside sample.Orders at [2:40]\"",\n      \""reason\"": \""invalidQuery\""\n    }\n  ],\n  \""message\"": \""Name Created_At not found inside sample.Orders at [2:40]\"",\n  \""status\"": \""INVALID_ARGUMENT\""\n}"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 13371339,
  :query
  {:aggregation
   [[:aggregation-options [:sum [:field 276 {:base-type :type/Integer}]] {:name ""sum""}]
    [:aggregation-options
     [:sum-where
      [:field 275 {:base-type :type/Integer}]
      [:=
       [:field 275 {:base-type :type/Integer}]
       [:value
        1
        {:base_type :type/Integer,
         :effective_type :type/Integer,
         :coercion_strategy nil,
         :semantic_type nil,
         :database_type ""INTEGER"",
         :name ""User_ID""}]]]
     {:display-name ""sumif_test"", :name ""sumif_test""}]],
   :breakout [[:field 277 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :month}]],
   :source-table 26,
   :order-by [[:asc [:field 277 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :month}]]],
   :joins
   [{:alias ""Orders"",
     :strategy :left-join,
     :condition
     [:= [:field 279 {:base-type :type/Integer}] [:field 279 {:base-type :type/Integer, :join-alias ""Orders""}]],
     :fields
     [[:field 279 {:join-alias ""Orders""}]
      [:field 276 {:join-alias ""Orders""}]
      [:field 274 {:join-alias ""Orders""}]
      [:field 280 {:join-alias ""Orders""}]
      [:field 282 {:join-alias ""Orders""}]
      [:field 281 {:join-alias ""Orders""}]
      [:field 278 {:join-alias ""Orders""}]],
     :source-table 26}]},
  :type :query,
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 13371339, :context :ad-hoc}},
 :data {:rows [], :cols []}}

[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:10-06:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 599.3 ms (16 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 1 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:10-06:00 DEBUG metabase.server.middleware.log GET /api/database/13371339 200 5.9 ms (3 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 17.9 ms (7 DB calls) App DB connections: 1/15 Jetty threads: 7/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 20.4 ms (11 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/collection/root 200 7.3 ms (2 DB calls) App DB connections: 2/15 Jetty threads: 10/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/bookmark 200 2.5 ms (1 DB calls) App DB connections: 1/15 Jetty threads: 9/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/database 200 7.2 ms (3 DB calls) App DB connections: 2/15 Jetty threads: 8/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 3.4 ms (1 DB calls) App DB connections: 2/15 Jetty threads: 8/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 14.0 ms (6 DB calls) App DB connections: 1/15 Jetty threads: 7/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/search 200 29.3 ms (5 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (6 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 6.7 ms (3 DB calls) App DB connections: 1/15 Jetty threads: 8/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/card/88 200 54.0 ms (15 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/database/13371339/schemas 200 7.4 ms (4 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 DEBUG metabase.server.middleware.log GET /api/table/26/query_metadata 200 20.7 ms (9 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:25-06:00 WARN metabase.driver.sql.query-processor.deprecated Warning: Driver :bigquery-cloud-sdk is using Honey SQL 1. This method was deprecated in 0.46.0 and will be removed in a future release.
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:26-06:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: 400 Bad Request
POST https://www.googleapis.com/bigquery/v2/projects/metabase-398400/queries
{
  ""code"": 400,
  ""errors"": [
    {
      ""domain"": ""global"",
      ""location"": ""q"",
      ""locationType"": ""parameter"",
      ""message"": ""Name Created_At not found inside sample.Orders at [2:40]"",
      ""reason"": ""invalidQuery""
    }
  ],
  ""message"": ""Name Created_At not found inside sample.Orders at [2:40]"",
  ""status"": ""INVALID_ARGUMENT""
}
{:database_id 13371339,
 :started_at #t ""2024-02-07T22:46:25.775603Z[GMT]"",
 :via
 [{:status :failed,
   :class com.google.cloud.bigquery.BigQueryException,
   :error ""Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:114)""
    ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:728)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
    ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
    ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
    ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__114973.invoke(bigquery_cloud_sdk.clj:274)""]}
  {:status :failed,
   :class java.util.concurrent.ExecutionException,
   :error ""com.google.cloud.bigquery.BigQueryException: Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""java.base/java.util.concurrent.FutureTask.report(Unknown Source)""
    ""java.base/java.util.concurrent.FutureTask.get(Unknown Source)""
    ""clojure.core$deref_future.invokeStatic(core.clj:2317)""
    ""clojure.core$future_call$reify__8544.deref(core.clj:7041)""
    ""clojure.core$deref.invokeStatic(core.clj:2337)""
    ""clojure.core$deref.invoke(core.clj:2323)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:262)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:258)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:303)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:301)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__115017.invoke(bigquery_cloud_sdk.clj:351)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:359)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:344)""
    ""driver.bigquery_cloud_sdk$fn__115023.invokeStatic(bigquery_cloud_sdk.clj:379)""
    ""driver.bigquery_cloud_sdk$fn__115023.invoke(bigquery_cloud_sdk.clj:371)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71642.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65605.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__105865$check_download_permissions__105866$fn__105867.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71463.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__107530$maybe_apply_column_level_perms_check__107531$fn__107532.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71473.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70710.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__72770$combined_post_process__72775$combined_post_process_STAR___72776.invoke(query_processor.clj:261)""
    ""query_processor$fn__72770$combined_pre_process__72771$combined_pre_process_STAR___72772.invoke(query_processor.clj:258)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65702.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553$fn__71557.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__66109$fn__66110.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__66109.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71550.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71855.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__79135$handle_audit_app_internal_queries__79136$fn__79138.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71501.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$add_default_userland_constraints$fn__68599.invoke(constraints.clj:81)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71786.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72374.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___61150$thunk__61152.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___61150.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___61162.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:401)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:397)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:415)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:405)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:430)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:420)""
    ""api.dataset$run_query_async$fn__95443.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724$fn__51726.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43056.invoke(streaming_response.clj:88)""]}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: com.google.cloud.bigquery.BigQueryException: Name Created_At not found inside sample.Orders at [2:40]"",
   :stacktrace
   [""--> driver.bigquery_cloud_sdk$throw_invalid_query.invokeStatic(bigquery_cloud_sdk.clj:254)""
    ""driver.bigquery_cloud_sdk$throw_invalid_query.invoke(bigquery_cloud_sdk.clj:253)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:299)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:258)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:303)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:301)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__115017.invoke(bigquery_cloud_sdk.clj:351)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:359)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:344)""
    ""driver.bigquery_cloud_sdk$fn__115023.invokeStatic(bigquery_cloud_sdk.clj:379)""
    ""driver.bigquery_cloud_sdk$fn__115023.invoke(bigquery_cloud_sdk.clj:371)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71642.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65605.invoke(permissions.clj:140)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__105865$check_download_permissions__105866$fn__105867.invoke(permissions.clj:127)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71463.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__107530$maybe_apply_column_level_perms_check__107531$fn__107532.invoke(column_level_perms_check.clj:33)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71473.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70710.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__72770$combined_post_process__72775$combined_post_process_STAR___72776.invoke(query_processor.clj:261)""
    ""query_processor$fn__72770$combined_pre_process__72771$combined_pre_process_STAR___72772.invoke(query_processor.clj:258)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65702.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553$fn__71557.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71553.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__66109$fn__66110.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__66109.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71550.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71855.invoke(normalize_query.clj:38)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__79135$handle_audit_app_internal_queries__79136$fn__79138.invoke(handle_audit_queries.clj:142)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71501.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$add_default_userland_constraints$fn__68599.invoke(constraints.clj:81)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71786.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72374.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___61150$thunk__61152.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___61150.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___61162.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:401)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:397)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:415)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:405)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:430)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:420)""
    ""api.dataset$run_query_async$fn__95443.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724$fn__51726.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51724.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43056.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:type :invalid-query,
    :sql
    ""-- Metabase:: userID: 13371339 queryType: MBQL queryHash: e175b2684d5cd04ae108a704a8e991126ad61f9efcd7f811b73794db760bcbc3\nSELECT timestamp_trunc(`sample.Orders`.`Created_At`, month) AS `Created_At`, sum(`sample.Orders`.`Product_ID`) AS `sum`, sum(CASE WHEN `sample.Orders`.`User_ID` = 1 THEN `sample.Orders`.`User_ID` ELSE 0.0 END) AS `sumif_test` FROM `sample.Orders` LEFT JOIN `sample.Orders` `Orders` ON `sample.Orders`.`ID` = `Orders`.`ID` GROUP BY `Created_At` ORDER BY `Created_At` ASC"",
    :parameters nil}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 13371339,
  :query
  {:aggregation
   [[""sum"" [""field"" 276 {:base-type ""type/Integer""}]]
    [""aggregation-options""
     [""sum-where"" [""field"" 275 {:base-type ""type/Integer""}] [""="" [""field"" 275 {:base-type ""type/Integer""}] 1]]
     {:display-name ""sumif_test"", :name ""sumif_test""}]],
   :breakout [[""field"" 277 {:base-type ""type/DateTimeWithLocalTZ"", :temporal-unit ""month""}]],
   :joins
   [{:alias ""Orders"",
     :condition
     [""="" [""field"" 279 {:base-type ""type/Integer""}] [""field"" 279 {:base-type ""type/Integer"", :join-alias ""Orders""}]],
     :fields ""all"",
     :source-table 26,
     :strategy ""left-join""}],
   :source-table 26},
  :type ""query"",
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT timestamp_trunc(`sample.Orders`.`Created_At`, month) AS `Created_At`, sum(`sample.Orders`.`Product_ID`) AS `sum`, sum(CASE WHEN `sample.Orders`.`User_ID` = 1 THEN `sample.Orders`.`User_ID` ELSE 0.0 END) AS `sumif_test` FROM `sample.Orders` LEFT JOIN `sample.Orders` `Orders` ON `sample.Orders`.`ID` = `Orders`.`ID` GROUP BY `Created_At` ORDER BY `Created_At` ASC"",
  :params nil,
  :table-name ""Orders"",
  :mbql? true},
 :status :failed,
 :class com.google.api.client.googleapis.json.GoogleJsonResponseException,
 :stacktrace
 [""com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest$3.interceptResponse(AbstractGoogleClientRequest.java:466)""
  ""com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:552)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:493)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:603)""
  ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:726)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
  ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
  ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
  ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
  ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__114973.invoke(bigquery_cloud_sdk.clj:274)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""400 Bad Request\nPOST https://www.googleapis.com/bigquery/v2/projects/metabase-398400/queries\n{\n  \""code\"": 400,\n  \""errors\"": [\n    {\n      \""domain\"": \""global\"",\n      \""location\"": \""q\"",\n      \""locationType\"": \""parameter\"",\n      \""message\"": \""Name Created_At not found inside sample.Orders at [2:40]\"",\n      \""reason\"": \""invalidQuery\""\n    }\n  ],\n  \""message\"": \""Name Created_At not found inside sample.Orders at [2:40]\"",\n  \""status\"": \""INVALID_ARGUMENT\""\n}"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 13371339,
  :query
  {:aggregation
   [[:aggregation-options [:sum [:field 276 {:base-type :type/Integer}]] {:name ""sum""}]
    [:aggregation-options
     [:sum-where
      [:field 275 {:base-type :type/Integer}]
      [:=
       [:field 275 {:base-type :type/Integer}]
       [:value
        1
        {:base_type :type/Integer,
         :effective_type :type/Integer,
         :coercion_strategy nil,
         :semantic_type nil,
         :database_type ""INTEGER"",
         :name ""User_ID""}]]]
     {:display-name ""sumif_test"", :name ""sumif_test""}]],
   :breakout [[:field 277 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :month}]],
   :source-table 26,
   :order-by [[:asc [:field 277 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :month}]]],
   :joins
   [{:alias ""Orders"",
     :strategy :left-join,
     :condition
     [:= [:field 279 {:base-type :type/Integer}] [:field 279 {:base-type :type/Integer, :join-alias ""Orders""}]],
     :fields
     [[:field 279 {:join-alias ""Orders""}]
      [:field 276 {:join-alias ""Orders""}]
      [:field 274 {:join-alias ""Orders""}]
      [:field 280 {:join-alias ""Orders""}]
      [:field 282 {:join-alias ""Orders""}]
      [:field 281 {:join-alias ""Orders""}]
      [:field 278 {:join-alias ""Orders""}]],
     :source-table 26}]},
  :type :query,
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 13371339, :context :ad-hoc}},
 :data {:rows [], :cols []}}

[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:26-06:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 509.7 ms (16 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:26-06:00 DEBUG metabase.server.middleware.log GET /api/database/13371339 200 7.6 ms (3 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:34-06:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 3.0 ms (1 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)
[1ae949fd-1c60-48d5-bda4-71b06d5b6e0c] 2024-02-07T16:46:34-06:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 2.9 ms (1 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (7 idle, 0 queued) (150 total active threads) Queries in flight: 0 (0 queued)

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.2.0""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v1.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

The user had to recreate the question - this could be a significant issue for a customer for whom many downstream Questions were impacted.

### Additional context

https://metabase.zendesk.com/agent/tickets/24585",ixipixi,2024-02-07 22:47:43+00:00,[],2024-06-26 03:27:24+00:00,2024-06-26 03:24:58+00:00,https://github.com/metabase/metabase/issues/38532,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder')]","[{'comment_id': 2190476031, 'issue_id': 2124028348, 'author': 'camsaul', 'body': 'Duplicate of #10371', 'created_at': datetime.datetime(2024, 6, 26, 3, 24, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2190480327, 'issue_id': 2124028348, 'author': 'camsaul', 'body': 'To clarify #10371 is about making sure the Notebook Editor lets you edit questions that have columns that no longer exist, not about removing them automatically in the QP when you attempt to run those queries. We are tracking that issue separately in https://github.com/metabase/metabase/issues/12721', 'created_at': datetime.datetime(2024, 6, 26, 3, 27, 23, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-06-26 03:24:58 UTC): Duplicate of #10371

camsaul on (2024-06-26 03:27:23 UTC): To clarify #10371 is about making sure the Notebook Editor lets you edit questions that have columns that no longer exist, not about removing them automatically in the QP when you attempt to run those queries. We are tracking that issue separately in https://github.com/metabase/metabase/issues/12721

"
2123623664,issue,closed,completed,Update auditv2 content for 49,"**Context**
- [x] Join query into query_execution (modeling)
- [x] Replace external with anonymous group
- [x] Do something about API key users
- [x] Check if dashboard overview works well with embedding data",luizarakaki,2024-02-07 18:24:24+00:00,['luizarakaki'],2024-02-09 14:46:16+00:00,2024-02-09 14:46:15+00:00,https://github.com/metabase/metabase/issues/38524,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2123619088,issue,open,,Field picker in query builder isn't consistent with Model column order,"### Describe the bug

-

### To Reproduce

1. Create model > Sample database > Orders > Save
2. Edit metadata > Move ID column to another position > Save
![image](https://github.com/metabase/metabase/assets/32561114/64580efc-0885-4a6a-804f-32bbf18e42a8)
ID in 4th position: makes sense
![image](https://github.com/metabase/metabase/assets/32561114/00b7d114-25ca-40e6-8d87-ff3f0104b026)
ID in 4th position: makes sense
![image](https://github.com/metabase/metabase/assets/32561114/c34756f8-69dd-477c-b2be-5da322fa8ac6)
ID in first position: wrong position

This is a problem in large models with many ordered columns like [this](https://stats.metabase.com/model/13342-cloud-admins-for-research)

### Expected behavior

Show the same column order in field picker

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master
```


### Severity

P2

### Additional context

One of the main benefits of Models is adding relevant metadata like column ordering. This reduces the value of the feature and causes frustration as it is expected that the column order will be preserved everywhere.",luizarakaki,2024-02-07 18:21:50+00:00,[],2025-02-04 20:31:08+00:00,,https://github.com/metabase/metabase/issues/38523,"[('Querying/MBQL', ''), ('Type:New Feature', ''), ('Difficulty:Hard', ''), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2221209913, 'issue_id': 2123619088, 'author': 'ranquild', 'body': 'The model column order is a viz-setting only thing. It cannot be ""fixed"" using the existing approach. We should check if we can change the order of columns in `result_metadata` instead.', 'created_at': datetime.datetime(2024, 7, 10, 18, 51, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528976871, 'issue_id': 2123619088, 'author': 'ixipixi', 'body': ""This has come up a few times again recently (in the context of drill throughs). It really does kill the ergonomics of models that this information isn't persisted throughout the product."", 'created_at': datetime.datetime(2024, 12, 9, 18, 12, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529037140, 'issue_id': 2123619088, 'author': 'Mackey22', 'body': '+1 - would really love to see this fixed!', 'created_at': datetime.datetime(2024, 12, 9, 18, 30, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627610698, 'issue_id': 2123619088, 'author': 'mngr', 'body': 'This will change when we make models like tables', 'created_at': datetime.datetime(2025, 1, 31, 15, 24, 18, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-10 18:51:32 UTC): The model column order is a viz-setting only thing. It cannot be ""fixed"" using the existing approach. We should check if we can change the order of columns in `result_metadata` instead.

ixipixi on (2024-12-09 18:12:22 UTC): This has come up a few times again recently (in the context of drill throughs). It really does kill the ergonomics of models that this information isn't persisted throughout the product.

Mackey22 on (2024-12-09 18:30:52 UTC): +1 - would really love to see this fixed!

mngr on (2025-01-31 15:24:18 UTC): This will change when we make models like tables

"
2123487263,issue,closed,completed,Dashboard filter of type ID may return wrong Entity name if ID is not unique in the source table,"### Describe the bug

On Audit v2, the underlying Content table is a `UNION` of questions, dashboards, events, collections. Because of that, the ID column isn't unique.

When we are retrieving entity names to display on the filter, looks like we select the name randomly.

<img width=""621"" alt=""image"" src=""https://github.com/metabase/metabase/assets/32561114/4aee05d6-428c-44e9-b4ff-f8f889f2035f"">

In this case, the dashboard 1907 is called `Metabase Business`, but the filter shows `Monthly Activated Hosting Logo...`

### To Reproduce

1. Go to https://stats.metabase.com/dashboard/2107-dashboard-overview
2. Filter dashboard ID 1907
3. Get wrong name in the filter widget


### Expected behavior

If there are multiple matches, we shouldn't show any value

### Logs

_No response_

### Information about your Metabase installation

```JSON
Master
```


### Severity

P2~P3

### Additional context

More like a P2 because it impacts audit v2",luizarakaki,2024-02-07 17:03:42+00:00,[],2024-08-20 19:15:11+00:00,2024-08-20 19:15:10+00:00,https://github.com/metabase/metabase/issues/38517,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2299583031, 'issue_id': 2123487263, 'author': 'cdeweyx', 'body': ""Getting the correct name now, @luizarakaki could you try again to gut check this. In the meantime, I'm going to close this as already fixed."", 'created_at': datetime.datetime(2024, 8, 20, 19, 15, 10, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-20 19:15:10 UTC): Getting the correct name now, @luizarakaki could you try again to gut check this. In the meantime, I'm going to close this as already fixed.

"
2123276118,issue,closed,completed,ClassCastException: class clojure.lang.Keyword cannot be cast to class java.lang.Throwable,"### Describe the bug

During startup a ClassCastException is thrown. This is the stacktrace.

```
2024-02-07 15:16:10,482 DEBUG toucan2.query :: Apply kv-args {:is_sample true}
2024-02-07 15:16:10,514 ERROR metabase.core :: Metabase Initialization FAILED
clojure.lang.ExceptionInfo: class clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader 'app'; java.lang.Throwable is in module java.base of loader 'bootstrap') {:toucan2/context-trace [[""with resolved query"" {:toucan2.pipeline/resolved-query {}}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances, :toucan2.pipeline/parsed-args {:kv-args {:is_sample true}, :queryable {}}}] [""with model"" {:toucan2.pipeline/model :model/Database}] [""with unparsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances, :toucan2.pipeline/unparsed-args (:model/Database :is_sample true)}]]}
	at clojure.tools.logging$eval136$fn__139.invoke(NO_SOURCE_FILE:0)
	at clojure.tools.logging.impl$fn__1684$G__1666__1695.invoke(impl.clj:16)
	at clojure.tools.logging$log_STAR_.invokeStatic(logging.clj:63)
	at clojure.tools.logging$log_STAR_.invoke(logging.clj:42)
	at toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invokeStatic(honeysql2.clj:47)
	at toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invoke(honeysql2.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at toucan2.tools.transformed$apply_kv_arg_primary_method_toucan2_tools_transformed_transformed_model_default_default.invokeStatic(transformed.clj:169)
	at toucan2.tools.transformed$apply_kv_arg_primary_method_toucan2_tools_transformed_transformed_model_default_default.invoke(transformed.clj:158)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at methodical.impl.combo.threaded$fn__17899$fn__17900$fn__17905.invoke(threaded.clj:72)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869$fn__17873.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6886)
	at clojure.core$reduce.invoke(core.clj:6868)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
	at clojure.lang.RestFn.invoke(RestFn.java:467)
	at methodical.impl.combo.threaded$combine_with_threader$fn__17879.invoke(threaded.clj:45)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:61)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:197)
	at toucan2.query$apply_kv_args$fn__21058.invoke(query.clj:222)
	at clojure.core.protocols$iter_reduce.invokeStatic(protocols.clj:49)
	at clojure.core.protocols$fn__8230.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8230.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6886)
	at clojure.core$reduce.invoke(core.clj:6868)
	at toucan2.query$apply_kv_args.invokeStatic(query.clj:220)
	at toucan2.query$apply_kv_args.invoke(query.clj:216)
	at toucan2.honeysql2$build_primary_method_default_default_clojure_lang_IPersistentMap.invokeStatic(honeysql2.clj:117)
	at toucan2.honeysql2$build_primary_method_default_default_clojure_lang_IPersistentMap.invoke(honeysql2.clj:111)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at toucan2.honeysql2$build_primary_method_toucan_query_type_select__STAR__default_clojure_lang_IPersistentMap.invokeStatic(honeysql2.clj:138)
	at toucan2.honeysql2$build_primary_method_toucan_query_type_select__STAR__default_clojure_lang_IPersistentMap.invoke(honeysql2.clj:120)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at methodical.impl.combo.threaded$fn__17899$fn__17900$fn__17905.invoke(threaded.clj:72)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869$fn__17873.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6886)
	at clojure.core$reduce.invoke(core.clj:6868)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
	at clojure.lang.RestFn.invoke(RestFn.java:467)
	at methodical.impl.combo.threaded$combine_with_threader$fn__17879.invoke(threaded.clj:45)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at metabase.db.setup$build_around_method_default.invokeStatic(setup.clj:205)
	at metabase.db.setup$build_around_method_default.invoke(setup.clj:198)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:61)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:197)
	at clojure.lang.Var.invoke(Var.java:399)
	at toucan2.pipeline$transduce_query_primary_method_default.invokeStatic(pipeline.clj:271)
	at toucan2.pipeline$transduce_query_primary_method_default.invoke(pipeline.clj:269)
	at clojure.lang.AFn.applyToHelper(AFn.java:178)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at methodical.impl.combo.threaded$fn__17899$fn__17900$fn__17907.invoke(threaded.clj:79)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869$fn__17873.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6886)
	at clojure.core$reduce.invoke(core.clj:6868)
	at methodical.impl.combo.threaded$reducer_fn$fn__17869.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
	at clojure.lang.RestFn.applyTo(RestFn.java:146)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$apply.doInvoke(core.clj:662)
	at clojure.lang.RestFn.invoke(RestFn.java:533)
	at methodical.impl.combo.threaded$combine_with_threader$fn__17879.doInvoke(threaded.clj:46)
	at clojure.lang.RestFn.applyTo(RestFn.java:151)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
	at clojure.core$apply.doInvoke(core.clj:662)
	at clojure.lang.RestFn.invoke(RestFn.java:533)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
	at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
	at clojure.lang.RestFn.invoke(RestFn.java:594)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
	at toucan2.pipeline$transduce_query_STAR_.invokeStatic(pipeline.clj:278)
	at toucan2.pipeline$transduce_query_STAR_.invoke(pipeline.clj:274)
	at toucan2.pipeline$transduce_with_model.invokeStatic(pipeline.clj:293)
	at toucan2.pipeline$transduce_with_model.invoke(pipeline.clj:280)
	at toucan2.pipeline$transduce_parsed.invokeStatic(pipeline.clj:309)
	at toucan2.pipeline$transduce_parsed.invoke(pipeline.clj:295)
	at toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:317)
	at toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311)
	at toucan2.select$select_one.invokeStatic(select.clj:58)
	at toucan2.select$select_one.doInvoke(select.clj:50)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.sample_data$update_sample_database_if_needed_BANG_.invokeStatic(sample_data.clj:88)
	at metabase.sample_data$update_sample_database_if_needed_BANG_.invoke(sample_data.clj:85)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:138)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:156)
	at metabase.core$init_BANG_.invoke(core.clj:151)
	at metabase.core$start_normally.invokeStatic(core.clj:168)
	at metabase.core$start_normally.invoke(core.clj:162)
	at metabase.core$entrypoint.invokeStatic(core.clj:201)
	at metabase.core$entrypoint.doInvoke(core.clj:195)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: java.lang.ClassCastException: class clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader 'app'; java.lang.Throwable is in module java.base of loader 'bootstrap')
	... 190 more
2024-02-07 15:16:10,545 INFO metabase.core :: Metabase Shutting Down ...
```

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase v0.48.5
H2 database
```


### Severity

blocking

### Additional context

_No response_",morten-holm,2024-02-07 15:21:13+00:00,['johnswanson'],2024-02-08 13:44:13+00:00,2024-02-08 13:44:12+00:00,https://github.com/metabase/metabase/issues/38516,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness')]","[{'comment_id': 1932298593, 'issue_id': 2123276118, 'author': 'paoliniluis', 'body': 'too little information\r\n1) how are you running metabase\r\n2) which env vars are you using\r\n\r\netc etc', 'created_at': datetime.datetime(2024, 2, 7, 15, 32, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932379809, 'issue_id': 2123276118, 'author': 'morten-holm', 'body': 'Deployed in kubernetes using the docker image from hub.docker.com\r\n\r\nENV:\r\n```\r\nJAVA_TIMEZONE: UTC\r\nJAVA_OPTS: -Xmx1536M \r\nMB_DB_FILE: /metabase-data/metabase.db\r\nMB_DB_TYPE: h2\r\nMB_EMOJI_IN_LOGS: ""true""\r\n```\r\n\r\nLogs:\r\n```\r\nWarning: environ value jdk-11.0.22+7 for key :java-version has been overwritten with 11.0.22\r\n2024-02-07 16:01:16,447 INFO metabase.util :: Maximum memory available to JVM: 1.5 GB\r\n...\r\n2024-02-07 16:01:40,939 INFO metabase.core :: \r\nMetabase v0.48.5 (dab12cf) \r\n\r\nCopyright © 2024 Metabase, Inc. \r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-02-07 16:01:40,973 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\n```\r\n\r\nAnything more specific?', 'created_at': datetime.datetime(2024, 2, 7, 16, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932399398, 'issue_id': 2123276118, 'author': 'dpsutton', 'body': 'this is a bug in our toucan library https://github.com/camsaul/toucan2/blob/master/src/toucan2/honeysql2.clj#L47\r\n\r\nI believe we don\'t see it because our log levels are high that we don\'t exercise that log statement.\r\n\r\nThe offending line is `(log/debugf  :compile ""apply kv-arg %s %s"" k v)`\r\n\r\nA repl in toucan2 running an equivalent \r\n\r\n```clojure\r\nhoneysql2=> (log/errorf  :compile ""apply kv-arg %s %s"" :foo :bar)\r\nExecution error (ClassCastException) at clojure.tools.logging/eval7516$fn (logging.clj:326).\r\nclass clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader \'app\'; java.lang.Throwable is in module java.base of loader \'bootstrap\')\r\n\r\n;; the correct way to use it:\r\nhoneysql2=> (log/errorf ""apply kv-arg %s %s"" :foo :bar)\r\nnil\r\n```\r\n\r\nThat macro seems to have some checking for an optional exception argument in the first position. And it assumes a non-string is an exception. This invocation uses a keyword (a pattern seemingly nowhere else used in the codebase).\r\n\r\n\r\nand the ""correct"" output of logs:\r\n\r\n```\r\n❯ clj -A:dev -J""$(socket-repl 6000)""\r\nClojure 1.11.1\r\nuser=>\r\n[SEVERE toucan2.honeysql2] apply kv-arg :foo :bar\r\n```', 'created_at': datetime.datetime(2024, 2, 7, 16, 18, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932413878, 'issue_id': 2123276118, 'author': 'dpsutton', 'body': 'I think a workaround would be bumping the logging level so that that debug message is not attempted while we get a fix out.', 'created_at': datetime.datetime(2024, 2, 7, 16, 25, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932491731, 'issue_id': 2123276118, 'author': 'dpsutton', 'body': 'I\'m able to reproduce on 0.48.3 in addition to 0.48.5:\r\n\r\ndebug.xml\r\n```\r\n<?xml version=""1.0"" encoding=""UTF-8""?>\r\n<Configuration>\r\n  <Appenders>\r\n    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">\r\n      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">\r\n        <replace regex="":basic-auth \\\\[.*\\\\]"" replacement="":basic-auth [redacted]""/>\r\n      </PatternLayout>\r\n    </Console>\r\n\r\n  </Appenders>\r\n  <Loggers>\r\n    <Root level=""DEBUG"">\r\n      <AppenderRef ref=""STDOUT""/>\r\n    </Root>\r\n  </Loggers>\r\n</Configuration>\r\n```\r\n\r\n```shell\r\nMB_JETTY_PORT=3006 java -Dlog4j2.configurationFile=debug.xml -jar 0.48.5.jar\r\n...\r\n2024-02-07 11:00:17,195 ERROR metabase.core :: Metabase Initialization FAILED\r\n...\r\nCaused by: clojure.lang.ExceptionInfo: class clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader \'app\'; java.lang.Throwable is in module java.base of loader \'bootstrap\') {:toucan2/context-trace [[""with resolved query"" {:toucan2.pipeline/resolved-query {}}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances.fns, :toucan2.pipeline/parsed-args {:kv-args {:key ""ldap-sync-admin-group""}, :queryable {}}}] [""with model"" {:toucan2.pipeline/model :setting}] [""with unparsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances.fns, :toucan2.pipeline/unparsed-args (:setting :key ""ldap-sync-admin-group"")}] [""resolve connection"" {:toucan2.connection/connectable org.h2.jdbc.JdbcConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat clojure.tools.logging$eval136$fn__139.invoke(NO_SOURCE_FILE:0)\r\n\tat clojure.tools.logging.impl$fn__1684$G__1666__1695.invoke(impl.clj:16)\r\n\tat clojure.tools.logging$log_STAR_.invokeStatic(logging.clj:63)\r\n\tat clojure.tools.logging$log_STAR_.invoke(logging.clj:42)\r\n\tat toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invokeStatic(honeysql2.clj:47)\r\n\tat toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invoke(honeysql2.clj:44)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:171)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:137)\r\n\tat clojure.core$apply.invokeStatic(core.clj:675)\r\n...\r\n```', 'created_at': datetime.datetime(2024, 2, 7, 17, 2, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932504869, 'issue_id': 2123276118, 'author': 'dpsutton', 'body': 'Workaround: include `<Logger name=""toucan2.honeysql2"" level=""INFO""/>` in your logging config (or some level above debug). I\'m able to get the 0.48.5 jar running with the following config:\r\n\r\n```xml\r\n<?xml version=""1.0"" encoding=""UTF-8""?>\r\n<Configuration>\r\n  <Appenders>\r\n    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">\r\n      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">\r\n        <replace regex="":basic-auth \\\\[.*\\\\]"" replacement="":basic-auth [redacted]""/>\r\n      </PatternLayout>\r\n    </Console>\r\n\r\n  </Appenders>\r\n  <Loggers>\r\n    <Logger name=""toucan2.honeysql2"" level=""INFO""/>\r\n    <Root level=""DEBUG"">\r\n      <AppenderRef ref=""STDOUT""/>\r\n    </Root>\r\n  </Loggers>\r\n</Configuration>\r\n```', 'created_at': datetime.datetime(2024, 2, 7, 17, 9, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-07 15:32:12 UTC): too little information
1) how are you running metabase
2) which env vars are you using

etc etc

morten-holm (Issue Creator) on (2024-02-07 16:09:00 UTC): Deployed in kubernetes using the docker image from hub.docker.com

ENV:
```
JAVA_TIMEZONE: UTC
JAVA_OPTS: -Xmx1536M 
MB_DB_FILE: /metabase-data/metabase.db
MB_DB_TYPE: h2
MB_EMOJI_IN_LOGS: ""true""
```

Logs:
```
Warning: environ value jdk-11.0.22+7 for key :java-version has been overwritten with 11.0.22
2024-02-07 16:01:16,447 INFO metabase.util :: Maximum memory available to JVM: 1.5 GB
...
2024-02-07 16:01:40,939 INFO metabase.core :: 
Metabase v0.48.5 (dab12cf) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-02-07 16:01:40,973 INFO metabase.core :: Starting Metabase in STANDALONE mode
```

Anything more specific?

dpsutton on (2024-02-07 16:18:17 UTC): this is a bug in our toucan library https://github.com/camsaul/toucan2/blob/master/src/toucan2/honeysql2.clj#L47

I believe we don't see it because our log levels are high that we don't exercise that log statement.

The offending line is `(log/debugf  :compile ""apply kv-arg %s %s"" k v)`

A repl in toucan2 running an equivalent 

```clojure
honeysql2=> (log/errorf  :compile ""apply kv-arg %s %s"" :foo :bar)
Execution error (ClassCastException) at clojure.tools.logging/eval7516$fn (logging.clj:326).
class clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader 'app'; java.lang.Throwable is in module java.base of loader 'bootstrap')

;; the correct way to use it:
honeysql2=> (log/errorf ""apply kv-arg %s %s"" :foo :bar)
nil
```

That macro seems to have some checking for an optional exception argument in the first position. And it assumes a non-string is an exception. This invocation uses a keyword (a pattern seemingly nowhere else used in the codebase).


and the ""correct"" output of logs:

```
❯ clj -A:dev -J""$(socket-repl 6000)""
Clojure 1.11.1
user=>
[SEVERE toucan2.honeysql2] apply kv-arg :foo :bar
```

dpsutton on (2024-02-07 16:25:20 UTC): I think a workaround would be bumping the logging level so that that debug message is not attempted while we get a fix out.

dpsutton on (2024-02-07 17:02:27 UTC): I'm able to reproduce on 0.48.3 in addition to 0.48.5:

debug.xml
```
<?xml version=""1.0"" encoding=""UTF-8""?>
<Configuration>
  <Appenders>
    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">
      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">
        <replace regex="":basic-auth \\[.*\\]"" replacement="":basic-auth [redacted]""/>
      </PatternLayout>
    </Console>

  </Appenders>
  <Loggers>
    <Root level=""DEBUG"">
      <AppenderRef ref=""STDOUT""/>
    </Root>
  </Loggers>
</Configuration>
```

```shell
MB_JETTY_PORT=3006 java -Dlog4j2.configurationFile=debug.xml -jar 0.48.5.jar
...
2024-02-07 11:00:17,195 ERROR metabase.core :: Metabase Initialization FAILED
...
Caused by: clojure.lang.ExceptionInfo: class clojure.lang.Keyword cannot be cast to class java.lang.Throwable (clojure.lang.Keyword is in unnamed module of loader 'app'; java.lang.Throwable is in module java.base of loader 'bootstrap') {:toucan2/context-trace [[""with resolved query"" {:toucan2.pipeline/resolved-query {}}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances.fns, :toucan2.pipeline/parsed-args {:kv-args {:key ""ldap-sync-admin-group""}, :queryable {}}}] [""with model"" {:toucan2.pipeline/model :setting}] [""with unparsed args"" {:toucan2.pipeline/query-type :toucan.query-type/select.instances.fns, :toucan2.pipeline/unparsed-args (:setting :key ""ldap-sync-admin-group"")}] [""resolve connection"" {:toucan2.connection/connectable org.h2.jdbc.JdbcConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at clojure.tools.logging$eval136$fn__139.invoke(NO_SOURCE_FILE:0)
	at clojure.tools.logging.impl$fn__1684$G__1666__1695.invoke(impl.clj:16)
	at clojure.tools.logging$log_STAR_.invokeStatic(logging.clj:63)
	at clojure.tools.logging$log_STAR_.invoke(logging.clj:42)
	at toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invokeStatic(honeysql2.clj:47)
	at toucan2.honeysql2$apply_kv_arg_primary_method_default_clojure_lang_IPersistentMap_default.invoke(honeysql2.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:171)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.applyTo(RestFn.java:137)
	at clojure.core$apply.invokeStatic(core.clj:675)
...
```

dpsutton on (2024-02-07 17:09:34 UTC): Workaround: include `<Logger name=""toucan2.honeysql2"" level=""INFO""/>` in your logging config (or some level above debug). I'm able to get the 0.48.5 jar running with the following config:

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<Configuration>
  <Appenders>
    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">
      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">
        <replace regex="":basic-auth \\[.*\\]"" replacement="":basic-auth [redacted]""/>
      </PatternLayout>
    </Console>

  </Appenders>
  <Loggers>
    <Logger name=""toucan2.honeysql2"" level=""INFO""/>
    <Root level=""DEBUG"">
      <AppenderRef ref=""STDOUT""/>
    </Root>
  </Loggers>
</Configuration>
```

"
2123234964,issue,closed,completed,Connection impersonation for redshift,"We have connection impersonation for a few drivers, including postgres. Let's extend it to redshift.",dpsutton,2024-02-07 15:02:59+00:00,"['iethree', 'noahmoss']",2024-02-07 15:13:05+00:00,2024-02-07 15:13:05+00:00,https://github.com/metabase/metabase/issues/38515,"[('Type:New Feature', '')]","[{'comment_id': 1932256487, 'issue_id': 2123234964, 'author': 'dpsutton', 'body': 'closing as duplicative to https://github.com/metabase/metabase/issues/38445', 'created_at': datetime.datetime(2024, 2, 7, 15, 13, 5, tzinfo=datetime.timezone.utc)}]","dpsutton (Issue Creator) on (2024-02-07 15:13:05 UTC): closing as duplicative to https://github.com/metabase/metabase/issues/38445

"
2122863514,issue,open,,Make `report_card.query_type` non-nullable,"`report_card.query_type` is currently nullable in the app DB, for what seems like historical reasons. `query_type` should just duplicate the value of `report_card.dataset_query`'s `type` key, and I have a feeling a `dataset_query` without a `type` has not been valid for a very long time.

The problem with a nullable `query_type` is it requires us to write code that handles the `null` case explicitly, as in [here](https://github.com/metabase/metabase/pull/38322/files#diff-af3188166dbf14ec61d196f0e71de90a50f7e2c9de2c152d7cd2e20c6af4051bR701-R702).

A related issue is that `dataset_query` can be empty by default in tests, meaning we have to handle those cases explicitly, as in [here](https://github.com/metabase/metabase/pull/38322/files#diff-af3188166dbf14ec61d196f0e71de90a50f7e2c9de2c152d7cd2e20c6af4051bR717).

[Slack thread](https://metaboat.slack.com/archives/CKZEMT1MJ/p1707170590392019)",calherries,2024-02-07 11:54:52+00:00,[],2024-03-13 08:02:20+00:00,,https://github.com/metabase/metabase/issues/38511,"[('Type:Tech Debt', 'or Refactoring'), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC'), ('dev/ergonomic', '')]","[{'comment_id': 1952457708, 'issue_id': 2122863514, 'author': 'calherries', 'body': 'The benefits of cleaning this up: \r\n- less code. code that requires `query_type` can be less complex as it allows us to remove a conditional branching handling null `query_type`, which is only used in tests.\r\n- makes code easier to understand, because the code reflects the actual assumptions we make in production. Also schemas can be tighter and reflect actual production constraints.\r\n- eliminates the possibility of bugs where we write code that only handles `nil` `query_type` and incorrectly passes tests, although I guess these bugs are pretty unlikely in practice.\r\n\r\nEstimated effort: a day, or two? The hardest part is updating the many tests to take a `query_type`', 'created_at': datetime.datetime(2024, 2, 19, 13, 29, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 1992156884, 'issue_id': 2122863514, 'author': 'camsaul', 'body': 'What are we even using `query_type` for? Maybe we can just get rid of it', 'created_at': datetime.datetime(2024, 3, 12, 17, 10, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 1993767815, 'issue_id': 2122863514, 'author': 'calherries', 'body': '@camsaul We use it in a few places outside the QP to determine whether a card has a MBQL or native query. Can we use a function from MLv2 instead?', 'created_at': datetime.datetime(2024, 3, 13, 8, 2, 4, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-02-19 13:29:18 UTC): The benefits of cleaning this up: 
- less code. code that requires `query_type` can be less complex as it allows us to remove a conditional branching handling null `query_type`, which is only used in tests.
- makes code easier to understand, because the code reflects the actual assumptions we make in production. Also schemas can be tighter and reflect actual production constraints.
- eliminates the possibility of bugs where we write code that only handles `nil` `query_type` and incorrectly passes tests, although I guess these bugs are pretty unlikely in practice.

Estimated effort: a day, or two? The hardest part is updating the many tests to take a `query_type`

camsaul on (2024-03-12 17:10:50 UTC): What are we even using `query_type` for? Maybe we can just get rid of it

calherries (Issue Creator) on (2024-03-13 08:02:04 UTC): @camsaul We use it in a few places outside the QP to determine whether a card has a MBQL or native query. Can we use a function from MLv2 instead?

"
2122721771,issue,closed,completed,[MLv2] [BE] `Lib.dependentMetadata` gives wrong results,"Blocks https://github.com/metabase/metabase/issues/37390

See [Slack](https://metaboat.slack.com/archives/C04CYTEL9N2/p1706712778172129) for details.

1. `foreignTables` flag has not been ported to MLv2 (not all tables are in the result)
2. For queries with aggregations, FKs are redundant

----

This causes e2e tests to fail in #38303 - please check the fix against that branch.

-----

### Case 1 - `foreignTables` flag

Given this query (get ""orders""):
```js
{
    ""database"": 1,
    ""type"": ""query"",
    ""query"": {
        ""source-table"": 5
    }
}
```

Currently `Lib.dependentMetadata` will return
```js
[
  {""type"": ""database"",""id"": 1 },
  {""type"": ""schema"",""id"": 1 },
  {""type"": ""table"",""id"": 5 }, // orders table
  {""type"": ""field"",""id"": 68 },
  {""type"": ""field"",""id"": 15 }
]
```

But ideally it should return 2 more tables:
```js
  {""type"": ""table"",""id"": 3 }, // people table
  {""type"": ""table"",""id"": 8 }, // products table
```

Because they are referenced by FKs (field id 68 & field id 15) in the Orders table.

### Case 2 - Redundant FKs in queries with aggregations

Given this query:
```js
{
    ""database"": 1,
    ""type"": ""query"",
    ""query"": {
        ""source-table"": 5, // orders table
        ""aggregation"": [[""count""]]
    }
}
```

`Lib.dependentMetadata` will return:
```js
[
    { ""type"": ""database"", ""id"": 1 },
    { ""type"": ""schema"", ""id"": 1 },
    { ""type"": ""table"", ""id"": 5 },
    { ""type"": ""field"", ""id"": 68 },
    { ""type"": ""field"", ""id"": 15 }
]
```

But the old `StructuredQuery.prototype.dependentMetadata` returns:
```js
[
    { ""type"": ""schema"", ""id"": 1 },
    { ""type"": ""table"", ""id"": 5, ""foreignTables"": true }
]
```
Notice that there are no type: ""field"" items here.

Interestingly, in the old implementation FE will fetch tables 3 & 8 (due to `foreignTables: true` ), but I don't think they're necessary in this case - **I am not 100% sure though**.

My expected output of `Lib.dependentMetadata` in this case is:
```js
[
    { ""type"": ""database"", ""id"": 1 },
    { ""type"": ""schema"", ""id"": 1 },
    { ""type"": ""table"", ""id"": 5 }
]
```

But it's ok if we keep the other tables in the result so that it works exactly like it used to:
```js
[
    { ""type"": ""database"", ""id"": 1 },
    { ""type"": ""schema"", ""id"": 1 },
    { ""type"": ""table"", ""id"": 5 },
    { ""type"": ""table"", ""id"": 3 }, // people table
    { ""type"": ""table"", ""id"": 8 }, // products table
]
```
",kamilmielnik,2024-02-07 10:41:54+00:00,['metamben'],2024-08-28 02:12:17+00:00,2024-02-13 19:43:29+00:00,https://github.com/metabase/metabase/issues/38510,"[('Type:Bug', 'Product defects'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]","[{'comment_id': 1932544535, 'issue_id': 2122721771, 'author': 'metamben', 'body': ""> Interestingly, in the old implementation FE will fetch tables 3 & 8 (due to foreignTables: true ), but I don't think they're necessary in this case - I am not 100% sure though.\r\n\r\nI find it totally counterintuitive to return tables 3 and 8 without returning the FK fields that refer to them. What's the logic of this? Why does the presence of an aggregation mean we can (and should) omit some items we would include otherwise?"", 'created_at': datetime.datetime(2024, 2, 7, 17, 32, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932724182, 'issue_id': 2122721771, 'author': 'metamben', 'body': '#38528 addresses Case 1.', 'created_at': datetime.datetime(2024, 2, 7, 19, 27, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 1935841871, 'issue_id': 2122721771, 'author': 'kamilmielnik', 'body': ""> What's the logic of this? Why does the presence of an aggregation mean we can (and should) omit some items we would include otherwise?\r\n\r\nI don't have answers to these questions. I scheduled a call with Alex on Monday to get more information.\r\n\r\nMy current point of view is that unless we make `Lib.dependentMetadata` work exactly like `StructuredQuery.prototype.dependentMetadata` used to work, the side effects (i.e. extra network requests) generate unrealistic numbers of changes needed to be done in e2e tests and possibly FE code as well (there are cases where extra network requests fail due to lack of permissions and e2e tests flake due to time spent performing extra network requests)."", 'created_at': datetime.datetime(2024, 2, 9, 12, 27, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936033821, 'issue_id': 2122721771, 'author': 'metamben', 'body': ""OK, let's discuss this on Monday then. Can a reasonable amount of software archeology help in finding out the rules?"", 'created_at': datetime.datetime(2024, 2, 9, 14, 28, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938912094, 'issue_id': 2122721771, 'author': 'metamben', 'body': '#38528 addresses Case 2 too.', 'created_at': datetime.datetime(2024, 2, 12, 15, 36, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942281848, 'issue_id': 2122721771, 'author': 'ranquild', 'body': 'Fixed by https://github.com/metabase/metabase/pull/38528', 'created_at': datetime.datetime(2024, 2, 13, 19, 43, 29, tzinfo=datetime.timezone.utc)}]","metamben (Assginee) on (2024-02-07 17:32:26 UTC): I find it totally counterintuitive to return tables 3 and 8 without returning the FK fields that refer to them. What's the logic of this? Why does the presence of an aggregation mean we can (and should) omit some items we would include otherwise?

metamben (Assginee) on (2024-02-07 19:27:10 UTC): #38528 addresses Case 1.

kamilmielnik (Issue Creator) on (2024-02-09 12:27:35 UTC): I don't have answers to these questions. I scheduled a call with Alex on Monday to get more information.

My current point of view is that unless we make `Lib.dependentMetadata` work exactly like `StructuredQuery.prototype.dependentMetadata` used to work, the side effects (i.e. extra network requests) generate unrealistic numbers of changes needed to be done in e2e tests and possibly FE code as well (there are cases where extra network requests fail due to lack of permissions and e2e tests flake due to time spent performing extra network requests).

metamben (Assginee) on (2024-02-09 14:28:53 UTC): OK, let's discuss this on Monday then. Can a reasonable amount of software archeology help in finding out the rules?

metamben (Assginee) on (2024-02-12 15:36:18 UTC): #38528 addresses Case 2 too.

ranquild on (2024-02-13 19:43:29 UTC): Fixed by https://github.com/metabase/metabase/pull/38528

"
2122636007,issue,closed,completed,All tables in mysql databases are marked as non-active and cannot browse them or use table metadata,"**Issue**
With the newest version v.0.48.4 the metadata sync that we have scheduled to run every day at midnight is marking all of the tables in mysql databases (specific engines only) as non-active causing users cannot explore (browse data) and cannot fetch table metadata in Admin section or use table fields for field filters, etc.

We have different mysql databases, some are not affected, like the Metabase database itself or other ones running 5.x or 8.x versions
However those that are affected are running ""Server version: 8.0.26-16 Percona Server (GPL), Release 16, Revision 3d64165"" 

We tried to trigger the table metadata fetch manually and the results are the same.
We tried to update the table metabase_table and set active = 1 to all of the tables listed.  After this manual update (SQL update) we can browse the tables, etc.  However, the next time the auto metadata fetch runs, all tables are again marked as non active.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to Browse data in the frontend and select to browse a mysql database (running the affected engine) .  There is not any table to explore.
![image](https://github.com/metabase/metabase/assets/52322349/c163bf30-c76d-4ed1-b688-97390df7f6fc)

3. Go to Admin->Table Metadata and select one of the mysql affected databases.  Thre is not any schema on it
![image](https://github.com/metabase/metabase/assets/52322349/01ec7a9f-97db-4c74-8191-a1ef392cddbd)

5. Go to your mysql client and query the Metabase database and run the following query
`select
     md.id
    , md.name
    , md.`engine`
    , sum(active) active_tables
    , sum(1) total_tables
from
    metabase_table mt
join metabase_database md on 
    md.id = mt.db_id
where
    true
    and md.`engine` = 'mysql'
group by 
    1,2, 3`
7. See that some mysql are not affected but the affecgted ones 100% of the tables are marked as inactive
![image](https://github.com/metabase/metabase/assets/52322349/fc226951-c86a-4e80-99c3-7cf3e2978d9f)


**Expected behavior**
After a scheduled or manual metadata fetch, the active tables (and columns) should keep ""active"" so users with permissions can browse those tables
Admins can administer the metadata of those mysql databases as regular
Editors can use any table-field in their query builders, field filters, etc

**Severity**
this is quite severe as disables the feature of browse data, build questions, add field filters, administer metadata, etc

**Additional context**
it seems that the mysql version affected is 
Server version: 8.0.26-16 Percona Server (GPL), Release 16, Revision 3d64165

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.16.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.16.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.16.1+1"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""sqlserver"",
      ""snowflake"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.33""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v0.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",jcorrea-tkww,2024-02-07 09:58:58+00:00,['crisptrutski'],2024-02-14 05:57:27+00:00,2024-02-14 05:51:59+00:00,https://github.com/metabase/metabase/issues/38509,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('Administration/Metadata & Sync', ''), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1931836156, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': 'Do you know if those tables are somewhat different to the others?', 'created_at': datetime.datetime(2024, 2, 7, 11, 22, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 1931854220, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'No, these databases are the same working as expected until the last version abovementioned.  If I downgrade de version of metabase to the previous, then I trigger manually metadata fetch and it works.  However I cannot downgrade because theare other issues that the new version corrects and I want to keep the latest but obviosly without the current issue.\r\nMaybe with v.0.48.4  it was included some driver update? or some changes related to how to match or interpret metadata?', 'created_at': datetime.datetime(2024, 2, 7, 11, 34, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932018252, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': 'When you say a previous version, you refer to 47?', 'created_at': datetime.datetime(2024, 2, 7, 13, 9, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932023709, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': ""If Im' not mistaken, with v.0.48.3 it worked as expected.  When I detected this issue, I quickly revert the version to the previous one v.0.48.3 and when I triggered the metadata fetch it worked as expected I guess.  I might test this in a preprod env when I get a chance and isolate the connections to only one db and test with different versions of metabase and capture logs\r\nI'll do this when i get a chance"", 'created_at': datetime.datetime(2024, 2, 7, 13, 12, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932068836, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': 'Are the inactive tables in different schemas? can you give me some characteristics?', 'created_at': datetime.datetime(2024, 2, 7, 13, 37, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932108070, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'In mysql connections, the ""schemas"" are databases within a server. so in server XXXX I have the database db_abc which with 100 tables in it and metabase now cannot read these 100 tables correctly and all of them are flagged as inactive.  The expected behavior is to check which tables do still exist and compare with the already fetched active and then flag inactiv only those that don\'t match between metabase and the database but the real thing with the issue is that 100% of tables within the mysql database are flagged as inactive.', 'created_at': datetime.datetime(2024, 2, 7, 13, 58, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932177835, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': ""@jcorrea-tkww sorry, I didn't get that, please explain with more detail"", 'created_at': datetime.datetime(2024, 2, 7, 14, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932346397, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'when in Metabase you create or define de conection to a mysql server you need to define the host and the database\r\n![image](https://github.com/metabase/metabase/assets/52322349/3976bbcf-cec2-4f4d-b204-a9e3c40d9fe4)\r\n\r\nit affects to all of the tables in that database and in all databases in that server (schemas)', 'created_at': datetime.datetime(2024, 2, 7, 15, 54, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932633269, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': 'got it, can you run SHOW TABLES? as the metabase user?', 'created_at': datetime.datetime(2024, 2, 7, 18, 27, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 1933596485, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'It would be very useful to have the server logs emitted during the faulty sync', 'created_at': datetime.datetime(2024, 2, 8, 8, 40, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 1933628398, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'Yes, using the same credentials that we use in metabase connection, the SHOW TABLES command returns all the tables as expected', 'created_at': datetime.datetime(2024, 2, 8, 9, 1, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 1933858053, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'It would also be very useful to see the output of `SHOW GRANTS FOR CURRENT_USER()`', 'created_at': datetime.datetime(2024, 2, 8, 11, 13, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934151258, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': '```\r\nSHOW GRANTS FOR CURRENT_USER()\r\n\r\nGRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `reporting-user-xxx`@`%`\r\nGRANT SELECT ON `Bodas%`.* TO `reporting-user`@`%`\r\nGRANT SELECT ON `performance_schema.replication_applier_status`.* TO `reporting-user-xxx`@`%`\r\n```', 'created_at': datetime.datetime(2024, 2, 8, 13, 43, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934355958, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': ""@jcorrea-tkww Thanks for the grant details, it's allowed us to rule out one cause.\r\n\r\nUnfortunately I don't have any other theories yet, so if you could provide the logs from the next time the database gets synced that would be immensely helpful.\r\n\r\nWhen you manually sync, does the UI show it completing?"", 'created_at': datetime.datetime(2024, 2, 8, 15, 21, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934382059, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': ""No, neither manual or scheduled metadata sync works.\r\nI'm now going to reproduce this in a separated instance with only one affected mysql engine and another non-affected mysql engine to compare and get logs\r\nWe'll keep you posted"", 'created_at': datetime.datetime(2024, 2, 8, 15, 33, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934510899, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': ""Preliminar analysis after creating a brand new instance of metabase with only the sample database and created a new one to the affected mysql server.\r\n\r\n![image](https://github.com/metabase/metabase/assets/52322349/26e1ce01-15e2-4a4b-b661-b94a17c53083)\r\n\r\nSo, using  v0.48.4 or higher it doesnt work\r\n\r\nThen shutdown the instance and swtich to use 0.48.3.    I create the same connection to the same db and this time everything works as expected.  The table METABASE_TABLE is quickly including all the tables in the schema and in the backend (admin->metadata) I can see the tables and columns as well.\r\n\r\nSo. my initital thought is that 0.48.4 introduced something in the mariadb or mysql driver or in the metadata fetch process.\r\n\r\nI'm now going to export logs for the non-working instance but I cannot expose these logs here, so let me know how can I send them to you a bit anonymized"", 'created_at': datetime.datetime(2024, 2, 8, 16, 37, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934610112, 'issue_id': 2122636007, 'author': 'paoliniluis', 'body': '@jcorrea-tkww can you give us the permissions of the user and also the names of the schemas?', 'created_at': datetime.datetime(2024, 2, 8, 17, 27, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 1934643806, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'the schema name is, for instance ""Bodas"" or ""Bodas_AR""\r\n\r\nthe permissions I already posted above.', 'created_at': datetime.datetime(2024, 2, 8, 17, 49, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 1935597970, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'You can send the logs to help@metabase.com', 'created_at': datetime.datetime(2024, 2, 9, 9, 33, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 1939223900, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'Logs sent by email', 'created_at': datetime.datetime(2024, 2, 12, 17, 42, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 1940811120, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'Cheers, found them and will be investigating this morning.', 'created_at': datetime.datetime(2024, 2, 13, 8, 58, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 1940855172, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': ""Good news - I think I have identified the issue, and it should be fixed by `0.48.6`\r\n\r\nI'll leave this issue open for you to confirm once that version is released."", 'created_at': datetime.datetime(2024, 2, 13, 9, 14, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 1941328862, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': ""great news, looking forward to testing that out!  I have just tested the 0.48.6 and it seems that the issue is still there.  Maybe that release didn't capture the changes."", 'created_at': datetime.datetime(2024, 2, 13, 11, 51, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 1941964395, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'The issue I spotted was definitely fixed by the release, there must be something else at play unfortunately.\r\n\r\nIn the logs you sent me, I believed the tables had already been deactivated by a previous sync for the logs you sent me for 48.4 - I did not see it emit any logs around ""retiring"" the tables. Can you confirm if that was the case?\r\n\r\nIn either event, getting logs for the sync with 48.6 against a db where the tables are currently active would be very helpful.', 'created_at': datetime.datetime(2024, 2, 13, 16, 34, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942150888, 'issue_id': 2122636007, 'author': 'jcorrea-tkww', 'body': 'I can confirm this is fixed by 48.6\r\nI tested in prod for both, new db and existing db with 100% marked as inactive and then after the metadata fetch the active = 1 is coming back to the existing tables when apply.\r\nI tested in a new environment from scratch, and also worked as expected.\r\nThank you so much !!', 'created_at': datetime.datetime(2024, 2, 13, 18, 26, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 1943126362, 'issue_id': 2122636007, 'author': 'crisptrutski', 'body': 'Very glad to hear that!', 'created_at': datetime.datetime(2024, 2, 14, 5, 51, 59, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-07 11:22:41 UTC): Do you know if those tables are somewhat different to the others?

jcorrea-tkww (Issue Creator) on (2024-02-07 11:34:09 UTC): No, these databases are the same working as expected until the last version abovementioned.  If I downgrade de version of metabase to the previous, then I trigger manually metadata fetch and it works.  However I cannot downgrade because theare other issues that the new version corrects and I want to keep the latest but obviosly without the current issue.
Maybe with v.0.48.4  it was included some driver update? or some changes related to how to match or interpret metadata?

paoliniluis on (2024-02-07 13:09:30 UTC): When you say a previous version, you refer to 47?

jcorrea-tkww (Issue Creator) on (2024-02-07 13:12:36 UTC): If Im' not mistaken, with v.0.48.3 it worked as expected.  When I detected this issue, I quickly revert the version to the previous one v.0.48.3 and when I triggered the metadata fetch it worked as expected I guess.  I might test this in a preprod env when I get a chance and isolate the connections to only one db and test with different versions of metabase and capture logs
I'll do this when i get a chance

paoliniluis on (2024-02-07 13:37:10 UTC): Are the inactive tables in different schemas? can you give me some characteristics?

jcorrea-tkww (Issue Creator) on (2024-02-07 13:58:28 UTC): In mysql connections, the ""schemas"" are databases within a server. so in server XXXX I have the database db_abc which with 100 tables in it and metabase now cannot read these 100 tables correctly and all of them are flagged as inactive.  The expected behavior is to check which tables do still exist and compare with the already fetched active and then flag inactiv only those that don't match between metabase and the database but the real thing with the issue is that 100% of tables within the mysql database are flagged as inactive.

paoliniluis on (2024-02-07 14:34:35 UTC): @jcorrea-tkww sorry, I didn't get that, please explain with more detail

jcorrea-tkww (Issue Creator) on (2024-02-07 15:54:50 UTC): when in Metabase you create or define de conection to a mysql server you need to define the host and the database
![image](https://github.com/metabase/metabase/assets/52322349/3976bbcf-cec2-4f4d-b204-a9e3c40d9fe4)

it affects to all of the tables in that database and in all databases in that server (schemas)

paoliniluis on (2024-02-07 18:27:43 UTC): got it, can you run SHOW TABLES? as the metabase user?

crisptrutski (Assginee) on (2024-02-08 08:40:21 UTC): It would be very useful to have the server logs emitted during the faulty sync

jcorrea-tkww (Issue Creator) on (2024-02-08 09:01:40 UTC): Yes, using the same credentials that we use in metabase connection, the SHOW TABLES command returns all the tables as expected

crisptrutski (Assginee) on (2024-02-08 11:13:31 UTC): It would also be very useful to see the output of `SHOW GRANTS FOR CURRENT_USER()`

jcorrea-tkww (Issue Creator) on (2024-02-08 13:43:03 UTC): ```
SHOW GRANTS FOR CURRENT_USER()

GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO `reporting-user-xxx`@`%`
GRANT SELECT ON `Bodas%`.* TO `reporting-user`@`%`
GRANT SELECT ON `performance_schema.replication_applier_status`.* TO `reporting-user-xxx`@`%`
```

crisptrutski (Assginee) on (2024-02-08 15:21:24 UTC): @jcorrea-tkww Thanks for the grant details, it's allowed us to rule out one cause.

Unfortunately I don't have any other theories yet, so if you could provide the logs from the next time the database gets synced that would be immensely helpful.

When you manually sync, does the UI show it completing?

jcorrea-tkww (Issue Creator) on (2024-02-08 15:33:57 UTC): No, neither manual or scheduled metadata sync works.
I'm now going to reproduce this in a separated instance with only one affected mysql engine and another non-affected mysql engine to compare and get logs
We'll keep you posted

jcorrea-tkww (Issue Creator) on (2024-02-08 16:37:59 UTC): Preliminar analysis after creating a brand new instance of metabase with only the sample database and created a new one to the affected mysql server.

![image](https://github.com/metabase/metabase/assets/52322349/26e1ce01-15e2-4a4b-b661-b94a17c53083)

So, using  v0.48.4 or higher it doesnt work

Then shutdown the instance and swtich to use 0.48.3.    I create the same connection to the same db and this time everything works as expected.  The table METABASE_TABLE is quickly including all the tables in the schema and in the backend (admin->metadata) I can see the tables and columns as well.

So. my initital thought is that 0.48.4 introduced something in the mariadb or mysql driver or in the metadata fetch process.

I'm now going to export logs for the non-working instance but I cannot expose these logs here, so let me know how can I send them to you a bit anonymized

paoliniluis on (2024-02-08 17:27:28 UTC): @jcorrea-tkww can you give us the permissions of the user and also the names of the schemas?

jcorrea-tkww (Issue Creator) on (2024-02-08 17:49:16 UTC): the schema name is, for instance ""Bodas"" or ""Bodas_AR""

the permissions I already posted above.

crisptrutski (Assginee) on (2024-02-09 09:33:02 UTC): You can send the logs to help@metabase.com

jcorrea-tkww (Issue Creator) on (2024-02-12 17:42:41 UTC): Logs sent by email

crisptrutski (Assginee) on (2024-02-13 08:58:23 UTC): Cheers, found them and will be investigating this morning.

crisptrutski (Assginee) on (2024-02-13 09:14:04 UTC): Good news - I think I have identified the issue, and it should be fixed by `0.48.6`

I'll leave this issue open for you to confirm once that version is released.

jcorrea-tkww (Issue Creator) on (2024-02-13 11:51:33 UTC): great news, looking forward to testing that out!  I have just tested the 0.48.6 and it seems that the issue is still there.  Maybe that release didn't capture the changes.

crisptrutski (Assginee) on (2024-02-13 16:34:38 UTC): The issue I spotted was definitely fixed by the release, there must be something else at play unfortunately.

In the logs you sent me, I believed the tables had already been deactivated by a previous sync for the logs you sent me for 48.4 - I did not see it emit any logs around ""retiring"" the tables. Can you confirm if that was the case?

In either event, getting logs for the sync with 48.6 against a db where the tables are currently active would be very helpful.

jcorrea-tkww (Issue Creator) on (2024-02-13 18:26:48 UTC): I can confirm this is fixed by 48.6
I tested in prod for both, new db and existing db with 100% marked as inactive and then after the metadata fetch the active = 1 is coming back to the existing tables when apply.
I tested in a new environment from scratch, and also worked as expected.
Thank you so much !!

crisptrutski (Assginee) on (2024-02-14 05:51:59 UTC): Very glad to hear that!

"
2122424182,issue,closed,completed,Improve dashboard selector `getParameters` to avoid unnecessary heavy operations,"**Context**
Improve dashboard selector `getParameters` to avoid unnecessary heavy operations

[suggestion](https://metaboat.slack.com/archives/C04CYTEL9N2/p1707156521548289?thread_ts=1706701672.407039&cid=C04CYTEL9N2)
```
why typing is so slow is because our getParameters[ selector](https://github.com/metabase/metabase/blob/ea05f6ff8dc09692761514423400ccef0cab5af8/frontend/src/metabase/dashboard/selectors.ts#L305) is using getDashboardComplete even tho it only cares about dashboard.parameters and dashcards’ parameter_mappings

We might not need debouncing heading/text change events if we could optimize this
Basically we only need to rerun getParameters when:
- metadata changes (can be frequent when initially loading a busy dashboard, mostly stale later)
- dashboard parameters (their values are decoupled, so dashboard.parameters should only change in edit mode if I’m not missing something)
- dashcard parameter mappings (again, should only be changing while in edit mode)
```",uladzimirdev,2024-02-07 08:06:05+00:00,[],2024-02-19 20:29:44+00:00,2024-02-19 20:28:56+00:00,https://github.com/metabase/metabase/issues/38502,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 1953123435, 'issue_id': 2122424182, 'author': 'uladzimirdev', 'body': ""tested it https://github.com/metabase/metabase/pull/38765 but didn't notice any significant change in perf"", 'created_at': datetime.datetime(2024, 2, 19, 20, 29, 43, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-02-19 20:29:43 UTC): tested it https://github.com/metabase/metabase/pull/38765 but didn't notice any significant change in perf

"
2122418999,issue,closed,completed,[Epic] Improve performance of dashboards MLv2,"Dashboard editing became extremely slow, what was described in the issue https://github.com/metabase/metabase/issues/38225

There are at least two reasons for it:
1. Not optimal frontend data flow, which triggers heavy operations and unnecessary re-rendering even after a small change
2. re-creating question on FE which leads to new instances of queries in many places which led to cache invalidation in MLv2 -> slow MLv2 calls

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/38426
- [ ] https://github.com/metabase/metabase/pull/38361
- [ ] https://github.com/metabase/metabase/pull/38360
- [ ] https://github.com/metabase/metabase/pull/38325
- [ ] https://github.com/metabase/metabase/pull/38425
- [ ] https://github.com/metabase/metabase/issues/38502
- [ ] https://github.com/metabase/metabase/pull/38375
- [ ] https://github.com/metabase/metabase/pull/38409
``` 

",uladzimirdev,2024-02-07 08:03:01+00:00,"['bshepherdson', 'uladzimirdev']",2024-02-19 15:27:09+00:00,2024-02-19 15:26:28+00:00,https://github.com/metabase/metabase/issues/38501,[],"[{'comment_id': 1932208752, 'issue_id': 2122418999, 'author': 'bshepherdson', 'body': ""I've added the two CLJS PRs above as well.\r\n\r\nI also edited the description slightly to distinguish MLv2 code (ie. CLJS code running in the FE) from the BE (meaning the server). To be clear, there's no network traffic directly involved here."", 'created_at': datetime.datetime(2024, 2, 7, 14, 50, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 1952690757, 'issue_id': 2122418999, 'author': 'uladzimirdev', 'body': ""All the related tasks are completed, the main fix is provided, other issues/PR which didn't make a significant difference were closed"", 'created_at': datetime.datetime(2024, 2, 19, 15, 27, 8, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-02-07 14:50:09 UTC): I've added the two CLJS PRs above as well.

I also edited the description slightly to distinguish MLv2 code (ie. CLJS code running in the FE) from the BE (meaning the server). To be clear, there's no network traffic directly involved here.

uladzimirdev (Issue Creator) on (2024-02-19 15:27:08 UTC): All the related tasks are completed, the main fix is provided, other issues/PR which didn't make a significant difference were closed

"
2122220492,issue,closed,completed,"Newly added MySQL DB tables not showing up, but old ones do show up","**Describe the bug**
After the upgrade to Metabase v0.48.4, I am not able to see any newly added MySQL DB tables even after I have clicked on the ""Sync database schema now"" and ""Re-scan field values now"" buttons. The old tables that were created before the upgrade is showing up. Updating to v0.48.5 does not seem to resolve this issue.

When I go to ""+ New"" and click on ""SQL Query"", I am able to pull up the data from my newly added table. However, when I go to ""+New"" and click on ""Question"", the newly added table does not show up in the ""Pick your starting data"" section. Only the old tables are there.

It seems like the **""Sync database schema now"" functionality** is not working correctly.

**Logs**
Feb 06 20:34:372024-02-07 04:34:37,037 DEBUG middleware.log :: GET /api/database/2/schemas 200 34.6 ms (4 DB calls) App DB connections: 1/4 Jetty threads: 4/50 (3 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:34:372024-02-07 04:34:37,149 DEBUG middleware.log :: GET /api/database/2/schema/ 200 56.8 ms (6 DB calls) App DB connections: 2/4 Jetty threads: 4/50 (3 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:34:372024-02-07 04:34:37,191 DEBUG middleware.log :: GET /api/database 200 170.7 ms (8 DB calls) App DB connections: 1/4 Jetty threads: 3/50 (3 idle, 0 queued) (49 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:35:332024-02-07 04:35:33,570 DEBUG middleware.log :: GET /api/database/2 200 25.0 ms (3 DB calls) App DB connections: 1/4 Jetty threads: 3/50 (4 idle, 0 queued) (49 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:35:352024-02-07 04:35:35,524 INFO metabase.events :: Loading events namespace: metabase.events.audit-log 👂
Feb 06 20:35:352024-02-07 04:35:35,602 INFO metabase.events :: Loading events namespace: metabase.events.driver-notifications 👂
Feb 06 20:35:352024-02-07 04:35:35,632 INFO metabase.events :: Loading events namespace: metabase.events.last-login 👂
Feb 06 20:35:352024-02-07 04:35:35,643 INFO metabase.events :: Loading events namespace: metabase.events.persisted-info 👂
Feb 06 20:35:352024-02-07 04:35:35,670 INFO metabase.events :: Loading events namespace: metabase.events.recent-views 👂
Feb 06 20:35:352024-02-07 04:35:35,687 INFO metabase.events :: Loading events namespace: metabase.events.revision 👂
Feb 06 20:35:352024-02-07 04:35:35,737 INFO metabase.events :: Loading events namespace: metabase.events.schema 👂
Feb 06 20:35:352024-02-07 04:35:35,738 INFO metabase.events :: Loading events namespace: metabase.events.sync-database 👂
Feb 06 20:35:352024-02-07 04:35:35,756 INFO metabase.events :: Loading events namespace: metabase.events.view-log 👂
Feb 06 20:35:352024-02-07 04:35:35,909 DEBUG middleware.log :: POST /api/database/2/sync_schema 200 409.2 ms (3 DB calls) App DB connections: 1/4 Jetty threads: 3/50 (4 idle, 0 queued) (49 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:35:362024-02-07 04:35:36,681 DEBUG middleware.log :: POST /api/database/2/rescan_values 200 55.8 ms (3 DB calls) App DB connections: 1/4 Jetty threads: 3/50 (4 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
Feb 06 20:35:362024-02-07 04:35:36,685 INFO sync.util :: STARTING: Cache field values in mysql Database 2 'Twrl Inventory'
Feb 06 20:35:362024-02-07 04:35:36,731 INFO sync.util :: STARTING: step 'delete-expired-advanced-field-values' for mysql Database 2 'Twrl Inventory'
Feb 06 20:35:372024-02-07 04:35:37,447 INFO sync.util :: FINISHED: step 'delete-expired-advanced-field-values' for mysql Database 2 'Twrl Inventory' (715.1 ms)
Feb 06 20:35:372024-02-07 04:35:37,448 INFO sync.util :: STARTING: step 'update-field-values' for mysql Database 2 'Twrl Inventory'
Feb 06 20:35:392024-02-07 04:35:39,511 INFO sync.util :: FINISHED: step 'update-field-values' for mysql Database 2 'Twrl Inventory' (2.1 s)
Feb 06 20:35:392024-02-07 04:35:39,539 INFO sync.util :: FINISHED: Cache field values in mysql Database 2 'Twrl Inventory' (2.9 s)
Feb 06 20:39:002024-02-07 04:39:00,042 INFO task.sync-databases :: Starting sync task for Database 2.
Feb 06 20:39:002024-02-07 04:39:00,121 ERROR core.JobRunShell :: Job DEFAULT.metabase.task.sync-and-analyze.job threw an unhandled Exception:
Feb 06 20:39:00java.lang.IllegalArgumentException: No matching clause: REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%""
Feb 06 20:39:00at metabase.driver.mysql$parse_grant.invokeStatic(mysql.clj:788)
Feb 06 20:39:00at metabase.driver.mysql$parse_grant.invoke(mysql.clj:766)
Feb 06 20:39:00at clojure.core$map$fn__5935.invoke(core.clj:2770)
Feb 06 20:39:00at clojure.lang.LazySeq.sval(LazySeq.java:42)
Feb 06 20:39:00at clojure.lang.LazySeq.seq(LazySeq.java:51)
Feb 06 20:39:00at clojure.lang.RT.seq(RT.java:535)
Feb 06 20:39:00at clojure.core$seq__5467.invokeStatic(core.clj:139)
Feb 06 20:39:00at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
Feb 06 20:39:00at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
Feb 06 20:39:00at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
Feb 06 20:39:00at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
Feb 06 20:39:00at clojure.core$reduce.invokeStatic(core.clj:6886)
Feb 06 20:39:00at clojure.core$group_by.invokeStatic(core.clj:7214)
Feb 06 20:39:00at clojure.core$group_by.invoke(core.clj:7214)
Feb 06 20:39:00at metabase.driver.mysql$privilege_grants_for_user.invokeStatic(mysql.clj:836)
Feb 06 20:39:00at metabase.driver.mysql$privilege_grants_for_user.invoke(mysql.clj:825)
Feb 06 20:39:00at metabase.driver.mysql$fn__104935.invokeStatic(mysql.clj:884)
Feb 06 20:39:00at metabase.driver.mysql$fn__104935.invoke(mysql.clj:872)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:234)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$schema_PLUS_table_with_select_privileges.invokeStatic(describe_database.clj:125)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$schema_PLUS_table_with_select_privileges.invoke(describe_database.clj:123)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$have_select_privilege_fn.invokeStatic(describe_database.clj:143)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$have_select_privilege_fn.invoke(describe_database.clj:131)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$post_filtered_active_tables.invokeStatic(describe_database.clj:186)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$post_filtered_active_tables.doInvoke(describe_database.clj:181)
Feb 06 20:39:00at clojure.lang.RestFn.applyTo(RestFn.java:142)
Feb 06 20:39:00at clojure.core$apply.invokeStatic(core.clj:667)
Feb 06 20:39:00at clojure.core$apply.invoke(core.clj:662)
Feb 06 20:39:00at metabase.driver.mysql$fn__104819.invokeStatic(mysql.clj:535)
Feb 06 20:39:00at metabase.driver.mysql$fn__104819.doInvoke(mysql.clj:533)
Feb 06 20:39:00at clojure.lang.RestFn.invoke(RestFn.java:457)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:244)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028$fn__81029$default_active_tbl_fn__81030.invoke(describe_database.clj:221)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028$fn__81029.invoke(describe_database.clj:233)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811$fn__78812.invoke(execute.clj:388)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78776$_AMPERSAND_f__78777.invoke(execute.clj:334)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78776$fn__78780.invoke(execute.clj:317)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811.invokeStatic(execute.clj:382)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811.invoke(execute.clj:380)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:244)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028.invoke(describe_database.clj:213)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$fn__81037.invoke(describe_database.clj:208)
Feb 06 20:39:00at metabase.driver.sql_jdbc$fn__107582.invokeStatic(sql_jdbc.clj:94)
Feb 06 20:39:00at metabase.driver.sql_jdbc$fn__107582.invoke(sql_jdbc.clj:92)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:234)
Feb 06 20:39:00at metabase.sync.fetch_metadata$db_metadata.invokeStatic(fetch_metadata.clj:15)
Feb 06 20:39:00at metabase.sync.fetch_metadata$db_metadata.invoke(fetch_metadata.clj:12)
Feb 06 20:39:00at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:61)
Feb 06 20:39:00at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:58)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:94)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:77)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:113)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:101)
Feb 06 20:39:00at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:118)
Feb 06 20:39:00at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
Feb 06 20:39:00at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
Feb 06 20:39:002024-02-07 04:39:00,137 ERROR core.ErrorLogger :: Job (DEFAULT.metabase.task.sync-and-analyze.job threw an exception.
Feb 06 20:39:00org.quartz.SchedulerException: Job threw an unhandled exception. [See nested exception: java.lang.IllegalArgumentException: No matching clause: REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%""]
Feb 06 20:39:00at org.quartz.core.JobRunShell.run(JobRunShell.java:213)
Feb 06 20:39:00at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
Feb 06 20:39:00Caused by: java.lang.IllegalArgumentException: No matching clause: REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%""
Feb 06 20:39:00at metabase.driver.mysql$parse_grant.invokeStatic(mysql.clj:788)
Feb 06 20:39:00at metabase.driver.mysql$parse_grant.invoke(mysql.clj:766)
Feb 06 20:39:00at clojure.core$map$fn__5935.invoke(core.clj:2770)
Feb 06 20:39:00at clojure.lang.LazySeq.sval(LazySeq.java:42)
Feb 06 20:39:00at clojure.lang.LazySeq.seq(LazySeq.java:51)
Feb 06 20:39:00at clojure.lang.RT.seq(RT.java:535)
Feb 06 20:39:00at clojure.core$seq__5467.invokeStatic(core.clj:139)
Feb 06 20:39:00at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
Feb 06 20:39:00at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
Feb 06 20:39:00at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
Feb 06 20:39:00at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
Feb 06 20:39:00at clojure.core$reduce.invokeStatic(core.clj:6886)
Feb 06 20:39:00at clojure.core$group_by.invokeStatic(core.clj:7214)
Feb 06 20:39:00at clojure.core$group_by.invoke(core.clj:7214)
Feb 06 20:39:00at metabase.driver.mysql$privilege_grants_for_user.invokeStatic(mysql.clj:836)
Feb 06 20:39:00at metabase.driver.mysql$privilege_grants_for_user.invoke(mysql.clj:825)
Feb 06 20:39:00at metabase.driver.mysql$fn__104935.invokeStatic(mysql.clj:884)
Feb 06 20:39:00at metabase.driver.mysql$fn__104935.invoke(mysql.clj:872)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:234)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$schema_PLUS_table_with_select_privileges.invokeStatic(describe_database.clj:125)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$schema_PLUS_table_with_select_privileges.invoke(describe_database.clj:123)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$have_select_privilege_fn.invokeStatic(describe_database.clj:143)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$have_select_privilege_fn.invoke(describe_database.clj:131)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$post_filtered_active_tables.invokeStatic(describe_database.clj:186)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$post_filtered_active_tables.doInvoke(describe_database.clj:181)
Feb 06 20:39:00at clojure.lang.RestFn.applyTo(RestFn.java:142)
Feb 06 20:39:00at clojure.core$apply.invokeStatic(core.clj:667)
Feb 06 20:39:00at clojure.core$apply.invoke(core.clj:662)
Feb 06 20:39:00at metabase.driver.mysql$fn__104819.invokeStatic(mysql.clj:535)
Feb 06 20:39:00at metabase.driver.mysql$fn__104819.doInvoke(mysql.clj:533)
Feb 06 20:39:00at clojure.lang.RestFn.invoke(RestFn.java:457)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:244)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028$fn__81029$default_active_tbl_fn__81030.invoke(describe_database.clj:221)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028$fn__81029.invoke(describe_database.clj:233)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811$fn__78812.invoke(execute.clj:388)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78776$_AMPERSAND_f__78777.invoke(execute.clj:334)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78776$fn__78780.invoke(execute.clj:317)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811.invokeStatic(execute.clj:382)
Feb 06 20:39:00at metabase.driver.sql_jdbc.execute$fn__78811.invoke(execute.clj:380)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:244)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$_AMPERSAND_f__81028.invoke(describe_database.clj:213)
Feb 06 20:39:00at metabase.driver.sql_jdbc.sync.describe_database$fn__81027$fn__81037.invoke(describe_database.clj:208)
Feb 06 20:39:00at metabase.driver.sql_jdbc$fn__107582.invokeStatic(sql_jdbc.clj:94)
Feb 06 20:39:00at metabase.driver.sql_jdbc$fn__107582.invoke(sql_jdbc.clj:92)
Feb 06 20:39:00at clojure.lang.MultiFn.invoke(MultiFn.java:234)
Feb 06 20:39:00at metabase.sync.fetch_metadata$db_metadata.invokeStatic(fetch_metadata.clj:15)
Feb 06 20:39:00at metabase.sync.fetch_metadata$db_metadata.invoke(fetch_metadata.clj:12)
Feb 06 20:39:00at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:61)
Feb 06 20:39:00at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:58)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:94)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:77)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:113)
Feb 06 20:39:00at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:101)
Feb 06 20:39:00at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:118)
Feb 06 20:39:00at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
Feb 06 20:39:00... 1 more
Feb 06 20:54:002024-02-07 04:54:00,036 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.
Feb 06 21:00:002024-02-07 05:00:00,047 INFO task.send-pulses :: Sending scheduled pulses...


**To Reproduce**
1. Use Metabase v0.48.4 or v0.48.5 and connect to DigitalOcean managed MySQL 8.
2. Create a new table in MySQL.
3. Click on ""Sync database schema now"" and newly created table does not show up. Also, if ti's a newly added database, the Syncing tables just continues to spin without stopping.

**Expected behavior**
I am expecting to create new DB tables and have it show up in Metabase after I've clicked on ""Sync database schema now"" and ""Re-scan field values now""

**Screenshots**
New DB table (woh_distribution_center) shows up in SQL query
![image](https://github.com/metabase/metabase/assets/5340486/da1eca49-0cbf-4794-b333-7b138a217a74)

But it (Woh Distribution Center) does not show up here
![image](https://github.com/metabase/metabase/assets/5340486/1c6d436a-f6ae-430e-a388-8b70c3be707b)

nor here
![image](https://github.com/metabase/metabase/assets/5340486/14508a35-43a8-40db-9036-d8d5cd5f0f3f)


**Severity**
This is a very severe issue as it is preventing me from completing new deliverables for my clients. It also creates doubts in my client's minds about the continued usage of Metabase.

**Additional context**
I am using Cloudron service hosted with DigitalOcean and using their managed MySQL Database version 8.0. When I tried using a locally hosted version (via Docker) of Metabase v0.48.4 with the DigitalOcean Managed MySQL Datbase, the Syncing tables notification just keeps going... I have to remove the database to stop the syncing.
![image](https://github.com/metabase/metabase/assets/5340486/7cfa3314-5b72-45b3-91d4-16114c8aa352)

When I tried to connect Metabase v0.48.4 from DigitalOcean to my local MariaDB (10.11.2-MariaDB-1:10.11.2+maria~ubu2204 - mariadb.org binary distribution), I do not have the same issue. It works fine.

Others are having similar issues:
https://discourse.metabase.com/t/this-database-doesnt-have-any-tables-mysql/73848
https://discourse.metabase.com/t/v0-48-4-bug/74410


**Metabase Diagnostic Info**
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-post-Ubuntu-0ubuntu122.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-post-Ubuntu-0ubuntu122.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-92-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.9 (Ubuntu 14.9-0ubuntu0.22.04.1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v0.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```",jfang,2024-02-07 05:28:44+00:00,['crisptrutski'],2024-02-13 09:05:08+00:00,2024-02-13 09:05:08+00:00,https://github.com/metabase/metabase/issues/38499,[],"[{'comment_id': 1932016848, 'issue_id': 2122220492, 'author': 'paoliniluis', 'body': ""what's metrics_user_telegraf? a table? a view? a schema?\r\nAre you completely sure that it's a MySQL 8 and not a fork or anything like that?"", 'created_at': datetime.datetime(2024, 2, 7, 13, 8, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932301089, 'issue_id': 2122220492, 'author': 'paoliniluis', 'body': 'Can you run \r\n```\r\nSHOW GRANTS FOR CURRENT_USER()\r\n```\r\nin your DB?', 'created_at': datetime.datetime(2024, 2, 7, 15, 33, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932417514, 'issue_id': 2122220492, 'author': 'jfang', 'body': 'Hi Luis,\r\n\r\n\r\n\r\nGrants for doadmin@%\r\n\r\n| GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, PROCESS, REFERENCES, INDEX, ALTER, SHOW DATABASES, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CR... |\r\n| GRANT REPLICATION_APPLIER,ROLE_ADMIN ON *.* TO ""doadmin""@""%"" WITH GRANT OPTION |\r\n| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%"" |\r\n| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""mysql"".* FROM ""doadmin""@""%"" |\r\n| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""sys"".* FROM ""doadmin""@""%"" |\r\n\r\n\r\nThanks,\r\nJeff\r\n    On Wednesday, February 7, 2024 at 07:33:37 AM PST, Luis Paolini ***@***.***> wrote:  \r\n \r\n \r\n\r\n\r\nCan you run\r\nSHOW GRANTS FOR CURRENT_USER()\r\n\r\nin your DB?\r\n\r\n—\r\nReply to this email directly, view it on GitHub, or unsubscribe.\r\nYou are receiving this because you authored the thread.Message ID: ***@***.***>', 'created_at': datetime.datetime(2024, 2, 7, 16, 27, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932420461, 'issue_id': 2122220492, 'author': 'jfang', 'body': ""Hi Luis,\r\nI'm not sure what\xa0metrics_user_telegraf is.\r\nYour MySQL connection id is 87861Server version: 8.0.30 Source distribution\r\n\r\n\r\n\r\n    On Wednesday, February 7, 2024 at 05:08:55 AM PST, Luis Paolini ***@***.***> wrote:  \r\n \r\n \r\n\r\n\r\nwhat's metrics_user_telegraf? a table? a view? a schema?\r\nAre you completely sure that it's a MySQL 8 and not a fork or anything like that?\r\n\r\n—\r\nReply to this email directly, view it on GitHub, or unsubscribe.\r\nYou are receiving this because you authored the thread.Message ID: ***@***.***>"", 'created_at': datetime.datetime(2024, 2, 7, 16, 28, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932619875, 'issue_id': 2122220492, 'author': 'paoliniluis', 'body': 'I\'m not able to reproduce what you\'re seeing. If you see one of the responses of the grants, you\'ll see a line of the error you post above\r\nREVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%""', 'created_at': datetime.datetime(2024, 2, 7, 18, 18, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1933111906, 'issue_id': 2122220492, 'author': 'jfang', 'body': 'Thanks again for looking into this. I just installed a Docker instance of Metabase v0.48.3 on my local system and connected to DigitalOcean\'s managed MySQL 8 database. I did not have any issues connecting to the existing database tables and I was able to create new tables and Sync without issues. The Syncing tables took a few seconds to complete.\r\n\r\nScreenshot from v.0.48.3\r\n![image](https://github.com/metabase/metabase/assets/5340486/9c78c8d7-e97b-4150-b7c5-6318a80247e0)\r\n\r\nI also installed the Docker instances of v0.48.4 and v0.48.5 on my local system and connected to DigitalOcean\'s managed MySQL database. For these two instances, when I click on Browse data and select my ""Test"" database, it is not able to see any tables  The Syncing... notification shows Syncing tables... and continues to spin. See below. Something changed between v0.48.3 to v0.48.4.\r\n\r\nScreenshot from v0.48.4\r\n![image](https://github.com/metabase/metabase/assets/5340486/f2d12944-3517-4545-bb08-4ec65e4dd277)\r\n\r\nScreenshot from v0.48.5\r\n![image](https://github.com/metabase/metabase/assets/5340486/7ad8b6aa-e656-42e0-a9b8-3dacdf420016)\r\n\r\nI tried ""+ New"" > ""SQL query"" with a SELECT statement (for both v0.48.4 and v0.48.5) and was able to see the data in the table ""sales_orders"", eventhough it is still trying to sync.\r\n![image](https://github.com/metabase/metabase/assets/5340486/786a1b85-84ff-4242-8a6b-a57e2163645b)\r\n\r\nI did not change any settings in MySQL 8 on DigitalOcean or updates to the MySQL user permissions.', 'created_at': datetime.datetime(2024, 2, 7, 23, 30, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938754212, 'issue_id': 2122220492, 'author': 'crisptrutski', 'body': 'This issue should be fixed in the upcoming 0.48.6 release', 'created_at': datetime.datetime(2024, 2, 12, 14, 11, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938865881, 'issue_id': 2122220492, 'author': 'jfang', 'body': 'Thank you!', 'created_at': datetime.datetime(2024, 2, 12, 15, 12, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 1940829880, 'issue_id': 2122220492, 'author': 'lbrdnk', 'body': 'Fixed by #38552.', 'created_at': datetime.datetime(2024, 2, 13, 9, 5, 8, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-07 13:08:43 UTC): what's metrics_user_telegraf? a table? a view? a schema?
Are you completely sure that it's a MySQL 8 and not a fork or anything like that?

paoliniluis on (2024-02-07 15:33:25 UTC): Can you run 
```
SHOW GRANTS FOR CURRENT_USER()
```
in your DB?

jfang (Issue Creator) on (2024-02-07 16:27:15 UTC): Hi Luis,



Grants for doadmin@%

| GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, PROCESS, REFERENCES, INDEX, ALTER, SHOW DATABASES, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CR... |
| GRANT REPLICATION_APPLIER,ROLE_ADMIN ON *.* TO ""doadmin""@""%"" WITH GRANT OPTION |
| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%"" |
| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""mysql"".* FROM ""doadmin""@""%"" |
| REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""sys"".* FROM ""doadmin""@""%"" |


Thanks,
Jeff
    On Wednesday, February 7, 2024 at 07:33:37 AM PST, Luis Paolini ***@***.***> wrote:  
 
 


Can you run
SHOW GRANTS FOR CURRENT_USER()

in your DB?

—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***>

jfang (Issue Creator) on (2024-02-07 16:28:39 UTC): Hi Luis,
I'm not sure what metrics_user_telegraf is.
Your MySQL connection id is 87861Server version: 8.0.30 Source distribution



    On Wednesday, February 7, 2024 at 05:08:55 AM PST, Luis Paolini ***@***.***> wrote:  
 
 


what's metrics_user_telegraf? a table? a view? a schema?
Are you completely sure that it's a MySQL 8 and not a fork or anything like that?

—
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***>

paoliniluis on (2024-02-07 18:18:53 UTC): I'm not able to reproduce what you're seeing. If you see one of the responses of the grants, you'll see a line of the error you post above
REVOKE INSERT, UPDATE, DELETE, CREATE, DROP, REFERENCES, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, EVENT, TRIGGER ON ""metrics_user_telegraf"".* FROM ""doadmin""@""%""

jfang (Issue Creator) on (2024-02-07 23:30:16 UTC): Thanks again for looking into this. I just installed a Docker instance of Metabase v0.48.3 on my local system and connected to DigitalOcean's managed MySQL 8 database. I did not have any issues connecting to the existing database tables and I was able to create new tables and Sync without issues. The Syncing tables took a few seconds to complete.

Screenshot from v.0.48.3
![image](https://github.com/metabase/metabase/assets/5340486/9c78c8d7-e97b-4150-b7c5-6318a80247e0)

I also installed the Docker instances of v0.48.4 and v0.48.5 on my local system and connected to DigitalOcean's managed MySQL database. For these two instances, when I click on Browse data and select my ""Test"" database, it is not able to see any tables  The Syncing... notification shows Syncing tables... and continues to spin. See below. Something changed between v0.48.3 to v0.48.4.

Screenshot from v0.48.4
![image](https://github.com/metabase/metabase/assets/5340486/f2d12944-3517-4545-bb08-4ec65e4dd277)

Screenshot from v0.48.5
![image](https://github.com/metabase/metabase/assets/5340486/7ad8b6aa-e656-42e0-a9b8-3dacdf420016)

I tried ""+ New"" > ""SQL query"" with a SELECT statement (for both v0.48.4 and v0.48.5) and was able to see the data in the table ""sales_orders"", eventhough it is still trying to sync.
![image](https://github.com/metabase/metabase/assets/5340486/786a1b85-84ff-4242-8a6b-a57e2163645b)

I did not change any settings in MySQL 8 on DigitalOcean or updates to the MySQL user permissions.

crisptrutski (Assginee) on (2024-02-12 14:11:33 UTC): This issue should be fixed in the upcoming 0.48.6 release

jfang (Issue Creator) on (2024-02-12 15:12:44 UTC): Thank you!

lbrdnk on (2024-02-13 09:05:08 UTC): Fixed by #38552.

"
2122100444,issue,open,,Custom column of convertTimezone dissapears if the timezone is entered incorrectly,"### Describe the bug

As soon as I add the custom column it dissapears

### To Reproduce

1) create a question with the orders table and add a custom column =convertTimezone([Created At], ""Asia/Ho_Chi_Mihn"", ""UTC"")
2) click visualize, the column will have dissapeared

### Expected behavior

We should tell the user that the timezone does not exist

### Logs

NA

### Information about your Metabase installation

```JSON
v47+
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-02-07 03:16:20+00:00,[],2025-02-04 20:28:56+00:00,,https://github.com/metabase/metabase/issues/38498,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Notebook/Custom Column', ''), ('.Team/Querying', '')]","[{'comment_id': 2116122777, 'issue_id': 2122100444, 'author': 'ranquild', 'body': '`Lib.diagnoseExpression` could handle that', 'created_at': datetime.datetime(2024, 5, 16, 20, 28, 39, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-05-16 20:28:39 UTC): `Lib.diagnoseExpression` could handle that

"
2121768896,issue,closed,completed,Getting fields in (Redshift) is slow,"### Describe the bug
(leaving the old description on the Additional context section of the issue)

Before 48, we used to go table by table on each schema checking for permissions. This was fixed already (checked on my machine and it takes 10 min in v48, super fast to what it was before), but now the problem is on getting fields: for every field we will go one by one inserting those into the DB which takes a huge amount of time

### To Reproduce

1) just connect a redshift cluster with Metabase and see the sync logs, it takes a massive amount of time for lots of tables

### Expected behavior

_No response_

### Logs

Above

### Information about your Metabase installation

```JSON
I believe it's been like this forever
```


### Severity

P1

### Additional context

OLD ISSUE here:
Seems that when we check for SELECT we do
```
2024-02-06 22:01:52,345 TRACE sync.describe-database :: Checking for SELECT privileges for ""federated_sample1"".""_metabase_metadata"" with query [""SELECT TRUE AS \""_\"" FROM \""federated_sample1\"".\""_metabase_metadata\"" WHERE 1 <> 1 LIMIT 0""]
2024-02-06 22:01:53,047 TRACE sync.describe-database :: [redshift] SELECT TRUE AS ""_"" FROM ""federated_sample1"".""_metabase_metadata"" WHERE 1 <> 1 LIMIT 0
2024-02-06 22:01:53,965 TRACE sync.describe-database :: SELECT privileges confirmed
2024-02-06 22:01:53,969 TRACE sync.describe-database :: Checking for SELECT privileges for ""federated_sample1"".""accounts"" with query [""SELECT TRUE AS \""_\"" FROM \""federated_sample1\"".\""accounts\"" WHERE 1 <> 1 LIMIT 0""]
2024-02-06 22:01:54,683 TRACE sync.describe-database :: [redshift] SELECT TRUE AS ""_"" FROM ""federated_sample1"".""accounts"" WHERE 1 <> 1 LIMIT 0
2024-02-06 22:01:55,472 TRACE sync.describe-database :: SELECT privileges confirmed
2024-02-06 22:01:55,476 TRACE sync.describe-database :: Checking for SELECT privileges for ""federated_sample1"".""analytic_events"" with query [""SELECT TRUE AS \""_\"" FROM \""federated_sample1\"".\""analytic_events\"" WHERE 1 <> 1 LIMIT 0""]
2024-02-06 22:01:56,135 TRACE sync.describe-database :: [redshift] SELECT TRUE AS ""_"" FROM ""federated_sample1"".""analytic_events"" WHERE 1 <> 1 LIMIT 0
2024-02-06 22:01:57,037 TRACE sync.describe-database :: SELECT privileges confirmed
```
...

Every query needs a separate connection and it can take 1 second or more depending where you are.

There's a way to make this more efficient
```
WITH tables_and_views as (SELECT schemaname
                               , objectname
                               , usename
                               , HAS_TABLE_PRIVILEGE(usrs.usename, fullobj, 'select') AND
                                 has_schema_privilege(usrs.usename, schemaname, 'usage') AS sel
                          FROM (SELECT schemaname,
                                       't'                          AS obj_type,
                                       tablename                    AS objectname,
                                       schemaname + '.' + tablename AS fullobj
                                FROM pg_tables
                                WHERE schemaname not in ('pg_internal', 'pg_automv', 'information_schema', 'pg_catalog')
                                UNION
                                SELECT schemaname,
                                       'v'                         AS obj_type,
                                       viewname                    AS objectname,
                                       schemaname + '.' + viewname AS fullobj
                                FROM pg_views
                                WHERE schemaname not in
                                      ('pg_internal', 'pg_automv', 'information_schema', 'pg_catalog')) AS objs
                             , (SELECT * FROM pg_user) AS usrs),
     external_objects as (SELECT schemaname,
                                 objectname,
                                 usename,
                                 'true' AS sel
                          FROM (SELECT schemaname,
                                       't'                          as obj_type,
                                       tablename                    as objectname,
                                       schemaname + '.' + tablename AS fullobj FROM SVV_EXTERNAL_TABLES)
                              AS objs
                             , (SELECT * FROM pg_user) AS usrs)

SELECT *
FROM tables_and_views
UNION ALL
SELECT *
FROM external_objects
```
(extracted from https://stackoverflow.com/questions/18741334/how-do-i-view-grants-on-redshift with a slight tweak for external objects as we trust that the user has select priviledges there, as otherwise the connection between servers could not have been made)
",paoliniluis,2024-02-06 22:23:54+00:00,['calherries'],2024-03-19 18:03:16+00:00,2024-03-19 17:36:45+00:00,https://github.com/metabase/metabase/issues/38492,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Redshift', None), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 1930871369, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'cc @qnkhuat in case you want to take a look', 'created_at': datetime.datetime(2024, 2, 6, 22, 24, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 1931844154, 'issue_id': 2121768896, 'author': 'qnkhuat', 'body': 'Which version are you testing this on? https://github.com/metabase/metabase/pull/37439 should already fix this for redshift', 'created_at': datetime.datetime(2024, 2, 7, 11, 27, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 1932005799, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': '@qnkhuat 48.5 release\r\n![image](https://github.com/metabase/metabase/assets/1711649/2930706a-3b98-43d2-891a-40e9ea3da17a)\r\n![image](https://github.com/metabase/metabase/assets/1711649/19bcfcf4-f2e1-4bd9-b7e7-2972204eaab5)', 'created_at': datetime.datetime(2024, 2, 7, 13, 2, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1937995706, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': ""Adding a few findings that I was able to get investigating 46, 47 and 48:\r\n1) v47 takes more time than 46 for every single permission change. On 46 it took 366ms for every query, while in 47 it takes 490 ms\r\nHere are the logs and the time differences\r\n[metabase46-filtered.log](https://github.com/metabase/metabase/files/14234629/metabase46-filtered.log)\r\n[metabase47-filtered.log](https://github.com/metabase/metabase/files/14234630/metabase47-filtered.log)\r\n[time-differences46.txt](https://github.com/metabase/metabase/files/14234638/time-differences46.txt)\r\n[metabase47-filtered.log](https://github.com/metabase/metabase/files/14234639/metabase47-filtered.log)\r\n2) in v48 we no longer log the permission check lines with the same logging config we have in 46-47, so I wasn't able to check the performance of 48 on permission checks\r\n\r\nI also tested using a single schema with an absurd amount of tables: it works super fast... so it seems that the problem is when we have lots of schemas, and lots of tables inside those schemas\r\n\r\ncc @qnkhuat sorry for telling you above that the logs I saw were in 48.5, clearly that was not the version I was running as I'm not able to see that right now"", 'created_at': datetime.datetime(2024, 2, 12, 2, 34, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938008442, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'Even if we make the permissions check faster, then the describe table, describe field and all subsequent operations will be slow as it goes 1 by 1, e.g. https://github.com/metabase/metabase/issues/38644', 'created_at': datetime.datetime(2024, 2, 12, 3, 1, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938341876, 'issue_id': 2121768896, 'author': 'calherries', 'body': '@paoliniluis since https://github.com/metabase/metabase/pull/37439 was merged we only do one query for non-external tables in a database. We are still doing one query per table for external tables though, so we can incorporate your subquery on `SVV_EXTERNAL_TABLES` that you included above and it should be a lot speedier.', 'created_at': datetime.datetime(2024, 2, 12, 9, 50, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938554737, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': '@calherries thanks, the test to pass here is to sync the database named ""massive"" in our dev instance in the shortest amount of time. I\'ve tried to sync it with 48.5 and it\'s been syncing for a day with no results\r\n\r\nEDIT: took me ~9 minutes since the DB was added till Metabase found schemas and tables. Now the problem is that it goes field by field inserting into the app DB and it\'s going to take ages', 'created_at': datetime.datetime(2024, 2, 12, 12, 6, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938648418, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'Changing the name of this to the real problem: https://github.com/metabase/metabase/pull/37439 fixed the get tables and get permissions, but now the problem seems to be that getting every field of every table takes a bunch of time and that slows down the process', 'created_at': datetime.datetime(2024, 2, 12, 13, 7, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 1939333572, 'issue_id': 2121768896, 'author': 'calherries', 'body': ""It's probably not just getting fields that could do with optimizing. Here are the timings from the major steps while syncing the much smaller dev database:\r\n```\r\nsync-fields 2.5 mins\r\nsync-fks 1.4 mins\r\nfingerprint-fields 1.9 mins\r\nupdate-field-values 4.3 mins\r\n```\r\n\r\nSyncing fields seems to be the longest of the analyze-data step, but syncing foreign keys is on the same order of magnitude. Fingerprinting and field values have similar problems, but we knew that already."", 'created_at': datetime.datetime(2024, 2, 12, 18, 48, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 1941600437, 'issue_id': 2121768896, 'author': 'calherries', 'body': '@paoliniluis do you know if there was a script used to create massive? Would be nice to have a small version to test on', 'created_at': datetime.datetime(2024, 2, 13, 14, 8, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 1941814509, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': '@calherries yup, here it is:\r\n\r\nuse bun and run:\r\n- bun init\r\n- bun install pg\r\n- bun install random-words\r\n- bun install sequelize\r\n\r\nthen just run the following script with bun and leave it till it fails:\r\n```\r\nconst { Sequelize } = require(\'sequelize\');\r\nimport { generate } from ""random-words"";\r\n\r\nconst config = {\r\n  dialect: \'postgres\',\r\n  host: \'redshifthostname\',\r\n  port: 5439,\r\n  database: \'massive\',\r\n  username: \'username\',\r\n  password: \'password\',\r\n  dialectOptions: {\r\n    ssl: {\r\n      require: true,\r\n      rejectUnauthorized: false\r\n    },\r\n    clientMinMessages: \'ignore\'\r\n  },\r\n  standardConformingStrings: false\r\n};\r\n\r\n\r\nconst sequelize = new Sequelize(config);\r\n\r\nlet counter = 0;\r\n// let schema_name = generate().concat(""_1"");\r\nlet schema_name = \'public\'\r\n\r\nwhile (true) {\r\n  try {\r\n    if (counter == 10) {\r\n      counter = 0;\r\n      // schema_name = generate().concat(Math.floor(Math.random() * 100) + 1);\r\n      schema_name = \'public\'\r\n    }\r\n    let table_name = generate().concat(Math.floor(Math.random() * 100) + 1);\r\n    // await sequelize.query(`CREATE SCHEMA IF NOT EXISTS ""${schema_name}"";`);\r\n    await sequelize.query(`CREATE TABLE IF NOT EXISTS ""${schema_name}"".""${table_name}"" (\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" VARCHAR(255),\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" CHAR(10),\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BIGINT,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DECIMAL(10,2),\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" REAL,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DOUBLE PRECISION,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BOOLEAN,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DATE,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMP,\r\n      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMPTZ\r\n    );`);\r\n    await sequelize.query(`INSERT INTO ""${schema_name}"".""${table_name}"" VALUES \r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\'),\r\n    (1, \'test\', \'test\', 1, 1, 1.1, 1.1, 1.1, true, \'2021-01-01\', \'2021-01-01 00:00:00\', \'2021-01-01 00:00:00\')\r\n    ;`);\r\n    counter++;\r\n  } catch (err) {\r\n    console.log(err);\r\n  }\r\n}\r\n```\r\n\r\nEDIT: uncomment the 2 commented lines and comment `schema_name = \'public\'`to make it multi-schema', 'created_at': datetime.datetime(2024, 2, 13, 15, 40, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 1942079347, 'issue_id': 2121768896, 'author': 'calherries', 'body': ""I found two causes: (1) querying each table’s metadata one-by-one in series and (2) calling `sql-jdbc.execute/do-with-connection-with-options` once for every table, which is super expensive (>500 ms per table). After we fix these two things, the `sync-fields` step should take >90% less time for syncing this database on my laptop. We can apply the same logic to `sync-fks` too. This isn’t a redshift specific issue so solving it will solve it for all DBs. I’m pretty sure it’ll solve our redshift flake issues too. The bad news: it will require a pretty big redesign of the sync code of similar in scope to the last big sync refactor, [3 years ago](https://github.com/metabase/metabase/pull/13746).\r\n\r\nbtw, https://github.com/metabase/metabase/issues/38644 will help but the biggest problem is that we're not using our connections effectively"", 'created_at': datetime.datetime(2024, 2, 13, 17, 39, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 1973727830, 'issue_id': 2121768896, 'author': 'calherries', 'body': 'The plan is to land these two PRs and backport them to 49:\r\n#38828\r\n#38970 \r\n\r\nBackporting to earlier versions is also possible and might not be much effort, given the stability of the sync code.\r\n\r\nI give a median time estimate of one week to complete these two PRs.\r\n\r\nThese will make redshift schema sync sufficiently fast to sync massive in minutes, not hours, but only for redshift, and excludes the fingerprint and field values steps, which will still take longer. But you will be able to query the tables at least.\r\n\r\nWe can then do the same thing for other drivers that we want to make faster, such as bigquery.', 'created_at': datetime.datetime(2024, 3, 1, 18, 37, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995152747, 'issue_id': 2121768896, 'author': 'calherries', 'body': 'The first of these, https://github.com/metabase/metabase/pull/38970, is in the 49 branch.\r\nThe second, https://github.com/metabase/metabase/pull/38828/, is currently in review. With this second branch I was able to sync the metadata of ""massive"" in 5 minutes from my laptop, which should be sufficient to close this issue.', 'created_at': datetime.datetime(2024, 3, 13, 17, 46, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995347977, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'outstanding', 'created_at': datetime.datetime(2024, 3, 13, 18, 43, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 1997438325, 'issue_id': 2121768896, 'author': 'calherries', 'body': ""Closed by \r\nhttps://github.com/metabase/metabase/pull/38970 (to be released in 49.0)\r\nhttps://github.com/metabase/metabase/pull/38828 (this didn't quite make 49.0, but will be in 49.1)"", 'created_at': datetime.datetime(2024, 3, 14, 13, 15, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007633299, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': ""I just tested syncing the massive database on my laptop. The initial sync will ingest tables very fast but it will take a LOT of time to insert the fields, the code to insert the fields from zero is still sequential and it ingests the fields at around 12 fields per second.\r\n\r\nAs the massive database has 121051 fields, the total sync time is 10087 seconds or 168 minutes or around 3 hours. Yes, we made an improvement of 10 hours to 3 hours, but I think we can take this to minutes or at least 1 hour (https://github.com/metabase/metabase/issues/38973)\r\n\r\nReopening to keep track that there's still room for improvement"", 'created_at': datetime.datetime(2024, 3, 19, 16, 29, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007637060, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'removing the escalation tag', 'created_at': datetime.datetime(2024, 3, 19, 16, 31, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007771114, 'issue_id': 2121768896, 'author': 'calherries', 'body': 'closing again, Luiggi was using the wrong version, phew :)', 'created_at': datetime.datetime(2024, 3, 19, 17, 36, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007819286, 'issue_id': 2121768896, 'author': 'paoliniluis', 'body': 'yes yes yes', 'created_at': datetime.datetime(2024, 3, 19, 18, 3, 16, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-02-06 22:24:36 UTC): cc @qnkhuat in case you want to take a look

qnkhuat on (2024-02-07 11:27:41 UTC): Which version are you testing this on? https://github.com/metabase/metabase/pull/37439 should already fix this for redshift

paoliniluis (Issue Creator) on (2024-02-07 13:02:53 UTC): @qnkhuat 48.5 release
![image](https://github.com/metabase/metabase/assets/1711649/2930706a-3b98-43d2-891a-40e9ea3da17a)
![image](https://github.com/metabase/metabase/assets/1711649/19bcfcf4-f2e1-4bd9-b7e7-2972204eaab5)

paoliniluis (Issue Creator) on (2024-02-12 02:34:10 UTC): Adding a few findings that I was able to get investigating 46, 47 and 48:
1) v47 takes more time than 46 for every single permission change. On 46 it took 366ms for every query, while in 47 it takes 490 ms
Here are the logs and the time differences
[metabase46-filtered.log](https://github.com/metabase/metabase/files/14234629/metabase46-filtered.log)
[metabase47-filtered.log](https://github.com/metabase/metabase/files/14234630/metabase47-filtered.log)
[time-differences46.txt](https://github.com/metabase/metabase/files/14234638/time-differences46.txt)
[metabase47-filtered.log](https://github.com/metabase/metabase/files/14234639/metabase47-filtered.log)
2) in v48 we no longer log the permission check lines with the same logging config we have in 46-47, so I wasn't able to check the performance of 48 on permission checks

I also tested using a single schema with an absurd amount of tables: it works super fast... so it seems that the problem is when we have lots of schemas, and lots of tables inside those schemas

cc @qnkhuat sorry for telling you above that the logs I saw were in 48.5, clearly that was not the version I was running as I'm not able to see that right now

paoliniluis (Issue Creator) on (2024-02-12 03:01:39 UTC): Even if we make the permissions check faster, then the describe table, describe field and all subsequent operations will be slow as it goes 1 by 1, e.g. https://github.com/metabase/metabase/issues/38644

calherries (Assginee) on (2024-02-12 09:50:46 UTC): @paoliniluis since https://github.com/metabase/metabase/pull/37439 was merged we only do one query for non-external tables in a database. We are still doing one query per table for external tables though, so we can incorporate your subquery on `SVV_EXTERNAL_TABLES` that you included above and it should be a lot speedier.

paoliniluis (Issue Creator) on (2024-02-12 12:06:45 UTC): @calherries thanks, the test to pass here is to sync the database named ""massive"" in our dev instance in the shortest amount of time. I've tried to sync it with 48.5 and it's been syncing for a day with no results

EDIT: took me ~9 minutes since the DB was added till Metabase found schemas and tables. Now the problem is that it goes field by field inserting into the app DB and it's going to take ages

paoliniluis (Issue Creator) on (2024-02-12 13:07:35 UTC): Changing the name of this to the real problem: https://github.com/metabase/metabase/pull/37439 fixed the get tables and get permissions, but now the problem seems to be that getting every field of every table takes a bunch of time and that slows down the process

calherries (Assginee) on (2024-02-12 18:48:27 UTC): It's probably not just getting fields that could do with optimizing. Here are the timings from the major steps while syncing the much smaller dev database:
```
sync-fields 2.5 mins
sync-fks 1.4 mins
fingerprint-fields 1.9 mins
update-field-values 4.3 mins
```

Syncing fields seems to be the longest of the analyze-data step, but syncing foreign keys is on the same order of magnitude. Fingerprinting and field values have similar problems, but we knew that already.

calherries (Assginee) on (2024-02-13 14:08:27 UTC): @paoliniluis do you know if there was a script used to create massive? Would be nice to have a small version to test on

paoliniluis (Issue Creator) on (2024-02-13 15:40:06 UTC): @calherries yup, here it is:

use bun and run:
- bun init
- bun install pg
- bun install random-words
- bun install sequelize

then just run the following script with bun and leave it till it fails:
```
const { Sequelize } = require('sequelize');
import { generate } from ""random-words"";

const config = {
  dialect: 'postgres',
  host: 'redshifthostname',
  port: 5439,
  database: 'massive',
  username: 'username',
  password: 'password',
  dialectOptions: {
    ssl: {
      require: true,
      rejectUnauthorized: false
    },
    clientMinMessages: 'ignore'
  },
  standardConformingStrings: false
};


const sequelize = new Sequelize(config);

let counter = 0;
// let schema_name = generate().concat(""_1"");
let schema_name = 'public'

while (true) {
  try {
    if (counter == 10) {
      counter = 0;
      // schema_name = generate().concat(Math.floor(Math.random() * 100) + 1);
      schema_name = 'public'
    }
    let table_name = generate().concat(Math.floor(Math.random() * 100) + 1);
    // await sequelize.query(`CREATE SCHEMA IF NOT EXISTS ""${schema_name}"";`);
    await sequelize.query(`CREATE TABLE IF NOT EXISTS ""${schema_name}"".""${table_name}"" (
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" VARCHAR(255),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" CHAR(10),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BIGINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DECIMAL(10,2),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" REAL,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DOUBLE PRECISION,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BOOLEAN,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DATE,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMP,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMPTZ
    );`);
    await sequelize.query(`INSERT INTO ""${schema_name}"".""${table_name}"" VALUES 
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00')
    ;`);
    counter++;
  } catch (err) {
    console.log(err);
  }
}
```

EDIT: uncomment the 2 commented lines and comment `schema_name = 'public'`to make it multi-schema

calherries (Assginee) on (2024-02-13 17:39:43 UTC): I found two causes: (1) querying each table’s metadata one-by-one in series and (2) calling `sql-jdbc.execute/do-with-connection-with-options` once for every table, which is super expensive (>500 ms per table). After we fix these two things, the `sync-fields` step should take >90% less time for syncing this database on my laptop. We can apply the same logic to `sync-fks` too. This isn’t a redshift specific issue so solving it will solve it for all DBs. I’m pretty sure it’ll solve our redshift flake issues too. The bad news: it will require a pretty big redesign of the sync code of similar in scope to the last big sync refactor, [3 years ago](https://github.com/metabase/metabase/pull/13746).

btw, https://github.com/metabase/metabase/issues/38644 will help but the biggest problem is that we're not using our connections effectively

calherries (Assginee) on (2024-03-01 18:37:03 UTC): The plan is to land these two PRs and backport them to 49:
#38828
#38970 

Backporting to earlier versions is also possible and might not be much effort, given the stability of the sync code.

I give a median time estimate of one week to complete these two PRs.

These will make redshift schema sync sufficiently fast to sync massive in minutes, not hours, but only for redshift, and excludes the fingerprint and field values steps, which will still take longer. But you will be able to query the tables at least.

We can then do the same thing for other drivers that we want to make faster, such as bigquery.

calherries (Assginee) on (2024-03-13 17:46:11 UTC): The first of these, https://github.com/metabase/metabase/pull/38970, is in the 49 branch.
The second, https://github.com/metabase/metabase/pull/38828/, is currently in review. With this second branch I was able to sync the metadata of ""massive"" in 5 minutes from my laptop, which should be sufficient to close this issue.

paoliniluis (Issue Creator) on (2024-03-13 18:43:39 UTC): outstanding

calherries (Assginee) on (2024-03-14 13:15:25 UTC): Closed by 
https://github.com/metabase/metabase/pull/38970 (to be released in 49.0)
https://github.com/metabase/metabase/pull/38828 (this didn't quite make 49.0, but will be in 49.1)

paoliniluis (Issue Creator) on (2024-03-19 16:29:53 UTC): I just tested syncing the massive database on my laptop. The initial sync will ingest tables very fast but it will take a LOT of time to insert the fields, the code to insert the fields from zero is still sequential and it ingests the fields at around 12 fields per second.

As the massive database has 121051 fields, the total sync time is 10087 seconds or 168 minutes or around 3 hours. Yes, we made an improvement of 10 hours to 3 hours, but I think we can take this to minutes or at least 1 hour (https://github.com/metabase/metabase/issues/38973)

Reopening to keep track that there's still room for improvement

paoliniluis (Issue Creator) on (2024-03-19 16:31:48 UTC): removing the escalation tag

calherries (Assginee) on (2024-03-19 17:36:46 UTC): closing again, Luiggi was using the wrong version, phew :)

paoliniluis (Issue Creator) on (2024-03-19 18:03:16 UTC): yes yes yes

"
2121677982,issue,closed,completed,Null values applied to filters with empty values in custom url from Click Behavior,"### Describe the bug

Null values are being applied to filters with empty values in custom urls generated from Click Behavior functionality.

### To Reproduce

1.) Create a basic query and attach to a dashboard.
```
SELECT *
FROM player_salary
WHERE {{team}}
  AND {{seasonID}}
```

<br>
<br>


2.) Create Click Behavior action from the dashboard that's going to a url with these parameters (team, seasonID) passed in.


**1.48.5**
**Null** is automatically being applied even though nothing was selected for the **‘seasonID’** filter.


<img width=""1458"" alt=""Screenshot 2024-02-06 at 2 31 26 PM"" src=""https://github.com/metabase/metabase/assets/17398657/76c9dfc1-ac9e-4601-bf31-35b9375a7ef9"">

<img width=""700"" alt=""Screenshot 2024-02-06 at 2 32 14 PM"" src=""https://github.com/metabase/metabase/assets/17398657/4b229137-0155-464b-9df0-fa4818fe085e"">


<br>
<br>


**1.47.9**
**‘seasonID’** isn't passed into the url since no filter values have been selected.
![Screenshot 2024-02-06 at 2 34 51 PM](https://github.com/metabase/metabase/assets/17398657/16d7ede0-c8dc-4d72-b581-6d1e96cc617c)

![Screenshot 2024-02-06 at 2 36 47 PM](https://github.com/metabase/metabase/assets/17398657/60bcdecc-8df9-4ff2-81c3-641fd6310632)


### Expected behavior

Results similar to 47 version as having a null value for a filter would produce unexpected results

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo"",
      ""h2"",
      ""mysql"",
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-06"",
      ""tag"": ""v1.48.5"",
      ""hash"": ""dab12cf""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```


### Severity

P2 - Results similar to 47 version as having a null value for a filter would produce unexpected results

### Additional context

_No response_",FilmonK,2024-02-06 21:15:44+00:00,['JesseSDevaney'],2024-03-19 21:02:17+00:00,2024-03-19 19:33:16+00:00,https://github.com/metabase/metabase/issues/38489,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2121584148,issue,closed,completed,[Epic] MLv2 Metrics v2,"MBQL queries read operations that get affected by metrics v2:
- Computing the list of clauses. It is affected because metrics-based queries have the last stage of a metric query combined with a consumer query.
- Computing the list of columns. It is affected because a metric defines a list of exposed dimensions; only these dimensions should be available in consumer queries.

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/36108
- [ ] https://github.com/metabase/metabase/issues/37105
```",camsaul,2024-02-06 20:09:27+00:00,[],2024-02-23 16:48:10+00:00,2024-02-23 16:48:09+00:00,https://github.com/metabase/metabase/issues/38484,"[('Administration/Metrics & Segments', ''), ('.Backend', ''), ('.Epic', 'Feature Implementation or Project'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib')]",[],
2121340888,issue,open,,Allow hiding individual components instead of sections in Interactive embedding,"**Is your feature request related to a problem? Please describe.**
Currently, you can only hide sections (header, actions buttons, etc.), but you can't hide specific components (like the refresh button, subscriptions button, etc.)

**Describe the solution you'd like**
Have the option to hide individual components, in addition to https://www.metabase.com/docs/latest/embedding/interactive-embedding#showing-or-hiding-metabase-ui-components

**Describe alternatives you've considered**
Applying Permissions, but it won't cover all and it's a workaround 

**How important is this feature to you?**
Several multi-tenant customers requested this

**Additional context**
N/A
",ignacio-mb,2024-02-06 17:31:53+00:00,[],2024-07-15 11:30:20+00:00,,https://github.com/metabase/metabase/issues/38477,"[('Type:New Feature', ''), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]","[{'comment_id': 1930455876, 'issue_id': 2121340888, 'author': 'paoliniluis', 'body': 'related to https://github.com/metabase/metabase/issues/35460 and https://github.com/metabase/metabase/issues/25249', 'created_at': datetime.datetime(2024, 2, 6, 17, 44, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2004338862, 'issue_id': 2121340888, 'author': 'albertoperdomo', 'body': ""Hello,\r\n\r\nI am the product manager for embedding and white-labeling at Metabase.\r\nWe're in the early stages of developing an SDK for interactive embedding and are looking for customers who would like to partner with us, test prototypes, provide feedback, and help us shape a great product.\r\n\r\nOne of the things we think this SDK should allow is more fine-granular control over the different components embedded.\r\n\r\nIf this sounds exciting to you, please [schedule a call with me](https://calendly.com/alberto-metabase/30min)."", 'created_at': datetime.datetime(2024, 3, 18, 16, 8, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 17:44:06 UTC): related to https://github.com/metabase/metabase/issues/35460 and https://github.com/metabase/metabase/issues/25249

albertoperdomo on (2024-03-18 16:08:33 UTC): Hello,

I am the product manager for embedding and white-labeling at Metabase.
We're in the early stages of developing an SDK for interactive embedding and are looking for customers who would like to partner with us, test prototypes, provide feedback, and help us shape a great product.

One of the things we think this SDK should allow is more fine-granular control over the different components embedded.

If this sounds exciting to you, please [schedule a call with me](https://calendly.com/alberto-metabase/30min).

"
2121269929,issue,closed,completed,Add a link to Metabase Analytics -> Question overview / Dashboard overview in the question/dashboard detail page,"**Context**
Users may want to explore how a dashboard/question is used from the question/dashboard page. Today, the user must go to the Metabase analytics collection, navigate to the dashboard and filter the question/dashboard.

We can simply add a link in the question/dashboard detail page to the overview dashboard, filtering the content ID.

- Add a new option in the `...` menu to `Usage insights` (it should use the same Metabase analytics icon)
- If it is a question, this should lead to Question overview dashboard (entity-id `jm7KgY6IuS6pQjkBZ7WUI`) with a question_id=id param.
- If it is a dashboard, send to Dashboard overview dashboard (entity-id `bJEYb0o5CXlfWFcIztDwJ`) with dashboard_id=id

Other
- [ ] This link should appear only to saved questions and dashboards
- [ ] Only users with access to the Metabase analytics colllection can see this link (if this proves hard to build quickly, we can show only to admins and improve later)

",luizarakaki,2024-02-06 16:55:30+00:00,"['npfitz', 'qwef']",2024-02-11 14:50:40+00:00,2024-02-11 14:50:40+00:00,https://github.com/metabase/metabase/issues/38474,"[('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2121187971,issue,open,,[MLv2] `summarize-column-by-time` drill should choose bucket based on `fingerprint`,Currently it's hard-coded to `:month` but there's [legacy logic](https://github.com/metabase/metabase/blob/0624d8d0933f577cc70c03948f4b57f73fe13ada/frontend/src/metabase-lib/metadata/Field.ts#L397) for a more sophisticated choice based on the `fingerprint` values.,bshepherdson,2024-02-06 16:18:55+00:00,[],2025-02-04 20:23:32+00:00,,https://github.com/metabase/metabase/issues/38471,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2120998226,issue,open,,Consider upgrading the way we handle native query represenation in mongo,"While solving the issue #37713, I've opened multiple issues relating to the way we handle mongo native query representation. I believe those issues could be solved together by changing the way we parse `bson` or generate `ejson`. Those issues are:

- #38311,
- #38288,
- #38181.

_Problem_. When we load saved native query, we parse it to array of bson documents in [`mongo.qp/parse-query-string`](https://github.com/metabase/metabase/blob/39fba6166af4e21cf18f120fe7c3fd1b46fed120/modules/drivers/mongo/src/metabase/driver/mongo/query_processor.clj#L1372). Then, when add new stages to the query, those are clojure structures. [`/dataset/native/`](https://github.com/metabase/metabase/blob/39fba6166af4e21cf18f120fe7c3fd1b46fed120/src/metabase/api/dataset.clj#L164) then generates json from the query. Newly added stages are transformed correctly. But bson documents from saved query are not.

_Possible solution_. To fix this, we could take advantage of `org.bson` package ejson parsing capabilities. We could either represent queries as ejson v2, which conforms to json rfc. That would make standard json parser sufficient when loading saved queries. Or we could try to generate ejson in mongo driver which would be returned on calls to `/dataset/native`, instead of generating json in the endpoint code.

_Watch for parameters_. It is important to consider how we use native query parameters, while trying to solve those issues as I believe eg. `{{x}}` would not be parseable.

_Usefule references_:
- [ejson v2 doc](https://www.mongodb.com/docs/manual/reference/mongodb-extended-json/),
- [ejson v1 doc](https://www.mongodb.com/docs/manual/reference/mongodb-extended-json-v1/),
- [`org.bson` package API](https://mongodb.github.io/mongo-java-driver/4.11/apidocs/bson/org/bson/package-summary.html).",lbrdnk,2024-02-06 15:00:11+00:00,[],2025-02-04 20:25:09+00:00,,https://github.com/metabase/metabase/issues/38469,"[('Database/Mongo', None), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2120855753,issue,closed,not_planned,Doesn't show new columns in Metabase after added into Snowflake,"**Describe the bug**
One of my sources is Snowflake, I had multiple tables in Snowflake and built a dashboard with multiple questions, I added new columns to the tables but I don't see these columns in the table, filter, or summarization, when I run native SQL query `SELCET *` it returns all columns normally.

I did:
- Sync database schema now on database level.
- Re-scan field values now on database level.
- Re-scan this table on table level.
- Discard cached field values on table level.

And didn't fixed.

**Logs**
No error here:

[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:50:11+03:00 DEBUG metabase.server.middleware.log POST /api/table/26/discard_values 200 17.4 ms (5 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (1 idle, 0 queued) (136 total active threads) Queries in flight: 0 (0 queued)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:50:14+03:00 DEBUG metabase.server.middleware.log POST /api/table/26/rescan_values 200 5.2 ms (3 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (1 idle, 0 queued) (136 total active threads) Queries in flight: 0 (0 queued)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:50:54+03:00 DEBUG metabase.server.middleware.log GET /api/database/2 200 8.7 ms (4 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (2 idle, 0 queued) (134 total active threads) Queries in flight: 0 (0 queued)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:08+03:00 DEBUG metabase.server.middleware.log POST /api/database/2/rescan_values 200 6.6 ms (3 DB calls) App DB connections: 0/15 Jetty threads: 8/50 (1 idle, 0 queued) (136 total active threads) Queries in flight: 0 (0 queued)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:08+03:00 INFO metabase.sync.util STARTING: Cache field values in snowflake Database 2 'Snowflake'
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:08+03:00 INFO metabase.sync.util STARTING: step 'delete-expired-advanced-field-values' for snowflake Database 2 'Snowflake'
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:08+03:00 INFO metabase.sync.util FINISHED: step 'delete-expired-advanced-field-values' for snowflake Database 2 'Snowflake' (823.8 ms)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:08+03:00 INFO metabase.sync.util STARTING: step 'update-field-values' for snowflake Database 2 'Snowflake'
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:15+03:00 INFO metabase.sync.util FINISHED: step 'update-field-values' for snowflake Database 2 'Snowflake' (6.5 s)
[ce5d18f7-454b-472a-be90-fe0dd2c04518] 2024-02-06T16:51:15+03:00 INFO metabase.sync.util FINISHED: Cache field values in snowflake Database 2 'Snowflake' (7.4 s)


**To Reproduce**
Steps to reproduce the behavior:
1. Add new column to snowflake table
2. Rescan table in Metabase 
3. explore the table.
4. No new columns here

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
Actually, its block building dashboard 

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-1012-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.11""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-12-19"",
      ""tag"": ""v0.48.1"",
      ""hash"": ""a8302d4""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",mlahlouh,2024-02-06 14:00:07+00:00,[],2024-02-06 14:08:00+00:00,2024-02-06 14:07:59+00:00,https://github.com/metabase/metabase/issues/38467,[],"[{'comment_id': 1929752217, 'issue_id': 2120855753, 'author': 'paoliniluis', 'body': ""move to 48.4, force a sync, and report back if things haven't appeared"", 'created_at': datetime.datetime(2024, 2, 6, 14, 7, 59, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:07:59 UTC): move to 48.4, force a sync, and report back if things haven't appeared

"
2120829596,issue,closed,not_planned,Filter type does not work with table aliasses,"### Describe the bug

ERROR: invalid reference to FROM-clause entry for table ""cte_issue_doof"" Hint: Perhaps you meant to reference the table alias ""d"". Position: 306

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

Create three tables in your selection database. Probably also fails with two, but this mimics best what I found
```
psql> create table cte_issue_zoof (c integer, s varchar);
psql> create table cte_issue_woof (c integer, s varchar);
psql> create table cte_issue_doof (c integer, d date);
```
Create a new SQL query
```
with
  z as (
    select * from cte_issue_zoof
    )
select    dt, z.s
from      cte_issue_doof d
left join z                on z.c = d.c
left join cte_issue_woof w on w.c = d.c
[[  and   {{filter}}]]
;
```
In the right, the variable filter springs into existence. I just have access to a Dutch version as added in the screen-dump
![20240206142648](https://github.com/metabase/metabase/assets/2492/e0263715-27d4-43f2-bfef-f35f88634dbe)

The selection of the field does not offer me to choose from any of the table aliasses, so I need to choose a real table field (why it is capitalized that way puzzles me, but I can live with that). The query works when the optional filter has no value, but causes an error
```
ERROR: invalid reference to FROM-clause entry for table ""cte_issue_doof"" Hint: Perhaps you meant to reference the table alias ""d"". Position: 306
```
when the dropdown on to is used to select a period. As selection does not offer or understand table aliasses, this causes a deadlock. The filter field can select the required field on the right and the left cannot be written to use the filter (unless table aliasses are not used at all)

Besides that, it would make more sense to be able to have those filters available on the selected columns rather than what is in the original tables


### Expected behavior

The dropdown on the right should support the table aliasses d and z from the example or the field shoul be entered manually, like `d.dt`

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase v0.48.4 in docker (updated after I hit this issue in v0.46.6.4)
- PostgreSQL 13.7 .. 16.1
- Reproduced on openSUSE Leap 15.5 with Opera One 108.0.5047.0
```


### Severity

very annoying

### Additional context

Queries are written and tested outside of the Metabase ecosystem. When they work as expected, the SQL is copied into Metabase and filers are added where wanted. This means that the people that write the selection write it in a readable and maintainable way where overly long schema.table names are aliassed to something logical to the query, e.g. `males as (select * from person where gender = 'M')`. Having to expand all those aliasses in queries of sometimes over 100 lines just to be able to use this kind of filter is extremely annoying",Tux,2024-02-06 13:49:42+00:00,[],2024-02-06 14:09:06+00:00,2024-02-06 14:09:06+00:00,https://github.com/metabase/metabase/issues/38466,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1929754389, 'issue_id': 2120829596, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/3324', 'created_at': datetime.datetime(2024, 2, 6, 14, 9, 6, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:09:06 UTC): duplicate of https://github.com/metabase/metabase/issues/3324

"
2120755444,issue,closed,completed,Query executed in Metabase is way slower than when executed directly in database,"### Describe the bug

We're running a pretty heavy query that uses: CTEs, aggregation functions, window functions, UNIONs, fetching data from a Materialized View that uses pretty much the same features. It operates on tables that have ~50GB of data in total. When I run the same native query in Metabase it takes around ~4 minutes to complete, while the exact same query executes in 3 seconds in DBeaver.

Metabase is deployed on ECS on Fargate.
 
What I tried:
- Adding more resources to Metabase container - it's currently set at 2 vCPUs and 4GB of RAM. Haven't noticed a change.
- Downgrading from v0.48.3 (I found this issue on this version) to v0.47.6.
-  adding LIMIT 1 (wasn't sure if this was some serialization issue caused by big result set) - no change.


What is interesting is that other less complicated queries execute in an acceptable time (the difference isn't that noticeable), even though they operate on the same tables.

### To Reproduce

Run a query with aggregate and window functions in Metabase and compare the execution time to e.g. DBeaver.

### Expected behavior

Execution time in Metabase should be similar to direct execution time  

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.20.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.20.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.20.1+1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.201-191.748.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-10-26"",
      ""tag"": ""v0.47.6"",
      ""branch"": ""?"",
      ""hash"": ""3a7ed7a""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

it heavily slows down the productivity of our client

### Additional context

_No response_",pk044,2024-02-06 13:15:05+00:00,[],2024-02-06 15:28:50+00:00,2024-02-06 15:28:49+00:00,https://github.com/metabase/metabase/issues/38464,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1929635150, 'issue_id': 2120755444, 'author': 'paoliniluis', 'body': 'Is DBeaver fetching the same amount of rows than what Metabase is pulling? are you passing parameters to the query?\r\n\r\nif you use a SQL question the query should take the exact amount of time, as we send the query as it is to the DB', 'created_at': datetime.datetime(2024, 2, 6, 13, 35, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 1929660846, 'issue_id': 2120755444, 'author': 'pk044', 'body': ""> Is DBeaver fetching the same amount of rows than what Metabase is pulling? \r\n\r\nyeah - I'm adding `LIMIT 2` at the end of the query\r\n\r\n> are you passing parameters to the query?\r\n\r\neven if I hardcode the parameters and execute the **exact same** query in both Metabase and DBeaver the difference is still there."", 'created_at': datetime.datetime(2024, 2, 6, 13, 44, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 1929707677, 'issue_id': 2120755444, 'author': 'paoliniluis', 'body': 'can you see how much time the API call takes in Metabase? As you can imagine we need to reproduce this and it would be pretty difficult.\r\n\r\ncan you post explain analyze logs and more information?', 'created_at': datetime.datetime(2024, 2, 6, 13, 55, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1930051331, 'issue_id': 2120755444, 'author': 'pk044', 'body': '@paoliniluis it was a PG settings-related issue actually - the value for `work_mem` for the Metabase user was set to way lower than other users in the DB, which resulted in choosing a inefficient query plan. \r\n\r\nanalyzing the `EXPLAIN` output helped out, thanks for the tip and the quick replies!', 'created_at': datetime.datetime(2024, 2, 6, 15, 28, 49, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 13:35:51 UTC): Is DBeaver fetching the same amount of rows than what Metabase is pulling? are you passing parameters to the query?

if you use a SQL question the query should take the exact amount of time, as we send the query as it is to the DB

pk044 (Issue Creator) on (2024-02-06 13:44:34 UTC): yeah - I'm adding `LIMIT 2` at the end of the query


even if I hardcode the parameters and execute the **exact same** query in both Metabase and DBeaver the difference is still there.

paoliniluis on (2024-02-06 13:55:12 UTC): can you see how much time the API call takes in Metabase? As you can imagine we need to reproduce this and it would be pretty difficult.

can you post explain analyze logs and more information?

pk044 (Issue Creator) on (2024-02-06 15:28:49 UTC): @paoliniluis it was a PG settings-related issue actually - the value for `work_mem` for the Metabase user was set to way lower than other users in the DB, which resulted in choosing a inefficient query plan. 

analyzing the `EXPLAIN` output helped out, thanks for the tip and the quick replies!

"
2120554171,issue,closed,completed,All table export options fail,"### Describe the bug

All table export options (csv/xlsx and json) fail, producing the expected file type, but with only the following content

```
{""via"":[{""type"":""java.lang.IllegalArgumentException"",""message"":""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",""at"":[""clojure.core$_cache_protocol_fn"",""invokeStatic"",""core_deftype.clj"",584]}],""trace"":[[""clojure.core$_cache_protocol_fn"",""invokeStatic"",""core_deftype.clj"",584],[""clojure.core$_cache_protocol_fn"",""invoke"",""core_deftype.clj"",576],[""ring.core.protocols$fn__372$G__367__381"",""invoke"",""protocols.clj"",8],[""ring.adapter.jetty9.servlet$update_servlet_response"",""invokeStatic"",""servlet.clj"",66],[""ring.adapter.jetty9.servlet$update_servlet_response"",""invoke"",""servlet.clj"",51],[""metabase.server.protocols$fn__13338"",""invokeStatic"",""protocols.clj"",28],[""metabase.server.protocols$fn__13338"",""invoke"",""protocols.clj"",21],[""metabase.server.protocols$fn__13314$fn__13317$G__13315__13324"",""invoke"",""protocols.clj"",6],[""metabase.server$async_proxy_handler$fn__66200$fn__66210"",""invoke"",""server.clj"",81],[""ring.middleware.gzip$wrap_gzip$fn__105202$fn__105203"",""invoke"",""gzip.clj"",89],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""ring.middleware.cookies$wrap_cookies$fn__105160$fn__105161"",""invoke"",""cookies.clj"",217],[""metabase.server.middleware.session$reset_session_timeout$fn__72039$fn__72040"",""invoke"",""session.clj"",490],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""clojure.core$comp$fn__5876"",""invoke"",""core.clj"",2586],[""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591$fn__99592"",""invoke"",""exceptions.clj"",113],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",199],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$wrap_route_matches$fn__43923"",""invoke"",""core.clj"",153],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$make_context$fn__43974"",""invoke"",""core.clj"",301],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$make_context$fn__43974"",""invoke"",""core.clj"",301],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$make_context$fn__43974"",""invoke"",""core.clj"",301],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$make_context$fn__43974"",""invoke"",""core.clj"",301],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$wrap_route_matches$fn__43923"",""invoke"",""core.clj"",153],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$wrap_route_matches$fn__43923"",""invoke"",""core.clj"",153],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""compojure.core$wrap_route_matches$fn__43923"",""invoke"",""core.clj"",153],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944"",""invoke"",""core.clj"",197],[""metabase.server.routes$fn__102658$fn__102660"",""invoke"",""routes.clj"",49],[""compojure.core$routes$fn__43942$f__43943"",""invoke"",""core.clj"",198],[""compojure.core$routes$fn__43942"",""invoke"",""core.clj"",200],[""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591"",""invoke"",""exceptions.clj"",108],[""metabase.server.middleware.exceptions$catch_api_exceptions$fn__99588"",""invoke"",""exceptions.clj"",96],[""metabase.server.middleware.log$log_api_call$fn__102939$fn__102940$fn__102941"",""invoke"",""log.clj"",216],[""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",""invokeStatic"",""diagnostic.clj"",18],[""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",""invoke"",""diagnostic.clj"",12],[""metabase.server.middleware.log$log_api_call$fn__102939$fn__102940"",""invoke"",""log.clj"",208],[""toucan2.execute$do_with_call_counts"",""invokeStatic"",""execute.clj"",112],[""toucan2.execute$do_with_call_counts"",""invoke"",""execute.clj"",103],[""metabase.server.middleware.log$log_api_call$fn__102939"",""invoke"",""log.clj"",207],[""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104973"",""invoke"",""browser_cookie.clj"",40],[""metabase.server.middleware.security$add_security_headers$fn__85481"",""invoke"",""security.clj"",180],[""metabase.server.middleware.json$wrap_json_body$fn__45303"",""invoke"",""json.clj"",69],[""metabase.server.middleware.offset_paging$handle_paging$fn__85505"",""invoke"",""offset_paging.clj"",45],[""metabase.server.middleware.json$wrap_streamed_json_response$fn__45321"",""invoke"",""json.clj"",103],[""ring.middleware.keyword_params$wrap_keyword_params$fn__105240"",""invoke"",""keyword_params.clj"",55],[""ring.middleware.params$wrap_params$fn__105259"",""invoke"",""params.clj"",77],[""metabase.server.middleware.misc$maybe_set_site_url$fn__66015"",""invoke"",""misc.clj"",61],[""metabase.server.middleware.session$reset_session_timeout$fn__72039"",""invoke"",""session.clj"",488],[""metabase.server.middleware.session$bind_current_user$fn__72006$fn__72007"",""invoke"",""session.clj"",383],[""metabase.server.middleware.session$do_with_current_user"",""invokeStatic"",""session.clj"",362],[""metabase.server.middleware.session$do_with_current_user"",""invoke"",""session.clj"",346],[""metabase.server.middleware.session$bind_current_user$fn__72006"",""invoke"",""session.clj"",382],[""metabase.server.middleware.session$wrap_current_user_info$fn__71989"",""invoke"",""session.clj"",321],[""metabase.server.middleware.session$wrap_session_id$fn__71972"",""invoke"",""session.clj"",253],[""metabase.server.middleware.auth$wrap_api_key$fn__94797"",""invoke"",""auth.clj"",30],[""ring.middleware.cookies$wrap_cookies$fn__105160"",""invoke"",""cookies.clj"",216],[""metabase.server.middleware.misc$add_content_type$fn__65997"",""invoke"",""misc.clj"",29],[""metabase.server.middleware.misc$disable_streaming_buffering$fn__66023"",""invoke"",""misc.clj"",78],[""ring.middleware.gzip$wrap_gzip$fn__105202"",""invoke"",""gzip.clj"",86],[""metabase.server.middleware.misc$bind_request$fn__66026"",""invoke"",""misc.clj"",95],[""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104989"",""invoke"",""ssl.clj"",41],[""metabase.server$async_proxy_handler$fn__66200"",""invoke"",""server.clj"",78],[""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",""handle"",null,-1],[""org.eclipse.jetty.server.handler.StatisticsHandler"",""handle"",""StatisticsHandler.java"",173],[""org.eclipse.jetty.server.handler.HandlerWrapper"",""handle"",""HandlerWrapper.java"",122],[""org.eclipse.jetty.server.Server"",""handle"",""Server.java"",563],[""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",""dispatch"",""HttpChannel.java"",1598],[""org.eclipse.jetty.server.HttpChannel"",""dispatch"",""HttpChannel.java"",753],[""org.eclipse.jetty.server.HttpChannel"",""handle"",""HttpChannel.java"",501],[""org.eclipse.jetty.server.HttpConnection"",""onFillable"",""HttpConnection.java"",287],[""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",""succeeded"",""AbstractConnection.java"",314],[""org.eclipse.jetty.io.FillInterest"",""fillable"",""FillInterest.java"",100],[""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",""run"",""SelectableChannelEndPoint.java"",53],[""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",""runTask"",""AdaptiveExecutionStrategy.java"",421],[""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",""consumeTask"",""AdaptiveExecutionStrategy.java"",390],[""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",""tryProduce"",""AdaptiveExecutionStrategy.java"",277],[""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",""run"",""AdaptiveExecutionStrategy.java"",199],[""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",""run"",""ReservedThreadExecutor.java"",411],[""org.eclipse.jetty.util.thread.QueuedThreadPool"",""runJob"",""QueuedThreadPool.java"",969],[""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",""doRunJob"",""QueuedThreadPool.java"",1194],[""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",""run"",""QueuedThreadPool.java"",1149],[""java.lang.Thread"",""run"",null,-1]],""cause"":""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",""message"":""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap""}
```
# Reproduction steps
```
Deploy metabase from `latest` (v0.48.4) docker container. Linked to postgres backend for persistent storage.

View a table with some data in, and select export (download full results) button in bottom right in any of the formats available.

```




# Logs
```
Metabase Admin

    Settings
    Databases
    Table Metadata
    People
    Permissions
    Troubleshooting

Exit admin

    Help
    Tasks
    Jobs
    Logs

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.core 
Metabase v0.48.4 (62145b0) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.core Starting Metabase in STANDALONE mode
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.server Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.core Starting Metabase version v0.48.4 (62145b0) ...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.core System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.22+7"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.22"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.22+7"",
 ""os.name"" ""Linux"",
 ""os.version"" ""6.2.0-1018-aws"",
 ""user.language"" ""en"",
 ""user.timezone"" ""GMT""}

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:08+00:00 INFO metabase.plugins Loading plugins in /plugins...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/googleanalytics.metabase-driver.jar -> /plugins/googleanalytics.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:09+00:00 INFO metabase.util.files Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:10+00:00 INFO metabase.util.files Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:10+00:00 INFO metabase.util.files Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :athena...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :athena (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :sqlserver...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :sqlserver (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :redshift...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :redshift (parents: [:postgres]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :sqlite...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :bigquery-cloud-sdk...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :bigquery-cloud-sdk (parents: [:sql]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :hive-like...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered abstract driver :hive-like (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :sparksql...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :sparksql (parents: [:hive-like]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Plugins with unsatisfied deps: [""Metabase Vertica Driver""]
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.plugins.dependencies Plugins with unsatisfied deps: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""]
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :mongo...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :mongo  🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :googleanalytics  🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :googleanalytics...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :presto-jdbc...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :presto-jdbc (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :druid  🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :druid...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 DEBUG metabase.plugins.lazy-loaded-driver Registering lazy loading driver :snowflake...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.driver.impl Registered driver :snowflake (parents: [:sql-jdbc]) 🚚
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.core Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.db.setup Verifying postgres Database Connection ...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.db.setup Successfully verified PostgreSQL 16.1 application database connection. ✅
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:11+00:00 INFO metabase.db.setup Checking if a database downgrade is required...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:12+00:00 INFO metabase.db.setup Running Database Migrations...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:12+00:00 INFO metabase.db.setup Setting up Liquibase...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:12+00:00 INFO metabase.db.setup Liquibase is ready.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:12+00:00 INFO metabase.db.liquibase Checking if Database has unrun migrations...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:13+00:00 INFO metabase.db.liquibase No unrun migrations found.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:13+00:00 INFO metabase.db.setup Database Migrations Current ...  ✅
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:13+00:00 INFO metabase.util Database setup took 2.2 s
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:13+00:00 ERROR metabase.server.middleware.log HEAD /api/health 503 4.3 ms (0 DB calls)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:13+00:00 INFO org.quartz.impl.StdSchedulerFactory Using default implementation for ThreadExecutor
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.core.SchedulerSignalerImpl Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.core.QuartzScheduler Quartz Scheduler v.2.3.2 created.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.jdbcjobstore.JobStoreTX Using db table-based data access locking (synchronization).
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.jdbcjobstore.JobStoreTX JobStoreTX initialized.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.StdSchedulerFactory Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.StdSchedulerFactory Quartz scheduler version: 2.3.2
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.core.QuartzScheduler Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'metabase1707218713992'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.core.QuartzScheduler Scheduler MetabaseScheduler_$_metabase1707218713992 paused.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Task scheduler initialized into standby mode.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task SyncDatabases 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task.sync-databases Updated default schedules for 0 databases
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task PersistRefresh 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.driver.impl Initializing driver :sql...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.driver.impl Initializing driver :postgres...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.driver.impl Initializing driver :sql-jdbc...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task CheckForNewVersions 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task PersistPrune 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task SendAnonymousUsageStats 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task ModelIndexValues 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task RefreshSlackChannelsAndUsers 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task TruncateAuditTables 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task SendPulses 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task SendFollowUpEmails 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task TaskHistoryCleanup 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Initializing task SendWarnPulseRemovalEmail 📆
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.jdbcjobstore.JobStoreTX ClusterManager: Scanning for instance ""metabase1707218000004""'s failed in-progress jobs.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.impl.jdbcjobstore.JobStoreTX ClusterManager: detected 1 failed or restarted instances.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO org.quartz.core.QuartzScheduler Scheduler MetabaseScheduler_$_metabase1707218713992 started.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task Task scheduler started
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.core Metabase Initialization COMPLETE in 31.2 s
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:14+00:00 INFO metabase.task.refresh-slack-channel-user-cache Slack is not configured, not refreshing slack user/channel cache.
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:29+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 869.8 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (30 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:41+00:00 INFO metabase.util.i18n.impl Reading available locales from locales.clj...
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:41+00:00 INFO metabase.util.fonts Reading available fonts from /frontend_client/app/fonts
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:42+00:00 INFO metabase.public-settings.premium-features GETTING ACTIVE USER COUNT!
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:42+00:00 INFO metabase.public-settings.premium-features => 1
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:42+00:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 370.9 ms (7 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (3 idle, 0 queued) (31 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:42+00:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 560.6 ms (11 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (3 idle, 0 queued) (32 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:43+00:00 DEBUG metabase.server.middleware.log GET /api/collection/root 200 63.5 ms (2 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (34 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:43+00:00 DEBUG metabase.server.middleware.log GET /api/database 200 73.3 ms (3 DB calls) App DB connections: 2/4 Jetty threads: 6/50 (0 idle, 0 queued) (34 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:43+00:00 DEBUG metabase.server.middleware.log GET /api/bookmark 200 123.7 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 7/50 (0 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:43+00:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 121.8 ms (6 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (3 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:43+00:00 DEBUG metabase.server.middleware.log GET /api/search 200 278.8 ms (4 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (4 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:44+00:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 57.3 ms (3 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:44+00:00 DEBUG metabase.server.middleware.log GET /api/database/2/schemas 200 186.6 ms (4 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (4 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:44+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 414.3 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (3 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:44+00:00 DEBUG metabase.server.middleware.log GET /api/table/22/query_metadata 200 611.4 ms (11 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:44+00:00 DEBUG metabase.server.middleware.log GET /api/table/15/query_metadata 200 68.6 ms (11 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 DEBUG metabase.server.middleware.log GET /api/table/17/query_metadata 200 145.7 ms (9 DB calls) App DB connections: 1/4 Jetty threads: 4/50 (3 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 DEBUG metabase.server.middleware.log GET /api/table/18/query_metadata 200 211.0 ms (11 DB calls) App DB connections: 1/4 Jetty threads: 3/50 (4 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.audit-log 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.driver-notifications 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.last-login 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.persisted-info 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.recent-views 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.revision 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.schema 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.sync-database 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:45+00:00 INFO metabase.events Loading events namespace: metabase.events.view-log 👂
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:47+00:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 1.9 s (15 DB calls) App DB connections: 0/4 Jetty threads: 2/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 1 (0 queued); postgres DB 2 connections: 0/0 (0 threads blocked)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:47+00:00 DEBUG metabase.server.middleware.log GET /api/database/2 200 67.0 ms (7 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:50+00:00 DEBUG metabase.server.middleware.log POST /apiset/csv null 150.9 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:50+00:00 ERROR metabase.server.middleware.log POST /apiset/csv 500 4.5 ms (0 DB calls) 
{:via
 [{:type java.lang.IllegalArgumentException,
   :message
   ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",
   :at [clojure.core$_cache_protocol_fn invokeStatic ""core_deftype.clj"" 584]}],
 :trace
 [[clojure.core$_cache_protocol_fn invokeStatic ""core_deftype.clj"" 584]
  [clojure.core$_cache_protocol_fn invoke ""core_deftype.clj"" 576]
  [ring.core.protocols$fn__372$G__367__381 invoke ""protocols.clj"" 8]
  [ring.adapter.jetty9.servlet$update_servlet_response invokeStatic ""servlet.clj"" 66]
  [ring.adapter.jetty9.servlet$update_servlet_response invoke ""servlet.clj"" 51]
  [metabase.server.protocols$fn__13338 invokeStatic ""protocols.clj"" 28]
  [metabase.server.protocols$fn__13338 invoke ""protocols.clj"" 21]
  [metabase.server.protocols$fn__13314$fn__13317$G__13315__13324 invoke ""protocols.clj"" 6]
  [metabase.server$async_proxy_handler$fn__66200$fn__66210 invoke ""server.clj"" 81]
  [ring.middleware.gzip$wrap_gzip$fn__105202$fn__105203 invoke ""gzip.clj"" 89]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [ring.middleware.cookies$wrap_cookies$fn__105160$fn__105161 invoke ""cookies.clj"" 217]
  [metabase.server.middleware.session$reset_session_timeout$fn__72039$fn__72040 invoke ""session.clj"" 490]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591$fn__99592 invoke ""exceptions.clj"" 113]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [metabase.server.routes$fn__102658$fn__102660 invoke ""routes.clj"" 49]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591 invoke ""exceptions.clj"" 108]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__99588 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__102939$fn__102940$fn__102941 invoke ""log.clj"" 216]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__102939$fn__102940 invoke ""log.clj"" 208]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__102939 invoke ""log.clj"" 207]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104973 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__85481 invoke ""security.clj"" 180]
  [metabase.server.middleware.json$wrap_json_body$fn__45303 invoke ""json.clj"" 69]
  [metabase.server.middleware.offset_paging$handle_paging$fn__85505 invoke ""offset_paging.clj"" 45]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__45321 invoke ""json.clj"" 103]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__105240 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__105259 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__66015 invoke ""misc.clj"" 61]
  [metabase.server.middleware.session$reset_session_timeout$fn__72039 invoke ""session.clj"" 488]
  [metabase.server.middleware.session$bind_current_user$fn__72006$fn__72007 invoke ""session.clj"" 383]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 362]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 346]
  [metabase.server.middleware.session$bind_current_user$fn__72006 invoke ""session.clj"" 382]
  [metabase.server.middleware.session$wrap_current_user_info$fn__71989 invoke ""session.clj"" 321]
  [metabase.server.middleware.session$wrap_session_id$fn__71972 invoke ""session.clj"" 253]
  [metabase.server.middleware.auth$wrap_api_key$fn__94797 invoke ""auth.clj"" 30]
  [ring.middleware.cookies$wrap_cookies$fn__105160 invoke ""cookies.clj"" 216]
  [metabase.server.middleware.misc$add_content_type$fn__65997 invoke ""misc.clj"" 29]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__66023 invoke ""misc.clj"" 78]
  [ring.middleware.gzip$wrap_gzip$fn__105202 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__66026 invoke ""misc.clj"" 95]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104989 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__66200 invoke ""server.clj"" 78]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause
 ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",
 :message
 ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap""}

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:52+00:00 DEBUG metabase.server.middleware.log POST /apiset/xlsx null 109.1 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:52+00:00 ERROR metabase.server.middleware.log POST /apiset/xlsx 500 4.0 ms (0 DB calls) 
{:via
 [{:type java.lang.IllegalArgumentException,
   :message
   ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",
   :at [clojure.core$_cache_protocol_fn invokeStatic ""core_deftype.clj"" 584]}],
 :trace
 [[clojure.core$_cache_protocol_fn invokeStatic ""core_deftype.clj"" 584]
  [clojure.core$_cache_protocol_fn invoke ""core_deftype.clj"" 576]
  [ring.core.protocols$fn__372$G__367__381 invoke ""protocols.clj"" 8]
  [ring.adapter.jetty9.servlet$update_servlet_response invokeStatic ""servlet.clj"" 66]
  [ring.adapter.jetty9.servlet$update_servlet_response invoke ""servlet.clj"" 51]
  [metabase.server.protocols$fn__13338 invokeStatic ""protocols.clj"" 28]
  [metabase.server.protocols$fn__13338 invoke ""protocols.clj"" 21]
  [metabase.server.protocols$fn__13314$fn__13317$G__13315__13324 invoke ""protocols.clj"" 6]
  [metabase.server$async_proxy_handler$fn__66200$fn__66210 invoke ""server.clj"" 81]
  [ring.middleware.gzip$wrap_gzip$fn__105202$fn__105203 invoke ""gzip.clj"" 89]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [ring.middleware.cookies$wrap_cookies$fn__105160$fn__105161 invoke ""cookies.clj"" 217]
  [metabase.server.middleware.session$reset_session_timeout$fn__72039$fn__72040 invoke ""session.clj"" 490]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2586]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591$fn__99592 invoke ""exceptions.clj"" 113]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__43974 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__43923 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942$f__43943$respond_SINGLEQUOTE___43944 invoke ""core.clj"" 197]
  [metabase.server.routes$fn__102658$fn__102660 invoke ""routes.clj"" 49]
  [compojure.core$routes$fn__43942$f__43943 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__43942 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99591 invoke ""exceptions.clj"" 108]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__99588 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__102939$fn__102940$fn__102941 invoke ""log.clj"" 216]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__102939$fn__102940 invoke ""log.clj"" 208]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__102939 invoke ""log.clj"" 207]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104973 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__85481 invoke ""security.clj"" 180]
  [metabase.server.middleware.json$wrap_json_body$fn__45303 invoke ""json.clj"" 69]
  [metabase.server.middleware.offset_paging$handle_paging$fn__85505 invoke ""offset_paging.clj"" 45]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__45321 invoke ""json.clj"" 103]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__105240 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__105259 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__66015 invoke ""misc.clj"" 61]
  [metabase.server.middleware.session$reset_session_timeout$fn__72039 invoke ""session.clj"" 488]
  [metabase.server.middleware.session$bind_current_user$fn__72006$fn__72007 invoke ""session.clj"" 383]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 362]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 346]
  [metabase.server.middleware.session$bind_current_user$fn__72006 invoke ""session.clj"" 382]
  [metabase.server.middleware.session$wrap_current_user_info$fn__71989 invoke ""session.clj"" 321]
  [metabase.server.middleware.session$wrap_session_id$fn__71972 invoke ""session.clj"" 253]
  [metabase.server.middleware.auth$wrap_api_key$fn__94797 invoke ""auth.clj"" 30]
  [ring.middleware.cookies$wrap_cookies$fn__105160 invoke ""cookies.clj"" 216]
  [metabase.server.middleware.misc$add_content_type$fn__65997 invoke ""misc.clj"" 29]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__66023 invoke ""misc.clj"" 78]
  [ring.middleware.gzip$wrap_gzip$fn__105202 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__66026 invoke ""misc.clj"" 95]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104989 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__66200 invoke ""server.clj"" 78]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause
 ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap"",
 :message
 ""No implementation of method: :write-body-to-stream of protocol: #'ring.core.protocols/StreamableResponseBody found for class: clojure.lang.PersistentArrayMap""}

[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:56+00:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 113.1 ms (6 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (4 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:56+00:00 DEBUG metabase.server.middleware.log GET /api/setting 200 161.8 ms (5 DB calls) App DB connections: 0/4 Jetty threads: 4/50 (4 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:56+00:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 106.3 ms (9 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:57+00:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 7.4 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:25:59+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 334.6 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:26:14+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 361.1 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:26:29+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 362.4 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:26:44+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 250.3 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (50 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:26:59+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 292.3 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:27:11+00:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 5.5 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:27:14+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 245.2 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:27:29+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 299.5 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (5 idle, 0 queued) (48 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:27:44+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 277.8 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:28:00+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 244.1 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:28:15+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 245.2 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:28:30+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 270.3 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued)
[405da316-1211-4a6e-b970-55ea8862259e] 2024-02-06T11:28:45+00:00 DEBUG metabase.server.middleware.log HEAD /api/health 200 393.3 µs (0 DB calls) App DB connections: 0/4 Jetty threads: 3/50 (4 idle, 0 queued) (47 total active threads) Queries in flight: 0 (0 queued)


```


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-1018-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Being able to export tables is a core use case for me 

### Additional context

_No response_",Xenov-X,2024-02-06 11:27:41+00:00,[],2024-02-06 12:55:40+00:00,2024-02-06 12:55:40+00:00,https://github.com/metabase/metabase/issues/38462,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1929417610, 'issue_id': 2120554171, 'author': 'paoliniluis', 'body': ""are you hitting a non-existent endpoint? what's POST /apiset/csv"", 'created_at': datetime.datetime(2024, 2, 6, 12, 25, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1929433525, 'issue_id': 2120554171, 'author': 'Xenov-X', 'body': 'Thanks @paoliniluis! \r\nThis is going to fall into user error - intermediate proxy rewriting urls to host under `/data/` has clearly mangled something \r\n\r\nShould anyone else land here, the correct URLs is: `/api/dataset/<filetype>`', 'created_at': datetime.datetime(2024, 2, 6, 12, 34, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 1929469206, 'issue_id': 2120554171, 'author': 'Xenov-X', 'body': '\\Close', 'created_at': datetime.datetime(2024, 2, 6, 12, 55, 40, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 12:25:53 UTC): are you hitting a non-existent endpoint? what's POST /apiset/csv

Xenov-X (Issue Creator) on (2024-02-06 12:34:02 UTC): Thanks @paoliniluis! 
This is going to fall into user error - intermediate proxy rewriting urls to host under `/data/` has clearly mangled something 

Should anyone else land here, the correct URLs is: `/api/dataset/<filetype>`

Xenov-X (Issue Creator) on (2024-02-06 12:55:40 UTC): \Close

"
2120512045,issue,open,,Show values for each aggregation on stacked bar chart,"**Describe the solution you'd like**
Show values on stacked bar chart like google sheet charts.
![image](https://github.com/metabase/metabase/assets/20394645/3ad0b17d-97b6-4fba-8c06-36f55bb084a6)

**How important is this feature to you?**
In most of our reports we have a stacked bar chart and when it hasn't values stakeholders can't understand it.

**Additional context**
![image](https://github.com/metabase/metabase/assets/20394645/3ad0b17d-97b6-4fba-8c06-36f55bb084a6)
",nixuri,2024-02-06 11:05:10+00:00,[],2024-02-23 18:22:32+00:00,,https://github.com/metabase/metabase/issues/38460,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]",[],
2119629082,issue,closed,completed,Issue with click Behavior and passing filters to custom destinations that are tabs of the same dashboard,"### Describe the bug

Click Behavior between tabs within the same dashboard don't appear to be working. Specifically passing filters to a custom destination, which happens to be a tab of the same dashboard.

### To Reproduce


1.) Create two questions to place on a dashboard.

Question 1:
```
SELECT *
FROM player_salary
WHERE {{team}}
AND {{seasonID}}
```

Question 2:
```
SELECT *
FROM season_gamelog
WHERE {{team_abv}}
 AND {{seasonID}}
 AND game_date = '2007-03-23'
```

<br>
<br>

2.) Place both questions on a dashboard in their own individual tabs, with the same filters being applied to each one.
Dashboard 1: **Dash Link**

<img width=""549"" alt=""Screenshot 2024-02-05 at 3 51 12 PM"" src=""https://github.com/metabase/metabase/assets/17398657/de51674c-b251-4928-bee8-bbfd8996eaf4"">

<img width=""557"" alt=""Screenshot 2024-02-05 at 3 51 35 PM"" src=""https://github.com/metabase/metabase/assets/17398657/10418103-2061-4a93-a1b2-5006c6b42889"">

<img width=""558"" alt=""Screenshot 2024-02-05 at 3 51 50 PM"" src=""https://github.com/metabase/metabase/assets/17398657/37a4ffa1-d135-46e8-ad2d-c96b73f6f0ae"">

<img width=""558"" alt=""Screenshot 2024-02-05 at 3 51 55 PM"" src=""https://github.com/metabase/metabase/assets/17398657/e771c1a7-5fe5-4cb8-b8be-ac9adeec762a"">

<br>
<br>

3.) Create a duplicate of this dashboard. 
Dashboard 2: **Dash Link - Duplicate**

<br>
<br>

4.) Create Click Behavior that will use a column from Tab 1 as a filter to be used for Tab 2.
This Click Behavior is going from **Tab 1** of **Dash Link**(original dashboard) to **Tab 2** of **Dash Link - Duplicate**(duplicate dashboard).

<br>
<br>
<br>
<br>

<img width=""1346"" alt=""Screenshot 2024-02-05 at 3 53 23 PM"" src=""https://github.com/metabase/metabase/assets/17398657/a7b19927-653a-483a-94c3-6bed965cc4c1"">

<br>
<br>



5.) When starting from **Dash Link** (original) and clicking on the column **‘tm'**, the filter is applied and **Tab 2 of Dash Link - Duplicate** dashboard is in the url.


<img width=""840"" alt=""Screenshot 2024-02-05 at 3 57 02 PM"" src=""https://github.com/metabase/metabase/assets/17398657/9ad986db-68b8-4406-90f3-f4ac679a901c"">


<br>
<br>
<br>
<br>


<img width=""840"" alt=""Screenshot 2024-02-05 at 3 58 19 PM"" src=""https://github.com/metabase/metabase/assets/17398657/c000afce-c0be-41d6-aa79-8f869d5ac544"">


<br>
<br>
<br>
<br>


6.) This Click Behavior is going from **Tab 1** of **Dash Link - Duplicate(duplicate)** to **Tab 2** of **Dash Link - Duplicate(duplicate)**.

<img width=""1346"" alt=""Screenshot 2024-02-05 at 3 54 33 PM"" src=""https://github.com/metabase/metabase/assets/17398657/8ce91796-837b-4b38-babc-e5b84f7eb637"">

<br>
<br>

When starting from **Dash Link - Duplicate** dashboard and clicking on the column **‘tm'**, the filter is applied, but to Tab 1 and the url reflects this.

<img width=""840"" alt=""Screenshot 2024-02-05 at 4 11 43 PM"" src=""https://github.com/metabase/metabase/assets/17398657/d17c88d0-314f-4af4-bb76-40cdf5f8e67f"">





### Expected behavior

For the redirection to be sent to the desired tab of the same dashboard

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v1.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2 - Speaking with a couple customers who have the expectation of being able to go to different tabs in the same dashboard

### Additional context

_No response_",FilmonK,2024-02-05 23:07:34+00:00,['JesseSDevaney'],2024-03-06 20:52:13+00:00,2024-03-01 19:31:13+00:00,https://github.com/metabase/metabase/issues/38455,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1978809897, 'issue_id': 2119629082, 'author': 'perivamsi', 'body': '@JesseSDevaney can you please backport this to 49?', 'created_at': datetime.datetime(2024, 3, 5, 13, 46, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 1981760172, 'issue_id': 2119629082, 'author': 'JesseSDevaney', 'body': '@perivamsi \r\n\r\n> @JesseSDevaney can you please backport this to 49?\r\n\r\nIt was automatically backported to 49\r\n- https://github.com/metabase/metabase/pull/39474\r\n\r\nI just forgot to throw the Milestone 0.49 marker on it. Just did :heavy_check_mark:', 'created_at': datetime.datetime(2024, 3, 6, 20, 52, 12, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-03-05 13:46:04 UTC): @JesseSDevaney can you please backport this to 49?

JesseSDevaney (Assginee) on (2024-03-06 20:52:12 UTC): @perivamsi 


It was automatically backported to 49
- https://github.com/metabase/metabase/pull/39474

I just forgot to throw the Milestone 0.49 marker on it. Just did :heavy_check_mark:

"
2119551107,issue,closed,completed,Failure to see the postgres schemas when apply permissions (ERROR: duplicate key value violates unique constraint),"**Describe the bug**

I upgrade metabase and [replace the Jdk](https://github.com/NixOS/nixpkgs/issues/215562#issuecomment-1910173978) so I can download excel files, but then after this is impossible to set permission of `group = pg schema`.

When I look at `/admin/permissions/data/group/16/database/2` the schemas are not displayed as before.

Then I see in the logs:

```bash
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1080]],
 :cause
 ""ERROR: duplicate key value violates unique constraint \""permissions_revision_pkey\""\n  Detail: Key (id)=(30) already exists."",
```

**Logs**

[error.log](https://github.com/metabase/metabase/files/14172397/error.log)

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '/admin/permissions/data/group/16'
2. Click on a group and select 'Granular'
3. See that in `Permissions for  Disfami group Sales` there are not schemas listed.

**Severity**

I can't add more companies for the app.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15"",
    ""vendor"": ""Apple Computer, Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.7+7-nixos"",
    ""java.vendor"": ""N/A"",
    ""java.vendor.url"": ""https://openjdk.java.net/"",
    ""java.version"": ""17.0.7"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.7+7-nixos"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.7.1"",
    ""user.language"": ""es"",
    ""user.timezone"": ""America/Bogota""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-10-26"",
      ""tag"": ""v0.47.6"",
      ""branch"": ""?"",
      ""hash"": ""3a7ed7a""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",mamcx,2024-02-05 22:12:49+00:00,[],2024-02-29 14:42:46+00:00,2024-02-29 14:42:46+00:00,https://github.com/metabase/metabase/issues/38454,[],"[{'comment_id': 1928305314, 'issue_id': 2119551107, 'author': 'paoliniluis', 'body': '1) downgrade to Java 11\r\n2) there seems to be a corruption in your DB, so back up your db and do ""DELETE FROM permissions_revision_pkey WHERE id=30""\r\n\r\nthen upgrade to v48.4', 'created_at': datetime.datetime(2024, 2, 5, 22, 29, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 1930672797, 'issue_id': 2119551107, 'author': 'mamcx', 'body': ""After doing this, I still can't see the schemas"", 'created_at': datetime.datetime(2024, 2, 6, 20, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 1970098593, 'issue_id': 2119551107, 'author': 'paoliniluis', 'body': '@mamcx what do you see after doing the sync?', 'created_at': datetime.datetime(2024, 2, 28, 23, 38, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 1971292039, 'issue_id': 2119551107, 'author': 'mamcx', 'body': 'I do. I upgrade the VM with more RAM, look like it was dying by resources.', 'created_at': datetime.datetime(2024, 2, 29, 14, 42, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-05 22:29:54 UTC): 1) downgrade to Java 11
2) there seems to be a corruption in your DB, so back up your db and do ""DELETE FROM permissions_revision_pkey WHERE id=30""

then upgrade to v48.4

mamcx (Issue Creator) on (2024-02-06 20:09:38 UTC): After doing this, I still can't see the schemas

paoliniluis on (2024-02-28 23:38:44 UTC): @mamcx what do you see after doing the sync?

mamcx (Issue Creator) on (2024-02-29 14:42:46 UTC): I do. I upgrade the VM with more RAM, look like it was dying by resources.

"
2119147368,issue,closed,completed,Fixed width dashboards (non-blocking milestones),"## Context
[Product doc](https://www.notion.so/Default-dashboards-to-a-max-width-to-give-creators-a-more-predictable-canvas-0a4f5b03fcba42f59752a6c41c453ebb)
Epic: https://github.com/metabase/metabase/issues/36010
Blocking milestones of this feature: https://github.com/metabase/metabase/issues/36358

---
## Tasks

**Dashboards Needing Changes**
1. Full-App
2. Static Embedding (`PublicDashboard`)
3. X-Rays (`AutomaticDashboardApp`)

---
#### Milestone 4: Make Dashboard Header Fixed Width
- https://github.com/metabase/metabase/pull/38634
  - [x] Include the full dashboard header in the fixed width container (edit mode header is the obstacle)
    - [x] Save mode UI should still extend to the edge of the viewport

---
#### Milestone 5: Clean-up RC1 Commits
- https://github.com/metabase/metabase/pull/38678
  - [x] Clean-up new Mantine tool-tips replacing old tool-tips on dashboard header buttons
- [x] Clean-up the filters moved below tabs in public/embedded dashboards (pre-RC1 work)
  - [ ] Create an issue to track the problem of using EmbedFrame to handle multiple different embedded scenarios (dashboards, questions, actions, ...). Refactoring this to respect separation of concerns would make it easier  to understand, maintain, and develop on top of.
  - https://github.com/metabase/metabase/pull/38766
    - [x] Add sticky filters to public/embedded dashboards (related issue: #24726)
    - https://github.com/metabase/metabase/pull/38882
      - [x] Prevent parameters container from being rendered on public/embedded dashboards when no visible filters are present ([see comment](https://github.com/metabase/metabase/pull/38634#discussion_r1487418364))

---
#### Milestone 6: Setup Analytics
- https://github.com/metabase/metabase/pull/38871
- https://github.com/metabase/metabase/pull/38872
  - [x] Setup analytics to track this new settings usage
    - [Event Spec](https://www.notion.so/metabase/Dashboard-width-toggled-1b3b1e5693f44a44bf79b30fcb732a67?pvs=4)
    - [Analytics Doc](https://www.notion.so/5da1f874beda4153b4fccfa6c1e77caa?pvs=4)
  
---
#### :x: Milestone 7: Make dashboard body true fixed width w/ overflow scroll
_Left unimplemented: Value < Effort Required_
- [ ] Turn off fixed-width logic when reaching the mobile breakpoint
- [ ] Make the dashboard have true fixed width + overflow scroll when mobile breakpoint < width < 1048px
  - [ ] Need to add this functionality to Public/Embed Dashboards + X-Rays as well

---
#### Milestone Xtra: Miscellaneous Clean-up
- https://github.com/metabase/metabase/pull/38790
  - https://github.com/metabase/metabase/pull/38834
  - [x] Adjust X-Ray dashboards to use the full grid width
    - X-Rays only use 3/4 of the dashboard grid. This combined with the new fixed-width feature makes X-Ray dashboards look unpolished.
    ![image](https://github.com/metabase/metabase/assets/22608765/a4d787ca-840b-4b37-8a96-b3fc89df24cc)
- https://github.com/metabase/metabase/pull/38836
  - https://github.com/metabase/metabase/pull/38884
    - [x] Update X-Rays to respect the new default card sizes
- https://github.com/metabase/metabase/pull/38880
  - [x] Fix dashboard header margin bug ([thread](https://metaboat.slack.com/archives/C505ZNNH4/p1708059629202699))",JesseSDevaney,2024-02-05 17:59:26+00:00,['JesseSDevaney'],2024-03-06 21:01:46+00:00,2024-03-06 21:01:45+00:00,https://github.com/metabase/metabase/issues/38446,"[('Reporting/Dashboards', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2119041093,issue,closed,completed,[Epic] Add connection impersonation to Redshift,"We support connection impersonation for Snowflake and Postgres. We can extend support to Redshift too.

It behaves slightly differently from Postgres as it uses `SET SESSION AUTHORIZATION` and passes usernames instead of roles.

[Product doc](https://www.notion.so/metabase/Add-impersonation-to-Redshift-5fd1d93fba3b4a9683241ad3729a9041?pvs=4)
```[tasklist]
### Tasks
- [x] [BE] Tweak driver to use `set session authorization`
- [x] [FE] Change copy: replace ""role"" with ""user""
```
",luizarakaki,2024-02-05 17:05:16+00:00,"['iethree', 'noahmoss']",2024-02-14 18:47:39+00:00,2024-02-12 10:34:34+00:00,https://github.com/metabase/metabase/issues/38445,"[('Database/Redshift', None), ('Type:New Feature', ''), ('.Epic', 'Feature Implementation or Project'), ('Administration/Impersonation', 'Role level security'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1936362858, 'issue_id': 2119041093, 'author': 'marcoquerque', 'body': 'In general, what are your thoughts on requiring the redshift user in the metabase connection be a super user to use this?', 'created_at': datetime.datetime(2024, 2, 9, 17, 57, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936376772, 'issue_id': 2119041093, 'author': 'luizarakaki', 'body': 'Redshift connection impersonation uses `SET SESSION AUTHORIZATION`.\r\nhttps://docs.aws.amazon.com/redshift/latest/dg/r_SET_SESSION_AUTHORIZATION.html\r\n\r\nTo run this command, the connection must use superuser', 'created_at': datetime.datetime(2024, 2, 9, 18, 3, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936383803, 'issue_id': 2119041093, 'author': 'marcoquerque', 'body': 'And what is our general thoughts on the metabase redshift user being a superuser? are we concerned from a security perspective - can we confidently say every query will use this?', 'created_at': datetime.datetime(2024, 2, 9, 18, 9, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 1936392297, 'issue_id': 2119041093, 'author': 'luizarakaki', 'body': ""Queries from users in groups with impersonated connection, yes. But admins are never impersonated, so at least queries run by admin won't use this."", 'created_at': datetime.datetime(2024, 2, 9, 18, 13, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1938415996, 'issue_id': 2119041093, 'author': 'calherries', 'body': ""Pretty sure this is closed by https://github.com/metabase/metabase/pull/38530, so I'm closing this to get it into the release notes. Please yell at me if not"", 'created_at': datetime.datetime(2024, 2, 12, 10, 34, 34, tzinfo=datetime.timezone.utc)}]","marcoquerque on (2024-02-09 17:57:48 UTC): In general, what are your thoughts on requiring the redshift user in the metabase connection be a super user to use this?

luizarakaki (Issue Creator) on (2024-02-09 18:03:54 UTC): Redshift connection impersonation uses `SET SESSION AUTHORIZATION`.
https://docs.aws.amazon.com/redshift/latest/dg/r_SET_SESSION_AUTHORIZATION.html

To run this command, the connection must use superuser

marcoquerque on (2024-02-09 18:09:13 UTC): And what is our general thoughts on the metabase redshift user being a superuser? are we concerned from a security perspective - can we confidently say every query will use this?

luizarakaki (Issue Creator) on (2024-02-09 18:13:12 UTC): Queries from users in groups with impersonated connection, yes. But admins are never impersonated, so at least queries run by admin won't use this.

calherries on (2024-02-12 10:34:34 UTC): Pretty sure this is closed by https://github.com/metabase/metabase/pull/38530, so I'm closing this to get it into the release notes. Please yell at me if not

"
2118939384,issue,closed,completed,[dc.js migration] on brushable charts cursor is always `crosshair` even when hovering chart elements,On timeseries and numeric x-axis charts brushing is enabled by default. This leads to always showing `crosshair` cursor (cross) instead of `pointer` even when hovering chart elements like bars.,alxnddr,2024-02-05 16:20:02+00:00,['alxnddr'],2024-02-06 19:01:16+00:00,2024-02-06 19:01:16+00:00,https://github.com/metabase/metabase/issues/38439,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2118878396,issue,closed,completed,[dc.js migration] tooltip is not triggered when line/area charts do not have dots,"When dots are not visible on line/area charts, the tooltip is not showing. This is because the hover event handlers are bound to the dots.",alxnddr,2024-02-05 15:51:01+00:00,['alxnddr'],2024-02-06 19:01:24+00:00,2024-02-06 19:01:24+00:00,https://github.com/metabase/metabase/issues/38436,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2118854480,issue,closed,completed,FE: add UI for uploading from collections list,"[figma](https://www.figma.com/file/tLUjTffE2vTCRbQeb71HJQ/Allow-appends-on-existing-CSV-upload-models?type=design&node-id=1005-58551&mode=design&t=WqF2DT117ImHZ3VV-0)

![Screen Shot 2024-02-05 at 1 49 12 PM](https://github.com/metabase/metabase/assets/30528226/60cd8fbb-c388-4bf6-bf61-d28070c5a744)

![Screen Shot 2024-02-05 at 1 49 21 PM](https://github.com/metabase/metabase/assets/30528226/97a4931f-143e-414d-b5ee-39b874410163)

![Screen Shot 2024-02-05 at 1 49 48 PM](https://github.com/metabase/metabase/assets/30528226/1c22bf26-8399-45ad-ae0d-e692b368e7fc)





```[tasklist]
### Tasks
- [x] Create Model Selection Modal
- [x] Handle Errors
- [x] Handle Upload to new model
```
",iethree,2024-02-05 15:39:40+00:00,['iethree'],2024-02-09 18:24:54+00:00,2024-02-09 18:24:53+00:00,https://github.com/metabase/metabase/issues/38435,"[('.Frontend', ''), ('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 1932428732, 'issue_id': 2118854480, 'author': 'calherries', 'body': ""@iethree I've removed the 49 milestone from the epic to not label it a blocker, so if this issue is closed before 49 you should add the milestone here"", 'created_at': datetime.datetime(2024, 2, 7, 16, 32, 51, tzinfo=datetime.timezone.utc)}]","calherries on (2024-02-07 16:32:51 UTC): @iethree I've removed the 49 milestone from the epic to not label it a blocker, so if this issue is closed before 49 you should add the milestone here

"
2118722749,issue,closed,completed,Implement advanced cache strategies,"[Tech doc](https://www.notion.so/metabase/Tech-Cache-arc-bbbdc728e38c49dbad52cebd22c9011e)
```[tasklist]
### Tasks
```
",piranha,2024-02-05 14:40:00+00:00,['piranha'],2024-03-20 13:08:48+00:00,2024-03-20 12:22:46+00:00,https://github.com/metabase/metabase/issues/38434,"[('Querying/Cache', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]",[],
2118609531,issue,closed,completed,Migrate the FieldInfo card to Mantine so it can be reused,"Migrate the FieldInfo hovercard to Mantine so that it no longer makes use of deprecated components.

",romeovs,2024-02-05 13:48:31+00:00,['romeovs'],2024-02-16 12:18:59+00:00,2024-02-07 16:39:54+00:00,https://github.com/metabase/metabase/issues/38432,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2118526898,issue,closed,completed,No option to hide/show tabs in Interactive embedding as a parameter. header=false will hide all tabs and go to tab 1 by default,"**Is your feature request related to a problem? Please describe.**
Setting `header=false` will hide tab selection and default to 1
In addition, I tried to put tab=x in the embedded URL and couldn't set the desired tab

**Describe the solution you'd like**
Have header=false not hide tabs in a dashboard, and instead have a new parameter that hides/shows tabs

**Describe alternatives you've considered**
Enabling header, but you might want the ability to hide one and not the other.

**How important is this feature to you?**
Requested by a customer, internal ticket [24697](https://metabase.zendesk.com/agent/tickets/24697)

**Additional context**
N/A
",ignacio-mb,2024-02-05 13:13:24+00:00,['WiNloSt'],2024-03-20 10:48:58+00:00,2024-02-22 07:21:10+00:00,https://github.com/metabase/metabase/issues/38429,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]","[{'comment_id': 1944442589, 'issue_id': 2118526898, 'author': 'albertoperdomo', 'body': ""Turning this into a bug as it's not the expected behavior.\r\nP2 because hiding the header should be compatible with using dashboards tabs."", 'created_at': datetime.datetime(2024, 2, 14, 19, 17, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 1944531406, 'issue_id': 2118526898, 'author': 'ignacio-mb', 'body': ""Should have asked if it was or wasn't the intended behaviour, thanks @albertoperdomo"", 'created_at': datetime.datetime(2024, 2, 14, 20, 20, 58, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-02-14 19:17:08 UTC): Turning this into a bug as it's not the expected behavior.
P2 because hiding the header should be compatible with using dashboards tabs.

ignacio-mb (Issue Creator) on (2024-02-14 20:20:58 UTC): Should have asked if it was or wasn't the intended behaviour, thanks @albertoperdomo

"
2118392854,issue,closed,completed,Pie chart % show on chart doesn't show for areas larger than 95%,"### Describe the bug

Hello,

For some reason when selecting 'show percentages on the chart' with pie charts areas over 95% in size don't display the percentage

![image](https://github.com/metabase/metabase/assets/97034772/e718302c-0f1b-495a-9ac4-3b90d9323590)

vs

![image](https://github.com/metabase/metabase/assets/97034772/65003b27-78b6-4dc7-9cda-f82a2317d4f5)

&

![image](https://github.com/metabase/metabase/assets/97034772/addb2969-2377-4539-be4d-e6469317f612)


I suppose this might be intentional behaviour but at the very least that seems to be undocumented, which caused me many hours of frustration, and ideally would be something we could turn off since having this setting turned on means the percentages will not be in the legend so the information is completely lost otherwise. Also it just makes the chart ugly

I'd consider being able to have them in both the legend and on the chart as a slightly less ideal solution to this too.

### To Reproduce

```
select 'first' as ""data"", 0 as ""amount""

union all

select 'second' as ""data"", 0 as ""amount""

union all

select 'third' as ""data"", 0 as ""amount""

union all

select 'fourth' as ""data"", 500 as ""amount""
```

Turn it into a pie chart visualisation and then tweak the values as you like. This should work regardless of which database you point metabase at.

### Expected behavior

I'd like to be able to configure it to not have a max % cap

### Logs

N/A

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.205-195.807.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.8""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""?"",
      ""tag"": ""vUNKNOWN"",
      ""hash"": ""?""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/London""
    }
  }
}
```


### Severity

Annoying because it's inconsistent and doesn't match other pie charts

### Additional context

_No response_",jamesladyman-cognitant,2024-02-05 12:13:22+00:00,[],2024-10-08 16:19:12+00:00,2024-07-31 17:11:58+00:00,https://github.com/metabase/metabase/issues/38424,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1929782225, 'issue_id': 2118392854, 'author': 'paoliniluis', 'body': 'to reproduce:\r\n1) create a SQL question\r\n```\r\nselect \'first\' as ""data"", 5 as ""amount""\r\nunion all\r\nselect \'second\' as ""data"", 5 as ""amount""\r\nunion all\r\nselect \'third\' as ""data"", 5 as ""amount""\r\nunion all\r\nselect \'fourth\' as ""data"", 500 as ""amount""\r\n```\r\n2) save it as a pie chart\r\n3) set the legend to be on the chart\r\n![image](https://github.com/metabase/metabase/assets/1711649/b6304acf-51e3-43a6-8a68-49cc8a4d84ab)\r\n\r\n\r\npercentages won\'t be shown', 'created_at': datetime.datetime(2024, 2, 6, 14, 17, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 1931797153, 'issue_id': 2118392854, 'author': 'perivamsi', 'body': '@alxnddr @EmmadUsmani does echarts fix this?', 'created_at': datetime.datetime(2024, 2, 7, 10, 59, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2136366083, 'issue_id': 2118392854, 'author': 'alxnddr', 'body': '@perivamsi it is not directly related to visualization layer, the bug appears to be in the way we compute slices. We need to implement the new Pie correctly', 'created_at': datetime.datetime(2024, 5, 29, 1, 43, 55, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:17:47 UTC): to reproduce:
1) create a SQL question
```
select 'first' as ""data"", 5 as ""amount""
union all
select 'second' as ""data"", 5 as ""amount""
union all
select 'third' as ""data"", 5 as ""amount""
union all
select 'fourth' as ""data"", 500 as ""amount""
```
2) save it as a pie chart
3) set the legend to be on the chart
![image](https://github.com/metabase/metabase/assets/1711649/b6304acf-51e3-43a6-8a68-49cc8a4d84ab)


percentages won't be shown

perivamsi on (2024-02-07 10:59:49 UTC): @alxnddr @EmmadUsmani does echarts fix this?

alxnddr on (2024-05-29 01:43:55 UTC): @perivamsi it is not directly related to visualization layer, the bug appears to be in the way we compute slices. We need to implement the new Pie correctly

"
2118144619,issue,open,,Pivot tables not working with Models based on sql query when mapping of columns to database is set,"### Describe the bug

When using a sql query defined model and filling in ""Database column this maps to"" and then using such column in group by summarization and displaying as Pivot table it fails. The generated query fails on Snowflake. 

### To Reproduce

1. Create a sql based mode
2. Set database column mapping
3. Use mapped column in group by for summarization
4. Visualize as Pivot table


### Expected behavior

Pivot table should work.

### Logs

SQL compilation error: error line X at position XX
invalid identifier '""source"".FIELD'

### Information about your Metabase installation

```JSON
Safari Version 17.3 (19617.2.4.11.8)
MacOs Sonoma 14.3 (23D56)
Metabase open source 0.48.4
Metabse db: Postgres
```


### Severity

annoying and blocking some users

### Additional context

It's possible to work around by removing the mappings.",vpasler,2024-02-05 10:09:24+00:00,[],2025-02-04 20:31:58+00:00,,https://github.com/metabase/metabase/issues/38423,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 1929870086, 'issue_id': 2118144619, 'author': 'paoliniluis', 'body': 'To reproduce:\r\n1) create a SQL query:\r\n```\r\nselect\r\n      orders.*,\r\n      people.email,\r\n      people.state\r\n    from\r\n      ORDERS\r\n      left join people on people.id = orders.user_id\r\n```\r\n2) make it a model\r\n3) edit the metadata and link product_id and state to orders->product_id and people->state\r\n4) group by state and product->id\r\n5) change the viz type to pivot table\r\n\r\n\r\nError:\r\n```\r\nColumn ""source.PRODUCT_ID"" not found; SQL statement:\r\nSELECT ""source"".""PRODUCT_ID"" AS ""PRODUCT_ID"", ""source"".""STATE"" AS ""STATE"", ""source"".""pivot-grouping"" AS ""pivot-grouping"", COUNT(*) AS ""count"" FROM (SELECT ABS(0) AS ""pivot-grouping"" FROM (select orders.*, people.email, people.state from ORDERS\r\nleft join people on people.id = orders.user_id) AS ""source"") AS ""source"" GROUP BY ""source"".""PRODUCT_ID"", ""source"".""STATE"", ""source"".""pivot-grouping"" ORDER BY ""source"".""PRODUCT_ID"" ASC, ""source"".""STATE"" ASC, ""source"".""pivot-grouping"" ASC [42122-214]\r\n```', 'created_at': datetime.datetime(2024, 2, 6, 14, 33, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 1929871154, 'issue_id': 2118144619, 'author': 'paoliniluis', 'body': ""Marking as a regression as it worked back in 46, haven't tried in 47"", 'created_at': datetime.datetime(2024, 2, 6, 14, 33, 59, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:33:41 UTC): To reproduce:
1) create a SQL query:
```
select
      orders.*,
      people.email,
      people.state
    from
      ORDERS
      left join people on people.id = orders.user_id
```
2) make it a model
3) edit the metadata and link product_id and state to orders->product_id and people->state
4) group by state and product->id
5) change the viz type to pivot table


Error:
```
Column ""source.PRODUCT_ID"" not found; SQL statement:
SELECT ""source"".""PRODUCT_ID"" AS ""PRODUCT_ID"", ""source"".""STATE"" AS ""STATE"", ""source"".""pivot-grouping"" AS ""pivot-grouping"", COUNT(*) AS ""count"" FROM (SELECT ABS(0) AS ""pivot-grouping"" FROM (select orders.*, people.email, people.state from ORDERS
left join people on people.id = orders.user_id) AS ""source"") AS ""source"" GROUP BY ""source"".""PRODUCT_ID"", ""source"".""STATE"", ""source"".""pivot-grouping"" ORDER BY ""source"".""PRODUCT_ID"" ASC, ""source"".""STATE"" ASC, ""source"".""pivot-grouping"" ASC [42122-214]
```

paoliniluis on (2024-02-06 14:33:59 UTC): Marking as a regression as it worked back in 46, haven't tried in 47

"
2118102030,issue,open,reopened,Columns not available in chill mode and Query Builder on a particular model,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/125455699/39d70cac-c40e-43b9-ad84-50be3ffdf6b0)
![image](https://github.com/metabase/metabase/assets/125455699/4063a2ca-c1be-412e-ba99-cadd0be6ae97)

For this specific model, you can't filter on any column because the columns are not available in the chill mode or in the Query Builder. I couldn't reproduce it with a simple model from the sample database so not all models are affected.

### To Reproduce

1. Go to [this model](https://stats.metabase.com/model/13559)
2. Open the notebook editor
3. Try to select columns, add a filter, summarize things
4. Observe that you can only ""Select none"" columns, add no filters, and only use a very limited subset of aggregations

### Expected behavior

This should work like other models

### Logs

_No response_

### Information about your Metabase installation

```JSON
this was `master` on stats as of february 1st 2024 at least
```


### Severity

makes the model not that usable (reported by PM)

### Additional context

[slack thread with a loom](https://metaboat.slack.com/archives/C04CYTEL9N2/p1706749178444739)",darksciencebase,2024-02-05 09:48:28+00:00,[],2025-02-04 20:23:51+00:00,,https://github.com/metabase/metabase/issues/38422,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Backend', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]","[{'comment_id': 1926683902, 'issue_id': 2118102030, 'author': 'kamilmielnik', 'body': '[`Lib.fieldableColumns(query, stageIndex)` returns an empty array.](https://github.com/metabase/metabase/blob/a5b10b2b4a95f0f89c39c718ef7d7f8eaab1222c/frontend/src/metabase/query_builder/components/notebook/steps/DataStep/DataStep.tsx#L96)\r\nMetadata is present, things look OK on FE side.\r\nAssigning to QP team.', 'created_at': datetime.datetime(2024, 2, 5, 10, 39, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 1966634617, 'issue_id': 2118102030, 'author': 'kamilmielnik', 'body': ""I think this has been fixed in `master`, I can't reproduce it anymore.\r\n\r\n@darksciencebase ok to close?"", 'created_at': datetime.datetime(2024, 2, 27, 14, 8, 38, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-02-05 10:39:11 UTC): [`Lib.fieldableColumns(query, stageIndex)` returns an empty array.](https://github.com/metabase/metabase/blob/a5b10b2b4a95f0f89c39c718ef7d7f8eaab1222c/frontend/src/metabase/query_builder/components/notebook/steps/DataStep/DataStep.tsx#L96)
Metadata is present, things look OK on FE side.
Assigning to QP team.

kamilmielnik on (2024-02-27 14:08:38 UTC): I think this has been fixed in `master`, I can't reproduce it anymore.

@darksciencebase ok to close?

"
2116253428,issue,closed,not_planned,Request for Internationalization of Email and Notification Templates in Metabase,"Dear Metabase Development Team,

I hope this message finds you well. I am reaching out to you as an enthusiastic user of Metabase to express a suggestion that I believe would significantly enhance the user experience worldwide: the internationalization of email and notification templates.

Currently, I have noticed that these templates, such as ""new_user_invite.mustache"" and others, are exclusively in English. This limitation poses a barrier for those users who prefer or need to interact with Metabase in other languages. As part of a global community of users, I firmly believe that including internationalization in these templates would be a major step forward in making Metabase truly accessible and adaptable to diverse linguistic and cultural needs.

I understand that this development may require additional resources, but I believe the resulting benefits in terms of user satisfaction and expansion of the user base fully justify the investment. Full internationalization of Metabase not only in the user interface but also in automated communications would be a significant advancement that would enhance the overall user experience and strengthen Metabase's position as a leading data analytics solution.

Therefore, I kindly urge you to consider this request and include the internationalization of email and notification templates in your future development roadmap. I am confident that many users, like myself, would greatly appreciate this effort on your team's part.

I am available to provide any further clarification you may need. I sincerely appreciate your attention to this matter and look forward to seeing how Metabase continues to evolve to meet the needs of its diverse user base.

Best regards
Joel Sulecio",Sulecio,2024-02-03 05:28:32+00:00,[],2024-02-06 14:34:46+00:00,2024-02-06 14:34:46+00:00,https://github.com/metabase/metabase/issues/38420,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 1929873951, 'issue_id': 2116253428, 'author': 'paoliniluis', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/7535', 'created_at': datetime.datetime(2024, 2, 6, 14, 34, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:34:46 UTC): Duplicate of https://github.com/metabase/metabase/issues/7535

"
2115983524,issue,closed,completed,Export formatting for Longitude & Latitude,"Exports of CSV, JSON, Excel, and HTML should have consistent geographical coordinate formatting as the FE. Currently, all of these export as plain floats.",markbastian,2024-02-02 23:17:05+00:00,['markbastian'],2024-02-06 14:23:03+00:00,2024-02-06 04:37:11+00:00,https://github.com/metabase/metabase/issues/38419,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2115838274,issue,closed,completed,[Epic] Auto-generate default question titles and descriptions,[Product doc](https://www.notion.so/metabase/Auto-generate-default-question-titles-and-descriptions-f68b42ffb8924de387b1ec914bfa9d80),cdeweyx,2024-02-02 21:36:01+00:00,['markbastian'],2024-02-23 16:07:53+00:00,2024-02-23 16:07:53+00:00,https://github.com/metabase/metabase/issues/38417,"[('.Epic', 'Feature Implementation or Project'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1961599724, 'issue_id': 2115838274, 'author': 'markbastian', 'body': 'Closed by https://github.com/metabase/metabase/pull/38298', 'created_at': datetime.datetime(2024, 2, 23, 16, 7, 53, tzinfo=datetime.timezone.utc)}]","markbastian (Assginee) on (2024-02-23 16:07:53 UTC): Closed by https://github.com/metabase/metabase/pull/38298

"
2115477338,issue,open,,"Let me order by Total amount of Aggregations when there is more that one, and not the individual amount","**Is your feature request related to a problem? Please describe.**
When you have a graph with multiple aggregations and you Order By one, it will order by the individual amount and not with a second aggregation amount.

Let's say you have a question that uses the orders table to count by Total:Auto binned and Product->Category. Sort this by Count, descending. When you select Bar chart and Stack the bars, you would expect (before heading to the table view) that the bars are ordered from biggest count to smallest count.

<img width=""1187"" alt=""Screenshot 2024-02-02 at 2 44 42 PM"" src=""https://github.com/metabase/metabase/assets/132273646/698ffdd1-80c2-496d-b154-51d07c330b2d"">

But, because of the distribution of the data, some individual grouping of Total>Bins AND Category will have smaller/bigger values and make the total (in this case) Bin, smaller than the second one, making the chart look like this.

To corroborate this, head to the Table view and see that the individual values are correctly ordered.

<img width=""320"" alt=""Screenshot 2024-02-02 at 2 47 35 PM"" src=""https://github.com/metabase/metabase/assets/132273646/bda46ed7-0bcb-4c18-b1d6-656d2ef6e4a1"">

**Describe the solution you'd like**
This might be a very crazy ask, but I expect that when I order by the Count, to order by the total amount, and not like it's doing now. Or at least let me choose by which Count what of aggregation I can order by.
That number we already have it, as it is shown in the tooltip when hovering over each bar. I would like to order by the ""Total"" amount there,

**Describe alternatives you've considered**
There are workarounds using SQL, but that takes me out of the beloved Editor.

**How important is this feature to you?**
Requested by a customer

**Additional context**
N/A
",ignacio-mb,2024-02-02 17:54:24+00:00,[],2024-02-02 17:54:25+00:00,,https://github.com/metabase/metabase/issues/38406,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]",[],
2115455227,issue,closed,not_planned,timestamps without time zone get exported as dates in CSV exports,"### Describe the bug

I have tz-aware timestamps (timestamptz) stored in my source PostgresDB.
I convert those tz-aware timestamps with the function convertTimezone in a custom column in Metabase, which outputs a naive timestamp, as per Metabase documentation.
When I export it to a csv, this custome column only displays as a date (""2023-02-01""). I do not have the time component.

More generally (feature request) I find that the customization of export formats for csv/excel could be imporved (chose how to output dates: as text or date, in which exact format etc.)

### To Reproduce

To Reproduce
1. create a Postgres DB with a timestamptz column
2. add a custom column with convertTimezone Metabase function
3. download an extract as csv
See error: the csv file only has the date component for this custom column

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Quite annoying yet not extremely critical

### Additional context

More generally (feature request) I find that the customization of export formats for csv/excel could be imporved (chose how to output dates: as text or date, in which exact format etc.)",scd75,2024-02-02 17:41:03+00:00,[],2024-02-21 12:32:27+00:00,2024-02-06 14:36:33+00:00,https://github.com/metabase/metabase/issues/38403,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1929880020, 'issue_id': 2115455227, 'author': 'paoliniluis', 'body': ""@scd75 can you try on a test environment (please do not use this in production)  metabase/metabase-head:latest and check if the issue still exists? pretty sure that we fixed this in v49 so I'm closing this while you test"", 'created_at': datetime.datetime(2024, 2, 6, 14, 36, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 1952908708, 'issue_id': 2115455227, 'author': 'scd75', 'body': ""sorry I hadn't time to check on the test env, but i confirm it is now resolved in prod"", 'created_at': datetime.datetime(2024, 2, 19, 17, 16, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 1956174513, 'issue_id': 2115455227, 'author': 'brunomenu', 'body': ""Hi everyone\r\nI have the same problem: when exporting to CSV, the column containing datetime has datetimes for most hours, but only a date when hour is 00:00, see example attached. There's a temporary solution of exporting as excel, in which case this bug doesn't appear.\r\n\r\n![image](https://github.com/metabase/metabase/assets/30413220/a97a49ed-ed4e-4143-bf2f-3aaf5454ea33)"", 'created_at': datetime.datetime(2024, 2, 21, 8, 57, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 1956551454, 'issue_id': 2115455227, 'author': 'paoliniluis', 'body': '@brunomenu please try 49 release candidate', 'created_at': datetime.datetime(2024, 2, 21, 12, 32, 26, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-06 14:36:33 UTC): @scd75 can you try on a test environment (please do not use this in production)  metabase/metabase-head:latest and check if the issue still exists? pretty sure that we fixed this in v49 so I'm closing this while you test

scd75 (Issue Creator) on (2024-02-19 17:16:37 UTC): sorry I hadn't time to check on the test env, but i confirm it is now resolved in prod

brunomenu on (2024-02-21 08:57:48 UTC): Hi everyone
I have the same problem: when exporting to CSV, the column containing datetime has datetimes for most hours, but only a date when hour is 00:00, see example attached. There's a temporary solution of exporting as excel, in which case this bug doesn't appear.

![image](https://github.com/metabase/metabase/assets/30413220/a97a49ed-ed4e-4143-bf2f-3aaf5454ea33)

paoliniluis on (2024-02-21 12:32:26 UTC): @brunomenu please try 49 release candidate

"
2115334620,issue,closed,completed,"Date filtering (specific dates) on ""timestamp without timezone"" Postgres Type does not work","### Describe the bug

I have tz-aware timestamps (timestamptz) stored in my source PostgresDB.
I convert those tz-aware timestamps with the function convertTimezone in a custom column in Metabase, which outputs a naive timestamp, as per Metabase documentation.
I try filtering on this custom column, with the date filter wizard: it works for relative data selections, but returns an error for specific date selections / ranges:
`ERROR: operator does not exist: timestamp without time zone < character varying Hint: No operator matches the given name and argument types. You might need to add explicit type casts. Position: 13812`

From the look at the SQL queries, it seems that:
- it works for relative date filterings, because the comparisons are made against a date object
- it fails for specific date filterings, because the comparisons are made against a string

### To Reproduce

1. create a Postgres DB with a timestamptz column
2. add a custom column with convertTimezone Metabase function
3. try filtering on this column (specific dates)
4. See error:

`ERROR: operator does not exist: timestamp without time zone < character varying Hint: No operator matches the given name and argument types. You might need to add explicit type casts. Position: 13812`

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking my usage of Metabase entirely

### Additional context

Additionnally, Is there a way to convert timezone-aware timestamps to a preferred_timezone stored in a column? I found a hack but it is very inconvenient - for context, we have record for clients in multiple zones around the world -:
custom_column = case([Client → Preferred Tz] = ""Africa/Johannesburg"", convertTimezone([datetime_utc], ""Africa/Johannesburg""), [Client → Preferred Tz] = ""America/Bogota"", convertTimezone([datetime_utc], ...)",scd75,2024-02-02 16:50:20+00:00,[],2025-01-30 11:54:55+00:00,2025-01-30 11:54:38+00:00,https://github.com/metabase/metabase/issues/38401,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Misc/Timezones', ''), ('.Backend', ''), ('Querying/Notebook/Custom Column', ''), ('.Team/Querying', '')]","[{'comment_id': 1924284368, 'issue_id': 2115334620, 'author': 'paoliniluis', 'body': ""seems like you're doing a filter on the custom column right? can you show us what you're doing?"", 'created_at': datetime.datetime(2024, 2, 2, 17, 2, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1924378244, 'issue_id': 2115334620, 'author': 'scd75', 'body': ""> seems like you're doing a filter on the custom column right? can you show us what you're doing?\r\n\r\nyes exactly, i'm going through the UI:\r\n![image](https://github.com/metabase/metabase/assets/70274528/8339cb0f-3b2a-4ca1-ba54-6f6e2562d68c)"", 'created_at': datetime.datetime(2024, 2, 2, 17, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 1952910536, 'issue_id': 2115334620, 'author': 'scd75', 'body': 'Hi @paoliniluis ,\r\nIs this one being picked? without this working, we are basically unable to use the solution. Thanks and let me know if anything is not clear', 'created_at': datetime.datetime(2024, 2, 19, 17, 18, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2624287076, 'issue_id': 2115334620, 'author': 'lbrdnk', 'body': 'Reproduced on `48.4`, working correctly on master 220e18db22cde8e41a7cf140c5e182af302692e7. Closing as completed.', 'created_at': datetime.datetime(2025, 1, 30, 11, 54, 38, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-02-02 17:02:25 UTC): seems like you're doing a filter on the custom column right? can you show us what you're doing?

scd75 (Issue Creator) on (2024-02-02 17:35:43 UTC): yes exactly, i'm going through the UI:
![image](https://github.com/metabase/metabase/assets/70274528/8339cb0f-3b2a-4ca1-ba54-6f6e2562d68c)

scd75 (Issue Creator) on (2024-02-19 17:18:05 UTC): Hi @paoliniluis ,
Is this one being picked? without this working, we are basically unable to use the solution. Thanks and let me know if anything is not clear

lbrdnk on (2025-01-30 11:54:38 UTC): Reproduced on `48.4`, working correctly on master 220e18db22cde8e41a7cf140c5e182af302692e7. Closing as completed.

"
2115277059,issue,closed,completed,Grouping by timezone-aware timestamps results in duplicates in DST-changing months (Snowflake),"### Describe the bug

Our Metabase instance and Snowflake database have timestamps in the America/Los_Angeles timezone, this timezone changes every year at March and November.

The way Metabase is generating queries when grouping by Month on such fields, generates duplicate values.

By inspecting the SQL Query, this seems to be because we are just using ""date_trunc"", which will generate e.g. on Nov 2023, to have a row that says ""Nov 2023, UTC-7"" and another row that says ""Nov 2023, UTC-8""

### To Reproduce

Create a table in Snowflake that has at least two timestamps with timezone, e.g.:

create table test as (
select convert_timezone('UTC', 'America/Los_Angeles', '2023-11-01 00:00:00')::timestamp_tz as date
union
select convert_timezone('UTC', 'America/Los_Angeles', '2023-11-08 00:00:00')::timestamp_tz as date
)

Go to metabase, sync this table and try to group by this field, instead of getting one row that indicates that there are two rows, you'll get two rows with one each.

### Expected behavior

Only one row should be generated per each month/quarter/year

### Logs

There are no relevant logs, but this is a sample query generated by Metabase from a question with this issue:

```
SELECT
  DATE_TRUNC(""month"", ""CORE"".""DIM_ACCOUNT"".""CREATED_AT"") AS ""CREATED_AT"",
  COUNT(*) AS ""count""
FROM
  ""INFORMATION_MARTS"".""CORE"".""DIM_ACCOUNT""
WHERE
  (
    ""CORE"".""DIM_ACCOUNT"".""CREATED_AT"" >= '2023-11-01 00:00 -07:00':: timestamp_tz
  )
 
   AND (
    ""CORE"".""DIM_ACCOUNT"".""CREATED_AT"" < '2023-12-01 00:00 -08:00':: timestamp_tz
  )
GROUP BY
  DATE_TRUNC(""month"", ""CORE"".""DIM_ACCOUNT"".""CREATED_AT"")
ORDER BY
  DATE_TRUNC(""month"", ""CORE"".""DIM_ACCOUNT"".""CREATED_AT"") ASC
```

<img width=""948"" alt=""image"" src=""https://github.com/metabase/metabase/assets/4952116/d480b08e-e499-4efa-9938-93f37cb0fec7"">
<img width=""304"" alt=""image"" src=""https://github.com/metabase/metabase/assets/4952116/c1146660-bdd1-4ad8-ba9e-4d15573cbeb0"">


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.201-191.748.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.28""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v0.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```


### Severity

This breaks a lot of reports and makes us resort to SQL instead of the visual editor in many cases.

### Additional context

_No response_",sicarul,2024-02-02 16:18:24+00:00,[],2024-02-05 16:40:43+00:00,2024-02-05 16:40:43+00:00,https://github.com/metabase/metabase/issues/38399,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1924822363, 'issue_id': 2115277059, 'author': 'perivamsi', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/37065', 'created_at': datetime.datetime(2024, 2, 2, 22, 40, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 1927420913, 'issue_id': 2115277059, 'author': 'sicarul', 'body': ""Closed as this is a dupe, sorry i didn't see it."", 'created_at': datetime.datetime(2024, 2, 5, 16, 40, 43, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-02-02 22:40:32 UTC): Duplicate of https://github.com/metabase/metabase/issues/37065

sicarul (Issue Creator) on (2024-02-05 16:40:43 UTC): Closed as this is a dupe, sorry i didn't see it.

"
