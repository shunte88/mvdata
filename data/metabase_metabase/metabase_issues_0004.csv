id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2611934851,issue,closed,completed,"FE - e2e - Add tests verifying that pre-existing dashboards without ""stage-number"" attribute present work",See #48734 and #49110,kamilmielnik,2024-10-24 15:26:39+00:00,[],2024-10-28 10:51:30+00:00,2024-10-28 10:51:29+00:00,https://github.com/metabase/metabase/issues/49109,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2441243731, 'issue_id': 2611934851, 'author': 'kamilmielnik', 'body': ""Closing - won't do.\nWe agreed that BE will have a proper migration for it (#48734), so once we release the feature, there should be no cases with missing `stage-number`. Nothing to test."", 'created_at': datetime.datetime(2024, 10, 28, 10, 51, 29, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-28 10:51:29 UTC): Closing - won't do.
We agreed that BE will have a proper migration for it (#48734), so once we release the feature, there should be no cases with missing `stage-number`. Nothing to test.

"
2611805894,issue,open,,[Epic] Metabot LLM UX Track,Placeholder: Improve the UX of the chatbot,perivamsi,2024-10-24 14:36:22+00:00,[],2025-02-04 20:26:03+00:00,,https://github.com/metabase/metabase/issues/49105,"[('.Epic', 'Feature Implementation or Project'), ('Metabot/UX', ""Metabot's user experience and chatbot"")]",[],
2611752646,issue,closed,not_planned,Results In visualization and dashboards are different from actual results in the tables on metabase and the actual database,"**Describe the bug**
When creating a question it initially shows the correct numbers but after saving it and adding it to dashboards the questions show wrong values even tho if remove the visualisations and look at the actual table with filters only the numbers are correct 


**To Reproduce**
Steps to reproduce the behavior:
1. Create a question 
2. Save it
3. Add it to a dashboard
4. Refresh after a while


**Expected behavior**
Show correct results that reflect the data in the tables 

**Screenshots**
![Image](https://github.com/user-attachments/assets/6f039d07-a89d-4d03-9d34-f23b516aaedc)
![Image](https://github.com/user-attachments/assets/b62778b7-ef81-4a2c-b95c-eec017e5d9b1)
![Image](https://github.com/user-attachments/assets/81abbfd6-c730-4e61-aeeb-7c787a36d3ea)
When I remove the summary and add a filter for today:
![Image](https://github.com/user-attachments/assets/4f606c87-507b-41e9-b815-bd73042ec5f4)
and here it is as a number card showing the correct result:
![Image](https://github.com/user-attachments/assets/0c0f8e43-c404-4395-927b-0f0ca242d1fd)
but even if I save it as a number card the same thing happens and the results become wrong after a while and not even increase but decrease which is impossible 
**Severity**
High imo, reports are showing wrong numbers and some of these reports are being sent daily or hourly to higher-ups at my workplace thus making all reports coming from Metabase worthless rn 

**Additional context**
We're using MariaDB

**Metabase Diagnostic Info**

``{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""Africa/Cairo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.226-214.879.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",ZiadEK8,2024-10-24 14:18:34+00:00,[],2024-10-24 17:02:49+00:00,2024-10-24 17:02:48+00:00,https://github.com/metabase/metabase/issues/49103,[],"[{'comment_id': 2435825064, 'issue_id': 2611752646, 'author': 'paoliniluis', 'body': ""please ensure that the rows are commited, we just send queries to the DW an render that, we're actually rendering what comes from the DB here"", 'created_at': datetime.datetime(2024, 10, 24, 17, 2, 48, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-24 17:02:48 UTC): please ensure that the rows are commited, we just send queries to the DW an render that, we're actually rendering what comes from the DB here

"
2611651056,issue,open,,[Epic] Metabot AI Service Track,"## Testing Strategy
https://www.notion.so/metabase/Think-about-how-to-evaluate-our-LLM-service-12069354c901806a89aae2fcdd356a5a

## Prompt Tweaking

## CI/CD
- Get the Github workflow setup to auto deploy to cloud

## Token Checks
- Thomas's work on getting [token check into ai-proxy.](https://github.com/metabase/ai-proxy/pull/35#discussion_r1812758356) ([Product Doc](https://www.notion.so/metabase/Token-gate-the-LLM-Service-12769354c9018090b141c0c988f397cf?d=12869354c901805b845c001c395a87c7#12769354c901805ba8d7ef40d31bbc00)) Currently we pass the token it within the request body (`instance_info.token` ) Is this something we want to keep or rather send it via the header?

## Other
- Adjust the system prompt to say “My mom says I’m the best” (without emoji) 
- Introduce versioning - like versions we can track. Those should be somehow automatically be generated on merge to master that we don't need to bother with that.
- ",perivamsi,2024-10-24 13:39:42+00:00,[],2025-02-04 20:26:02+00:00,,https://github.com/metabase/metabase/issues/49101,"[('.Epic', 'Feature Implementation or Project'), ('Metabot/LLMService', '(we can change this name) aka ai-proxy aka LLM agent service')]",[],
2611631119,issue,open,,Schema sync - tables with identical names but different capitalization are not handled correctly,"### Describe the bug

When two tables have names that only differ in capitalization, the column metadata may get loaded into the wrong table.

### To Reproduce

Use a Postgres database and execute the DDL statements one by one, performing a schema sync after each step.
I've exported the relevant metabase_field and metabase_table records after each step using the following query:
```
select
    t.id, t.name, t.active, f.id, f.name, f.active, f.database_position
from metabase_table t
left join metabase_field f
                    on f.table_id = t.id
where lower(t.name) like 'test%'
order by t.db_id, t.id, f.database_position
```

```
-- Issue 3 - tables with identical names but different capitalization are not handled correctly
--
-- 1. create a table
create table testa (
    id_a serial primary key,
    name_a text
)
-- 68,testa,true,453,id_a,true,0
-- 68,testa,true,452,name_a,true,1

-- 2. create a table with the same name but different capitalization
-- See that the second table does not have any columns associated with in the metadata. 
-- The new columns are mapped to the first table.
create table ""testA"" (
    id_Acapital serial primary key,
    name_Acapital text
)
-- 68,testa,true,454,id_acapital,true,0
-- 68,testa,true,453,id_a,false,0
-- 68,testa,true,455,name_acapital,true,1
-- 68,testa,true,452,name_a,false,1
-- 69,testA,true,,,,
```

### Expected behavior

It should work.

### Logs

_No response_

### Information about your Metabase installation

1.50.30

### Severity

Rare but serious issue as resolving it may require manual updates to the metadata.

### Additional context

_No response_",zbodi74,2024-10-24 13:31:33+00:00,[],2025-02-04 20:24:34+00:00,,https://github.com/metabase/metabase/issues/49100,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2476212180, 'issue_id': 2611631119, 'author': 'artem-levashov', 'body': 'I have  worse situation after latest update.  I have 3 differend  DBs. all three  has  tables with exact same  name. tables has about several fields with same name  but second and third table hass own additional fields.  after scan DB table metadata contains fields from all 3 tables. why it shares between diffrenet DBs?  how to fix it? I cannot rename my tables.  My version is  Metabase 0.51.3', 'created_at': datetime.datetime(2024, 11, 14, 12, 18, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477500832, 'issue_id': 2611631119, 'author': 'paoliniluis', 'body': ""@artem-levashov I just tested the same version and I wasn't able to find the issue you're seeing. Can you please check?"", 'created_at': datetime.datetime(2024, 11, 14, 22, 6, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478162493, 'issue_id': 2611631119, 'author': 'artem-levashov', 'body': 'I still have this problem. Today  I had  to go inside metabase db  and set schedule for db scnhema sync  of all 3 tables  for  1st Sept next year.  otherwise  I had to  clean  wrong filed in metabse_field  every day after cron.', 'created_at': datetime.datetime(2024, 11, 15, 7, 52, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478164875, 'issue_id': 2611631119, 'author': 'artem-levashov', 'body': 'additinal info - all 3 DBs  hosted on same server with same connection string - difference only in DB name', 'created_at': datetime.datetime(2024, 11, 15, 7, 54, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482290329, 'issue_id': 2611631119, 'author': 'zbodi74', 'body': ""@artem-levashov - could you confirm the type of database you're using?\nAny chance that you are seeing this issue: https://github.com/metabase/metabase/issues/50072?"", 'created_at': datetime.datetime(2024, 11, 18, 8, 42, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486020260, 'issue_id': 2611631119, 'author': 'artem-levashov', 'body': 'I`m author of  #50072   :-) loos like problem is solev in next version', 'created_at': datetime.datetime(2024, 11, 19, 15, 23, 43, tzinfo=datetime.timezone.utc)}]","artem-levashov on (2024-11-14 12:18:27 UTC): I have  worse situation after latest update.  I have 3 differend  DBs. all three  has  tables with exact same  name. tables has about several fields with same name  but second and third table hass own additional fields.  after scan DB table metadata contains fields from all 3 tables. why it shares between diffrenet DBs?  how to fix it? I cannot rename my tables.  My version is  Metabase 0.51.3

paoliniluis on (2024-11-14 22:06:02 UTC): @artem-levashov I just tested the same version and I wasn't able to find the issue you're seeing. Can you please check?

artem-levashov on (2024-11-15 07:52:14 UTC): I still have this problem. Today  I had  to go inside metabase db  and set schedule for db scnhema sync  of all 3 tables  for  1st Sept next year.  otherwise  I had to  clean  wrong filed in metabse_field  every day after cron.

artem-levashov on (2024-11-15 07:54:06 UTC): additinal info - all 3 DBs  hosted on same server with same connection string - difference only in DB name

zbodi74 (Issue Creator) on (2024-11-18 08:42:29 UTC): @artem-levashov - could you confirm the type of database you're using?
Any chance that you are seeing this issue: https://github.com/metabase/metabase/issues/50072?

artem-levashov on (2024-11-19 15:23:43 UTC): I`m author of  #50072   :-) loos like problem is solev in next version

"
2611616707,issue,open,,[Epic] Metabot Tools Track,"## Viz Tools
- Remove the apply-viztool, split it up into parts and design those properly
- Create tools for changing viz type, color schemes, axes labels, hide/show legends

## Admin Tools
- Think about tool results (maybe not purely success but something like "" <email> was invited"") and human readable errors with action advice (e.g. ""your email 'thomas@metabase' is missing a top level domain"")
- Create tool to assign users to groups

## Cleanup work
- Remove goto-question . Right now it confuses the LLM when other tools would be appropriate. As we talked yesterday, this also brings not much benefit compared to cmd+k for now.

## Testing
- Potentially port the tool testing framework in ai-proxy over to Metabase repo (see discussion in [the thread](https://metaboat.slack.com/archives/C06UF8TBYH2/p1729617875992349?thread_ts=1729513011.092289&cid=C06UF8TBYH2)). This would allow to iterate on the tools in Metabase AND to realize if something breaks if we do adjustments to the schema.",perivamsi,2024-10-24 13:25:52+00:00,[],2025-02-04 20:26:01+00:00,,https://github.com/metabase/metabase/issues/49099,"[('.Epic', 'Feature Implementation or Project'), ('Metabot/Tools', 'Tools that are agnostic of the LLM framework itself, could be reused for notifications framework als')]",[],
2611602704,issue,open,,[Epic] Metabot Infra Track,"## API call sequencing
- Do the roundtrip to send back tool results to the LLM for a text response. 
- We should not hardcode all responses as reactions. Only in cases where it fully makes sense for some reason. 
- The agent should respond (especially for BE actions - for FE there might be reactions where we don't need a response from the Metabot)

## Context enrichment and management
- Send current time with the context (this allows time relative queries like ""orders from last week"" in the future)
- Come up with a plan what we send in the context and how to name it (e.g. ""question"" might be a bad term since the LLM will not understand that this is a chart. There needs to be some mapping that uses easy to understand things)
- Create tools that just enrich the context
",perivamsi,2024-10-24 13:21:24+00:00,"['johnswanson', 'sloansparger']",2025-02-04 20:26:15+00:00,,https://github.com/metabase/metabase/issues/49098,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Metabot/Infra', 'Infra for the multi tool agent LLM')]","[{'comment_id': 2435511240, 'issue_id': 2611602704, 'author': 'Somtom', 'body': '@perivamsi \n**Re context:** \n\nI was about to write this down in the Metabot vision for the future but would fit here as well.\nWe want to keep the context we send as small as possible. Imagine the LLM knows nothing about where the user is and what it can do - it just gets the message. This limits its ability and might make it ask for clarification more often than needed.\nSo what if we include this as a start:\n\n* Current time \n* Current Page\n  * Some understandable title\n  * Some description of what this page is about\n\nCould be something like this\n```json\n{\n  ""current_time"": <timestamp>,\n  ""page_user_is_on"": {\n      ""name"": ""Visualizer"",\n      ""description"": ""Visualizes the current result of a query""\n   }\n}\n```\n\nI was thinking that each page in the frontend could implement such a page description + **which tools are available on that page** (+ potentially some globally available ones).\nThe later could be sent to the BE and the BE uses it to pre-filter the tools sent to the LLM service.\nThis will help pre-selecting for tools that actually make sense on that page.\n\n\n\n\n> Create tools that just enrich the context\n\nDepending on how far we get with viz / query tools, this could potentially be something for later since it involves multi-steps - buuut with the roundtrip it could actually already work', 'created_at': datetime.datetime(2024, 10, 24, 14, 48, 20, tzinfo=datetime.timezone.utc)}]","Somtom on (2024-10-24 14:48:20 UTC): @perivamsi 
**Re context:** 

I was about to write this down in the Metabot vision for the future but would fit here as well.
We want to keep the context we send as small as possible. Imagine the LLM knows nothing about where the user is and what it can do - it just gets the message. This limits its ability and might make it ask for clarification more often than needed.
So what if we include this as a start:

* Current time 
* Current Page
  * Some understandable title
  * Some description of what this page is about

Could be something like this
```json
{
  ""current_time"": <timestamp>,
  ""page_user_is_on"": {
      ""name"": ""Visualizer"",
      ""description"": ""Visualizes the current result of a query""
   }
}
```

I was thinking that each page in the frontend could implement such a page description + **which tools are available on that page** (+ potentially some globally available ones).
The later could be sent to the BE and the BE uses it to pre-filter the tools sent to the LLM service.
This will help pre-selecting for tools that actually make sense on that page.





Depending on how far we get with viz / query tools, this could potentially be something for later since it involves multi-steps - buuut with the roundtrip it could actually already work

"
2611491733,issue,open,,Schema sync - incorrect handling of renames of columns with identical name but different capitalization,"### Describe the bug

1. When a table has multiple columns with identical names but different capitalization, changes to those column names are not handled correctly - the table ends up with having one additional column in Metabase.

2. Additionally, changing the capitalization of a column is treated differently than a standard column rename. Not sure if this is intentional, but it's surprising to see it handled this way.

### To Reproduce

Use a Postgres database and execute the DDL statements one by one, performing a schema sync after each step. 
I've exported the relevant `metabase_field` and `metabase_table` records after each step using the following query:

```
select
    t.id, t.name, t.active, f.id, f.name, f.active, f.database_position
from metabase_table t
left join metabase_field f
                    on f.table_id = t.id
where lower(t.name) like 'test%'
order by t.db_id, t.id, f.database_position
```

Reproduction steps for issue 1 - multiple columns with identical names
```
drop table ""Test1"";
-- 1. create a table with columns having identical names with different capitalization
create table ""Test1""(
                      ""Id"" serial primary key,
                      ""Name"" text,
                      ""name"" text
)
-- 55,Test1,true,434,Id,true,0
-- 55,Test1,true,432,Name,true,1
-- 55,Test1,true,433,name,true,2

-- 2. rename one of such columns, and see the metadata ending up with one more active column
alter table ""Test1"" rename column ""Name"" to ""Name2"";
-- 55,Test1,true,434,Id,true,0
-- 55,Test1,true,435,Name2,true,1
-- 55,Test1,true,432,Name,true,1
-- 55,Test1,true,433,name,true,2
```


Reproduction steps for issue 2 - renaming a column vs only changing its capitalization is handled differently:
```
-- rename - a new metabase_field entry is added for the column, and the previous one is inactivated
create table test2 (
        id serial primary key,
        name text
);
-- 62,test2,true,442,id,true,0
-- 62,test2,true,443,name,true,1
alter table test2 rename name to name2;
-- 62,test2,true,442,id,true,0
-- 62,test2,true,443,name,false,1
-- 62,test2,true,444,name2,true,1

-- capitalization change - the metabase_field record of the column is updated
create table test3 (
       id serial primary key,
       name text
);
-- 63,test3,true,446,id,true,0
-- 63,test3,true,445,name,true,1
alter table test3 rename column name to ""Name"";
-- 63,test3,true,446,id,true,0
-- 63,test3,true,445,Name,true,1
```

### Expected behavior

Issue 1 - it should work.
Issue 2 - I would expect the capitalization change to be handled the same way as a column rename.

### Logs

_No response_

### Information about your Metabase installation

1.50.30

### Severity

Rare but severe issue as resolving it may require manual updates to the metadata.

### Additional context

_No response_",zbodi74,2024-10-24 12:50:52+00:00,[],2025-02-04 20:24:33+00:00,,https://github.com/metabase/metabase/issues/49096,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2611359619,issue,closed,completed,[Testing Plan] Admin Onboarding Checklist,"# Testing plan for #48387

## Admin onboarding checklist
We are creating this view for admins only, which makes it easier from the permissions standpoint. However, we should be mindful about the different app settings and the types of instances.


### Dimensions
- User type
    - Admin only
- Instance type
    - Hosted
    - Self-hosted
- License
    - OSS
    - Started
    - Pro
- Environment that Metabase runs in
    - ""Regular""
    - Embedding (full app, sdk)
    - On a subpath
- Settings
    - Whitelabelling
        - Show Metabase links?
        - Custom company name?
    - x-rays
        - enabled
        - disabled
    - `example-dashboard-id`
        - available
        - not available
- Analytics
    - enabled
    - disabled
---

### Actions
```[tasklist]
#### Main navigation sidebar
- [x] Show ""How to use Metabase"" menu item below ""Home"" for admins only
- [x] Show ""How to use Metabase"" menu item only for instances that are <= 30 days old
- [x] **Do not show** ""How to use Metabase"" menu item if whitelabelling is enabled and there is a custom company name
- [x] **Do not show** ""How to use Metabase"" menu item if the app is embedded
- [x] Clicking on ""How to use Metabase"" item leads to `/getting-started` page
- [x] Guard the `/getting-started` route if non-admin navigates directly to it
```

```[tasklist]
#### Analytics (Snowplow)
- [x] Track ""How to use Metabase"" sidebar item click
- [x] Make sure the default opened accordion item on `/getting-started` page load doesn't send Snowplow event
- [x] Track individual checklist item clicks when they open
- [x] Track CTAs (primary or secondary buttons) within an individual checklist item
```

## Checklist page (`/getting-started`)
Has four sections:
  1. Set up your Metabase
  2. Start visualizing your data
  3. Get email updates and alerts
  4. Get the most out of Metabase

```[tasklist]
#### General
- [x] The first accordion item (""Connect to your database"") opens by default on the first page load
- [x] Videos do not auto play
- [x] Videos stop playing when the item is collapsed (manually tested!)
- [x] It should be possible to play videos in full screen
- [x] **Show Metabase links enabled**: links are present in the copy, and they lead to the Metabase documentation
- [x] **Show Metabase links disabled**: just the copy exists; no links whatsoever
- [x] Items scroll into view when expanded
```

## 1. _Set up your Metabase_ section
Has two items:
1. Connect to your database
2. Invite people

```[tasklist]
#### 1.1 *Connect to your database* item
- [x] CTA: ""Add database"" button that leads to `/admin/databases/create`
```

```[tasklist]
#### 1.2 *Invite people* item
- [x] Starter/Pro/Enterprise copy: ""Don't be shy with invites. Metabase Starter plan includes 5 users, and Pro includes 10 users without the need to pay additionally.""
- [x] OSS copy: ""Don't be shy with invites. Metabase makes self-service analytics easy.""
- [x] Primary CTA: ""Invite people"" button that leads to `/admin/people`
- [x] Secondary CTA: ""Set up Single Sign-on"" button that leads to `/admin/settings/authentication`
```

## 2. _Start visualizing your data_ section
Has four items:
1. Create automatic dashboards
2. Make an interactive chart with the query builder
3. Query with SQL
4. Create and share a dashboard

```[tasklist]
#### 2.1 *Create automatic dashboards* item
- [x] **x-rays enabled** copy: ""Hover over a table and click the yellow lightning bolt ⚡️. Metabase will create a bunch of charts based on that data and arrange them on a dashboard.""
- [x] **x-rays disabled** copy: ""You need to enable this feature first."" (maybe link to the general settings?)
- [x] **x-rays enabled** cta: ""Browse data"" button that leads to `/browse/databases`
- [x] **x-rays disabled**: no cta
```

```[tasklist]
#### 2.2 *Make an interactive chart with the query builder* item
- [x] CTA: ""New question"" button that opens a new (notebook) **question** page
```

```[tasklist]
#### 2.3 *Query with SQL* item
- [x] CTA: ""New native query"" button that opens a new (native) **question** page
```

```[tasklist]
#### 2.4 *Create and filter a dashboard* item
- [x] CTA: ""Edit a sample dashboard"" button that opens `/dashboard/{example-dashboard-id}` link
- [x] If the `example-dashboard-id` is not present in settings (_Example_ collection archived, deleted, or the dashboard itself is missing) **do not show the CTA**
```

## 3. _Get email updates and alerts_ section

Has two items:
1. Get dashboard updates by email
2. Get alerts when metrics behave unexpectedly

```[tasklist]
#### 3.1 *Get dashboard updates by email* item
- [x] **self-hosted**: Prompt to set up email and Slack first
- [x] email link goes to `/admin/settings/email/smtp`
- [x] Slack link goes to `/admin/settings/notifications`
- [x] **hosted**: Do not show email/Slack setup links
- [x] CTA: ""Set up subscriptions for a sample dashboard"" button that opens `/dashboard/{example-dashboard-id}` link
- [x] If the `example-dashboard-id` is not present in settings (_Example_ collection archived, deleted, or the dashboard itself is missing) **do not show the CTA**
```

```[tasklist]
#### 3.2 *Get alerts when metrics behave unexpectedly* item
- [x] **self-hosted**: Prompt to set up email and Slack first
- [x] **hosted**: Do not show email/Slack setup links
- [x] CTA: ""Set up alert for a sample question"" button that opens `/question/12` from Example collection[^1]
- [x] If the `example-dashboard-id` is not present in settings, do not display the CTA for the example question
```

## 3. _Get the most out of Metabase_ section
Has two sub-sections:
1. Learn more CTA
2. Help

```[tasklist]
- [x] Do not render ""learn more"" section if Metabase whitelabelling is turned on with ""show Metabase links"" set to false
- [x] ""Click here to continue learning"" link leads to the YouTube playlist
- [x] Show the ""help"" section only when the token is activated (this automatically excludes OSS instances)
```

[^1]: It is unclear what do to if this question doesn't exist, or how to make sure the id is correct.

",nemanjaglumac,2024-10-24 12:01:41+00:00,['nemanjaglumac'],2024-10-30 08:22:51+00:00,2024-10-28 19:58:05+00:00,https://github.com/metabase/metabase/issues/49092,"[('.TestingStrategy/FE', '')]",[],
2611321541,issue,closed,completed,[Epic] Onboarding checklist,,nemanjaglumac,2024-10-24 11:47:22+00:00,['nemanjaglumac'],2024-11-09 12:28:53+00:00,2024-11-09 12:28:52+00:00,https://github.com/metabase/metabase/issues/49090,[],"[{'comment_id': 2466196634, 'issue_id': 2611321541, 'author': 'nemanjaglumac', 'body': ""We're postponing the #48388 so this epic can be closed for now."", 'created_at': datetime.datetime(2024, 11, 9, 12, 28, 52, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-11-09 12:28:52 UTC): We're postponing the #48388 so this epic can be closed for now.

"
2611313452,issue,closed,completed,[Epic] Make it easy to add data,This epic is a part of the larger arc whose goal is to improve the onboarding with better UX (#48163).,nemanjaglumac,2024-10-24 11:43:31+00:00,['nemanjaglumac'],2024-11-26 18:51:37+00:00,2024-11-09 12:26:01+00:00,https://github.com/metabase/metabase/issues/49088,"[('.Epic', 'Feature Implementation or Project')]",[],
2611300703,issue,closed,completed,Time inputs in date picker in native query editor don't always use AM/PM format,"### Describe the bug

![image](https://github.com/user-attachments/assets/47c6bb86-3d3d-4f0a-b4e5-184f15ce93ce)


### To Reproduce

1. Go to Admin > Settings > Localization
2. Change ""Time style"" setting to 24h
3. Exit Admin
4. New > SQL Query
5. Type `select {{date}}`
6. Change parameter type to Date
7. Click to change parameter value
8. Click ""Add a time""

The time inputs use 24h time format.

### Expected behavior

The time inputs should use 12h format.

### Information about your Metabase installation

master, b96f551

### Severity

P2

### Additional context


Original report (https://github.com/metabase/metabase/pull/49046#discussion_r1814486873) was that inputs should not be using AM/PM when ""Time style"" setting is set to 24h (#49077). Apparently this is expected:

> this was a deliberate decision made 1-2 years ago or so. We don’t use these settings for inputs.

See https://github.com/metabase/metabase/pull/49046#issuecomment-2434953696




",kamilmielnik,2024-10-24 11:38:26+00:00,['ranquild'],2025-01-23 18:27:37+00:00,2025-01-23 18:27:34+00:00,https://github.com/metabase/metabase/issues/49086,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2610646276, 'issue_id': 2611300703, 'author': 'ranquild', 'body': 'Fixed when migrated date pickers in dashboards to the new one', 'created_at': datetime.datetime(2025, 1, 23, 18, 27, 34, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2025-01-23 18:27:34 UTC): Fixed when migrated date pickers in dashboards to the new one

"
2611036433,issue,open,,[Mini Epic] Chart Axes / Display Settings,"```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/48929
- [ ] https://github.com/metabase/metabase/pull/48941
- [ ] https://github.com/metabase/metabase/pull/48994
- [ ] https://github.com/metabase/metabase/pull/48837
- [ ] Separate settings from visualization in `ChartSettings`
- [ ] PoC of Chart Settings
``` ",oisincoveney,2024-10-24 09:44:54+00:00,['oisincoveney'],2024-10-24 10:08:39+00:00,,https://github.com/metabase/metabase/issues/49082,[],[],
2611011156,issue,closed,completed,EXT: MetabaseProvider reloads excessively,"See more information on how to reproduce this in [this Notion document](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4#12a69354c901805287d9f5f7d7980dac)

Slack Thread: https://metaboat.slack.com/archives/C07166YL2UU/p1729760797338199",oisincoveney,2024-10-24 09:33:52+00:00,['heypoom'],2024-11-04 15:13:45+00:00,2024-11-04 14:04:20+00:00,https://github.com/metabase/metabase/issues/49081,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2442127730, 'issue_id': 2611011156, 'author': 'heypoom', 'body': ""I couldn't reproduce the exact issue with `iat` being `null` yet; even trying the exact code and payload from the customer still never results in `null`.\n\nOn an unrelated note, I noticed that when I do not provide any `exp` at all when signing the JWT (e.g. providing only `email`, `first_name` and `last_name` in the payload), it did indeed make 3 separate requests to `/sso/metabase` instead of 1. I'll look into this further if this is the same behaviour that causes the MetabaseProvider to reload excessively.\n\n![Image](https://github.com/user-attachments/assets/b92ac6ff-2578-46bf-849c-2226558015ce)"", 'created_at': datetime.datetime(2024, 10, 28, 16, 54, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446192780, 'issue_id': 2611011156, 'author': 'npretto', 'body': ""> I couldn't reproduce the exact issue with `iat` being `null` yet; even trying the exact code and payload from the customer still never results in `null`.\n> \n> On an unrelated note, I noticed that when I do not provide any `exp` at all when signing the JWT (e.g. providing only `email`, `first_name` and `last_name` in the payload), it did indeed make 3 separate requests to `/sso/metabase` instead of 1. I'll look into this further if this is the same behaviour that causes the MetabaseProvider to reload excessively.\n> \n> ![Image](https://github.com/user-attachments/assets/b92ac6ff-2578-46bf-849c-2226558015ce)\n\nThat's because we check the expiration on the FE to see if we should refresh it: https://github.com/metabase/metabase/blob/842f3f358fc99757e6e3ab19ab93c202ee530031/enterprise/frontend/src/embedding-sdk/store/reducer.ts#L48-L49\n\nIf it doesn't have the exp, we fetch the session on each request, I think we should assume that exp is present, handling that case would require too much logic/change from our side.\nI'll add an error to the console if exp is not present to make it easier to debug"", 'created_at': datetime.datetime(2024, 10, 30, 8, 38, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2448053859, 'issue_id': 2611011156, 'author': 'heypoom', 'body': 'I can reproduce `iat` being `null` now. Turns out that the `jsonwebtoken` library automatically adds the issued at (`iat`) key in the payload automatically. In this case, the customer needs to pass `iat` manually using their library.\n\n```ts\n  const token = jwt.sign(\n    {\n      email: \'foo@example.com\',\n      first_name: \'Foo\',\n      last_name: \'Bar\',\n      exp: Math.round(Date.now() / 1000) + 60 * 20,\n    },\n    METABASE_JWT_SHARED_SECRET,\n    {algorithm: \'HS256\', noTimestamp: true}\n  )\n```\n\nThe plot thickens though, as I managed to have the same JWT payload as the customer in this case with only `exp` and not `iat`, and the auth works correctly and only loads once. It is not the missing `iat` that is the issue - that\'s just a red herring, but the React code of the customer that causes the `MetabaseProvider` to reload.\n\n```\n{\n  ""status"": ""ok"",\n  ""id"": ""05e7a0ec-fc38-4255-8533-xxxxxxxxxxx"",\n  ""exp"": 1730314324,\n  ""iat"": null\n}\n```\n\nThe customer\'s [React code sample](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4#12f69354c90180678290e7e6f079c5cb) seems to be fairly innocent though. My guess is that their parent component is re-rendering. Next obvious thing to try is to deliberately re-render the parent and see if the MetabaseProvider and its child component also reloads.', 'created_at': datetime.datetime(2024, 10, 30, 18, 36, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454648894, 'issue_id': 2611011156, 'author': 'heypoom', 'body': 'For the parent re-rendering issue, the root cause stems from the fact the `store` is currently [not a singleton](https://github.com/metabase/metabase/pull/48071/files#r1776753555), and therefore when the parent re-render the reference to store changes, and that likely triggers auth to reload.\n\nPS. in addition, we also make a bunch of dispatch calls on `store` reference changes, which in this case is on every parent re-render:\n\n```tsx\n  useEffect(() => {\n    if (fontFamily) {\n      store.dispatch(setOptions({ font: fontFamily }));\n    }\n  }, [store, fontFamily]);\n\n  useEffect(() => {\n    store.dispatch(setPlugins(pluginsConfig || null));\n  }, [store, pluginsConfig]);\n\n  useEffect(() => {\n    store.dispatch(setEventHandlers(eventHandlers || null));\n  }, [store, eventHandlers]);\n\n  useEffect(() => {\n    store.dispatch(setLoaderComponent(config.loaderComponent ?? null));\n  }, [store, config.loaderComponent]);\n\n  useEffect(() => {\n    store.dispatch(setErrorComponent(config.errorComponent ?? null));\n  }, [store, config.errorComponent]);\n\n  useEffect(() => {\n    store.dispatch(setMetabaseClientUrl(config.metabaseInstanceUrl));\n  }, [store, config.metabaseInstanceUrl]);\n```', 'created_at': datetime.datetime(2024, 11, 4, 12, 56, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454793055, 'issue_id': 2611011156, 'author': 'heypoom', 'body': 'Update: we [received confirmation from our customer](https://metaboat.slack.com/archives/C07166YL2UU/p1730728154724929?thread_ts=1729760797.338199&cid=C07166YL2UU) that this is indeed caused by their parent component re-rendering, so fixing the non-singleton `store` issue should indeed do the trick. Closing this issue - will create a separate issue for auth / component reloading.', 'created_at': datetime.datetime(2024, 11, 4, 14, 0, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454978163, 'issue_id': 2611011156, 'author': 'heypoom', 'body': 'Opened a separate issue in https://github.com/metabase/metabase/issues/49482.', 'created_at': datetime.datetime(2024, 11, 4, 15, 13, 43, tzinfo=datetime.timezone.utc)}]","heypoom (Assginee) on (2024-10-28 16:54:37 UTC): I couldn't reproduce the exact issue with `iat` being `null` yet; even trying the exact code and payload from the customer still never results in `null`.

On an unrelated note, I noticed that when I do not provide any `exp` at all when signing the JWT (e.g. providing only `email`, `first_name` and `last_name` in the payload), it did indeed make 3 separate requests to `/sso/metabase` instead of 1. I'll look into this further if this is the same behaviour that causes the MetabaseProvider to reload excessively.

![Image](https://github.com/user-attachments/assets/b92ac6ff-2578-46bf-849c-2226558015ce)

npretto on (2024-10-30 08:38:56 UTC): That's because we check the expiration on the FE to see if we should refresh it: https://github.com/metabase/metabase/blob/842f3f358fc99757e6e3ab19ab93c202ee530031/enterprise/frontend/src/embedding-sdk/store/reducer.ts#L48-L49

If it doesn't have the exp, we fetch the session on each request, I think we should assume that exp is present, handling that case would require too much logic/change from our side.
I'll add an error to the console if exp is not present to make it easier to debug

heypoom (Assginee) on (2024-10-30 18:36:18 UTC): I can reproduce `iat` being `null` now. Turns out that the `jsonwebtoken` library automatically adds the issued at (`iat`) key in the payload automatically. In this case, the customer needs to pass `iat` manually using their library.

```ts
  const token = jwt.sign(
    {
      email: 'foo@example.com',
      first_name: 'Foo',
      last_name: 'Bar',
      exp: Math.round(Date.now() / 1000) + 60 * 20,
    },
    METABASE_JWT_SHARED_SECRET,
    {algorithm: 'HS256', noTimestamp: true}
  )
```

The plot thickens though, as I managed to have the same JWT payload as the customer in this case with only `exp` and not `iat`, and the auth works correctly and only loads once. It is not the missing `iat` that is the issue - that's just a red herring, but the React code of the customer that causes the `MetabaseProvider` to reload.

```
{
  ""status"": ""ok"",
  ""id"": ""05e7a0ec-fc38-4255-8533-xxxxxxxxxxx"",
  ""exp"": 1730314324,
  ""iat"": null
}
```

The customer's [React code sample](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4#12f69354c90180678290e7e6f079c5cb) seems to be fairly innocent though. My guess is that their parent component is re-rendering. Next obvious thing to try is to deliberately re-render the parent and see if the MetabaseProvider and its child component also reloads.

heypoom (Assginee) on (2024-11-04 12:56:50 UTC): For the parent re-rendering issue, the root cause stems from the fact the `store` is currently [not a singleton](https://github.com/metabase/metabase/pull/48071/files#r1776753555), and therefore when the parent re-render the reference to store changes, and that likely triggers auth to reload.

PS. in addition, we also make a bunch of dispatch calls on `store` reference changes, which in this case is on every parent re-render:

```tsx
  useEffect(() => {
    if (fontFamily) {
      store.dispatch(setOptions({ font: fontFamily }));
    }
  }, [store, fontFamily]);

  useEffect(() => {
    store.dispatch(setPlugins(pluginsConfig || null));
  }, [store, pluginsConfig]);

  useEffect(() => {
    store.dispatch(setEventHandlers(eventHandlers || null));
  }, [store, eventHandlers]);

  useEffect(() => {
    store.dispatch(setLoaderComponent(config.loaderComponent ?? null));
  }, [store, config.loaderComponent]);

  useEffect(() => {
    store.dispatch(setErrorComponent(config.errorComponent ?? null));
  }, [store, config.errorComponent]);

  useEffect(() => {
    store.dispatch(setMetabaseClientUrl(config.metabaseInstanceUrl));
  }, [store, config.metabaseInstanceUrl]);
```

heypoom (Assginee) on (2024-11-04 14:00:21 UTC): Update: we [received confirmation from our customer](https://metaboat.slack.com/archives/C07166YL2UU/p1730728154724929?thread_ts=1729760797.338199&cid=C07166YL2UU) that this is indeed caused by their parent component re-rendering, so fixing the non-singleton `store` issue should indeed do the trick. Closing this issue - will create a separate issue for auth / component reloading.

heypoom (Assginee) on (2024-11-04 15:13:43 UTC): Opened a separate issue in https://github.com/metabase/metabase/issues/49482.

"
2611008036,issue,closed,completed,[Epic] SDK Polishing - v51,"Notion Docs: [Customer Feedback (Internal)](https://www.notion.so/metabase/SDK-Customer-Feedback-Oct-26-12a69354c90180a38713e92076d8161b?pvs=4)

***Bugs***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/47563
- [ ] https://github.com/metabase/metabase/issues/48788
- [ ] https://github.com/metabase/metabase/issues/48789
- [ ] https://github.com/metabase/metabase/issues/48925
- [ ] https://github.com/metabase/metabase/issues/48933
- [ ] https://github.com/metabase/metabase/issues/49307
- [ ] https://github.com/metabase/metabase/issues/49081
- [ ] https://github.com/metabase/metabase/issues/49082
- [ ] https://github.com/metabase/metabase/issues/49345
- [ ] https://github.com/metabase/metabase/issues/49346
- [ ] https://github.com/metabase/metabase/issues/49466
- [ ] https://github.com/metabase/metabase/issues/49581
```

***Feature Request***
```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/49194
- [ ] https://github.com/metabase/metabase/issues/49229
- [ ] https://github.com/metabase/metabase/issues/49232
- [ ] https://github.com/metabase/metabase/issues/49193
- [ ] https://github.com/metabase/metabase/issues/49325
- [ ] Callbacks / Customization for Table Visualization Data
- [ ] Customize Record Detail view
- [ ] https://github.com/metabase/metabase/issues/49560
```
",oisincoveney,2024-10-24 09:32:25+00:00,[],2024-11-08 14:10:49+00:00,2024-11-08 14:10:49+00:00,https://github.com/metabase/metabase/issues/49080,"[('.Frontend', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2610834576,issue,closed,completed,"""Time style"" setting does not affect time inputs in notebook editor","### Describe the bug

![Image](https://github.com/user-attachments/assets/49fcd681-2632-4a8e-8d96-79dda8052964)


### To Reproduce

1. Go to Admin > Settings > Localization
2. Change ""Time style"" setting to 24h
3. Exit Admin
4. New > Question > Orders
5. Add Filter > Created At > Specific dates > Add time (set whatever time)

Time inputs use AM/PM.

### Expected behavior

Time inputs use 24h time format (like in SQL editor)

### Information about your Metabase installation

master, b96f551

### Severity

P2
",kamilmielnik,2024-10-24 08:21:05+00:00,[],2024-10-24 11:29:21+00:00,2024-10-24 11:29:20+00:00,https://github.com/metabase/metabase/issues/49077,[],"[{'comment_id': 2435019748, 'issue_id': 2610834576, 'author': 'kamilmielnik', 'body': '> this was a deliberate decision made 1-2 years ago or so. We don’t use these settings for inputs.\n\nSee https://github.com/metabase/metabase/pull/49046#issuecomment-2434953696\n\n---- \n\nClosing.', 'created_at': datetime.datetime(2024, 10, 24, 11, 29, 20, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-24 11:29:20 UTC): See https://github.com/metabase/metabase/pull/49046#issuecomment-2434953696

---- 

Closing.

"
2610824150,issue,closed,not_planned,"""Time style"" setting does not affect dates formatted by QP","### Describe the bug

![Image](https://github.com/user-attachments/assets/fd3d1d68-3406-49ef-a4ff-a31ea457d7f5)


### To Reproduce

1. Go to Admin > Settings > Localization
2. Change ""Time style"" setting to 24h
3. Exit Admin
4. New > Question > Orders
5. Add Filter > Created At > Specific dates > Add time (set whatever time) > Add filter

Display name of the created filter uses AM/PM

### Expected behavior

Display name of the created filter uses 24h time format


### Information about your Metabase installation

master, b96f551

### Severity

P2
",kamilmielnik,2024-10-24 08:16:17+00:00,[],2025-01-17 07:07:53+00:00,2025-01-16 20:32:58+00:00,https://github.com/metabase/metabase/issues/49076,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2596836723, 'issue_id': 2610824150, 'author': 'ranquild', 'body': ""My understanding is that it shouldn't. This has been brought multiple times. The setting only affects query results. For now closing."", 'created_at': datetime.datetime(2025, 1, 16, 20, 32, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597573830, 'issue_id': 2610824150, 'author': 'kamilmielnik', 'body': '> My understanding is that it shouldn\'t. This has been brought multiple times. The setting only affects query results. For now closing.\n\nWe should at least explain in the docs what does the ""time style"" settings affect.\n[The way it\'s written now](https://www.metabase.com/docs/latest/configuring-metabase/localization#localization-options)  is as if it  applied everywhere, which is not true:\n\n> Localization options allow you to set global default display formats for dates, times, numbers, and currencies.\n\ncc: @jeff-bruemmer', 'created_at': datetime.datetime(2025, 1, 17, 7, 7, 52, tzinfo=datetime.timezone.utc)}]","ranquild on (2025-01-16 20:32:54 UTC): My understanding is that it shouldn't. This has been brought multiple times. The setting only affects query results. For now closing.

kamilmielnik (Issue Creator) on (2025-01-17 07:07:52 UTC): We should at least explain in the docs what does the ""time style"" settings affect.
[The way it's written now](https://www.metabase.com/docs/latest/configuring-metabase/localization#localization-options)  is as if it  applied everywhere, which is not true:


cc: @jeff-bruemmer

"
2610798238,issue,closed,completed,"""Add filter"" button is disabled after clicking ""add a time""","### Describe the bug

![Image](https://github.com/user-attachments/assets/8d9e0bf3-2375-4bad-8124-c62d11ee0905)


### To Reproduce

1. New > SQL query
2. Type `select {{date}}`
3. Change variable type to Date
4. Click the filter to set the value
5. Notice ""Add filter"" button is enabled
6. Click ""Add a time""

""Add filter"" button is disabled

### Expected behavior

""Add filter"" button is enabled

### Information about your Metabase installation

master, b96f55194c2670c1c8e73d75ab0645c6864bd940

### Severity

P2",kamilmielnik,2024-10-24 08:04:30+00:00,['ranquild'],2024-10-28 14:58:04+00:00,2024-10-28 13:51:18+00:00,https://github.com/metabase/metabase/issues/49075,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2610445908,issue,closed,not_planned,URL manipulation allows unauthorised data access,"### Describe the bug

Hello Metabase team,

I am currently using the free version of Metabase for learning and testing purposes. I've set up two dashboards for two different users based on hardcoding state names into the filters. The expectation is that users should only be able to view data for their respective states.

For example, if a user from Karnataka logs in, they should only see data related to Karnataka, and similarly for another user from a different state.

### The Problem:

When a user from Karnataka logs in, they are initially presented with the correct data. However, if they manually modify the URL and change the query parameter from select_state=Karnataka to another state like select_state=Kerala, they can then access data for Kerala, which should not be permitted.

### For example:

**Original URL (working as expected):**
`/dashboard/4-state-report-karnataka?state_param=Karnataka`
[Image](https://discourse.metabase.com/uploads/default/original/3X/3/f/3f72c903836f1a2e84a791047ba56fb51fd41f92.png)

**Modified URL (security issue):**
`/dashboard/4-state-report-karnataka?state_param=Kerala`
[Image](https://discourse.metabase.com/uploads/default/original/3X/5/e/5ed8e8aee1231aa9894c0c308ca69d6dd42e9a41.png)

This unauthorized access exposes data from other states, which breaks the intended state-specific restrictions. My expectation was that each user would be restricted to their own state data, regardless of any changes they make to the URL.

I would appreciate your help in fixing this issue or guiding me towards the correct way to implement state-specific access restrictions that cannot be overridden by URL changes.

Thank you for your attention to this matter!

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error
5. https://discourse.metabase.com/uploads/default/original/3X/3/f/3f72c903836f1a2e84a791047ba56fb51fd41f92.png


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.4.16-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-13"",
      ""tag"": ""v0.50.20"",
      ""hash"": ""df82d58""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

### Severity

High - This will allow user to access unauthorised data 

### Additional context

_No response_",Vivek-M-08,2024-10-24 04:52:24+00:00,[],2024-10-26 20:48:16+00:00,2024-10-26 20:48:15+00:00,https://github.com/metabase/metabase/issues/49070,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2439732161, 'issue_id': 2610445908, 'author': 'paoliniluis', 'body': 'As I mentioned in your stackoverflow post, please read the docs before creating an issue, this is not a security issue and the product has a feature to make filters to be locked to user parameters', 'created_at': datetime.datetime(2024, 10, 26, 20, 48, 15, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-26 20:48:15 UTC): As I mentioned in your stackoverflow post, please read the docs before creating an issue, this is not a security issue and the product has a feature to make filters to be locked to user parameters

"
2609917060,issue,open,,Visually group cards on a dashboard,"**Is your feature request related to a problem? Please describe.**
In a dashboard with multiple charts, want to be able to visually group them together (such as with a border around the cards or a the same background color behind the cards in the same group). Gives a little more context to the user on the data presented.

**Describe the solution you'd like**
something like this ![Image](https://github.com/user-attachments/assets/e8f95a6a-4e63-4f16-ac4a-a6e1629f1edc)

**Describe alternatives you've considered**
Leaving space on the dashboard between the different charts, have users infer the groups.  

**How important is this feature to you?**
would be nice, visually 

",jessicaul,2024-10-23 21:51:52+00:00,[],2025-02-04 20:30:43+00:00,,https://github.com/metabase/metabase/issues/49065,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2609905794,issue,open,,Call version-info.json when a user visits the admin > settings > update page,"Right now, the backend calls version-info.json twice a day on a schedule and that can potentially lead to stale upgrade info on the `admin/settings/updates` screen

We should make a call to version-info.json file every time a user visits the update page and we should pass in the appropriate url parameters (current-version and channel) as well.",perivamsi,2024-10-23 21:42:16+00:00,[],2025-02-04 20:30:22+00:00,,https://github.com/metabase/metabase/issues/49063,"[('Type:New Feature', ''), ('.Building & Releasing', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2433521068, 'issue_id': 2609905794, 'author': 'perivamsi', 'body': 'More context in [this Notion doc](https://www.notion.so/metabase/In-product-release-notifications-11a69354c901806b8386f9995cc2a4d4?pvs=4#11c69354c90180558da9cbcfdaa0381c)', 'created_at': datetime.datetime(2024, 10, 23, 21, 43, 24, tzinfo=datetime.timezone.utc)}]","perivamsi (Issue Creator) on (2024-10-23 21:43:24 UTC): More context in [this Notion doc](https://www.notion.so/metabase/In-product-release-notifications-11a69354c901806b8386f9995cc2a4d4?pvs=4#11c69354c90180558da9cbcfdaa0381c)

"
2609846200,issue,closed,completed,"Pie charts percentages computed incorrectly for ""Other"" slice","**Context**

Incorrect Other slice label:
![Image](https://github.com/user-attachments/assets/a5d486b9-1007-4f3d-86b6-b5806afe079b)

Incorrect percentages in the tooltip:
![Image](https://github.com/user-attachments/assets/97d7c583-8621-4bd8-a44c-e2482695c359)


",alxnddr,2024-10-23 21:05:43+00:00,['alxnddr'],2024-10-25 22:44:53+00:00,2024-10-25 22:01:10+00:00,https://github.com/metabase/metabase/issues/49061,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2609812500,issue,closed,completed,Blinking on homepage while syncing databases,"### Describe the bug

If you have a database that is syncing, we invalidate the database cache every 2 seconds. This causes the page to flicker, which is annoying.
Context in [slack thread ](https://metaboat.slack.com/archives/C01LQQ2UW03/p1729715272956669)

### To Reproduce

1. Sync a fairly large database
2. Go to home page while it's syncing
3. See the homepage blinking


### Expected behavior

It should not blink. 

### Logs

_No response_

### Information about your Metabase installation

94081aeadd00fa188e6836d907356edf2fce0357

### Severity

p2

### Additional context

_No response_",npfitz,2024-10-23 20:48:23+00:00,['npfitz'],2024-10-24 19:54:10+00:00,2024-10-24 19:54:09+00:00,https://github.com/metabase/metabase/issues/49059,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug')]",[],
2609788782,issue,open,,Bring combo line/bars to row charts,"**Describe the solution you'd like**
We currently have a horizontal combo bar/line chart. Would love for there to be a vertical one. 
Like a row chart with a line 
![Image](https://github.com/user-attachments/assets/ba273186-3808-42c6-87f5-df44ac883ae3)



**Describe alternatives you've considered**
Use the horizontal combo chart 

**How important is this feature to you?**
Nice to have
",jessicaul,2024-10-23 20:38:41+00:00,[],2025-02-04 20:31:18+00:00,,https://github.com/metabase/metabase/issues/49057,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2433578318, 'issue_id': 2609788782, 'author': 'lzrdbrain', 'body': ""I would love to have this chart! I used this chart a bunch in another tool because it allows me to show a category broken out by both a count and a ratio ( For example, total website visits and conversion rate by marketing source).  I don't like the Horizontal version as much because I often think of the x axis being a time series on Horizontal charts, and I am not always doing a time series with a combo chart."", 'created_at': datetime.datetime(2024, 10, 23, 22, 22, 13, tzinfo=datetime.timezone.utc)}]","lzrdbrain on (2024-10-23 22:22:13 UTC): I would love to have this chart! I used this chart a bunch in another tool because it allows me to show a category broken out by both a count and a ratio ( For example, total website visits and conversion rate by marketing source).  I don't like the Horizontal version as much because I often think of the x axis being a time series on Horizontal charts, and I am not always doing a time series with a combo chart.

"
2609643093,issue,open,,Signal to admins that a linked filter has cached values,"**Is your feature request related to a problem? Please describe.**
We're the only ones that know how linked filters work so debugging might be complex. E.g. a customer was seeing all the values on a linked filter, since the values were pulled BEFORE they connected 2 tables together and after they did the linkage of the tables the linked filters were getting values from the cache

We should signal in some way to the admins that filters are getting cached values so they can understand how the linked filters are working so they can clean the cache manually

**Describe the solution you'd like**
- Give admins a visual indicator that a linked filter is getting values from the cache
- clean cached field values when there's a change in the table metadata on a table that has a filter in a dashboard

**Describe alternatives you've considered**
None

**How important is this feature to you?**
It could have saved me a debugging session looking at the DW to see how stuff is working (or not)

**Additional context**
NA
",paoliniluis,2024-10-23 19:19:50+00:00,[],2025-02-04 20:30:54+00:00,,https://github.com/metabase/metabase/issues/49055,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2609447957,issue,closed,completed,Native query drill should be disabled for queries with variable template tags,"### Describe the bug

When there is a native query with variable template tags, it should not be possible to use drills. Doing so leads to query errors.

### To Reproduce

- New -> SQL query -> `SELECT * FROM PRODUCTS WHERE CATEGORY = {{category}}`
- Enter some category (e.g. `Gadget`) and run the query -> Save
- Click on one of the column headers and use drills (e.g. sort, ...)
- See the query error

![Image](https://github.com/user-attachments/assets/be4c6ce8-c08b-4d10-8f2e-4ed8cf4ab8f8)
![Image](https://github.com/user-attachments/assets/967f0501-15b8-456a-abb1-5139d8e82bb4)



### Expected behavior

Drills should be disabled for native queries with variable template tags. `card` and `snippet` tags should still be allowed.

### Logs

_No response_

### Information about your Metabase installation

`434703431f9c54708819420fe725d4446546653f`, pre-51 master.

### Severity

P2

### Additional context

_No response_",ranquild,2024-10-23 18:13:01+00:00,['appleby'],2025-01-24 17:40:48+00:00,2025-01-24 16:31:08+00:00,https://github.com/metabase/metabase/issues/49051,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2605757090, 'issue_id': 2609447957, 'author': 'appleby', 'body': 'Upgrading to P1 per https://metaboat.slack.com/archives/C0645JP1W81/p1737493192537889?thread_ts=1737493000.610949&cid=C0645JP1W81', 'created_at': datetime.datetime(2025, 1, 21, 21, 16, 59, tzinfo=datetime.timezone.utc)}]","appleby (Assginee) on (2025-01-21 21:16:59 UTC): Upgrading to P1 per https://metaboat.slack.com/archives/C0645JP1W81/p1737493192537889?thread_ts=1737493000.610949&cid=C0645JP1W81

"
2608612990,issue,closed,completed,Tab key does not change focus in expression editor,"### Describe the bug

![Image](https://github.com/user-attachments/assets/17534b9d-d773-4865-be77-ef3706fcc0bb)


### To Reproduce

1. New > Question > Orders
2. Add new custom column
3. Type `[Tot` in the expression input
4. Hit Enter to apply first suggestion
5. Hit Tab key to focus the name input

Nothing happens


### Expected behavior

Focus moves to the next input


### Information about your Metabase installation

master, bdc9c5a943651de202a1bc915058cd2126be2321

### Severity

P2 (annoying)
",kamilmielnik,2024-10-23 13:28:42+00:00,['kamilmielnik'],2024-10-31 15:01:23+00:00,2024-10-31 12:59:27+00:00,https://github.com/metabase/metabase/issues/49036,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2608496200,issue,closed,completed,Convert this Question to SQL doesn't convert SQL properly for Databricks,"### Describe the bug

The Convert this Question to SQL leaves spaces with table and column names that fail to run if you don't get rid of them 

![Image](https://github.com/user-attachments/assets/22e287e8-697d-4666-965a-573439a963ff)


### To Reproduce

1. Go to New  -> Question -> Databricks Table -> then convert this question to SQL

![Image](https://github.com/user-attachments/assets/dc106ffd-2e95-41ff-bd75-854cea677276)

The new SQL query fails with [TABLE_OR_VIEW_NOT_FOUND] The table or view ` test_1 `.` sample_table ` cannot be found


### Expected behavior

There are no spaces added with column and table names

### Logs

[TABLE_OR_VIEW_NOT_FOUND] The table or view ` test_1 `.` sample_table ` cannot be found

### Information about your Metabase installation

v1.51.0.9-beta


### Severity

Gets annoying if you want to convert to SQL

### Additional context

_No response_",Tony-metabase,2024-10-23 12:51:26+00:00,[],2024-10-25 10:03:14+00:00,2024-10-24 20:56:20+00:00,https://github.com/metabase/metabase/issues/49032,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Querying', ''), ('Database/Databricks', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2608408292,issue,closed,completed,Pie chart viz crashes when rendered in a small dashcard,"### Describe the bug

![Image](https://github.com/user-attachments/assets/6f99270d-d7ec-46bf-8bca-579f9917f5e4)

![Image](https://github.com/user-attachments/assets/a48908ae-9172-4991-a724-81742ae3c908)


### To Reproduce

1. Go to https://stats.metabase.com/dashboard/1887
2. Look at ""Open Bugs by Priority"" chart
3. Set viewport width to: 1477 (or smaller)

Chart crashes. There's an uncaught error in JS console: `Invalid horizontal label`.

### Information about your Metabase installation

master, e3158b0

### Severity

P1",kamilmielnik,2024-10-23 12:23:32+00:00,['alxnddr'],2024-10-23 17:48:53+00:00,2024-10-23 16:44:58+00:00,https://github.com/metabase/metabase/issues/49031,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2608011549,issue,closed,completed,"Another ""Sorry, you don’t have permission to see that.""","**Describe the bug**
Moved database by simply copying to another host with the same docker version, but getting 403 and ""Sorry, you don’t have permission to see that."" when trying to edit any query / model / dashboard. But titles of dashboards, collections and settings and are editable.

**Logs**
```
There is nothing strange in logs, it just shows POST request was ok:
2024-10-23 09:52:01,282 DEBUG middleware.log :: POST /api/dashboard/3/dashcard/96/card/118/query 202 [ASYNC: completed] 1.3 s (16 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (19 idle, 0 queued) (130 total active threads) Queries in flight: 3 (0 queued); mysql DB 3 connections: 3/14 (0 threads blocked) {:metabase-user-id 1}
2024-10-23 09:52:02,362 INFO middleware.cache :: Query 64120d30 took 1.8 s to run; minimum for cache eligibility is 1000.0 ms; eligible
2024-10-23 09:52:02,363 INFO middleware.cache :: Caching results for next time for query with hash ""64120d30"". 💾
2024-10-23 09:52:02,386 DEBUG middleware.log :: POST /api/dashboard/3/dashcard/82/card/96/query 202 [ASYNC: completed] 2.4 s (21 DB calls) App DB connections: 0/15 Jetty threads: 6/50 (19 idle, 0 queued) (131 total active threads) Queries in flight: 3 (0 queued); mysql DB 3 connections: 4/14 (0 threads blocked) {:metabase-user-id 1}
2024-10-23 09:52:02,521 INFO middleware.cache :: Query f8a5c3b1 took 2.0 s to run; minimum for cache eligibility is 1000.0 ms; eligible
2024-10-23 09:52:02,521 INFO middleware.cache :: Caching results for next time for query with hash ""f8a5c3b1"". 💾
...
```


**To Reproduce**
Steps to reproduce the behavior:
1. Copy whole /metabase.db folder to different container
2. Try to edit any saved query or dashboard
3. See error

**Screenshots**
No need, only ""Sorry, you don’t have permission to see that."" in the center of screen with keys icon.

**Severity**
Every time upon save

**Additional context**
Tried everything with permissions, CORS and other recommendations in similar Metabase issues over Google. 

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""ru-RU"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-150-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-25"",
      ""tag"": ""v0.50.16"",
      ""hash"": ""28de9df""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Baku""
    }
  }
}
```",RK-BAKU,2024-10-23 10:00:58+00:00,[],2024-10-23 10:08:53+00:00,2024-10-23 10:08:51+00:00,https://github.com/metabase/metabase/issues/49026,[],"[{'comment_id': 2431605434, 'issue_id': 2608011549, 'author': 'RK-BAKU', 'body': 'The issue was with Cloudflare. Just found the post below and it helped to solve. Thanks!\nhttps://www.metabase.com/docs/latest/troubleshooting-guide/proxies.html', 'created_at': datetime.datetime(2024, 10, 23, 10, 8, 51, tzinfo=datetime.timezone.utc)}]","RK-BAKU (Issue Creator) on (2024-10-23 10:08:51 UTC): The issue was with Cloudflare. Just found the post below and it helped to solve. Thanks!
https://www.metabase.com/docs/latest/troubleshooting-guide/proxies.html

"
2607838484,issue,closed,not_planned,Update nekohtml to 2.70.0 or higher,"It's not really a bug or a feature so I didn't know how to tag it, but dependency scanning reports Metabase images because they contain a dependency on a pretty old version of nekohtml which have https://nvd.nist.gov/vuln/detail/CVE-2022-29546
Would it be possible to bump it to a version where it is fixed? Like 2.70.0 of higher.
Not sure which dependency actually brings it into the runtime...
More info here https://github.com/HtmlUnit/htmlunit-neko/tree/2.70.0?tab=readme-ov-file#latest-release-version-2700--january-22-2023",v3rm0n,2024-10-23 09:05:58+00:00,[],2024-10-23 12:44:18+00:00,2024-10-23 12:44:17+00:00,https://github.com/metabase/metabase/issues/49025,[],"[{'comment_id': 2432033469, 'issue_id': 2607838484, 'author': 'paoliniluis', 'body': 'This is being tackled separately', 'created_at': datetime.datetime(2024, 10, 23, 12, 44, 17, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-23 12:44:17 UTC): This is being tackled separately

"
2607586891,issue,closed,completed,FE - e2e - Update tests after `Lib.ensureFilterStage` changes,"Depends on #48339

TODO:
- [x] unskip repro for #19744",kamilmielnik,2024-10-23 07:35:16+00:00,['kamilmielnik'],2024-10-29 07:27:15+00:00,2024-10-29 07:27:14+00:00,https://github.com/metabase/metabase/issues/49022,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2443446141, 'issue_id': 2607586891, 'author': 'kamilmielnik', 'body': 'Closed by #49222', 'created_at': datetime.datetime(2024, 10, 29, 7, 27, 14, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-29 07:27:14 UTC): Closed by #49222

"
2607532712,issue,closed,not_planned,Subscription removes google group email ID after some time,"### Describe the bug

We can use Google group email ID (analytics@) in our case to send dashboard to the whole team. It works for a day or so and automatically gets removed from the recipients list.

Also, the dashboard snapshot doesn't refresh with the latest data before sending an emailer.

### To Reproduce

1. Go to any dashboard with a subscription, add an email group as a recipient 
2. check in a day or two
3. expectation - email group is removed from the recipients' list

### Expected behavior

email group should work and the dashboard should refresh before sending the emailer

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""databricks-sql"",
      ""redshift"",
      ""postgres"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-13"",
      ""tag"": ""v0.50.4"",
      ""hash"": ""15343a3""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}

### Severity

Medium

### Additional context

have to add the email group again every other day to share updated dashboard",gajanand-jm,2024-10-23 07:11:50+00:00,[],2024-10-23 16:34:10+00:00,2024-10-23 12:58:36+00:00,https://github.com/metabase/metabase/issues/49021,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2432070880, 'issue_id': 2607532712, 'author': 'paoliniluis', 'body': 'Hi, how do you know that this is not one of the users in the subscription clicking on the unsubscribe button?', 'created_at': datetime.datetime(2024, 10, 23, 12, 58, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432809859, 'issue_id': 2607532712, 'author': 'gajanand-jm', 'body': ""I know that for certain because I'm the owner/editor of this dashboard and analytics@ isn't a user but email group"", 'created_at': datetime.datetime(2024, 10, 23, 16, 34, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-23 12:58:36 UTC): Hi, how do you know that this is not one of the users in the subscription clicking on the unsubscribe button?

gajanand-jm (Issue Creator) on (2024-10-23 16:34:09 UTC): I know that for certain because I'm the owner/editor of this dashboard and analytics@ isn't a user but email group

"
2606745414,issue,open,,Support parameters in iframes for dashbboards,"**Is your feature request related to a problem? Please describe.**
The iframe support in dashboards (v51 feature) lacks support for parameters. This means users who wish to display varying iframe content must create a new dashboard for each unique iframe, which is redundant. 

**Describe the solution you'd like**
A way to parameterize iframes inside of the dashboard. This would allow users to re-use a single dashboard while updating the iframe content based on parameters.

**Describe alternatives you've considered**
Manually create separate dashboards for each variation of the iframe content, which is difficult to maintain. 

**How important is this feature to you?**
Requested by a potential customer.
",dahyeik,2024-10-22 23:30:58+00:00,[],2025-02-04 20:30:56+00:00,,https://github.com/metabase/metabase/issues/49017,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2606539183,issue,closed,completed,Don't hardcode driver names,,snoe,2024-10-22 21:18:56+00:00,[],2024-11-04 23:43:44+00:00,2024-11-04 22:42:52+00:00,https://github.com/metabase/metabase/issues/49014,[],[],
2606474571,issue,closed,completed,"""No results"" image in email notification still uses the old filing cabinet image","### Describe the bug

Dashboard notifications sent as email still get the old ""no results"" image with the empty filing cabinet instead of the sailboat.

Email:
![Image](https://github.com/user-attachments/assets/afd10694-ee8f-4ff6-a139-5d340a3513e7)

Dashboard in browser:
![Image](https://github.com/user-attachments/assets/c59e5d18-86b1-4791-a0b4-e5d4f283b9e5)




### To Reproduce

1. Create a question with no results.
2. Add it to a dashboard.
3. Email that dashboard.
4. View in email client, note image used for no results.


### Expected behavior

Same image used in both views.

### Logs

N/A

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-10"",
      ""tag"": ""v0.50.29"",
      ""hash"": ""1f643ea""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Auckland""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  }
}

### Severity

Very minor

### Additional context

_No response_",notrom,2024-10-22 20:52:10+00:00,[],2024-11-26 23:04:44+00:00,2024-11-26 23:04:44+00:00,https://github.com/metabase/metabase/issues/49012,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2606468415,issue,closed,completed,Faster sync on MySQL,,snoe,2024-10-22 20:48:45+00:00,[],2024-11-05 18:01:50+00:00,2024-11-05 16:26:02+00:00,https://github.com/metabase/metabase/issues/49010,[],[],
2606322246,issue,closed,completed,Log Action runs in audit/usage analytics,"**Is your feature request related to a problem? Please describe.**
Currently, action runs are not being logged. Difficult to tell when or who executed an action. 

**Describe the solution you'd like**
I would like actions runs to be logged in the `Query Log` table in the `Usage Analytics` collection. There's already an `Action Qualified ID` field in that table. 

**How important is this feature to you?**
Important for visibility and audit purposes. 
",jessicaul,2024-10-22 19:40:20+00:00,[],2024-12-30 15:24:06+00:00,2024-12-30 15:24:04+00:00,https://github.com/metabase/metabase/issues/49008,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('Querying/Actions', '')]","[{'comment_id': 2432676830, 'issue_id': 2606322246, 'author': 'andyhernandez', 'body': 'An additional nicety to the Query Log would be the ability for some sort of variable we could use to actually log the user id/name as part of the action.\n\n```\nINSERT INTO table_name (\n  column1, \n  column2, \n  created_by\n)\nVALUES (\n  value1, \n  value2, \n  {{ MB_current_user_id }}\n);\n```\n^ some sort of global variable for the logged in user would be useful in many many contexts.  Personalized dashboards, action logging, etc.', 'created_at': datetime.datetime(2024, 10, 23, 15, 42, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565619266, 'issue_id': 2606322246, 'author': 'brunobergher', 'body': 'Duplicate of #33659', 'created_at': datetime.datetime(2024, 12, 30, 15, 24, 4, tzinfo=datetime.timezone.utc)}]","andyhernandez on (2024-10-23 15:42:22 UTC): An additional nicety to the Query Log would be the ability for some sort of variable we could use to actually log the user id/name as part of the action.

```
INSERT INTO table_name (
  column1, 
  column2, 
  created_by
)
VALUES (
  value1, 
  value2, 
  {{ MB_current_user_id }}
);
```
^ some sort of global variable for the logged in user would be useful in many many contexts.  Personalized dashboards, action logging, etc.

brunobergher on (2024-12-30 15:24:04 UTC): Duplicate of #33659

"
2606046891,issue,open,,OIDC support,"It would be awesome to let login from generic OIDC.

We use Github to login on all out applications exept metabase. it would be awesome to can connect throught OIDC.",cmiranda98,2024-10-22 17:22:12+00:00,[],2025-02-04 20:30:30+00:00,,https://github.com/metabase/metabase/issues/49002,"[('Type:New Feature', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT')]","[{'comment_id': 2509085105, 'issue_id': 2606046891, 'author': 'khoramism', 'body': 'This would be great.', 'created_at': datetime.datetime(2024, 11, 30, 17, 40, 50, tzinfo=datetime.timezone.utc)}]","khoramism on (2024-11-30 17:40:50 UTC): This would be great.

"
2605745542,issue,open,,Enable Per-Query Warehouse Selection for Snowflake Connections,"**Is your feature request related to a problem? Please describe.**
Yes. Currently, when using Metabase with Snowflake, we are restricted to a single, fixed warehouse specified in the database connection settings. This limitation:

- Prevents selecting different warehouses based on the computational needs of individual queries.
- Hinders our ability to optimize for performance and cost.
- Disallows adding multiple statements: We can’t add e.g  ```USE WAREHOUSE REPORTING_S```; at the top of a Metabase question followed by the SQL statement because Metabase expects only one statement.
- Forces us to use a workaround of creating multiple Database Connections for each warehouse to bypass this limitation, leading to inefficiencies such as:
  - Reconfiguring field filters and other settings for each duplicate source.
  - Increased maintenance overhead, making it harder to manage and update configurations.

**Describe the solution you'd like**
It would be helpful if Metabase allowed users to:

- Select from a list of predefined Snowflake warehouses directly within the question interface.
- Retrieve the list of accessible warehouses for the user.
- Choose the appropriate warehouse from a dropdown menu populated with warehouses defined in the database connection settings when creating or running a query.
- Default to the primary warehouse if no selection is made.

**How important is this feature to you?**
This feature is important as it would greatly enhance our ability to manage costs and improve query performance by allowing us to match computational resources to the specific needs of each query.


",JGustavo0,2024-10-22 15:09:14+00:00,[],2025-02-04 20:30:39+00:00,,https://github.com/metabase/metabase/issues/48992,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', ''), ('Database/Snowflake', ''), ('Administration/Databases', '')]",[],
2604830019,issue,open,,"Date picker: Incorrect translation of ""This month"" (and more)","### Describe the bug

The Date picker filter (type ""All"") that can be added as a filter to a dashboard contains incorrect translations. Half of the ""sentence"" is translated. For example, if a user picks ""Current"" and then ""Month"" the button says ""This Month"" in english (correct). But in other languages, for example Swedish, the translation will be ""This Månad"" (incorrect). It goes for other units than month as well.

### To Reproduce

1. Go to a dashboard and add a filter of type ""Date picker"". Choose type ""All"".
2. Connect the filter to a question so it will become visible during viewing.
3. Verify that the language for your current account is something else than English, for example Swedish (as in screenshot).
4. Open date picker filter and pick current month and close the filter.
5. The issue should now be visible since the filter button says ""This Månad"" (a mix of both english and swedish).
![Image](https://github.com/user-attachments/assets/d1f4c31c-ce36-4aaf-bd75-010d4dc87252)




### Expected behavior

Expect the button label to be translated according to PO-project. For the Swedish version, that would be ""Denna månad"".

PO:
![Image](https://github.com/user-attachments/assets/a0614e96-3886-451b-93b2-ce2edc1d6845)


### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-04"",
      ""src_hash"": ""41a2064fd0b59020cb1f1056b8ced0968e98fc64"",
      ""tag"": ""v0.1.35-SNAPSHOT"",
      ""hash"": ""321103f""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2"",
    ""java.vendor"": ""Homebrew"",
    ""java.vendor.url"": ""https://github.com/Homebrew/homebrew-core/issues"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.6.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Stockholm""
  }
}

### Severity

Annoying

### Additional context

I have tried debugging why this is but my code base knowledge (and time) is limited so was unable to find the exact reason. I reached the conclusion that it boils down to [this line](https://github.com/metabase/metabase/blob/d4c49a85af4123ae1c58a7ef33861b93c2bf8021/frontend/src/metabase-lib/temporal_bucket.ts#L62) (which calls `describe_temporal_interval()` from `cljs/metabase.lib.js`). ",antonhedstrom,2024-10-22 09:24:50+00:00,[],2025-02-04 20:25:00+00:00,,https://github.com/metabase/metabase/issues/48978,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/i18n', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2429291567, 'issue_id': 2604830019, 'author': 'ixipixi', 'body': 'https://github.com/metabase/metabase/issues/13188', 'created_at': datetime.datetime(2024, 10, 22, 13, 28, 45, tzinfo=datetime.timezone.utc)}]","ixipixi on (2024-10-22 13:28:45 UTC): https://github.com/metabase/metabase/issues/13188

"
2604537193,issue,closed,completed,"Automate npm dist-tags. `release-x.51.x` -> `51-stable`,  `master` -> `canary`","[product doc](https://www.notion.so/metabase/Improve-npm-release-process-11e69354c901808687bcfb8368fd0327)

When publishing from the release branch `release-x.51.x`
- Publish the package with `51-stable` dist tags
- Add an additional `latest` tag

When publishing from `master` branch
- Publish the package with `canary` dist tags",WiNloSt,2024-10-22 07:32:13+00:00,['WiNloSt'],2024-10-24 09:16:21+00:00,2024-10-24 09:13:34+00:00,https://github.com/metabase/metabase/issues/48974,[],[],
2604531425,issue,closed,completed,Newely created database not visible in the UI,"### Describe the bug

When I create a new Database in the UI it works as normaly, but when I save it the new database is not in any list where the database are listed.
The only way to edit the database connection is by changing the ID in the URL.

I have not seen any error in the logs and the connection to the database is also working as the database is findable in the ""search"" field.

Im using the version 0.50.30 (docker image) with postgres 12.1, in production mode.

### To Reproduce

I was not able to reproduce the bug.

### Expected behavior

That the database I just created is listed on the Main page and I can change the settings of the database with the ui.

### Logs

[logs.txt](https://github.com/user-attachments/files/17471927/logs.txt)


### Information about your Metabase installation


```json
{
  ""browser-info"": {
    ""language"": ""de"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""oracle"",
      ""ibminformix"",
      ""sqlserver"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-15"",
      ""tag"": ""v0.50.30"",
      ""hash"": ""a49cb77""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.1 (Debian 12.1-1.pgdg100+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""3.10.0-1160.119.1.el7.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Berlin""
  }
}
```

### Severity

Low-Medium

### Additional context

_No response_",Vetrixs,2024-10-22 07:29:19+00:00,[],2025-01-16 17:25:19+00:00,2025-01-16 17:25:17+00:00,https://github.com/metabase/metabase/issues/48973,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2596302151, 'issue_id': 2604531425, 'author': 'luizarakaki', 'body': ""Closing this while we don't have better reproduction steps"", 'created_at': datetime.datetime(2025, 1, 16, 17, 25, 17, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-16 17:25:17 UTC): Closing this while we don't have better reproduction steps

"
2603552790,issue,closed,completed,Add verifications to Dashboards,"- [x] Add and Remove verification from dashboards
- [x] Add verification status to dashboard headers
- [x] Add verification status to dashboards in collections page
- [x] Add verification status to dashboards in recents views (command palette)
- [x] Add verification status to dashboards in search results (command palette)",npfitz,2024-10-21 20:06:56+00:00,"['escherize', 'npfitz']",2024-11-26 18:52:01+00:00,2024-11-02 01:39:24+00:00,https://github.com/metabase/metabase/issues/48954,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2603443462,issue,open,,Custom column functions for spatial analysis,"**Is your feature request related to a problem? Please describe.**
Want more support for point fields for spatial analysis. 

**Describe the solution you'd like**
When adding a custom column, would want additional functions such as:
  - finding the distance between two point fields 
  - getting the total surface area of a spatial polygon
  - (from the customer)

> Having a table A with a point field (ie. Location) and another table B with a polygon field (ie. Area), I would love to be able to easily perform from the interface (or with a function) a ""contains"" filter so I can get all the items on table A continued on some Areas of the table B. An easy example is a set of geocoded Leads and a list of provinces or working areas, so you can split your leads by regions. 
  - etc

**Describe alternatives you've considered**
Able to do analysis with spatial columns using SQL, but not supported in the UI. 


**Additional Context**
Customer's use case -- their business connects people to other businesses, and a lot of different factors need to be taken into consideration such as:
  - availability/capacity of the business (if they can take more people)
  - the distance between the person and the business
  - how far the person can travel to the business 
  - what region the business is in (if there are different contracts/constraints based on region) 
  - etc ",jessicaul,2024-10-21 19:16:06+00:00,[],2025-02-04 20:30:47+00:00,,https://github.com/metabase/metabase/issues/48952,"[('Type:New Feature', ''), ('Querying/Notebook/Custom Column', '')]",[],
2603376761,issue,open,,Pivots Don't Respect MB_DOWNLOAD_ROW_LIMIT in v50,"### Describe the bug

Pivots exports  ignore the new download row limit environment variable and instead refer to the agg / unagg variables for downloads and subscriptions.

### To Reproduce

1. Launch Metabase v50 with MB_DOWNLOAD_ROW_LIMIT=9000
2. Create a pivot table with over 10k records in v50
3. Download via the GUI and note it exports 10k records
4. Send a subscription and note that it also exports 10k records





### Expected behavior

MB_DOWNLOAD_ROW_LIMIT should be respected

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v1.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-10-21 18:43:17+00:00,[],2025-02-04 20:31:56+00:00,,https://github.com/metabase/metabase/issues/48949,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Visualization/Download', ''), ('.Team/Querying', '')]",[],
2603267073,issue,closed,completed,CSV Imports Sometimes Incorrectly Infer Encoding (50.25+),"### Describe the bug

Imported a UTF8 CSV file with ASCII extended characters and it's importing them as Chinese characters. Interestingly whether this occurs seems to have some relationship to the size of the sample set in the file. the same row in the file 7 times will be imported correctly. But duplicate the 7 rows 10 more times and things go sideways.

The user initially experiencing this has large CSV files - oddly if the sample dataset is small the file imports correctly. Adding the same rows via copy/paste to the same file until the sample set is larger results in this bug presenting as well. So if you begin with a smaller CSV, then the encoding breaks as the files grows, you can no longer append to CSV, either.

### To Reproduce

1. Spin up version 50.25+ (works in 50.24)
2. Enabled CSV uploads for Postrges test DB
3. Import these test files:

- Incorrect: [import_test.csv](https://github.com/user-attachments/files/17464933/import_test.csv)
- Incorrect: [import_test2.csv](https://github.com/user-attachments/files/17464935/import_test2.csv)
- Correct: [import_test3.csv](https://github.com/user-attachments/files/17464938/import_test3.csv)

These import correctly in 50.24 and prior. They also work correctly if you use UTF8-BOM rather than UTF8.


### Expected behavior

Character encoding should be inferred correctly.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-10"",
      ""tag"": ""v1.50.25"",
      ""hash"": ""473a7ca""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

blocking some users

### Additional context

_No response_",ixipixi,2024-10-21 17:50:13+00:00,['crisptrutski'],2024-10-23 14:44:10+00:00,2024-10-23 11:58:03+00:00,https://github.com/metabase/metabase/issues/48945,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2427535840, 'issue_id': 2603267073, 'author': 'crisptrutski', 'body': 'Sound like this may be related to https://github.com/metabase/metabase/pull/47799', 'created_at': datetime.datetime(2024, 10, 21, 19, 23, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428465569, 'issue_id': 2603267073, 'author': 'crisptrutski', 'body': ""I've confirmed that this behavior is due to the inference coming from our 3rd party dependency.\n\nThe files are inferred respectively as:\n\n1. TIS620 (Thai)\n2. GB18030 (Chinese)\n3. UTF-8"", 'created_at': datetime.datetime(2024, 10, 22, 7, 25, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428475162, 'issue_id': 2603267073, 'author': 'crisptrutski', 'body': ""One potential solution is to have a allowed or disallowed encoding list, and treat the excluded ones as UTF-8.\n\nAnother avenue could be to explore the confidence our inference has, although there's no high level API for doing this in the dependency and it would need to be quite complex. I'm also not sure what the confidence ratings are in these particular cases, let alone in the customer's actual data.\n\nA more long term solution could be to add a modal on upload where the user can confirm the encoding. This modal could also be used for confirming column types, matching columns on append, etc."", 'created_at': datetime.datetime(2024, 10, 22, 7, 30, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431892973, 'issue_id': 2603267073, 'author': 'crisptrutski', 'body': 'The reason longer files tended to trigger the issues more is that the detection algorithms build confidence based on both the relative and absolute frequency of various codepoints.', 'created_at': datetime.datetime(2024, 10, 23, 11, 59, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432465678, 'issue_id': 2603267073, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 23, 14, 44, 7, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-10-21 19:23:12 UTC): Sound like this may be related to https://github.com/metabase/metabase/pull/47799

crisptrutski (Assginee) on (2024-10-22 07:25:37 UTC): I've confirmed that this behavior is due to the inference coming from our 3rd party dependency.

The files are inferred respectively as:

1. TIS620 (Thai)
2. GB18030 (Chinese)
3. UTF-8

crisptrutski (Assginee) on (2024-10-22 07:30:09 UTC): One potential solution is to have a allowed or disallowed encoding list, and treat the excluded ones as UTF-8.

Another avenue could be to explore the confidence our inference has, although there's no high level API for doing this in the dependency and it would need to be quite complex. I'm also not sure what the confidence ratings are in these particular cases, let alone in the customer's actual data.

A more long term solution could be to add a modal on upload where the user can confirm the encoding. This modal could also be used for confirming column types, matching columns on append, etc.

crisptrutski (Assginee) on (2024-10-23 11:59:19 UTC): The reason longer files tended to trigger the issues more is that the detection algorithms build confidence based on both the relative and absolute frequency of various codepoints.

github-actions[bot] on (2024-10-23 14:44:07 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2603212023,issue,closed,completed,Add custom hook for temporary and ephemeral user settings,"We often have the need to keep track of some ephemeral ""setting"" in the app. It should be a bit more persistent than the component state, but still less persistent and less important than the full-fledged user-level backend setting. We can't rely on `localStorage` because of embedding. `sessionStorage` would suffice, but we don't want to introduce yet another way of storing settings when we already have the Redux store with batteries included.

### Task
Create a custom hook `useTempStorage`.",nemanjaglumac,2024-10-21 17:24:37+00:00,['nemanjaglumac'],2024-10-30 00:18:16+00:00,2024-10-22 22:00:55+00:00,https://github.com/metabase/metabase/issues/48944,"[('.Frontend', ''), ('.DX', 'Developer experience and QoL related.')]","[{'comment_id': 2445554483, 'issue_id': 2603212023, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.1](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 30, 0, 18, 16, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-30 00:18:16 UTC): 🚀 This should also be released by [v0.51.1](https://github.com/metabase/metabase/milestone/231)

"
2602525959,issue,closed,completed,`<EditableDashboard />` content protrudes the bottom boundary,"### Describe the bug

![Image](https://github.com/user-attachments/assets/fe88c91b-8f2c-4482-b257-6112d75855c6)

The `<EditableDashboard />` content could protrude its bottom boundary, if the dashboard is really long.

### To Reproduce

1. Create a long dashboard with lots of cards.
2. Embed that with the SDK with `EditableDashboard`
3. Render something under the `EditableDashboard`



### Expected behavior

the height is respected somehow, I'd expect it to behave the same way as `<StaticDashboard />` or `<InteractiveDashboard />`

### Logs

_No response_

### Information about your Metabase installation

-

### Severity

This could block the host application elements which could be really bad

### Additional context

_No response_",WiNloSt,2024-10-21 13:14:28+00:00,['deniskaber'],2024-10-30 18:37:57+00:00,2024-10-30 17:54:37+00:00,https://github.com/metabase/metabase/issues/48933,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2602405788,issue,open,,Incorrect binning options provided,"User is presented with incorrect binning options in the second query stage. See the attached loom. Namely, `Created At: Day of Week` is by default bucketed by month while attempting to join on that column. The month option, and presumably other binning options, should not be available here. User has to shutdown binning manually to make the query work.

Loom:
https://www.loom.com/share/f81402522e2a4bf1aa1e16ddd82abff5?sid=0da2ed6b-fa05-45fa-86ac-05ee5081a9cf

Found on `7be52702e4b49605d03a7caea278f8c6c9f17b7d`.

",lbrdnk,2024-10-21 12:30:56+00:00,[],2025-02-04 20:27:11+00:00,,https://github.com/metabase/metabase/issues/48932,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2602086773,issue,open,,[Epic] Remove Tippy,"**Description**
Simple Epic to track migrating components away from Tippy in favor of the `<Popover>` component from Mantine.

- [ ] actions/containers/ActionCreator/FormCreator/FieldSettingsPopover.tsx
- [ ] actions/containers/ActionCreator/FormCreator/OptionEditor.tsx
- [ ] parameters/components/ParameterTargetWidget.jsx
- [ ] core/components/AccordionList/AccordionList.unit.spec.js
- [ ] core/components/Select/Select.tsx
- [ ] core/components/DateWidget/DateWidget.tsx
- [ ] core/components/ColorPicker/ColorPicker.tsx
- [ ] core/components/ColorRangeSelector/ColorRangeSelector.tsx
- [ ] core/components/ColorSelector/ColorSelector.tsx
- [ ] core/components/AutocompleteInput/AutocompleteInput.tsx
- [ ] core/components/Tooltip/Tooltip.tsx
- [ ] core/components/TabButton/TabButton.tsx
- [ ] nav/containers/MainNavbar/MainNavbarContainer/MainNavbarView.tsx
- [ ] visualizations/visualizations/LinkViz/LinkViz.tsx
- [ ] visualizations/components/ChartSettingsWidgetPopover.tsx
- [ ] visualizations/components/legend/Legend.jsx
- [ ] visualizations/components/ClickActions/ClickActionsPopover.styled.tsx
- [ ] visualizations/components/ChartSettingsWidget.tsx
- [ ] visualizations/components/skeletons/ChartSkeleton/ChartSkeleton.unit.spec.tsx
- [ ] containers/ItemSelect.jsx
- [ ] query_builder/components/view/QuestionRowCount/QuestionRowCount.tsx
- [ ] query_builder/components/NativeQueryEditor/RightClickPopover/RightClickPopover.tsx
- [ ] query_builder/components/SelectionModule.jsx
- [ ] query_builder/components/template_tags/SnippetSidebar/SnippetSidebar.jsx
- [ ] query_builder/components/expressions/ExpressionEditorHelpText/ExpressionEditorHelpText.tsx
- [ ] query_builder/components/DataSelector/DataSelector.jsx
- [ ] search/components/DropdownSidebarFilter/DropdownSidebarFilter.tsx
- [ ] public/containers/PublicOrEmbeddedDashboard/PublicOrEmbeddedDashboardView.stories.tsx
- [ ] admin/permissions/components/PermissionsSelect/PermissionsSelect.jsx
- [ ] admin/permissions/components/ToolbarUpsell/ToolbarUpsell.tsx
- [ ] admin/datamodel/metadata/components/FieldRemappingSettings/FieldRemappingSettings.jsx
- [ ] admin/datamodel/metadata/components/MetadataTableColumnList/MetadataTableColumnList.tsx
- [ ] admin/datamodel/components/DimensionList/DimensionList.jsx
- [ ] admin/datamodel/components/FilterPopover/FilterPopoverFooter.tsx
- [ ] admin/datamodel/components/filters/pickers/LegacyDatePicker/DatePicker.jsx
- [ ] admin/datamodel/components/filters/pickers/SelectPicker.jsx
- [ ] admin/datamodel/components/filters/pickers/DatePicker/CurrentPicker/CurrentPicker.tsx
- [ ] admin/datamodel/components/filters/pickers/DefaultPicker/DefaultPicker.tsx
- [ ] admin/datamodel/components/ObjectActionSelect.jsx
- [ ] admin/settings/components/widgets/ModelCachingScheduleWidget/CronExpressionInput.tsx
- [ ] admin/settings/components/widgets/GroupMappingsWidget/GroupSelect/GroupSelect.tsx
- [ ] admin/settings/components/ApiKeys/SecretKeyModal.tsx
- [ ] admin/databases/components/DatabaseEditApp/Sidebar/ModelCachingControl/ModelCachingControl.tsx
- [ ] admin/people/components/GroupsListing.jsx
- [ ] admin/people/components/AddMemberRow.jsx
- [ ] admin/people/components/MembershipSelect/MembershipSelect.tsx
- [ ] components/TokenField/TokenField.tsx
- [ ] components/Popover/TippyPopover.tsx
- [ ] components/PopoverWithTrigger/PopoverWithTrigger.jsx
- [ ] components/PopoverWithTrigger/ControlledPopoverWithTrigger.tsx
- [ ] dashboard/components/DashCard/DashCardParameterMapper/DashCardCardParameterMapperButton.tsx
- [ ] dashboard/components/ClickBehaviorSidebar/LinkOptions/ValuesYouCanReference.jsx


",npfitz,2024-10-21 10:27:57+00:00,['npfitz'],2024-10-21 10:27:57+00:00,,https://github.com/metabase/metabase/issues/48928,"[('.Epic', 'Feature Implementation or Project')]",[],
2601881331,issue,closed,completed,Clarify the removal of 'Powered by Metabase' banner for Cloud / Starter plan,"### Describe the bug

On OSS instances, the Admin Settings / Embedding section directs users to upgrade to a paid plan to remove the ""powered by"" banner on static embeds:
> A ""powered by Metabase"" banner apperas on static embeds. You can upgrade to a paid plan to remove it.
![Image](https://github.com/user-attachments/assets/4f304876-5c4a-472b-87cb-eb656d90a32f)

The message is correct for self-hosting, but it could be confusing for admins of cloud instances on the Starter plan, as it's also a paid tier. To avoid this, we should display a different message for them, something like:

> ""A 'powered by Metabase' banner appears on static embeds. Upgrade to a Pro or Enterprise plan to remove this banner from your cloud instance.""

### To Reproduce

Go to Admin Settings / Embedding on a Cloud hosted Starter instance.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

All versions

### Severity

Confusing for customers on the Starter plan

### Additional context

_No response_",zbodi74,2024-10-21 09:12:01+00:00,['WiNloSt'],2024-10-30 09:24:02+00:00,2024-10-30 07:04:53+00:00,https://github.com/metabase/metabase/issues/48925,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2441340088, 'issue_id': 2601881331, 'author': 'brunobergher', 'body': 'Yeah, let’s change it to \n\n> A “powered by Metabase” banner appears on static embeds. You can upgrade to a specific paid plan which removes it.\n\nusing the same URL', 'created_at': datetime.datetime(2024, 10, 28, 11, 36, 31, tzinfo=datetime.timezone.utc)}]","brunobergher on (2024-10-28 11:36:31 UTC): Yeah, let’s change it to 


using the same URL

"
2601839701,issue,open,,Add an `ignore_view` and/or `ignore_card_view` query parameter to the GET `/api/dashboard/:id` endpoint,"**Is your feature request related to a problem? Please describe.**
Currently when you calls to the API GET `/api/card/:id` a  `ignore_view` parameter is available to set to true or false

![Image](https://github.com/user-attachments/assets/250e9cbc-8411-4e62-b57b-f89d3c213416)

But for the GET Dashboard endpoint (GET `/api/dashboard/:id`) doesn't have this option ... It seems a call to the endpoint will generate an entry to the view_log table for each card in that Dashboard. Ideally there would be an option to ignore these 'views' from getting logged to the table, which should hopefully decrease the size of the view_log table. 

**Describe the solution you'd like**

Support a `ignore_view` parameter for `/api/dashboard/:id`  similar to the GET `/api/card/:id` 
",Tony-metabase,2024-10-21 08:55:34+00:00,[],2025-02-04 20:30:29+00:00,,https://github.com/metabase/metabase/issues/48924,"[('Misc/API', ''), ('Type:New Feature', ''), ('Querying/', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2601624573,issue,closed,completed,Clause popover attached to the wrong trigger after dragging & dropping clauses,"### Describe the bug

![Image](https://github.com/user-attachments/assets/bd7961d5-4d46-41ed-9e89-f31aad670fa2)

----

https://github.com/user-attachments/assets/4361b039-261c-45d5-85fc-033670059a2f


### To Reproduce

1. New > Question > People
2. Add 2 filters on different columns
3. Click one of the filters to edit it - popover will be opened
4. Drag & drop to swap filters while popover is opened



### Information about your Metabase installation

master, c92e8c993f

### Severity

P3
",kamilmielnik,2024-10-21 07:31:28+00:00,['ranquild'],2025-01-24 16:15:05+00:00,2025-01-24 14:21:12+00:00,https://github.com/metabase/metabase/issues/48922,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2426184236, 'issue_id': 2601624573, 'author': 'pramittt', 'body': 'Can I pick this up', 'created_at': datetime.datetime(2024, 10, 21, 9, 51, 59, tzinfo=datetime.timezone.utc)}]","pramittt on (2024-10-21 09:51:59 UTC): Can I pick this up

"
2601433529,issue,closed,not_planned,No More external DB mess and issue of loss of data with h2 bydefault database,"![Image](https://github.com/user-attachments/assets/b6d5ff0f-8c1a-424c-a05c-eff1d422a247)

**Solved**
**Use the h2 database giving persistent volume**


services:
  metabase:
    image: metabase/metabase
    container_name: metabase
    user: ""1001""  # Switch to non-root user ID  modify the existing container and commit OR modify the Dockerfile  image creation                     
    ports:
      - ""3000:3000""
    volumes:
      - metabase-db:/metabase.db
    restart: always

volumes:
  metabase-db:
    driver: local

* Note : please make sure that the you restrict permissions of tha docker volume folder on your host machine
connect me : maheboob.dev


",mehboobpatel,2024-10-21 06:00:30+00:00,[],2024-10-21 11:17:30+00:00,2024-10-21 11:17:29+00:00,https://github.com/metabase/metabase/issues/48921,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2426383694, 'issue_id': 2601433529, 'author': 'paoliniluis', 'body': ""sorry I don't know what this is. Please do not, never ever, use H2 as a database that you'll use in a production deployment. You'll end up losing everything, forever, and it's going to be unrecoverable. We can't say this enough: please use postgres or mysql when using Metabase for production deployments"", 'created_at': datetime.datetime(2024, 10, 21, 11, 17, 29, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-21 11:17:29 UTC): sorry I don't know what this is. Please do not, never ever, use H2 as a database that you'll use in a production deployment. You'll end up losing everything, forever, and it's going to be unrecoverable. We can't say this enough: please use postgres or mysql when using Metabase for production deployments

"
2599492376,issue,open,,More theming control for table viz,"To be discussed. Refer to [this customer note](https://www.notion.so/metabase/SDK-follow-up-call-Lifesight-12269354c9018072ade9d022f62e078e?pvs=4#12269354c90180aebba2f10b4dce063b) for more info.

# Blocked 🔴 

Awaiting more requirements before we can proceed. [See this Slack thread on the Slack customer channel.](https://metaboat.slack.com/archives/C07166YL2UU/p1732538681166059)",albertoperdomo,2024-10-19 18:56:10+00:00,[],2025-02-04 20:30:53+00:00,,https://github.com/metabase/metabase/issues/48920,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2475633156, 'issue_id': 2599492376, 'author': 'heypoom', 'body': '@albertoperdomo I think this is from [this customer note](https://www.notion.so/metabase/SDK-follow-up-call-Lifesight-12269354c9018072ade9d022f62e078e?pvs=4#12269354c90180aebba2f10b4dce063b), right?', 'created_at': datetime.datetime(2024, 11, 14, 7, 44, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559023401, 'issue_id': 2599492376, 'author': 'heypoom', 'body': ""@albertoperdomo I'm removing this from the epic for now as we have no feedback from the customer channel: https://metaboat.slack.com/archives/C07166YL2UU/p1732538681166059"", 'created_at': datetime.datetime(2024, 12, 23, 6, 51, 33, tzinfo=datetime.timezone.utc)}]","heypoom on (2024-11-14 07:44:20 UTC): @albertoperdomo I think this is from [this customer note](https://www.notion.so/metabase/SDK-follow-up-call-Lifesight-12269354c9018072ade9d022f62e078e?pvs=4#12269354c90180aebba2f10b4dce063b), right?

heypoom on (2024-12-23 06:51:33 UTC): @albertoperdomo I'm removing this from the epic for now as we have no feedback from the customer channel: https://metaboat.slack.com/archives/C07166YL2UU/p1732538681166059

"
2598606742,issue,open,,Can't sync the nyctaxi database from the samples schema,"### Describe the bug

I'm seeing a big stack trace when trying to sync that schema with lots of errors

### To Reproduce

1) start a databricks cluster
2) try to sync their sample catalog

### Expected behavior

_No response_

### Logs

```
clojure.lang.ExceptionInfo: Error executing query: [Databricks][JDBCDriver](500051) ERROR processing query/statement. Error Code: 0, SQL state: 42P01, Query: SELECT `c`***, Error message from Server: org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `samples`.`information_schema`.`columns` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:786)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:624)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:469)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:704)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:469)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:27)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:74)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:174)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:729)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:738)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:617)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:615)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$11(ThriftLocalProperties.scala:195)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:190)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:71)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:446)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:432)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:482)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `samples`.`information_schema`.`columns` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01

```

### Information about your Metabase installation

v51.0-beta

### Severity

P1 I guess?

### Additional context

_No response_",paoliniluis,2024-10-19 00:25:43+00:00,['lbrdnk'],2025-02-04 20:25:18+00:00,,https://github.com/metabase/metabase/issues/48917,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', ''), ('Database/Databricks', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2423402685, 'issue_id': 2598606742, 'author': 'paoliniluis', 'body': ""It ends up saying that there's no table trips ![Image](https://github.com/user-attachments/assets/cb367b67-8366-4896-b20e-4bbc9dd0a4f8)"", 'created_at': datetime.datetime(2024, 10, 19, 0, 26, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428053603, 'issue_id': 2598606742, 'author': 'perivamsi', 'body': 'Based on [this conversation](https://metaboat.slack.com/archives/C07L35T7UFQ/p1729512048097999), downgrading this to a P2. The fix is on the Databricks side.', 'created_at': datetime.datetime(2024, 10, 22, 1, 58, 18, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-10-19 00:26:13 UTC): It ends up saying that there's no table trips ![Image](https://github.com/user-attachments/assets/cb367b67-8366-4896-b20e-4bbc9dd0a4f8)

perivamsi on (2024-10-22 01:58:18 UTC): Based on [this conversation](https://metaboat.slack.com/archives/C07L35T7UFQ/p1729512048097999), downgrading this to a P2. The fix is on the Databricks side.

"
2598586967,issue,open,,"""Display a column as a link"" not functional in Detail visualization type","### Describe the bug

If you change the field display for a column in table metadata using the ""Display a column as a link"" option, the link is displayed in table visualizations. If you view the same record in a detail viz the field no longer displays as a link.

### To Reproduce

1. Modify the ID field of the sample order table to direct to ""google.com/{{id}}"" and set a fancy display name
2. Create a simple question with the table
3. See that the link shows up in a table viz
4. Modify the question to a detail view
5. Note that the link is no longer display in lieu of the ID

### Expected behavior

After you change the field to display as a URL I'd expect to see it that way throughout the visualizations

### Logs

_No response_

### Information about your Metabase installation

v50

### Severity

annoying

### Additional context

_No response_",ixipixi,2024-10-18 23:55:26+00:00,[],2025-02-04 20:31:34+00:00,,https://github.com/metabase/metabase/issues/48915,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Detail', 'ObjectDetail'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2450186247, 'issue_id': 2598586967, 'author': 'maowerner', 'body': 'I also run into this issue on  v1.51.1. I have a dashboard with a filter on a unique ID that shows a report card and want to link to relevant systems within this report card. \n\nWit a regular table that works but the user experience is much worse because I get a scroll bar.', 'created_at': datetime.datetime(2024, 10, 31, 15, 34, 25, tzinfo=datetime.timezone.utc)}]","maowerner on (2024-10-31 15:34:25 UTC): I also run into this issue on  v1.51.1. I have a dashboard with a filter on a unique ID that shows a report card and want to link to relevant systems within this report card. 

Wit a regular table that works but the user experience is much worse because I get a scroll bar.

"
2598351162,issue,closed,not_planned,[Epic] Content Verification,"**Links**
- Product Doc: [link](https://www.notion.so/metabase/Evolve-content-verification-and-deprecation-03e20f5c0cad4323be671423a1b473ce)

**Implementation Plan**
Implementation plan is largely extending the current verification system to Dashboards, extending it to include content deprecation, then incorporation entity health. Each milestone should be mergable (and shippable?) independently.


***Milestone 1: Verified Dashboards***
- [x] #48954
- [x] #49188
- [x] #49398

***Milestone 2: Add Reasons + new Statuses to Entities***
- [ ] FE: Build verification popover
- [ ] #49295
- [ ] New statuses to moderation reviews: `""neutral""` `""expired""` `""flagged""`
- [ ] #49628
- [ ] Event tracking

***Milestone 3: Moderation Review Expiration***
- [ ] FE: send expiration
- [ ] BE: Add expiration to moderation statuses
- [ ] BE: Add 'cron job' to mark moderation statuses as expired
- [ ] BE: Add notification warning for moderation review expiration

***Milestone 4: Health Status***
- [ ] BE: Figure out persistence for Health Status (new table probably)
- [ ] BE: Add Health status propogation
- [ ] FE: Display Health of Entities

***Milestone 5: Verification Notifications***
- [ ] BE: Add boolean ""has_warned"" column to `moderation_status`
    - Used for sending emails.
- [ ] BE: Send Emails on verification expiration
    - to the users who have edited the card / verified it


",npfitz,2024-10-18 20:40:28+00:00,"['escherize', 'npfitz']",2025-01-17 18:24:46+00:00,2025-01-17 18:24:46+00:00,https://github.com/metabase/metabase/issues/48911,"[('.Epic', 'Feature Implementation or Project')]",[],
2597653028,issue,closed,completed,Order of selected filter values may cause cache miss due to hash mismatch,"### Describe the bug

The order in which values are selected in a category filter affects the hash used for query caching. This can lead to a cache miss when the same values are selected in a different order.

### To Reproduce

1. Create a question
2. Add it to a dashboard and link a category filter
3. Set caching policy for the dashboard: Duration: 1 hour
4. Select two values in the filter, e.g. 'Widget', 'Gizmo'
5. Check the logs, and note the question is being cached
6. Deselect the values
7. Select the same values again, but in a different order: 'Gizmo', 'Widget'
8. Check the logs and see a different cache key has been generated for the query

### Expected behavior

The same value selection should generate the same cache key, regardless of the order in which the values are selected.

### Logs



```{""parameters"":[{""type"":""string/="",""value"":[""Widget"",""Gizmo""],""id"":""5e84a14b"",""target"":[""dimension"",[""field"",357,{""base-type"":""type/Text"",""source-field"":366}]]}],""dashboard_id"":13,""dashboard_load_id"":""f16cf5aa-588c-da10-ec07-fb56427b0329""}```

> metabase-v1.50.30-ee-1  | 2024-10-18 13:48:53,647 INFO middleware.cache :: Query 72082a2b took 24.2 ms to run; minimum for cache eligibility is 0.0 ns; eligible
> metabase-v1.50.30-ee-1  | 2024-10-18 13:48:53,647 INFO middleware.cache :: Caching results for next time for query with hash ""72082a2b"". 💾
> metabase-v1.50.30-ee-1  | 2024-10-18 13:48:53,671 DEBUG middleware.log :: POST /api/dashboard/13/dashcard/70/card/104/query 202 [ASYNC: completed] 151.7 ms (27 DB calls) App DB connections: 1/13 Jetty threads: 4/50 (8 idle, 0 queued) (133 total active threads) Queries in flight: 0 (0 queued); mysql DB 3 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}




```{""parameters"":[{""type"":""string/="",""value"":[""Gizmo"",""Widget""],""id"":""5e84a14b"",""target"":[""dimension"",[""field"",357,{""base-type"":""type/Text"",""source-field"":366}]]}],""dashboard_id"":13,""dashboard_load_id"":""ed9af5cd-b565-2fa2-c1cd-883162210e32""}```


> metabase-v1.50.30-ee-1  | 2024-10-18 13:50:54,825 INFO middleware.cache :: Query 197b7422 took 24.0 ms to run; minimum for cache eligibility is 0.0 ns; eligible
> metabase-v1.50.30-ee-1  | 2024-10-18 13:50:54,827 INFO middleware.cache :: Caching results for next time for query with hash ""197b7422"". 💾
> metabase-v1.50.30-ee-1  | 2024-10-18 13:50:54,860 DEBUG middleware.log :: POST /api/dashboard/13/dashcard/70/card/104/query 202 [ASYNC: completed] 200.4 ms (27 DB calls) App DB connections: 1/13 Jetty threads: 4/50 (10 idle, 0 queued) (127 total active threads) Queries in flight: 0 (0 queued); mysql DB 3 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-10-15"",
      ""tag"": ""v1.50.30"",
      ""hash"": ""a49cb77""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19 (Debian 12.19-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.75-0-virt"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  }
}

### Severity

P2 - found it while troubleshooting something else

### Additional context

_No response_",zbodi74,2024-10-18 14:15:26+00:00,['nvoxland'],2024-12-13 22:50:21+00:00,2024-12-13 22:08:41+00:00,https://github.com/metabase/metabase/issues/48887,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2597563374,issue,closed,completed,FE - Do not add extra filtering stage for pivot tables,"See https://metaboat.slack.com/archives/C0645JP1W81/p1729258402989309?thread_ts=1729213440.034179&cid=C0645JP1W81

Counter-part of #48884",kamilmielnik,2024-10-18 13:44:55+00:00,['kamilmielnik'],2024-10-22 11:06:42+00:00,2024-10-22 11:06:41+00:00,https://github.com/metabase/metabase/issues/48885,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2428982807, 'issue_id': 2597563374, 'author': 'kamilmielnik', 'body': 'Closed by #48975', 'created_at': datetime.datetime(2024, 10, 22, 11, 6, 41, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-22 11:06:41 UTC): Closed by #48975

"
2597562066,issue,closed,completed,BE - Do not add extra filtering stage for pivot tables,"See https://metaboat.slack.com/archives/C0645JP1W81/p1729258402989309?thread_ts=1729213440.034179&cid=C0645JP1W81

Counter-part of #48885

This should make the following 3 tests pass in CI:
- `multiple-column-breakouts.cy.spec.ts`
    - `should be able to use temporal-unit parameters with multiple temporal breakouts of a column`
- `temporal-unit-parameters.cy.spec.js`
    - `should connect a parameter to a question and drill thru`
    - `should connect multiple parameters to a card with multiple breakouts and drill thru`",kamilmielnik,2024-10-18 13:44:22+00:00,['metamben'],2024-10-25 10:54:17+00:00,2024-10-25 10:54:17+00:00,https://github.com/metabase/metabase/issues/48884,"[('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2437482627, 'issue_id': 2597562066, 'author': 'kamilmielnik', 'body': 'Closed by #48906', 'created_at': datetime.datetime(2024, 10, 25, 10, 54, 17, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-25 10:54:17 UTC): Closed by #48906

"
2597405387,issue,closed,completed,Databases added by config file are not synced regularly,"### Describe the bug

No Quartz trigger is created for databases added by the config file, thus they are not synced regularly.

### To Reproduce


1. Metabase starts with an empty application database, and a [config file
   containing configuration for a connected database](https://www.metabase.com/docs/latest/configuring-metabase/config-file#databases)
2. It passes ""INFO advanced-config.file :: Initializing :databases from config file... 🗄️""
3. It prints ""INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""Metabase Cloud Storage"" has been enabled with schedule: ""0 22 * * * ? *"""" *multiple* times
4. It reaches ""INFO metabase.task :: Task scheduler started""
5. `qrtz_triggers` does not contain *any* `metabase.task.sync-and-analyze` triggers (not for the DB from the config file and not for the sample H2 DB)
6. Changes to the database (adding tables) do not become visible to Metabase

### Expected behavior

Databases should always be synced regularly, no matter how they are created.

### Logs

_No response_

### Information about your Metabase installation

Local setup of deac5cbcc7e68d20f7ffe71d021dafa73e6e9de6.

### Severity

Full blocker

### Additional context

References: https://metaboat.slack.com/archives/C079ZS06ERJ/p1728991333736979",devurandom,2024-10-18 12:32:55+00:00,['devurandom'],2024-10-18 19:55:03+00:00,2024-10-18 15:43:12+00:00,https://github.com/metabase/metabase/issues/48881,"[('Type:Bug', 'Product defects'), ('Administration/Metadata & Sync', ''), ('Administration/Table Metadata', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2422455196, 'issue_id': 2597405387, 'author': 'dpsutton', 'body': 'I\'m starting up a local instance with an empty app-db:\n\n```shell\nMB_PREMIUM_EMBEDDING_TOKEN=$TOKEN MB_JETTY_PORT=3006 MB_DB_CONNECTION_URI=$PG_CONN java ""$(socket-repl 6006)"" -jar $JARS/1.50.30.jar\n```\n\nand i see there are indeed no triggers for the database:\n\n```clojure\ntask=> (filter (comp #{""metabase.task.sync-and-analyze.job""} :key) (jobs-info))\n({:key ""metabase.task.sync-and-analyze.job"",\n  :class ""metabase.task.sync_databases.SyncAndAnalyzeDatabase"",\n  :description ""sync-and-analyze for all databases"",\n  :concurrent-execution-disallowed? true,\n  :durable? true,\n  :requests-recovery? false,\n  :triggers ()})\n```\n\nThis demonstrates that there are indeed no triggers for the database. I had a suspicion that a trigger would be added when the instance restarted but this is not the case unfortunately.', 'created_at': datetime.datetime(2024, 10, 18, 13, 15, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422462756, 'issue_id': 2597405387, 'author': 'devurandom', 'body': 'Fix in https://github.com/metabase/metabase/pull/48882.  (Waiting for tests to pass.)', 'created_at': datetime.datetime(2024, 10, 18, 13, 19, 37, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-18 13:15:42 UTC): I'm starting up a local instance with an empty app-db:

```shell
MB_PREMIUM_EMBEDDING_TOKEN=$TOKEN MB_JETTY_PORT=3006 MB_DB_CONNECTION_URI=$PG_CONN java ""$(socket-repl 6006)"" -jar $JARS/1.50.30.jar
```

and i see there are indeed no triggers for the database:

```clojure
task=> (filter (comp #{""metabase.task.sync-and-analyze.job""} :key) (jobs-info))
({:key ""metabase.task.sync-and-analyze.job"",
  :class ""metabase.task.sync_databases.SyncAndAnalyzeDatabase"",
  :description ""sync-and-analyze for all databases"",
  :concurrent-execution-disallowed? true,
  :durable? true,
  :requests-recovery? false,
  :triggers ()})
```

This demonstrates that there are indeed no triggers for the database. I had a suspicion that a trigger would be added when the instance restarted but this is not the case unfortunately.

devurandom (Issue Creator) on (2024-10-18 13:19:37 UTC): Fix in https://github.com/metabase/metabase/pull/48882.  (Waiting for tests to pass.)

"
2597251643,issue,open,,Cannot duplicate a dashboard with an action card,"### Describe the bug

![Image](https://github.com/user-attachments/assets/79be3484-1fa1-4b18-a6b8-3ee3179af034)


### To Reproduce

1. Go to https://stats.metabase.com/dashboard/2662
2. Try to duplicate this dashboard

2 problems:
❌ Duplication fails
❌ The ""Duplicate"" button gets squeezed due to the wide error message and you can't read its label


### Information about your Metabase installation

master, 405ed53

### Severity

P2

### Additional context

Discovered while looking at #48878
",kamilmielnik,2024-10-18 11:20:28+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/48880,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2499654614, 'issue_id': 2597251643, 'author': 'ixipixi', 'body': 'Possibly related: https://github.com/metabase/metabase/issues/38224', 'created_at': datetime.datetime(2024, 11, 26, 4, 52, 25, tzinfo=datetime.timezone.utc)}]","ixipixi on (2024-11-26 04:52:25 UTC): Possibly related: https://github.com/metabase/metabase/issues/38224

"
2597203229,issue,closed,completed,Actions are broken in 50.30 when Models are based on SQL,"### Describe the bug

Actions fail to load on dashboard for release 50.30  when using models based on SQL ... This used to work on 50.27.4

### To Reproduce

1. Go to Admin -> Database -> Sample Database -> Enable Actions
2. New -> SQL Question -> `Select * from orders` -> Save and turn to a Model
3. Go to Model Details and just create a basic action:

![Image](https://github.com/user-attachments/assets/115eaf35-33b6-4d22-9dda-ed01722f301f)

4. Go to Dashboard -> Add an action and pick up any action from orders -> It will work and you see this:

![Image](https://github.com/user-attachments/assets/e9dc0c75-f561-426b-a7ac-ceeaa6670ab9)

5. Refresh the page maybe a couple of times (for me happens once):

![Image](https://github.com/user-attachments/assets/9a86dfcd-1d5b-494e-8f53-a8180ff0ebbe)

you can also try this on stats https://stats.metabase.com/dashboard/2662-fail-action-model-based-on-sql



### Expected behavior

The button loads

### Logs

Nothing relevant

### Information about your Metabase installation

50.30 and master

### Severity

Broke a couple of dashboards 

### Additional context

_No response_",Tony-metabase,2024-10-18 10:56:22+00:00,['kamilmielnik'],2024-10-22 07:51:05+00:00,2024-10-21 15:11:22+00:00,https://github.com/metabase/metabase/issues/48878,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Actions', ''), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 2422417067, 'issue_id': 2597203229, 'author': 'NevRA', 'body': 'Context: https://metaboat.slack.com/archives/C052ZBWRG3W/p1729248994578069', 'created_at': datetime.datetime(2024, 10, 18, 12, 56, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426154696, 'issue_id': 2597203229, 'author': 'kamilmielnik', 'body': 'Debugging notes:\n- this issue reproduces only when GET `/api/collection/root/items?models=dataset` ends before GET `/api/card/:id`\n- GET `/api/collection/root/items?models=dataset` populates `entities.questions` in redux store (entity framework) with an incomplete card object (it does not have `dataset_query` attribute)\n- `ActionViz/Action` component uses `useQuestionQuery` which will give this incomplete card from redux store (entity framework)\n\nPossible solutions:\n- quick: use `isLoading` from `useQuestionQuery` to delay trying to use card data\n- proper: use `useGetCardQuery` instead of deprecated, entity-framework-using `useQuestionQuery`', 'created_at': datetime.datetime(2024, 10, 21, 9, 41, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428520057, 'issue_id': 2597203229, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 22, 7, 51, 4, tzinfo=datetime.timezone.utc)}]","NevRA on (2024-10-18 12:56:06 UTC): Context: https://metaboat.slack.com/archives/C052ZBWRG3W/p1729248994578069

kamilmielnik (Assginee) on (2024-10-21 09:41:46 UTC): Debugging notes:
- this issue reproduces only when GET `/api/collection/root/items?models=dataset` ends before GET `/api/card/:id`
- GET `/api/collection/root/items?models=dataset` populates `entities.questions` in redux store (entity framework) with an incomplete card object (it does not have `dataset_query` attribute)
- `ActionViz/Action` component uses `useQuestionQuery` which will give this incomplete card from redux store (entity framework)

Possible solutions:
- quick: use `isLoading` from `useQuestionQuery` to delay trying to use card data
- proper: use `useGetCardQuery` instead of deprecated, entity-framework-using `useQuestionQuery`

github-actions[bot] on (2024-10-22 07:51:04 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2596754583,issue,open,,Pivot table not applied by default due to columns cardinality cache key collisions,"### Describe the bug

https://github.com/user-attachments/assets/f4d3661c-b414-4e7c-b4d2-4574c35b2899


### To Reproduce

1. Open new tab with Metabase at index page
2. New > Question > Orders > Count > Breakout by Created At: Month > Breakout by Product Category > Visualize
3. Click ""Visualization"" and change it to ""Table""
4. Click cog icon and notice that ""Pivot table"" is **turned on** by default for such question

All good here ✅ 
Now we will try to create the same question but first we will create another that has a ""Category"" column with different cardinality (to populate the cache).

-----

1. Open new tab with Metabase at index page (this clears the cache)
2. New > Question > Orders > Add custom column called `CATEGORY` with value `[Product → Vendor]` >  Count > Breakout by Created At: Month > Breakout by CATEGORY custom column
3. Click ""Visualization"" and change it to ""Table""
4. New > Question > Orders > Count > Breakout by Created At: Month > Breakout by Product Category > Visualize
5. Click ""Visualization"" and change it to ""Table""
6. Click cog icon and notice that ""Pivot table"" is **turned off** ❌ 

It should be **turned on** (see first bunch of repro steps).

----

Pivot table not being applied is only one of the symptoms.
Everything that depends on column cardinality computation is affected.

### Information about your Metabase installation

master, deac5cbcc7e68d20f7ffe71d021dafa73e6e9de6

### Severity

P2

### Additional context

The columns cardinality cache is globally shared and the keys in cache depend only on the column name (which is very likely to repeat across different questions):

https://github.com/metabase/metabase/blob/b8073ded7d9bbb852c7338ac2476df387c452a55/frontend/src/metabase/visualizations/lib/utils.js#L213-L229",kamilmielnik,2024-10-18 07:55:51+00:00,[],2025-02-04 20:29:57+00:00,,https://github.com/metabase/metabase/issues/48874,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2596724773,issue,closed,not_planned,CPU usage at 98%,"### Describe the bug

Hello everyone,

for several versions of Metabase community, I have been encountering a CPU usage issue. For several days, everything runs smoothly with 0 errors in the logs, but for an unknown reason, suddenly the Java process starts using 98% of the CPU on my Linux server. The only solution is to restart the process.

### To Reproduce

wait...

### Expected behavior

_No response_

### Logs

```
oct. 18 08:52:26 [...] metabase[257492]: 2024-10-18 08:52:26,874 INFO middleware.exceptions :: Request canceled before finishing.
oct. 18 08:52:26 [...] metabase[257492]: 2024-10-18 08:52:22,363 WARN middleware.exceptions :: Exception in API call
oct. 18 08:52:26 [...] metabase[257492]: org.eclipse.jetty.io.EofException
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:116)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:422)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:275)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:254)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:386)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:832)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:243)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:224)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:589)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:1051)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:1123)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:270)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:254)
oct. 18 08:52:26 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:736)
oct. 18 08:52:26 [...] metabase[257492]:         at java.base/java.io.FilterOutputStream.flush(FilterOutputStream.java:153)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.util.jakarta.servlet.proxy$java.io.FilterOutputStream$ff19274a.flush(Unknown Source)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.middleware.gzip$fn__107220.invokeStatic(gzip.clj:35)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.middleware.gzip$fn__107220.invoke(gzip.clj:28)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.MultiFn.invoke(MultiFn.java:239)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.java.io$copy.invokeStatic(io.clj:406)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.java.io$copy.doInvoke(io.clj:391)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:425)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.core.protocols$fn__34406$fn__34407.invoke(protocols.clj:57)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.core.protocols$fn__34406.invokeStatic(protocols.clj:56)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.core.protocols$fn__34406.invoke(protocols.clj:38)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.core.protocols$fn__34368$G__34363__34377.invoke(protocols.clj:7)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.util.jakarta.servlet$update_servlet_response.invokeStatic(servlet.clj:97)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.util.jakarta.servlet$update_servlet_response.invoke(servlet.clj:82)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server.protocols$fn__34501.invokeStatic(protocols.clj:28)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server.protocols$fn__34501.invoke(protocols.clj:21)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server.protocols$fn__34477$fn__34480$G__34478__34487.invoke(protocols.clj:6)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server$async_proxy_handler$fn__72017$fn__72027.invoke(server.clj:80)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.middleware.gzip$wrap_gzip$fn__107249$fn__107250.invoke(gzip.clj:89)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at ring.middleware.cookies$wrap_cookies$fn__107207$fn__107208.invoke(cookies.clj:201)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server.middleware.session$reset_session_timeout$fn__65814$fn__65815.invoke(session.clj:551)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.core$comp$fn__5876.invoke(core.clj:2586)
oct. 18 08:52:26 [...] metabase[257492]:         at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99523$fn__99524.invoke(exceptions.clj:112)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767$fn__52768.invoke(core.clj:151)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.response$send.invokeStatic(response.clj:28)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.response$send.invoke(response.clj:22)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_response$fn__52774.invoke(core.clj:160)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_middleware$fn__52758.invoke(core.clj:132)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_info$fn__52763.invoke(core.clj:139)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:151)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:153)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:26 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:26 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786.invoke(core.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.exceptions$public_exceptions$fn__99486.invoke(exceptions.clj:28)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786.invoke(core.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$handler__52814.invoke(core.clj:290)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:300)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:301)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.Var.invoke(Var.java:393)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.api.routes$fn__103163$fn__103166.invoke(routes.clj:73)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786.invoke(core.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyToHelper(AFn.java:160)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.AFn.applyTo(AFn.java:144)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.core$apply.invokeStatic(core.clj:667)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.core$apply.invoke(core.clj:662)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.routes$fn__103443$fn__103444.doInvoke(routes.clj:73)
oct. 18 08:52:27 [...] metabase[257492]:         at clojure.lang.RestFn.invoke(RestFn.java:436)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786.invoke(core.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$handler__52814.invoke(core.clj:290)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$make_context$fn__52818.invoke(core.clj:300)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:153)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$wrap_route_matches$fn__52767.invoke(core.clj:152)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787$respond_SINGLEQUOTE___52788.invoke(core.clj:197)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.routes$fn__103426$fn__103428.invoke(routes.clj:47)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786$f__52787.invoke(core.clj:198)
oct. 18 08:52:27 [...] metabase[257492]:         at compojure.core$routes$fn__52786.invoke(core.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99523.invoke(exceptions.clj:107)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.exceptions$catch_api_exceptions$fn__99520.invoke(exceptions.clj:96)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.log$log_api_call$fn__103730$fn__103731$fn__103732.invoke(log.clj:233)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.log$log_api_call$fn__103730$fn__103731.invoke(log.clj:224)
oct. 18 08:52:27 [...] metabase[257492]:         at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
oct. 18 08:52:27 [...] metabase[257492]:         at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.log$log_api_call$fn__103730.invoke(log.clj:223)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__107020.invoke(browser_cookie.clj:40)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.security$add_security_headers$fn__99479.invoke(security.clj:246)
oct. 18 08:52:27 [...] metabase[257492]:         at ring.middleware.json$wrap_json_body$fn__107279.invoke(json.clj:64)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.offset_paging$handle_paging$fn__87842.invoke(offset_paging.clj:43)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.json$wrap_streamed_json_response$fn__54402.invoke(json.clj:83)
oct. 18 08:52:27 [...] metabase[257492]:         at ring.middleware.keyword_params$wrap_keyword_params$fn__107368.invoke(keyword_params.clj:55)
oct. 18 08:52:27 [...] metabase[257492]:         at ring.middleware.params$wrap_params$fn__107387.invoke(params.clj:77)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.misc$maybe_set_site_url$fn__64261.invoke(misc.clj:59)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$reset_session_timeout$fn__65814.invoke(session.clj:549)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$bind_current_user$fn__65780$fn__65781.invoke(session.clj:443)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:405)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$bind_current_user$fn__65780.invoke(session.clj:442)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$wrap_current_user_info$fn__65761.invoke(session.clj:381)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.session$wrap_session_id$fn__65733.invoke(session.clj:259)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.auth$wrap_static_api_key$fn__97497.invoke(auth.clj:32)
oct. 18 08:52:27 [...] metabase[257492]:         at ring.middleware.cookies$wrap_cookies$fn__107207.invoke(cookies.clj:200)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.misc$add_content_type$fn__64243.invoke(misc.clj:28)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.misc$disable_streaming_buffering$fn__64269.invoke(misc.clj:75)
oct. 18 08:52:27 [...] metabase[257492]:         at ring.middleware.gzip$wrap_gzip$fn__107249.invoke(gzip.clj:86)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.misc$bind_request$fn__64272.invoke(misc.clj:91)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__107036.invoke(ssl.clj:41)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server$async_proxy_handler$fn__72017.invoke(server.clj:77)
oct. 18 08:52:27 [...] metabase[257492]:         at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.Server.handle(Server.java:563)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/java.lang.Thread.run(Thread.java:829)
oct. 18 08:52:27 [...] metabase[257492]: Caused by: java.io.IOException: Relais brisé (pipe)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/sun.nio.ch.FileDispatcherImpl.writev0(Native Method)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/sun.nio.ch.SocketDispatcher.writev(SocketDispatcher.java:51)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:182)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/sun.nio.ch.IOUtil.write(IOUtil.java:130)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:493)
oct. 18 08:52:27 [...] metabase[257492]:         at java.base/java.nio.channels.SocketChannel.write(SocketChannel.java:507)
oct. 18 08:52:27 [...] metabase[257492]:         at org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:110)
oct. 18 08:52:27 [...] metabase[257492]:         ... 401 more

```

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:131.0) Gecko/20100101 Firefox/131.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.5.15-MariaDB-0+deb11u1""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.15+10-post-Debian-1deb11u1"",
    ""java.vendor"": ""Debian"",
    ""java.vendor.url"": ""https://tracker.debian.org/openjdk-11"",
    ""java.version"": ""11.0.15"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.15+10-post-Debian-1deb11u1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-14-amd64"",
    ""user.language"": ""fr"",
    ""user.timezone"": ""Europe/Paris""
  }
}

### Severity

blocking my usage 

### Additional context

_No response_",Philippe-M,2024-10-18 07:45:01+00:00,[],2025-01-06 16:49:03+00:00,2025-01-06 16:49:01+00:00,https://github.com/metabase/metabase/issues/48873,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2421755165, 'issue_id': 2596724773, 'author': 'paoliniluis', 'body': 'What is Metabase doing when this happens?', 'created_at': datetime.datetime(2024, 10, 18, 8, 2, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421850815, 'issue_id': 2596724773, 'author': 'Philippe-M', 'body': 'It starts with queries that do not complete and are stopped by Metabase, and then it is no longer possible to load the interface. At this point, even stopping the Metabase process takes more than a minute.', 'created_at': datetime.datetime(2024, 10, 18, 8, 42, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428181976, 'issue_id': 2596724773, 'author': 'perivamsi', 'body': 'Downgrading this to P2 based on the localized nature of the issue', 'created_at': datetime.datetime(2024, 10, 22, 4, 3, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559699368, 'issue_id': 2596724773, 'author': 'paoliniluis', 'body': '@Philippe-M does this keep happening?', 'created_at': datetime.datetime(2024, 12, 23, 13, 19, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573502313, 'issue_id': 2596724773, 'author': 'paoliniluis', 'body': 'Closing due to no response', 'created_at': datetime.datetime(2025, 1, 6, 16, 49, 2, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-18 08:02:10 UTC): What is Metabase doing when this happens?

Philippe-M (Issue Creator) on (2024-10-18 08:42:48 UTC): It starts with queries that do not complete and are stopped by Metabase, and then it is no longer possible to load the interface. At this point, even stopping the Metabase process takes more than a minute.

perivamsi on (2024-10-22 04:03:44 UTC): Downgrading this to P2 based on the localized nature of the issue

paoliniluis on (2024-12-23 13:19:48 UTC): @Philippe-M does this keep happening?

paoliniluis on (2025-01-06 16:49:02 UTC): Closing due to no response

"
2596552077,issue,closed,completed,Rename jwtProviderUri to authProviderUri in embedding sdk,"We should deprecate `jwtProviderUri` and rename it to `authProviderUri` in the embedding sdk, to make it generic enough as the term ""JWT"" is confusing.",heypoom,2024-10-18 06:30:59+00:00,['oisincoveney'],2024-11-14 07:06:01+00:00,2024-11-14 07:06:00+00:00,https://github.com/metabase/metabase/issues/48870,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2475572932, 'issue_id': 2596552077, 'author': 'heypoom', 'body': 'Closed by https://github.com/metabase/metabase/pull/49843 as that PR is merged', 'created_at': datetime.datetime(2024, 11, 14, 7, 6, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-11-14 07:06:00 UTC): Closed by https://github.com/metabase/metabase/pull/49843 as that PR is merged

"
2596061679,issue,closed,completed,"Latest version, download json file to convert numeric format to string","### Describe the bug

Latest version, download json file to convert numeric format to string

version:0.50.x    --- bug
```
[
{""QTY"":""1""}
]
```


version:0.47.9   --- ok
```
[
{""QTY"":1}
]
```

### To Reproduce

![Image](https://github.com/user-attachments/assets/1009f0bf-40d1-4786-8a28-9dc4f816ca9e)



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

centos 
java -jar metabase.jar

### Severity

bug

### Additional context

_No response_",aokinba,2024-10-18 00:24:07+00:00,[],2024-10-22 16:27:01+00:00,2024-10-22 02:46:58+00:00,https://github.com/metabase/metabase/issues/48868,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2429735036, 'issue_id': 2596061679, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 22, 16, 27, 1, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-22 16:27:01 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2595169073,issue,closed,completed,Text Filter breaks when to many values are added,"### Describe the bug

When adding a lot of ids via copy paste to the filter box, it currently becomes infinitely long without a scroll option. as such it is impossible to click the filter button and go ahead with the desired operation.

(image redacted for data privacy reasons)

![Image](https://github.com/user-attachments/assets/13c38aa3-b3eb-4b57-9332-04695563a37b)

### To Reproduce

1. Go to a table and filter for a text value.
2. Copy paste a big list of values, for instance from an excel, to the filter box. The filter box is as per default set to the ""contains"" operator.
3. See the list extents beyond the screen without the option to filter.
4. There is no way to click next and actually filter.


### Expected behavior

The box with the added values becomes scrollable and does next extend infinitely.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-15"",
      ""tag"": ""v0.50.30"",
      ""hash"": ""a49cb77""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.15""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.12+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.12"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.12+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  }
}

### Severity

High

### Additional context

_No response_",carstenkadmos,2024-10-17 16:06:28+00:00,['romeovs'],2024-10-29 10:12:59+00:00,2024-10-29 09:27:48+00:00,https://github.com/metabase/metabase/issues/48851,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2419971978, 'issue_id': 2595169073, 'author': 'Timelessprod', 'body': 'I got some users reporting getting stuck because of this. The workaround is to change the filter type which will bring back the popup to the default size with a scrollable list and then switch again to the correct filter type. Not ideal solution.', 'created_at': datetime.datetime(2024, 10, 17, 16, 16, 20, tzinfo=datetime.timezone.utc)}]","Timelessprod on (2024-10-17 16:16:20 UTC): I got some users reporting getting stuck because of this. The workaround is to change the filter type which will bring back the popup to the default size with a scrollable list and then switch again to the correct filter type. Not ideal solution.

"
2595155871,issue,closed,completed,Downloading Pivot Table doesn't show data only column headers - Oracle Specific,"### Describe the bug

When you download a Pivot (any pivot config) there are no rows visible in the csv/xlsx/json files ... This is what you get:

![Image](https://github.com/user-attachments/assets/609b4737-179a-4b30-a670-ca2f160057b7)

Only happens for Oracle based connections

### To Reproduce

Connect to an Oracle DB - Luis has a handy lab for Linux https://github.com/paoliniluis/metabase-oracle

1. Go to Orders -> Create a couple of aggregates:

![Image](https://github.com/user-attachments/assets/ca0e1b57-e2b8-479f-b294-931c35e40927)

2. You will get something like this:

![Image](https://github.com/user-attachments/assets/2e10ff8c-d0bb-4e5f-b177-97e10e675ad2)

3. Then download the pivot and notice the empty file:

![Image](https://github.com/user-attachments/assets/3b5d9b96-fe0e-4b25-a4a9-8484a001964b)

### Expected behavior

The file is populated with data

### Logs

Nothing that is relevant

### Information about your Metabase installation

50.28

### Severity

Breaks download functionality for pivot tables which is client facing. 

### Additional context

_No response_",Tony-metabase,2024-10-17 15:59:49+00:00,[],2024-10-22 16:27:01+00:00,2024-10-22 02:46:57+00:00,https://github.com/metabase/metabase/issues/48849,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/', ''), ('Database/Oracle', None), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2429735003, 'issue_id': 2595155871, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 22, 16, 27, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-22 16:27:00 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2595144795,issue,open,,Show grid lines for right y-axis on two y-axes charts when a series associated with the right y-axis is hovered,"[Slack report](https://metaboat.slack.com/archives/C064QMXEV9N/p1729169864342649)

On cartesian charts with two y-axes, we show grid lines only for the left y-axis. At the same time when hovering over a series, we hide the axis not associated with that series. If we hover a series that is associated with the right y-axis then the grid lines will be hidden. Instead, we should show grid lines for the right y-axis.",alxnddr,2024-10-17 15:55:13+00:00,[],2025-02-04 20:26:14+00:00,,https://github.com/metabase/metabase/issues/48847,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2595138721,issue,open,,Bar chart data labels jump 1px on hover,"[Slack report](https://metaboat.slack.com/archives/C064QMXEV9N/p1729169864342649)

Steps to reproduce
- Create a bar chart
- Enable data labels
- Hover bars -> data labels slightly change their position",alxnddr,2024-10-17 15:52:55+00:00,['retro'],2025-02-04 20:26:14+00:00,,https://github.com/metabase/metabase/issues/48846,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2595131438,issue,closed,completed,"Roll back default filter operator to ""is"" from ""contains""","**Is your feature request related to a problem? Please describe.**
The problem is the new default operator when filtering string columns. Before the default operator was ""is"". For a couple releases it is ""contains"", which leads to a lot of danger in filtering and getting false positives. Very dangerous for beginners.

**Describe the solution you'd like**
Roll back to having ""is"" as the default operator.

**Describe alternatives you've considered**
95% of filter operations are ""is"". I just have to spend more time every time i filter.

**How important is this feature to you?**
Very important. I think it is a dangerous default to set as most users will think of a direct match as the default filter.
",carstenkadmos,2024-10-17 15:49:43+00:00,[],2024-11-05 17:27:26+00:00,2024-11-05 17:27:26+00:00,https://github.com/metabase/metabase/issues/48845,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2419915757, 'issue_id': 2595131438, 'author': 'Timelessprod', 'body': 'Big up on this one!', 'created_at': datetime.datetime(2024, 10, 17, 15, 50, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420159970, 'issue_id': 2595131438, 'author': 'paoliniluis', 'body': '@carstenkadmos here\'s what the FE team is mentioning about this:\n```\nit’s Is for\n- PKs\n- FKs\n- Anything with field values\nOtherwise it’s ""Contains""\n```\n\nwould you say what\'s the use case here so we can check this out?', 'created_at': datetime.datetime(2024, 10, 17, 17, 58, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420191654, 'issue_id': 2595131438, 'author': 'mngr', 'body': '@carstenkadmos what is you Metabase version? the mentioned logic is implemented in 51', 'created_at': datetime.datetime(2024, 10, 17, 18, 4, 20, tzinfo=datetime.timezone.utc)}]","Timelessprod on (2024-10-17 15:50:44 UTC): Big up on this one!

paoliniluis on (2024-10-17 17:58:25 UTC): @carstenkadmos here's what the FE team is mentioning about this:
```
it’s Is for
- PKs
- FKs
- Anything with field values
Otherwise it’s ""Contains""
```

would you say what's the use case here so we can check this out?

mngr on (2024-10-17 18:04:20 UTC): @carstenkadmos what is you Metabase version? the mentioned logic is implemented in 51

"
2595105513,issue,closed,completed,Fix Changelog generation to support multiple branches,We can modify the changelog manually until we could automatically generate it.,WiNloSt,2024-10-17 15:41:56+00:00,['WiNloSt'],2024-10-22 07:32:10+00:00,2024-10-21 14:33:15+00:00,https://github.com/metabase/metabase/issues/48844,[],"[{'comment_id': 2426864062, 'issue_id': 2595105513, 'author': 'WiNloSt', 'body': ""After testing extensively, it turns out this is already working and I misunderstood its behavior.\n\nThe tags that will be used to calculate changelog would be tags that exist on the brach being used. That means when we are using the release branch 51 to generate a changelog we would `conventional-changelog` would ignore all `embedding-sdk-1.52.x` tags because these tags don't exist on the branch `release-x.51.x` (only `embedding-sdk-1.51.x` exists on the release branch 51)"", 'created_at': datetime.datetime(2024, 10, 21, 14, 33, 12, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-10-21 14:33:12 UTC): After testing extensively, it turns out this is already working and I misunderstood its behavior.

The tags that will be used to calculate changelog would be tags that exist on the brach being used. That means when we are using the release branch 51 to generate a changelog we would `conventional-changelog` would ignore all `embedding-sdk-1.52.x` tags because these tags don't exist on the branch `release-x.51.x` (only `embedding-sdk-1.51.x` exists on the release branch 51)

"
2594946964,issue,open,,Create an ESLint rule to check if all tags rendered inside `jt` have a `key` prop,"**Context**

See #48825
See https://metaboat.slack.com/archives/C505ZNNH4/p1729164717248499",kamilmielnik,2024-10-17 14:39:50+00:00,[],2025-02-04 20:25:37+00:00,,https://github.com/metabase/metabase/issues/48836,"[('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('dev/ergonomic', ''), ('.Team/DevEx', '')]",[],
2594902100,issue,closed,completed,Error connecting to Athena Database from Metabase,"### Describe the bug

I previously used two VPCs. One had an MSK cluster and an msk-athena-connector, and the second was for Metabase running on ECS. I set up an Athena database in Metabase, which connected to Athena to query my MSK Kafka topic. However, when I changed my setup and used a single VPC, I got this error when I synced my Athena database.



### To Reproduce

1. Setup MSK Cluster with a VPC
2. Setup Metabase on ECS with the same VPC
3. Create a Kafka topic and publish messages to it
4. Create a schema in AWS Glue using (AthenaFederatedQuery)
5. Query the topic in AWS Athena to verify
6. Configure the Athena Database in Metabase
7. Sync the database 
8. View the error below

### Expected behavior

It shouldn't fail to sync with Athena

### Logs

```log

Oct 17 06:48:38.072 DEBUG 33 com.simba.athena.athena.api.AJClient.fetchSchemasWithProxyApi: Aws::Athena - AthenaClient - GetNameSpaces ----- exit -----
--
Oct 17 06:48:38.074 ERROR 33 com.simba.athena.exceptions.ExceptionConverter.toSQLException: [Simba][AthenaJDBC](100131) An error has been thrown from the AWS SDK client. Unable to execute HTTP request: The target server failed to respond [Execution ID not available]
java.sql.SQLException: [Simba][AthenaJDBC](100131) An error has been thrown from the AWS SDK client. Unable to execute HTTP request: The target server failed to respond [Execution ID not available]
at com.simba.athena.athena.api.AJClient.checkAndThrowException(Unknown Source)
at com.simba.athena.athena.api.AJClient.fetchSchemasWithProxyApi(Unknown Source)
at com.simba.athena.athena.api.AJClient.getSchemas(Unknown Source)
at com.simba.athena.athena.utilities.AJMetadataHelperUtilities.getSchemasWithCatalogCheck(Unknown Source)
at com.simba.athena.athena.dataengine.metadata.AJCatalogSchemaOnlyMetadataSource.<init>(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataSource(Unknown Source)
at com.simba.athena.dsi.dataengine.impl.DSIDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.jdbc.jdbc42.S42DatabaseMetaData.createMetaDataResult(Unknown Source)
at com.simba.athena.jdbc.common.BaseDatabaseMetaData.getSchemas(Unknown Source)
at com.mchange.v2.c3p0.impl.NewProxyDatabaseMetaData.getSchemas(NewProxyDatabaseMetaData.java:2990)
at metabase.driver.athena$fast_active_tables.invokeStatic(athena.clj:427)
at metabase.driver.athena$fast_active_tables.invoke(athena.clj:416)
at metabase.driver.athena$fn__121290$fn__121292.invoke(athena.clj:455)
at metabase.driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)
at metabase.driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)
at metabase.driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)
at clojure.lang.MultiFn.invoke(MultiFn.java:244)
at metabase.driver.athena$fn__121290.invokeStatic(athena.clj:449)
at metabase.driver.athena$fn__121290.invoke(athena.clj:447)
at clojure.lang.MultiFn.invoke(MultiFn.java:234)
at metabase.sync.fetch_metadata$db_metadata.invokeStatic(fetch_metadata.clj:30)
at metabase.sync.fetch_metadata$db_metadata.invoke(fetch_metadata.clj:26)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_$fn__86091.invoke(sync_metadata.clj:69)
at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189)
at metabase.sync.util$do_with_error_handling.invoke(util.clj:182)
at clojure.core$partial$fn__5910.invoke(core.clj:2647)
at metabase.driver$fn__55334.invokeStatic(driver.clj:826)
at metabase.driver$fn__55334.invoke(driver.clj:826)
at clojure.lang.MultiFn.invoke(MultiFn.java:239)
at metabase.sync.util$sync_in_context$fn__57781.invoke(util.clj:165)
at metabase.sync.util$with_db_logging_disabled$fn__57778.invoke(util.clj:157)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124)
at metabase.sync.util$with_start_and_finish_logging$fn__57765.invoke(util.clj:142)
at metabase.sync.util$with_sync_events$fn__57760.invoke(util.clj:116)
at metabase.sync.util$with_duplicate_ops_prevented$fn__57747.invoke(util.clj:88)
at metabase.sync.util$do_sync_operation.invokeStatic(util.clj:214)
at metabase.sync.util$do_sync_operation.invoke(util.clj:208)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:68)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:65)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:88)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:71)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:107)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:95)
at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:112)
at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
Caused by: com.simba.athena.support.exceptions.GeneralException: [Simba][AthenaJDBC](100131) An error has been thrown from the AWS SDK client. Unable to execute HTTP request: The target server failed to respond [Execution ID not available]
... 49 more
Caused by: com.simba.athena.amazonaws.SdkClientException: Unable to execute HTTP request: The target server failed to respond
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.handleRetryableException(AmazonHttpClient.java:1219)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1165)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.doExecute(AmazonHttpClient.java:814)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.executeWithTimer(AmazonHttpClient.java:781)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.execute(AmazonHttpClient.java:755)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.access$500(AmazonHttpClient.java:715)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutionBuilderImpl.execute(AmazonHttpClient.java:697)
at com.simba.athena.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:561)
at com.simba.athena.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:541)
at com.simba.athena.amazonaws.services.athena.AmazonAthenaClient.doInvoke(AmazonAthenaClient.java:2570)
at com.simba.athena.amazonaws.services.athena.AmazonAthenaClient.invoke(AmazonAthenaClient.java:2537)
at com.simba.athena.amazonaws.services.athena.AmazonAthenaClient.invoke(AmazonAthenaClient.java:2526)
at com.simba.athena.amazonaws.services.athena.AmazonAthenaClient.executeListDatabases(AmazonAthenaClient.java:1542)
at com.simba.athena.amazonaws.services.athena.AmazonAthenaClient.listDatabases(AmazonAthenaClient.java:1511)
at com.simba.athena.athena.api.AJClient.fetchSchemasWithProxyApi(Unknown Source)
at com.simba.athena.athena.api.AJClient.getSchemas(Unknown Source)
at com.simba.athena.athena.utilities.AJMetadataHelperUtilities.getSchemasWithCatalogCheck(Unknown Source)
at com.simba.athena.athena.dataengine.metadata.AJCatalogSchemaOnlyMetadataSource.<init>(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataSource(Unknown Source)
at com.simba.athena.dsi.dataengine.impl.DSIDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.jdbc.jdbc42.S42DatabaseMetaData.createMetaDataResult(Unknown Source)
at com.simba.athena.jdbc.common.BaseDatabaseMetaData.getSchemas(Unknown Source)
at com.mchange.v2.c3p0.impl.NewProxyDatabaseMetaData.getSchemas(NewProxyDatabaseMetaData.java:2990)
at metabase.driver.athena$fast_active_tables.invokeStatic(athena.clj:427)
at metabase.driver.athena$fast_active_tables.invoke(athena.clj:416)
at metabase.driver.athena$fn__121290$fn__121292.invoke(athena.clj:455)
at metabase.driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)
at metabase.driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)
at metabase.driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)
at clojure.lang.MultiFn.invoke(MultiFn.java:244)
at metabase.driver.athena$fn__121290.invokeStatic(athena.clj:449)
at metabase.driver.athena$fn__121290.invoke(athena.clj:447)
at clojure.lang.MultiFn.invoke(MultiFn.java:234)
at metabase.sync.fetch_metadata$db_metadata.invokeStatic(fetch_metadata.clj:30)
at metabase.sync.fetch_metadata$db_metadata.invoke(fetch_metadata.clj:26)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_$fn__86091.invoke(sync_metadata.clj:69)
at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189)
at metabase.sync.util$do_with_error_handling.invoke(util.clj:182)
at clojure.core$partial$fn__5910.invoke(core.clj:2647)
at metabase.driver$fn__55334.invokeStatic(driver.clj:826)
at metabase.driver$fn__55334.invoke(driver.clj:826)
at clojure.lang.MultiFn.invoke(MultiFn.java:239)
at metabase.sync.util$sync_in_context$fn__57781.invoke(util.clj:165)
at metabase.sync.util$with_db_logging_disabled$fn__57778.invoke(util.clj:157)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124)
at metabase.sync.util$with_start_and_finish_logging$fn__57765.invoke(util.clj:142)
at metabase.sync.util$with_sync_events$fn__57760.invoke(util.clj:116)
at metabase.sync.util$with_duplicate_ops_prevented$fn__57747.invoke(util.clj:88)
at metabase.sync.util$do_sync_operation.invokeStatic(util.clj:214)
at metabase.sync.util$do_sync_operation.invoke(util.clj:208)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:68)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:65)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:88)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:71)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:107)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:95)
at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:112)
at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
Caused by: org.apache.http.NoHttpResponseException: The target server failed to respond
at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:141)
at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)
at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)
at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)
at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:157)
at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)
at com.simba.athena.amazonaws.http.protocol.SdkHttpRequestExecutor.doReceiveResponse(SdkHttpRequestExecutor.java:82)
at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)
at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:56)
at com.simba.athena.amazonaws.http.apache.client.impl.SdkHttpClient.execute(SdkHttpClient.java:72)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.executeOneRequest(AmazonHttpClient.java:1346)
at com.simba.athena.amazonaws.http.AmazonHttpClient$RequestExecutor.executeHelper(AmazonHttpClient.java:1157)
... 61 more
Oct 17 06:48:38.076 TRACE 33 com.simba.athena.jdbc.common.SConnection.getAutoCommit(): +++++ enter +++++
Oct 17 06:48:38.076 TRACE 33 com.simba.athena.dsi.core.impl.DSIConnection.getProperty(19): +++++ enter +++++
Oct 17 06:48:38.083 TRACE 69 com.simba.athena.jdbc.common.SConnection.clearWarnings(): +++++ enter +++++
Oct 17 06:48:38.083 TRACE 69 com.simba.athena.jdbc.common.SConnection.getAutoCommit(): +++++ enter +++++
Oct 17 06:48:38.083 TRACE 69 com.simba.athena.dsi.core.impl.DSIConnection.getProperty(19): +++++ enter +++++
2024-10-17 06:48:38,083 ERROR sync.fetch-metadata :: Error while fetching metdata with 'db-metadata'
java.sql.SQLException: [Simba][AthenaJDBC](100131) An error has been thrown from the AWS SDK client. Unable to execute HTTP request: The target server failed to respond [Execution ID not available]
at com.simba.athena.athena.api.AJClient.checkAndThrowException(Unknown Source)
at com.simba.athena.athena.api.AJClient.fetchSchemasWithProxyApi(Unknown Source)
at com.simba.athena.athena.api.AJClient.getSchemas(Unknown Source)
at com.simba.athena.athena.utilities.AJMetadataHelperUtilities.getSchemasWithCatalogCheck(Unknown Source)
at com.simba.athena.athena.dataengine.metadata.AJCatalogSchemaOnlyMetadataSource.<init>(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataSource(Unknown Source)
at com.simba.athena.dsi.dataengine.impl.DSIDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.athena.dataengine.AJDataEngine.makeNewMetadataResult(Unknown Source)
at com.simba.athena.jdbc.jdbc42.S42DatabaseMetaData.createMetaDataResult(Unknown Source)
at com.simba.athena.jdbc.common.BaseDatabaseMetaData.getSchemas(Unknown Source)
at com.mchange.v2.c3p0.impl.NewProxyDatabaseMetaData.getSchemas(NewProxyDatabaseMetaData.java:2990)
at metabase.driver.athena$fast_active_tables.invokeStatic(athena.clj:427)
at metabase.driver.athena$fast_active_tables.invoke(athena.clj:416)
at metabase.driver.athena$fn__121290$fn__121292.invoke(athena.clj:455)
at metabase.driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)
at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)
at metabase.driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)
at metabase.driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)
at clojure.lang.MultiFn.invoke(MultiFn.java:244)
at metabase.driver.athena$fn__121290.invokeStatic(athena.clj:449)
at metabase.driver.athena$fn__121290.invoke(athena.clj:447)
at clojure.lang.MultiFn.invoke(MultiFn.java:234)
at metabase.sync.fetch_metadata$db_metadata.invokeStatic(fetch_metadata.clj:30)
at metabase.sync.fetch_metadata$db_metadata.invoke(fetch_metadata.clj:26)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_$fn__86091.invoke(sync_metadata.clj:69)
at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189)
at metabase.sync.util$do_with_error_handling.invoke(util.clj:182)
at clojure.core$partial$fn__5910.invoke(core.clj:2647)
at metabase.driver$fn__55334.invokeStatic(driver.clj:826)
at metabase.driver$fn__55334.invoke(driver.clj:826)
at clojure.lang.MultiFn.invoke(MultiFn.java:239)
at metabase.sync.util$sync_in_context$fn__57781.invoke(util.clj:165)
at metabase.sync.util$with_db_logging_disabled$fn__57778.invoke(util.clj:157)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130)
at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124)
at metabase.sync.util$with_start_and_finish_logging$fn__57765.invoke(util.clj:142)
at metabase.sync.util$with_sync_events$fn__57760.invoke(util.clj:116)
at metabase.sync.util$with_duplicate_ops_prevented$fn__57747.invoke(util.clj:88)
at metabase.sync.util$do_sync_operation.invokeStatic(util.clj:214)
at metabase.sync.util$do_sync_operation.invoke(util.clj:208)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:68)
at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:65)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:88)
at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:71)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:107)
at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:95)
at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:112)
at org.quartz.core.JobRunShell.run(JobRunShell.java:202)


```

### Information about your Metabase installation

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""athena"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.226-214.879.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""US/Pacific""
  }
}
```

### Severity

Blocking usage of Metabase entirely

### Additional context

_No response_",jackton1,2024-10-17 14:23:36+00:00,[],2024-10-20 14:18:52+00:00,2024-10-20 14:18:51+00:00,https://github.com/metabase/metabase/issues/48835,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', ''), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2419779723, 'issue_id': 2594902100, 'author': 'paoliniluis', 'body': 'Can you check if the vpc can accept traffic from outside to the msk cluster?', 'created_at': datetime.datetime(2024, 10, 17, 14, 55, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425002864, 'issue_id': 2594902100, 'author': 'jackton1', 'body': 'Yes, it can. I decided to use 2 VPCs and set up VPC peering.', 'created_at': datetime.datetime(2024, 10, 20, 14, 18, 51, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-17 14:55:38 UTC): Can you check if the vpc can accept traffic from outside to the msk cluster?

jackton1 (Issue Creator) on (2024-10-20 14:18:51 UTC): Yes, it can. I decided to use 2 VPCs and set up VPC peering.

"
2594638294,issue,closed,completed,Unsaved changes warning redundantly shown when targeting a question with custom click behavior,"### Describe the bug

https://github.com/user-attachments/assets/32c719c5-3ce9-4a3d-a738-a40363a7c5e3


### To Reproduce

1. New > Question > Orders > Visualize > Save
2. Add this (or any other) question to dashboard
3. Configure click behavior for this dashcard:
    - choose any source column
    - set saved question from step 1 as target
    - choose any target column
4. Save
5. Try out the click behavior
6. You're now taken to chill mode
7. Click ""Show editor""
8. Remove the filter
9. Click ""Visualize"" or ""Show Visualization""

❌ Unsaved changes warning is shown

10. Click ""Show editor""

❌ Unsaved changes warning is shown

### Information about your Metabase installation

master, deac5cbcc7

### Severity

P2
",kamilmielnik,2024-10-17 12:46:34+00:00,['romeovs'],2024-11-05 08:22:19+00:00,2024-11-04 11:10:57+00:00,https://github.com/metabase/metabase/issues/48829,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Reporting/Dashboards/Click Behavior', ''), ('.Team/Querying', '')]","[{'comment_id': 2451669819, 'issue_id': 2594638294, 'author': 'romeovs', 'body': 'This also happens when:\n\n1. New > Question > Orders > Visualize > Save\n2. Navigate to the question\n3. Add a filter to the question (by clicking on a header and selecting Filter on this column)\n4. Show Editor\n5. Remove the filter\n6. Visualize\n\n❌ Unsaved changes warning is shown\n\nStrangly, it does not happen when setting the filter from the filter modal.', 'created_at': datetime.datetime(2024, 11, 1, 10, 39, 4, tzinfo=datetime.timezone.utc)}]","romeovs (Assginee) on (2024-11-01 10:39:04 UTC): This also happens when:

1. New > Question > Orders > Visualize > Save
2. Navigate to the question
3. Add a filter to the question (by clicking on a header and selecting Filter on this column)
4. Show Editor
5. Remove the filter
6. Visualize

❌ Unsaved changes warning is shown

Strangly, it does not happen when setting the filter from the filter modal.

"
2594423332,issue,open,,Date filter translations: Key not being translated,"### Describe the bug

The date filter (of type relative - that can be added to a dashboard) only translates some of the translation keys.

![Image](https://github.com/user-attachments/assets/0fb68407-3a35-4356-90d5-5689ea5d1a4e)

I have looked into [the code](https://github.com/metabase/metabase/blob/deac5cbcc7e68d20f7ffe71d021dafa73e6e9de6/frontend/src/metabase/components/DateRelativeWidget/DateRelativeWidget.tsx#L22) but I am not able to figure out why that is. The translation keys do exist in the POEditor project. 

_Might_ be related to #24624

### To Reproduce

1. Create a dashboard and add a filter of type Date picker > Relative Date:
![Filter creation](https://github.com/user-attachments/assets/0b441c0e-1a20-470d-a291-21b1d08d568a)
1. Connect it to a question with a date field so it will stay visible.
1. Make sure your Metabase instance (or personal account settings) is set to any other language than English.
1. Open date filter any notice the missing translations for ""Previous 7 days"" and ""Previous 30 days"":
![Relative date filter popup](https://github.com/user-attachments/assets/47eec1ea-f313-42e2-8313-524e1999f849)

I reproduced it on the latest commit (at the time of writing this) on master: deac5cbcc7e68d20f7ffe71d021dafa73e6e9de6

### Expected behavior

Relative Date picker popup to translate all keys using the PO project, including ""Previous 7 days"" and ""Previous 30 days"". That is, for the Swedish version, it should say: ""Föregående 7 dagar"" respectively ""Föregående 30 dagar"".

Tried to find the cause of this by changing to different translation keys but all other keys I tried works as expected.

### Logs

_No response_

### Information about your Metabase installation
```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-04"",
      ""src_hash"": ""41a2064fd0b59020cb1f1056b8ced0968e98fc64"",
      ""tag"": ""v0.1.35-SNAPSHOT"",
      ""hash"": ""321103f""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2"",
    ""java.vendor"": ""Homebrew"",
    ""java.vendor.url"": ""https://github.com/Homebrew/homebrew-core/issues"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.6.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Stockholm""
  }
}
```

### Severity

Annoying

### Additional context

Also noticed that the same goes for Date picker of type ""all"":
![Image](https://github.com/user-attachments/assets/f0c91ece-de8d-4892-8f95-72dd12ce182b)

",antonhedstrom,2024-10-17 11:23:43+00:00,[],2025-02-04 20:25:03+00:00,,https://github.com/metabase/metabase/issues/48824,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/i18n', ''), ('.Frontend', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]",[],
2593974970,issue,closed,completed,"Automate version number. `release-x.51.x` -> `v1.51.x`, `master` -> `v1.52.x`","[product doc](https://www.notion.so/metabase/Improve-npm-release-process-11e69354c901808687bcfb8368fd0327)

We want to not have to fill out the version number manually as that is error prone.

Here's how our input on the SDK release workflow look currently
![Image](https://github.com/user-attachments/assets/cbf6a18a-fd72-4258-bcfa-7a87a8cc3407)

```[tasklist]
### Tasks
- [x] Figure out Changelog + package version bump for each branch (master vs release)
```",WiNloSt,2024-10-17 08:12:06+00:00,['WiNloSt'],2024-10-22 07:34:00+00:00,2024-10-21 15:03:03+00:00,https://github.com/metabase/metabase/issues/48822,[],[],
2593970700,issue,open,,Better troubleshooting: show release workflow input values in the run summary,"Example from `.github/workflows/e2e-stress-test-flake-fix.yml`

https://github.com/metabase/metabase/blob/deac5cbcc7e68d20f7ffe71d021dafa73e6e9de6/.github/workflows/e2e-stress-test-flake-fix.yml#L34-L49

",WiNloSt,2024-10-17 08:10:01+00:00,[],2024-10-17 08:23:52+00:00,,https://github.com/metabase/metabase/issues/48820,[],[],
2593443821,issue,open,,Allow Custom Click Behavior for Detail Visualizations,"**Is your feature request related to a problem? Please describe.**
Sometimes there are dashboard cards that display a single row of data in key value pairs in key-value pairs and we want to turn some of the values into hyperlinks. The ""details"" viz type works best to displaying this illustration but it doesn't offer custom click behavior. 

**Describe the solution you'd like**
The option to assign custom click behavior to individual fields on the Detail viz type from a dashboard.

**Describe alternatives you've considered**
Currently we're using a Table visualization, which looks worse for a single record but can support the links.


",ixipixi,2024-10-17 02:38:20+00:00,[],2025-02-04 20:31:33+00:00,,https://github.com/metabase/metabase/issues/48816,"[('Type:New Feature', ''), ('Reporting/Dashboards/Click Behavior', ''), ('Visualization/Detail', 'ObjectDetail')]",[],
2592879122,issue,closed,not_planned,"ERROR: syntax error at or near "")""   Position: 50","**Describe the bug**
When attempting to access our dashboard, the dashboard appears uneditable, and only surfaces the error: ERROR: syntax error at or near "")""
  Position: 50. This starting happening seemingly without change to the source dashboard.

**Logs**
```json
  ""url"": ""https://reporting.zayzoon.xyz/dashboard/406-transa-dashboard-qbr"",
  ""entityName"": ""dashboard"",
  ""backendErrors"": [
    {
      ""timestamp"": ""2024-10-16T19:23:11.966Z"",
      ""level"": ""ERROR"",
      ""fqns"": ""metabase.server.middleware.log"",
      ""msg"": ""GET /api/dashboard/406/query_metadata 500 193.9 ms (29 DB calls) {:metabase-user-id 225} \n{:via\n [{:type clojure.lang.ExceptionInfo,\n   :message \""ERROR: syntax error at or near \\\"")\\\""\\n  Position: 50\"",\n   :data\n   {:toucan2/context-trace\n    [[\""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection\""\n      {:toucan2.jdbc.query/sql-args [\""SELECT * FROM \\\""metabase_database\\\"" WHERE \\\""id\\\"" IN ()\""]}]\n     [\""resolve connection\"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}]\n     [\""resolve connection\"" {:toucan2.connection/connectable :default}]\n     [\""resolve connection\"" {:toucan2.connection/connectable nil}]\n     {:toucan2.pipeline/rf\n      #object[clojure.core$map$fn__5931$fn__5932 0x6c3da3f1 \""clojure.core$map$fn__5931$fn__5932@6c3da3f1\""]}\n     [\""with compiled query\""\n      {:toucan2.pipeline/compiled-query [\""SELECT * FROM \\\""metabase_database\\\"" WHERE \\\""id\\\"" IN ()\""]}]\n     [\""with built query\""\n      {:toucan2.pipeline/built-query {:select [:*], :from [[:metabase_database]], :where [:in :id #{}]}}]\n     [\""with resolved query\"" {:toucan2.pipeline/resolved-query {}}]\n     [\""with parsed args\""\n      {:toucan2.pipeline/query-type :toucan.query-type/select.instances,\n       :toucan2.pipeline/parsed-args {:kv-args {:id [:in #{}]}, :queryable {}}}]\n     [\""with model\"" {:toucan2.pipeline/model :model/Database}]\n     [\""with unparsed args\""\n      {:toucan2.pipeline/query-type :toucan.query-type/select.instances,\n       :toucan2.pipeline/unparsed-args (:model/Database :id [:in #{}])}]]},\n   :at [org.postgresql.core.v3.QueryExecutorImpl receiveErrorResponse \""QueryExecutorImpl.java\"" 2725]}\n  {:type org.postgresql.util.PSQLException,\n   :message \""ERROR: syntax error at or near \\\"")\\\""\\n  Position: 50\"",\n   :at [org.postgresql.core.v3.QueryExecutorImpl receiveErrorResponse \""QueryExecutorImpl.java\"" 2725]}],\n :trace\n [[org.postgresql.core.v3.QueryExecutorImpl receiveErrorResponse \""QueryExecutorImpl.java\"" 2725]\n  [org.postgresql.core.v3.QueryExecutorImpl processResults \""QueryExecutorImpl.java\"" 2412]\n  [org.postgresql.core.v3.QueryExecutorImpl execute \""QueryExecutorImpl.java\"" 371]\n  [org.postgresql.jdbc.PgStatement executeInternal \""PgStatement.java\"" 502]\n  [org.postgresql.jdbc.PgStatement execute \""PgStatement.java\"" 419]\n  [org.postgresql.jdbc.PgPreparedStatement executeWithFlags \""PgPreparedStatement.java\"" 194]\n  [org.postgresql.jdbc.PgPreparedStatement execute \""PgPreparedStatement.java\"" 180]\n  [com.mchange.v2.c3p0.impl.NewProxyPreparedStatement execute \""NewProxyPreparedStatement.java\"" 67]\n  [toucan2.jdbc.query$reduce_jdbc_query invokeStatic \""query.clj\"" 40]\n  [toucan2.jdbc.query$reduce_jdbc_query invoke \""query.clj\"" 22]\n  [toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default\n   invokeStatic\n   \""pipeline.clj\""\n   19]\n  [toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default\n   invoke\n   \""pipeline.clj\""\n   9]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 15]\n  [methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497\n   invoke\n   \""threaded.clj\""\n   64]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [methodical.impl.standard$invoke_multifn invokeStatic \""standard.clj\"" 65]\n  [methodical.impl.standard$invoke_multifn invoke \""standard.clj\"" 47]\n  [methodical.impl.standard.StandardMultiFn invoke \""standard.clj\"" 216]\n  [toucan2.pipeline$transduce_execute$with_connection_STAR___21604 invoke \""pipeline.clj\"" 78]\n  [toucan2.connection$bind_current_connectable_fn$fn__21281 invoke \""connection.clj\"" 104]\n  [toucan2.connection$bind_current_connectable_fn$fn__21281 invoke \""connection.clj\"" 104]\n  [toucan2.connection$bind_current_connectable_fn$fn__21281 invoke \""connection.clj\"" 104]\n  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invokeStatic \""connection.clj\"" 18]\n  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invoke \""connection.clj\"" 15]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic \""connection.clj\"" 118]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke \""connection.clj\"" 106]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [methodical.impl.standard$invoke_multifn invokeStatic \""standard.clj\"" 55]\n  [methodical.impl.standard$invoke_multifn invoke \""standard.clj\"" 47]\n  [methodical.impl.standard.StandardMultiFn invoke \""standard.clj\"" 210]\n  [metabase.db.connection$do_with_connection_primary_method_default invokeStatic \""connection.clj\"" 132]\n  [metabase.db.connection$do_with_connection_primary_method_default invoke \""connection.clj\"" 130]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic \""connection.clj\"" 118]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke \""connection.clj\"" 106]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [methodical.impl.standard$invoke_multifn invokeStatic \""standard.clj\"" 55]\n  [methodical.impl.standard$invoke_multifn invoke \""standard.clj\"" 47]\n  [methodical.impl.standard.StandardMultiFn invoke \""standard.clj\"" 210]\n  [toucan2.connection$do_with_connection_primary_method_ invokeStatic \""connection.clj\"" 204]\n  [toucan2.connection$do_with_connection_primary_method_ invoke \""connection.clj\"" 194]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic \""connection.clj\"" 118]\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke \""connection.clj\"" 106]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 12]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [methodical.impl.standard$invoke_multifn invokeStatic \""standard.clj\"" 55]\n  [methodical.impl.standard$invoke_multifn invoke \""standard.clj\"" 47]\n  [methodical.impl.standard.StandardMultiFn invoke \""standard.clj\"" 210]\n  [toucan2.pipeline$transduce_execute invokeStatic \""pipeline.clj\"" 77]\n  [toucan2.pipeline$transduce_execute invoke \""pipeline.clj\"" 64]\n  [clojure.lang.Var invoke \""Var.java\"" 399]\n  [toucan2.pipeline$transduce_compiled_query invokeStatic \""pipeline.clj\"" 244]\n  [toucan2.pipeline$transduce_compiled_query invoke \""pipeline.clj\"" 240]\n  [toucan2.pipeline$transduce_built_query invokeStatic \""pipeline.clj\"" 252]\n  [toucan2.pipeline$transduce_built_query invoke \""pipeline.clj\"" 246]\n  [toucan2.pipeline$transduce_query_primary_method_default invokeStatic \""pipeline.clj\"" 272]\n  [toucan2.pipeline$transduce_query_primary_method_default invoke \""pipeline.clj\"" 269]\n  [methodical.impl.combo.common$partial_STAR_$fn__18186 invoke \""common.clj\"" 15]\n  [methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497\n   invoke\n   \""threaded.clj\""\n   64]\n  [methodical.util.FnWithMeta invoke \""util.clj\"" 46]\n  [methodical.impl.standard$invoke_multifn invokeStatic \""standard.clj\"" 65]\n  [methodical.impl.standard$invoke_multifn invoke \""standard.clj\"" 47]\n  [methodical.impl.standard.StandardMultiFn invoke \""standard.clj\"" 216]\n  [toucan2.pipeline$transduce_query_STAR_ invokeStatic \""pipeline.clj\"" 278]\n  [toucan2.pipeline$transduce_query_STAR_ invoke \""pipeline.clj\"" 274]\n  [toucan2.pipeline$transduce_with_model invokeStatic \""pipeline.clj\"" 293]\n  [toucan2.pipeline$transduce_with_model invoke \""pipeline.clj\"" 280]\n  [toucan2.pipeline$transduce_parsed invokeStatic \""pipeline.clj\"" 309]\n  [toucan2.pipeline$transduce_parsed invoke \""pipeline.clj\"" 295]\n  [toucan2.pipeline$transduce_unparsed invokeStatic \""pipeline.clj\"" 317]\n  [toucan2.pipeline$transduce_unparsed invoke \""pipeline.clj\"" 311]\n  [toucan2.select$select_fn__GT_fn invokeStatic \""select.clj\"" 195]\n  [toucan2.select$select_fn__GT_fn doInvoke \""select.clj\"" 181]\n  [clojure.lang.RestFn applyTo \""RestFn.java\"" 142]\n  [clojure.core$apply invokeStatic \""core.clj\"" 673]\n  [clojure.core$apply invoke \""core.clj\"" 662]\n  [toucan2.select$select_pk__GT_fn invokeStatic \""select.clj\"" 221]\n  [toucan2.select$select_pk__GT_fn doInvoke \""select.clj\"" 210]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 464]\n  [metabase.api.table$batch_fetch_card_query_metadatas invokeStatic \""table.clj\"" 517]\n  [metabase.api.table$batch_fetch_card_query_metadatas invoke \""table.clj\"" 497]\n  [metabase.api.query_metadata$batch_fetch_query_metadata_STAR_ invokeStatic \""query_metadata.clj\"" 49]\n  [metabase.api.query_metadata$batch_fetch_query_metadata_STAR_ invoke \""query_metadata.clj\"" 41]\n  [metabase.api.query_metadata$batch_fetch_query_metadata invokeStatic \""query_metadata.clj\"" 71]\n  [metabase.api.query_metadata$batch_fetch_query_metadata invoke \""query_metadata.clj\"" 68]\n  [metabase.api.query_metadata$batch_fetch_card_metadata invokeStatic \""query_metadata.clj\"" 83]\n  [metabase.api.query_metadata$batch_fetch_card_metadata invoke \""query_metadata.clj\"" 73]\n  [metabase.api.query_metadata$batch_fetch_dashboard_metadata invokeStatic \""query_metadata.clj\"" 142]\n  [metabase.api.query_metadata$batch_fetch_dashboard_metadata invoke \""query_metadata.clj\"" 131]\n  [metabase.api.dashboard$fn__96434$fn__96437 invoke \""dashboard.clj\"" 915]\n  [metabase.api.dashboard$do_with_dashboard_load_id invokeStatic \""dashboard.clj\"" 309]\n  [metabase.api.dashboard$do_with_dashboard_load_id invoke \""dashboard.clj\"" 304]\n  [metabase.api.dashboard$fn__96434 invokeStatic \""dashboard.clj\"" 912]\n  [metabase.api.dashboard$fn__96434 invoke \""dashboard.clj\"" 908]\n  [compojure.core$wrap_response$fn__52779 invoke \""core.clj\"" 160]\n  [compojure.core$wrap_route_middleware$fn__52763 invoke \""core.clj\"" 132]\n  [compojure.core$wrap_route_info$fn__52768 invoke \""core.clj\"" 139]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 151]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 153]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 153]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 153]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 153]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [metabase.server.middleware.auth$enforce_authentication$fn__98192 invoke \""auth.clj\"" 18]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$make_context$handler__52819 invoke \""core.clj\"" 290]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 300]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [clojure.lang.Var invoke \""Var.java\"" 393]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [metabase.api.routes$fn__103866$fn__103867 invoke \""routes.clj\"" 70]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.lang.AFunction$1 doInvoke \""AFunction.java\"" 31]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [clojure.lang.AFn applyToHelper \""AFn.java\"" 160]\n  [clojure.lang.AFn applyTo \""AFn.java\"" 144]\n  [clojure.core$apply invokeStatic \""core.clj\"" 667]\n  [clojure.core$apply invoke \""core.clj\"" 662]\n  [metabase.server.routes$fn__104146$fn__104147 doInvoke \""routes.clj\"" 73]\n  [clojure.lang.RestFn invoke \""RestFn.java\"" 436]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$make_context$handler__52819 invoke \""core.clj\"" 290]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 300]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 153]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$wrap_route_matches$fn__52772 invoke \""core.clj\"" 152]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 199]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$make_context$handler__52819 invoke \""core.clj\"" 290]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 300]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793 invoke \""core.clj\"" 197]\n  [compojure.core$make_context$fn__52823 invoke \""core.clj\"" 301]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [compojure.core$routes$fn__52791$f__52792 invoke \""core.clj\"" 198]\n  [compojure.core$routes$fn__52791 invoke \""core.clj\"" 200]\n  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100226 invoke \""exceptions.clj\"" 107]\n  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__100223 invoke \""exceptions.clj\"" 96]\n  [metabase.server.middleware.log$log_api_call$fn__106503$fn__106504$fn__106505 invoke \""log.clj\"" 233]\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic \""diagnostic.clj\"" 18]\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke \""diagnostic.clj\"" 12]\n  [metabase.server.middleware.log$log_api_call$fn__106503$fn__106504 invoke \""log.clj\"" 224]\n  [toucan2.execute$do_with_call_counts invokeStatic \""execute.clj\"" 112]\n  [toucan2.execute$do_with_call_counts invoke \""execute.clj\"" 103]\n  [metabase.server.middleware.log$log_api_call$fn__106503 invoke \""log.clj\"" 223]\n  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__112705 invoke \""browser_cookie.clj\"" 40]\n  [metabase.server.middleware.security$add_security_headers$fn__100182 invoke \""security.clj\"" 246]\n  [ring.middleware.json$wrap_json_body$fn__112964 invoke \""json.clj\"" 64]\n  [metabase.server.middleware.offset_paging$handle_paging$fn__88545 invoke \""offset_paging.clj\"" 43]\n  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54407 invoke \""json.clj\"" 83]\n  [ring.middleware.keyword_params$wrap_keyword_params$fn__113053 invoke \""keyword_params.clj\"" 55]\n  [ring.middleware.params$wrap_params$fn__113072 invoke \""params.clj\"" 77]\n  [metabase.server.middleware.misc$maybe_set_site_url$fn__64266 invoke \""misc.clj\"" 59]\n  [metabase.server.middleware.session$reset_session_timeout$fn__65819 invoke \""session.clj\"" 549]\n  [metabase.server.middleware.session$bind_current_user$fn__65785$fn__65786 invoke \""session.clj\"" 443]\n  [metabase.server.middleware.session$do_with_current_user invokeStatic \""session.clj\"" 422]\n  [metabase.server.middleware.session$do_with_current_user invoke \""session.clj\"" 405]\n  [metabase.server.middleware.session$bind_current_user$fn__65785 invoke \""session.clj\"" 442]\n  [metabase.server.middleware.session$wrap_current_user_info$fn__65766 invoke \""session.clj\"" 381]\n  [metabase.server.middleware.session$wrap_session_id$fn__65738 invoke \""session.clj\"" 259]\n  [metabase.server.middleware.auth$wrap_static_api_key$fn__98200 invoke \""auth.clj\"" 32]\n  [ring.middleware.cookies$wrap_cookies$fn__112892 invoke \""cookies.clj\"" 200]\n  [metabase.server.middleware.misc$add_content_type$fn__64248 invoke \""misc.clj\"" 28]\n  [metabase.server.middleware.misc$disable_streaming_buffering$fn__64274 invoke \""misc.clj\"" 75]\n  [ring.middleware.gzip$wrap_gzip$fn__112934 invoke \""gzip.clj\"" 86]\n  [metabase.server.middleware.misc$bind_request$fn__64277 invoke \""misc.clj\"" 91]\n  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__112721 invoke \""ssl.clj\"" 51]\n  [metabase.server$async_proxy_handler$fn__72022 invoke \""server.clj\"" 77]\n  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]\n  [org.eclipse.jetty.server.handler.StatisticsHandler handle \""StatisticsHandler.java\"" 173]\n  [org.eclipse.jetty.server.handler.HandlerWrapper handle \""HandlerWrapper.java\"" 122]\n  [org.eclipse.jetty.server.Server handle \""Server.java\"" 563]\n  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch \""HttpChannel.java\"" 1598]\n  [org.eclipse.jetty.server.HttpChannel dispatch \""HttpChannel.java\"" 753]\n  [org.eclipse.jetty.server.HttpChannel handle \""HttpChannel.java\"" 501]\n  [org.eclipse.jetty.server.HttpConnection onFillable \""HttpConnection.java\"" 287]\n  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded \""AbstractConnection.java\"" 314]\n  [org.eclipse.jetty.io.FillInterest fillable \""FillInterest.java\"" 100]\n  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run \""SelectableChannelEndPoint.java\"" 53]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask \""AdaptiveExecutionStrategy.java\"" 421]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask \""AdaptiveExecutionStrategy.java\"" 390]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce \""AdaptiveExecutionStrategy.java\"" 277]\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run \""AdaptiveExecutionStrategy.java\"" 199]\n  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run \""ReservedThreadExecutor.java\"" 411]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob \""QueuedThreadPool.java\"" 969]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob \""QueuedThreadPool.java\"" 1194]\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run \""QueuedThreadPool.java\"" 1149]\n  [java.lang.Thread run nil -1]],\n :cause \""ERROR: syntax error at or near \\\"")\\\""\\n  Position: 50\"",\n :message \""ERROR: syntax error at or near \\\"")\\\""\\n  Position: 50\""}\n"",
      ""exception"": null,
      ""process_uuid"": ""3f3c11f0-b2ec-4772-815c-76cc4c02d929""
    }
```

**To Reproduce**
Steps to reproduce the behavior:
1. Go to an impacted dashboard, in this case: https://reporting.zayzoon.xyz/dashboard/406-transa-dashboard-qbr
2. Click Show Error Details 

**Expected Behavior**
I expect that if there is a query error impacting a card in a dashboard that I am able to edit it to remove the error, and that the error should only prevent the impacted card from delivering results.

**Screenshots**
![Image](https://github.com/user-attachments/assets/2c941118-dbae-4c9e-b318-02a3c0b0f9d9)


**Severity**
It's a moderately serious issue for us as we can't identify what causes it, and the boards it has impacted were in active use. It does not prevent us from creating new dashboards, but it is definitely a hinderance without understanding the cause. If we had an understanding of what causes it we could at least work around the issue for now.

**Additional context**
This is the second dashboard this issue has impacted for us, and while we were able to rebuild the last one, that it is impacting more dashbaords is a concern for us.

**Metabase Diagnostic Info**

```json
""bugReportDetails"": {
    ""metabase-info"": {
      ""databases"": [
        ""postgres"",
        ""redshift""
      ],
      ""run-mode"": ""prod"",
      ""plan-alias"": ""pro-self-hosted-yearly"",
      ""version"": {
        ""date"": ""2024-10-02"",
        ""tag"": ""v1.50.28"",
        ""hash"": ""3179ef2""
      },
      ""settings"": {
        ""report-timezone"": ""America/Edmonton""
      },
      ""hosting-env"": ""unknown"",
      ""application-database"": ""postgres"",
      ""application-database-details"": {
        ""database"": {
          ""name"": ""PostgreSQL"",
          ""version"": ""14.12""
        },
        ""jdbc-driver"": {
          ""name"": ""PostgreSQL JDBC Driver"",
          ""version"": ""42.7.3""
        }
      }
    },
    ""system-info"": {
      ""file.encoding"": ""UTF-8"",
      ""java.runtime.name"": ""OpenJDK Runtime Environment"",
      ""java.runtime.version"": ""11.0.24+8"",
      ""java.vendor"": ""Eclipse Adoptium"",
      ""java.vendor.url"": ""https://adoptium.net/"",
      ""java.version"": ""11.0.24"",
      ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
      ""java.vm.version"": ""11.0.24+8"",
      ""os.name"": ""Linux"",
      ""os.version"": ""5.10.226-214.879.amzn2.x86_64"",
      ""user.language"": ""en"",
      ""user.timezone"": ""GMT""
    }
  }
```",Selisk,2024-10-16 19:40:07+00:00,[],2024-10-16 19:51:17+00:00,2024-10-16 19:51:14+00:00,https://github.com/metabase/metabase/issues/48810,[],"[{'comment_id': 2417811211, 'issue_id': 2592879122, 'author': 'paoliniluis', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/48461', 'created_at': datetime.datetime(2024, 10, 16, 19, 51, 14, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-16 19:51:14 UTC): Duplicate of https://github.com/metabase/metabase/issues/48461

"
2592682883,issue,open,,Multi-select Option for Text Filters (SQL),"**Is your feature request related to a problem? Please describe.**
We are able to select multiple options for field filters, but that option is missing from text filters. In the case, that I am seeing, I am able to pre-select all 20 options in the drop-down text filter, but if I want to change the selection on the Dashboard or Question, I can then only select a single option. I am also unable to go back to select an options. 

**Describe the solution you'd like**
I want to be able to select multiple options with a drop-down text filter. 

**Describe alternatives you've considered**
I am not sure what types of alternatives we could really choose here since the filter is based off a another Question. I cannot use a field filter as I only want to display these 20 options, and the field filter would ultimately display hundreds of options (most not relevant to the Dashboard.

**How important is this feature to you?**
I believe this used to exist, but could be wrong. I feel like this is a definite feature gap that would lead to a better customer experience. There are complaints with the version that is out there, but the report is working, just not like it should.

**Additional context**
N/A",miguel-patientiq,2024-10-16 18:14:34+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/48809,"[('Querying/MBQL', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2592282318,issue,closed,completed,Add webhook icon to alert list modal,"Current Alert list modal doesn't show the number of webhook channels are active on the alert

![Image](https://github.com/user-attachments/assets/80b70f60-e8cb-4763-9a8d-417976ffa7ac)
",npfitz,2024-10-16 15:42:26+00:00,[],2024-10-17 19:51:49+00:00,2024-10-17 19:08:07+00:00,https://github.com/metabase/metabase/issues/48803,[],[],
2592208294,issue,closed,completed,Implement New Color Tokens,https://www.figma.com/design/OlyKP09vro7EkQ2ZzXDDla/Colors?node-id=720-2712&amp;node-type=frame&amp;t=vP0BgaiN0moMhbNh-11,iethree,2024-10-16 15:17:14+00:00,['iethree'],2024-11-12 14:49:13+00:00,2024-11-05 13:50:22+00:00,https://github.com/metabase/metabase/issues/48801,[],[],
2591982900,issue,closed,completed,"Subscriptions: Dashboard is squeezed in email body, not using full width as it is in Metabase - v50.10","### Describe the bug

Metabase v50.10

Still dashboards are squeezed in the email and they don't look like in Metabase. 
Do I miss something? Any configuration or Env var that I need to add?
I thought this would change with v50, reading that in release  notes:
""Chart appearance in subscriptions the same as in Metabase (https://github.com/metabase/metabase/issues/41764)""

I have updated from v49.1 to v50.10, still no luck.

In Metabase:
![Image](https://github.com/user-attachments/assets/b0ef9366-a495-4576-9a62-facc02a73ca2)

In email body:
![Image](https://github.com/user-attachments/assets/7cc50555-e467-41dd-b713-ab1b2603f6db)



### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Metabase v50.10

### Severity

Minor

### Additional context

_No response_",MyckeTap,2024-10-16 13:56:04+00:00,[],2024-10-17 01:30:54+00:00,2024-10-17 01:30:53+00:00,https://github.com/metabase/metabase/issues/48797,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2418307659, 'issue_id': 2591982900, 'author': 'alxnddr', 'body': ""Hey @MyckeTap 👋 While individual chart types now have improved feature parity between the app and emails, the overall dashboard layout and responsiveness in emails remain limited due to email client constraints. In emails, we can't have a responsive dashboard that adjusts to different screen widths, so emails have fixed-width charts displayed as a list.\n\nHowever, we could render entire dashboards as images or PDF files. There's an existing issue for this feature: https://github.com/metabase/metabase/issues/34907"", 'created_at': datetime.datetime(2024, 10, 17, 1, 30, 53, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-10-17 01:30:53 UTC): Hey @MyckeTap 👋 While individual chart types now have improved feature parity between the app and emails, the overall dashboard layout and responsiveness in emails remain limited due to email client constraints. In emails, we can't have a responsive dashboard that adjusts to different screen widths, so emails have fixed-width charts displayed as a list.

However, we could render entire dashboards as images or PDF files. There's an existing issue for this feature: https://github.com/metabase/metabase/issues/34907

"
2591910836,issue,open,,Add Short Query Optimized connection string option to BigQuery,"**Is your feature request related to a problem? Please describe.**
A customer would like the ability for BigQuery to have JDBC connection string options that some other databases have to pass additional parameters like the following
https://cloud.google.com/bigquery/docs/running-queries#short-query-optimized


",FilmonK,2024-10-16 13:33:58+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/48795,"[('Type:New Feature', ''), ('Database/BigQuery', '')]",[],
2591868409,issue,closed,completed,SDK fails to release when there is no changelog change,"### Describe the bug

[Reported on Slack](https://metaboat.slack.com/archives/C063Q3F1HPF/p1729083238841149).

Example of the failed release: https://github.com/metabase/metabase/actions/runs/11363317518

This is probably the first time we tried to release from a release branch. There is no `CHANGELOG.MD` file in the release branch that's why it failed.

### To Reproduce

Release the SDK from the branch without `enterprise/frontend/src/embedding-sdk/CHANGELOG.md`

### Expected behavior

The release process should complete even if there's no changelog.

### Logs

_No response_

### Information about your Metabase installation

-

### Severity

mild since this doesn't happen often

### Additional context

_No response_",WiNloSt,2024-10-16 13:16:49+00:00,['WiNloSt'],2024-10-16 15:49:58+00:00,2024-10-16 15:49:49+00:00,https://github.com/metabase/metabase/issues/48794,"[('Type:Bug', 'Product defects'), ('.CI & Tests', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2417235390, 'issue_id': 2591868409, 'author': 'WiNloSt', 'body': 'Closing as we now have released npm v0.1.39 with `release-x.51.x`', 'created_at': datetime.datetime(2024, 10, 16, 15, 49, 49, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-10-16 15:49:49 UTC): Closing as we now have released npm v0.1.39 with `release-x.51.x`

"
2591593022,issue,closed,completed,Hiding columns in InteractiveQuestion in the sdk throws a JavaScript error,"Hiding columns in InteractiveQuestion throws a JavaScript error in the embedding sdk.

### Screenshot

When clicking on ""Hide Column""

<img src=""https://github.com/user-attachments/assets/2a92794c-cf71-4eb7-be80-13bb3754b223"" width=""200"">

JavaScript error is thrown

```tsx
Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'query')
    at visualization-settings.js:36:58
    at Object.dispatch (redux-thunk.mjs:5:14)
    at dispatch (page.bundle.js:6:7424)
    at pR (action.js:12:7)
    at ClickActionsPopover.tsx:56:26
    at onClick (ClickActionsView.tsx:52:32)
    at o10 (ClickActionControl.tsx:53:15)
    at HTMLUnknownElement.callCallback2 (react-dom.development.js:4164:14)
    at Object.invokeGuardedCallbackDev (react-dom.development.js:4213:16)
    at invokeGuardedCallback (react-dom.development.js:4277:31)
```

<img src=""https://github.com/user-attachments/assets/f7d86524-c2ab-4daf-8f84-447e628302c3"" width=""400"">
",heypoom,2024-10-16 11:34:31+00:00,['heypoom'],2024-10-25 14:34:41+00:00,2024-10-25 13:36:09+00:00,https://github.com/metabase/metabase/issues/48789,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2421006750, 'issue_id': 2591593022, 'author': 'heypoom', 'body': 'This is caused by the click actions popover referencing `getQuestion` to get question from the Redux store, which the SDK does not have.\n\n```ts\nconst question = getQuestion(getState());\n```', 'created_at': datetime.datetime(2024, 10, 18, 0, 53, 58, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-10-18 00:53:58 UTC): This is caused by the click actions popover referencing `getQuestion` to get question from the Redux store, which the SDK does not have.

```ts
const question = getQuestion(getState());
```

"
2591577051,issue,closed,completed,Save button in InteractiveQuestion is not visible when isSaveEnabled is true in the sdk,"When rendering the InteractiveQuestion with `isSaveEnabled`, the save button is not visible.

> The `isSaveEnabled` prop on `<InteractiveQuestion />` doesn’t work (the save button or the save form isn't rendering). However, using `<InteractiveQuestion.saveButton />` and `<InteractiveQuestion.saveQuestionForm />` separately works fine.
",heypoom,2024-10-16 11:27:50+00:00,['heypoom'],2024-10-24 21:33:25+00:00,2024-10-24 20:49:39+00:00,https://github.com/metabase/metabase/issues/48788,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2591473491,issue,closed,completed,Extra filter stage breaks pivot table drills,"### Repro steps #1

1. `git checkout dbfd4618ef5b981933035752c3b7bf81a26bd026`
    - it's branch `48445-unit-of-time-and-other-stages-tests` (#48726)
2. Run this test: https://github.com/metabase/metabase/blob/dcc33cebdfcd406f2a9bfb7359fcbe76f1446f7a/e2e/test/scenarios/dashboard-filters/temporal-unit-parameters.cy.spec.js#L401

### Repro steps #2

1. `git checkout dbfd4618ef5b981933035752c3b7bf81a26bd026`
2. Create a question with aggregation and 2 temporal breakouts in the last stage (e.g. Orders > Count > Breakout by Product Created At > Breakout by Order Created At)
3. Add it to dashboard and save it
4. Notice that POST `/api/dashboard/:id/dashcard/:id/card/:id/query` will give `data.cols[].source === ""aggregation""` for the aggregation column ([screenshot](https://github.com/user-attachments/assets/bec2a230-186e-4360-97cd-794dbc8b4426))
5. Add unit of time parameter to the dashboard and connect it to the dashcard
6. Save dashboard
7. Notice that POST `/api/dashboard/:id/dashcard/:id/card/:id/query` will now give `data.cols[].source === ""fields""` for the aggregation column ([screenshot](https://github.com/user-attachments/assets/491d3870-cd0b-4fb4-b8fe-e8e9dc368439))


This breaks FE logic detecting whether pivot table should be used: https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/frontend/src/metabase/visualizations/visualizations/Table.tsx#L97

`data.cols.filter(isDimension).length` will be `3` instead of `2`

### Additional info

It's the mere presence of `{ ""stage-number"": -2 }` in `dashboard.dashcards[].parameter_mappings[].target` that causes this.

We can't simply remove this because FE depends on the presence of this information when applying dashboard filters and parameters to a dashcard when clicking on its title (which navigates to an ad-hoc question).

### Non-negative stage indexes

Using [non-negative stage indexes](https://github.com/metabase/metabase/issues/48441) could possible help with this.
OTOH it may cause some issues with composed ad-hoc questions on FE side where we use virtual tables to use models and metrics as query source.",kamilmielnik,2024-10-16 10:49:44+00:00,[],2024-10-18 13:52:38+00:00,2024-10-18 13:52:02+00:00,https://github.com/metabase/metabase/issues/48787,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2416763025, 'issue_id': 2591473491, 'author': 'kamilmielnik', 'body': '### Repro steps #3\n\n1. `git checkout dbfd4618ef5b981933035752c3b7bf81a26bd026`\n2. Run this test: https://github.com/metabase/metabase/blob/dcc33cebdfcd406f2a9bfb7359fcbe76f1446f7a/e2e/test/scenarios/dashboard-filters/temporal-unit-parameters.cy.spec.js#L471\n\nThe root cause of this issue looks the same.\nIn this case we\'re getting unexpected:\n- `data.cols[].source === ""fields""` instead of `data.cols[].source === ""breakout""`\n- `data.cols[].field_ref[2]` is missing `""temporal-unit""` attribute', 'created_at': datetime.datetime(2024, 10, 16, 12, 54, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418862143, 'issue_id': 2591473491, 'author': 'kamilmielnik', 'body': 'The following e2e tests are failing in `48445-unit-of-time-and-other-stages-tests` (#48726) due to this issue:\n- `multiple-column-breakouts.cy.spec.ts`\n    - `should be able to use temporal-unit parameters with multiple temporal breakouts of a column`\n- `visualizations-tabular/pivot_tables.cy.spec.js`\n    - `should allow filtering drill through (metabase#14632) (metabase#14465)`\n- `temporal-unit-parameters.cy.spec.js`\n    - `should connect a parameter to a question and drill thru`\n    - `should connect multiple parameters to a card with multiple breakouts and drill thru`', 'created_at': datetime.datetime(2024, 10, 17, 8, 11, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421013733, 'issue_id': 2591473491, 'author': 'ranquild', 'body': ""@kamilmielnik the `source` is actually correct and it's not a BE bug. We get an extra stage which changes `source`. Which is bad news for us because the FE needs to be fixed, but (!) pivot tables are just built this way so they rely on presence of aggregations and breakouts in the last stage."", 'created_at': datetime.datetime(2024, 10, 18, 1, 1, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422530072, 'issue_id': 2591473491, 'author': 'kamilmielnik', 'body': 'We [decided](https://metaboat.slack.com/archives/C0645JP1W81/p1729213440034179) to not use the extra filtering stage for pivot tables.\nClosing in favor of #48884 and #48885.', 'created_at': datetime.datetime(2024, 10, 18, 13, 52, 2, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-16 12:54:19 UTC): ### Repro steps #3

1. `git checkout dbfd4618ef5b981933035752c3b7bf81a26bd026`
2. Run this test: https://github.com/metabase/metabase/blob/dcc33cebdfcd406f2a9bfb7359fcbe76f1446f7a/e2e/test/scenarios/dashboard-filters/temporal-unit-parameters.cy.spec.js#L471

The root cause of this issue looks the same.
In this case we're getting unexpected:
- `data.cols[].source === ""fields""` instead of `data.cols[].source === ""breakout""`
- `data.cols[].field_ref[2]` is missing `""temporal-unit""` attribute

kamilmielnik (Issue Creator) on (2024-10-17 08:11:53 UTC): The following e2e tests are failing in `48445-unit-of-time-and-other-stages-tests` (#48726) due to this issue:
- `multiple-column-breakouts.cy.spec.ts`
    - `should be able to use temporal-unit parameters with multiple temporal breakouts of a column`
- `visualizations-tabular/pivot_tables.cy.spec.js`
    - `should allow filtering drill through (metabase#14632) (metabase#14465)`
- `temporal-unit-parameters.cy.spec.js`
    - `should connect a parameter to a question and drill thru`
    - `should connect multiple parameters to a card with multiple breakouts and drill thru`

ranquild on (2024-10-18 01:01:39 UTC): @kamilmielnik the `source` is actually correct and it's not a BE bug. We get an extra stage which changes `source`. Which is bad news for us because the FE needs to be fixed, but (!) pivot tables are just built this way so they rely on presence of aggregations and breakouts in the last stage.

kamilmielnik (Issue Creator) on (2024-10-18 13:52:02 UTC): We [decided](https://metaboat.slack.com/archives/C0645JP1W81/p1729213440034179) to not use the extra filtering stage for pivot tables.
Closing in favor of #48884 and #48885.

"
2591245401,issue,closed,completed,[SPIKE] check feasibility of component testing for the sdk,"# What
This spike is to experiment with component testing to see if it solves the issues described on [Embedding sdk e2e tests](https://www.notion.so/metabase/Embedding-sdk-e2e-tests-11169354c901804cbdb0e1a1cdb41ea3)

# Why now
It's a good moment to investigate this as [embedding-sdk:dev: --watch that makes ""fixed"" dts](https://github.com/metabase/metabase/pull/48574) should unlock the ability to use the build package with reasonable watch speed.

# Goals of the spike
- see if cypress/playwright component testing work with our sdk
- see how much configuration is needed
- see if the performances on watch is reasonable with the built package, if not see if it's easy to make it work with the source code directly (although it would be less ""e2e-y""
- document the points above so that we can discuss the results and decide how to move forward",npretto,2024-10-16 09:28:37+00:00,['npretto'],2024-10-22 07:35:08+00:00,2024-10-22 07:35:07+00:00,https://github.com/metabase/metabase/issues/48784,"[('.Team/Embedding', '')]","[{'comment_id': 2417366340, 'issue_id': 2591245401, 'author': 'npretto', 'body': 'Temporary results\n\n- component testing works out of the box using vite + package sdk from npm (so `yarn add @metabase/embedding-sdk-react` and then `import {...} from \'@metabase/embedding-sdk-react\'`)\n    - it looks it\'s impossible though to make vite reload a non-esm package without having to re-install it and clean the cache, which is a terrible dev-ex\n- with webpack, it works if we don\'t use our webpack config and we use the package fron npm\n    - i haven\'t found a way to make it reload the package without re-installing it though, so not very helpful either\n- as last try, I tried to make cypress use our webpack config so it could read directly our code, it seems to crash without any useful error message as soon as we import something from our code, i suspect it\'s because [branch with code here](https://github.com/metabase/metabase/pull/48806)\n\nI _think_ that component tests compile what you pass to `cy.mount` ""on the fly"" and sends the js code to the webpack/vite dev server over network, this was most likely not built with the idea of sending 5-10Mbs of js so it runs into all sort of issues and crashes', 'created_at': datetime.datetime(2024, 10, 16, 16, 40, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428485164, 'issue_id': 2591245401, 'author': 'npretto', 'body': 'Closing, results are here: https://github.com/metabase/metabase/pull/48943', 'created_at': datetime.datetime(2024, 10, 22, 7, 35, 7, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-10-16 16:40:29 UTC): Temporary results

- component testing works out of the box using vite + package sdk from npm (so `yarn add @metabase/embedding-sdk-react` and then `import {...} from '@metabase/embedding-sdk-react'`)
    - it looks it's impossible though to make vite reload a non-esm package without having to re-install it and clean the cache, which is a terrible dev-ex
- with webpack, it works if we don't use our webpack config and we use the package fron npm
    - i haven't found a way to make it reload the package without re-installing it though, so not very helpful either
- as last try, I tried to make cypress use our webpack config so it could read directly our code, it seems to crash without any useful error message as soon as we import something from our code, i suspect it's because [branch with code here](https://github.com/metabase/metabase/pull/48806)

I _think_ that component tests compile what you pass to `cy.mount` ""on the fly"" and sends the js code to the webpack/vite dev server over network, this was most likely not built with the idea of sending 5-10Mbs of js so it runs into all sort of issues and crashes

npretto (Issue Creator) on (2024-10-22 07:35:07 UTC): Closing, results are here: https://github.com/metabase/metabase/pull/48943

"
2591137514,issue,open,,Include selected database in SQL editor URL,"My biggest use-case - by far - for Metabase is writing ad-hoc queries to our production database mirror.

To do so, I always take the following steps:
1. Open Metabase
2. Click on ""New""
3. Select ""SQL query""
4. Select the correct database

I would love for this to be one click to a bookmark.

I can manage to get to step 3 by copying the URL after selecting ""SQL query"", however it is very obscure and potentially not permanent. And more so, I cannot achieve the same for the entire process by copying the URL after selecting a database.",franzliedke,2024-10-16 08:51:52+00:00,[],2025-02-04 20:31:01+00:00,,https://github.com/metabase/metabase/issues/48783,"[('Type:New Feature', ''), ('Querying/Native', 'The SQL/native query editor')]","[{'comment_id': 2471274007, 'issue_id': 2591137514, 'author': 'JulianHinsch', 'body': '+1, this is a big gripe of mine and could very easily be solved', 'created_at': datetime.datetime(2024, 11, 12, 18, 28, 56, tzinfo=datetime.timezone.utc)}]","JulianHinsch on (2024-11-12 18:28:56 UTC): +1, this is a big gripe of mine and could very easily be solved

"
2591104940,issue,open,,[Spike] see if we can isolate the scripts and config files for the sdk from the root ones,"After [embedding-sdk:dev: --watch that makes ""fixed"" dts](https://github.com/metabase/metabase/pull/48574) (still open at the time of writing) we have ~18 scripts related to the sdk in the main package.json, they're not all grouped together (because we have the scripts sorted alphabetically but our scripts sometime have `sdk` later on in the name).
We also have some configuration for the sdk inside the [root storybook config file](https://github.com/metabase/metabase/blob/ed24366ea9855cb4e5f41eb76eef06d80e4ba21f/.storybook/main.js) (where we basically opt out of some configuration), and the webpack config file that lives in the root folder, same for the tsconfig file,  while the actual code is nested in `enterprise/frontend/src/embedding-sdk`.

I think it would be cleaner to have our own config files + scripts all grouped together in a ""sdk folder"" (TBD if it should be `enterprise/frontend/src/embedding-sdk` or something a few folders up so that it's close to the root).

I believe the most annoying part for now is the scripts, as it's becoming hard to parse the main package.json and understand what the commands are doing (or even which scripts are for the sdk). I tried [something](https://github.com/metabase/metabase/commit/7c4b3817498b8894708809b649c075fbb8c3a207) to move the scripts to their own package.json but that specific solution required a lot of ""../"" in the commands as we expect to run a lot of commands from the root folder, as that's where we have the config files. For this reason it *could* be easier to address both the scripts and the config files at the same time.


## Other things we could look into
- yarn workspaces (but I think we'd need to make the core app a workspace, which should be nested in a folder, so this would require an RFC and agreement with the other FE teams)
- custom ""sdk"" nodejs script that accept a sub command and we can do whatever we want with it, this would allow co-location of comments too which may be good actually
- some other build tool, as the sdk is it's own little thing, we could experiment with wireit or similar tool. We had some people wanting to do it on the main app but the main reason we didn't was that it would require a lot of setup to make it work safely with the caches etc",npretto,2024-10-16 08:40:06+00:00,[],2025-02-04 20:25:55+00:00,,https://github.com/metabase/metabase/issues/48781,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2591087943,issue,open,,Version compatibility metabase and database - Documentation,"**Is your feature request related to a problem? Please describe.**
_A clear and concise description of what the problem is. Ex. I'm always frustrated when_ I'm updating Metabase and I cannot find which database version of postgres is compatible.

**Describe the solution you'd like**
_A clear and concise description of what you want to happen._
Updated docs that tell me for each version which database versions are compatible. Other sites refer to 'the official docs' but I can't find them.

_I would like_ to see on [this](https://www.metabase.com/docs/v0.51/databases/connecting) page or on [this](https://www.metabase.com/docs/v0.51/databases/connections/postgresql) page which version is minimum and maximum supported. 
Also on the release page of github and in the upgrade instructions I would expect a version compatibility definition.

Thanks!
",Ruud-cb,2024-10-16 08:33:02+00:00,[],2025-02-04 20:31:08+00:00,,https://github.com/metabase/metabase/issues/48780,"[('Type:Documentation', ''), ('Type:New Feature', '')]","[{'comment_id': 2416340621, 'issue_id': 2591087943, 'author': 'paoliniluis', 'body': '@jeff-bruemmer', 'created_at': datetime.datetime(2024, 10, 16, 10, 7, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-16 10:07:33 UTC): @jeff-bruemmer

"
2590943490,issue,closed,completed,Investigate why loki assets are not uploaded when the test fails,"https://metaboat.slack.com/archives/C010L1Z4F9S/p1729062724307509

Loki tests are being flaky and it's affecting other teams, the workflow is supposed to upload the results but for some reason it's not, this makes troubleshooting the flakes almost impossible


GH actions that failed and didn't upload anything:

https://github.com/metabase/metabase/actions/runs/11348457207/job/31562292587",npretto,2024-10-16 07:37:20+00:00,[],2024-10-16 09:07:09+00:00,2024-10-16 08:50:32+00:00,https://github.com/metabase/metabase/issues/48778,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2590571720,issue,closed,completed,Cannot update metabase 0.47.1 to 0.50.29,"### Describe the bug

I am unable to update to 0.50.29. It corrupts my database and does not load anything and is stuck at start of the page.

For now, I have reverted back to the previous version.

Do I need some specific postgres version or mine is fine?
Do I need to update next version from 0.47.1 or can I upgrade directly to 0.50?

### To Reproduce

Stop service : systemctl stop metabase
download .jar : wget ....
made backup of existing jar
replaced main jar with downloaded jar 
start service : systemctl start metabase

### Expected behavior

_No response_

### Logs

Oct 15 05:46:43 ip-172-0-2-143 metabase[2107164]: Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""date""
Oct 15 05:46:43 ip-172-0-2-143 metabase[2107164]:   Position: 184
Oct 15 05:46:43 ip-172-0-2-143 metabase[2107164]: #011... 199 more
Oct 15 05:46:43 ip-172-0-2-143 metabase[2107164]: 2024-10-15 05:46:43,123 INFO metabase.core :: Metabase Shutting Down ...

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8-post-Ubuntu-1ubuntu320.04"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8-post-Ubuntu-1ubuntu320.04"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1070-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""csv"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-09-07"",
      ""tag"": ""v0.47.1"",
      ""branch"": ""release-x.47.x"",
      ""hash"": ""bd278b9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

### Severity

Critical

### Additional context

_No response_",abdulwahab20029,2024-10-16 04:25:35+00:00,[],2024-10-16 13:02:57+00:00,2024-10-16 13:02:55+00:00,https://github.com/metabase/metabase/issues/48775,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2415815611, 'issue_id': 2590571720, 'author': 'paoliniluis', 'body': 'Please post full logs', 'created_at': datetime.datetime(2024, 10, 16, 6, 9, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416444290, 'issue_id': 2590571720, 'author': 'abdulwahab20029', 'body': '> Please post full logs\n[log_metabase_update.log](https://github.com/user-attachments/files/17394672/log_metabase_update.log)\n\n@paoliniluis logs uploaded. Let me know if you need more logs.', 'created_at': datetime.datetime(2024, 10, 16, 10, 48, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416620973, 'issue_id': 2590571720, 'author': 'dpsutton', 'body': 'We are running a custom migration at https://github.com/metabase/metabase/blob/master/src/metabase/db/custom_migrations.clj#L951-L1029 to unify the date types in the application db.\n\nThe query run to get these is\n\n```sql\n SELECT table_name,\n       column_name,\n       is_nullable\nFROM   information_schema.columns\nWHERE  (\n              data_type = \'timestamp without time zone\')\nAND    (\n              table_schema = current_schema())\nAND    (\n              table_catalog = current_database()) \n```\n\nFor some reason this is picking up the table `view_bad_pv_maping_cloud` which is not a table that should be in the metabase application db.\n\nIt\'s running the sql\n\n```sql\n ALTER TABLE ""view_bad_pv_maping_cloud"" ALTER COLUMN ""installation date"" TYPE timestamp WITH time zone\nusing       (""installation date""::timestamp WITH time zone),\n            ALTER COLUMN installation date DROP NOT NULL \n```\n\nAnd it looks like what is happening is that this table has a column with a space in its name which we don\'t handle. `ALTER COLUMN installation date DROP NOT NULL` would have to quote `""installation date""` to be valid.\n\nWe expect to be the exclusive source of tables in the application database. Other tables is unsupported and results in errors like this.', 'created_at': datetime.datetime(2024, 10, 16, 12, 3, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416631577, 'issue_id': 2590571720, 'author': 'dpsutton', 'body': ""I started up a 0.47.12 jar and see the expected tables as the following:\n\n```sql\n SELECT table_name,\n       column_name,\n       is_nullable\nFROM   information_schema.columns\nWHERE  (\n              data_type = 'timestamp without time zone')\nAND    (\n              table_schema = current_schema())\nAND    (\n              table_catalog = current_database()) ;\n              table_name              | column_name  | is_nullable\n--------------------------------------+--------------+-------------\n databasechangelog                    | dateexecuted | NO\n databasechangeloglock                | lockgranted  | YES\n core_user                            | updated_at   | YES\n data_migrations                      | timestamp    | NO\n permissions_revision                 | created_at   | NO\n collection_permission_graph_revision | created_at   | NO\n computation_job_result               | created_at   | NO\n computation_job_result               | updated_at   | NO\n computation_job                      | created_at   | NO\n computation_job                      | updated_at   | NO\n computation_job                      | ended_at     | YES\n dimension                            | created_at   | NO\n dimension                            | updated_at   | NO\n application_permissions_revision     | created_at   | NO\n(14 rows)\n```\n\nThis is what we expect to migrate. (although we have logic to remove `databasechangelog`, `databasechangeloglock`, and some views that start with `v_` from this migration.)"", 'created_at': datetime.datetime(2024, 10, 16, 12, 8, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416781916, 'issue_id': 2590571720, 'author': 'abdulwahab20029', 'body': '@dpsutton Noted. Thanks', 'created_at': datetime.datetime(2024, 10, 16, 13, 2, 55, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-16 06:09:47 UTC): Please post full logs

abdulwahab20029 (Issue Creator) on (2024-10-16 10:48:14 UTC): [log_metabase_update.log](https://github.com/user-attachments/files/17394672/log_metabase_update.log)

@paoliniluis logs uploaded. Let me know if you need more logs.

dpsutton on (2024-10-16 12:03:51 UTC): We are running a custom migration at https://github.com/metabase/metabase/blob/master/src/metabase/db/custom_migrations.clj#L951-L1029 to unify the date types in the application db.

The query run to get these is

```sql
 SELECT table_name,
       column_name,
       is_nullable
FROM   information_schema.columns
WHERE  (
              data_type = 'timestamp without time zone')
AND    (
              table_schema = current_schema())
AND    (
              table_catalog = current_database()) 
```

For some reason this is picking up the table `view_bad_pv_maping_cloud` which is not a table that should be in the metabase application db.

It's running the sql

```sql
 ALTER TABLE ""view_bad_pv_maping_cloud"" ALTER COLUMN ""installation date"" TYPE timestamp WITH time zone
using       (""installation date""::timestamp WITH time zone),
            ALTER COLUMN installation date DROP NOT NULL 
```

And it looks like what is happening is that this table has a column with a space in its name which we don't handle. `ALTER COLUMN installation date DROP NOT NULL` would have to quote `""installation date""` to be valid.

We expect to be the exclusive source of tables in the application database. Other tables is unsupported and results in errors like this.

dpsutton on (2024-10-16 12:08:15 UTC): I started up a 0.47.12 jar and see the expected tables as the following:

```sql
 SELECT table_name,
       column_name,
       is_nullable
FROM   information_schema.columns
WHERE  (
              data_type = 'timestamp without time zone')
AND    (
              table_schema = current_schema())
AND    (
              table_catalog = current_database()) ;
              table_name              | column_name  | is_nullable
--------------------------------------+--------------+-------------
 databasechangelog                    | dateexecuted | NO
 databasechangeloglock                | lockgranted  | YES
 core_user                            | updated_at   | YES
 data_migrations                      | timestamp    | NO
 permissions_revision                 | created_at   | NO
 collection_permission_graph_revision | created_at   | NO
 computation_job_result               | created_at   | NO
 computation_job_result               | updated_at   | NO
 computation_job                      | created_at   | NO
 computation_job                      | updated_at   | NO
 computation_job                      | ended_at     | YES
 dimension                            | created_at   | NO
 dimension                            | updated_at   | NO
 application_permissions_revision     | created_at   | NO
(14 rows)
```

This is what we expect to migrate. (although we have logic to remove `databasechangelog`, `databasechangeloglock`, and some views that start with `v_` from this migration.)

abdulwahab20029 (Issue Creator) on (2024-10-16 13:02:55 UTC): @dpsutton Noted. Thanks

"
2590236158,issue,closed,not_planned,Color options for numbers visualization,"**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
We heavily use Cards in Power BI on our dashboard and we color coded some significant value, sometimes even with conditional formatting too. It would be amazing if Metabase can support this as well.

**Describe the solution you'd like**
A clear and concise description of what you want to happen.
Option to select static color and dynamic color depending on its conditional formatting

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.
n/a

**How important is this feature to you?**
![Image](https://github.com/user-attachments/assets/d6f3bef1-1bda-4cd2-9745-43a487869cea)
We use it a lot before migrating to Metabase

**Additional context**
Add any other context or screenshots about the feature request here.
![Image](https://github.com/user-attachments/assets/69bd3f48-ee53-4caf-9e4c-e36213c4cf9e)
_Image off Power BI_

",tatuhey,2024-10-16 00:21:23+00:00,[],2024-10-17 18:24:58+00:00,2024-10-17 18:24:56+00:00,https://github.com/metabase/metabase/issues/48774,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2420241684, 'issue_id': 2590236158, 'author': 'paoliniluis', 'body': 'similar, if not the same as https://github.com/metabase/metabase/issues/48142', 'created_at': datetime.datetime(2024, 10, 17, 18, 24, 57, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-17 18:24:57 UTC): similar, if not the same as https://github.com/metabase/metabase/issues/48142

"
2590171853,issue,open,,Filter Fails in Multi Level Aggregate for Model Based on SQL Questions,"### Describe the bug

If a model is based on a SQL question, users with GUI access (but not native access) cannot apply filters after the aggregate stage in the GUI builder.

### To Reproduce

1. Create a SQL questions and promote it to a model
2. Set up a user with no native access to DB the model was built on
3. Log in as the user and view the model
4. Join a table onto the model and see the preview works
5. Add a group and a summary and see the preview still works
6. Post aggregate try to add a filter and preview the results or save the question
7. See error ""You do not have permission to run this query""


https://www.loom.com/share/7745358cca984898985880f7e8ff674a?sid=25fd27e2-a2af-44ff-bd6b-007338c98fde

### Expected behavior

If they have access otherwise then this should work.

### Logs

_No response_

### Information about your Metabase installation

Tested in v50 and v47

### Severity

Blocking some business users from leveraging models

### Additional context

Customer said they noticed this behavior a long time ago but they've generally been able to work around it. Now they're asking us to look at it because it's become a blocker for some deliverables.",ixipixi,2024-10-15 23:38:58+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/48771,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]",[],
2589981491,issue,closed,not_planned,Upgrade to 0.50.29 fails with missing column report_card.dataset,"### Describe the bug

Metabase goes into a loop after upgrading from v0.50.0-RC2 to 0.50.29. The following column is missing:
report_card.dataset

[Failed SQL: (1054) ALTER TABLE `metabase`.`report_card` MODIFY `dataset` BIT(1)]

Oct 15 15:34:21 host01 metabase[3459389]:         ... 90 more
Oct 15 15:34:21 host01 metabase[3459389]: UPDATE SUMMARY
Oct 15 15:34:21 host01 metabase[3459389]: Run:                         67
Oct 15 15:34:21 host01 metabase[3459389]: Previously run:             345
Oct 15 15:34:21 host01 metabase[3459389]: Filtered out:                 5
Oct 15 15:34:21 host01 metabase[3459389]: -------------------------------
Oct 15 15:34:21 host01 metabase[3459389]: Total change sets:          417
Oct 15 15:34:21 host01 metabase[3459389]: FILTERED CHANGE SETS SUMMARY
Oct 15 15:34:21 host01 metabase[3459389]: DBMS mismatch:                5
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: UPDATE SUMMARY
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: Run:                         67
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: Previously run:             345
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: Filtered out:                 5
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: -------------------------------
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,231 INFO liquibase.util :: Total change sets:          417
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,232 INFO liquibase.util :: FILTERED CHANGE SETS SUMMARY
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,232 INFO liquibase.util :: DBMS mismatch:                5
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,234 INFO liquibase.util :: Update summary generated
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,236 INFO liquibase.command :: Update command encountered an exception.
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,241 INFO liquibase.lockservice :: Successfully released change log lock
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,242 INFO liquibase.command :: Logging exception.
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,243 INFO liquibase.command :: Command execution complete
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,245 INFO liquibase.lockservice :: Successfully released change log lock
Oct 15 15:34:21 host01 metabase[3459389]: 2024-10-15 15:34:21,276 ERROR metabase.core :: Metabase Initialization FAILED


### To Reproduce

Attempt to upgrade from v0.50.0-RC2 to 0.50.29.


### Expected behavior

It should correctly deal with missing column.

### Logs

These are the relevant log entries:


Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-05-29T09:26:20::johnswanson:
Oct 15 15:13:43 host01 metabase[3440275]:      Reason: liquibase.exception.DatabaseException: (conn=684) Unknown column 'dataset' in 'report_card' [Failed SQL: (1054) ALTER TABLE `metabase`.`report_card` MODIFY `dataset` BIT(1)]
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.lambda$child$0(Scope.java:186)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:195)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:185)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:164)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.lambda$child$0(Scope.java:186)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:195)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:185)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:164)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:252)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.Scope.child(Scope.java:256)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
Oct 15 15:13:43 host01 metabase[3440275]:         ... 66 more
Oct 15 15:13:43 host01 metabase[3440275]: Caused by: liquibase.exception.DatabaseException: (conn=684) Unknown column 'dataset' in 'report_card' [Failed SQL: (1054) ALTER TABLE `metabase`.`report_card` MODIFY `dataset` BIT(1)]
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
Oct 15 15:13:43 host01 metabase[3440275]:         ... 81 more
Oct 15 15:13:43 host01 metabase[3440275]: Caused by: java.sql.SQLSyntaxErrorException: (conn=684) Unknown column 'dataset' in 'report_card'
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
Oct 15 15:13:43 host01 metabase[3440275]:         at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
Oct 15 15:13:43 host01 metabase[3440275]:         at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
Oct 15 15:13:43 host01 metabase[3440275]:         ... 86 more
Oct 15 15:13:43 host01 metabase[3440275]: Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Unknown column 'dataset' in 'report_card'
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
Oct 15 15:13:43 host01 metabase[3440275]:         ... 89 more
Oct 15 15:13:43 host01 metabase[3440275]: Caused by: java.sql.SQLException: Unknown column 'dataset' in 'report_card'
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
Oct 15 15:13:43 host01 metabase[3440275]:         at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
Oct 15 15:13:43 host01 metabase[3440275]:         ... 90 more


### Information about your Metabase installation

:: System info:
Oct 15 15:29:55 host01 metabase[3455052]:  {""file.encoding"" ""UTF-8"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.runtime.version"" ""17.0.12+7"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.vendor"" ""Eclipse Adoptium"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.vendor.url"" ""https://adoptium.net/"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.version"" ""17.0.12"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""java.vm.version"" ""17.0.12+7"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""os.name"" ""Linux"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""os.version"" ""4.18.0-553.22.1.el8_10.x86_64"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""user.language"" ""en"",
Oct 15 15:29:55 host01 metabase[3455052]:  ""user.timezone"" ""America/New_York""}


### Severity

We've reverted back to previous version

### Additional context

_No response_",cabarria,2024-10-15 21:35:15+00:00,[],2024-10-29 23:45:58+00:00,2024-10-29 23:45:58+00:00,https://github.com/metabase/metabase/issues/48763,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2415276170, 'issue_id': 2589981491, 'author': 'paoliniluis', 'body': 'What version of MySQL are you running? Also, please always use Java 11', 'created_at': datetime.datetime(2024, 10, 15, 22, 25, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417507878, 'issue_id': 2589981491, 'author': 'cabarria', 'body': '> What version of MySQL are you running? Also, please always use Java 11\n\n8.0.36 (Source distribution)\n\nI downgraded to java 11 and the same issue persists\n{""file.encoding"" ""UTF-8"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.runtime.name"" ""OpenJDK Runtime Environment"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.runtime.version"" ""11.0.24+8-LTS"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.vendor"" ""Red Hat, Inc."",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.vendor.url"" ""https://www.redhat.com/"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.version"" ""11.0.24"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\nOct 16 13:55:19 host01 metabase[497049]:  ""java.vm.version"" ""11.0.24+8-LTS"",\nOct 16 13:55:19 host01 metabase[497049]:  ""os.name"" ""Linux"",\nOct 16 13:55:19 host01 metabase[497049]:  ""os.version"" ""4.18.0-553.22.1.el8_10.x86_64"",\nOct 16 13:55:19 host01 metabase[497049]:  ""user.language"" ""en"",\nOct 16 13:55:19 host01 metabase[497049]:  ""user.timezone"" ""America/New_York""}', 'created_at': datetime.datetime(2024, 10, 16, 17, 48, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445231174, 'issue_id': 2589981491, 'author': 'cabarria', 'body': 'Any ideas why does it fail with unknown column dataset?', 'created_at': datetime.datetime(2024, 10, 29, 20, 9, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445523796, 'issue_id': 2589981491, 'author': 'paoliniluis', 'body': ""@cabarria there's a migration missing most definitely. Some previous migration on your app db didn't run and now you're hitting this.\n\nThis is the DDL of the table that has an error, please adapt your table to this:\n```\ncreate table if not exists metabase.report_card\n(\n    id                     int auto_increment\n        primary key,\n    created_at             timestamp(6)                   not null,\n    updated_at             timestamp(6)                   null,\n    name                   varchar(254)                   not null,\n    description            longtext                       null,\n    display                varchar(254)                   not null,\n    dataset_query          longtext                       null,\n    visualization_settings longtext                       null,\n    creator_id             int                            not null,\n    database_id            int                            not null,\n    table_id               int                            null,\n    query_type             varchar(16)                    null,\n    archived               bit         default b'0'       not null,\n    collection_id          int                            null comment 'Optional ID of Collection this Card belongs to.',\n    public_uuid            char(36)                       null comment 'Unique UUID used to in publically-accessible links to this Card.',\n    made_public_by_id      int                            null comment 'The ID of the User who first publically shared this Card.',\n    enable_embedding       bit         default b'0'       not null comment 'Is this Card allowed to be embedded in different websites (using a signed JWT)?',\n    embedding_params       longtext                       null,\n    cache_ttl              int                            null comment 'The maximum time, in seconds, to return cached results for this Card rather than running a new query.',\n    result_metadata        longtext                       null,\n    collection_position    smallint                       null comment 'Optional pinned position for this item in its Collection. NULL means item is not pinned.',\n    dataset                bit         default b'0'       not null,\n    entity_id              char(21)                       null comment 'Random NanoID tag for unique identity.',\n    parameters             longtext                       null comment 'List of parameter associated to a card',\n    parameter_mappings     longtext                       null comment 'List of parameter associated to a card',\n    collection_preview     bit         default b'1'       not null,\n    metabase_version       varchar(100)                   null comment 'Metabase version used to create the card.',\n    type                   varchar(16) default 'question' not null comment 'The type of card, could be ''question'', ''model'', ''metric''',\n    initially_published_at timestamp(6)                   null comment 'The timestamp when the card was first published in a static embed',\n    constraint entity_id\n        unique (entity_id),\n    constraint public_uuid\n        unique (public_uuid),\n    constraint fk_card_collection_id\n        foreign key (collection_id) references metabase.collection (id)\n            on delete set null,\n    constraint fk_card_made_public_by_id\n        foreign key (made_public_by_id) references metabase.core_user (id)\n            on delete cascade,\n    constraint fk_card_ref_user_id\n        foreign key (creator_id) references metabase.core_user (id)\n            on delete cascade,\n    constraint fk_report_card_ref_database_id\n        foreign key (database_id) references metabase.metabase_database (id)\n            on delete cascade,\n    constraint fk_report_card_ref_table_id\n        foreign key (table_id) references metabase.metabase_table (id)\n            on delete cascade\n);\n\ncreate index idx_card_collection_id\n    on metabase.report_card (collection_id);\n\ncreate index idx_card_creator_id\n    on metabase.report_card (creator_id);\n\ncreate index idx_card_public_uuid\n    on metabase.report_card (public_uuid);\n```"", 'created_at': datetime.datetime(2024, 10, 29, 23, 45, 47, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-15 22:25:42 UTC): What version of MySQL are you running? Also, please always use Java 11

cabarria (Issue Creator) on (2024-10-16 17:48:05 UTC): 8.0.36 (Source distribution)

I downgraded to java 11 and the same issue persists
{""file.encoding"" ""UTF-8"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.runtime.version"" ""11.0.24+8-LTS"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.vendor"" ""Red Hat, Inc."",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.vendor.url"" ""https://www.redhat.com/"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.version"" ""11.0.24"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
Oct 16 13:55:19 host01 metabase[497049]:  ""java.vm.version"" ""11.0.24+8-LTS"",
Oct 16 13:55:19 host01 metabase[497049]:  ""os.name"" ""Linux"",
Oct 16 13:55:19 host01 metabase[497049]:  ""os.version"" ""4.18.0-553.22.1.el8_10.x86_64"",
Oct 16 13:55:19 host01 metabase[497049]:  ""user.language"" ""en"",
Oct 16 13:55:19 host01 metabase[497049]:  ""user.timezone"" ""America/New_York""}

cabarria (Issue Creator) on (2024-10-29 20:09:44 UTC): Any ideas why does it fail with unknown column dataset?

paoliniluis on (2024-10-29 23:45:47 UTC): @cabarria there's a migration missing most definitely. Some previous migration on your app db didn't run and now you're hitting this.

This is the DDL of the table that has an error, please adapt your table to this:
```
create table if not exists metabase.report_card
(
    id                     int auto_increment
        primary key,
    created_at             timestamp(6)                   not null,
    updated_at             timestamp(6)                   null,
    name                   varchar(254)                   not null,
    description            longtext                       null,
    display                varchar(254)                   not null,
    dataset_query          longtext                       null,
    visualization_settings longtext                       null,
    creator_id             int                            not null,
    database_id            int                            not null,
    table_id               int                            null,
    query_type             varchar(16)                    null,
    archived               bit         default b'0'       not null,
    collection_id          int                            null comment 'Optional ID of Collection this Card belongs to.',
    public_uuid            char(36)                       null comment 'Unique UUID used to in publically-accessible links to this Card.',
    made_public_by_id      int                            null comment 'The ID of the User who first publically shared this Card.',
    enable_embedding       bit         default b'0'       not null comment 'Is this Card allowed to be embedded in different websites (using a signed JWT)?',
    embedding_params       longtext                       null,
    cache_ttl              int                            null comment 'The maximum time, in seconds, to return cached results for this Card rather than running a new query.',
    result_metadata        longtext                       null,
    collection_position    smallint                       null comment 'Optional pinned position for this item in its Collection. NULL means item is not pinned.',
    dataset                bit         default b'0'       not null,
    entity_id              char(21)                       null comment 'Random NanoID tag for unique identity.',
    parameters             longtext                       null comment 'List of parameter associated to a card',
    parameter_mappings     longtext                       null comment 'List of parameter associated to a card',
    collection_preview     bit         default b'1'       not null,
    metabase_version       varchar(100)                   null comment 'Metabase version used to create the card.',
    type                   varchar(16) default 'question' not null comment 'The type of card, could be ''question'', ''model'', ''metric''',
    initially_published_at timestamp(6)                   null comment 'The timestamp when the card was first published in a static embed',
    constraint entity_id
        unique (entity_id),
    constraint public_uuid
        unique (public_uuid),
    constraint fk_card_collection_id
        foreign key (collection_id) references metabase.collection (id)
            on delete set null,
    constraint fk_card_made_public_by_id
        foreign key (made_public_by_id) references metabase.core_user (id)
            on delete cascade,
    constraint fk_card_ref_user_id
        foreign key (creator_id) references metabase.core_user (id)
            on delete cascade,
    constraint fk_report_card_ref_database_id
        foreign key (database_id) references metabase.metabase_database (id)
            on delete cascade,
    constraint fk_report_card_ref_table_id
        foreign key (table_id) references metabase.metabase_table (id)
            on delete cascade
);

create index idx_card_collection_id
    on metabase.report_card (collection_id);

create index idx_card_creator_id
    on metabase.report_card (creator_id);

create index idx_card_public_uuid
    on metabase.report_card (public_uuid);
```

"
2589888422,issue,closed,completed,Select none is shown when nothing fits the search in the dashboard filter,"### Describe the bug

![Image](https://github.com/user-attachments/assets/586edff7-b5c0-436d-ba1c-c5eb45437cf4)


### To Reproduce

1. Create a text filter on the dashboard
2. Type something in the filter that doesn't march anything
3. You'll see ""Select none"" checkbox along with ""Didn't find anything"" message


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

8e950e8

### Severity

minor but weird looking

### Additional context

_No response_",mngr,2024-10-15 20:51:47+00:00,['ranquild'],2024-10-17 19:32:35+00:00,2024-10-17 13:52:52+00:00,https://github.com/metabase/metabase/issues/48761,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Needs Triage', ''), ('.Team/Querying', '')]",[],
2589757742,issue,closed,completed,Port Select-related components to Mantine v7,"`Select`, `MultiSelect`, `Autocomplete`, `MultiAutocomplete`",rafpaf,2024-10-15 20:02:09+00:00,[],2025-02-03 11:08:11+00:00,2025-02-03 11:08:11+00:00,https://github.com/metabase/metabase/issues/48756,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2589691513,issue,open,,Joining Saved Questions with the same implicit join in group by field causes an error,"### Describe the bug

If the title seems familiar it's because this issue is very similar to repro 3 in #26631 .

Joining a saved question on an aggregated field that uses the same implicit join results in an error. Difference from #26631 is that now the base question and the joined saved question both use implicit joins.

Note that if you have two questions with aggregations on the same implicitly joined fields and you save both of them, then create new question joining them, it's fine. The error only happens when you join a saved question into a question you're currently building

### To Reproduce

1. New question from `Orders`
2. Summary: `Count` by `Product -> Category`
3. Save the question as Q1
![Image](https://github.com/user-attachments/assets/ba5adf66-fe6e-4e09-936f-9b5770ebcb0b)

5. New question from `Reviews`
6. Summary: `Count` by `Product -> Category`  _(this is different from repro 3 in #26631, which used Products table so there was no implicit join)_
7. Add a Join to Q1 on `Product-> Category`
8. Error
![Image](https://github.com/user-attachments/assets/3b8f9fd2-9d18-4317-b060-101d4ea7f942)


### Expected behavior

Not an error

### Logs

_No response_

### Information about your Metabase installation

Tried on 49.1, 50.1, 51.0-beta, probably always been like this

### Severity

P2-ish?

### Additional context

https://github.com/user-attachments/assets/e475a871-c1f1-4496-8520-2f33c0fecda0


Generated SQL:
```sql
SELECT
  ""source"".""PRODUCTS__via__PRODUCT_ID_2__CATEGORY"" AS ""PRODUCTS__via__PRODUCT_ID_2__CATEGORY"",
  ""source"".""count"" AS ""count"",
  ""Q1 - Category"".""PRODUCTS__via__PRODUCT_ID__CATEGORY"" AS ""Q1 - Category__PRODUCTS__via__PRODUCT_ID__CATEGORY"",
  ""Q1 - Category"".""count"" AS ""Q1 - Category__count""
FROM
  (
    SELECT
      ""PRODUCTS__via__PRODUCT_ID_2"".""CATEGORY"" AS ""PRODUCTS__via__PRODUCT_ID_2__CATEGORY"",
      COUNT(*) AS ""count""
    FROM
      ""PUBLIC"".""REVIEWS""
     
LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""PRODUCTS__via__PRODUCT_ID_2"" ON ""PUBLIC"".""REVIEWS"".""PRODUCT_ID"" = ""PRODUCTS__via__PRODUCT_ID_2"".""ID""
   
GROUP BY
      ""PRODUCTS__via__PRODUCT_ID_2"".""CATEGORY""
   
ORDER BY
      ""PRODUCTS__via__PRODUCT_ID_2"".""CATEGORY"" ASC
  ) AS ""source""
  LEFT JOIN (
    SELECT
      ""PRODUCTS__via__PRODUCT_ID"".""CATEGORY"" AS ""PRODUCTS__via__PRODUCT_ID__CATEGORY"",
      COUNT(*) AS ""count""
    FROM
      ""PUBLIC"".""ORDERS""
      LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""PRODUCTS__via__PRODUCT_ID"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS__via__PRODUCT_ID"".""ID""
    GROUP BY
      ""PRODUCTS__via__PRODUCT_ID"".""CATEGORY""
    ORDER BY
      ""PRODUCTS__via__PRODUCT_ID"".""CATEGORY"" ASC
  ) AS ""Q1 - Category"" ON ""source"".""PRODUCTS__via__PRODUCT_ID__CATEGORY"" = ""Q1 - Category"".""PRODUCTS__via__PRODUCT_ID__CATEGORY""
LIMIT
  1048575
```",alexyarosh,2024-10-15 19:31:57+00:00,[],2025-02-04 20:27:16+00:00,,https://github.com/metabase/metabase/issues/48754,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2589672222,issue,open,,Granular options for enabling exports in the sdk,"We should increase the granularity of enabling and disabling exports in the SDK.

We have 3 scenarios:
- JSON/CSV data exports
- PNG export for individual dashboard card
- PDF export for the entire page of dashboard
 
Possible options
- One for JSON+CSV data exports, another for PNG+PDF image exports.
  - e.g. `withDataDownload` (JSON/CSV) and `withImageDownload` (dashboard PDF + dashcard PNG)
  - as PDF is for entire dashboard and PNG is for a single dashcard, should `withImageDownload` be more granular?
- Provide an object or array on what formats to enable.
  - e.g. `downloadFormats={['json', 'csv', 'pdf', 'png']}` or `downloadFormats={{png:true, csv:true, pdf:true}}`",heypoom,2024-10-15 19:25:12+00:00,[],2025-02-04 20:30:55+00:00,,https://github.com/metabase/metabase/issues/48753,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2589661897,issue,open,,Summarization calculations change when adding/removing a distinct count summarization,"### Describe the bug

In a question that includes percentage and count summarizations in addition to a distinct count summarization, adding/removing the distinct count summarization changes the result or the other summarizations.

Original question:
![Image](https://github.com/user-attachments/assets/45e62398-c290-408b-a362-61f47bf7cf2b)

Original result:
![Image](https://github.com/user-attachments/assets/6ffbac71-51df-4a12-ae1d-7054b7698a21)

Question after removing the distinct count summarization
![Image](https://github.com/user-attachments/assets/55a851c5-d85d-4f26-b45a-e89d73ab9d32)

Different result:
![Image](https://github.com/user-attachments/assets/f9259980-3ba6-477e-a55a-37604b8e7ba6)


### To Reproduce

See images in bug description


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Metabase v48.1

### Severity

blocking some users

### Additional context

_No response_",meldiner,2024-10-15 19:20:35+00:00,[],2025-02-04 20:27:38+00:00,,https://github.com/metabase/metabase/issues/48752,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2416782559, 'issue_id': 2589661897, 'author': 'mngr', 'body': '@meldiner Could you please share the SQL generated in both situations\nAlso are you able to update your Metabase instance?\nYour version is far behind the latest one.', 'created_at': datetime.datetime(2024, 10, 16, 13, 3, 14, tzinfo=datetime.timezone.utc)}]","mngr on (2024-10-16 13:03:14 UTC): @meldiner Could you please share the SQL generated in both situations
Also are you able to update your Metabase instance?
Your version is far behind the latest one.

"
2589641438,issue,closed,completed,Configure Slack link in Setup Channel modal,"The Current ""ChannelSetupModal"" when you don't have any channels setup (slack/webhook/email) only shows 2 buttons, and the Slack button link is broken.

![Image](https://github.com/user-attachments/assets/deaa02de-2005-4526-93d5-e1f5fb42a416)
",npfitz,2024-10-15 19:09:41+00:00,['npfitz'],2024-10-18 14:38:58+00:00,2024-10-18 13:54:08+00:00,https://github.com/metabase/metabase/issues/48751,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Sharing/Public', '')]",[],
2589500350,issue,open,,[FE] Default to previously selected data,,ranquild,2024-10-15 18:01:39+00:00,['ranquild'],2024-10-15 18:01:48+00:00,,https://github.com/metabase/metabase/issues/48748,[],[],
2589500188,issue,open,,[Epic] Default to previously selected data source when starting new query,"Product doc https://www.notion.so/metabase/Default-to-previously-selected-data-source-when-starting-new-query-7eaeda08d95d4105923b5ad6fcdfc7a7

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/48748
- [ ] [Testing plan] Default to previously selected data
```",ranquild,2024-10-15 18:01:35+00:00,['ranquild'],2024-10-15 18:01:54+00:00,,https://github.com/metabase/metabase/issues/48747,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2589475704,issue,closed,completed,"""Models"" navigation menu dont work","**Describe the bug**
When I try to open the ""Models"" navigation menu an error message appears insted of the list of models.

**Logs**
See atached.[metabase-diagnostic-info-2024-10-15T17_40_30.264Z.json](https://github.com/user-attachments/files/17382581/metabase-diagnostic-info-2024-10-15T17_40_30.264Z.json)


**To Reproduce**
Steps to reproduce the behavior:
1. Go to Models menu
2. See the error message.

**Expected behavior**
Open the list of models.

**Screenshots**
![Image](https://github.com/user-attachments/assets/6b491740-2236-44ea-a965-b8ba0a5de9bf)


**Severity**
Low.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Ubuntu 16.4-0ubuntu0.24.04.2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-45-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",fmercurio,2024-10-15 17:51:22+00:00,[],2025-01-16 17:26:32+00:00,2025-01-16 17:26:32+00:00,https://github.com/metabase/metabase/issues/48745,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2422922124, 'issue_id': 2589475704, 'author': 'dpsutton', 'body': '@fmercurio can you provide any backend logs? Would be helpful to understand what is going on.', 'created_at': datetime.datetime(2024, 10, 18, 17, 22, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471173576, 'issue_id': 2589475704, 'author': 'dpsutton', 'body': '@fmercurio any update on this issue?', 'created_at': datetime.datetime(2024, 11, 12, 17, 37, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483593930, 'issue_id': 2589475704, 'author': 'fmercurio', 'body': '> [@fmercurio](https://github.com/fmercurio) any update on this issue?\n\nHello @dpsutton,\n\nThe Metabase instance is running in a Docker container. The only log messages that appear when monitoring via docker logs are as follows:\n\n```\n2024-11-18 16:49:09,348 DEBUG middleware.log :: HEAD /api/health 200 74.6 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (1 idle, 0 queued) (125 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}\n2024-11-18 16:49:09,501 DEBUG middleware.log :: GET /api/util/bug_report_details 200 24.8 ms (1 database call) Connections in the database: 0 / 15 Jetty threads: 7 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id 1}\n2024-11-18 16:49:24,425 DEBUG middleware.log :: HEAD /api/health 200 133.3 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}\n2024-11-18 16:49:39,491 DEBUG middleware.log :: HEAD /api/health 200 85.6 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}\n```\n\nAdditionally, the diagnostic files provided by Metabase are already attached in the following link:\n\nhttps://github.com/user-attachments/files/17382581/metabase-diagnostic-info-2024-10-15T17_40_30.264Z.json\n\nAny further guidance would be greatly appreciated.', 'created_at': datetime.datetime(2024, 11, 18, 16, 55, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498130898, 'issue_id': 2589475704, 'author': 'dpsutton', 'body': '@fmercurio those logs are something hitting the health endpoint frequently and the request to get the information to populate the bug reporting details.\n\nLooking at the the json file you\'ve uploaded, all i\'m seeing is that your email settings seem off (there are 32 errors relating to ""javax.mail.MessagingException: Could not connect to SMTP host: smtp.office365.com, port: 587;"").\n\n\nI\'m piping that file through `jq`, getting the `backendErrors` and for each one (`map`) getting the message (`msg`) (and only taking at most `50` characters of it):\n```shell\n❯ cat ""metabase-diagnostic-info-2024-10-15T17_40_30.264Z(2).json"" | jq \'.backendErrors|map(.msg[0:50])\'\n[\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""Error testing SMTP connection"",\n  ""\\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao"",\n  ""\\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao"",\n  ""\\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao""\n]\n```', 'created_at': datetime.datetime(2024, 11, 25, 14, 12, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596304419, 'issue_id': 2589475704, 'author': 'luizarakaki', 'body': 'Closing this for now. If we have reproduction steps, happy to reopen', 'created_at': datetime.datetime(2025, 1, 16, 17, 26, 25, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-18 17:22:49 UTC): @fmercurio can you provide any backend logs? Would be helpful to understand what is going on.

dpsutton on (2024-11-12 17:37:43 UTC): @fmercurio any update on this issue?

fmercurio (Issue Creator) on (2024-11-18 16:55:11 UTC): Hello @dpsutton,

The Metabase instance is running in a Docker container. The only log messages that appear when monitoring via docker logs are as follows:

```
2024-11-18 16:49:09,348 DEBUG middleware.log :: HEAD /api/health 200 74.6 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (1 idle, 0 queued) (125 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}
2024-11-18 16:49:09,501 DEBUG middleware.log :: GET /api/util/bug_report_details 200 24.8 ms (1 database call) Connections in the database: 0 / 15 Jetty threads: 7 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id 1}
2024-11-18 16:49:24,425 DEBUG middleware.log :: HEAD /api/health 200 133.3 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}
2024-11-18 16:49:39,491 DEBUG middleware.log :: HEAD /api/health 200 85.6 µs (0 database calls) Connections in the database: 0 / 15 Jetty threads: 6 / 50 (2 idle, 0 queued) (126 total active threads) Active queries: 0 (0 queued) {:metabase-user-id nil}
```

Additionally, the diagnostic files provided by Metabase are already attached in the following link:

https://github.com/user-attachments/files/17382581/metabase-diagnostic-info-2024-10-15T17_40_30.264Z.json

Any further guidance would be greatly appreciated.

dpsutton on (2024-11-25 14:12:49 UTC): @fmercurio those logs are something hitting the health endpoint frequently and the request to get the information to populate the bug reporting details.

Looking at the the json file you've uploaded, all i'm seeing is that your email settings seem off (there are 32 errors relating to ""javax.mail.MessagingException: Could not connect to SMTP host: smtp.office365.com, port: 587;"").


I'm piping that file through `jq`, getting the `backendErrors` and for each one (`map`) getting the message (`msg`) (and only taking at most `50` characters of it):
```shell
❯ cat ""metabase-diagnostic-info-2024-10-15T17_40_30.264Z(2).json"" | jq '.backendErrors|map(.msg[0:50])'
[
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""Error testing SMTP connection"",
  ""\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao"",
  ""\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao"",
  ""\u001b[31mPOST /api/email/test 500 5.2 s (1 chamadas ao""
]
```

luizarakaki on (2025-01-16 17:26:25 UTC): Closing this for now. If we have reproduction steps, happy to reopen

"
2589455393,issue,open,,Re-run a sorted query when sorting in dashboard table cards (instead of just FE sorting),"**Is your feature request related to a problem? Please describe.**
On a dashboard, when a user clicks on a column in a card to sort, for the card's query to be run in the same way it would be had a user sorted a column in a question.

![Image](https://github.com/user-attachments/assets/04027088-6a3d-4801-a693-91fe77a75351)


**Describe the solution you'd like**
For there be a “toggle” on a card in the dashboard that can be enabled to trigger this functionality.


**Describe alternatives you've considered**
Using Auto-Refresh functionality for a dashboard.


",FilmonK,2024-10-15 17:42:56+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/48744,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]",[],
2589381124,issue,open,,Granular model persistency frequency settings,"**Is your feature request related to a problem? Please describe.**
The ability to set a Custom time, or use the standard refresh option (hours) on a per model basis rather than having a global value for all models.


**Describe the solution you'd like**
Extend the scheduling option to models individually.

![Image](https://github.com/user-attachments/assets/0363189f-d926-497b-9c26-9c766ee285db)

![Image](https://github.com/user-attachments/assets/d2f66ebd-d8cd-4dcf-a68d-3d89ad9588e1)



**Describe alternatives you've considered**
Using the ""refresh"" endpoint in the Card API to update the model on a desired frequency.
https://www.metabase.com/docs/latest/api/card



",FilmonK,2024-10-15 17:09:05+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/48743,"[('Administration/', ''), ('Querying/Models', 'aka Datasets'), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2518846053, 'issue_id': 2589381124, 'author': 'michael-gratton', 'body': ""Some more per-model flexibility here would be great. We have a use case around email performance (emails sent, opens, clicks, etc) with wildly different parameters:\n\n* Models built from long term historical data with billions of rows. These are used for benchmarking and to show long-term trends year on year, so need to be refreshed once a day at most, if not less.\n* Models built to reflect live data, with maybe low millions or hundreds of thousands of rows, used to show performance of an email that was sent. We'd want this refreshed only on use and if the cached data is not older than say 5 minutes."", 'created_at': datetime.datetime(2024, 12, 5, 0, 41, 24, tzinfo=datetime.timezone.utc)}]","michael-gratton on (2024-12-05 00:41:24 UTC): Some more per-model flexibility here would be great. We have a use case around email performance (emails sent, opens, clicks, etc) with wildly different parameters:

* Models built from long term historical data with billions of rows. These are used for benchmarking and to show long-term trends year on year, so need to be refreshed once a day at most, if not less.
* Models built to reflect live data, with maybe low millions or hundreds of thousands of rows, used to show performance of an email that was sent. We'd want this refreshed only on use and if the cached data is not older than say 5 minutes.

"
2589197827,issue,closed,not_planned,Unable to discard cached field values,"**Describe the bug**
When trying to discard cached field values, I get the following error:
>  PreparedStatement can have at most 65,535 parameters. Please consider using arrays, or splitting the query in several ones, or using COPY. Given query has 1,967,379 parameters.

**To Reproduce**
Add a MongoDB collection with a lot of different field values and field names.
Go to Admin settings > Table Metadata > gear icon > Discard cached field values.

**Metabase Diagnostic Info**

```json
{
  ""metabase-info"": {
    ""databases"": [
      ""mongo""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.8 (Ubuntu 14.8-1.pgdg18.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  }
}
```",thibauds,2024-10-15 15:47:01+00:00,[],2024-11-07 14:48:52+00:00,2024-11-07 14:48:51+00:00,https://github.com/metabase/metabase/issues/48738,[],"[{'comment_id': 2462426575, 'issue_id': 2589197827, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/33037', 'created_at': datetime.datetime(2024, 11, 7, 14, 48, 51, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-07 14:48:51 UTC): duplicate of https://github.com/metabase/metabase/issues/33037

"
2588965462,issue,open,,Dashboard filter placeholder should have the name of the filter and not the name of the field,"**Is your feature request related to a problem? Please describe.**
when you add a filter to a dashboard, it will use the name of the field in the placeholder, and the correct name would be that it inherits the name of the filter

**Describe the solution you'd like**
The placeholder should use the name of the filter, rather than the field name

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer since it confuses users

**Additional context**
This only happens if you set the field to a SEARCH BOX. So to see this:
1) go to table metadata
2) find a field and change the filter type to a search box
3) then create a chart + a dashboard and then connect the field to the chart and see the results
",paoliniluis,2024-10-15 14:30:24+00:00,[],2025-02-04 20:30:26+00:00,,https://github.com/metabase/metabase/issues/48737,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]","[{'comment_id': 2417955088, 'issue_id': 2588965462, 'author': 'daedalus28', 'body': 'Alternatively, just allow setting placeholder explicitly.', 'created_at': datetime.datetime(2024, 10, 16, 21, 0, 39, tzinfo=datetime.timezone.utc)}]","daedalus28 on (2024-10-16 21:00:39 UTC): Alternatively, just allow setting placeholder explicitly.

"
2588899645,issue,closed,not_planned,[BE] Support offset calls in displayInfo for aggregations,"MBQL lib should handle all offset expressions we generate in the UI and generate correct `displayName`s for them

1. Offset expressions https://github.com/metabase/metabase/blob/6b7f381fe0f34d415cac7e00f3388c4dc92297f8/frontend/src/metabase-lib/offset.ts
2. Moving average expressions https://github.com/metabase/metabase/blob/6b7f381fe0f34d415cac7e00f3388c4dc92297f8/frontend/src/metabase-lib/moving-average.ts

In the UI it's:
- Open `48533-time-comparison-ui` branch
- New -> Question -> Orders -> Count
- New -> Aggregation -> Compare to the past -> Choose options and click Done",ranquild,2024-10-15 14:06:50+00:00,[],2024-10-25 19:07:56+00:00,2024-10-25 19:07:56+00:00,https://github.com/metabase/metabase/issues/48735,[],[],
2588893038,issue,closed,completed,Migrate existing dashboards to always include explicit target stage-number,"https://www.notion.so/Tech-Allow-to-use-both-pre-and-post-last-aggregation-columns-in-dashboard-filters-1f8c3309aa824463827a38bedcd47ac6?d=12069354c90180d9897d001cba0b6068&pvs=4#5b5f58453af34dec8eea87a307696b9b

https://metaboat.slack.com/archives/C0645JP1W81/p1729000631787829

This task is only about dashboard params. ",kamilmielnik,2024-10-15 14:04:15+00:00,['metamben'],2024-10-29 07:22:40+00:00,2024-10-29 07:22:28+00:00,https://github.com/metabase/metabase/issues/48734,"[('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2443425921, 'issue_id': 2588893038, 'author': 'kamilmielnik', 'body': 'Closed by #49256', 'created_at': datetime.datetime(2024, 10, 29, 7, 22, 28, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-29 07:22:28 UTC): Closed by #49256

"
2588892651,issue,open,,Migrate existing dashboards to always include explicit target stage-number,,kamilmielnik,2024-10-15 14:04:06+00:00,[],2024-10-15 14:04:06+00:00,,https://github.com/metabase/metabase/issues/48733,[],[],
2588567208,issue,closed,completed,Remove uberjar from the release process to speed up the build,"We used to build an Uberjar with the commit for the release and link that to the SDK doc. We don't do that anymore, and we linked to a prebuilt Metabase jars/docker images instead.",WiNloSt,2024-10-15 12:00:02+00:00,['WiNloSt'],2024-10-16 13:14:08+00:00,2024-10-16 13:10:54+00:00,https://github.com/metabase/metabase/issues/48728,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2588564614,issue,closed,completed,[Epic] Improve SDK npm release process,"**Links**
- [product doc](https://www.notion.so/metabase/Improve-npm-release-process-11e69354c901808687bcfb8368fd0327)

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/48728
- [ ] https://github.com/metabase/metabase/issues/48822
- [ ] https://github.com/metabase/metabase/issues/48974
- [ ] https://github.com/metabase/metabase/issues/48844
- [ ] https://github.com/metabase/metabase/pull/49074
- [ ] https://github.com/metabase/metabase/pull/49083
- [ ] https://github.com/metabase/metabase/pull/49240
- [ ] https://github.com/metabase/metabase/pull/49243
- [ ] https://github.com/metabase/metabase/pull/49267
- [ ] https://github.com/metabase/metabase/issues/49881
- [ ] https://github.com/metabase/metabase/issues/49925
```
",WiNloSt,2024-10-15 11:59:00+00:00,[],2024-11-13 07:46:13+00:00,2024-10-24 13:49:04+00:00,https://github.com/metabase/metabase/issues/48727,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2588270233,issue,closed,completed,Metric on a calculated column randomly fails,"### Describe the bug

I built a metric that shows the median of a calculated column which then ends up failing when consulted past the first time. To see it again, I need to edit its definition, change the default time dimension to something, and revert it back to see the metric properly computed again.

The model in my case is ""Issues"" (GitHub) and my calculated column is called ""Days open"" computed this way `datetimeDiff([Created At], now, ""day"")`. The metric is then defined as `Median of Days open` (cf. repro steps below).

### To Reproduce

You can check out this repro Loom: https://www.loom.com/share/d7b7926283ea43a7b0eb6cfeafde9714

1. Create a new metric in stats.metabase.com using ""Issues"" as the source data
2. Create a custom column called ""Days open"" with the following formula `datetimeDiff([Created At], now, ""day"")`
3. Define the metric's formula as `Median of Days open`
4. Visualize and save -> Everything works fine
5. Reload Metabase, and navigate to your metric -> There's a failure with the following error message: `Cannot determine the source table or query for Field clause [:field ""created_at"" {:base-type :type/DateTimeWithLocalTZ}]` 
6. Edit the metric definition
7. Change the default time dimension to anything and click Play -> It works again




### Expected behavior

This should be consistently displayed, without failing.

### Logs

_No response_

### Information about your Metabase installation

Using stats.metabase.com on a Brave browser, but I doubt this has anything to do with the issue :)

### Severity

Prevents from using the metric

### Additional context

_No response_",thebiglabasky,2024-10-15 10:00:35+00:00,['lbrdnk'],2024-10-17 19:06:42+00:00,2024-10-17 19:06:41+00:00,https://github.com/metabase/metabase/issues/48722,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2588208470,issue,closed,completed,Upgrading to v50 broke all queries that have summaries with custom expressions on unix timestamp columns,"### Describe the bug

Seems like the upgrade to v50 broke all of our queries that have summaries with custom expressions on tables with timestamp columns for dates. 

Specifically what happens is that the FROM clause in the query converts the timestamp to date and assigns that as the ""ts"" field of the ""source"" alias, but then the SUM calculations perform another FROM_UNIXTIME conversion on that value, which will obviously fail. 

Converting the query to SQL and manually removing the extraneous FROM_UNIXTIME calls from all the SUM columns restores the original functionality, but this is not desirable. 

I tried manually adjusting the table's metadata in the admin settings and converting it from unix timestamp (seconds) to datetime, however this had no effect.

### To Reproduce

Upgrade Metabase to v50.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Helsinki""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.4.13-MariaDB-log""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.214-202.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

Blocking the usage of Metabase entirely

### Additional context

_No response_",MarkoTukiainen,2024-10-15 09:40:08+00:00,['metamben'],2024-11-21 21:06:11+00:00,2024-11-21 20:21:50+00:00,https://github.com/metabase/metabase/issues/48721,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2413863438, 'issue_id': 2588208470, 'author': 'paoliniluis', 'body': 'Hi @MarkoTukiainen any example of a question you can give us also with a table definition?', 'created_at': datetime.datetime(2024, 10, 15, 13, 5, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413879701, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': ""The table contains fields:\n\nts int (11) unsigned\nshopid varchar(32)\nsales double\ncommission double\ninvoices int(11) unsigned\nconsolidatedorders int(11) unsigned\nconsolidatedsales double\n\nHere's a question that gets generated. \n\n```\nSELECT\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  ) AS `ts`,\n  SUM(\n    CASE\n      WHEN\nFROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2022-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n     \n   AND DATE(\n        convert_tz(\n          '2022-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `source`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2022`,\n  SUM(\n    CASE\n      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2023-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n      AND DATE(\n        convert_tz(\n          '2023-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `source`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2023`,\n  SUM(\n    CASE\n      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2024-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n      AND DATE(\n        convert_tz(\n          '2024-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `source`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2024`,\n  SUM(\n    CASE\n      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2023-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n      AND DATE(\n        convert_tz(\n          '2023-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `source`.`Commission Goal 2`\n      ELSE 0.0\n    END\n  ) AS `Commission Goal 2024 (+19%)`\nFROM\n  (\n    SELECT\n      FROM_UNIXTIME(`dailysales`.`ts`) AS `ts`,\n      `dailysales`.`commission` AS `commission`,\n      (`dailysales`.`commission` * 0.19) + `dailysales`.`commission` AS `Commission Goal 2`\n    FROM\n      `dailysales`\n  ) AS `source`\nGROUP BY\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  )\nORDER BY\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  ) ASC\n```"", 'created_at': datetime.datetime(2024, 10, 15, 13, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419703837, 'issue_id': 2588208470, 'author': 'Tony-metabase', 'body': 'Hi Marko,\n\nIf you downgrade to 50.27 do you get the same behaviour?', 'created_at': datetime.datetime(2024, 10, 17, 14, 25, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421431722, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': '> If you downgrade to 50.27 do you get the same behaviour?\n\nDowngraded to v0.50.27.4, it does the same thing.', 'created_at': datetime.datetime(2024, 10, 18, 5, 25, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421754788, 'issue_id': 2588208470, 'author': 'Tony-metabase', 'body': 'Interesting cause we tested this on different versions and cannot seem to hit what is going on. Even our cloud is currently on 50.30 and no one flagged such a case.\n\nYou are converting to unix timestamp at metabase level right? When you go to Admin -> Table Metadata -> Table -> Column and inside the settings right? Can you share a screenshot of this column `ts`', 'created_at': datetime.datetime(2024, 10, 18, 8, 2, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421778866, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': ""![Image](https://github.com/user-attachments/assets/6706f2af-15b1-4bda-abe0-225154c6dd8b)\n\nThis is the ts field (it's title is Date in the metadata settings)."", 'created_at': datetime.datetime(2024, 10, 18, 8, 8, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2437481321, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': ""> Interesting cause we tested this on different versions and cannot seem to hit what is going on. Even our cloud is currently on 50.30 and no one flagged such a case.\n> \n> You are converting to unix timestamp at metabase level right? When you go to Admin -> Table Metadata -> Table -> Column and inside the settings right? Can you share a screenshot of this column `ts`\n\nHey @Tony-metabase, a quick update on this. I'm not sure if my downgrade didn't work properly immediately or if there's some sort of caching involved in this, but I just got a message that said that the graphs were suddenly working again (without anyone doing anything). Now, with v0.50.27.4 installed the query looks like this (FROM_UNIXTIME is done to dailysales.ts and not source.ts as in my previous example):\n\n```\nSELECT\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(\n              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)\n            ),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  ) AS `ts`,\n  SUM(\n    CASE\n      WHEN\nFROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2022-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n     \n   AND DATE(\n        convert_tz(\n          '2022-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `dailysales`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2022`,\n  SUM(\n    CASE\n      WHEN FROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2023-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n      AND DATE(\n        convert_tz(\n          '2023-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `dailysales`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2023`,\n  SUM(\n    CASE\n      WHEN FROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(\n        convert_tz(\n          '2024-01-01 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      )\n      AND DATE(\n        convert_tz(\n          '2024-12-31 00:00:00.000',\n          '+02:00',\n          @@session.time_zone\n        )\n      ) THEN `dailysales`.`commission`\n      ELSE 0.0\n    END\n  ) AS `Commission 2024`\nFROM\n  `dailysales`\nGROUP BY\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(\n              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)\n            ),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  )\nORDER BY\n  CEIL(\n    DAYOFYEAR(\n      DATE_ADD(\n        STR_TO_DATE(\n          CONCAT(\n            YEARWEEK(\n              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)\n            ),\n            ' Sunday'\n          ),\n          '%X%V %W'\n        ),\n        INTERVAL 1 day\n      )\n    ) / 7.0\n  ) ASC\n```"", 'created_at': datetime.datetime(2024, 10, 25, 10, 53, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438122013, 'issue_id': 2588208470, 'author': 'paoliniluis', 'body': '@MarkoTukiainen should we close this then?', 'created_at': datetime.datetime(2024, 10, 25, 15, 27, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438169793, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': '@paoliniluis No, I mean I downgraded from a newer version (as suggested) and things started eventually working again. I can try upgrading to the newer version and see if the issue reappears.', 'created_at': datetime.datetime(2024, 10, 25, 15, 46, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438221458, 'issue_id': 2588208470, 'author': 'MarkoTukiainen', 'body': '@paoliniluis @Tony-metabase So seems like I was mistaken about the downgrade actually doing anything. I asked around and turns out that someone had modified the questions so that they would at least partially work again. \n\nAnd what they did to fix it was as follows:\nThere are three custom columns in the question, which are dynamically calculated from other fields. For example the custom ""goal"" column is some value + a percentage. Now, if you attempt to create a custom summarize expression based on the custom column, for example `SumIf([Commission Goal 2], between([Date], ""2022-01-01"", ""2022-12-31""))` then everything in the question goes to zero, since all the columns start referring to the dynamic ""source.ts"" instead of ""dailysales.ts"" and they perform an extra FROM_UNIXTIME on the source, since those values have already been converted to dates.', 'created_at': datetime.datetime(2024, 10, 25, 16, 7, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451910582, 'issue_id': 2588208470, 'author': 'ranquild', 'body': 'Seems like a duplicate of https://github.com/metabase/metabase/issues/47940', 'created_at': datetime.datetime(2024, 11, 1, 13, 53, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486662090, 'issue_id': 2588208470, 'author': 'metamben', 'body': 'The following query works in v49, but fails on master at 893e297e0d when `ORDERS.PRODUCT_ID` is changed to Category and coerced to date.\n![Image](https://github.com/user-attachments/assets/419d5530-49c2-4f80-aeae-4e81cc8727e8)', 'created_at': datetime.datetime(2024, 11, 19, 20, 15, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-15 13:05:12 UTC): Hi @MarkoTukiainen any example of a question you can give us also with a table definition?

MarkoTukiainen (Issue Creator) on (2024-10-15 13:12:06 UTC): The table contains fields:

ts int (11) unsigned
shopid varchar(32)
sales double
commission double
invoices int(11) unsigned
consolidatedorders int(11) unsigned
consolidatedsales double

Here's a question that gets generated. 

```
SELECT
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  ) AS `ts`,
  SUM(
    CASE
      WHEN
FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(
        convert_tz(
          '2022-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
     
   AND DATE(
        convert_tz(
          '2022-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `source`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2022`,
  SUM(
    CASE
      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(
        convert_tz(
          '2023-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
      AND DATE(
        convert_tz(
          '2023-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `source`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2023`,
  SUM(
    CASE
      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(
        convert_tz(
          '2024-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
      AND DATE(
        convert_tz(
          '2024-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `source`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2024`,
  SUM(
    CASE
      WHEN FROM_UNIXTIME(`source`.`ts`) BETWEEN DATE(
        convert_tz(
          '2023-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
      AND DATE(
        convert_tz(
          '2023-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `source`.`Commission Goal 2`
      ELSE 0.0
    END
  ) AS `Commission Goal 2024 (+19%)`
FROM
  (
    SELECT
      FROM_UNIXTIME(`dailysales`.`ts`) AS `ts`,
      `dailysales`.`commission` AS `commission`,
      (`dailysales`.`commission` * 0.19) + `dailysales`.`commission` AS `Commission Goal 2`
    FROM
      `dailysales`
  ) AS `source`
GROUP BY
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  )
ORDER BY
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(DATE_ADD(`source`.`ts`, INTERVAL -1 day)),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  ) ASC
```

Tony-metabase on (2024-10-17 14:25:22 UTC): Hi Marko,

If you downgrade to 50.27 do you get the same behaviour?

MarkoTukiainen (Issue Creator) on (2024-10-18 05:25:13 UTC): Downgraded to v0.50.27.4, it does the same thing.

Tony-metabase on (2024-10-18 08:02:02 UTC): Interesting cause we tested this on different versions and cannot seem to hit what is going on. Even our cloud is currently on 50.30 and no one flagged such a case.

You are converting to unix timestamp at metabase level right? When you go to Admin -> Table Metadata -> Table -> Column and inside the settings right? Can you share a screenshot of this column `ts`

MarkoTukiainen (Issue Creator) on (2024-10-18 08:08:03 UTC): ![Image](https://github.com/user-attachments/assets/6706f2af-15b1-4bda-abe0-225154c6dd8b)

This is the ts field (it's title is Date in the metadata settings).

MarkoTukiainen (Issue Creator) on (2024-10-25 10:53:31 UTC): Hey @Tony-metabase, a quick update on this. I'm not sure if my downgrade didn't work properly immediately or if there's some sort of caching involved in this, but I just got a message that said that the graphs were suddenly working again (without anyone doing anything). Now, with v0.50.27.4 installed the query looks like this (FROM_UNIXTIME is done to dailysales.ts and not source.ts as in my previous example):

```
SELECT
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(
              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)
            ),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  ) AS `ts`,
  SUM(
    CASE
      WHEN
FROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(
        convert_tz(
          '2022-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
     
   AND DATE(
        convert_tz(
          '2022-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `dailysales`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2022`,
  SUM(
    CASE
      WHEN FROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(
        convert_tz(
          '2023-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
      AND DATE(
        convert_tz(
          '2023-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `dailysales`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2023`,
  SUM(
    CASE
      WHEN FROM_UNIXTIME(`dailysales`.`ts`) BETWEEN DATE(
        convert_tz(
          '2024-01-01 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      )
      AND DATE(
        convert_tz(
          '2024-12-31 00:00:00.000',
          '+02:00',
          @@session.time_zone
        )
      ) THEN `dailysales`.`commission`
      ELSE 0.0
    END
  ) AS `Commission 2024`
FROM
  `dailysales`
GROUP BY
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(
              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)
            ),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  )
ORDER BY
  CEIL(
    DAYOFYEAR(
      DATE_ADD(
        STR_TO_DATE(
          CONCAT(
            YEARWEEK(
              DATE_ADD(FROM_UNIXTIME(`dailysales`.`ts`), INTERVAL -1 day)
            ),
            ' Sunday'
          ),
          '%X%V %W'
        ),
        INTERVAL 1 day
      )
    ) / 7.0
  ) ASC
```

paoliniluis on (2024-10-25 15:27:17 UTC): @MarkoTukiainen should we close this then?

MarkoTukiainen (Issue Creator) on (2024-10-25 15:46:12 UTC): @paoliniluis No, I mean I downgraded from a newer version (as suggested) and things started eventually working again. I can try upgrading to the newer version and see if the issue reappears.

MarkoTukiainen (Issue Creator) on (2024-10-25 16:07:50 UTC): @paoliniluis @Tony-metabase So seems like I was mistaken about the downgrade actually doing anything. I asked around and turns out that someone had modified the questions so that they would at least partially work again. 

And what they did to fix it was as follows:
There are three custom columns in the question, which are dynamically calculated from other fields. For example the custom ""goal"" column is some value + a percentage. Now, if you attempt to create a custom summarize expression based on the custom column, for example `SumIf([Commission Goal 2], between([Date], ""2022-01-01"", ""2022-12-31""))` then everything in the question goes to zero, since all the columns start referring to the dynamic ""source.ts"" instead of ""dailysales.ts"" and they perform an extra FROM_UNIXTIME on the source, since those values have already been converted to dates.

ranquild on (2024-11-01 13:53:32 UTC): Seems like a duplicate of https://github.com/metabase/metabase/issues/47940

metamben (Assginee) on (2024-11-19 20:15:23 UTC): The following query works in v49, but fails on master at 893e297e0d when `ORDERS.PRODUCT_ID` is changed to Category and coerced to date.
![Image](https://github.com/user-attachments/assets/419d5530-49c2-4f80-aeae-4e81cc8727e8)

"
2588152379,issue,closed,not_planned,doesn't correspond to initial query LOAD DATA LOCAL INFILE,"(conn=328) LOAD DATA LOCAL INFILE asked for file 'C:UsersADMINI~1AppDataLocalTemp2upload_test_202410151656215568985393024798676.tsv' that doesn't correspond to initial query LOAD DATA LOCAL INFILE 'C:\Users\ADMINI~1\AppData\Local\Temp\2\upload_test_202410151656215568985393024798676.tsv' INTO TABLE `upload_test_20241015165621` (`1`, `2`). Possible malicious proxy changing server answer ! Command interrupted",yangshifei,2024-10-15 09:17:44+00:00,[],2024-10-16 01:45:22+00:00,2024-10-15 13:04:03+00:00,https://github.com/metabase/metabase/issues/48720,[],"[{'comment_id': 2413399883, 'issue_id': 2588152379, 'author': 'yangshifei', 'body': '![Image](https://github.com/user-attachments/assets/5df2d907-e7ed-472d-aad5-7023e3347662)', 'created_at': datetime.datetime(2024, 10, 15, 9, 41, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413860666, 'issue_id': 2588152379, 'author': 'paoliniluis', 'body': ""I don't think we support TSV"", 'created_at': datetime.datetime(2024, 10, 15, 13, 4, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415546199, 'issue_id': 2588152379, 'author': 'yangshifei', 'body': ""> I don't think we support TSV\n\nBut what I uploaded is a CSV file"", 'created_at': datetime.datetime(2024, 10, 16, 1, 33, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415557092, 'issue_id': 2588152379, 'author': 'yangshifei', 'body': '![Image](https://github.com/user-attachments/assets/0e8c1712-5d25-441f-a6ca-aea6146d3024)\nsupport TSV', 'created_at': datetime.datetime(2024, 10, 16, 1, 45, 21, tzinfo=datetime.timezone.utc)}]","yangshifei (Issue Creator) on (2024-10-15 09:41:22 UTC): ![Image](https://github.com/user-attachments/assets/5df2d907-e7ed-472d-aad5-7023e3347662)

paoliniluis on (2024-10-15 13:04:03 UTC): I don't think we support TSV

yangshifei (Issue Creator) on (2024-10-16 01:33:19 UTC): But what I uploaded is a CSV file

yangshifei (Issue Creator) on (2024-10-16 01:45:21 UTC): ![Image](https://github.com/user-attachments/assets/0e8c1712-5d25-441f-a6ca-aea6146d3024)
support TSV

"
2587992752,issue,closed,completed,Fix PDF export visual artifacts on custom sdk themes,"There are visual artifacts present in the SDK's PDF exports when we use custom themes in the SDK.

# Issues

- Background color of the export is incorrect. It does not follow the theme.
- Text are being cut off vertically.
- The arrow up/down icon in trend charts and the circle in front of chart legends is misaligned with the text.
- The font on the chart legends is not loading. It uses the exact same ""Custom"" font-face name as other text elements, and loads via a `@font-face` rule, yet the font does not load.
- There is extraneous padding on the bottom. Setting `background-color` would not get rid of the white space.

# Screenshots

Theme 1 on Shoppy demo

![Image](https://github.com/user-attachments/assets/2a7e9c47-c5d3-4fe8-974e-1a8f6a358030)

Theme 2 on Shoppy demo

![Image](https://github.com/user-attachments/assets/211278d1-37c8-416f-a692-a29f618ef44c)

Theme 3 on Shoppy demo

![Image](https://github.com/user-attachments/assets/56b0c7fa-0d60-42c8-bd50-a7c711624487)
",heypoom,2024-10-15 08:12:08+00:00,['heypoom'],2024-10-24 08:35:54+00:00,2024-10-17 23:46:23+00:00,https://github.com/metabase/metabase/issues/48716,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2587916204,issue,open,,The CSV export fails when datetime values are set to '1970-01-01 00:00:00'.,"**Describe the bug**
The export to CSV fails when encountering datetime fields with the value '1970-01-01 00:00:00', which is displayed as '00:00:00Z'. This causes the process to crash or output incorrect data.



**To Reproduce**
Steps to reproduce the behavior:
1. Create new SQL question
2. 
```sql 
SELECT
        arrayJoin([1, 2]) AS id,
        arrayElement([
            toDateTime('1970-01-01 00:00:00'),
            toDateTime('2021-01-02 03:10:12')
        ], id) AS datetime
ORDER BY id ASC
```

4.  Download as CSV

**Expected behavior**
output csv will contain query logs not query data

**logs**
[query_result_2024-10-15T06_36_36.404418Z.csv](https://github.com/user-attachments/files/17374403/query_result_2024-10-15T06_36_36.404418Z.csv)


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""ru-RU"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""clickhouse""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-29"",
      ""tag"": ""v0.50.23"",
      ""hash"": ""7040ff1""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.26-google""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```",Adilkhan13,2024-10-15 07:39:01+00:00,[],2025-01-30 14:41:32+00:00,,https://github.com/metabase/metabase/issues/48714,[],"[{'comment_id': 2413868397, 'issue_id': 2587916204, 'author': 'paoliniluis', 'body': 'it says: Error reducing result rows: Unsupported field: DayOfMonth', 'created_at': datetime.datetime(2024, 10, 15, 13, 7, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2624681059, 'issue_id': 2587916204, 'author': 'mva-coinify', 'body': 'This is a major issue and I\'m surprised it has not been fixed yet. The consequence of this is essentially random crashes of pulses, which are very hard to debug because of the incoherent error message as @paoliniluis mentioned above. \n\nHere\'s a snippet from a stacktrace from version 48:\n\n```\n[e532a385-2ee5-494d-bc76-619274dd9d27] 2025-01-30T14:11:36+01:00 ERROR metabase.server.middleware.log POST /api/pulse/test 500 7.5 mins (788 DB calls) \n{:via\n [{:type java.time.temporal.UnsupportedTemporalTypeException,\n   :message ""Unsupported field: DayOfWeek"",\n   :at [java.time.temporal.TemporalAccessor range nil -1]}],\n :trace\n [[java.time.temporal.TemporalAccessor range nil -1]\n  [java.time.LocalTime range nil -1]\n  [java.time.OffsetTime range nil -1]\n  [java.time.temporal.TemporalAccessor get nil -1]\n  [java.time.OffsetTime get nil -1]\n  [java.time.temporal.WeekFields$ComputedDayOfField localizedDayOfWeek nil -1]\n  [java.time.temporal.WeekFields$ComputedDayOfField localizedWeekBasedYear nil -1]\n  [java.time.temporal.WeekFields$ComputedDayOfField getFrom nil -1]\n  [java.time.OffsetTime getLong nil -1]\n  [java.time.format.DateTimePrintContext getValue nil -1]\n  [java.time.format.DateTimeFormatterBuilder$NumberPrinterParser format nil -1]\n  [java.time.format.DateTimeFormatterBuilder$WeekBasedFieldPrinterParser format nil -1]\n  [java.time.format.DateTimeFormatterBuilder$CompositePrinterParser format nil -1]\n  [java.time.format.DateTimeFormatter formatTo nil -1]\n  [java.time.format.DateTimeFormatter format nil -1]\n  [java_time.format$format invokeStatic ""format.clj"" 82]\n  [java_time.format$format invoke ""format.clj"" 66]\n  [metabase.pulse.render.datetime$reformat_temporal_str invokeStatic ""datetime.clj"" 29]\n  [metabase.pulse.render.datetime$reformat_temporal_str invoke ""datetime.clj"" 28]\n  [metabase.pulse.render.datetime$format_temporal_str invokeStatic ""datetime.clj"" 127]\n  [metabase.pulse.render.datetime$format_temporal_str invoke ""datetime.clj"" 66]\n  [metabase.pulse.render.body$fn__72208$get_format__72213$fn__72214$fn__72215 invoke ""body.clj"" 87]\n  [metabase.pulse.render.body$fn__72291$query_results__GT_row_seq__72296$fn__72300$iter__72304__72308$fn__72309$iter__72343__72347$fn__72348\n   invoke\n   ""body.clj""\n   170]\n  [clojure.lang.LazySeq sval ""LazySeq.java"" 42]\n  [clojure.lang.LazySeq seq ""LazySeq.java"" 51]\n  [clojure.lang.Cons next ""Cons.java"" 39]\n  [clojure.lang.RT countFrom ""RT.java"" 653]\n  [clojure.lang.RT count ""RT.java"" 643]\n  [metabase.pulse.render.table$render_table_body$iter__72086__72090$fn__72091$iter__72125__72129$fn__72130\n   invoke\n   ""table.clj""\n   130]\n```', 'created_at': datetime.datetime(2025, 1, 30, 14, 36, 3, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-15 13:07:24 UTC): it says: Error reducing result rows: Unsupported field: DayOfMonth

mva-coinify on (2025-01-30 14:36:03 UTC): This is a major issue and I'm surprised it has not been fixed yet. The consequence of this is essentially random crashes of pulses, which are very hard to debug because of the incoherent error message as @paoliniluis mentioned above. 

Here's a snippet from a stacktrace from version 48:

```
[e532a385-2ee5-494d-bc76-619274dd9d27] 2025-01-30T14:11:36+01:00 ERROR metabase.server.middleware.log POST /api/pulse/test 500 7.5 mins (788 DB calls) 
{:via
 [{:type java.time.temporal.UnsupportedTemporalTypeException,
   :message ""Unsupported field: DayOfWeek"",
   :at [java.time.temporal.TemporalAccessor range nil -1]}],
 :trace
 [[java.time.temporal.TemporalAccessor range nil -1]
  [java.time.LocalTime range nil -1]
  [java.time.OffsetTime range nil -1]
  [java.time.temporal.TemporalAccessor get nil -1]
  [java.time.OffsetTime get nil -1]
  [java.time.temporal.WeekFields$ComputedDayOfField localizedDayOfWeek nil -1]
  [java.time.temporal.WeekFields$ComputedDayOfField localizedWeekBasedYear nil -1]
  [java.time.temporal.WeekFields$ComputedDayOfField getFrom nil -1]
  [java.time.OffsetTime getLong nil -1]
  [java.time.format.DateTimePrintContext getValue nil -1]
  [java.time.format.DateTimeFormatterBuilder$NumberPrinterParser format nil -1]
  [java.time.format.DateTimeFormatterBuilder$WeekBasedFieldPrinterParser format nil -1]
  [java.time.format.DateTimeFormatterBuilder$CompositePrinterParser format nil -1]
  [java.time.format.DateTimeFormatter formatTo nil -1]
  [java.time.format.DateTimeFormatter format nil -1]
  [java_time.format$format invokeStatic ""format.clj"" 82]
  [java_time.format$format invoke ""format.clj"" 66]
  [metabase.pulse.render.datetime$reformat_temporal_str invokeStatic ""datetime.clj"" 29]
  [metabase.pulse.render.datetime$reformat_temporal_str invoke ""datetime.clj"" 28]
  [metabase.pulse.render.datetime$format_temporal_str invokeStatic ""datetime.clj"" 127]
  [metabase.pulse.render.datetime$format_temporal_str invoke ""datetime.clj"" 66]
  [metabase.pulse.render.body$fn__72208$get_format__72213$fn__72214$fn__72215 invoke ""body.clj"" 87]
  [metabase.pulse.render.body$fn__72291$query_results__GT_row_seq__72296$fn__72300$iter__72304__72308$fn__72309$iter__72343__72347$fn__72348
   invoke
   ""body.clj""
   170]
  [clojure.lang.LazySeq sval ""LazySeq.java"" 42]
  [clojure.lang.LazySeq seq ""LazySeq.java"" 51]
  [clojure.lang.Cons next ""Cons.java"" 39]
  [clojure.lang.RT countFrom ""RT.java"" 653]
  [clojure.lang.RT count ""RT.java"" 643]
  [metabase.pulse.render.table$render_table_body$iter__72086__72090$fn__72091$iter__72125__72129$fn__72130
   invoke
   ""table.clj""
   130]
```

"
2587887785,issue,open,,Use memorable passwords instead of random passwords for the cli,"We should use a more memorable type of password in the embedding sdk's CLI, similar to 1Password.

![Image](https://github.com/user-attachments/assets/2c9f21a6-e962-437a-9adc-fcaf187e1739)
",heypoom,2024-10-15 07:27:43+00:00,[],2025-02-04 20:30:55+00:00,,https://github.com/metabase/metabase/issues/48713,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React'), ('Embedding/SDK-CLI', 'Onboarding CLI for React SDK')]",[],
2587870349,issue,closed,completed,Autocomplete suggestions reset users choice on load,"### Describe the bug

https://github.com/user-attachments/assets/32e0fa4e-5349-4fa2-b8eb-fa518ebc80ec


### To Reproduce

1. New > Native query
2. Type ""pro"" and wait for autosuggestions to load
3. Delete ""pro""
4. Type ""select * from pro"" and once autocomplete suggestion popover opens quickly hit Arrow Down (and Enter if you want to experience extra annoyance)

Once GET `/database/:id/autocomplete_suggestions` completes, the selection state is reset in the autocomplete dropdown



### Expected behavior

""PRODUCTS"" is selected


### Information about your Metabase installation

master, a1d8face34

### Severity

P2 (annoying)
",kamilmielnik,2024-10-15 07:18:25+00:00,['romeovs'],2025-01-29 17:39:23+00:00,2025-01-29 17:39:23+00:00,https://github.com/metabase/metabase/issues/48712,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2598483702, 'issue_id': 2587870349, 'author': 'kamilmielnik', 'body': '@romeovs your #51632 will fix this, so I assigned you and linked your PR. It might need a repro though.', 'created_at': datetime.datetime(2025, 1, 17, 14, 25, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598490991, 'issue_id': 2587870349, 'author': 'romeovs', 'body': ""@kamilmielnik Thanks, I'll add a reproduction to the PR."", 'created_at': datetime.datetime(2025, 1, 17, 14, 28, 56, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2025-01-17 14:25:28 UTC): @romeovs your #51632 will fix this, so I assigned you and linked your PR. It might need a repro though.

romeovs (Assginee) on (2025-01-17 14:28:56 UTC): @kamilmielnik Thanks, I'll add a reproduction to the PR.

"
2587432009,issue,closed,completed,The page is automatically closed,"### Describe the bug

On the report page, when all filter options of the current filter are cleared from the existing filters, the page will automatically close.

### To Reproduce

![Image](https://github.com/user-attachments/assets/a075918a-0c16-485c-a9af-54aa1a1f2ad9)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

I don't know

### Severity

Significantly impacts the user experience.

### Additional context

_No response_",githubdawn,2024-10-15 02:08:59+00:00,[],2024-10-15 02:30:27+00:00,2024-10-15 02:30:25+00:00,https://github.com/metabase/metabase/issues/48711,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2412670188, 'issue_id': 2587432009, 'author': 'githubdawn', 'body': 'Is this a bug that needs to be solved urgently? Is it a version problem? The current running version is 0.50.19', 'created_at': datetime.datetime(2024, 10, 15, 2, 11, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412685074, 'issue_id': 2587432009, 'author': 'dpsutton', 'body': 'I believe this issue was reported in https://github.com/metabase/metabase/issues/46570, fixed in https://github.com/metabase/metabase/pull/46754, and released in v0.50.20 https://github.com/metabase/metabase/releases/tag/v0.50.20', 'created_at': datetime.datetime(2024, 10, 15, 2, 30, 25, tzinfo=datetime.timezone.utc)}]","githubdawn (Issue Creator) on (2024-10-15 02:11:40 UTC): Is this a bug that needs to be solved urgently? Is it a version problem? The current running version is 0.50.19

dpsutton on (2024-10-15 02:30:25 UTC): I believe this issue was reported in https://github.com/metabase/metabase/issues/46570, fixed in https://github.com/metabase/metabase/pull/46754, and released in v0.50.20 https://github.com/metabase/metabase/releases/tag/v0.50.20

"
2587085712,issue,closed,completed,"Column sandboxing powered by a SQL question still shows all columns in query builder, leading to errors","### Describe the bug

As an admin, you can set up a sandbox powered by a SQL question which selects a subset of columns from a table, in order to restrict the columns which a user should have access to.

However, the user still is able to see the full list of columns in the query builder, and thus might try to create a query which will subsequently error due to the sandbox. 

### To Reproduce

1. As an admin, create a SQL question as a base for sandboxing like:
```sql
select ID, USER_ID, TAX, TOTAL from ORDERS where USER_ID = 1;
```
2. Sandbox Orders table for ""All users"" using this SQL question
3. Log in as a non-admin, and start a new question using the query builder
4. You'll be able to see the full list of fields in the table in the query builder, and if you try to create a question that includes all fields, you will get an error

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

n/a (already fixed)

### Severity

P1

### Additional context

_No response_",noahmoss,2024-10-14 21:15:21+00:00,[],2024-10-14 21:16:17+00:00,2024-10-14 21:15:49+00:00,https://github.com/metabase/metabase/issues/48707,"[('Type:Bug', 'Product defects'), ('.Escalation', '')]","[{'comment_id': 2412356896, 'issue_id': 2587085712, 'author': 'noahmoss', 'body': 'Fixed by https://github.com/metabase/metabase/pull/48577', 'created_at': datetime.datetime(2024, 10, 14, 21, 15, 49, tzinfo=datetime.timezone.utc)}]","noahmoss (Issue Creator) on (2024-10-14 21:15:49 UTC): Fixed by https://github.com/metabase/metabase/pull/48577

"
2586948486,issue,open,,Model Persistence Tasks not Updated when Changing the DB Connection for a Model,"### Describe the bug

If you have model persistence enabled for model, then change the source database for the model, the persistence tasks continue to (attempt to) run against the original target DB.

### To Reproduce

1. Set up a test question on a Postgres SB
2. Promote to a model
3. Enabled model persistence on a schedule and set it to run the next minute
4. Verify the model has been persisted
5. Edit the model definition and choose a table in a different DB Connection as the source
6. Save the change
7. Refresh the model cache
8. Observe error via ""Admin-> Tasks - persist-refresh"" job:

`
{""success"":0,""error"":1,""trigger"":""Manual"",""error-details"":[{""persisted-info-id"":159,""error"":""ERROR: cross-database references are not implemented: \""v3_sample-dataset.TEST.TEST_TABLE\""\n  Position: 161""}]}
`

**Note:** Generally you'll see the cross-database error (tested with BQ and Snowflake) but in some cases you'll get a syntax error when the model persistence task runs (ran into this targeting MySQL as the new database). When you get the syntax error it's less obvious what's causing the problem.

### Expected behavior

If the new target DB doesn't offer model persistence I imagine we should disable the persistence tasks and notify the user.

If model persistence does exist for the target DB attempt to migrate the persisted model to the new source?

### Logs

{""success"":0,""error"":1,""trigger"":""Manual"",""error-details"":[{""persisted-info-id"":159,""error"":""ERROR: cross-database references are not implemented: \""v3_sample-dataset.TEST.TEST_TABLE\""\n  Position: 161""}]}

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""snowflake"",
      ""bigquery-cloud-sdk"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-10"",
      ""tag"": ""v1.50.25"",
      ""hash"": ""473a7ca""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

Annoying

### Additional context

In this case the user was switching from a DB that allows model persistence to one that does not so we were able to simply turn off model persistence on the original DB to stop the errors. However, if the new source DB did allow model persistence there's no way to transition the persisted jobs without modifying the ""persisted_info"" table.",ixipixi,2024-10-14 20:13:42+00:00,[],2025-02-04 20:28:23+00:00,,https://github.com/metabase/metabase/issues/48703,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/Cache', ''), ('.Team/Querying', '')]",[],
2586821653,issue,closed,completed,"In question sidesheet, models appear to be based on themselves",Discussion here: https://github.com/metabase/metabase/pull/48315#issuecomment-2411947670,rafpaf,2024-10-14 19:01:01+00:00,[],2024-11-12 23:46:46+00:00,2024-10-29 15:05:41+00:00,https://github.com/metabase/metabase/issues/48698,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2432212819, 'issue_id': 2586821653, 'author': 'rafpaf', 'body': 'Upgrading priority to P2 since the sources for models are now inaccurate. The table is not included in the list, and the model itself is. The sources for a model are not listed in the header, so this means crucial info is missing.', 'created_at': datetime.datetime(2024, 10, 23, 13, 34, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471871809, 'issue_id': 2586821653, 'author': 'iethree', 'body': ""note: SQL models don't work in v51, but seem to work on master. Might be because of native SQL parsing?"", 'created_at': datetime.datetime(2024, 11, 12, 23, 46, 19, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-10-23 13:34:06 UTC): Upgrading priority to P2 since the sources for models are now inaccurate. The table is not included in the list, and the model itself is. The sources for a model are not listed in the header, so this means crucial info is missing.

iethree on (2024-11-12 23:46:19 UTC): note: SQL models don't work in v51, but seem to work on master. Might be because of native SQL parsing?

"
2586565972,issue,closed,completed,Warning is not shown when trying to zoom in a line chart in an unsaved sql query,"### Describe the bug

When trying to zoom in a line chart in an unsaved sql query nothing happens
https://www.loom.com/share/ecba0c9b068c4991be321c7d689cb1b1

### To Reproduce

1. Click + New SQL
2. Write some code and visualize it as a line chart but don't save
3. Try to zoom in part of the chart

### Expected behavior

It should show the same modal ""Save this question to drill-thru"" as for the other drills

### Logs

_No response_

### Information about your Metabase installation

464902f

### Severity

very minor

### Additional context

_No response_",mngr,2024-10-14 16:51:19+00:00,[],2024-10-17 16:40:57+00:00,2024-10-17 16:40:57+00:00,https://github.com/metabase/metabase/issues/48693,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2418382490, 'issue_id': 2586565972, 'author': 'ranquild', 'body': ""@mngr currently the behavior is different. We don't allow brush filters for unsaved native queries"", 'created_at': datetime.datetime(2024, 10, 17, 2, 46, 21, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-10-17 02:46:21 UTC): @mngr currently the behavior is different. We don't allow brush filters for unsaved native queries

"
2586561746,issue,closed,not_planned,Date-picker Issue,"### Describe the bug

When i execute the native query in the Metabase with hard-coded ""FROM_DATE"" and ""TO_DATE"", it is giving me ""**correct results**"" same as MYSQL DB.

But when i read From and To Date from the **date-picker of Metabase** then i am getting **one day older data**.

Note: 
Both Metabase and MySQL both zones are in-sync.


Please share the steps to resolve the date-picker issue.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

Even i select the from and to date from the date picker from Metabase, native sql query should give the same result as hard code dates.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""1.8.0_401-b10"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""http://java.oracle.com/"",
    ""java.version"": ""1.8.0_401"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""25.401-b10"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.18.0-425.19.2.el8_7.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Kolkata""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""run-mode"": ""prod"",
    ""version"": {
      ""tag"": ""v0.33.6"",
      ""date"": ""2019-11-19"",
      ""branch"": ""release-0.33.x"",
      ""hash"": ""be1e0e1""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

### Severity

blocking my usage

### Additional context

_No response_",krishna-tech-dot,2024-10-14 16:48:38+00:00,[],2024-10-14 17:44:24+00:00,2024-10-14 17:44:23+00:00,https://github.com/metabase/metabase/issues/48692,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2411879676, 'issue_id': 2586561746, 'author': 'paoliniluis', 'body': 'your version of metabase is so old that this might have been fixed in the last 4 years, please upgrade', 'created_at': datetime.datetime(2024, 10, 14, 17, 44, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-14 17:44:23 UTC): your version of metabase is so old that this might have been fixed in the last 4 years, please upgrade

"
2586541732,issue,closed,completed,Wrong header when doing the native drill thru,"### Describe the bug

When doing some of the native drill thrus (sort by this column, filter by this column, ...?), we show a header and breadcrumbs like it's a model
![Image](https://github.com/user-attachments/assets/95554538-307b-40e6-ae33-1f55c02216a5)


### To Reproduce

1. Create and save a sql query like `select * from orders`
2. Click on the column header in the table view
3. Click sort button, or click Filter by this column and apply settings
4. See the header and breadcrumbs like for a model


### Expected behavior

We should show a header and breadcrumbs to reflect that it's a new ad-hoc mbql question created on top of the sql question as a data source.
![Image](https://github.com/user-attachments/assets/696dbac9-eb10-481a-b611-bfc943e6d9f0)

### Logs

_No response_

### Information about your Metabase installation

464902f

### Severity

Minor

### Additional context

_No response_",mngr,2024-10-14 16:40:19+00:00,['ranquild'],2024-10-18 02:13:13+00:00,2024-10-17 15:58:32+00:00,https://github.com/metabase/metabase/issues/48690,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]",[],
2586336454,issue,closed,not_planned,Wrong results using dropdown list with string contains,"### Describe the bug

Wrong results when I select one item of dropdown list and the filter widget type is 'string contains'.
This caused a lot of divergence in my reports, because in the Dashboard the results are correct, but in the question they are not.
Now I need to update all the questions with this condition.

I`m using BigQuery.

![Image](https://github.com/user-attachments/assets/5d02891f-a8fb-466b-b184-044a6ad110b9)


### To Reproduce

1. Go to native query
2. Create a variable
3. Set variable filter = field filter
4. Mapping the field
5. Set filter widget type = string contains
6. Use dropdown list
7. Use the filter to select only one item


### Expected behavior

I believe that when only one item is selected, the query should filter by that item alone. Or, when a dropdown list is selected, then the filter widget type should be set to 'string'.

OR

When the filter widget type is set to 'string contains', then the filter type shouldn't be allowed to be a 'dropdown list'.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v1.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

P1

### Additional context

_No response_",fer-batista,2024-10-14 15:07:26+00:00,[],2025-01-10 15:06:42+00:00,2025-01-10 15:06:40+00:00,https://github.com/metabase/metabase/issues/48686,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2569530888, 'issue_id': 2586336454, 'author': 'ranquild', 'body': 'To me it looks like the expected behavior. There is a **contains** filter with a value from a dropdown. Only this value is selected in the filter.', 'created_at': datetime.datetime(2025, 1, 3, 16, 51, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582917169, 'issue_id': 2586336454, 'author': 'mngr', 'body': 'This is the expected behavior, indeed', 'created_at': datetime.datetime(2025, 1, 10, 15, 6, 40, tzinfo=datetime.timezone.utc)}]","ranquild on (2025-01-03 16:51:19 UTC): To me it looks like the expected behavior. There is a **contains** filter with a value from a dropdown. Only this value is selected in the filter.

mngr on (2025-01-10 15:06:40 UTC): This is the expected behavior, indeed

"
2586287342,issue,open,,[Epic] Showing columns from all stages — follow-ups,"**Links**
- product doc: https://www.notion.so/metabase/Showing-columns-from-all-stages-follow-ups-11569354c901803c836ec5cd85b04dbc
- links
  - original epic: #46519 (issues below have been extracted from that epic)

**Implementation Plan**


```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/issues/46932
- [ ] https://github.com/metabase/metabase/issues/46774
- [ ] https://github.com/metabase/metabase/issues/48298
- [ ] https://github.com/metabase/metabase/issues/46845
```

",kamilmielnik,2024-10-14 14:50:24+00:00,['kamilmielnik'],2024-11-18 17:33:26+00:00,,https://github.com/metabase/metabase/issues/48681,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2586074084,issue,open,,Performance suggestions,"Hi! I recently added tracing to our Metabase instance (v1.50.28) and identified some traces that appear unnecessarily verbose. 

Disclaimer: I am not a software developer myself and there may be good reasons for (some of) these implementations. 

- GET /api/database with `saved=true`
    - Does a permissions query for every single database in the app. That is 445 queries to our database.
- GET /api/collection/
    - Does a separate query for every single user (>1000 for us). 
- GET /api/activity/recents with `context=views`
    - The following query is executed like 30 times: `SELECT * FROM ""collection"" WHERE (""id"" IS NULL) OR (""id"" IN (SELECT ""id"" FROM (SELECT ""c"".* FROM ""collection"" AS ""c"") AS ""c"" WHERE TRUE))`.
- GET /api/search with `models=dataset&filter_items_in_personal_collection=exclude&model_ancestors=false&limit=1`
    - At the end of the two massive search queries there are ~1000 filters on the form `and collection.location not like ?`.
        - Seems unnecessary when there are only ~100 distinct locations to pick from.
        - Not sure how much this affects the query time as those queries seem pretty large either way.
- The query `select * from permission_revision order by id` is always >1s.
    - We have a large number of permission groups and databases.
    - I imagine there is no easy fix here, but worth mentioning. 

Metabase version: 1.50.28 (self hosted)
Database: PostgeSQL 12 

Let me know if you need additional information.",vebjorre,2024-10-14 13:35:29+00:00,['nvoxland'],2025-02-05 18:47:29+00:00,,https://github.com/metabase/metabase/issues/48674,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Organization/Search', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2585436606,issue,closed,completed,Deleting a model doesn't remove it from database.,"### Describe the bug

Deleting a model doesn't remove from database.

### To Reproduce

1. Go to View archive
2. Delete a model
3. Go to the database side
4. The model is still persisted


### Expected behavior

It should be removed from the database

### Logs

_No response_

### Information about your Metabase installation

Metabase version: v0.50.29
Metabase hosting environment: Jar-file
Metabase internal database : MySQL

### Severity

Unable to clean the database, which consumes disk space and leads to database clutter.

### Additional context

_No response_",vipera7,2024-10-14 09:41:33+00:00,['noahmoss'],2024-10-28 13:10:28+00:00,2024-10-25 21:15:54+00:00,https://github.com/metabase/metabase/issues/48664,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('Organization/Trash', 'Where deleted items go'), ('.Product Input Needed', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2410844709, 'issue_id': 2585436606, 'author': 'kamilmielnik', 'body': 'Related Slack thread: https://metaboat.slack.com/archives/C05NXACAG1G/p1728898909893109', 'created_at': datetime.datetime(2024, 10, 14, 10, 49, 35, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-14 10:49:35 UTC): Related Slack thread: https://metaboat.slack.com/archives/C05NXACAG1G/p1728898909893109

"
2585338234,issue,open,,Cannot change the type of a column,"### Describe the bug

Cannot change the type of a column.

### To Reproduce

1. Navigate to the ""Upload Data"" section.
2. Select and upload a CSV file.
_Sample data:_

```
Date;SerialNumber0;RevisionID
11/10/2024 18:47:01;48211;1
11/10/2024 18:47:02;48212;0

```
A model is automatically created.
Modify the CSV file as follows:

```
Date;SerialNumber0;RevisionID
11/10/2024 18:47:01;48211;1
11/10/2024 18:47:02;48212;3
```
3. Click on ""Replace all data in this model"" using the updated CSV file.
4. Encounter the following error during upload:

```
Upload error details:
There were some errors while uploading test_upload.csv:
'3' is not a recognizable boolean
```

Problem: I am unable to change the data type of the ""RevisionID"" column using the metadata.

### Expected behavior

I should have the ability to modify the data type of this column to upload the updated file.

### Logs

[8ccb5d5a-3660-47ff-bdee-60ae91bdece5] 2024-10-14T10:58:54+02:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 73,9 ms (11 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (5 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
[8ccb5d5a-3660-47ff-bdee-60ae91bdece5] 2024-10-14T10:58:55+02:00 DEBUG metabase.server.middleware.log GET /api/table/2838 200 20,2 ms (3 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (6 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 2}
[8ccb5d5a-3660-47ff-bdee-60ae91bdece5] 2024-10-14T10:58:56+02:00 DEBUG metabase.server.middleware.log GET /api/persist 200 50,2 ms (5 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (6 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
[8ccb5d5a-3660-47ff-bdee-60ae91bdece5] 2024-10-14T10:58:57+02:00 WARN metabase.server.middleware.log POST /api/table/2838/replace-csv 422 1,5 s (7 DB calls) {:metabase-user-id 2} 
{:message ""'3' is not a recognizable boolean""}

### Information about your Metabase installation

Metabase version: v0.50.29
Metabase hosting environment: Jar-file
Metabase internal database : MySQL

### Severity

Cannot upload new data to the model

### Additional context

_No response_",vipera7,2024-10-14 09:04:03+00:00,['wotbrew'],2025-02-04 20:27:27+00:00,,https://github.com/metabase/metabase/issues/48662,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2426450884, 'issue_id': 2585338234, 'author': 'crisptrutski', 'body': 'This would be fixed if we allow boolean columns to be promoted to integers @luizarakaki', 'created_at': datetime.datetime(2024, 10, 21, 11, 49, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575924464, 'issue_id': 2585338234, 'author': 'luizarakaki', 'body': 'Yes, we should support this type of resolution. We already do with some, right? Like int > float.\nMakes sense to do boolean > int or boolean > float.', 'created_at': datetime.datetime(2025, 1, 7, 18, 5, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-10-21 11:49:56 UTC): This would be fixed if we allow boolean columns to be promoted to integers @luizarakaki

luizarakaki on (2025-01-07 18:05:00 UTC): Yes, we should support this type of resolution. We already do with some, right? Like int > float.
Makes sense to do boolean > int or boolean > float.

"
2585149449,issue,open,,"Log axis showing wrong values for decimal in [0,1]","### Describe the bug

When plotting a scatter chart with points having values within the [0,1] interval using a logarithmic scale, the values shown on the axis don't match the data point values.

On the example below (fake data), I set the X axis (Revenue Amount USD) to be log scaled and Y axis as linear. We can see the X value of the point is within [0,1] yet the axis shows a value somewhere in [-10000, -3000]. This is misleading.

![Image](https://github.com/user-attachments/assets/ce267a09-8887-43a8-9a06-ea8a221a94e2)


### To Reproduce

1. Create a new question which output a table with at least 2 decimal columns, one of them having values within the [0,1] interval
2. Create a visualisation using the scatter plot
3. Choose the 2 decimal columns as X & Y axis
4. In the Axis tab, set the scale to log for the column with values in [0,1]
5. See the axis showing wrong values 


### Expected behavior

The axis should show values between 0 and 1 like 0.1, 0.01, 0.001 and so on or even as scientific notation 10^-3 for example.

### Logs

```
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:31+02:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 46.7 ms (10 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (63 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:31+02:00 DEBUG metabase.server.middleware.log GET /api/setting 200 56.9 ms (15 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (3 idle, 0 queued) (64 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:31+02:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 185.1 ms (10 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (1 idle, 0 queued) (66 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:31+02:00 DEBUG metabase.server.middleware.log GET /api/setting 200 300.5 ms (14 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (66 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:31+02:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 223.7 ms (11 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (66 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:33+02:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 5.5 ms (1 DB calls) App DB connections: 0/15 Jetty threads: 3/50 (4 idle, 0 queued) (68 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:39+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 142.2 µs (0 DB calls) App DB connections: 0/15 Jetty threads: 3/50 (4 idle, 0 queued) (68 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:42+02:00 DEBUG metabase.server.middleware.log GET /api/health 200 183.3 µs (0 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (3 idle, 0 queued) (68 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id nil}
[8c808a4d-6c1c-41a0-aebf-c70a4396d8c8] 2024-10-14T09:58:45+02:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 1.6 s (5 DB calls) App DB connections: 1/15 Jetty threads: 2/50 (5 idle, 0 queued) (70 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 5}```

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.15""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.12+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.12"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.12+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  }
}

### Severity

Showing wrong data

### Additional context

_No response_",Timelessprod,2024-10-14 08:00:47+00:00,[],2025-02-04 20:31:15+00:00,,https://github.com/metabase/metabase/issues/48659,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Correctness', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2584341515,issue,closed,not_planned,"v0.51.0-beta error message on startup ""Unhandled error when attempting to analyse the next card in the queue""","### Describe the bug

Error in logged on startup. Fresh Metabase instance, no data sources connected, running straight from jar file.

```
2024-10-11 09:16:10,415 ::::: [main] INFO  metabase.core - Metabase Initialization COMPLETE in 25.9 s
2024-10-11 09:16:11,716 ::::: [MetabaseScheduler_Worker-1] INFO  metabase.task.sweep-query-analysis - Recalculating potentially stale analysis
2024-10-11 09:16:11,718 ::::: [MetabaseScheduler_Worker-2] ERROR metabase.task.analyze-queries - Unhandled error when attempting to analyse the next card in the queue
clojure.lang.ExceptionInfo: You can't operate on a closed ResultSet!!!
	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118) ~[metabase.jar:?]
	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:77) ~[metabase.jar:?]
	at com.mchange.v2.c3p0.impl.NewProxyResultSet.getObject(NewProxyResultSet.java:171) ~[metabase.jar:?]
	at toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26091.invoke(read.clj:73) ~[metabase.jar:?]
	at toucan2.jdbc.read$read_column_thunk_after_method_default$fn__26103.invoke(read.clj:79) ~[metabase.jar:?]
	at toucan2.jdbc.read$make_column_thunk$column_thunk__26136.invoke(read.clj:136) ~[metabase.jar:?]
	at toucan2.jdbc.read$make_cached_row_num__GT_i__GT_thunk$row_num__GT_i__GT_thunk_STAR___26145$i__GT_thunk_STAR___26146$cached_column_thunk__26147.invoke(read.clj:180) ~[metabase.jar:?]
	at toucan2.jdbc.row$fetch_column_with_name.invokeStatic(row.clj:36) ~[metabase.jar:?]
	at toucan2.jdbc.row$fetch_column_with_name.invoke(row.clj:26) ~[metabase.jar:?]
	at toucan2.jdbc.row.TransientRow.valAt(row.clj:211) ~[metabase.jar:?]
	at toucan2.jdbc.row.TransientRow.valAt(row.clj:192) ~[metabase.jar:?]
	at clojure.lang.KeywordLookupSite$1.get(KeywordLookupSite.java:45) ~[metabase.jar:?]
	at metabase.util$id.invokeStatic(util.cljc:452) ~[metabase.jar:?]
	at metabase.util$id.invoke(util.cljc:443) ~[metabase.jar:?]
	at metabase.util$the_id.invokeStatic(util.cljc:462) ~[metabase.jar:?]
	at metabase.util$the_id.invoke(util.cljc:455) ~[metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_STAR_.invokeStatic(analyze_queries.clj:44) [metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_STAR_.invoke(analyze_queries.clj:40) [metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:72) [metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68) [metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:70) [metabase.jar:?]
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68) [metabase.jar:?]
	at metabase.task.analyze_queries.QueryAnalyzer.execute(analyze_queries.clj:81) [metabase.jar:?]
	at org.quartz.core.JobRunShell.run(JobRunShell.java:202) [metabase.jar:?]
	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573) [metabase.jar:?]
Caused by: java.sql.SQLException: You can't operate on a closed ResultSet!!!
	... 25 more
Caused by: java.lang.NullPointerException: Cannot invoke ""java.sql.ResultSet.getObject(int)"" because ""this.inner"" is null
	at com.mchange.v2.c3p0.impl.NewProxyResultSet.getObject(NewProxyResultSet.java:165) ~[metabase.jar:?]
	... 22 more
```

I've ignored the error and can continue to use the system with no other noticeable issues.

This message is generated each time I start that Metabase instance.


### To Reproduce

1. With v0.51.0-beta jar file
2. `java -jar -jar metabase.jar`
3. Error is displayed
4. Error generates each time I run that instance


### Expected behavior

No errors.

### Logs

As listed.

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-08"",
      ""tag"": ""v0.51.0-beta"",
      ""hash"": ""f69afc2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows 10"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  }
}

### Severity

Minor

### Additional context

_No response_",notrom,2024-10-13 22:50:50+00:00,[],2024-10-21 11:47:52+00:00,2024-10-14 02:40:02+00:00,https://github.com/metabase/metabase/issues/48656,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.Needs Triage', ''), ('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2409264987, 'issue_id': 2584341515, 'author': 'perivamsi', 'body': 'I think this is a known issue\n\n@metabase/core-backend-components', 'created_at': datetime.datetime(2024, 10, 13, 22, 55, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409823346, 'issue_id': 2584341515, 'author': 'qnkhuat', 'body': 'yea, dup of https://github.com/metabase/metabase/issues/48550#issuecomment-2408071420', 'created_at': datetime.datetime(2024, 10, 14, 2, 40, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426446431, 'issue_id': 2584341515, 'author': 'crisptrutski', 'body': 'This should be fixed in the next beta (`v1.50.0.1-beta`)', 'created_at': datetime.datetime(2024, 10, 21, 11, 47, 51, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-10-13 22:55:54 UTC): I think this is a known issue

@metabase/core-backend-components

qnkhuat on (2024-10-14 02:40:02 UTC): yea, dup of https://github.com/metabase/metabase/issues/48550#issuecomment-2408071420

crisptrutski on (2024-10-21 11:47:51 UTC): This should be fixed in the next beta (`v1.50.0.1-beta`)

"
2583658259,issue,open,,Make MAX_SERIES configurable,"**Is your feature request related to a problem? Please describe.**
Some users use Metabase for use cases we never imagined, e.g.: WAF records visualization, where you would have way more than 100 series

**Describe the solution you'd like**
Make the constant of MAX_SERIES configurable via an env var

**Describe alternatives you've considered**
A custom build

**How important is this feature to you?**
Could make Metabase a possibility for some additional use cases like the one I mentioned above

**Additional context**
NA
",paoliniluis,2024-10-13 05:11:03+00:00,[],2025-02-04 20:31:27+00:00,,https://github.com/metabase/metabase/issues/48655,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]",[],
2583655798,issue,open,,Resize tables unless there's more data than what can fit in a defined table size,"**Is your feature request related to a problem? Please describe.**
If the table is less than a specified number of rows we should resize the table to the results, but when there's more, we should respect the dashboard creator definition and then paginate

**Describe the solution you'd like**
Above

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Seems important for embedding contexts where users don't want any possibility of a scrollbar

**Additional context**
Ticket 31020
",paoliniluis,2024-10-13 05:02:24+00:00,[],2025-02-04 20:31:56+00:00,,https://github.com/metabase/metabase/issues/48654,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('Embedding/Static', 'Static embedding, previously known as signed embedding')]",[],
2583651107,issue,closed,not_planned,Sign the JAR,"**Is your feature request related to a problem? Please describe.**
Seems that mac's don't like an unsigned JAR and it should be pretty simple to do when we do a release

**Describe the solution you'd like**
create a cert and sign the JAR when we do a release via jarsigner

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Could be interesting for strict isolation spaces/companies that don't let users run unsigned things

**Additional context**
We should check if this works by double clicking on the JAR file on a mac (and probably windows as well) and it works without showing an alert",paoliniluis,2024-10-13 04:55:25+00:00,[],2025-01-03 16:42:50+00:00,2025-01-03 16:42:49+00:00,https://github.com/metabase/metabase/issues/48653,"[('Type:New Feature', ''), ('.Building & Releasing', ''), ('.Team/DevEx', '')]","[{'comment_id': 2569520462, 'issue_id': 2583651107, 'author': 'brunobergher', 'body': 'As per the conclusion of our [Slack discussion](https://metaboat.slack.com/archives/C864UT5CZ/p1735921439846149):\n> So maybe if we self-sign we do allow people to double-click jars and run them in the background… I don’t think that benefits us (or them) too much tbh.\n\nClosing as not planned.', 'created_at': datetime.datetime(2025, 1, 3, 16, 42, 49, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 16:42:49 UTC): As per the conclusion of our [Slack discussion](https://metaboat.slack.com/archives/C864UT5CZ/p1735921439846149):

Closing as not planned.

"
2583602459,issue,closed,completed,Substitution variables break query when using s3 wildcards in clickhouse query,"### Describe the bug

Using both
- a wildcard inside a Clickhouse S3 Parquet query
- a Metabase template variable

breaks all queries with the error `Expected substitution name (identifier). (SYNTAX_ERROR)`.

### To Reproduce

_Assuming you're using a real S3 parquet file path_

This works:
```
(in Metabase UI, some_value = 'abcd')
SELECT col1 FROM s3('s3://my_bucket/my_file.parquet','Parquet') where col1 = {{ some_value }};
```

This works:
```
SELECT col1 FROM s3('s3://my_bucket/*.parquet','Parquet') where col1 = 'abcd';
```

**This does not work:**
```
(in Metabase UI, some_value = 'abcd')
SELECT col1 FROM s3('s3://my_bucket/*.parquet','Parquet') where col1 = {{ some_value }};
```

Yields the following error:
```Code: 62. DB::Exception: Syntax error: failed at position 276 ('{') (line 3, col 20): {some_value}}. Expected substitution name (identifier). (SYNTAX_ERROR) (version 24.8.4.13 (official build))```

### Expected behavior

The query should execute without a syntax error.

### Logs

```
{:type ""native"",
  :database 274,
  :native
  {:query
   ""with a as ( SELECT user_uuid\n    FROM\n      s3('s3://censored_path/*.parquet','Parquet')\n  )\nselect * from a where user_uuid = {{ some }}"",
   :template-tags
   {:some {:type ""text"", :name ""some"", :id ""68ef3abe-e843-4b97-b1f7-287ed184ac17"", :display-name ""Some""}}},
  :parameters
  [{:id ""68ef3abe-e843-4b97-b1f7-287ed184ac17"",
    :type ""category"",
    :value ""1234"",
    :target [""variable"" [""template-tag"" ""some""]]}],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class java.io.IOException,
 :stacktrace
 [""com.clickhouse.client.http.HttpUrlConnectionImpl.checkResponse(HttpUrlConnectionImpl.java:203)""
  ""com.clickhouse.client.http.HttpUrlConnectionImpl.post(HttpUrlConnectionImpl.java:246)""
  ""com.clickhouse.client.http.ClickHouseHttpClient.send(ClickHouseHttpClient.java:200)""
  ""com.clickhouse.client.AbstractClient.execute(AbstractClient.java:280)""
  ""com.clickhouse.client.ClickHouseClientBuilder$Agent.sendOnce(ClickHouseClientBuilder.java:282)""
  ""com.clickhouse.client.ClickHouseClientBuilder$Agent.send(ClickHouseClientBuilder.java:294)""
  ""com.clickhouse.client.ClickHouseClientBuilder$Agent.execute(ClickHouseClientBuilder.java:349)""
  ""com.clickhouse.client.ClickHouseClient.executeAndWait(ClickHouseClient.java:878)""
  ""com.clickhouse.client.ClickHouseRequest.executeAndWait(ClickHouseRequest.java:2154)""
  ""com.clickhouse.jdbc.internal.ClickHouseStatementImpl.getLastResponse(ClickHouseStatementImpl.java:137)""
  ""com.clickhouse.jdbc.internal.ClickHouseStatementImpl.executeQuery(ClickHouseStatementImpl.java:492)""
  ""com.clickhouse.jdbc.internal.ClickHouseStatementImpl.execute(ClickHouseStatementImpl.java:480)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__81085.invokeStatic(execute.clj:569)""
  ""driver.sql_jdbc.execute$fn__81085.invoke(execute.clj:567)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:577)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:574)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81166$fn__81167.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81166.invoke(execute.clj:713)""
  ""driver.sql_jdbc.execute$fn__80959$fn__80960.invoke(execute.clj:397)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
  ""driver.sql_jdbc.execute$fn__80959.invokeStatic(execute.clj:391)""
  ""driver.sql_jdbc.execute$fn__80959.invoke(execute.clj:389)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc$fn__114725.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__114725.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:88)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:81)""
  ""query_processor.execute$run.invokeStatic(execute.clj:61)""
  ""query_processor.execute$run.invoke(execute.clj:55)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__69662.invoke(execute.clj:24)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__69667.invoke(execute.clj:35)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___69653.invoke(cache.clj:242)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__63729.invoke(permissions.clj:118)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__109354$check_download_permissions__109355$fn__109356.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64305.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111193$maybe_apply_column_level_perms_check__111194$fn__111195.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64315.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__69694.invoke(execute.clj:93)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
  ""query_processor.execute$execute.invoke(execute.clj:88)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81535$handle_audit_app_internal_queries__81536$fn__81537.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64343.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75512.invoke(process_userland_query.clj:182)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75581.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__75618.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__64747.invoke(setup.clj:189)""
  ""query_processor.setup$do_with_database_local_settings$fn__64742.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__64737$fn__64738.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__64737.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__64730$fn__64733.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.setup$do_with_metadata_provider$fn__64730.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__64724.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__97912.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__68139$fn__68140$fn__68141.invoke(streaming.clj:175)""
  ""query_processor.streaming$_streaming_response$fn__68139$fn__68140.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__68139.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
  ""async.streaming_response$do_f_async$task__52169.invoke(streaming_response.clj:87)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""Code: 62. DB::Exception: Syntax error: failed at position 303 ('{') (line 6, col 36): { some }}. Expected substitution name (identifier). (SYNTAX_ERROR) (version 24.8.4.13 (official build))\n"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation
```
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.215-203.850.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""clickhouse"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-25"",
      ""tag"": ""v1.50.7"",
      ""hash"": ""431cd8f""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```

### Severity

Blocking a common query pattern, will be hard to work around

### Additional context

_No response_",lucasvanbramer,2024-10-13 03:30:27+00:00,[],2024-10-15 06:21:45+00:00,2024-10-15 06:21:17+00:00,https://github.com/metabase/metabase/issues/48652,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2408824108, 'issue_id': 2583602459, 'author': 'paoliniluis', 'body': 'Hi, can you create this issue in the clickhouse driver repository? also, which version of the clickhouse driver are you using?', 'created_at': datetime.datetime(2024, 10, 13, 4, 57, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409550164, 'issue_id': 2583602459, 'author': 'lucasvanbramer', 'body': '> Hi, can you create this issue in the clickhouse driver repository? also, which version of the clickhouse driver are you using?\n\nMigrated ticket to [here](https://github.com/ClickHouse/metabase-clickhouse-driver/issues/274) - version  `1.50.7`, btw.', 'created_at': datetime.datetime(2024, 10, 14, 1, 2, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412993435, 'issue_id': 2583602459, 'author': 'kamilmielnik', 'body': 'Closing as the issue is now tracked here: https://github.com/ClickHouse/metabase-clickhouse-driver/issues/274\nSee [Slack conversation](https://metaboat.slack.com/archives/C05NXACAG1G/p1728930948541289?thread_ts=1728790242.245969&cid=C05NXACAG1G).', 'created_at': datetime.datetime(2024, 10, 15, 6, 21, 17, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-13 04:57:50 UTC): Hi, can you create this issue in the clickhouse driver repository? also, which version of the clickhouse driver are you using?

lucasvanbramer (Issue Creator) on (2024-10-14 01:02:53 UTC): Migrated ticket to [here](https://github.com/ClickHouse/metabase-clickhouse-driver/issues/274) - version  `1.50.7`, btw.

kamilmielnik on (2024-10-15 06:21:17 UTC): Closing as the issue is now tracked here: https://github.com/ClickHouse/metabase-clickhouse-driver/issues/274
See [Slack conversation](https://metaboat.slack.com/archives/C05NXACAG1G/p1728930948541289?thread_ts=1728790242.245969&cid=C05NXACAG1G).

"
2582812077,issue,closed,not_planned,Metabase pulse report fails if we include both internal and external email addresses,"We have generated a Metabase pulse report; however, when we include both internal and external email addresses, the pulse fails, however when we include only internal email addresses, it succeeds. The most recent pulse report, which included both internal and external email addresses, was successful on September 9, 2024. Would you kindly suggest ",Chandra-cp,2024-10-12 10:48:12+00:00,[],2024-10-13 03:51:36+00:00,2024-10-12 16:40:48+00:00,https://github.com/metabase/metabase/issues/48651,[],"[{'comment_id': 2408621931, 'issue_id': 2582812077, 'author': 'paoliniluis', 'body': 'This is not an issue but a question. Please post this in our forums and include all relevant information', 'created_at': datetime.datetime(2024, 10, 12, 16, 40, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408808692, 'issue_id': 2582812077, 'author': 'Chandra-cp', 'body': 'Can you please share the path or url for forums?', 'created_at': datetime.datetime(2024, 10, 13, 3, 51, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-12 16:40:48 UTC): This is not an issue but a question. Please post this in our forums and include all relevant information

Chandra-cp (Issue Creator) on (2024-10-13 03:51:34 UTC): Can you please share the path or url for forums?

"
2582347003,issue,closed,completed,There should not be Pulse unsubscribe endpoints in `/api/session`,"We can't have a nice organized codebase if people don't work to keep it organized... you can't just put stuff wherever you want for no reason.

These were added in #30597... I'm guessing the reason was that endpoints in this namespace don't normally require auth. Still a terrible place to put these endpoints. We need to move somewhere more appropriate

CC @noahmoss since you reviewed the original PR",camsaul,2024-10-11 23:51:01+00:00,['camsaul'],2024-11-26 18:52:28+00:00,2024-10-19 00:10:53+00:00,https://github.com/metabase/metabase/issues/48647,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', '')]",[],
2582153881,issue,closed,completed,Error when unfold nested records in BigQuery,"### Describe the bug

Error when unfold nested records in BigQuery.

![Image](https://github.com/user-attachments/assets/d1e1401d-5fa2-44ab-aa29-504994ab0cea)

The first query created by Metabase return the error.
The second query created by me run fine.

BigQuery schema and query:
![Image](https://github.com/user-attachments/assets/bda893b7-3552-4abb-a7dd-fbb1473de379)
![Image](https://github.com/user-attachments/assets/66e29141-7cb3-40af-8067-750d088f0d8d)
![Image](https://github.com/user-attachments/assets/f52a582e-1f88-4406-8902-9a239e135563)



### To Reproduce

1. Go to query builder ou native SQL
2. Select a nested field
3. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

v1.51.0-beta

### Severity

P2

### Additional context

_No response_",fer-batista,2024-10-11 20:41:27+00:00,['snoe'],2024-10-21 20:59:43+00:00,2024-10-21 19:42:57+00:00,https://github.com/metabase/metabase/issues/48642,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/BigQuery', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2408130205, 'issue_id': 2582153881, 'author': 'luizarakaki', 'body': ""We don't support arrays (or repeated in BQ), but we also shouldn't error like this."", 'created_at': datetime.datetime(2024, 10, 11, 21, 16, 10, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-10-11 21:16:10 UTC): We don't support arrays (or repeated in BQ), but we also shouldn't error like this.

"
2582105709,issue,closed,completed,Joining Model on Model leading to Wrong Column Name Error,"### Describe the bug

This query used to work perfectly fine. Now when I attempt to join on Timestamp, a simple model with Timestamp and Value with a query that also has Timestamp and Value columns, for some reason the query builder decides to rename 'RIGHT JOIN ""public"".""djangoModels_historicaldata"" AS ""DjangoModels Historicaldata_2"" ON ""public"".""djangoModels_metadata"".""id"" = ""DjangoModels Historicaldata_2"".""metadata_id""'. This leads to the query failing because there is no such column named Historicaldata_2.

### To Reproduce

Start from a model, sum a column values by timestamp, then join with another model on timestamp


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""starter-yearly"",
    ""version"": {
      ""date"": ""2024-10-01"",
      ""tag"": ""v1.50.27.4"",
      ""hash"": ""83c850d""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}

### Severity

Blocking analysis of important data

### Additional context

![Image](https://github.com/user-attachments/assets/f44a05aa-3619-4529-b0af-432aeea62072)
![Image](https://github.com/user-attachments/assets/fffafb2c-23f4-4d0a-add5-fd65bd45bbd0)
![Image](https://github.com/user-attachments/assets/55762c62-3803-4e1a-81a4-016dd3270acf)

",jojayala,2024-10-11 20:03:09+00:00,['metamben'],2024-10-17 13:37:57+00:00,2024-10-17 13:37:57+00:00,https://github.com/metabase/metabase/issues/48639,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Postgres', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]",[],
2581821138,issue,closed,completed,"Investigate effect of not bundling node_modules in the sdk, in the build time of the host app","Follow up to [[Spike] Investigate if not doing a bundle helps with performances and (customer) bundle size](https://github.com/metabase/metabase/issues/48105)
We want to check if having a bundle without the deps will make the devex of the host apps better. Some bundlers/tools take +1 minute when the sdk is a dependency.

I'll start from [don't bundle the deps](https://github.com/metabase/metabase/pull/48360) and will try to record these timings with a few build tools:
- build with empty project
- build with normal sdk from master
- build with ""no node_modules""

The goal is to understand if we should keep the node_modules out of the bundle in order to improve the devex of customers working with the sdk


Results: https://www.notion.so/metabase/Results-for-Investigate-effect-of-not-bundling-node_modules-in-the-sdk-in-the-build-time-of-the-hos-12069354c9018097be15ff2c796afd67?pvs=4",npretto,2024-10-11 17:00:40+00:00,['npretto'],2024-10-15 11:18:20+00:00,2024-10-15 11:18:19+00:00,https://github.com/metabase/metabase/issues/48635,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', '')]","[{'comment_id': 2413608221, 'issue_id': 2581821138, 'author': 'npretto', 'body': ""Closing as [this doesn't seem to move us in the right direction](https://www.notion.so/metabase/Results-for-Investigate-effect-of-not-bundling-node_modules-in-the-sdk-in-the-build-time-of-the-hos-12069354c9018097be15ff2c796afd67)"", 'created_at': datetime.datetime(2024, 10, 15, 11, 18, 19, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-10-15 11:18:19 UTC): Closing as [this doesn't seem to move us in the right direction](https://www.notion.so/metabase/Results-for-Investigate-effect-of-not-bundling-node_modules-in-the-sdk-in-the-build-time-of-the-hos-12069354c9018097be15ff2c796afd67)

"
2581814109,issue,closed,completed,"[flaky test] ""public question sharing snowplow events when embedding question when interacting with static embedding should send `static_embed_published` when publishing changes in the static embed modal""","https://github.com/metabase/metabase/actions/runs/11269445619/attempts/1#summary-31338408708


The error was very confusing: 
```
Error: Snowplow retry timeout Expected 1 good Snowplow events with data: {
  ""event"": ""static_embed_published"",
  ""artifact"": ""question"",
  ""new_embed"": false,
  ""params"": {
    ""disabled"": 1,
    ""locked"": 1,
    ""enabled"": 1
  }
}
 Last event found was {
  ""event"": ""static_embed_published"",
  ""artifact"": ""question"",
  ""new_embed"": false,
  ""time_since_creation"": 3612,
  ""time_since_initial_publication"": 3604,
  ""params"": {
    ""disabled"": 1,
    ""locked"": 1,
    ""enabled"": 1
  },
  ""is_example_dashboard"": false
}
```
When I added the ""Last event found was"" message I didn't consider one thing, we expect a specific number of events to match the matcher.
In this case after some debug I found out we have more than 1 event matching that.",npretto,2024-10-11 16:57:05+00:00,['npretto'],2024-10-15 09:18:56+00:00,2024-10-15 08:14:02+00:00,https://github.com/metabase/metabase/issues/48634,"[('flaky-test-fix', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', '')]",[],
2581761534,issue,open,,Add `grouped_metrics` data + schema to snowplow,"**Context**

We need to add grouped metrics to our anonymous snowplow instance stats ping.

- [ ] copy `snowplow/iglu-client-embedded/schemas/com.metabase/instance_stats/jsonschema/1-0-1` into `snowplow/iglu-client-embedded/schemas/com.metabase/instance_stats/jsonschema/1-0-2`, and add the following json schema.

- [ ] add ""grouped_metrics"" as a required key on the top level json schema map 

- [ ] generate grouped_metrics data and pass it through `metabase.analytics.stats/phone-home-stats!`

----

Here's the WIP json schema that should go into `snowplow/iglu-client-embedded/schemas/com.metabase/instance_stats/jsonschema/1-0-2`.

``` json
""grouped_metrics"": {
      ""description"": ""Key-value pairs of grouped metrics, with tags."",
      ""type"": ""array"",
      ""items"": {
        ""description"": ""a Metric, which has a key a value and tags"",
        ""type"": ""object"",
        ""properties"": {
          ""name"": {
            ""description"": ""The unique name of the grouped metric"",
            ""type"": ""string"",
            ""maxLength"": 255
          },
          ""values"": {
            ""description"": ""Values for the grouped metric"",
            ""type"": ""array"",
            ""items"": {
              ""description"": ""Items in a groped metric value"",
              ""type"": ""object"",
              ""properties"": {
                ""group"": {
                  ""description"": ""The group name"",
                  ""type"": ""string"",
                  ""maxLength"": 255
                },
                ""value"": {
                  ""description"": ""The value for the group"",
                  ""type"": ""number"",
                  ""minimum"": 0,
                  ""maximum"": 9007199254740991
                }
              },
              ""required"": [""group"", ""value""],
              ""additionalProperties"": false
            }
          },
          ""tags"": {
            ""description"": ""Tags that can be used flagging teams / features the grouped_metric belongs to"",
            ""type"": ""array"",
            ""items"": {
              ""description"": ""a single tag"",
              ""type"": ""string"",
              ""maxLength"": 255
            }
          }
        },
        ""required"": [""name"", ""values"", ""tags""],
        ""additionalProperties"": false
      }
    },
```",escherize,2024-10-11 16:28:15+00:00,[],2025-02-04 20:23:53+00:00,,https://github.com/metabase/metabase/issues/48632,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2581650712,issue,closed,completed,Add release tag dropdown to release job,"It's annoying to remember to set a new release as ""latest"" after the release has completed. We should add a new optional parameter to the release publish job that lets you set a release channel for the release.

",iethree,2024-10-11 15:29:24+00:00,[],2024-11-26 18:51:58+00:00,2024-11-04 19:42:12+00:00,https://github.com/metabase/metabase/issues/48627,"[('.Building & Releasing', '')]",[],
2581548616,issue,closed,completed,Model that uses v1 metrics does not work after v2 migration,"Briefly, model that uses 2 v1 metrics fails to execute after the migration to v2 metrics.

- I've used tag `v0.49.25.2` where I defined those metrics. Then started the application on `v1.51.0.1-beta`. Migration ran successfully.
- I've used Postgresql as data warehouse (`test-data`) and application database.

Metric 1 definition (named mfa):
![Image](https://github.com/user-attachments/assets/9766cb6a-001f-4c9b-a753-1cebd145432c)


Metric 2 definition (named mt):
![Image](https://github.com/user-attachments/assets/e3f6fb2f-4942-4fc8-9429-9f7d483ae169)


Model:
![Image](https://github.com/user-attachments/assets/0921b8b7-90c3-4f84-88d8-01cf04d4cc8c)


Finally, opening that model after migration results in an error. Screenshot and trace follow.
![Image](https://github.com/user-attachments/assets/f65e1450-52cb-4b20-ac53-0df89824c0e4)


<details closed>
<summary>Trace</summary>
<code>
2024-10-11 14:27:54,548 ERROR middleware.catch-exceptions :: Error processing query: ERROR: column source.avg does not exist
  Position: 183
{:database_id 2,
 :started_at #t ""2024-10-11T14:27:53.964048Z[UTC]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: ERROR: column source.avg does not exist\n  Position: 183"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__140327$fn__140328.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__140327.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$eval140041$fn__140042$fn__140043.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$fn__139990$do_with_resolved_connection139989__139991.invoke(execute.clj:338)""
    ""driver.sql_jdbc.execute$fn__139990$fn__139994.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$eval140041$fn__140042.invoke(execute.clj:392)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$eval142036$fn__142037.invoke(sql_jdbc.clj:79)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:62)""
    ""query_processor.execute$run.invoke(execute.clj:56)""
    ""query_processor.middleware.update_used_cards$fn__104007$update_used_cards_BANG_104006__104008$_AMPERSAND_f__104009.invoke(update_used_cards.clj:60)""
    ""query_processor.middleware.update_used_cards$fn__104007$update_used_cards_BANG_104006__104008$fn__104019.invoke(update_used_cards.clj:52)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__104031.invoke(execute.clj:25)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__104037.invoke(execute.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___103857.invoke(cache.clj:239)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__102771.invoke(permissions.clj:147)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__100777.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__100787.invoke(enterprise.clj:64)""
    ""query_processor.execute$fn__104071$execute104070__104072$fn__104073.invoke(execute.clj:94)""
    ""query_processor.setup$fn__103338$do_with_qp_setup103337__103339.invoke(setup.clj:225)""
    ""query_processor.setup$fn__103338$fn__103343.invoke(setup.clj:216)""
    ""query_processor.execute$fn__104071$execute104070__104072.invoke(execute.clj:93)""
    ""query_processor.execute$fn__104071$fn__104076.invoke(execute.clj:89)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
    ""query_processor.middleware.enterprise$eval100804$handle_audit_app_internal_queries__100805$fn__100807.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__100815.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$fn__104458$process_userland_query_middleware104457__104459$_AMPERSAND_f__104460.invoke(process_userland_query.clj:204)""
    ""query_processor.middleware.process_userland_query$fn__104458$process_userland_query_middleware104457__104459$fn__104466.invoke(process_userland_query.clj:188)""
    ""query_processor.middleware.catch_exceptions$fn__104170$catch_exceptions104169__104171$_AMPERSAND_f__104172.invoke(catch_exceptions.clj:132)""
    ""query_processor.middleware.catch_exceptions$fn__104170$catch_exceptions104169__104171$fn__104187.invoke(catch_exceptions.clj:122)""
    ""query_processor$fn__104802$process_query104801__104803$fn__104804.invoke(query_processor.clj:80)""
    ""query_processor.setup$fn__103329$do_with_canceled_chan103328__103330$fn__103331.invoke(setup.clj:187)""
    ""query_processor.setup$fn__103318$do_with_database_local_settings103317__103319$fn__103320.invoke(setup.clj:181)""
    ""query_processor.setup$fn__103307$do_with_driver103306__103308$fn__103309$fn__103310.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:106)""
    ""driver$do_with_driver.invoke(driver.clj:101)""
    ""query_processor.setup$fn__103307$do_with_driver103306__103308$fn__103309.invoke(setup.clj:165)""
    ""query_processor.setup$fn__103294$do_with_metadata_provider103293__103295$fn__103296$fn__103299.invoke(setup.clj:151)""
    ""query_processor.store$fn__86949$do_with_metadata_provider86948__86950.invoke(store.clj:170)""
    ""query_processor.store$fn__86949$fn__86953.invoke(store.clj:150)""
    ""query_processor.store$fn__86949$do_with_metadata_provider86948__86950.invoke(store.clj:159)""
    ""query_processor.store$fn__86949$fn__86953.invoke(store.clj:150)""
    ""query_processor.setup$fn__103294$do_with_metadata_provider103293__103295$fn__103296.invoke(setup.clj:150)""
    ""query_processor.setup$fn__103274$do_with_resolved_database103273__103275$_AMPERSAND_f__103276.invoke(setup.clj:128)""
    ""query_processor.setup$fn__103274$do_with_resolved_database103273__103275$fn__103279.invoke(setup.clj:122)""
    ""query_processor.setup$fn__103338$do_with_qp_setup103337__103339.invoke(setup.clj:232)""
    ""query_processor.setup$fn__103338$fn__103343.invoke(setup.clj:216)""
    ""query_processor$fn__104802$process_query104801__104803.invoke(query_processor.clj:78)""
    ""query_processor$fn__104802$fn__104808.invoke(query_processor.clj:71)""
    ""api.dataset$fn__150512$run_streaming_query150511__150515$fn__150519.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__127832$fn__127833$fn__127834.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__127832$fn__127833.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__127832.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__64242.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: MBQL queryHash: 7bc9be55d5035954b5b452ae1680126b7d0f72a349ab772c370b2c52855fb6c4""
     ""SELECT""
     ""  \""source\"".\""Products__created_at\"" AS \""Products__created_at\"",""
     ""  \""source\"".\""avg\"" AS \""avg\"",""
     ""  \""source\"".\""sum\"" AS \""sum\""""
     ""FROM""
     ""  (""
     ""    SELECT""
     ""      DATE_TRUNC('month', \""Products\"".\""created_at\"") AS \""Products__created_at\"",""
     ""      AVG(\""public\"".\""orders\"".\""tax\"") AS \""mfa\"",""
     ""      SUM(\""public\"".\""orders\"".\""total\"") AS \""mt\""""
     ""    FROM""
     ""      \""public\"".\""orders\""""
     ""      LEFT JOIN \""public\"".\""products\"" AS \""Products\"" ON \""public\"".\""orders\"".\""product_id\"" = \""Products\"".\""id\""""
     ""    WHERE""
     ""      (\""Products\"".\""created_at\"" < ?)""
     ""      AND (\""public\"".\""orders\"".\""user_id\"" < 30)""
     ""      AND (\""public\"".\""orders\"".\""user_id\"" > 10)""
     ""    GROUP BY""
     ""      DATE_TRUNC('month', \""Products\"".\""created_at\"")""
     ""    ORDER BY""
     ""      DATE_TRUNC('month', \""Products\"".\""created_at\"") ASC""
     ""  ) AS \""source\""""
     ""LIMIT""
     ""  2000""],
    :params (#t ""2024-10-11T00:00Z""),
    :type :invalid-query}}],
 :action_id nil,
 :state ""42703"",
 :error_type :invalid-query,
 :json_query
 {:database 2,
  :type ""query"",
  :query {:source-table ""card__76""},
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""source\"".\""Products__created_at\"" AS \""Products__created_at\"", \""source\"".\""avg\"" AS \""avg\"", \""source\"".\""sum\"" AS \""sum\"" FROM (SELECT DATE_TRUNC('month', \""Products\"".\""created_at\"") AS \""Products__created_at\"", AVG(\""public\"".\""orders\"".\""tax\"") AS \""mfa\"", SUM(\""public\"".\""orders\"".\""total\"") AS \""mt\"" FROM \""public\"".\""orders\"" LEFT JOIN \""public\"".\""products\"" AS \""Products\"" ON \""public\"".\""orders\"".\""product_id\"" = \""Products\"".\""id\"" WHERE (\""Products\"".\""created_at\"" < ?) AND (\""public\"".\""orders\"".\""user_id\"" < 30) AND (\""public\"".\""orders\"".\""user_id\"" > 10) GROUP BY DATE_TRUNC('month', \""Products\"".\""created_at\"") ORDER BY DATE_TRUNC('month', \""Products\"".\""created_at\"") ASC) AS \""source\"" LIMIT 2000"",
  :params (#t ""2024-10-11T00:00Z"")},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)""
  ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)""
  ""--> driver.sql_jdbc.execute$eval140209$fn__140210.invoke(execute.clj:566)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:579)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__140327$fn__140328.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__140327.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$eval140041$fn__140042$fn__140043.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$fn__139990$do_with_resolved_connection139989__139991.invoke(execute.clj:338)""
  ""driver.sql_jdbc.execute$fn__139990$fn__139994.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$eval140041$fn__140042.invoke(execute.clj:392)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$eval142036$fn__142037.invoke(sql_jdbc.clj:79)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:62)""
  ""query_processor.execute$run.invoke(execute.clj:56)""
  ""query_processor.middleware.update_used_cards$fn__104007$update_used_cards_BANG_104006__104008$_AMPERSAND_f__104009.invoke(update_used_cards.clj:60)""
  ""query_processor.middleware.update_used_cards$fn__104007$update_used_cards_BANG_104006__104008$fn__104019.invoke(update_used_cards.clj:52)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__104031.invoke(execute.clj:25)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__104037.invoke(execute.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___103857.invoke(cache.clj:239)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__102771.invoke(permissions.clj:147)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__100777.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__100787.invoke(enterprise.clj:64)""
  ""query_processor.execute$fn__104071$execute104070__104072$fn__104073.invoke(execute.clj:94)""
  ""query_processor.setup$fn__103338$do_with_qp_setup103337__103339.invoke(setup.clj:225)""
  ""query_processor.setup$fn__103338$fn__103343.invoke(setup.clj:216)""
  ""query_processor.execute$fn__104071$execute104070__104072.invoke(execute.clj:93)""
  ""query_processor.execute$fn__104071$fn__104076.invoke(execute.clj:89)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:49)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
  ""query_processor.middleware.enterprise$eval100804$handle_audit_app_internal_queries__100805$fn__100807.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__100815.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$fn__104458$process_userland_query_middleware104457__104459$_AMPERSAND_f__104460.invoke(process_userland_query.clj:204)""
  ""query_processor.middleware.process_userland_query$fn__104458$process_userland_query_middleware104457__104459$fn__104466.invoke(process_userland_query.clj:188)""
  ""query_processor.middleware.catch_exceptions$fn__104170$catch_exceptions104169__104171$_AMPERSAND_f__104172.invoke(catch_exceptions.clj:132)""
  ""query_processor.middleware.catch_exceptions$fn__104170$catch_exceptions104169__104171$fn__104187.invoke(catch_exceptions.clj:122)""
  ""query_processor$fn__104802$process_query104801__104803$fn__104804.invoke(query_processor.clj:80)""
  ""query_processor.setup$fn__103329$do_with_canceled_chan103328__103330$fn__103331.invoke(setup.clj:187)""
  ""query_processor.setup$fn__103318$do_with_database_local_settings103317__103319$fn__103320.invoke(setup.clj:181)""
  ""query_processor.setup$fn__103307$do_with_driver103306__103308$fn__103309$fn__103310.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:106)""
  ""driver$do_with_driver.invoke(driver.clj:101)""
  ""query_processor.setup$fn__103307$do_with_driver103306__103308$fn__103309.invoke(setup.clj:165)""
  ""query_processor.setup$fn__103294$do_with_metadata_provider103293__103295$fn__103296$fn__103299.invoke(setup.clj:151)""
  ""query_processor.store$fn__86949$do_with_metadata_provider86948__86950.invoke(store.clj:170)""
  ""query_processor.store$fn__86949$fn__86953.invoke(store.clj:150)""
  ""query_processor.store$fn__86949$do_with_metadata_provider86948__86950.invoke(store.clj:159)""
  ""query_processor.store$fn__86949$fn__86953.invoke(store.clj:150)""
  ""query_processor.setup$fn__103294$do_with_metadata_provider103293__103295$fn__103296.invoke(setup.clj:150)""
  ""query_processor.setup$fn__103274$do_with_resolved_database103273__103275$_AMPERSAND_f__103276.invoke(setup.clj:128)""
  ""query_processor.setup$fn__103274$do_with_resolved_database103273__103275$fn__103279.invoke(setup.clj:122)""
  ""query_processor.setup$fn__103338$do_with_qp_setup103337__103339.invoke(setup.clj:232)""
  ""query_processor.setup$fn__103338$fn__103343.invoke(setup.clj:216)""
  ""query_processor$fn__104802$process_query104801__104803.invoke(query_processor.clj:78)""
  ""query_processor$fn__104802$fn__104808.invoke(query_processor.clj:71)""
  ""api.dataset$fn__150512$run_streaming_query150511__150515$fn__150519.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__127832$fn__127833$fn__127834.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__127832$fn__127833.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__127832.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__64242.invoke(streaming_response.clj:97)""],
 :card_id 76,
 :context :ad-hoc,
 :error ""ERROR: column source.avg does not exist\n  Position: 183"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
  :qp/source-card-id 76,
  :info
  {:executed-by 1,
   :context :ad-hoc,
   :card-id 76,
   :metadata/model-metadata
   [{:semantic_type :type/CreationTimestamp,
     :unit :month,
     :name ""created_at"",
     :field_ref [:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products"", :temporal-unit :month}],
     :effective_type :type/DateTimeWithLocalTZ,
     :id 278,
     :visibility_type :normal,
     :display_name ""Products → Created At"",
     :fingerprint
     {:global {:distinct-count 200, :nil% 0},
      :type {:type/DateTime {:earliest ""2016-04-26T19:29:55.147Z"", :latest ""2019-04-15T13:34:19.931Z""}}},
     :base_type :type/DateTimeWithLocalTZ}
    {:display_name ""mfa"",
     :field_ref [:aggregation 0],
     :name ""avg"",
     :base_type :type/Float,
     :effective_type :type/Float,
     :fingerprint
     {:global {:distinct-count 32, :nil% 0},
      :type
      {:type/Number
       {:min 0, :q1 1.7537500000000001, :q3 4.26625, :max 8.42, :sd 2.236228905364952, :avg 3.2791850340136057}}}}
    {:display_name ""mt"",
     :field_ref [:aggregation 1],
     :name ""sum"",
     :base_type :type/Float,
     :effective_type :type/Float,
     :fingerprint
     {:global {:distinct-count 35, :nil% 0},
      :type
      {:type/Number
       {:min 41.24,
        :q1 122.4425,
        :q3 337.0625,
        :max 644.4599999999999,
        :sd 152.21541606519085,
        :avg 245.8065714285714}}}}]},
  :database 2,
  :type :query,
  :query
  {:qp/stage-had-source-card 76,
   :source-query/model? true,
   :source-metadata
   [{:database_type ""timestamptz"",
     :semantic_type :type/CreationTimestamp,
     :table_id 27,
     :unit :month,
     :name ""created_at"",
     :field_ref [:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products"", :temporal-unit :month}],
     :effective_type :type/DateTimeWithLocalTZ,
     :id 278,
     :position 7,
     :visibility_type :normal,
     :display_name ""Products → Created At"",
     :fingerprint
     {:global {:distinct-count 200, :nil% 0},
      :type {:type/DateTime {:earliest ""2016-04-26T19:29:55.147Z"", :latest ""2019-04-15T13:34:19.931Z""}}},
     :base_type :type/DateTimeWithLocalTZ}
    {:name ""avg"",
     :field_ref [:aggregation 0],
     :effective_type :type/Float,
     :display_name ""mfa"",
     :fingerprint
     {:global {:distinct-count 32, :nil% 0},
      :type
      {:type/Number
       {:min 0, :q1 1.7537500000000001, :q3 4.26625, :max 8.42, :sd 2.236228905364952, :avg 3.2791850340136057}}},
     :base_type :type/Float}
    {:name ""sum"",
     :field_ref [:aggregation 1],
     :effective_type :type/Float,
     :display_name ""mt"",
     :fingerprint
     {:global {:distinct-count 35, :nil% 0},
      :type
      {:type/Number
       {:min 41.24,
        :q1 122.4425,
        :q3 337.0625,
        :max 644.4599999999999,
        :sd 152.21541606519085,
        :avg 245.8065714285714}}},
     :base_type :type/Float}],
   :fields
   [[:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products""}]
    [:field ""avg"" {:base-type :type/Float}]
    [:field ""sum"" {:base-type :type/Float}]],
   :source-query
   {:source-table 24,
    :aggregation
    [[:aggregation-options [:avg [:field 262 {:base-type :type/Float}]] {:name ""mfa""}]
     [:aggregation-options [:sum [:field 263 {:base-type :type/Float}]] {:name ""mt""}]],
    :breakout [[:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products"", :temporal-unit :month}]],
    :qp/stage-is-from-source-card 76,
    :filter
    [:and
     [:<
      [:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products"", :temporal-unit :default}]
      [:absolute-datetime #t ""2024-10-11T00:00Z"" :default]]
     [:<
      [:field 260 nil]
      [:value
       30
       {:effective_type :type/Integer,
        :name ""user_id"",
        :base_type :type/Integer,
        :semantic_type :type/FK,
        :database_type ""int4""}]]
     [:>
      [:field 260 nil]
      [:value
       10
       {:effective_type :type/Integer,
        :name ""user_id"",
        :base_type :type/Integer,
        :semantic_type :type/FK,
        :database_type ""int4""}]]],
    :order-by
    [[:asc [:field 278 {:base-type :type/DateTimeWithLocalTZ, :join-alias ""Products"", :temporal-unit :month}]]],
    :joins
    [{:alias ""Products"",
      :strategy :left-join,
      :fields
      [[:field 274 {:join-alias ""Products""}]
       [:field 280 {:join-alias ""Products""}]
       [:field 275 {:join-alias ""Products""}]
       [:field 279 {:join-alias ""Products""}]
       [:field 281 {:join-alias ""Products""}]
       [:field 277 {:join-alias ""Products""}]
       [:field 276 {:join-alias ""Products""}]
       [:field 278 {:join-alias ""Products""}]],
      :condition
      [:= [:field 256 {:base-type :type/Integer}] [:field 274 {:base-type :type/Integer, :join-alias ""Products""}]],
      :source-table 27}]},
   :limit 2000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :data {:rows [], :cols []}}

</code>
</details>


",lbrdnk,2024-10-11 14:40:42+00:00,['lbrdnk'],2024-10-17 16:02:54+00:00,2024-10-17 16:02:54+00:00,https://github.com/metabase/metabase/issues/48625,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2416472960, 'issue_id': 2581548616, 'author': 'perivamsi', 'body': 'Using the 51 milestone is enough to mark this as a 51 blocker, removing the `Release-Blocker:51` tag (this is still a release blocker)', 'created_at': datetime.datetime(2024, 10, 16, 11, 1, 12, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-10-16 11:01:12 UTC): Using the 51 milestone is enough to mark this as a 51 blocker, removing the `Release-Blocker:51` tag (this is still a release blocker)

"
2581534049,issue,closed,not_planned,Expose webhook invokations as Prometheus metrics,"Should be two different counters - successes and failures.

Look for `prometheus/counter` and `prometheus/inc` for examples.",piranha,2024-10-11 14:35:10+00:00,['qnkhuat'],2024-12-09 13:12:18+00:00,2024-12-09 13:12:18+00:00,https://github.com/metabase/metabase/issues/48624,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]",[],
2581491634,issue,open,,Passkey and/or U2F support request,"One improvement to the application's security would be the integration of Passkey or MFA via Yubikey keys. At present, MFA is accessible via SSO, such as SAML. However, this is not a feature of the free version, apart from Google Auth. It would be advantageous to provide security-enhancing features across both the free and paid versions.",yonarsky,2024-10-11 14:15:48+00:00,[],2025-02-04 20:30:18+00:00,,https://github.com/metabase/metabase/issues/48622,"[('Type:New Feature', ''), ('Administration/Auth', 'Google Auth, LDAP, pw+email login')]","[{'comment_id': 2407527324, 'issue_id': 2581491634, 'author': 'paoliniluis', 'body': ""Why can't you use U2F via your IdP?"", 'created_at': datetime.datetime(2024, 10, 11, 14, 24, 6, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-11 14:24:06 UTC): Why can't you use U2F via your IdP?

"
2581457767,issue,closed,completed,Snowplow event to track moving questions/dashboards to trash,"**Context**
We are shipping collection cleanup now. It would be nice to know how people are moving things to trash and how the new feature is impacting the numbers.

Send this event in the FE whenever a user moves something to trash.

Add a simple_event:
name: `moved-to-trash`
target_id: question/dashboard ID
triggered_from: `collection`, `detail_page`, `cleanup_modal`
duration_ms: time to execute (only if trivial, otherwise `null`)
results: `success` or `failure`
event_detail: model (`question`, `model`, `metric`, `dashboard`, `collection`)

",luizarakaki,2024-10-11 13:59:06+00:00,[],2024-11-21 20:58:03+00:00,2024-11-21 20:01:26+00:00,https://github.com/metabase/metabase/issues/48619,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2581387841,issue,closed,completed,Lets include channel and current info on version checks,"Include version info and channel (when available) in version checks

`https://static.metabase.com/version-info.json?current-version=0.51.0.1-beta&channel=stable`

```clojure
user=> (in-ns 'metabase.public-settings)
#object[clojure.lang.Namespace 0x64df93a3 ""metabase.public-settings""]
public-settings=> (-> config/mb-version-info :tag)
""v1.51.0-beta""
public-settings=> (update-channel)
""latest""
```

These values should be included in the query parameters",dpsutton,2024-10-11 13:29:58+00:00,[],2024-10-14 13:04:17+00:00,2024-10-14 11:56:50+00:00,https://github.com/metabase/metabase/issues/48615,"[('Difficulty:Easy', ''), ('.Backend', ''), ('Administration/Settings', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2581250683,issue,closed,completed,Cannot fetch filter values in dashboard for breakout column from query with aggregation and breakout on implicitly joined field,"https://github.com/user-attachments/assets/8a4caefb-c817-4c1a-980b-95481b7ee6d3

### Repro steps
1. if #48289 is open -> `git checkout 47219-dashboard-drills-tests` 
    - if it's merged -> `git checkout dashboard-filter-columns`
2. New > Question > Orders > Aggregate by Count > Breakout by Created At: Month > Breakout by Product Category
3. Save and add it to a dashboard
4. Add category filter to dashboard and connect it to ""Summarize > Category""
5. Save 
6. Click the filter

GET `/api/dashboard/:id/params/:id/values` fails with HTTP 500
```
Error compiling query: Cannot determine the source table or query for Field clause [:field \""PRODUCTS__via__PRODUCT_ID__CATEGORY\"" {:base-type :type/Text}]
```

",kamilmielnik,2024-10-11 12:19:52+00:00,['metamben'],2024-11-20 13:33:39+00:00,2024-11-20 13:33:37+00:00,https://github.com/metabase/metabase/issues/48613,"[('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2407338298, 'issue_id': 2581250683, 'author': 'kamilmielnik', 'body': ""It does not seem that it's field refs bug because it works in query builder filter modal."", 'created_at': datetime.datetime(2024, 10, 11, 12, 44, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488602355, 'issue_id': 2581250683, 'author': 'kamilmielnik', 'body': 'Closed by #50120', 'created_at': datetime.datetime(2024, 11, 20, 13, 33, 38, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-11 12:44:16 UTC): It does not seem that it's field refs bug because it works in query builder filter modal.

kamilmielnik (Issue Creator) on (2024-11-20 13:33:38 UTC): Closed by #50120

"
2581236763,issue,open,,Empty or incomplete results when using `where` statement,"**Describe the bug**
When querying one of our tables we see empty or incomplete results. It does not happen when we query using native SQL.

**Logs**
Only this log line is produced when running the query.
```
2024-10-11 15:46:59,622 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 28.0 ms (2 DB calls) App DB connections: 1/7 Jetty threads: 3/50 (4 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued); mysql DB 2 connections: 0/2 (0 threads blocked) {:metabase-user-id 1}
```

I see these logs in mysql:

```
2024-10-11T12:29:57.065333Z	2556348 Query	set autocommit=0
2024-10-11T12:29:57.066064Z	2556348 Query	SELECT * FROM QRTZ_SCHEDULER_STATE WHERE SCHED_NAME = 'MetabaseScheduler'
2024-10-11T12:29:57.067092Z	2556348 Query	UPDATE QRTZ_SCHEDULER_STATE SET LAST_CHECKIN_TIME = 1728649797049 WHERE SCHED_NAME = 'MetabaseScheduler' AND INSTANCE_NAME = 'oxuyan-metabase1728648851136'
2024-10-11T12:29:57.068027Z	2556348 Query	COMMIT
2024-10-11T12:29:57.073361Z	2556348 Query	set autocommit=1
2024-10-11T12:29:58.653828Z	2556348 Query	SELECT `session`.`user_id` AS `metabase-user-id`, `user`.`is_superuser` AS `is-superuser?`, `user`.`locale` AS `user-locale` FROM `core_session` AS `session` LEFT JOIN `core_user` AS `user` ON `session`.`user_id` = `user`.`id` WHERE (`user`.`is_active` = TRUE) AND (`session`.`id` = 'd9b71431-e08f-4042-b9c4-0ba4b5446c17') AND (`session`.`created_at` > DATE_ADD(NOW(), INTERVAL -20160 minute)) AND (`session`.`anti_csrf_token` IS NULL) LIMIT 1
2024-10-11T12:29:58.661158Z	2556348 Query	SELECT * FROM `metabase_database` WHERE `id` = 2
2024-10-11T12:29:58.669329Z	2556348 Query	SELECT `id`, `engine`, `name`, `dbms_version`, `settings`, `is_audit`, `details`, `timezone` FROM `metabase_database` WHERE `id` = 2
2024-10-11T12:29:58.679242Z	2558114 Query	SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED
2024-10-11T12:29:58.679835Z	2558114 Query	set @@SQL_SELECT_LIMIT=DEFAULT
2024-10-11T12:29:58.680290Z	2558114 Query	SET @@session.time_zone = 'Asia/Baku'
2024-10-11T12:29:58.681443Z	2558114 Query	set @@SQL_SELECT_LIMIT=2000
2024-10-11T12:29:58.682077Z	2558114 Query	-- Metabase:: userID: 1 queryType: native queryHash: 6c734fbd22ba9172b573e3b570889cac829722d6ed7abc93489cf73ee024d1e8
select * from user_exams where user_id=2
2024-10-11T12:29:58.693594Z	2558114 Query	SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ
2024-10-11T12:29:58.694034Z	2556348 Query	set autocommit=0
2024-10-11T12:29:58.696209Z	2556348 Query	SAVEPOINT `ce66bfe6-f200-4e60-b1bf-5dc5ac0ad6f1`
2024-10-11T12:29:58.697282Z	2556348 Query	UPDATE `query` SET `query` = '{\""database\"":2,\""type\"":\""native\"",\""native\"":{\""query\"":\""select * from user_exams where user_id=2\"",\""template-tags\"":{}},\""middleware\"":{\""js-int-to-string?\"":true,\""userland-query?\"":true,\""add-default-userland-constraints?\"":true}}', `average_execution_time` = CAST(ROUND((0.9 * `average_execution_time`) + 2.0, 0) AS unsigned) WHERE (`query_hash` = _binary 'lsO�\""��r�s�p�����\""��z��H��>�$��') AND (`query` IS NULL)
2024-10-11T12:29:58.698607Z	2556348 Query	COMMIT
2024-10-11T12:29:58.699211Z	2556348 Query	set autocommit=1
2024-10-11T12:29:58.701056Z	2556348 Query	set autocommit=0
2024-10-11T12:29:58.701622Z	2556348 Query	SAVEPOINT `dd502213-2dc4-412a-88df-2b57dcc9255e`
2024-10-11T12:29:58.702252Z	2556348 Query	UPDATE `query` SET `average_execution_time` = CAST(ROUND((0.9 * `average_execution_time`) + 2.0, 0) AS unsigned) WHERE `query_hash` = _binary 'lsO�\""��r�s�p�����\""��z��H��>�$��'
2024-10-11T12:29:58.703018Z	2556348 Query	COMMIT
2024-10-11T12:29:58.703523Z	2556348 Query	set autocommit=1
2024-10-11T12:29:58.704472Z	2556348 Query	set autocommit=0
2024-10-11T12:29:58.704996Z	2556348 Query	SAVEPOINT `7a40731a-dbb8-42aa-a09b-d922e0d5384c`
2024-10-11T12:29:58.706856Z	2556348 Query	INSERT INTO `query_execution` (`hash`, `database_id`, `result_rows`, `started_at`, `executor_id`, `action_id`, `cache_hash`, `native`, `pulse_id`, `card_id`, `context`, `cache_hit`, `is_sandboxed`, `running_time`, `dashboard_id`) VALUES (_binary 'lsO�\""��r�s�p�����\""��z��H��>�$��', 2, 0, '2024-10-11 16:29:58.654512', 1, NULL, NULL, TRUE, NULL, NULL, 'ad-hoc', FALSE, FALSE, 20, NULL)
2024-10-11T12:29:58.709865Z	2556348 Query	COMMIT
2024-10-11T12:29:58.714342Z	2556348 Query	set autocommit=1
2024-10-11T12:29:59.031993Z	2556348 Query	set autocommit=0
2024-10-11T12:29:59.033044Z	2556348 Query	set @@SQL_SELECT_LIMIT=1
2024-10-11T12:29:59.033756Z	2556348 Query	SELECT TRIGGER_NAME, TRIGGER_GROUP, NEXT_FIRE_TIME, PRIORITY FROM QRTZ_TRIGGERS WHERE SCHED_NAME = 'MetabaseScheduler' AND TRIGGER_STATE = 'WAITING' AND NEXT_FIRE_TIME <= 1728649829014 AND (MISFIRE_INSTR = -1 OR (MISFIRE_INSTR != -1 AND NEXT_FIRE_TIME >= 1728648899015)) ORDER BY NEXT_FIRE_TIME ASC, PRIORITY DESC
2024-10-11T12:29:59.035391Z	2556348 Query	set @@SQL_SELECT_LIMIT=DEFAULT
2024-10-11T12:29:59.035878Z	2556348 Query	COMMIT
```

**To Reproduce**
I run this query:
```sql
select * from user_exams where user_id = 2
```
But it returns empty result instead of 53 rows.

```sql
select * from user_exams where user_id = 1
```
Returns 1 result but there are 226 rows.

**Expected behavior**
It should return all the available data

**Screenshots**
Make sure to unmute the audio:

https://github.com/user-attachments/assets/700d22db-93bb-4ddf-9caa-b11b26f5b160


**Severity**
Well, it casts shadow to the query results in general

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Baku""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.30""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.8+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.8"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.8+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-71-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Baku""
  }
}
```",OrkhanAlikhanov,2024-10-11 12:12:44+00:00,[],2025-02-04 20:25:10+00:00,,https://github.com/metabase/metabase/issues/48612,"[('Database/MySQL', None), ('.Needs Triage', '')]","[{'comment_id': 2407330448, 'issue_id': 2581236763, 'author': 'OrkhanAlikhanov', 'body': 'Seems like when I run this, I get the same results:\n```sql\nSET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\nselect * from user_exams where user_id=1;\n```', 'created_at': datetime.datetime(2024, 10, 11, 12, 39, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407352710, 'issue_id': 2581236763, 'author': 'OrkhanAlikhanov', 'body': 'I see some related issues #39130 and #13254. Is there a way for us to adjust transaction isolation level to unblock ourselves?\n\nI also came across this blogpost which is interesting https://falseisnotnull.wordpress.com/2018/02/06/about-read-uncommitted/', 'created_at': datetime.datetime(2024, 10, 11, 12, 52, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407532089, 'issue_id': 2581236763, 'author': 'paoliniluis', 'body': ""Thanks for creating this: why aren't your writes commiting fast enough to disk?"", 'created_at': datetime.datetime(2024, 10, 11, 14, 26, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407665549, 'issue_id': 2581236763, 'author': 'OrkhanAlikhanov', 'body': ""Sorry I didn't understand it. The table has 3.5 million rows, and the record with `user_id = 2` is the very first one in the table.  I think they are indeed written to the disk."", 'created_at': datetime.datetime(2024, 10, 11, 15, 36, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573509131, 'issue_id': 2581236763, 'author': 'paoliniluis', 'body': ""So I don't think this is a problem with the commits then..."", 'created_at': datetime.datetime(2025, 1, 6, 16, 52, 42, tzinfo=datetime.timezone.utc)}]","OrkhanAlikhanov (Issue Creator) on (2024-10-11 12:39:30 UTC): Seems like when I run this, I get the same results:
```sql
SET SESSION TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;
select * from user_exams where user_id=1;
```

OrkhanAlikhanov (Issue Creator) on (2024-10-11 12:52:40 UTC): I see some related issues #39130 and #13254. Is there a way for us to adjust transaction isolation level to unblock ourselves?

I also came across this blogpost which is interesting https://falseisnotnull.wordpress.com/2018/02/06/about-read-uncommitted/

paoliniluis on (2024-10-11 14:26:19 UTC): Thanks for creating this: why aren't your writes commiting fast enough to disk?

OrkhanAlikhanov (Issue Creator) on (2024-10-11 15:36:04 UTC): Sorry I didn't understand it. The table has 3.5 million rows, and the record with `user_id = 2` is the very first one in the table.  I think they are indeed written to the disk.

paoliniluis on (2025-01-06 16:52:42 UTC): So I don't think this is a problem with the commits then...

"
2580986710,issue,closed,completed,Unsupported temporal bucketing: You can't bucket a :type/Date Field by :minute when using brush filters,"### Describe the bug

![Image](https://github.com/user-attachments/assets/6175afef-dfd9-4aea-b857-532b64e218a6)


### To Reproduce

1. Go to https://stats.metabase.com/question/11691
2. Apply brush filter by selecting 1 bar, [like this](https://github.com/user-attachments/assets/e8cc4152-c8f6-46e4-b700-b5db267bb2e9) 

### Expected result

- The question should use ""month"" bucketing like in the original question
- No crash
- A visualization with 1 bar should be rendered

### Information about your Metabase installation

stats @ 989f595

### Severity

P2

### Additional context

I cannot reproduce it with sample db",kamilmielnik,2024-10-11 10:08:51+00:00,['ericnormand'],2025-02-03 15:33:24+00:00,2025-01-29 21:50:53+00:00,https://github.com/metabase/metabase/issues/48608,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2410310827, 'issue_id': 2580986710, 'author': 'Somtom', 'body': 'Also bumped into this. [Here](https://metaboat.slack.com/archives/C05MPF0TM3L/p1728883402571649) is some more context.', 'created_at': datetime.datetime(2024, 10, 14, 7, 45, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426799408, 'issue_id': 2580986710, 'author': 'ranquild', 'body': '> Also bumped into this. [Here](https://metaboat.slack.com/archives/C05MPF0TM3L/p1728883402571649) is some more context.\n\nhttps://github.com/metabase/metabase/pull/48818 fixed FE issues in the DatePicker. The remaining issue with brush filters is MBQL lib only.', 'created_at': datetime.datetime(2024, 10, 21, 14, 9, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617726675, 'issue_id': 2580986710, 'author': 'ranquild', 'body': 'Similar to https://github.com/metabase/metabase/issues/49469', 'created_at': datetime.datetime(2025, 1, 28, 2, 57, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617728507, 'issue_id': 2580986710, 'author': 'ranquild', 'body': '`Lib.updateTemporalFilter` should be fixed - it should not use units not supported by the column type', 'created_at': datetime.datetime(2025, 1, 28, 2, 58, 23, tzinfo=datetime.timezone.utc)}]","Somtom on (2024-10-14 07:45:14 UTC): Also bumped into this. [Here](https://metaboat.slack.com/archives/C05MPF0TM3L/p1728883402571649) is some more context.

ranquild on (2024-10-21 14:09:56 UTC): https://github.com/metabase/metabase/pull/48818 fixed FE issues in the DatePicker. The remaining issue with brush filters is MBQL lib only.

ranquild on (2025-01-28 02:57:18 UTC): Similar to https://github.com/metabase/metabase/issues/49469

ranquild on (2025-01-28 02:58:23 UTC): `Lib.updateTemporalFilter` should be fixed - it should not use units not supported by the column type

"
2580863270,issue,open,,Metabase reporting errors when queries are cancelled,"### Describe the bug

In the Metabase logs, there are error entries whenever a user cancels a query, when it is actually an expected outcome.

### To Reproduce

1. Go to Metabase and do a long-running query, like `select pg_sleep(5 * 60)` for postgres.
2. Click on ""run query"", then again on ""X"" to cancel it.
3. Find the error in the Metabase logs.


### Expected behavior

No error should be logged. Postgres adequately responds with a 57014 code which conveys that the query was cancelled by the user.

### Logs

This is the ERROR being logged on the server side:

```
2024-10-11 08:56:35,566 ERROR middleware.catch-exceptions :: Error processing query: ERROR: canceling statement due to user request
{:database_id 3,
 :started_at #t ""2024-10-11T08:56:32.532086Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: ERROR: canceling statement due to user request"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__82629$fn__82630.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__82629.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__82433$fn__82434.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__82433.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__82433.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__114262.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__114262.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:60)""
    ""query_processor.execute$run.invoke(execute.clj:54)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71583.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__71598.invoke(execute.clj:23)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71603.invoke(execute.clj:34)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71556.invoke(cache.clj:239)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66189.invoke(permissions.clj:147)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__108848$check_download_permissions__108849$fn__108850.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66801.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__110679$maybe_apply_column_level_perms_check__110680$fn__110681.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66811.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__71630.invoke(execute.clj:92)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
    ""query_processor.execute$execute.invoke(execute.clj:87)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__82976$handle_audit_app_internal_queries__82977$fn__82978.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66839.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76830.invoke(process_userland_query.clj:198)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76899.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76936.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__67243.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings$fn__67238.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__67233$fn__67234.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__67233.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__67226$fn__67229.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider$fn__67226.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__67220.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""api.dataset$run_streaming_query$fn__94849.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__70139$fn__70140$fn__70141.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__70139$fn__70140.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__70139.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__52030.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: native queryHash: ee1ee8625359d0682d144001df6f521d5a997c2eb03762f17e5321400151758b""
     ""SELECT""
     ""  \""public\"".\""user\"".\""_id\"" AS \""_id\"",""
     ""  \""public\"".\""user\"".\""firstName\"" AS \""firstName\"",""
     ""  \""public\"".\""user\"".\""lastName\"" AS \""lastName\"",""
     ""  \""public\"".\""user\"".\""age\"" AS \""age\"",""
     ""  pg_sleep(5 * 60) AS sleeping""
     ""FROM""
     ""  \""public\"".\""user\""""
     ""LIMIT""
     ""  1048575""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :state ""57014"",
 :error_type :invalid-query,
 :json_query
 {:type ""native"",
  :native
  {:query
   ""SELECT\n  \""public\"".\""user\"".\""_id\"" AS \""_id\"",\n  \""public\"".\""user\"".\""firstName\"" AS \""firstName\"",\n  \""public\"".\""user\"".\""lastName\"" AS \""lastName\"",\n  \""public\"".\""user\"".\""age\"" AS \""age\"",\n  pg_sleep(5 * 60) AS sleeping\nFROM\n  \""public\"".\""user\""\nLIMIT\n  1048575"",
   :template-tags {},
   :collection ""user""},
  :database 3,
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__82559.invokeStatic(execute.clj:570)""
  ""driver.sql_jdbc.execute$fn__82559.invoke(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:578)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82629$fn__82630.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82629.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__82433$fn__82434.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__82433.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__82433.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__114262.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__114262.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
  ""query_processor.execute$run.invoke(execute.clj:54)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71583.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71598.invoke(execute.clj:23)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71603.invoke(execute.clj:34)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71556.invoke(cache.clj:239)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66189.invoke(permissions.clj:147)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__108848$check_download_permissions__108849$fn__108850.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66801.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__110679$maybe_apply_column_level_perms_check__110680$fn__110681.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66811.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__71630.invoke(execute.clj:92)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
  ""query_processor.execute$execute.invoke(execute.clj:87)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__82976$handle_audit_app_internal_queries__82977$fn__82978.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66839.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76830.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76899.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76936.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67243.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67238.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67233$fn__67234.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__67233.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67226$fn__67229.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67226.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67220.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__94849.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__70139$fn__70140$fn__70141.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70139$fn__70140.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70139.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52030.invoke(streaming_response.clj:97)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""ERROR: canceling statement due to user request"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v1.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.11.1-arch1-1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

Inconveniency for finding actual errors

### Additional context

_No response_",egg-juxt,2024-10-11 09:09:45+00:00,[],2025-02-04 20:24:47+00:00,,https://github.com/metabase/metabase/issues/48605,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Administration/Troubleshooting', ''), ('.Team/Querying', '')]","[{'comment_id': 2596310183, 'issue_id': 2580863270, 'author': 'luizarakaki', 'body': ""Isn't this Querying? I suppose Querying is responsible for querying related logs"", 'created_at': datetime.datetime(2025, 1, 16, 17, 29, 17, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-16 17:29:17 UTC): Isn't this Querying? I suppose Querying is responsible for querying related logs

"
2579901712,issue,closed,completed,Examples collection is not visible to non-admins,"### Describe the bug

The `Examples` collection, with pre-populated content, is not visible to non-admins, even when collection permissions are set to `Curate` for All Users. However, a non-admin can navigate to an example card directly and view it.

### To Reproduce

see above

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Current master 3fe1ef7cb6

### Severity

P2?

### Additional context

_No response_",noahmoss,2024-10-10 21:41:19+00:00,[],2024-10-16 14:27:58+00:00,2024-10-16 13:10:01+00:00,https://github.com/metabase/metabase/issues/48594,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Collections', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2579824490,issue,closed,not_planned,"v0.51.0-beta Multiple groupings by same date field, labels are confusing","### Describe the bug

Love this feature, I've been working around this for ages.

When I create a question with a summary by different granularity of the same datetime, the chart, and some settings, don't distinguish between these meaning you've got to guess which one is which.

### To Reproduce

1. New question on sample data > Orders
2. Count by ""Create At: Hour of day"" and ""Created At: Day of week""
![Image](https://github.com/user-attachments/assets/a117734e-af7a-42eb-a5e4-b0c652aa7fe7)
3. Visulise > scatter chart
4. Open settings
5. Both date groupings are called ""Created At"" so you've got guess which is which
6. Both x and y axis on the chart are labelled ""Created At""
![Image](https://github.com/user-attachments/assets/f0cdbc60-8371-459a-af4e-e8aa08e0fe2b)


### Expected behavior

I should be able to distinguish the different groupings both in the chart settings and the visualisation itself.

### Logs

NA

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-08"",
      ""tag"": ""v0.51.0-beta"",
      ""hash"": ""f69afc2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows 10"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  }
}

### Severity

Annoying, have to guess and manually relabel

### Additional context

This seems to apply across different visualisation types.",notrom,2024-10-10 20:54:52+00:00,[],2024-10-18 01:11:20+00:00,2024-10-18 01:11:18+00:00,https://github.com/metabase/metabase/issues/48591,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2417032087, 'issue_id': 2579824490, 'author': 'mngr', 'body': 'Related to or duplicates https://github.com/metabase/metabase/issues/47579 and https://github.com/metabase/metabase/issues/47576', 'created_at': datetime.datetime(2024, 10, 16, 14, 36, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421022903, 'issue_id': 2579824490, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/47579', 'created_at': datetime.datetime(2024, 10, 18, 1, 11, 18, tzinfo=datetime.timezone.utc)}]","mngr on (2024-10-16 14:36:22 UTC): Related to or duplicates https://github.com/metabase/metabase/issues/47579 and https://github.com/metabase/metabase/issues/47576

ranquild on (2024-10-18 01:11:18 UTC): Duplicate of https://github.com/metabase/metabase/issues/47579

"
2579796605,issue,closed,completed,"Pie chart labels are hidden when there's not enough space, causing confusion with settings","### Describe the bug

When you disable show labels in pie chart it enables the labels. It is inverted.

[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1728614230478829)

### To Reproduce

Create a new question, select pie chart, go to display, switch show labels.
![Image](https://github.com/user-attachments/assets/505702f2-c193-4024-a2d5-092baf025a53)
![Image](https://github.com/user-attachments/assets/a9ef8671-6b37-402d-bc7a-1850f72becff)

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

v1.51.0-beta

### Severity

P2

### Additional context

_No response_",fer-batista,2024-10-10 20:39:12+00:00,['alxnddr'],2024-10-22 18:20:51+00:00,2024-10-22 18:20:50+00:00,https://github.com/metabase/metabase/issues/48587,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2417408657, 'issue_id': 2579796605, 'author': 'cdeweyx', 'body': '[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1728614230478829)', 'created_at': datetime.datetime(2024, 10, 16, 17, 0, 10, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-10-16 17:00:10 UTC): [Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1728614230478829)

"
2579775939,issue,closed,completed,Use `information_schema` instead of jdbc methods in `describe-database` in Databricks driver,"Parent `:sql-jdbc` implementation of `describe-database` (1) fetches all the schemas from all catalogs and (2) in some circumstances can produce an exception. See [this slack thread](https://metaboat.slack.com/archives/C07L35T7UFQ/p1728318329287749) for the details.

To overcome that, `information_schema` should be used to get the necessary information during sync.",lbrdnk,2024-10-10 20:28:10+00:00,['lbrdnk'],2024-10-15 21:19:41+00:00,2024-10-14 21:31:19+00:00,https://github.com/metabase/metabase/issues/48584,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', ''), ('Database/Databricks', ''), ('.Team/Drivers', '')]",[],
2579748976,issue,open,,Date type SQL Parameter generating incorrect query for JSONB column,"**Describe the bug**
When using an SQL Parameter of type date in Metabase, the query is being generated incorrectly.

Example: I created the following condition in my SQL: 
`[[AND mv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade'::date >= {{data_inicio_atividade}}]]`

The variable {{data_inicio_atividade}} is configured with the Date type.

The SQL generated by Metabase was as follows:
`AND mv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade'::date >= date '2000-01-01'`

**Logs**
```
[d73a5fda-70de-4883-94d6-0907e5faf816] 2024-10-10T16:48:36-03:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: ERROR: invalid input syntax for type date: ""data_inicio_atividade""
  Position: 8868
{:database_id 3,
 :started_at #t ""2024-10-10T19:48:36.812433Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Erro ao executar consulta: ERROR: invalid input syntax for type date: \""data_inicio_atividade\""\n  Position: 8868"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__82518$fn__82519.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__108335.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__108335.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:60)""
    ""query_processor.execute$run.invoke(execute.clj:54)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71610.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__71625.invoke(execute.clj:23)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71630.invoke(execute.clj:34)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71583.invoke(cache.clj:239)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66212.invoke(permissions.clj:147)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66824.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66834.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__71657.invoke(execute.clj:92)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
    ""query_processor.execute$execute.invoke(execute.clj:87)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""query_processor.middleware.enterprise$fn__66851$handle_audit_app_internal_queries__66852$fn__66854.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66862.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76857.invoke(process_userland_query.clj:198)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76926.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76963.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__67266.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings$fn__67261.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__67256$fn__67257.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:105)""
    ""driver$do_with_driver.invoke(driver.clj:100)""
    ""query_processor.setup$do_with_driver$fn__67256.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__67249$fn__67252.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider$fn__67249.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__67243.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""api.dataset$run_streaming_query$fn__94182.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__70166$fn__70167$fn__70168.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__70166$fn__70167.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__70166.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__52036.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: native queryHash: c85fc6602d030f8cc05f51c727cf51d57a5c4fd62f3a652d861a5e6ddc1a18a8""
     ""SELECT""
     ""  mv_empresas.cnpj_basico,""
     ""  cnpj,""
     ""  cnpj_ordem,""
     ""  cnpj_dv,""
     ""  -- Colunas para o ano de 2021""
     ""  mv_empresas.dados_2021 ->> 'porte' as porte_2021,""
     ""  mv_empresas.dados_2021 ->> 'razao_social' AS razao_social_2021,""
     ""  mv_empresas.dados_2021 ->> 'capital_social' AS capital_social_2021,""
     ""  mv_empresas.dados_2021 ->> 'natureza_juridica' AS natureza_juridica_2021,""
     ""  mv_empresas.dados_2021 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2021,""
     ""  mv_empresas.dados_2021 ->> 'ente_federativo' AS ente_federativo_2021,""
     ""  mv_empresas.dados_2021 ->> 'opcao_mei' AS opcao_mei_2021,""
     ""  mv_empresas.dados_2021 ->> 'data_opcao_mei' AS data_opcao_mei_2021,""
     ""  mv_empresas.dados_2021 ->> 'data_exclusao_mei' AS data_exclusao_mei_2021,""
     ""  mv_empresas.dados_2021 ->> 'opcao_simples' AS opcao_simples_2021,""
     ""  mv_empresas.dados_2021 ->> 'data_opcao_simples' AS data_opcao_simples_2021,""
     ""  mv_empresas.dados_2021 ->> 'data_exclusao_simples' AS data_exclusao_simples_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade' AS data_inicio_atividade_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'nome_fantasia' AS nome_fantasia_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'id_pais' AS id_pais_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'sigla_uf' AS sigla_uf_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'municipio' AS municipio_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'grupo_cnae' AS grupo_cnae_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'secao_cnae' AS secao_cnae_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'classe_cnae' AS classe_cnae_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'divisao_cnae' AS divisao_cnae_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'subclasse_cnae' AS subclasse_cnae_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'situacao_cadastral' AS situacao_cadastral_2021,""
     ""  mv_estabelecimentos.dados_2021 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2021,""
     ""  -- Colunas para o ano de 2022""
     ""  mv_empresas.dados_2022 ->> 'porte' as porte_2022,""
     ""  mv_empresas.dados_2022 ->> 'razao_social' AS razao_social_2022,""
     ""  mv_empresas.dados_2022 ->> 'capital_social' AS capital_social_2022,""
     ""  mv_empresas.dados_2022 ->> 'natureza_juridica' AS natureza_juridica_2022,""
     ""  mv_empresas.dados_2022 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2022,""
     ""  mv_empresas.dados_2022 ->> 'ente_federativo' AS ente_federativo_2022,""
     ""  mv_empresas.dados_2022 ->> 'opcao_mei' AS opcao_mei_2022,""
     ""  mv_empresas.dados_2022 ->> 'data_opcao_mei' AS data_opcao_mei_2022,""
     ""  mv_empresas.dados_2022 ->> 'data_exclusao_mei' AS data_exclusao_mei_2022,""
     ""  mv_empresas.dados_2022 ->> 'opcao_simples' AS opcao_simples_2022,""
     ""  mv_empresas.dados_2022 ->> 'data_opcao_simples' AS data_opcao_simples_2022,""
     ""  mv_empresas.dados_2022 ->> 'data_exclusao_simples' AS data_exclusao_simples_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'data_inicio_atividade' AS data_inicio_atividade_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'nome_fantasia' AS nome_fantasia_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'id_pais' AS id_pais_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'sigla_uf' AS sigla_uf_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'municipio' AS municipio_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'grupo_cnae' AS grupo_cnae_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'secao_cnae' AS secao_cnae_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'classe_cnae' AS classe_cnae_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'divisao_cnae' AS divisao_cnae_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'subclasse_cnae' AS subclasse_cnae_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'situacao_cadastral' AS situacao_cadastral_2022,""
     ""  mv_estabelecimentos.dados_2022 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2022,""
     ""  -- Colunas para o ano de 2023""
     ""  mv_empresas.dados_2023 ->> 'porte' as porte_2023,""
     ""  mv_empresas.dados_2023 ->> 'razao_social' AS razao_social_2023,""
     ""  mv_empresas.dados_2023 ->> 'capital_social' AS capital_social_2023,""
     ""  mv_empresas.dados_2023 ->> 'natureza_juridica' AS natureza_juridica_2023,""
     ""  mv_empresas.dados_2023 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2023,""
     ""  mv_empresas.dados_2023 ->> 'ente_federativo' AS ente_federativo_2023,""
     ""  mv_empresas.dados_2023 ->> 'opcao_mei' AS opcao_mei_2023,""
     ""  mv_empresas.dados_2023 ->> 'data_opcao_mei' AS data_opcao_mei_2023,""
     ""  mv_empresas.dados_2023 ->> 'data_exclusao_mei' AS data_exclusao_mei_2023,""
     ""  mv_empresas.dados_2023 ->> 'opcao_simples' AS opcao_simples_2023,""
     ""  mv_empresas.dados_2023 ->> 'data_opcao_simples' AS data_opcao_simples_2023,""
     ""  mv_empresas.dados_2023 ->> 'data_exclusao_simples' AS data_exclusao_simples_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'data_inicio_atividade' AS data_inicio_atividade_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'nome_fantasia' AS nome_fantasia_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'id_pais' AS id_pais_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'sigla_uf' AS sigla_uf_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'municipio' AS municipio_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'grupo_cnae' AS grupo_cnae_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'secao_cnae' AS secao_cnae_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'classe_cnae' AS classe_cnae_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'divisao_cnae' AS divisao_cnae_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'subclasse_cnae' AS subclasse_cnae_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'situacao_cadastral' AS situacao_cadastral_2023,""
     ""  mv_estabelecimentos.dados_2023 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2023,""
     ""  -- Colunas para o ano de 2024""
     ""  mv_empresas.dados_2024 ->> 'porte' as porte_2024,""
     ""  mv_empresas.dados_2024 ->> 'razao_social' AS razao_social_2024,""
     ""  mv_empresas.dados_2024 ->> 'capital_social' AS capital_social_2024,""
     ""  mv_empresas.dados_2024 ->> 'natureza_juridica' AS natureza_juridica_2024,""
     ""  mv_empresas.dados_2024 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2024,""
     ""  mv_empresas.dados_2024 ->> 'ente_federativo' AS ente_federativo_2024,""
     ""  mv_empresas.dados_2024 ->> 'opcao_mei' AS opcao_mei_2024,""
     ""  mv_empresas.dados_2024 ->> 'data_opcao_mei' AS data_opcao_mei_2024,""
     ""  mv_empresas.dados_2024 ->> 'data_exclusao_mei' AS data_exclusao_mei_2024,""
     ""  mv_empresas.dados_2024 ->> 'opcao_simples' AS opcao_simples_2024,""
     ""  mv_empresas.dados_2024 ->> 'data_opcao_simples' AS data_opcao_simples_2024,""
     ""  mv_empresas.dados_2024 ->> 'data_exclusao_simples' AS data_exclusao_simples_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'data_inicio_atividade' AS data_inicio_atividade_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'nome_fantasia' AS nome_fantasia_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'id_pais' AS id_pais_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'sigla_uf' AS sigla_uf_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'municipio' AS municipio_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'grupo_cnae' AS grupo_cnae_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'secao_cnae' AS secao_cnae_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'classe_cnae' AS classe_cnae_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'divisao_cnae' AS divisao_cnae_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'subclasse_cnae' AS subclasse_cnae_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'situacao_cadastral' AS situacao_cadastral_2024,""
     ""  mv_estabelecimentos.dados_2024 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2024""
     ""from""
     ""  dados.mv_estabelecimentos""
     ""  left join dados.mv_empresas on mv_estabelecimentos.cnpj_basico = mv_empresas.cnpj_basico""
     ""WHERE""
     ""  1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND mv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade' :: date >= ?""],
    :params [#t ""2000-01-01""],
    :type :invalid-query}}],
 :action_id nil,
 :state ""22007"",
 :error_type :invalid-query,
 :json_query
 {:native
  {:query
   ""\tSELECT \r\n    mv_empresas.cnpj_basico,\r\n    cnpj,\r\n    cnpj_ordem,\r\n    cnpj_dv,\r\n    -- Colunas para o ano de 2021\r\n    mv_empresas.dados_2021 ->> 'porte' as porte_2021,\r\n    mv_empresas.dados_2021 ->> 'razao_social' AS razao_social_2021,\r\n    mv_empresas.dados_2021 ->> 'capital_social' AS capital_social_2021,\r\n    mv_empresas.dados_2021 ->> 'natureza_juridica' AS natureza_juridica_2021,\r\n    mv_empresas.dados_2021 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2021,\r\n    mv_empresas.dados_2021 ->> 'ente_federativo' AS ente_federativo_2021,\r\n    mv_empresas.dados_2021 ->> 'opcao_mei' AS opcao_mei_2021,\r\n    mv_empresas.dados_2021 ->> 'data_opcao_mei' AS data_opcao_mei_2021,\r\n    mv_empresas.dados_2021 ->> 'data_exclusao_mei' AS data_exclusao_mei_2021,\r\n    mv_empresas.dados_2021 ->> 'opcao_simples' AS opcao_simples_2021,\r\n    mv_empresas.dados_2021 ->> 'data_opcao_simples' AS data_opcao_simples_2021,\r\n    mv_empresas.dados_2021 ->> 'data_exclusao_simples' AS data_exclusao_simples_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2021,\r\n\tmv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade' AS data_inicio_atividade_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'nome_fantasia' AS nome_fantasia_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'id_pais' AS id_pais_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'sigla_uf' AS sigla_uf_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'municipio' AS municipio_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'grupo_cnae' AS grupo_cnae_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'secao_cnae' AS secao_cnae_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'classe_cnae' AS classe_cnae_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'divisao_cnae' AS divisao_cnae_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'subclasse_cnae' AS subclasse_cnae_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'situacao_cadastral' AS situacao_cadastral_2021,\r\n    mv_estabelecimentos.dados_2021 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2021,\r\n    -- Colunas para o ano de 2022\r\n    mv_empresas.dados_2022 ->> 'porte' as porte_2022,\r\n    mv_empresas.dados_2022 ->> 'razao_social' AS razao_social_2022,\r\n    mv_empresas.dados_2022 ->> 'capital_social' AS capital_social_2022,\r\n    mv_empresas.dados_2022 ->> 'natureza_juridica' AS natureza_juridica_2022,\r\n    mv_empresas.dados_2022 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2022,\r\n    mv_empresas.dados_2022 ->> 'ente_federativo' AS ente_federativo_2022,\r\n    mv_empresas.dados_2022 ->> 'opcao_mei' AS opcao_mei_2022,\r\n    mv_empresas.dados_2022 ->> 'data_opcao_mei' AS data_opcao_mei_2022,\r\n    mv_empresas.dados_2022 ->> 'data_exclusao_mei' AS data_exclusao_mei_2022,\r\n    mv_empresas.dados_2022 ->> 'opcao_simples' AS opcao_simples_2022,\r\n    mv_empresas.dados_2022 ->> 'data_opcao_simples' AS data_opcao_simples_2022,\r\n    mv_empresas.dados_2022 ->> 'data_exclusao_simples' AS data_exclusao_simples_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2022,\r\n\tmv_estabelecimentos.dados_2022 ->> 'data_inicio_atividade' AS data_inicio_atividade_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'nome_fantasia' AS nome_fantasia_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'id_pais' AS id_pais_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'sigla_uf' AS sigla_uf_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'municipio' AS municipio_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'grupo_cnae' AS grupo_cnae_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'secao_cnae' AS secao_cnae_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'classe_cnae' AS classe_cnae_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'divisao_cnae' AS divisao_cnae_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'subclasse_cnae' AS subclasse_cnae_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'situacao_cadastral' AS situacao_cadastral_2022,\r\n    mv_estabelecimentos.dados_2022 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2022,\r\n\t-- Colunas para o ano de 2023\r\n\tmv_empresas.dados_2023 ->> 'porte' as porte_2023,\r\n    mv_empresas.dados_2023 ->> 'razao_social' AS razao_social_2023,\r\n    mv_empresas.dados_2023 ->> 'capital_social' AS capital_social_2023,\r\n    mv_empresas.dados_2023 ->> 'natureza_juridica' AS natureza_juridica_2023,\r\n    mv_empresas.dados_2023 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2023,\r\n    mv_empresas.dados_2023 ->> 'ente_federativo' AS ente_federativo_2023,\r\n    mv_empresas.dados_2023 ->> 'opcao_mei' AS opcao_mei_2023,\r\n    mv_empresas.dados_2023 ->> 'data_opcao_mei' AS data_opcao_mei_2023,\r\n    mv_empresas.dados_2023 ->> 'data_exclusao_mei' AS data_exclusao_mei_2023,\r\n    mv_empresas.dados_2023 ->> 'opcao_simples' AS opcao_simples_2023,\r\n    mv_empresas.dados_2023 ->> 'data_opcao_simples' AS data_opcao_simples_2023,\r\n    mv_empresas.dados_2023 ->> 'data_exclusao_simples' AS data_exclusao_simples_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2023,\r\n\tmv_estabelecimentos.dados_2023 ->> 'data_inicio_atividade' AS data_inicio_atividade_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'nome_fantasia' AS nome_fantasia_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'id_pais' AS id_pais_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'sigla_uf' AS sigla_uf_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'municipio' AS municipio_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'grupo_cnae' AS grupo_cnae_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'secao_cnae' AS secao_cnae_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'classe_cnae' AS classe_cnae_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'divisao_cnae' AS divisao_cnae_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'subclasse_cnae' AS subclasse_cnae_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'situacao_cadastral' AS situacao_cadastral_2023,\r\n    mv_estabelecimentos.dados_2023 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2023,\r\n\t-- Colunas para o ano de 2024\r\n\tmv_empresas.dados_2024 ->> 'porte' as porte_2024,\r\n    mv_empresas.dados_2024 ->> 'razao_social' AS razao_social_2024,\r\n    mv_empresas.dados_2024 ->> 'capital_social' AS capital_social_2024,\r\n    mv_empresas.dados_2024 ->> 'natureza_juridica' AS natureza_juridica_2024,\r\n    mv_empresas.dados_2024 ->> 'qualificacao_responsavel' AS qualificacao_responsavel_2024,\r\n    mv_empresas.dados_2024 ->> 'ente_federativo' AS ente_federativo_2024,\r\n    mv_empresas.dados_2024 ->> 'opcao_mei' AS opcao_mei_2024,\r\n    mv_empresas.dados_2024 ->> 'data_opcao_mei' AS data_opcao_mei_2024,\r\n    mv_empresas.dados_2024 ->> 'data_exclusao_mei' AS data_exclusao_mei_2024,\r\n    mv_empresas.dados_2024 ->> 'opcao_simples' AS opcao_simples_2024,\r\n    mv_empresas.dados_2024 ->> 'data_opcao_simples' AS data_opcao_simples_2024,\r\n    mv_empresas.dados_2024 ->> 'data_exclusao_simples' AS data_exclusao_simples_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'identificador_matriz_filial' AS identificador_matriz_filial_2024,\r\n\tmv_estabelecimentos.dados_2024 ->> 'data_inicio_atividade' AS data_inicio_atividade_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'nome_fantasia' AS nome_fantasia_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'id_pais' AS id_pais_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'sigla_uf' AS sigla_uf_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'municipio' AS municipio_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'grupo_cnae' AS grupo_cnae_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'secao_cnae' AS secao_cnae_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'classe_cnae' AS classe_cnae_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'divisao_cnae' AS divisao_cnae_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'subclasse_cnae' AS subclasse_cnae_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'cnae_fiscal_secundaria' AS cnae_fiscal_secundaria_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'situacao_cadastral' AS situacao_cadastral_2024,\r\n    mv_estabelecimentos.dados_2024 ->> 'motivo_situacao_cadastral' AS motivo_situacao_cadastral_2024\r\nfrom dados.mv_estabelecimentos\r\nleft join dados.mv_empresas on mv_estabelecimentos.cnpj_basico = mv_empresas.cnpj_basico\r\nWHERE 1=1\r\nAND {{razao_social}}\r\nAND {{descricao_porte}}\r\nAND {{natureza_juridica}}\r\nAND {{secao_cnae}}\r\nAND {{divisao_cnae}}\r\nAND {{grupo_cnae}}\r\nAND {{classe_cnae}}\r\nAND {{subclasse_cnae}}\r\nAND {{municipio}}\r\nAND {{sigla_uf}}\r\nAND {{qualificacao_responsavel}}\r\nAND {{cnpj}}\r\nAND {{cnpj_basico}}\r\nAND {{opcao_simples}}\r\nAND {{opcao_mei}}\r\n[[AND mv_estabelecimentos.dados_2021 ->> 'data_inicio_atividade'::date >= {{data_inicio_atividade}}]]\r\n"",
   :template-tags
   {:natureza_juridica
    {:type ""dimension"",
     :name ""natureza_juridica"",
     :id ""444682dc-3690-473d-8018-36a68e451773"",
     :display-name ""Natureza Jurídica"",
     :dimension [""field"" 41063 nil],
     :widget-type ""string/="",
     :options nil,
     :default nil},
    :subclasse_cnae
    {:type ""dimension"",
     :name ""subclasse_cnae"",
     :id ""91427d47-62dc-40d5-8d10-1557575d452d"",
     :display-name ""Subclasse CNAE"",
     :dimension [""field"" 40982 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :divisao_cnae
    {:type ""dimension"",
     :name ""divisao_cnae"",
     :id ""e930be30-ddc4-4c5f-9e32-1afa686c0e29"",
     :display-name ""Divisão CNAE"",
     :dimension [""field"" 41007 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :razao_social
    {:type ""dimension"",
     :name ""razao_social"",
     :id ""b5b7c2f3-c5b2-44d6-b06c-15f332eabf70"",
     :display-name ""Razão Social"",
     :default nil,
     :dimension [""field"" 41048 nil],
     :widget-type ""string/="",
     :options nil},
    :data_inicio_atividade
    {:type ""date"",
     :name ""data_inicio_atividade"",
     :id ""4c024642-cd21-4891-90f0-a7343612be85"",
     :display-name ""Início atividade depois de""},
    :qualificacao_responsavel
    {:type ""dimension"",
     :name ""qualificacao_responsavel"",
     :id ""037bba87-9acc-42c7-b647-0fdfe65dc56c"",
     :display-name ""Qualificação Responsável"",
     :dimension [""field"" 41081 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :opcao_simples
    {:type ""dimension"",
     :name ""opcao_simples"",
     :id ""34008417-d52a-4018-9e95-b86f4edad6a6"",
     :display-name ""Simples"",
     :dimension [""field"" 41062 nil],
     :widget-type ""string/=""},
    :descricao_porte
    {:type ""dimension"",
     :name ""descricao_porte"",
     :id ""7b41e7d2-98f4-41ba-861f-44d13ff0506d"",
     :display-name ""Porte"",
     :dimension [""field"" 41064 nil],
     :widget-type ""string/="",
     :options nil},
    :cnpj
    {:type ""dimension"",
     :name ""cnpj"",
     :id ""80f1a2a1-8c88-429d-a34b-34096894dd70"",
     :display-name ""CNPJ"",
     :dimension [""field"" 40286 nil],
     :widget-type ""string/contains"",
     :options {:case-sensitive false}},
    :cnpj_basico
    {:type ""dimension"",
     :name ""cnpj_basico"",
     :id ""7fadb89f-8540-40f1-adf4-fd544f10e0d2"",
     :display-name ""CNPJ Básico"",
     :dimension [""field"" 40318 nil],
     :widget-type ""string/="",
     :default nil},
    :municipio
    {:type ""dimension"",
     :name ""municipio"",
     :id ""5c1750c2-8589-4d10-b6fa-f1b4e2603a2a"",
     :display-name ""Município"",
     :dimension [""field"" 41014 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :grupo_cnae
    {:type ""dimension"",
     :name ""grupo_cnae"",
     :id ""1793bb25-7f7d-4204-a462-deb7746b9104"",
     :display-name ""Grupo CNAE"",
     :dimension [""field"" 41018 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :sigla_uf
    {:type ""dimension"",
     :name ""sigla_uf"",
     :id ""f1e0c9a4-08b7-4713-a83d-d65631451d7e"",
     :display-name ""Sigla UF"",
     :dimension [""field"" 40990 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :secao_cnae
    {:type ""dimension"",
     :name ""secao_cnae"",
     :id ""c493ddd1-fd41-48da-b02c-ab7d29c168ca"",
     :display-name ""Seção CNAE"",
     :dimension [""field"" 40981 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :classe_cnae
    {:type ""dimension"",
     :name ""classe_cnae"",
     :id ""de259360-198c-4e7c-8275-30e64ccbfc1c"",
     :display-name ""Classe CNAE"",
     :dimension [""field"" 40992 nil],
     :widget-type ""string/="",
     :default nil,
     :options nil},
    :opcao_mei
    {:type ""dimension"",
     :name ""opcao_mei"",
     :id ""0ffbbd4c-a6ff-48a1-a76b-3e720c337021"",
     :display-name ""MEI"",
     :default nil,
     :dimension [""field"" 41068 nil],
     :widget-type ""string/="",
     :options nil}}},
  :type ""native"",
  :database 3,
  :parameters
  [{:id ""444682dc-3690-473d-8018-36a68e451773"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""natureza_juridica""]],
    :options nil}
   {:id ""7b41e7d2-98f4-41ba-861f-44d13ff0506d"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_porte""]],
    :options nil}
   {:id ""80f1a2a1-8c88-429d-a34b-34096894dd70"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""cnpj""]],
    :options {:case-sensitive false}}
   {:id ""91427d47-62dc-40d5-8d10-1557575d452d"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""subclasse_cnae""]],
    :options nil}
   {:id ""e930be30-ddc4-4c5f-9e32-1afa686c0e29"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""divisao_cnae""]],
    :options nil}
   {:id ""1793bb25-7f7d-4204-a462-deb7746b9104"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""grupo_cnae""]],
    :options nil}
   {:id ""0ffbbd4c-a6ff-48a1-a76b-3e720c337021"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""opcao_mei""]],
    :options nil}
   {:id ""c493ddd1-fd41-48da-b02c-ab7d29c168ca"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""secao_cnae""]],
    :options nil}
   {:id ""34008417-d52a-4018-9e95-b86f4edad6a6"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""opcao_simples""]]}
   {:id ""b5b7c2f3-c5b2-44d6-b06c-15f332eabf70"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""razao_social""]],
    :options nil}
   {:id ""7fadb89f-8540-40f1-adf4-fd544f10e0d2"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""cnpj_basico""]]}
   {:id ""f1e0c9a4-08b7-4713-a83d-d65631451d7e"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""sigla_uf""]],
    :options nil}
   {:id ""037bba87-9acc-42c7-b647-0fdfe65dc56c"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""qualificacao_responsavel""]],
    :options nil}
   {:id ""4c024642-cd21-4891-90f0-a7343612be85"",
    :type ""date/single"",
    :value ""2000-01-01"",
    :target [""variable"" [""template-tag"" ""data_inicio_atividade""]]}
   {:id ""de259360-198c-4e7c-8275-30e64ccbfc1c"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""classe_cnae""]],
    :options nil}
   {:id ""5c1750c2-8589-4d10-b6fa-f1b4e2603a2a"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""municipio""]],
    :options nil}],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)""
  ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)""
  ""--> driver.sql_jdbc.execute$fn__82446.invokeStatic(execute.clj:566)""
  ""driver.sql_jdbc.execute$fn__82446.invoke(execute.clj:564)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:579)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518$fn__82519.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__108335.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__108335.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
  ""query_processor.execute$run.invoke(execute.clj:54)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71610.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71625.invoke(execute.clj:23)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71630.invoke(execute.clj:34)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71583.invoke(cache.clj:239)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66212.invoke(permissions.clj:147)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66824.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66834.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__71657.invoke(execute.clj:92)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
  ""query_processor.execute$execute.invoke(execute.clj:87)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""query_processor.middleware.enterprise$fn__66851$handle_audit_app_internal_queries__66852$fn__66854.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66862.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76857.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76926.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76963.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67266.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67261.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67256$fn__67257.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:105)""
  ""driver$do_with_driver.invoke(driver.clj:100)""
  ""query_processor.setup$do_with_driver$fn__67256.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67249$fn__67252.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67249.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67243.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__94182.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__70166$fn__70167$fn__70168.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70166$fn__70167.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70166.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52036.invoke(streaming_response.clj:97)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""ERROR: invalid input syntax for type date: \""data_inicio_atividade\""\n  Position: 8868"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}
```


**To Reproduce**
Steps to reproduce the behavior:

1. Create a question using the SQL Builder.
2. Use a date parameter in a key of a JSONB column defined as date.
3. Execute the query.
4. Observe the error in the SQL query generation.

**Expected behavior**
The dados_2021 ->> 'data_inicio_atividade' column should be correctly interpreted as a date type when using an SQL Parameter of type date in the query.

**Screenshots**
![Image](https://github.com/user-attachments/assets/5192fba0-236e-47f1-810f-bbeaef55b64c)

![Image](https://github.com/user-attachments/assets/fc065379-36b0-4dcc-b0b6-1b2550d1566c)


**Severity**
This issue is blocking some users from correctly viewing and interpreting date values in their dashboards. It is a significant hindrance to our workflow and data analysis.

**Additional context**
I also tried using the ""Field filter"" parameter type with the data type ""Date"" and encountered another SQL error:
`AND (""dados"".""mv_estabelecimentos"".""dados_2021""#>> array[date '2021-09-10']::text[])::text BETWEEN date '2021-10-10' AND ?`

This problem persists across multiple dashboards and queries involving the dados_2021 ->> 'data_inicio_atividade' column. Reconfiguring the Metadata settings does not resolve the issue.

![Image](https://github.com/user-attachments/assets/db407247-ab45-461d-80f0-28e612332a1b)

![Image](https://github.com/user-attachments/assets/0eaea683-6434-4a69-9add-6b1ee4fccc3a)


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Ubuntu 16.4-0ubuntu0.24.04.2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-45-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",fmercurio,2024-10-10 20:09:52+00:00,[],2024-10-10 20:20:32+00:00,,https://github.com/metabase/metabase/issues/48583,[],[],
2579725810,issue,closed,not_planned,Add Snowplow event to track cleanup modal opening,"**Context**
Simple event

`name` = `collection-cleanup-opened`
`target_id` = collection_id (`null` if triggered from elsewhere)
`triggered_from` = `banner` or `overflow_menu`
`duration_ms` = `null`
`result` = `success` or `failure` (only return failure if we get an error in the modal)
`event_detail` = `null`


",luizarakaki,2024-10-10 19:59:58+00:00,[],2024-10-11 14:03:55+00:00,2024-10-11 14:03:54+00:00,https://github.com/metabase/metabase/issues/48582,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2407486805, 'issue_id': 2579725810, 'author': 'luizarakaki', 'body': 'closing in favor of https://github.com/metabase/metabase/pull/48586', 'created_at': datetime.datetime(2024, 10, 11, 14, 3, 54, tzinfo=datetime.timezone.utc)}]","luizarakaki (Issue Creator) on (2024-10-11 14:03:54 UTC): closing in favor of https://github.com/metabase/metabase/pull/48586

"
2579722785,issue,open,,"Add Snowplow event to track Channel create, update, and archive","**Context**
We shipped Webhooks on 51 and we need to track feature adoption.

### Create, update, and archive event
Send a `simple-event` when users create, update or archive a channel.
`name` = `channel-created` or `channel-updated` or `channel-archived`
`target_id` = channel_id
`triggered_from` = where in the UI this was triggered, for now, it is only possible to trigger these actions from notifications page, so this should be `admin-notification_channels`
`duration_ms` = time to process the request (only add this if this is trivial, otherwise can leave this null)
`result` = `success` or `failure`
`event_detail` = `null`

### Channel context
Add a new Snowplow context with Channel data. This context can be reused in other events in the future that are related to channels.
This requires a new schema.

`type` = `webhook`, in the future we will have more channel types
`auth` = none/basic/bearer/api_key
`has_description` = true/false

This schema will likely evolve as we add more channel types",luizarakaki,2024-10-10 19:58:20+00:00,[],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/48581,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2579677569,issue,closed,completed,[Epic] admin/webapp 51 feature tracking,"### SCIM
- [x] Adoption: tracked on anonymous stats
- [ ] Errors: grafana

### Webhooks
- [ ] Adoption: webhook (channel creation): Snowplow event
- [x] Usage: webhooks sent: Hosting insights: Tasks

### Sidesheets
nothing

### Trash v2
- [ ] Errors: errors when trying to send an item to trash

### Collections cleanup
- [ ] Adoption: Snowplow events: open cleanup modal
- [ ] Usage: Snowplow event: move item to trash with source property (detail page, collection page, cleanup)
- [ ] Errors: ?",luizarakaki,2024-10-10 19:37:43+00:00,[],2024-11-13 18:41:53+00:00,2024-11-13 18:41:53+00:00,https://github.com/metabase/metabase/issues/48580,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2579375925,issue,closed,completed,Faster sync on Postgres,,snoe,2024-10-10 16:54:31+00:00,['snoe'],2024-10-30 21:32:58+00:00,2024-10-30 20:24:40+00:00,https://github.com/metabase/metabase/issues/48575,"[('.Team/Drivers', '')]",[],
2579325521,issue,open,,Log in `audit_log` when users are added or removed from groups,"**Is your feature request related to a problem? Please describe.**
Can't audit who was added to a group and when

**Describe the solution you'd like**
Log in `audit_log` all group membership changes, including: who added/removed the person (if manual change), which SSO method automatically did it, who was affected, which groups were affected and the timestamp

**Describe alternatives you've considered**
-

**How important is this feature to you?**
Important for audit and compliance reasons",luizarakaki,2024-10-10 16:31:19+00:00,[],2025-02-04 20:30:12+00:00,,https://github.com/metabase/metabase/issues/48571,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2579182726,issue,open,,"`lib.aggregation/aggregation-column` can try to `find-matching-column` on an expression, rather than the inner ref","### Describe the bug

`metabase.models.field-usage/aggregation->field-usage` wants to find all the field refs inside an aggregation.

`lib.aggregation/aggregation-column` naively assumes the 2nd element of an aggregation clause must be a direct ref. That's not true - it can be a subexpression that contains field refs for eg. a `:sum-where`.

1. That's straight-up a bug in `aggregation-column` and should be fixed. (By picking the inner column correctly for each kind of aggregation.)
2. But it's also a problem for `aggregation->field-usage` which actually wants both the field being eg. summed *and* any fields referenced in the `:sum-where` condition!

So some deeper change is needed to support `aggregation->field-usage`; probably a new `lib.aggregation/aggregation-filter` that returns the filtering expression for `:count-where` and `:sum-where`. (`models.field-usage` has logic for pulling apart expressions already.)

### To Reproduce

1. Write a `:sum-where` aggregation.
2. Run the query
3. Observe the `""Unknown type of ref""` error on the client where `find-match-column` was called with the filter expression as the ref, rather than the column getting summed.

### Expected behavior

Correctly finding field usage in all cases!

### Logs

_No response_

### Information about your Metabase installation

any version; eg. master

### Severity

Log spam, also a gap in field usage stats

### Additional context

_No response_",bshepherdson,2024-10-10 15:25:23+00:00,[],2025-02-04 20:27:54+00:00,,https://github.com/metabase/metabase/issues/48567,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/Querying', '')]","[{'comment_id': 2405526012, 'issue_id': 2579182726, 'author': 'appleby', 'body': 'There is a similar bug in `filter->field-usage` as well where `filter-parts` also does not handle nested filter expressions\n\nhttps://github.com/metabase/metabase/issues/44376#issuecomment-2394420271', 'created_at': datetime.datetime(2024, 10, 10, 16, 9, 37, tzinfo=datetime.timezone.utc)}]","appleby on (2024-10-10 16:09:37 UTC): There is a similar bug in `filter->field-usage` as well where `filter-parts` also does not handle nested filter expressions

https://github.com/metabase/metabase/issues/44376#issuecomment-2394420271

"
2579093547,issue,closed,completed,Add snowplow event on FE for stale modal,"![Image](https://github.com/user-attachments/assets/ef0cc916-9a03-47e6-8534-7a28b9f81ccd)

When the user uses this modal to clean things up, we should capture an event that they have done so, and include how many things were sent over.",dpsutton,2024-10-10 14:48:56+00:00,[],2024-10-11 19:15:26+00:00,2024-10-11 14:21:47+00:00,https://github.com/metabase/metabase/issues/48566,"[('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2578729055,issue,open,,Handle failing requests better when part of the notebook editor can still be rendered,"See the discussion here: https://github.com/metabase/metabase/issues/47058

Some requests are not vital to the notebook editor, or are only vital to parts of the notebook editor.

It would be good if we could render the other (still functional parts) of the notebook editor if a request fails.",romeovs,2024-10-10 12:38:40+00:00,[],2025-02-04 20:27:50+00:00,,https://github.com/metabase/metabase/issues/48562,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]",[],
2578563407,issue,closed,completed,Applying a visualization to a metric and saving offers to replace a non-existing question,"### Describe the bug

After creating a metric, opening it and applying a visualization to it, hitting ""Save"" will offer to replace an existing question which was never created in the first place, making it confusing.

### To Reproduce

1. Create a metric like this one:
![Image](https://github.com/user-attachments/assets/3dccd694-3e30-4556-befa-c76346749bbc)

2. Click on 'Visualization'
3. Choose another visualization type or customize the current visualization settings
4. First, you lose sight of the metric and land on what appears to be a question done directly on the data source (Flights table from the Air database in my case)
![Image](https://github.com/user-attachments/assets/d75f6fab-4c65-4eaa-a6af-6e3fb9d53499)

Second, saving offers to replace an existing question I never created
![Image](https://github.com/user-attachments/assets/d7a97fcb-136f-4fed-a6b8-29bed9987305)

### Expected behavior

I expect to stick to the navigation breadcrumbs present when opening the Metric like so:
![Image](https://github.com/user-attachments/assets/287d6081-7095-449b-91e8-8cb3954c0dee)

I also don't expect to have a question generated for me. If that's technically necessary, then I would expect the auto-generated question to be a brand new one, and saving not offering to replace, but only to create a new one.

### Logs

_No response_

### Information about your Metabase installation

Brave browser Version 1.70.126 Chromium: 129.0.6668.100 (Official Build) (arm64)

Local installation built on Hash: 06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5

Database source is postgres, data loaded via CSV


### Severity

This is annoying, confusing

### Additional context

_No response_",thebiglabasky,2024-10-10 11:28:40+00:00,['romeovs'],2024-10-16 14:32:03+00:00,2024-10-16 14:31:29+00:00,https://github.com/metabase/metabase/issues/48555,"[('Type:Bug', 'Product defects'), ('Type:UX', ''), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2404842347, 'issue_id': 2578563407, 'author': 'kamilmielnik', 'body': 'Related Slack conversation: https://metaboat.slack.com/archives/C0645JP1W81/p1728547763335779', 'created_at': datetime.datetime(2024, 10, 10, 11, 31, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404847730, 'issue_id': 2578563407, 'author': 'kamilmielnik', 'body': '@mngr this is not a simple bugfix, we need to spec out how should this work', 'created_at': datetime.datetime(2024, 10, 10, 11, 33, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405324860, 'issue_id': 2578563407, 'author': 'mngr', 'body': 'We should not show the block with choice to save as new or replace, the same as we do for Models\n![Image](https://github.com/user-attachments/assets/19410169-4c6e-4196-be76-e8f50422e421)', 'created_at': datetime.datetime(2024, 10, 10, 14, 47, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406718154, 'issue_id': 2578563407, 'author': 'kamilmielnik', 'body': '> We should not show the block with choice to save as new or replace, the same as we do for Models \n\n@mngr This adresses just one of the problems mentioned in the report. Also see ""expected behavior"" section.', 'created_at': datetime.datetime(2024, 10, 11, 7, 26, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417019585, 'issue_id': 2578563407, 'author': 'mngr', 'body': 'The title problem is fixed here https://github.com/metabase/metabase/pull/48669\nDefault breadcrumbs should be fixed here https://github.com/metabase/metabase/issues/47006.\nBreadcrumbs when starting a new ad-hoc query based on a metric are shown correctly.\nThe behavior when changing viz settings will be different after upcoming development of the query and viz splitting.', 'created_at': datetime.datetime(2024, 10, 16, 14, 31, 29, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-10 11:31:05 UTC): Related Slack conversation: https://metaboat.slack.com/archives/C0645JP1W81/p1728547763335779

kamilmielnik on (2024-10-10 11:33:48 UTC): @mngr this is not a simple bugfix, we need to spec out how should this work

mngr on (2024-10-10 14:47:47 UTC): We should not show the block with choice to save as new or replace, the same as we do for Models
![Image](https://github.com/user-attachments/assets/19410169-4c6e-4196-be76-e8f50422e421)

kamilmielnik on (2024-10-11 07:26:30 UTC): @mngr This adresses just one of the problems mentioned in the report. Also see ""expected behavior"" section.

mngr on (2024-10-16 14:31:29 UTC): The title problem is fixed here https://github.com/metabase/metabase/pull/48669
Default breadcrumbs should be fixed here https://github.com/metabase/metabase/issues/47006.
Breadcrumbs when starting a new ad-hoc query based on a metric are shown correctly.
The behavior when changing viz settings will be different after upcoming development of the query and viz splitting.

"
2578009701,issue,closed,completed,ESLint - Enforce empty line between `describe` and `it` calls in tests,"https://eslint.style/rules/default/padding-line-between-statements

To avoid having these comments in PRs:
- https://github.com/metabase/metabase/pull/48468#discussion_r1794859815
- https://github.com/metabase/metabase/pull/48468#discussion_r1793150586",kamilmielnik,2024-10-10 08:04:22+00:00,['romeovs'],2024-11-26 18:52:41+00:00,2024-10-14 15:36:37+00:00,https://github.com/metabase/metabase/issues/48553,"[('Type:Tech Debt', 'or Refactoring'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2577866195,issue,open,,Field filters not working for databricks,"### Describe the bug

![Image](https://github.com/user-attachments/assets/b0c04a9f-2e5f-4352-9f42-2648e6ef7529)

Field filter is not working for the Databricks driver

### To Reproduce

1. Go to 'New > Sql query'
2. Write a query with variables
3. Try to declare the variable type as 'Field Filter'
4. No tables will be shown in the dropdown


### Expected behavior

It should show a list of tables and on selecting the table it should show the list of columns to select as a field filter.

### Logs

No error in the logs

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""databricks""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-08"",
      ""tag"": ""v1.51.0-beta"",
      ""hash"": ""f69afc2""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+0"",
    ""java.vendor"": ""Homebrew"",
    ""java.vendor.url"": ""https://github.com/Homebrew/homebrew-core/issues"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+0"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.6.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Asia/Kolkata""
  }
}

### Severity

Blocking usage of Metabase partially. Around 8-10 charts which require field filters are not working out 200.

### Additional context

_No response_",ggoyal01,2024-10-10 07:10:11+00:00,['lbrdnk'],2025-02-04 20:28:53+00:00,,https://github.com/metabase/metabase/issues/48551,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/Remapping', 'Remapped display values, whether human-readable values or Field->Field remappings'), ('.Team/Querying', ''), ('Database/Databricks', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2405753918, 'issue_id': 2577866195, 'author': 'lbrdnk', 'body': ""Hey @ggoyal01. Thank you for the report. As in attached screenshot, I'm able to see the tables and fields to be used in field filter just fine.\n\n![Image](https://github.com/user-attachments/assets/4120de64-00dc-45fe-9895-bb1d985b1e0d)\n\n\nCould you confirm that sync completed successfully? Eg. by going from home screen to Databases (left pane) > your database > your table. Than, when you execute just a plain select from query builder, are those columns that you'd expect to show up in the field filter present?"", 'created_at': datetime.datetime(2024, 10, 10, 18, 13, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408617310, 'issue_id': 2577866195, 'author': 'perivamsi', 'body': '@ggoyal01 could you please let us know if there were any sync failures? Appreciate your help and thank you for reporting this issue!', 'created_at': datetime.datetime(2024, 10, 12, 16, 23, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416469992, 'issue_id': 2577866195, 'author': 'perivamsi', 'body': 'Downgrading to P3 because it is not reproducible despite our best efforts, waiting for @ggoyal01 to respond', 'created_at': datetime.datetime(2024, 10, 16, 10, 59, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428102842, 'issue_id': 2577866195, 'author': 'ggoyal01', 'body': 'Hi @perivamsi \nHow could I check the sync failures ? The metadata fectch queries were passing though. \nDo you have multiple catalogs in databricks ? Are you connected to hive metastore catalog or unity catalog ?', 'created_at': datetime.datetime(2024, 10, 22, 2, 52, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429147051, 'issue_id': 2577866195, 'author': 'ggoyal01', 'body': 'Sorry, my bad. Missed the instruction.\n\nChecked Databases (left pane) > your database > your table. It is showing me the error attached below - `No fields found for table ""trip_tripnode_employee"".`\nAlso checked in databricks cluster that the metadata fetch queries are succeeding.\n\n![Image](https://github.com/user-attachments/assets/46e26611-94a8-43a6-ab68-166073621253)\n\n\n![Image](https://github.com/user-attachments/assets/50c25cbe-5f79-4f00-9808-af82cea2d556)', 'created_at': datetime.datetime(2024, 10, 22, 12, 27, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441787799, 'issue_id': 2577866195, 'author': 'lbrdnk', 'body': 'Hey @ggoyal01, thank you for the update. Are your data stored in the unity catalog or legacy?', 'created_at': datetime.datetime(2024, 10, 28, 14, 42, 46, tzinfo=datetime.timezone.utc)}]","lbrdnk (Assginee) on (2024-10-10 18:13:52 UTC): Hey @ggoyal01. Thank you for the report. As in attached screenshot, I'm able to see the tables and fields to be used in field filter just fine.

![Image](https://github.com/user-attachments/assets/4120de64-00dc-45fe-9895-bb1d985b1e0d)


Could you confirm that sync completed successfully? Eg. by going from home screen to Databases (left pane) > your database > your table. Than, when you execute just a plain select from query builder, are those columns that you'd expect to show up in the field filter present?

perivamsi on (2024-10-12 16:23:47 UTC): @ggoyal01 could you please let us know if there were any sync failures? Appreciate your help and thank you for reporting this issue!

perivamsi on (2024-10-16 10:59:44 UTC): Downgrading to P3 because it is not reproducible despite our best efforts, waiting for @ggoyal01 to respond

ggoyal01 (Issue Creator) on (2024-10-22 02:52:01 UTC): Hi @perivamsi 
How could I check the sync failures ? The metadata fectch queries were passing though. 
Do you have multiple catalogs in databricks ? Are you connected to hive metastore catalog or unity catalog ?

ggoyal01 (Issue Creator) on (2024-10-22 12:27:43 UTC): Sorry, my bad. Missed the instruction.

Checked Databases (left pane) > your database > your table. It is showing me the error attached below - `No fields found for table ""trip_tripnode_employee"".`
Also checked in databricks cluster that the metadata fetch queries are succeeding.

![Image](https://github.com/user-attachments/assets/46e26611-94a8-43a6-ab68-166073621253)


![Image](https://github.com/user-attachments/assets/50c25cbe-5f79-4f00-9808-af82cea2d556)

lbrdnk (Assginee) on (2024-10-28 14:42:46 UTC): Hey @ggoyal01, thank you for the update. Are your data stored in the unity catalog or legacy?

"
2577788995,issue,closed,completed,"ResultSet not positioned properly, perhaps you need to call next","### Describe the bug

Interesting new line that appears when you start v51

### To Reproduce

I just started v51

### Expected behavior

That should not appear at all

### Logs

```
metabase-load         | 2024-10-10 06:39:03,460 INFO task.sweep-query-analysis :: Recalculating potentially stale analysis
metabase-load         | 2024-10-10 06:39:03,467 ERROR task.analyze-queries :: Unhandled error when attempting to analyse the next card in the queue
metabase-load         | clojure.lang.ExceptionInfo: ResultSet not positioned properly, perhaps you need to call next. {:toucan2/context-trace [[""read column"" {:thunk #object[toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26095 0x584e365d ""toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26095@584e365d""], :model :model/Card}]]}
metabase-load         | 	at org.postgresql.jdbc.PgResultSet.getRawValue(PgResultSet.java:3276)
metabase-load         | 	at org.postgresql.jdbc.PgResultSet.getObject(PgResultSet.java:3048)
metabase-load         | 	at com.mchange.v2.c3p0.impl.NewProxyResultSet.getObject(NewProxyResultSet.java:165)
metabase-load         | 	at toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26095.invoke(read.clj:73)
metabase-load         | 	at toucan2.jdbc.read$read_column_thunk_after_method_default$fn__26107.invoke(read.clj:79)
metabase-load         | 	at toucan2.jdbc.read$make_column_thunk$column_thunk__26140.invoke(read.clj:136)
metabase-load         | 	at toucan2.jdbc.read$make_cached_row_num__GT_i__GT_thunk$row_num__GT_i__GT_thunk_STAR___26149$i__GT_thunk_STAR___26150$cached_column_thunk__26151.invoke(read.clj:180)
metabase-load         | 	at toucan2.jdbc.row$fetch_column_with_name.invokeStatic(row.clj:36)
metabase-load         | 	at toucan2.jdbc.row$fetch_column_with_name.invoke(row.clj:26)
metabase-load         | 	at toucan2.jdbc.row.TransientRow.valAt(row.clj:211)
metabase-load         | 	at toucan2.jdbc.row.TransientRow.valAt(row.clj:192)
metabase-load         | 	at clojure.lang.KeywordLookupSite$1.get(KeywordLookupSite.java:45)
metabase-load         | 	at metabase.util$id.invokeStatic(util.cljc:452)
metabase-load         | 	at metabase.util$id.invoke(util.cljc:443)
metabase-load         | 	at metabase.util$the_id.invokeStatic(util.cljc:462)
metabase-load         | 	at metabase.util$the_id.invoke(util.cljc:455)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_STAR_.invokeStatic(analyze_queries.clj:44)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_STAR_.invoke(analyze_queries.clj:40)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:72)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:70)
metabase-load         | 	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
metabase-load         | 	at metabase.task.analyze_queries.QueryAnalyzer.execute(analyze_queries.clj:81)
metabase-load         | 	at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
metabase-load         | 	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
metabase-load         | Caused by: org.postgresql.util.PSQLException: ResultSet not positioned properly, perhaps you need to call next.
metabase-load         | 	... 25 more

```

### Information about your Metabase installation

v51

### Severity

P1?

### Additional context

_No response_",paoliniluis,2024-10-10 06:41:25+00:00,[],2024-10-21 11:48:34+00:00,2024-10-21 11:48:33+00:00,https://github.com/metabase/metabase/issues/48550,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Postgres', None), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', ''), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2404240606, 'issue_id': 2577788995, 'author': 'qnkhuat', 'body': ""I think the nature of this bug is similar to https://github.com/metabase/metabase/issues/48310, it's not critical, so I'd give this a P3."", 'created_at': datetime.datetime(2024, 10, 10, 7, 12, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404241601, 'issue_id': 2577788995, 'author': 'qnkhuat', 'body': 'cc @crisptrutski', 'created_at': datetime.datetime(2024, 10, 10, 7, 13, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405463328, 'issue_id': 2577788995, 'author': 'crisptrutski', 'body': ""Agree on P3, my reasoning:\n\n1. No public functionality uses analysis.\n2. Analysis is rate limited so errors won't wreck logs or CPU.\n3. Analysis will be retried later by worker.\n4. Not seeing this consistently - for example was not happening on my local machine or on stats. \n\nI suspect this is just another way that the skipped realize can manifest. I see that https://github.com/metabase/metabase/pull/48509 hasn't merged into 51 yet as we ran into the issue where some tests didn't start. I rebased it to restart CI.\n\nI'm very interested in what was different in these environments that seems to have triggered exceptions so reliably 🤔"", 'created_at': datetime.datetime(2024, 10, 10, 15, 39, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405466557, 'issue_id': 2577788995, 'author': 'crisptrutski', 'body': ""@qnkhuat since I'm out, do you mind sheparding that PR to make sure it merges, and following up to see if we can resolve these two issues?"", 'created_at': datetime.datetime(2024, 10, 10, 15, 41, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406439909, 'issue_id': 2577788995, 'author': 'qnkhuat', 'body': ""I checked the log on stats and there are no more errors since, so I think we're good?"", 'created_at': datetime.datetime(2024, 10, 11, 2, 45, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408071420, 'issue_id': 2577788995, 'author': 'crisptrutski', 'body': ""I've never seen this issue on stats, so I think it's best to wait a bit to see if luis bumps into it again on other instances."", 'created_at': datetime.datetime(2024, 10, 11, 20, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426447962, 'issue_id': 2577788995, 'author': 'crisptrutski', 'body': ""Resolving as the only report I've seen was for the beta preceding the related PR"", 'created_at': datetime.datetime(2024, 10, 21, 11, 48, 33, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-10-10 07:12:57 UTC): I think the nature of this bug is similar to https://github.com/metabase/metabase/issues/48310, it's not critical, so I'd give this a P3.

qnkhuat on (2024-10-10 07:13:35 UTC): cc @crisptrutski

crisptrutski on (2024-10-10 15:39:28 UTC): Agree on P3, my reasoning:

1. No public functionality uses analysis.
2. Analysis is rate limited so errors won't wreck logs or CPU.
3. Analysis will be retried later by worker.
4. Not seeing this consistently - for example was not happening on my local machine or on stats. 

I suspect this is just another way that the skipped realize can manifest. I see that https://github.com/metabase/metabase/pull/48509 hasn't merged into 51 yet as we ran into the issue where some tests didn't start. I rebased it to restart CI.

I'm very interested in what was different in these environments that seems to have triggered exceptions so reliably 🤔

crisptrutski on (2024-10-10 15:41:01 UTC): @qnkhuat since I'm out, do you mind sheparding that PR to make sure it merges, and following up to see if we can resolve these two issues?

qnkhuat on (2024-10-11 02:45:20 UTC): I checked the log on stats and there are no more errors since, so I think we're good?

crisptrutski on (2024-10-11 20:20:00 UTC): I've never seen this issue on stats, so I think it's best to wait a bit to see if luis bumps into it again on other instances.

crisptrutski on (2024-10-21 11:48:33 UTC): Resolving as the only report I've seen was for the beta preceding the related PR

"
2577657774,issue,open,,Ability to set filter on the instance of a question-dashboard association.,"**Is your feature request related to a problem? Please describe.**
We have a single event table driving a number of our reports. When creating dashboards using this normalized event table we find that we end up creating dashboards with literally 10s of questions that are functionally and structurally identical but with a different filter. Doing this involves creating all the questions, individually adding them to the dashboard and placing them.

**Describe the solution you'd like**
It would be nice if in the association between a question and the dashboard you could codify a question's filter (or a summarization). So this isn't tied to the dashboard's filters per se, but also isn't saved in the question. 

As a simple example, take CRM activity events. In order to have an aggregation of closed won and closed lost deals, I have to go through the step to open question 1, change the filter, save it as question 2 (half the time forgetting to make it a new question), adding it to the dashboard, moving it to the right tab.

![Image](https://github.com/user-attachments/assets/84ad2770-82ec-4d79-8edb-5fa2dcefd41e)
![Image](https://github.com/user-attachments/assets/c36d8661-079e-49cd-9228-08b089462e7d)

Instead what I'd like to be able to do is, from the dashboard, copy an existing question, and set the filter in the instance of the copied question. So in essence I just have 1 single question that summarizes the way I want, and the instance of the question on a dashboard has the option to set a filter on it.

**Describe alternatives you've considered**
Another way could be to have a filter only apply to certain questions but the layout and management of dashboard level filters would get unbearably complex and unusable (which is already the case on mobile browsers due to inability to collapse or hide filters). So if this route was taken, there'd have to be an ability to hide some of the dashboard level filters.

**How important is this feature to you?**
Would be hugely time saving. 3 minutes per question down to 10 seconds per question. I'd say I'd be pretty darn excited if this came out in a future release.

**Additional context**
See above",shyrahnama,2024-10-10 05:35:06+00:00,[],2025-02-04 20:30:33+00:00,,https://github.com/metabase/metabase/issues/48549,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/', '')]","[{'comment_id': 2404130348, 'issue_id': 2577657774, 'author': 'paoliniluis', 'body': 'Thanks @shyrahnama, why can\'t you do simply a group by of the ""deal closed"" field instead of generating 2 questions?', 'created_at': datetime.datetime(2024, 10, 10, 6, 16, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565739787, 'issue_id': 2577657774, 'author': 'brunobergher', 'body': 'Probably addressed by the complete solution to #3575, which would include static/hardcoded values to parameters.', 'created_at': datetime.datetime(2024, 12, 30, 17, 24, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569379500, 'issue_id': 2577657774, 'author': 'brunobergher', 'body': ""But I should also ask, @shyrahnama, if you were able to:\n- Create a single question with all of the different aggregations you need to visualize\n- Easily add it multiple times to the same dashboard, just showing/hiding columns\n\nWould it address your need? Bonus that by doing that we'd potentially only the single query once."", 'created_at': datetime.datetime(2025, 1, 3, 15, 13, 36, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-10 06:16:14 UTC): Thanks @shyrahnama, why can't you do simply a group by of the ""deal closed"" field instead of generating 2 questions?

brunobergher on (2024-12-30 17:24:02 UTC): Probably addressed by the complete solution to #3575, which would include static/hardcoded values to parameters.

brunobergher on (2025-01-03 15:13:36 UTC): But I should also ask, @shyrahnama, if you were able to:
- Create a single question with all of the different aggregations you need to visualize
- Easily add it multiple times to the same dashboard, just showing/hiding columns

Would it address your need? Bonus that by doing that we'd potentially only the single query once.

"
2576901256,issue,open,,"Filter by this value when selecting ""equals"" / ""not equal to"" doesn't work for the aggregated queries","### Describe the bug

When you click on the value in the result of the aggregated query and select ""="" or ""≠"" in Filter by this value, you get the query that produces no results.

### To Reproduce

1. Go to + New question
2. Select Products table from the Sample database
3. Add Sum of Price and group by Category
4. Click on one of the bars in the viz or one of the Sum of Price values in the resulting table
5. Select ""="" or ""≠"" in Filter by this value
6. See No results!


### Expected behavior

It should filter the result by the specified value

### Logs

_No response_

### Information about your Metabase installation

0b7bf91

### Severity

Produces incorrect results

### Additional context

_No response_",mngr,2024-10-09 20:34:47+00:00,[],2025-02-04 20:27:04+00:00,,https://github.com/metabase/metabase/issues/48543,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Product Input Needed', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2404177441, 'issue_id': 2576901256, 'author': 'kamilmielnik', 'body': 'Looks like floating point precision issue, the filter uses a very specific value:\n![Image](https://github.com/user-attachments/assets/38202f4c-5330-490e-ad5a-60348fdd9a68)\n\nUsing a ""between"" filter with 1 less digit gives a correct result:\n![Image](https://github.com/user-attachments/assets/b0a3dfc6-8054-49e1-8a95-eab0c574ddab)', 'created_at': datetime.datetime(2024, 10, 10, 6, 43, 39, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-10 06:43:39 UTC): Looks like floating point precision issue, the filter uses a very specific value:
![Image](https://github.com/user-attachments/assets/38202f4c-5330-490e-ad5a-60348fdd9a68)

Using a ""between"" filter with 1 less digit gives a correct result:
![Image](https://github.com/user-attachments/assets/b0a3dfc6-8054-49e1-8a95-eab0c574ddab)

"
2576739233,issue,closed,not_planned,[FE] Time over time comparison UI,,ranquild,2024-10-09 19:10:12+00:00,['ranquild'],2024-10-25 19:07:25+00:00,2024-10-25 19:07:25+00:00,https://github.com/metabase/metabase/issues/48534,[],[],
2576723788,issue,closed,not_planned,[Epic] Compare UI follow-ons part 2,"Product doc https://www.notion.so/metabase/Compare-UI-follow-ons-part-2-13ff2cab0d714b58904ea038ad0ae843

#### Milestone 1 - Time over time comparison UI changes - FE only

Items 1, 4, 6 from the doc. Change the popover + disallow nesting offset calls. 

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/48534
- [ ] https://github.com/metabase/metabase/issues/48735
- [ ] [Testing plan] Time over time comparison UI
```

#### Milestone 2 - visualization settings - FE only

Item 3 from the doc.

```[tasklist]
- [ ] [FE] Set viz settings for newly created columns
- [ ] [Testing plan] Set viz settings for newly created columns
```

#### Milestone 3 - handling no breakouts case - BE, MBQL lib

Item 5 from the doc. We need to ignore `offset` calls and use the underlying column when there are no breakouts.

#### Milestone 4 - handling filters with offset - BE

Item 2 from the doc. Unclear for now.",ranquild,2024-10-09 19:04:01+00:00,['ranquild'],2024-10-15 22:32:24+00:00,2024-10-15 22:32:24+00:00,https://github.com/metabase/metabase/issues/48533,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2576100660,issue,open,,Dashboard filter values prefill with previous values when left unspecified,"### Describe the bug

If a user has previously opened a dashboard and specified filter values then re-opening the dashboard from a URL that doesn't explicitly specify all of the filter values will prefill the filters with the values from the previous visit.

This is especially bad when having multiple filters that end up having conflicting/non-appropriate values.
e.g. having a user dashboard with filters for user id and account id and getting it prefilled with wrong users account.

This behaviour seems to have been added a few versions back.

### To Reproduce

1. Go to a dashboard with filters A and B. 
2. Select a value for the filter A
3. Close browser tab
4. Open the dashboard again from pasting a link to the dashboard to browser address bar but having only the value for filter B specified.
5. Notice that the filter value for filter A is prefilled with the value from previous visit along with the filter B having the value specified in the url


### Expected behavior

Having prefill not happen when at least one filter parameter is provided or having a way to turn off this prefill for all or some dashboards.

### Logs

_No response_

### Information about your Metabase installation

v0.50.28

### Severity

P2

### Additional context

_No response_",neljandik,2024-10-09 14:25:37+00:00,[],2025-02-04 20:29:04+00:00,,https://github.com/metabase/metabase/issues/48524,"[('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2403358579, 'issue_id': 2576100660, 'author': 'mngr', 'body': 'Product note:\nPossible intermediate solution is to reset all the filters when opening from direct link.\nAlternative is to remove the preserving filter values feature in favor of allowing to bookmark a dashboard with a specific set of filter values.', 'created_at': datetime.datetime(2024, 10, 9, 20, 20, 46, tzinfo=datetime.timezone.utc)}]","mngr on (2024-10-09 20:20:46 UTC): Product note:
Possible intermediate solution is to reset all the filters when opening from direct link.
Alternative is to remove the preserving filter values feature in favor of allowing to bookmark a dashboard with a specific set of filter values.

"
2576029169,issue,closed,completed,Banner for instance in trial,"__Context__
We want to nudge our cloud customers on trial to activate their instance.

__Problem__
We do not have a mechanism for us to show our customers that their trial will soon end.

__Proposal__

[Product doc](https://www.notion.so/metabase/No-CC-required-for-Cloud-trial-d268a1a7f1d94990aef261cf1211aa76?pvs=4#10e69354c901800a802cd38e56aedd5b).

- [x] We need to display a banner for to admin users of an instance in trial, similarly to the past-due payment banner. 
- [x]  Banner appears 14d before trial ends
- [x]  X dismisses the banner
- [x]  banner appears 3d before trial ends, 2d before trial ends, 1d before trial ends (this is just conditional on the days until the end of trial, does not check if the banner was dismissed or not)
- [ ] Depends on https://github.com/metabase/infra-frontend/issues/1153, exact deep link url tbd 

[Figma with the updated design](https://www.figma.com/design/OGkkIYPpfcEfd7EjnmL6SJ/No-CC-required-for-Cloud-trial?node-id=657-1054&t=8zdpNzGRg0uz7WJ0-4)

![Image](https://github.com/user-attachments/assets/50e9413a-36ee-44a8-b616-93bef6a28768)


",losrebellos,2024-10-09 13:57:57+00:00,['nemanjaglumac'],2024-12-04 20:44:45+00:00,2024-12-04 12:49:55+00:00,https://github.com/metabase/metabase/issues/48522,"[('.Frontend', '')]","[{'comment_id': 2426167662, 'issue_id': 2576029169, 'author': 'trinya', 'body': 'Suggestion for the banner behavior:\n- if user never closes the banner - the banner will always be at the top\n- if they close it, they will not see it again until 3 days before the trial ends\n- if they close it again, it will re-appear every 24h\n- if, for whatever reason, they log out - the banner should re-appear', 'created_at': datetime.datetime(2024, 10, 21, 9, 44, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427416142, 'issue_id': 2576029169, 'author': 'nemanjaglumac', 'body': 'The store URL: `https://store.metabase.com/account/manage/billing#section=payment-method`', 'created_at': datetime.datetime(2024, 10, 21, 18, 21, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429007989, 'issue_id': 2576029169, 'author': 'imrkd', 'body': 'This suggestions are fairly complex, each of them has non trivial implementation cost. Specifically `if they close it again, it will re-appear every 24h` is turning into a backend concern for what should\'ve been a trivial FE only change, and also imo user hostile. \nCan we narrow down suggestions to ""minimal set of things that you\'re ok shipping""? and also once agreed let\'s update the product doc please.', 'created_at': datetime.datetime(2024, 10, 22, 11, 19, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429041679, 'issue_id': 2576029169, 'author': 'trinya', 'body': ""Thanks, yes, let's not do the backend.\nMinimal set we talked to with Nemanja about is hardcoded on FE:\n- banner appears 14d before trial ends\n- X dismisses the banner\n- banner appears 3d before trial ends, 2d before trial ends, 1d before trial ends (this is just conditional on the days until the end of trial, does not check if the banner was dismissed or not)"", 'created_at': datetime.datetime(2024, 10, 22, 11, 37, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429291192, 'issue_id': 2576029169, 'author': 'imrkd', 'body': 'This is more or less doable, BUT \n* why are we making this dissmisable again? why can\'t we just leave it there always till they put in the card? \n* and now thinking about it, what should we do when they do input the card? figure out a way to hide the banner via some signal, _or_ should we make adding the CC effectively end the trial and be a ""Buy Now"" moment?', 'created_at': datetime.datetime(2024, 10, 22, 13, 28, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429344646, 'issue_id': 2576029169, 'author': 'trinya', 'body': '>  why are we making this dissmisable again? why can\'t we just leave it there always till they put in the card?\n\nBecause we want to keep it for all trialers, even those that have a card. They don\'t need this banner whatsoever. If we make it conditional on having the card, that can work.\n\n> and now thinking about it, what should we do when they do input the card? figure out a way to hide the banner via some signal, or should we make adding the CC effectively end the trial and be a ""Buy Now"" moment?\n\nThat was supposed to be ""Buy Now"" moment, yes. If this is too hard to do, then we need something else - either a way to dismiss it, or hide the banner if the payment details are in place.', 'created_at': datetime.datetime(2024, 10, 22, 13, 49, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429445118, 'issue_id': 2576029169, 'author': 'imrkd', 'body': 'ok, so dismiss-able 👍 \nconditional on having a card is going to be fairly tedious. \n@kidd note re ""Buy Now"" ☝', 'created_at': datetime.datetime(2024, 10, 22, 14, 27, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429471541, 'issue_id': 2576029169, 'author': 'kidd', 'body': 'Added an issue in milestone 3:\n\nhttps://github.com/metabase/harbormaster/issues/5409?issue=metabase%7Charbormaster%7C5434\n\nidk which milestone it belongs to, but I wanted to write it somewhere. Feel free to move it', 'created_at': datetime.datetime(2024, 10, 22, 14, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429741285, 'issue_id': 2576029169, 'author': 'imrkd', 'body': 'milestone3 makes sense and thank you 🙏', 'created_at': datetime.datetime(2024, 10, 22, 16, 29, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442060962, 'issue_id': 2576029169, 'author': 'trinya', 'body': '[Figma with the updated design](https://www.figma.com/design/OGkkIYPpfcEfd7EjnmL6SJ/No-CC-required-for-Cloud-trial?node-id=657-1054&t=8zdpNzGRg0uz7WJ0-4)\n\n![Image](https://github.com/user-attachments/assets/50e9413a-36ee-44a8-b616-93bef6a28768)', 'created_at': datetime.datetime(2024, 10, 28, 16, 26, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2499943749, 'issue_id': 2576029169, 'author': 'nemanjaglumac', 'body': ""We're still not able to use this color in the main app. I have to use deep yellow (`warning`) color instead.\nSee: https://github.com/metabase/metabase/pull/49344#discussion_r1857294644\n\n![Image](https://github.com/user-attachments/assets/13b808ae-84ec-46fd-ace3-8fd565eb729f)"", 'created_at': datetime.datetime(2024, 11, 26, 8, 13, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518524093, 'issue_id': 2576029169, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2024, 12, 4, 20, 44, 44, tzinfo=datetime.timezone.utc)}]","trinya on (2024-10-21 09:44:55 UTC): Suggestion for the banner behavior:
- if user never closes the banner - the banner will always be at the top
- if they close it, they will not see it again until 3 days before the trial ends
- if they close it again, it will re-appear every 24h
- if, for whatever reason, they log out - the banner should re-appear

nemanjaglumac (Assginee) on (2024-10-21 18:21:11 UTC): The store URL: `https://store.metabase.com/account/manage/billing#section=payment-method`

imrkd on (2024-10-22 11:19:26 UTC): This suggestions are fairly complex, each of them has non trivial implementation cost. Specifically `if they close it again, it will re-appear every 24h` is turning into a backend concern for what should've been a trivial FE only change, and also imo user hostile. 
Can we narrow down suggestions to ""minimal set of things that you're ok shipping""? and also once agreed let's update the product doc please.

trinya on (2024-10-22 11:37:06 UTC): Thanks, yes, let's not do the backend.
Minimal set we talked to with Nemanja about is hardcoded on FE:
- banner appears 14d before trial ends
- X dismisses the banner
- banner appears 3d before trial ends, 2d before trial ends, 1d before trial ends (this is just conditional on the days until the end of trial, does not check if the banner was dismissed or not)

imrkd on (2024-10-22 13:28:36 UTC): This is more or less doable, BUT 
* why are we making this dissmisable again? why can't we just leave it there always till they put in the card? 
* and now thinking about it, what should we do when they do input the card? figure out a way to hide the banner via some signal, _or_ should we make adding the CC effectively end the trial and be a ""Buy Now"" moment?

trinya on (2024-10-22 13:49:20 UTC): Because we want to keep it for all trialers, even those that have a card. They don't need this banner whatsoever. If we make it conditional on having the card, that can work.


That was supposed to be ""Buy Now"" moment, yes. If this is too hard to do, then we need something else - either a way to dismiss it, or hide the banner if the payment details are in place.

imrkd on (2024-10-22 14:27:40 UTC): ok, so dismiss-able 👍 
conditional on having a card is going to be fairly tedious. 
@kidd note re ""Buy Now"" ☝

kidd on (2024-10-22 14:37:54 UTC): Added an issue in milestone 3:

https://github.com/metabase/harbormaster/issues/5409?issue=metabase%7Charbormaster%7C5434

idk which milestone it belongs to, but I wanted to write it somewhere. Feel free to move it

imrkd on (2024-10-22 16:29:51 UTC): milestone3 makes sense and thank you 🙏

trinya on (2024-10-28 16:26:13 UTC): [Figma with the updated design](https://www.figma.com/design/OGkkIYPpfcEfd7EjnmL6SJ/No-CC-required-for-Cloud-trial?node-id=657-1054&t=8zdpNzGRg0uz7WJ0-4)

![Image](https://github.com/user-attachments/assets/50e9413a-36ee-44a8-b616-93bef6a28768)

nemanjaglumac (Assginee) on (2024-11-26 08:13:15 UTC): We're still not able to use this color in the main app. I have to use deep yellow (`warning`) color instead.
See: https://github.com/metabase/metabase/pull/49344#discussion_r1857294644

![Image](https://github.com/user-attachments/assets/13b808ae-84ec-46fd-ace3-8fd565eb729f)

github-actions[bot] on (2024-12-04 20:44:44 UTC): 🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)

"
2575886166,issue,closed,completed,Cannot read properties of undefined (reading 'includes') when doing an x-ray on the orders table,"### Describe the bug

Some error that pops up on the FE on one card when doing an x-ray on the orders table

### To Reproduce

1) start metabase 51 beta
2) do an x-ray on the orders table (I used the postgres sample DB)
3) see the map on the bottom of the page that has an error
![Image](https://github.com/user-attachments/assets/bbf783bf-343c-4f01-86fc-8b8600572b77)

The card works fine if you click on the title
![Image](https://github.com/user-attachments/assets/02a7217b-5ad2-435c-ac2d-45962ee8aeff)

### Expected behavior

It should render

### Logs

![Image](https://github.com/user-attachments/assets/5cdb4395-4631-4d3f-8870-ed75c0edfa4c)


### Information about your Metabase installation

v51-beta

### Severity

P2

### Additional context

NA",paoliniluis,2024-10-09 13:05:45+00:00,['kulyk'],2024-10-15 19:10:15+00:00,2024-10-15 18:26:49+00:00,https://github.com/metabase/metabase/issues/48519,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2402306726, 'issue_id': 2575886166, 'author': 'dpsutton', 'body': '@paoliniluis is this different from v0.50.28?', 'created_at': datetime.datetime(2024, 10, 9, 13, 10, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402317031, 'issue_id': 2575886166, 'author': 'kamilmielnik', 'body': 'It works in 0.50.28', 'created_at': datetime.datetime(2024, 10, 9, 13, 13, 18, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-09 13:10:45 UTC): @paoliniluis is this different from v0.50.28?

kamilmielnik on (2024-10-09 13:13:18 UTC): It works in 0.50.28

"
2575491285,issue,open,,Hide some columns of a visualization conditionally for certain groups of users,"**Is your feature request related to a problem? Please describe.**
From customer:
> About our use case: We have internal users and external users accessing the platform where they can see a dashboard showing KPIs of advertising campaigns. In this dashboard, all the cards are common, except one which is internal facing only. We could duplicate, but we also take care about the cost of maintaining these dashboards + we have a preference to ""eat our own dog food"", meaning the more we use the same dashboards as our external users, the better we will adjust it.

**Describe the solution you'd like**
Allow the option to conditionally hide columns from visualizations based on group membership and / or user attributes. This could be an entirely new feature or something which would work in combination with data sandboxing. 

The idea is to ensure certain data or visual elements are only visible to specific users without duplicating cards or dashboards.

**Describe alternatives you've considered**
Advanced sandboxing allows restricting specific columns by returning nulls for certain users. However, this does not address the requirement of completely hiding the columns from the visualization.

**How important is this feature to you?**
It is fairly important, as it would help reduce the complexity and cost of maintaining multiple sets of questions and dashboards.",zbodi74,2024-10-09 10:27:12+00:00,[],2025-02-04 20:30:55+00:00,,https://github.com/metabase/metabase/issues/48515,"[('Visualization/', ''), ('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2575131600,issue,open,,Migrate SDK build to rspack,"The main app migrated to rspack some time ago and static viz will probably follow too.
That would make the sdk the only remaining part of the codebase using webpack.

Migrating to rspack would have two main benefits:
- some performance benefit on building the sdk
- being able to remove one tool, right our code needs to work on both build systems

As we should already be using swc, this shouldn't be too hard",npretto,2024-10-09 08:00:48+00:00,[],2025-02-04 20:29:48+00:00,,https://github.com/metabase/metabase/issues/48512,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2575069255,issue,open,,Possibility to set spacing between bars in bar charts,"Hello,

I open a feature request as asked here: https://discourse.metabase.com/t/bar-chart-customization-bar-width-and-spacing/158757

it would be nice to be able to customize the bar width and the spacing between bars in bar charts like in the example below (actual, proposed):

![Image](https://github.com/user-attachments/assets/60c134f0-8471-4670-ad3c-60f6b6a49ff8)

![Image](https://github.com/user-attachments/assets/8ec2e72f-37ae-4f85-98dc-5b1135deb48f)

",dri-mobisec,2024-10-09 07:39:09+00:00,[],2025-02-04 20:31:27+00:00,,https://github.com/metabase/metabase/issues/48511,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2574440506,issue,closed,completed,JSONB column is incorrectly converted to the bigint type,"**Describe the bug**
When using Metabase, the value stored inside a JSONB column is incorrectly converted to the bigint type. The column ""dados_2021 ->> 'capital_social'"" contains monetary values and is correctly configured with the ""Currency"" type in the Metadata configurator. However, when creating a question that unfolds this JSONB column, the monetary values are treated as bigint instead of remaining as decimal or currency values.

**Logs**
[5c923c01-bf9d-43a6-8d2f-0a0386a6819e] 2024-10-08T20:31:24-03:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: ERROR: invalid input syntax for type bigint: ""533242.11""
{:database_id 3,
 :started_at #t ""2024-10-08T23:31:24.166737Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Erro ao executar consulta: ERROR: invalid input syntax for type bigint: \""533242.11\"""",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__82518$fn__82519.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__108335.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__108335.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:60)""
    ""query_processor.execute$run.invoke(execute.clj:54)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71610.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__71625.invoke(execute.clj:23)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71630.invoke(execute.clj:34)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71583.invoke(cache.clj:239)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66212.invoke(permissions.clj:147)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66824.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66834.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__71657.invoke(execute.clj:92)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
    ""query_processor.execute$execute.invoke(execute.clj:87)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""query_processor.middleware.enterprise$fn__66851$handle_audit_app_internal_queries__66852$fn__66854.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66862.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76857.invoke(process_userland_query.clj:198)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76926.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76963.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__67266.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings$fn__67261.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__67256$fn__67257.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:105)""
    ""driver$do_with_driver.invoke(driver.clj:100)""
    ""query_processor.setup$do_with_driver$fn__67256.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__67249$fn__67252.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider$fn__67249.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__67243.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""api.dataset$run_streaming_query$fn__94182.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__70166$fn__70167$fn__70168.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__70166$fn__70167.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__70166.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__52036.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: MBQL queryHash: 6ab7f5c7da546f352cf17b4dadae8cb7e9610090f4ee54078254eccf9a7f6c02""
     ""SELECT""
     ""  \""dados\"".\""mv_empresas\"".\""cnpj_basico\"" AS \""cnpj_basico\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: bigint AS \""dados_2021 → capital_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → data_exclusao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → data_exclusao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → data_extract\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → data_opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → data_opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → ente_federativo\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → natureza_juridica\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → porte\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → qualificacao_responsavel\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2021\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2021 → razao_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: bigint AS \""dados_2022 → capital_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → data_exclusao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → data_exclusao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → data_extract\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → data_opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → data_opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → ente_federativo\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → natureza_juridica\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → porte\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → qualificacao_responsavel\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2022\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2022 → razao_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: bigint AS \""dados_2023 → capital_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → data_exclusao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → data_exclusao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → data_extract\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → data_opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → data_opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → ente_federativo\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → natureza_juridica\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → porte\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → qualificacao_responsavel\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2023\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2023 → razao_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: bigint AS \""dados_2024 → capital_social\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → data_exclusao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → data_exclusao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → data_extract\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → data_opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → data_opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → ente_federativo\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → natureza_juridica\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → opcao_mei\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → opcao_simples\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → porte\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → qualificacao_responsavel\"",""
     ""  (""
     ""    \""dados\"".\""mv_empresas\"".\""dados_2024\"" #>> array [ ? ] :: text [ ]""
     ""  ) :: text AS \""dados_2024 → razao_social\"",""
     ""  \""dados\"".\""mv_empresas\"".\""dados_2021\"" AS \""dados_2021\"",""
     ""  \""dados\"".\""mv_empresas\"".\""dados_2022\"" AS \""dados_2022\"",""
     ""  \""dados\"".\""mv_empresas\"".\""dados_2023\"" AS \""dados_2023\"",""
     ""  \""dados\"".\""mv_empresas\"".\""dados_2024\"" AS \""dados_2024\""""
     ""FROM""
     ""  \""dados\"".\""mv_empresas\""""
     ""LIMIT""
     ""  2000""],
    :params
    (""capital_social""
     ""data_exclusao_mei""
     ""data_exclusao_simples""
     ""data_extract""
     ""data_opcao_mei""
     ""data_opcao_simples""
     ""ente_federativo""
     ""natureza_juridica""
     ""opcao_mei""
     ""opcao_simples""
     ""porte""
     ""qualificacao_responsavel""
     ""razao_social""
     ""capital_social""
     ""data_exclusao_mei""
     ""data_exclusao_simples""
     ""data_extract""
     ""data_opcao_mei""
     ""data_opcao_simples""
     ""ente_federativo""
     ""natureza_juridica""
     ""opcao_mei""
     ""opcao_simples""
     ""porte""
     ""qualificacao_responsavel""
     ""razao_social""
     ""capital_social""
     ""data_exclusao_mei""
     ""data_exclusao_simples""
     ""data_extract""
     ""data_opcao_mei""
     ""data_opcao_simples""
     ""ente_federativo""
     ""natureza_juridica""
     ""opcao_mei""
     ""opcao_simples""
     ""porte""
     ""qualificacao_responsavel""
     ""razao_social""
     ""capital_social""
     ""data_exclusao_mei""
     ""data_exclusao_simples""
     ""data_extract""
     ""data_opcao_mei""
     ""data_opcao_simples""
     ""ente_federativo""
     ""natureza_juridica""
     ""opcao_mei""
     ""opcao_simples""
     ""porte""
     ""qualificacao_responsavel""
     ""razao_social""),
    :type :invalid-query}}],
 :action_id nil,
 :state ""22P02"",
 :error_type :invalid-query,
 :json_query
 {:database 3,
  :type ""query"",
  :query {:source-table 1161},
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""dados\"".\""mv_empresas\"".\""cnpj_basico\"" AS \""cnpj_basico\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::bigint AS \""dados_2021 → capital_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → data_exclusao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → data_exclusao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → data_extract\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → data_opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → data_opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → ente_federativo\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → natureza_juridica\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → porte\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → qualificacao_responsavel\"", (\""dados\"".\""mv_empresas\"".\""dados_2021\""#>> array[?]::text[])::text AS \""dados_2021 → razao_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::bigint AS \""dados_2022 → capital_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → data_exclusao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → data_exclusao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → data_extract\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → data_opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → data_opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → ente_federativo\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → natureza_juridica\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → porte\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → qualificacao_responsavel\"", (\""dados\"".\""mv_empresas\"".\""dados_2022\""#>> array[?]::text[])::text AS \""dados_2022 → razao_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::bigint AS \""dados_2023 → capital_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → data_exclusao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → data_exclusao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → data_extract\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → data_opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → data_opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → ente_federativo\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → natureza_juridica\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → porte\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → qualificacao_responsavel\"", (\""dados\"".\""mv_empresas\"".\""dados_2023\""#>> array[?]::text[])::text AS \""dados_2023 → razao_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::bigint AS \""dados_2024 → capital_social\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → data_exclusao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → data_exclusao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → data_extract\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → data_opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → data_opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → ente_federativo\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → natureza_juridica\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → opcao_mei\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → opcao_simples\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → porte\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → qualificacao_responsavel\"", (\""dados\"".\""mv_empresas\"".\""dados_2024\""#>> array[?]::text[])::text AS \""dados_2024 → razao_social\"", \""dados\"".\""mv_empresas\"".\""dados_2021\"" AS \""dados_2021\"", \""dados\"".\""mv_empresas\"".\""dados_2022\"" AS \""dados_2022\"", \""dados\"".\""mv_empresas\"".\""dados_2023\"" AS \""dados_2023\"", \""dados\"".\""mv_empresas\"".\""dados_2024\"" AS \""dados_2024\"" FROM \""dados\"".\""mv_empresas\"" LIMIT 2000"",
  :params
  (""capital_social""
   ""data_exclusao_mei""
   ""data_exclusao_simples""
   ""data_extract""
   ""data_opcao_mei""
   ""data_opcao_simples""
   ""ente_federativo""
   ""natureza_juridica""
   ""opcao_mei""
   ""opcao_simples""
   ""porte""
   ""qualificacao_responsavel""
   ""razao_social""
   ""capital_social""
   ""data_exclusao_mei""
   ""data_exclusao_simples""
   ""data_extract""
   ""data_opcao_mei""
   ""data_opcao_simples""
   ""ente_federativo""
   ""natureza_juridica""
   ""opcao_mei""
   ""opcao_simples""
   ""porte""
   ""qualificacao_responsavel""
   ""razao_social""
   ""capital_social""
   ""data_exclusao_mei""
   ""data_exclusao_simples""
   ""data_extract""
   ""data_opcao_mei""
   ""data_opcao_simples""
   ""ente_federativo""
   ""natureza_juridica""
   ""opcao_mei""
   ""opcao_simples""
   ""porte""
   ""qualificacao_responsavel""
   ""razao_social""
   ""capital_social""
   ""data_exclusao_mei""
   ""data_exclusao_simples""
   ""data_extract""
   ""data_opcao_mei""
   ""data_opcao_simples""
   ""ente_federativo""
   ""natureza_juridica""
   ""opcao_mei""
   ""opcao_simples""
   ""porte""
   ""qualificacao_responsavel""
   ""razao_social"")},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194)""
  ""org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:137)""
  ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)""
  ""--> driver.sql_jdbc.execute$fn__82446.invokeStatic(execute.clj:566)""
  ""driver.sql_jdbc.execute$fn__82446.invoke(execute.clj:564)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:579)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518$fn__82519.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82518.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__82322$fn__82323.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__82322.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__82322.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__108335.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__108335.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
  ""query_processor.execute$run.invoke(execute.clj:54)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71610.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71625.invoke(execute.clj:23)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71630.invoke(execute.clj:34)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71583.invoke(cache.clj:239)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66212.invoke(permissions.clj:147)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66824.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66834.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__71657.invoke(execute.clj:92)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
  ""query_processor.execute$execute.invoke(execute.clj:87)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""query_processor.middleware.enterprise$fn__66851$handle_audit_app_internal_queries__66852$fn__66854.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66862.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76857.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76926.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76963.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67266.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67261.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67256$fn__67257.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:105)""
  ""driver$do_with_driver.invoke(driver.clj:100)""
  ""query_processor.setup$do_with_driver$fn__67256.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67249$fn__67252.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67249.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67243.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__94182.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__70166$fn__70167$fn__70168.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70166$fn__70167.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70166.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52036.invoke(streaming_response.clj:97)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""ERROR: invalid input syntax for type bigint: \""533242.11\"""",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 3,
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
  :info {:executed-by 1, :context :ad-hoc},
  :constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :query
  {:source-table 1161,
   :fields
   [[:field 40318 nil]
    [:field 41066 nil]
    [:field 41047 nil]
    [:field 41088 nil]
    [:field 41036 nil]
    [:field 41073 nil]
    [:field 41090 nil]
    [:field 41085 nil]
    [:field 41063 nil]
    [:field 41068 nil]
    [:field 41062 nil]
    [:field 41064 nil]
    [:field 41081 nil]
    [:field 41048 nil]
    [:field 41070 nil]
    [:field 41060 nil]
    [:field 41043 nil]
    [:field 41041 nil]
    [:field 41058 nil]
    [:field 41059 nil]
    [:field 41050 nil]
    [:field 41061 nil]
    [:field 41069 nil]
    [:field 41080 nil]
    [:field 41072 nil]
    [:field 41042 nil]
    [:field 41077 nil]
    [:field 41067 nil]
    [:field 41045 nil]
    [:field 41044 nil]
    [:field 41038 nil]
    [:field 41071 nil]
    [:field 41084 nil]
    [:field 41076 nil]
    [:field 41087 nil]
    [:field 41040 nil]
    [:field 41083 nil]
    [:field 41053 nil]
    [:field 41056 nil]
    [:field 41055 nil]
    [:field 41082 nil]
    [:field 41078 nil]
    [:field 41039 nil]
    [:field 41074 nil]
    [:field 41049 nil]
    [:field 41052 nil]
    [:field 41051 nil]
    [:field 41046 nil]
    [:field 41035 nil]
    [:field 41065 nil]
    [:field 41079 nil]
    [:field 41057 nil]
    [:field 41089 nil]
    [:field 41075 nil]
    [:field 41054 nil]
    [:field 41037 nil]
    [:field 41086 nil]],
   :limit 2000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :data {:rows [], :cols []}}

**To Reproduce**
Steps to reproduce the behavior:
1. Create a new Question in Metabase using data from a table that contains a JSONB column with monetary values stored inside, such as ""dados_2021 ->> 'capital_social'.""
2. Metabase will generate a SQL query that explicitly casts the monetary data from the JSONB column to bigint.
3. Execute the query
4. See  the following error: ""ERROR: invalid input syntax for type bigint: ""90000023475.34""

**Expected behavior**
The monetary values inside the JSONB column should not be explicitly cast to bigint. Instead, they should retain their original format as decimal or currency values, as defined in the Metadata settings. This would prevent errors and allow for correct handling of monetary data in queries.

**Screenshots**
![Image](https://github.com/user-attachments/assets/c9062965-48b4-483f-a769-b6088f17cd6f)

![Image](https://github.com/user-attachments/assets/8276399b-d4f4-4ecb-811f-191b818ea876)

![Image](https://github.com/user-attachments/assets/7b360d58-5e0d-404a-aa6e-9483130d31ed)


**Severity**
This issue is preventing the use of the Question creation tool in Metabase. The incorrect conversion of monetary values to bigint leads to errors during query execution, making it impossible to create and use new Questions based on JSONB columns with monetary data.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-10-02"",
      ""tag"": ""v0.50.28"",
      ""hash"": ""3179ef2""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Ubuntu 16.4-0ubuntu0.24.04.2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-45-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",fmercurio,2024-10-08 23:56:48+00:00,['snoe'],2024-10-17 16:55:34+00:00,2024-10-17 15:34:06+00:00,https://github.com/metabase/metabase/issues/48507,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.')]","[{'comment_id': 2401662264, 'issue_id': 2574440506, 'author': 'paoliniluis', 'body': ""tagging as P1 as it's a complete blocker"", 'created_at': datetime.datetime(2024, 10, 9, 8, 20, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407418388, 'issue_id': 2574440506, 'author': 'luizarakaki', 'body': ""@fmercurio can you check if there are decimal values in this key in the first rows of your table? Metabase doesn't inspect all values to define the data type. If all first 500 values are integers and decimals only come later, it will be wrongly assigned as bigint.\nIn this case, you'd need to add a decimal value in the first rows"", 'created_at': datetime.datetime(2024, 10, 11, 13, 28, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412198574, 'issue_id': 2574440506, 'author': 'fmercurio', 'body': ""> [@fmercurio](https://github.com/fmercurio) can you check if there are decimal values in this key in the first rows of your table? Metabase doesn't inspect all values to define the data type. If all first 500 values are integers and decimals only come later, it will be wrongly assigned as bigint. In this case, you'd need to add a decimal value in the first rows\n\nThere is few decimal numbers in this database. And I can't manipulate data because the dataset is a materialized view."", 'created_at': datetime.datetime(2024, 10, 14, 20, 30, 6, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-09 08:20:53 UTC): tagging as P1 as it's a complete blocker

luizarakaki on (2024-10-11 13:28:46 UTC): @fmercurio can you check if there are decimal values in this key in the first rows of your table? Metabase doesn't inspect all values to define the data type. If all first 500 values are integers and decimals only come later, it will be wrongly assigned as bigint.
In this case, you'd need to add a decimal value in the first rows

fmercurio (Issue Creator) on (2024-10-14 20:30:06 UTC): There is few decimal numbers in this database. And I can't manipulate data because the dataset is a materialized view.

"
2574201333,issue,open,,Update react-router to fix legacy context detected in their Link component," - Error: Legacy context API has been detected within a strict-mode tree. 
  - Where: Link in react-router-dom
  - This requires updating the react-router package, as the Link component is from react-router@3.",heypoom,2024-10-08 20:58:58+00:00,[],2024-11-05 08:25:18+00:00,,https://github.com/metabase/metabase/issues/48500,[],"[{'comment_id': 2456525516, 'issue_id': 2574201333, 'author': 'kamilmielnik', 'body': 'Upgrading react-router would also fix #33832', 'created_at': datetime.datetime(2024, 11, 5, 8, 25, 17, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-11-05 08:25:17 UTC): Upgrading react-router would also fix #33832

"
2574195567,issue,closed,completed,Fix minWidth larger than item width/maxWidth console error in React Grid Layout,"This error shows up when you render an InteractiveDashboard or EditableDashboard, and the console error only happens on development environment.
 
- Error message: ""Failed prop type: minWidth larger than item width/maxWidth""
  - Where: ReactGridLayout2 > GridItem2

P.S. This is not limited to the Embedding SDK, also happens in the main Metabase app. It is just particularly annoying for customers of the Embedding SDK to see React console errors.",heypoom,2024-10-08 20:56:09+00:00,['heypoom'],2025-02-06 11:21:18+00:00,2025-02-03 17:18:43+00:00,https://github.com/metabase/metabase/issues/48499,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Team/Embedding', '')]","[{'comment_id': 2639546281, 'issue_id': 2574195567, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 2, 6, 11, 21, 17, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-06 11:21:17 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2574192964,issue,closed,completed,Fix deprecated findDOMNode React console errors in ExplicitSize,"- Error: `findDOMNode is deprecated and will be removed in the next major release. Instead, add a ref directly to the element you want to reference.`
  - Where: ExplicitSize
  - Usage instances: `ExplicitSize[Connect(DashboardGrid)], ExplicitSize[Connect(Visualization)], ExplicitSize[RowChartRendererInner]`

### Screenshots

This React errors appears on production builds of the embedding sdk, in both Vite and create-react-app.

![Image](https://github.com/user-attachments/assets/03e22674-5434-4144-8dd2-28197b200da1)
",heypoom,2024-10-08 20:54:42+00:00,['oisincoveney'],2025-01-31 14:03:14+00:00,2025-01-31 14:03:13+00:00,https://github.com/metabase/metabase/issues/48498,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2459652677, 'issue_id': 2574192964, 'author': 'albertoperdomo', 'body': 'Is this still relevant @heypoom ?', 'created_at': datetime.datetime(2024, 11, 6, 12, 41, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627430294, 'issue_id': 2574192964, 'author': 'NevRA', 'body': 'Fixed by https://github.com/metabase/metabase/pull/52253#top. @oisincoveney fyi', 'created_at': datetime.datetime(2025, 1, 31, 14, 3, 13, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-11-06 12:41:23 UTC): Is this still relevant @heypoom ?

NevRA on (2025-01-31 14:03:13 UTC): Fixed by https://github.com/metabase/metabase/pull/52253#top. @oisincoveney fyi

"
2574187430,issue,closed,completed,Fix obvious unsafe React lifecycle console errors visible in SDK,"- Error: `Using UNSAFE_componentWillReceiveProps in strict mode is not recommended and may indicate bugs in your code`
  - DashboardGrid - https://github.com/metabase/metabase/pull/53213
  - Visualization - https://github.com/metabase/metabase/pull/52885
  - Link - this is from `react-router@v3` and requires a version bump. We can't fix this without upgrading.

- Error: `Using UNSAFE_componentWillMount in strict mode is not recommended and may indicate bugs in your code.`
  - Visualization - https://github.com/metabase/metabase/pull/52885",heypoom,2024-10-08 20:51:30+00:00,['heypoom'],2025-02-06 13:41:32+00:00,2025-02-05 15:25:11+00:00,https://github.com/metabase/metabase/issues/48497,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2639864142, 'issue_id': 2574187430, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 2, 6, 13, 41, 30, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-06 13:41:30 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2574185137,issue,closed,completed,Fix defaultProps React console errors in Modal and ReactMarkdown,"Error: `Support for defaultProps will be removed from function components in a future major release. Use JavaScript default parameters instead.`

Where:
- Modal (used by DashboardGrid)
- ReactMarkdown",heypoom,2024-10-08 20:50:25+00:00,['heypoom'],2024-10-21 09:59:38+00:00,2024-10-17 23:26:04+00:00,https://github.com/metabase/metabase/issues/48496,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2574184700,issue,open,,Fix defaultProps React console errors in Modal and ReactMarkdown,,heypoom,2024-10-08 20:50:13+00:00,[],2024-10-08 20:50:13+00:00,,https://github.com/metabase/metabase/issues/48495,[],[],
2573911007,issue,closed,not_planned,"In Native Mongo Queries, JSON Parser adds extra quotes around variables when variable is inside quotes, breaking queries with dynamic fields","### Describe the bug

When using a mongo native query with a variable ({{coin}}) in JSON syntax (for example: ""balance.{{coin}}""), the Metabase JSON parser incorrectly adds extra double quotes around the variable name, breaking the JSON structure. This results in errors like ""balance.""USD"""" instead of the expected ""balance.USD"".

### To Reproduce

1. Create a query in Metabase using a variable, such as:
```
(...)
{
  ""balance.{{coin}}"": {
    ""$ne"": null
  }
}
(...)
```
2. Assign a variable to {{coin}} (e.g., USD)
3. Run the query.
4. Observe how Metabase generates the query with extra double quotes, resulting in an error.


### Expected behavior

Metabase should substitute the {{coin}} variable into the JSON query without adding extra quotes, generating the correct JSON structure (e.g., ""balance.USD"").

### Logs

Relevant output:

```
 ...    {\r\n          \""balance.\""USD\""\"": {\r\n        ...
```

### Information about your Metabase installation
      ""tag"": ""v0.50.24"",

### Severity

blocks usage

### Additional context

_No response_",cubargh,2024-10-08 18:30:00+00:00,['appleby'],2024-10-21 14:30:01+00:00,2024-10-21 14:29:59+00:00,https://github.com/metabase/metabase/issues/48484,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('.Backend', ''), ('.Team/Querying', ''), ('Querying/Native/Parser', '')]","[{'comment_id': 2426854542, 'issue_id': 2573911007, 'author': 'appleby', 'body': 'Enclosing a variable in quotes is not supported, and not something we plan to do at this time.\n\nAlternatively, if you can get the full nested field into a variable, you can use something like\n\n```\n{{field}}: {""$ne"": null}\n```\n\nInternal slack discussion: https://metaboat.slack.com/archives/C0645JP1W81/p1729202416761989', 'created_at': datetime.datetime(2024, 10, 21, 14, 29, 59, tzinfo=datetime.timezone.utc)}]","appleby (Assginee) on (2024-10-21 14:29:59 UTC): Enclosing a variable in quotes is not supported, and not something we plan to do at this time.

Alternatively, if you can get the full nested field into a variable, you can use something like

```
{{field}}: {""$ne"": null}
```

Internal slack discussion: https://metaboat.slack.com/archives/C0645JP1W81/p1729202416761989

"
2573822948,issue,closed,completed,[Epic] EntityPicker improvements,[Design improvements to the EntityPicker](https://www.notion.so/metabase/Design-improvements-to-the-EntityPicker-10d69354c9018020b235cf84928df3ba),luizarakaki,2024-10-08 17:42:33+00:00,[],2024-12-02 20:52:17+00:00,2024-12-02 20:52:15+00:00,https://github.com/metabase/metabase/issues/48479,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Entity picker', '')]","[{'comment_id': 2512803216, 'issue_id': 2573822948, 'author': 'dpsutton', 'body': 'closing in favor of https://github.com/metabase/metabase/issues/50526', 'created_at': datetime.datetime(2024, 12, 2, 20, 52, 15, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-12-02 20:52:15 UTC): closing in favor of https://github.com/metabase/metabase/issues/50526

"
2573751141,issue,open,,Goal line tooltip formatting does not match ticks formatting,"[Slack convo](https://metaboat.slack.com/archives/C064QMXEV9N/p1728396408722079)

![Image](https://github.com/user-attachments/assets/07a2447f-2347-4f77-af8b-5ef640882c6e)

- Goal line value is not formatted as ticks
- Goal line value should not use [auto compating formatting](https://metaboat.slack.com/archives/C064QMXEV9N/p1728396408722079)

",alxnddr,2024-10-08 17:02:13+00:00,[],2025-02-04 20:31:15+00:00,,https://github.com/metabase/metabase/issues/48473,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2573727172,issue,open,,Reset App Database via API Call for Efficient End-to-End Testing,"**Is your feature request related to a problem? Please describe.**
The need is for a way to quickly reset the Metabase Application database to a known state before each test. 

**Describe the solution you'd like**
The ability to reset the database through an API. Right now we have a ""Revision History"" for Dashboards in which you can simply click and the Dashboard will revert to a previous state. 

![Image](https://github.com/user-attachments/assets/78adc021-1a59-48ab-ad18-25e06366660d)

The idea would be to have a similar endpoint but to a previous instance state. So that the whole instance gets reverted to a known state before the test.

**Describe alternatives you've considered**

You can do things manually or use the container/DB commands themself, example:

1. You could do some bespoke scripting with pg_dump and pg_restore ... So theoretically you can also do
`CREATE DATABASE [dbname] TEMPLATE [template db name];` so you could set your ""snapshot"" database up, then before each test do `CREATE DATABASE my_temp_db TEMPLATE my_snapshot;` and set up the app db to use the new db. 
 
2. Another suggestion is you can save a Postgres container in a certain state, so you can configure Metabase and then save the container in that exact moment, and then use that container every single time so you start over, but on the initial state.
",Tony-metabase,2024-10-08 16:50:46+00:00,[],2025-02-04 20:30:29+00:00,,https://github.com/metabase/metabase/issues/48471,"[('Type:New Feature', ''), ('Operation/', '')]","[{'comment_id': 2403548976, 'issue_id': 2573727172, 'author': 'david-ape', 'body': 'This would be extremely useful for us. In order to embed Metabase dashboards in our Ruby on Rails app with appropriate user access control, we have tightly coupled integration, including managing collections, dashboards, questions, groups, and permissions. We have many automated tests and the setup/teardown process is painful (either time consuming or a lot of work or both), particularly when we have to update the tests because of a Metabase upgrade.', 'created_at': datetime.datetime(2024, 10, 9, 22, 41, 19, tzinfo=datetime.timezone.utc)}]","david-ape on (2024-10-09 22:41:19 UTC): This would be extremely useful for us. In order to embed Metabase dashboards in our Ruby on Rails app with appropriate user access control, we have tightly coupled integration, including managing collections, dashboards, questions, groups, and permissions. We have many automated tests and the setup/teardown process is painful (either time consuming or a lot of work or both), particularly when we have to update the tests because of a Metabase upgrade.

"
2573709432,issue,closed,completed,[Testing plan] Native query drill,"### Dimensions

#### Drills
- [x] Drill type
- [x] Click type - column header, cell, pivot cell, legend item
- [x] Saved/unsaved question, going from unsaved -> saved
- [x] Location - QB, dashboards

#### Brush filters
- [x] Brush type - temporal, numeric, location
- [x] Saved/unsaved question
- [x] Map type",ranquild,2024-10-08 16:43:08+00:00,['ranquild'],2024-10-12 13:09:15+00:00,2024-10-12 13:09:15+00:00,https://github.com/metabase/metabase/issues/48469,[],[],
2573694820,issue,closed,completed,[Epic] Native query drill,"```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/48232
- [ ] https://github.com/metabase/metabase/pull/48459
- [ ] https://github.com/metabase/metabase/pull/48463
- [ ] https://github.com/metabase/metabase/pull/48482
- [ ] https://github.com/metabase/metabase/issues/48469
```",ranquild,2024-10-08 16:34:46+00:00,['ranquild'],2024-10-12 13:09:23+00:00,2024-10-12 13:09:23+00:00,https://github.com/metabase/metabase/issues/48466,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2573544926,issue,closed,completed,Deleting a model will corrupt all dashboards where cards based on the model are,"### Describe the bug

if you delete a model from where cards are based upon, we'll send a ""SELECT * FROM ""metabase_database"" WHERE ""id"" IN ()"" to the app db, that makes the query metadata endpoint to fail

### To Reproduce

1) create a model
2) create a question based on this model
3) create a dashboard and add the question
4) delete the model

see the dashboard corrupting

### Expected behavior

_No response_


<details>
<summary> logs:</summary>
### Logs

```
{
    ""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": ""ERROR: syntax error at or near \"")\""\n  Position: 50"",
            ""data"": {
                ""toucan2/context-trace"": [
                    [
                        ""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"",
                        {
                            ""toucan2.jdbc.query/sql-args"": [
                                ""SELECT * FROM \""metabase_database\"" WHERE \""id\"" IN ()""
                            ]
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": ""class metabase.db.connection.ApplicationDB""
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": ""default""
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": null
                        }
                    ],
                    {
                        ""toucan2.pipeline/rf"": ""clojure.core$map$fn__5931$fn__5932@18572694""
                    },
                    [
                        ""with compiled query"",
                        {
                            ""toucan2.pipeline/compiled-query"": [
                                ""SELECT * FROM \""metabase_database\"" WHERE \""id\"" IN ()""
                            ]
                        }
                    ],
                    [
                        ""with built query"",
                        {
                            ""toucan2.pipeline/built-query"": {
                                ""select"": [
                                    ""*""
                                ],
                                ""from"": [
                                    [
                                        ""metabase_database""
                                    ]
                                ],
                                ""where"": [
                                    ""in"",
                                    ""id"",
                                    []
                                ]
                            }
                        }
                    ],
                    [
                        ""with resolved query"",
                        {
                            ""toucan2.pipeline/resolved-query"": {}
                        }
                    ],
                    [
                        ""with parsed args"",
                        {
                            ""toucan2.pipeline/query-type"": ""toucan.query-type/select.instances"",
                            ""toucan2.pipeline/parsed-args"": {
                                ""kv-args"": {
                                    ""id"": [
                                        ""in"",
                                        []
                                    ]
                                },
                                ""queryable"": {}
                            }
                        }
                    ],
                    [
                        ""with model"",
                        {
                            ""toucan2.pipeline/model"": ""model/Database""
                        }
                    ],
                    [
                        ""with unparsed args"",
                        {
                            ""toucan2.pipeline/query-type"": ""toucan.query-type/select.instances"",
                            ""toucan2.pipeline/unparsed-args"": [
                                ""model/Database"",
                                ""id"",
                                [
                                    ""in"",
                                    []
                                ]
                            ]
                        }
                    ]
                ]
            },
            ""at"": [
                ""org.postgresql.core.v3.QueryExecutorImpl"",
                ""receiveErrorResponse"",
                ""QueryExecutorImpl.java"",
                2725
            ]
        },
        {
            ""type"": ""org.postgresql.util.PSQLException"",
            ""message"": ""ERROR: syntax error at or near \"")\""\n  Position: 50"",
            ""at"": [
                ""org.postgresql.core.v3.QueryExecutorImpl"",
                ""receiveErrorResponse"",
                ""QueryExecutorImpl.java"",
                2725
            ]
        }
    ],
    ""trace"": [
        [
            ""org.postgresql.core.v3.QueryExecutorImpl"",
            ""receiveErrorResponse"",
            ""QueryExecutorImpl.java"",
            2725
        ],
        [
            ""org.postgresql.core.v3.QueryExecutorImpl"",
            ""processResults"",
            ""QueryExecutorImpl.java"",
            2412
        ],
        [
            ""org.postgresql.core.v3.QueryExecutorImpl"",
            ""execute"",
            ""QueryExecutorImpl.java"",
            371
        ],
        [
            ""org.postgresql.jdbc.PgStatement"",
            ""executeInternal"",
            ""PgStatement.java"",
            502
        ],
        [
            ""org.postgresql.jdbc.PgStatement"",
            ""execute"",
            ""PgStatement.java"",
            419
        ],
        [
            ""org.postgresql.jdbc.PgPreparedStatement"",
            ""executeWithFlags"",
            ""PgPreparedStatement.java"",
            194
        ],
        [
            ""org.postgresql.jdbc.PgPreparedStatement"",
            ""execute"",
            ""PgPreparedStatement.java"",
            180
        ],
        [
            ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement"",
            ""execute"",
            ""NewProxyPreparedStatement.java"",
            67
        ],
        [
            ""toucan2.jdbc.query$reduce_jdbc_query"",
            ""invokeStatic"",
            ""query.clj"",
            40
        ],
        [
            ""toucan2.jdbc.query$reduce_jdbc_query"",
            ""invoke"",
            ""query.clj"",
            22
        ],
        [
            ""toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default"",
            ""invokeStatic"",
            ""pipeline.clj"",
            19
        ],
        [
            ""toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default"",
            ""invoke"",
            ""pipeline.clj"",
            9
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            15
        ],
        [
            ""methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497"",
            ""invoke"",
            ""threaded.clj"",
            64
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invokeStatic"",
            ""standard.clj"",
            65
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invoke"",
            ""standard.clj"",
            47
        ],
        [
            ""methodical.impl.standard.StandardMultiFn"",
            ""invoke"",
            ""standard.clj"",
            216
        ],
        [
            ""toucan2.pipeline$transduce_execute$with_connection_STAR___21604"",
            ""invoke"",
            ""pipeline.clj"",
            78
        ],
        [
            ""toucan2.connection$bind_current_connectable_fn$fn__21281"",
            ""invoke"",
            ""connection.clj"",
            104
        ],
        [
            ""toucan2.connection$bind_current_connectable_fn$fn__21281"",
            ""invoke"",
            ""connection.clj"",
            104
        ],
        [
            ""toucan2.connection$bind_current_connectable_fn$fn__21281"",
            ""invoke"",
            ""connection.clj"",
            104
        ],
        [
            ""toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource"",
            ""invokeStatic"",
            ""connection.clj"",
            18
        ],
        [
            ""toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource"",
            ""invoke"",
            ""connection.clj"",
            15
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invokeStatic"",
            ""connection.clj"",
            118
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invoke"",
            ""connection.clj"",
            106
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invokeStatic"",
            ""standard.clj"",
            55
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invoke"",
            ""standard.clj"",
            47
        ],
        [
            ""methodical.impl.standard.StandardMultiFn"",
            ""invoke"",
            ""standard.clj"",
            210
        ],
        [
            ""metabase.db.connection$do_with_connection_primary_method_default"",
            ""invokeStatic"",
            ""connection.clj"",
            132
        ],
        [
            ""metabase.db.connection$do_with_connection_primary_method_default"",
            ""invoke"",
            ""connection.clj"",
            130
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invokeStatic"",
            ""connection.clj"",
            118
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invoke"",
            ""connection.clj"",
            106
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invokeStatic"",
            ""standard.clj"",
            55
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invoke"",
            ""standard.clj"",
            47
        ],
        [
            ""methodical.impl.standard.StandardMultiFn"",
            ""invoke"",
            ""standard.clj"",
            210
        ],
        [
            ""toucan2.connection$do_with_connection_primary_method_"",
            ""invokeStatic"",
            ""connection.clj"",
            204
        ],
        [
            ""toucan2.connection$do_with_connection_primary_method_"",
            ""invoke"",
            ""connection.clj"",
            194
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invokeStatic"",
            ""connection.clj"",
            118
        ],
        [
            ""toucan2.connection$do_with_connection_around_method_toucan2_connection_default"",
            ""invoke"",
            ""connection.clj"",
            106
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            12
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invokeStatic"",
            ""standard.clj"",
            55
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invoke"",
            ""standard.clj"",
            47
        ],
        [
            ""methodical.impl.standard.StandardMultiFn"",
            ""invoke"",
            ""standard.clj"",
            210
        ],
        [
            ""toucan2.pipeline$transduce_execute"",
            ""invokeStatic"",
            ""pipeline.clj"",
            77
        ],
        [
            ""toucan2.pipeline$transduce_execute"",
            ""invoke"",
            ""pipeline.clj"",
            64
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            399
        ],
        [
            ""toucan2.pipeline$transduce_compiled_query"",
            ""invokeStatic"",
            ""pipeline.clj"",
            244
        ],
        [
            ""toucan2.pipeline$transduce_compiled_query"",
            ""invoke"",
            ""pipeline.clj"",
            240
        ],
        [
            ""toucan2.pipeline$transduce_built_query"",
            ""invokeStatic"",
            ""pipeline.clj"",
            252
        ],
        [
            ""toucan2.pipeline$transduce_built_query"",
            ""invoke"",
            ""pipeline.clj"",
            246
        ],
        [
            ""toucan2.pipeline$transduce_query_primary_method_default"",
            ""invokeStatic"",
            ""pipeline.clj"",
            272
        ],
        [
            ""toucan2.pipeline$transduce_query_primary_method_default"",
            ""invoke"",
            ""pipeline.clj"",
            269
        ],
        [
            ""methodical.impl.combo.common$partial_STAR_$fn__18186"",
            ""invoke"",
            ""common.clj"",
            15
        ],
        [
            ""methodical.impl.combo.threaded$combine_methods_thread_last$fn__18496$combined_method_thread_last__18497"",
            ""invoke"",
            ""threaded.clj"",
            64
        ],
        [
            ""methodical.util.FnWithMeta"",
            ""invoke"",
            ""util.clj"",
            46
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invokeStatic"",
            ""standard.clj"",
            65
        ],
        [
            ""methodical.impl.standard$invoke_multifn"",
            ""invoke"",
            ""standard.clj"",
            47
        ],
        [
            ""methodical.impl.standard.StandardMultiFn"",
            ""invoke"",
            ""standard.clj"",
            216
        ],
        [
            ""toucan2.pipeline$transduce_query_STAR_"",
            ""invokeStatic"",
            ""pipeline.clj"",
            278
        ],
        [
            ""toucan2.pipeline$transduce_query_STAR_"",
            ""invoke"",
            ""pipeline.clj"",
            274
        ],
        [
            ""toucan2.pipeline$transduce_with_model"",
            ""invokeStatic"",
            ""pipeline.clj"",
            293
        ],
        [
            ""toucan2.pipeline$transduce_with_model"",
            ""invoke"",
            ""pipeline.clj"",
            280
        ],
        [
            ""toucan2.pipeline$transduce_parsed"",
            ""invokeStatic"",
            ""pipeline.clj"",
            309
        ],
        [
            ""toucan2.pipeline$transduce_parsed"",
            ""invoke"",
            ""pipeline.clj"",
            295
        ],
        [
            ""toucan2.pipeline$transduce_unparsed"",
            ""invokeStatic"",
            ""pipeline.clj"",
            317
        ],
        [
            ""toucan2.pipeline$transduce_unparsed"",
            ""invoke"",
            ""pipeline.clj"",
            311
        ],
        [
            ""toucan2.select$select_fn__GT_fn"",
            ""invokeStatic"",
            ""select.clj"",
            195
        ],
        [
            ""toucan2.select$select_fn__GT_fn"",
            ""doInvoke"",
            ""select.clj"",
            181
        ],
        [
            ""clojure.lang.RestFn"",
            ""applyTo"",
            ""RestFn.java"",
            142
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            673
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""toucan2.select$select_pk__GT_fn"",
            ""invokeStatic"",
            ""select.clj"",
            221
        ],
        [
            ""toucan2.select$select_pk__GT_fn"",
            ""doInvoke"",
            ""select.clj"",
            210
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            464
        ],
        [
            ""metabase.api.table$batch_fetch_card_query_metadatas"",
            ""invokeStatic"",
            ""table.clj"",
            517
        ],
        [
            ""metabase.api.table$batch_fetch_card_query_metadatas"",
            ""invoke"",
            ""table.clj"",
            497
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_query_metadata_STAR_"",
            ""invokeStatic"",
            ""query_metadata.clj"",
            49
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_query_metadata_STAR_"",
            ""invoke"",
            ""query_metadata.clj"",
            41
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_query_metadata"",
            ""invokeStatic"",
            ""query_metadata.clj"",
            71
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_query_metadata"",
            ""invoke"",
            ""query_metadata.clj"",
            68
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_card_metadata"",
            ""invokeStatic"",
            ""query_metadata.clj"",
            83
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_card_metadata"",
            ""invoke"",
            ""query_metadata.clj"",
            73
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_dashboard_metadata"",
            ""invokeStatic"",
            ""query_metadata.clj"",
            142
        ],
        [
            ""metabase.api.query_metadata$batch_fetch_dashboard_metadata"",
            ""invoke"",
            ""query_metadata.clj"",
            131
        ],
        [
            ""metabase.api.dashboard$fn__96434$fn__96437"",
            ""invoke"",
            ""dashboard.clj"",
            915
        ],
        [
            ""metabase.api.dashboard$do_with_dashboard_load_id"",
            ""invokeStatic"",
            ""dashboard.clj"",
            309
        ],
        [
            ""metabase.api.dashboard$do_with_dashboard_load_id"",
            ""invoke"",
            ""dashboard.clj"",
            304
        ],
        [
            ""metabase.api.dashboard$fn__96434"",
            ""invokeStatic"",
            ""dashboard.clj"",
            912
        ],
        [
            ""metabase.api.dashboard$fn__96434"",
            ""invoke"",
            ""dashboard.clj"",
            908
        ],
        [
            ""compojure.core$wrap_response$fn__52779"",
            ""invoke"",
            ""core.clj"",
            160
        ],
        [
            ""compojure.core$wrap_route_middleware$fn__52763"",
            ""invoke"",
            ""core.clj"",
            132
        ],
        [
            ""compojure.core$wrap_route_info$fn__52768"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            151
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""metabase.server.middleware.auth$enforce_authentication$fn__98192"",
            ""invoke"",
            ""auth.clj"",
            18
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__52819"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.api.routes$fn__103866$fn__103867"",
            ""invoke"",
            ""routes.clj"",
            70
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.lang.AFunction$1"",
            ""doInvoke"",
            ""AFunction.java"",
            31
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            667
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""metabase.server.routes$fn__104146$fn__104147"",
            ""doInvoke"",
            ""routes.clj"",
            73
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__52819"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__52772"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__52819"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792$respond_SINGLEQUOTE___52793"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__52823"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__52791$f__52792"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__52791"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__100226"",
            ""invoke"",
            ""exceptions.clj"",
            107
        ],
        [
            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__100223"",
            ""invoke"",
            ""exceptions.clj"",
            96
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__106503$fn__106504$fn__106505"",
            ""invoke"",
            ""log.clj"",
            233
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invokeStatic"",
            ""diagnostic.clj"",
            18
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invoke"",
            ""diagnostic.clj"",
            12
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__106503$fn__106504"",
            ""invoke"",
            ""log.clj"",
            224
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invokeStatic"",
            ""execute.clj"",
            112
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invoke"",
            ""execute.clj"",
            103
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__106503"",
            ""invoke"",
            ""log.clj"",
            223
        ],
        [
            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__112705"",
            ""invoke"",
            ""browser_cookie.clj"",
            40
        ],
        [
            ""metabase.server.middleware.security$add_security_headers$fn__100182"",
            ""invoke"",
            ""security.clj"",
            246
        ],
        [
            ""ring.middleware.json$wrap_json_body$fn__112964"",
            ""invoke"",
            ""json.clj"",
            64
        ],
        [
            ""metabase.server.middleware.offset_paging$handle_paging$fn__88545"",
            ""invoke"",
            ""offset_paging.clj"",
            43
        ],
        [
            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__54407"",
            ""invoke"",
            ""json.clj"",
            83
        ],
        [
            ""ring.middleware.keyword_params$wrap_keyword_params$fn__113053"",
            ""invoke"",
            ""keyword_params.clj"",
            55
        ],
        [
            ""ring.middleware.params$wrap_params$fn__113072"",
            ""invoke"",
            ""params.clj"",
            77
        ],
        [
            ""metabase.server.middleware.misc$maybe_set_site_url$fn__64266"",
            ""invoke"",
            ""misc.clj"",
            59
        ],
        [
            ""metabase.server.middleware.session$reset_session_timeout$fn__65819"",
            ""invoke"",
            ""session.clj"",
            549
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__65785$fn__65786"",
            ""invoke"",
            ""session.clj"",
            443
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invokeStatic"",
            ""session.clj"",
            422
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invoke"",
            ""session.clj"",
            405
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__65785"",
            ""invoke"",
            ""session.clj"",
            442
        ],
        [
            ""metabase.server.middleware.session$wrap_current_user_info$fn__65766"",
            ""invoke"",
            ""session.clj"",
            381
        ],
        [
            ""metabase.server.middleware.session$wrap_session_id$fn__65738"",
            ""invoke"",
            ""session.clj"",
            259
        ],
        [
            ""metabase.server.middleware.auth$wrap_static_api_key$fn__98200"",
            ""invoke"",
            ""auth.clj"",
            32
        ],
        [
            ""ring.middleware.cookies$wrap_cookies$fn__112892"",
            ""invoke"",
            ""cookies.clj"",
            200
        ],
        [
            ""metabase.server.middleware.misc$add_content_type$fn__64248"",
            ""invoke"",
            ""misc.clj"",
            28
        ],
        [
            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__64274"",
            ""invoke"",
            ""misc.clj"",
            75
        ],
        [
            ""ring.middleware.gzip$wrap_gzip$fn__112934"",
            ""invoke"",
            ""gzip.clj"",
            86
        ],
        [
            ""metabase.server.middleware.misc$bind_request$fn__64277"",
            ""invoke"",
            ""misc.clj"",
            91
        ],
        [
            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__112721"",
            ""invoke"",
            ""ssl.clj"",
            51
        ],
        [
            ""metabase.server$async_proxy_handler$fn__72022"",
            ""invoke"",
            ""server.clj"",
            77
        ],
        [
            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
            ""handle"",
            null,
            -1
        ],
        [
            ""org.eclipse.jetty.server.handler.StatisticsHandler"",
            ""handle"",
            ""StatisticsHandler.java"",
            173
        ],
        [
            ""org.eclipse.jetty.server.handler.HandlerWrapper"",
            ""handle"",
            ""HandlerWrapper.java"",
            122
        ],
        [
            ""org.eclipse.jetty.server.Server"",
            ""handle"",
            ""Server.java"",
            563
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
            ""dispatch"",
            ""HttpChannel.java"",
            1598
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""dispatch"",
            ""HttpChannel.java"",
            753
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""handle"",
            ""HttpChannel.java"",
            501
        ],
        [
            ""org.eclipse.jetty.server.HttpConnection"",
            ""onFillable"",
            ""HttpConnection.java"",
            287
        ],
        [
            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
            ""succeeded"",
            ""AbstractConnection.java"",
            314
        ],
        [
            ""org.eclipse.jetty.io.FillInterest"",
            ""fillable"",
            ""FillInterest.java"",
            100
        ],
        [
            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
            ""run"",
            ""SelectableChannelEndPoint.java"",
            53
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""runTask"",
            ""AdaptiveExecutionStrategy.java"",
            421
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""consumeTask"",
            ""AdaptiveExecutionStrategy.java"",
            390
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""tryProduce"",
            ""AdaptiveExecutionStrategy.java"",
            277
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""run"",
            ""AdaptiveExecutionStrategy.java"",
            199
        ],
        [
            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
            ""run"",
            ""ReservedThreadExecutor.java"",
            411
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
            ""runJob"",
            ""QueuedThreadPool.java"",
            969
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""doRunJob"",
            ""QueuedThreadPool.java"",
            1194
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""run"",
            ""QueuedThreadPool.java"",
            1149
        ],
        [
            ""java.lang.Thread"",
            ""run"",
            ""Thread.java"",
            829
        ]
    ],
    ""cause"": ""ERROR: syntax error at or near \"")\""\n  Position: 50"",
    ""message"": ""ERROR: syntax error at or near \"")\""\n  Position: 50""
}
```
</details>
### Information about your Metabase installation

v50

### Severity

P1

### Additional context

_No response_",paoliniluis,2024-10-08 15:29:50+00:00,['appleby'],2024-11-20 00:43:37+00:00,2024-11-19 22:09:19+00:00,https://github.com/metabase/metabase/issues/48461,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2400350013, 'issue_id': 2573544926, 'author': 'dpsutton', 'body': ""I'm unable to reproduce on master, 0.50.23, 1.50.23, and 1.50.26."", 'created_at': datetime.datetime(2024, 10, 8, 16, 39, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402242645, 'issue_id': 2573544926, 'author': 'paoliniluis', 'body': ""~I have bad news: this is still there in v51-beta, so it's a release blocker~ So if you created the question in v50, then it will keep failing, but if you do it in v51, it will work"", 'created_at': datetime.datetime(2024, 10, 9, 12, 54, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402535123, 'issue_id': 2573544926, 'author': 'paoliniluis', 'body': ""tested in 0.50.23-1.50.23 and it doesn't work till 1.50.28"", 'created_at': datetime.datetime(2024, 10, 9, 14, 39, 29, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-10-08 16:39:30 UTC): I'm unable to reproduce on master, 0.50.23, 1.50.23, and 1.50.26.

paoliniluis (Issue Creator) on (2024-10-09 12:54:13 UTC): ~I have bad news: this is still there in v51-beta, so it's a release blocker~ So if you created the question in v50, then it will keep failing, but if you do it in v51, it will work

paoliniluis (Issue Creator) on (2024-10-09 14:39:29 UTC): tested in 0.50.23-1.50.23 and it doesn't work till 1.50.28

"
2573445356,issue,closed,completed,Investigate FE performance bug in v50,"### Describe the bug

A customer just sent us a trace about a performance regression they're seeing on the native query editor
https://drive.google.com/file/d/17mb_kk4n8Wu6iB2HRDI16FXdl-FtHYQC/view?usp=sharing

### To Reproduce

NA

### Expected behavior

It should be fast

### Logs

NA

### Information about your Metabase installation

v50.x

### Severity

P1

### Additional context

NA",paoliniluis,2024-10-08 14:50:26+00:00,['kulyk'],2024-10-21 13:21:50+00:00,2024-10-18 15:26:46+00:00,https://github.com/metabase/metabase/issues/48458,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2402033008, 'issue_id': 2573445356, 'author': 'kamilmielnik', 'body': 'Related Slack thread: https://metaboat.slack.com/archives/C07BWMG9C8M/p1728461137804439\n\nPerf report is pointing [here](https://github.com/metabase/metabase/blob/61e610b3b9a0fce2817345564c53fed7319f0b7b/frontend/src/metabase/visualizations/shared/settings/pie.ts#L163).\n\n![Image](https://github.com/user-attachments/assets/111444f3-ca2b-4194-a134-96f02f47aebb)', 'created_at': datetime.datetime(2024, 10, 9, 11, 15, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406435515, 'issue_id': 2573445356, 'author': 'perivamsi', 'body': 'While we should definitely fix this, this is not a P1 because the instance specifically overrode MB_AGGREGATED_QUERY_ROW_LIMIT\nand MB_UNAGGREGATED_QUERY_ROW_LIMIT and set it to 50K. Increasing that limit has perf implications and while we should fix it, it should not be fixed at a P1 priority.', 'created_at': datetime.datetime(2024, 10, 11, 2, 39, 36, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-09 11:15:20 UTC): Related Slack thread: https://metaboat.slack.com/archives/C07BWMG9C8M/p1728461137804439

Perf report is pointing [here](https://github.com/metabase/metabase/blob/61e610b3b9a0fce2817345564c53fed7319f0b7b/frontend/src/metabase/visualizations/shared/settings/pie.ts#L163).

![Image](https://github.com/user-attachments/assets/111444f3-ca2b-4194-a134-96f02f47aebb)

perivamsi on (2024-10-11 02:39:36 UTC): While we should definitely fix this, this is not a P1 because the instance specifically overrode MB_AGGREGATED_QUERY_ROW_LIMIT
and MB_UNAGGREGATED_QUERY_ROW_LIMIT and set it to 50K. Increasing that limit has perf implications and while we should fix it, it should not be fixed at a P1 priority.

"
2573309954,issue,closed,not_planned,Unable to deploy metabase to the specified postgres schema,"# Problem
I want to deploy the metabase to a specific schema, but it fails. I found this [code](https://github.com/metabase/metabase/blob/2ec9fdb1783d6028d64d87609c25c33e2ff14d7d/resources/migrations/initialization/metabase_postgres.sql#L5), which seems to be the main reason why the metabase cannot be deployed to the specified schema.",yinxulai,2024-10-08 14:00:16+00:00,[],2024-10-08 14:13:55+00:00,2024-10-08 14:13:54+00:00,https://github.com/metabase/metabase/issues/48457,[],"[{'comment_id': 2399976854, 'issue_id': 2573309954, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/37836', 'created_at': datetime.datetime(2024, 10, 8, 14, 13, 54, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-08 14:13:54 UTC): duplicate of https://github.com/metabase/metabase/issues/37836

"
2573274278,issue,closed,completed,Implement a button to create a new metric in the empty state of the Metrics page,,romeovs,2024-10-08 13:49:23+00:00,['romeovs'],2024-10-16 11:39:52+00:00,2024-10-11 14:31:55+00:00,https://github.com/metabase/metabase/issues/48453,"[('.Frontend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2')]",[],
2573150364,issue,closed,completed,"Change texts from ""Basic Metrics"" and ""Common Metrics"" to ""Summaries"" and ""Metrics” in the Summarize block in the notebook editor and the Summarize sidebar in the chill mode",,romeovs,2024-10-08 13:04:37+00:00,['romeovs'],2024-10-15 08:32:27+00:00,2024-10-15 07:42:58+00:00,https://github.com/metabase/metabase/issues/48450,"[('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', ''), ('Querying/Metrics', 'v2')]",[],
2573106814,issue,closed,completed,Change the texts to be the same in the empty state of the Metrics page and the Metric editor,"Change the empty text for the metrics page and the metrics editor to:


> ### Create Metrics to define the official way to calculate important numbers for your team
> Metrics are like pre-defined calculations: create your aggregations once, save them as metrics, and use them whenever you need to analyze your data",romeovs,2024-10-08 12:46:48+00:00,['romeovs'],2024-10-15 10:18:21+00:00,2024-10-09 09:12:23+00:00,https://github.com/metabase/metabase/issues/48448,"[('.Frontend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2')]",[],
2573106290,issue,open,,[Epic] Metrics v2 follow-ups,"[product doc](https://www.notion.so/metabase/Metrics-v2-follow-ups-11569354c90180d38cdcd1b042f17fe4)

## Implementation Plan

```[tasklist]
### Milestone 1: FE
- [ ] https://github.com/metabase/metabase/issues/48448
- [ ] https://github.com/metabase/metabase/issues/48450
- [ ] https://github.com/metabase/metabase/issues/48453
- [ ] https://github.com/metabase/metabase/issues/47058
- [ ] https://github.com/metabase/metabase/issues/44171
- [ ] https://github.com/metabase/metabase/issues/48555
```

```[tasklist]
## Milestone 2: BE
- [ ] https://github.com/metabase/metabase/issues/48192
- [ ] https://github.com/metabase/metabase/issues/44210
- [ ] https://github.com/metabase/metabase/issues/48277
- [ ] Show metric name as the column name in the resulting table (like Revenue instead of Sum of Total)
- [ ] https://github.com/metabase/metabase/issues/42392
```",romeovs,2024-10-08 12:46:35+00:00,[],2024-10-22 12:39:42+00:00,,https://github.com/metabase/metabase/issues/48447,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2573064499,issue,closed,completed,FE - e2e - Cover combination of unit of time parameter + non-last-stage filters with tests,"Q3:
```tsx
      describe(""applies filter to the the dashcard and allows to drill via dashcard header"", () => {
        it.only(""1st stage explicit join + unit of time parameter"", () => {
          setup1stStageExplicitJoinFilter();

          verifyDashcardRowsCount({
            dashcardIndex: 0,
            dashboardCount: ""Rows 1-1 of 953"",
            queryBuilderCount: ""Showing 953 rows"",
          });

          goBackToDashboard();

          verifyDashcardRowsCount({
            dashcardIndex: 1,
            dashboardCount: ""Rows 1-1 of 953"",
            queryBuilderCount: ""Showing 953 rows"",
          });
        });
      });
```

then add unit of time parameter",kamilmielnik,2024-10-08 12:28:35+00:00,['kamilmielnik'],2024-10-18 08:48:13+00:00,2024-10-18 08:48:12+00:00,https://github.com/metabase/metabase/issues/48445,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2421862528, 'issue_id': 2573064499, 'author': 'kamilmielnik', 'body': 'Closed by #48726', 'created_at': datetime.datetime(2024, 10, 18, 8, 48, 12, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-18 08:48:12 UTC): Closed by #48726

"
2573033135,issue,closed,not_planned,"No fields found for table ""XXXXX""","### Describe the bug

We’re encountering an issue with some Snowflake tables/views in Metabase where the columns are not being detected and don’t appear in the Table Metadata.

Despite multiple attempts at running a full “Sync database schema now.” the problem persists. The Metabase logs show an error stating “No fields found for table ‘XXXXX’.”

On the Snowflake side, the “getColumns()” call is successful and returns data to Metabase:

```
show /* JDBC:DatabaseMetaData.getColumns() */ columns 
in table ""XXXXXX.XXXXX.XXXXX""
```

Additionally, querying the table directly via SQL works without any issues.

### To Reproduce

	1.	Create a table in Snowflake.
	2.	Click “Sync database schema now.”
	3.	The table appears, but no fields are displayed.

### Expected behavior

The table fields should be displayed

### Logs

[9f56f209-1be1-41ef-ac54-6d55f3c44f01] 2024-10-08T13:38:44+02:00 ERROR metabase.models.query.permissions ,clojure.lang.ExceptionInfo: Error calculating permissions for query {:query {:database 5, :type :query, :query {:source-table 1868}}},	at metabase.models.query.permissions$legacy_mbql_required_perms.invokeStatic(permissions.clj:153),	at metabase.models.query.permissions$legacy_mbql_required_perms.invoke(permissions.clj:131),	at metabase.models.query.permissions$required_perms_for_query.invokeStatic(permissions.clj:180),	at metabase.models.query.permissions$required_perms_for_query.doInvoke(permissions.clj:171),	at clojure.lang.RestFn.invoke(RestFn.java:410),	at metabase.models.query.permissions$can_run_query_QMARK_.invokeStatic(permissions.clj:266),	at metabase.models.query.permissions$can_run_query_QMARK_.invoke(permissions.clj:263),	at metabase.models.query.permissions$can_query_table_QMARK_.invokeStatic(permissions.clj:272),	at metabase.models.query.permissions$can_query_table_QMARK_.invoke(permissions.clj:269),	at metabase.events.view_log$publish_event_BANG__primary_method_metabase_events_view_log_table_read.invokeStatic(view_log.clj:154),	at metabase.events.view_log$publish_event_BANG__primary_method_metabase_events_view_log_table_read.invoke(view_log.clj:141),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.combo.operator$invoke_fn$fn__18297.invoke(operator.clj:69),	at methodical.impl.combo.operator$fn__18318$fn__18319$fn__18320.invoke(operator.clj:112),	at clojure.core$comp$fn__5876.invoke(core.clj:2587),	at metabase.events$publish_event_BANG__around_method_default$fn__39544.invoke(events.clj:132),	at metabase.events$publish_event_BANG__around_method_default.invokeStatic(events.clj:129),	at metabase.events$publish_event_BANG__around_method_default.invoke(events.clj:108),	at methodical.impl.combo.common$partial_STAR_$fn__18182.invoke(common.clj:12),	at methodical.util.FnWithMeta.invoke(util.clj:46),	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55),	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47),	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:210),	at metabase.api.dataset$run_streaming_query.invokeStatic(dataset.clj:66),	at metabase.api.dataset$run_streaming_query.doInvoke(dataset.clj:50),	at clojure.lang.RestFn.invoke(RestFn.java:410),	at metabase.api.dataset$fn__94140.invokeStatic(dataset.clj:90),	at metabase.api.dataset$fn__94140.invoke(dataset.clj:86),	at compojure.core$wrap_response$fn__52764.invoke(core.clj:160),	at compojure.core$wrap_route_middleware$fn__52748.invoke(core.clj:132),	at compojure.core$wrap_route_info$fn__52753.invoke(core.clj:139),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:151),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:152),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776.invoke(core.clj:200),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at metabase.server.middleware.auth$enforce_authentication$fn__97435.invoke(auth.clj:18),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776.invoke(core.clj:200),	at compojure.core$make_context$handler__52804.invoke(core.clj:290),	at compojure.core$make_context$fn__52808.invoke(core.clj:300),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$make_context$fn__52808.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:153),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at metabase.api.routes$fn__103111$fn__103114.invoke(routes.clj:73),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776.invoke(core.clj:200),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:667),	at clojure.core$apply.invoke(core.clj:662),	at metabase.server.routes$fn__103391$fn__103392.doInvoke(routes.clj:73),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776.invoke(core.clj:200),	at compojure.core$make_context$handler__52804.invoke(core.clj:290),	at compojure.core$make_context$fn__52808.invoke(core.clj:300),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:153),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:153),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:153),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52757.invoke(core.clj:153),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776$f__52777$respond_SINGLEQUOTE___52778.invoke(core.clj:197),	at metabase.server.routes$fn__103374$fn__103376.invoke(routes.clj:47),	at compojure.core$routes$fn__52776$f__52777.invoke(core.clj:198),	at compojure.core$routes$fn__52776.invoke(core.clj:200),	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99469.invoke(exceptions.clj:107),	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__99466.invoke(exceptions.clj:96),	at metabase.server.middleware.log$log_api_call$fn__103678$fn__103679$fn__103680.invoke(log.clj:233),	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18),	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12),	at metabase.server.middleware.log$log_api_call$fn__103678$fn__103679.invoke(log.clj:224),	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112),	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103),	at metabase.server.middleware.log$log_api_call$fn__103678.invoke(log.clj:223),	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__106968.invoke(browser_cookie.clj:40),	at metabase.server.middleware.security$add_security_headers$fn__99425.invoke(security.clj:246),	at ring.middleware.json$wrap_json_body$fn__107227.invoke(json.clj:64),	at metabase.server.middleware.offset_paging$handle_paging$fn__87789.invoke(offset_paging.clj:43),	at metabase.server.middleware.json$wrap_streamed_json_response$fn__54392.invoke(json.clj:83),	at ring.middleware.keyword_params$wrap_keyword_params$fn__107316.invoke(keyword_params.clj:55),	at ring.middleware.params$wrap_params$fn__107335.invoke(params.clj:77),	at metabase.server.middleware.misc$maybe_set_site_url$fn__64236.invoke(misc.clj:59),	at metabase.server.middleware.session$reset_session_timeout$fn__65787.invoke(session.clj:548),	at metabase.server.middleware.session$bind_current_user$fn__65753$fn__65754.invoke(session.clj:443),	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:422),	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:405),	at metabase.server.middleware.session$bind_current_user$fn__65753.invoke(session.clj:442),	at metabase.server.middleware.session$wrap_current_user_info$fn__65734.invoke(session.clj:381),	at metabase.server.middleware.session$wrap_session_id$fn__65706.invoke(session.clj:259),	at metabase.server.middleware.auth$wrap_static_api_key$fn__97443.invoke(auth.clj:32),	at ring.middleware.cookies$wrap_cookies$fn__107155.invoke(cookies.clj:200),	at metabase.server.middleware.misc$add_content_type$fn__64218.invoke(misc.clj:28),	at metabase.server.middleware.misc$disable_streaming_buffering$fn__64244.invoke(misc.clj:75),	at ring.middleware.gzip$wrap_gzip$fn__107197.invoke(gzip.clj:86),	at metabase.server.middleware.misc$bind_request$fn__64247.invoke(misc.clj:91),	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__106984.invoke(ssl.clj:41),	at metabase.server$async_proxy_handler$fn__71978.invoke(server.clj:77),	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source),	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173),	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122),	at org.eclipse.jetty.server.Server.handle(Server.java:563),	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598),	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753),	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Unknown Source),Caused by: clojure.lang.ExceptionInfo: Error preprocessing query in metabase.query_processor.preprocess$ensure_legacy$fn__67746@18d68987: No fields found for table ""XXXXX"". {:fn #object[metabase.query_processor.preprocess$ensure_legacy$fn__67746 0x18d68987 ""metabase.query_processor.preprocess$ensure_legacy$fn__67746@18d68987""], :query {:database 5, :type :query, :query {:source-table 1868}}, :type :qp},	at metabase.query_processor.preprocess$preprocess$fn__67754$fn__67755.invoke(preprocess.clj:133),	at clojure.lang.PersistentVector.reduce(PersistentVector.java:343),	at clojure.core$transduce.invokeStatic(core.clj:6947),	at clojure.core$transduce.invoke(core.clj:6934),	at metabase.query_processor.preprocess$preprocess$fn__67754.invoke(preprocess.clj:119),	at metabase.query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:189),	at metabase.query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181),	at metabase.query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166),	at metabase.driver$do_with_driver.invokeStatic(driver.clj:104),	at metabase.driver$do_with_driver.invoke(driver.clj:99),	at metabase.query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165),	at metabase.query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151),	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170),	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150),	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159),	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150),	at metabase.query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150),	at metabase.query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128),	at metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232),	at metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216),	at metabase.query_processor.preprocess$preprocess.invokeStatic(preprocess.clj:118),	at metabase.query_processor.preprocess$preprocess.invoke(preprocess.clj:114),	at clojure.lang.Var.invoke(Var.java:384),	at metabase.models.query.permissions$preprocess_query$fn__66055.invoke(permissions.clj:105),	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:422),	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:405),	at metabase.models.query.permissions$preprocess_query.invokeStatic(permissions.clj:104),	at metabase.models.query.permissions$preprocess_query.invoke(permissions.clj:100),	at metabase.models.query.permissions$legacy_mbql_required_perms.invokeStatic(permissions.clj:139),	... 213 more,Caused by: clojure.lang.ExceptionInfo: No fields found for table ""SAAS_SELLSY_ORCHESTRATOR_MOVE_TO_S3"". {:table-id 1868, :type :invalid-query},	at metabase.query_processor.middleware.add_implicit_clauses$sorted_implicit_fields_for_table.invokeStatic(add_implicit_clauses.clj:36),	at metabase.query_processor.middleware.add_implicit_clauses$sorted_implicit_fields_for_table.invoke(add_implicit_clauses.clj:30),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_fields.invokeStatic(add_implicit_clauses.clj:100),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_fields.invoke(add_implicit_clauses.clj:93),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses$fn__61101.invoke(add_implicit_clauses.clj:177),	at clojure.walk$walk.invokeStatic(walk.clj:50),	at clojure.walk$postwalk.invokeStatic(walk.clj:53),	at clojure.walk$postwalk.invoke(walk.clj:53),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses.invokeStatic(add_implicit_clauses.clj:170),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses.invoke(add_implicit_clauses.clj:167),	at clojure.core$update.invokeStatic(core.clj:6232),	at clojure.core$update.invoke(core.clj:6224),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_clauses.invokeStatic(add_implicit_clauses.clj:187),	at metabase.query_processor.middleware.add_implicit_clauses$add_implicit_clauses.invoke(add_implicit_clauses.clj:181),	at clojure.lang.Var.invoke(Var.java:384),	at metabase.query_processor.preprocess$ensure_legacy$fn__67746.invoke(preprocess.clj:62),	at metabase.query_processor.preprocess$preprocess$fn__67754$fn__67755.invoke(preprocess.clj:128),	... 241 more
[9f56f209-1be1-41ef-ac54-6d55f3c44f01] 2024-10-08T13:38:44+02:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: No fields found for table ""SAAS_SELLSY_ORCHESTRATOR_MOVE_TO_S3"".
{:database_id 5,
 :started_at #t ""2024-10-08T11:38:44.643984Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error preprocessing query in metabase.query_processor.preprocess$ensure_legacy$fn__67746@18d68987: No fields found for table \""SAAS_SELLSY_ORCHESTRATOR_MOVE_TO_S3\""."",
   :stacktrace
   [""--> query_processor.preprocess$preprocess$fn__67754$fn__67755.invoke(preprocess.clj:133)""
    ""query_processor.preprocess$preprocess$fn__67754.invoke(preprocess.clj:119)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.preprocess$preprocess.invokeStatic(preprocess.clj:118)""
    ""query_processor.preprocess$preprocess.invoke(preprocess.clj:114)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76913.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""api.dataset$run_streaming_query$fn__94128.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97)""],
   :error_type :qp,
   :ex-data
   {:fn
    #object[metabase.query_processor.preprocess$ensure_legacy$fn__67746 0x18d68987 ""metabase.query_processor.preprocess$ensure_legacy$fn__67746@18d68987""],
    :query
    {:database 5,
     :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
     :info {:executed-by 3, :context :ad-hoc, :query-hash #object[""[B"" 0x43f5d9d8 ""[B@43f5d9d8""]},
     :constraints {:max-results 10000, :max-results-bare-rows 2000},
     :type :query,
     :query {:source-table 1868}},
    :type :qp}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 5,
  :query {:source-table 1868},
  :type ""query"",
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> query_processor.middleware.add_implicit_clauses$sorted_implicit_fields_for_table.invokeStatic(add_implicit_clauses.clj:36)""
  ""query_processor.middleware.add_implicit_clauses$sorted_implicit_fields_for_table.invoke(add_implicit_clauses.clj:30)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_fields.invokeStatic(add_implicit_clauses.clj:100)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_fields.invoke(add_implicit_clauses.clj:93)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses$fn__61101.invoke(add_implicit_clauses.clj:177)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses.invokeStatic(add_implicit_clauses.clj:170)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_mbql_clauses.invoke(add_implicit_clauses.clj:167)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_clauses.invokeStatic(add_implicit_clauses.clj:187)""
  ""query_processor.middleware.add_implicit_clauses$add_implicit_clauses.invoke(add_implicit_clauses.clj:181)""
  ""query_processor.preprocess$ensure_legacy$fn__67746.invoke(preprocess.clj:62)""
  ""query_processor.preprocess$preprocess$fn__67754$fn__67755.invoke(preprocess.clj:128)""
  ""query_processor.preprocess$preprocess$fn__67754.invoke(preprocess.clj:119)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.preprocess$preprocess.invokeStatic(preprocess.clj:118)""
  ""query_processor.preprocess$preprocess.invoke(preprocess.clj:114)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76913.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__94128.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""No fields found for table \""XXXXXX\""."",
 :row_count 0,
 :running_time 0,
 :preprocessed nil,
 :ex-data {:table-id 1868, :type :invalid-query},
 :data {:rows [], :cols []}}


### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""snowflake"",
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-17"",
      ""tag"": ""v0.50.26.1"",
      ""hash"": ""c192751""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Debian 16.2-1.pgdg110+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-36-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}

### Severity

blocking some users

### Additional context

_No response_",tcourtainsellsy,2024-10-08 12:15:04+00:00,[],2024-10-08 14:12:23+00:00,2024-10-08 14:12:21+00:00,https://github.com/metabase/metabase/issues/48443,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('Administration/Metadata & Sync', ''), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2399775199, 'issue_id': 2573033135, 'author': 'Tony-metabase', 'body': 'Can you share the whole logs from STARTING: to FINISHED: logs when you hit the `Sync database schema now`\n\nAlso if you go to Admin -> Table Metadata for DB are you able to find column form other tables or you only get Tables with empty columns? Can you share some screenshots in this case', 'created_at': datetime.datetime(2024, 10, 8, 12, 57, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399844000, 'issue_id': 2573033135, 'author': 'tcourtainsellsy', 'body': 'Hello @Tony-metabase,\n\nI have identified an error in the logs regarding the 4 fields that are missing in the table metadata : `[cd15e861-18c1-4020-a32a-04f34048ed4a] 2024-10-08T13:58:03+02:00 WARN metabase.sync.util Error checking if Fields (""CORP_ID"" ""START_AT"" ""FAILED_AT"" ""END_AT"") need to be created or reactivated,clojure.lang.ExceptionInfo: ERROR: could not read block 1398 in file ""base/18286/21153"": read only 0 of 8192 bytes {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""INSERT INTO \\""metabase_field\\"" `\n\nThe other tables are functioning correctly, but the last two we recently added are not displaying any fields.\u200b\n\nFull log attached [metabase.log](https://github.com/user-attachments/files/17293948/metabase.log)', 'created_at': datetime.datetime(2024, 10, 8, 13, 25, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399973085, 'issue_id': 2573033135, 'author': 'paoliniluis', 'body': 'you have a disk failure in your database: ""ERROR: could not read block 1398 in file ""base/18286/21153""', 'created_at': datetime.datetime(2024, 10, 8, 14, 12, 21, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-10-08 12:57:09 UTC): Can you share the whole logs from STARTING: to FINISHED: logs when you hit the `Sync database schema now`

Also if you go to Admin -> Table Metadata for DB are you able to find column form other tables or you only get Tables with empty columns? Can you share some screenshots in this case

tcourtainsellsy (Issue Creator) on (2024-10-08 13:25:13 UTC): Hello @Tony-metabase,

I have identified an error in the logs regarding the 4 fields that are missing in the table metadata : `[cd15e861-18c1-4020-a32a-04f34048ed4a] 2024-10-08T13:58:03+02:00 WARN metabase.sync.util Error checking if Fields (""CORP_ID"" ""START_AT"" ""FAILED_AT"" ""END_AT"") need to be created or reactivated,clojure.lang.ExceptionInfo: ERROR: could not read block 1398 in file ""base/18286/21153"": read only 0 of 8192 bytes {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""INSERT INTO \""metabase_field\"" `

The other tables are functioning correctly, but the last two we recently added are not displaying any fields.​

Full log attached [metabase.log](https://github.com/user-attachments/files/17293948/metabase.log)

paoliniluis on (2024-10-08 14:12:21 UTC): you have a disk failure in your database: ""ERROR: could not read block 1398 in file ""base/18286/21153""

"
2572938409,issue,closed,completed,Pivot Table Column reordering from Visualization UI doesn't reflect in downloaded files,"### Describe the bug

If you order the columns for a Pivot Table via the UI, they will show up in the Visual but will not reflected in downloaded files:

 ![Image](https://github.com/user-attachments/assets/1443be13-c299-473f-b07b-11b8757c6201)

It only works if you order them form the editor section:

![Image](https://github.com/user-attachments/assets/257480e3-a538-4eba-bc06-a8b01f3e3520)


### To Reproduce

1. Go toNew ->  Question -> Products -> Count and Sum of Rating -> Grouped by Created At -> Turn into a Pivot

![Image](https://github.com/user-attachments/assets/5a06bb54-8f58-49d0-bd91-b80bc9df7591)

2.Re-order the columns from the UI

![Image](https://github.com/user-attachments/assets/b2be9387-29eb-4184-a1f2-397370162fdb)

3. Download the Pivot and notice that the order didn't match the Pivot

![Image](https://github.com/user-attachments/assets/4de2c41b-2177-47f3-aaa8-39ff265a683a)

You can test this on stats https://stats.metabase.com/question/20058-test

### Expected behavior

The download should be an exact copy of what you get presented in the UI

### Logs

None that are relevant

### Information about your Metabase installation

Tested on 50.28 and master

### Severity

It's very annoying if you don't know about this bug. 

### Additional context

There is a workaround in which you need to go and order the columns from the editor",Tony-metabase,2024-10-08 11:37:17+00:00,['adam-james-v'],2024-11-04 20:23:10+00:00,2024-11-04 20:23:09+00:00,https://github.com/metabase/metabase/issues/48442,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2399612549, 'issue_id': 2572938409, 'author': 'kamilmielnik', 'body': 'Also dates are formatted differently in the ""Created At"" column, and the column name does not match', 'created_at': datetime.datetime(2024, 10, 8, 11, 42, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404453004, 'issue_id': 2572938409, 'author': 'Tony-metabase', 'body': 'I am escalating this cause it causes more weird stuff happening when you add the question to a dashboard, for reference:\n\nhttps://stats.metabase.com/dashboard/2650-test\n\nI added a new column to the question\n\n![Image](https://github.com/user-attachments/assets/b2b6a0c9-a42c-4e43-b4dd-4a364841efaf)\n\nAnd added the question to the dashboard but the order is still broken:\n\n![Image](https://github.com/user-attachments/assets/35660a2c-81ad-4e4a-bf3d-9f5939519c42)\n\nThis makes pivot with many columns very very hard to work with', 'created_at': datetime.datetime(2024, 10, 10, 8, 33, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429690805, 'issue_id': 2572938409, 'author': 'adam-james-v', 'body': 'This bug is solved by https://github.com/metabase/metabase/pull/46995\n\nSince the fix for v50 is a bit of a hacky fix, I am closing this issue and encourage transitioning to v51 when feasible, as the pivot exports are much improved.\n\nIn the meantime, as a workaround, it should be possible to switch to Table viz, arrange columns as you want them to be there, save the question, and switch back to a pivot viz. This may not be perfect, but can be a stopgap until v51 can be used.', 'created_at': datetime.datetime(2024, 10, 22, 16, 6, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447497012, 'issue_id': 2572938409, 'author': 'Tony-metabase', 'body': ""Reopening this since the download as pivot still doesn't respect reordering, both if you thick the Keep data pivoted option\n\n![Image](https://github.com/user-attachments/assets/775a096d-3103-4ce3-aaf1-3918a5be252e)\n\nAlso for the Keep data pivoted enabled the column names this time are also being ignored\n\n![Image](https://github.com/user-attachments/assets/11a7c178-1692-4a72-ba9c-de2f98cf228c)"", 'created_at': datetime.datetime(2024, 10, 30, 15, 15, 47, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-08 11:42:12 UTC): Also dates are formatted differently in the ""Created At"" column, and the column name does not match

Tony-metabase (Issue Creator) on (2024-10-10 08:33:51 UTC): I am escalating this cause it causes more weird stuff happening when you add the question to a dashboard, for reference:

https://stats.metabase.com/dashboard/2650-test

I added a new column to the question

![Image](https://github.com/user-attachments/assets/b2b6a0c9-a42c-4e43-b4dd-4a364841efaf)

And added the question to the dashboard but the order is still broken:

![Image](https://github.com/user-attachments/assets/35660a2c-81ad-4e4a-bf3d-9f5939519c42)

This makes pivot with many columns very very hard to work with

adam-james-v (Assginee) on (2024-10-22 16:06:37 UTC): This bug is solved by https://github.com/metabase/metabase/pull/46995

Since the fix for v50 is a bit of a hacky fix, I am closing this issue and encourage transitioning to v51 when feasible, as the pivot exports are much improved.

In the meantime, as a workaround, it should be possible to switch to Table viz, arrange columns as you want them to be there, save the question, and switch back to a pivot viz. This may not be perfect, but can be a stopgap until v51 can be used.

Tony-metabase (Issue Creator) on (2024-10-30 15:15:47 UTC): Reopening this since the download as pivot still doesn't respect reordering, both if you thick the Keep data pivoted option

![Image](https://github.com/user-attachments/assets/775a096d-3103-4ce3-aaf1-3918a5be252e)

Also for the Keep data pivoted enabled the column names this time are also being ignored

![Image](https://github.com/user-attachments/assets/11a7c178-1692-4a72-ba9c-de2f98cf228c)

"
2572839787,issue,closed,completed,Dashboard filters on structured questions work incorrectly when non-negative stage-number is used,"Similar to #48258

1. `git checkout 47219-dashboard-drills-tests`
    - if #48289 is already merged then `git checkout dashboard-filter-columns`
2. `git revert 4ea374870d5e2283fc5f2ad9053720a32c848eca`
3. Run any unskipped e2e test in `dashboard-filters-query-stages.cy.spec.ts` except the ones called `allows to map to all relevant columns`
POST `/api/dashboard/:id/dashcard/:id/card/:id/query` will fail with error like `""Cannot determine the source table or query for Field clause [:field 32 {:base-type :type/Text, :join-alias \""Reviews - Product\""}]""`",kamilmielnik,2024-10-08 10:54:27+00:00,['metamben'],2024-10-25 10:53:52+00:00,2024-10-25 10:53:50+00:00,https://github.com/metabase/metabase/issues/48441,"[('Querying/Processor', ''), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2437481888, 'issue_id': 2572839787, 'author': 'kamilmielnik', 'body': 'Closed by #48906', 'created_at': datetime.datetime(2024, 10, 25, 10, 53, 50, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-25 10:53:50 UTC): Closed by #48906

"
2572839459,issue,open,,Dashboard filters on structured questions work incorrectly when non-negative stage-number is used,,kamilmielnik,2024-10-08 10:54:21+00:00,[],2024-10-08 10:54:21+00:00,,https://github.com/metabase/metabase/issues/48440,[],[],
2572701270,issue,open,,Row count differs when question is connected to an empty dashboard filter,"### Describe the bug

https://github.com/user-attachments/assets/057838f5-24fa-47c5-addc-311bebc29fe3


### To Reproduce

1. New > Question > Orders
    - join Reviews on Product ID = Product ID
    - add aggregations: Count and Sum of Total
    - add breakouts: Created At: Month, Product -> Category, User -> Created At: Year
    - join Reviews on Created At: Month = Created At: Month
    - add Count aggregation
    - add breakouts: Reviews -> Reviewer and Product -> Category
2. Visualize, notice rows count is 4308 (⚠ **shouldn't it be limited to 2000?**)
3. Save and add to a new dashboard, save it
4. Notice rows count is 4308
5. Add any parameter to the dashboard and connect it to the card, save (do not provide parameter value)
6. Notice rows count is 2000

### Expected behavior

Rows count should be the same

### Information about your Metabase installation

master, cd4d76463228932b4a3baf9b9ff5e3eefa4e0392

### Severity

P2

### Additional context

POST `/api/dashboard/:id/dashcard/:id/card/:id/query` 

----


Request:
```
{""parameters"":[],""dashboard_id"":49,""dashboard_load_id"":""4acd13dd-58e0-0dcd-26c4-38e31dbf7c75""}
```

Response:
```
{
  /* ... */
  row_count: 4308,
  /* ... */
}
```

----

Request:
```
{""parameters"":[{""type"":""number/="",""value"":null,""id"":""e8a3b775"",""target"":[""dimension"",[""field"",44,{""base-type"":""type/Float""}],{""stage-number"":-3}]}],""dashboard_id"":49,""dashboard_load_id"":""2f67706b-db07-3bec-2aaa-46410694c17e""}
```

Response:
```
{
  /* ... */
  row_count: 2000,
  /* ... */
}
```

",kamilmielnik,2024-10-08 09:55:13+00:00,[],2025-02-04 20:27:52+00:00,,https://github.com/metabase/metabase/issues/48439,"[('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2399416349, 'issue_id': 2572701270, 'author': 'kamilmielnik', 'body': ""> 2. Visualize, notice rows count is 4308 (⚠ shouldn't it be limited to 2000?)\n\nI think that's the actual bug but I'm not entirely sure.\nPlease confirm with product team when working on this."", 'created_at': datetime.datetime(2024, 10, 8, 10, 3, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417762880, 'issue_id': 2572701270, 'author': 'appleby', 'body': ""> > 2. Visualize, notice rows count is 4308 (⚠ shouldn't it be limited to 2000?)\n> \n> I think that's the actual bug but I'm not entirely sure. Please confirm with product team when working on this.\n\nTurns out the 2000 limit is only used for queries without aggregations, so I think working as designed that we ignore it initially, but not clear why adding the empty dashboard filter causes it to come into effect.\n\nhttps://github.com/metabase/metabase/issues/48298#issuecomment-2417759455"", 'created_at': datetime.datetime(2024, 10, 16, 19, 28, 23, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-08 10:03:27 UTC): I think that's the actual bug but I'm not entirely sure.
Please confirm with product team when working on this.

appleby on (2024-10-16 19:28:23 UTC): Turns out the 2000 limit is only used for queries without aggregations, so I think working as designed that we ignore it initially, but not clear why adding the empty dashboard filter causes it to come into effect.

https://github.com/metabase/metabase/issues/48298#issuecomment-2417759455

"
2572639323,issue,open,,Driver: Connection Impersonation: Databricks,"**Is your feature request related to a problem? Please describe.**
A user mentioned that they define everything on the Databricks unity catalog, so they want Metabase to inherit those permissions for the queries

**Describe the solution you'd like**
Use https://www.databricks.com/product/unity-catalog for permissions

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a lead (banking)

**Additional context**
NA
",paoliniluis,2024-10-08 09:32:03+00:00,[],2025-02-04 20:30:33+00:00,,https://github.com/metabase/metabase/issues/48438,"[('Type:New Feature', ''), ('Administration/Impersonation', 'Role level security'), ('Database/Databricks', '')]",[],
2572351794,issue,closed,not_planned,Maps are being cut off during export,"### Describe the bug

When exporting maps, they are being truncated. 

### To Reproduce

![Image](https://github.com/user-attachments/assets/fca9051c-0156-4c54-ba06-e273716d61ec)
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Chrome  129.0.6668.60

### Severity

HIGH

### Additional context

This is a serious problem because maps represent fundamental functionality and need to be flawlessly available as PNG files. I noticed that this bug was reported a year ago but is marked as low priority. Why is that a low prio?",guthmpte,2024-10-08 07:36:15+00:00,[],2024-10-08 09:47:33+00:00,2024-10-08 09:17:53+00:00,https://github.com/metabase/metabase/issues/48436,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2399312295, 'issue_id': 2572351794, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/34753', 'created_at': datetime.datetime(2024, 10, 8, 9, 17, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399378535, 'issue_id': 2572351794, 'author': 'guthmpte', 'body': 'Hello,\r\n\r\nthanks for coming back to me. I am not an expert with Github, so pls. can\r\nyou explain what it means that the reported bug is not planned to be\r\nfixed?  Is there any other solution or is considered not to be relevant?\r\n\r\nThank \u200byo.\r\n\r\nMit freundlichen Grüßen,\r\n\r\nPeter Guthmann\r\nManaging Director | Geschäftsführer\r\n\r\n--\r\n\r\n\r\nAm Puls des Berliner Immobilienmarkts mit den wöchentlich aktualisierten\r\nGuthmann Reports.\r\n\r\n\r\nGuthmann Report <https://guthmann.estate/de/marktreport/berlin/>\r\n\r\n*Peter Guthmann*\r\n*Geschäftsführer*\r\n\r\nGuthmann Estate GmbH\r\nBlücherstraße 22\r\n10961 Berlin\r\nGermany\r\n\r\nPhone: +49 30 69004240 <00493069004240>\r\nMail: ***@***.***\r\nLinkedIn: linkedin.com/in/peter-guthmann/\r\n<https://www.linkedin.com/in/peter-guthmann/>\r\n\r\nWebsite: https://guthmann.estate\r\n<https://guthmann.estate/?utm_source=guthmann-estate&utm_medium=email&utm_campaign=signature>\r\nSocial Media: LinkedIn <https://www.linkedin.com/company/guthmannestate/> |\r\nFacebook <https://www.facebook.com/GuthmannEstate> | X\r\n<https://twitter.com/guthmannestate>\r\n\r\nGeschäftsführer: M.A. Peter Guthmann\r\nFirmensitz: Berlin, Germany\r\nAmtsgericht Berlin-Charlottenburg\r\nHR Nummer: HRB 129720\r\nUSt-ID: DE815223623\r\n\r\nAm 08. Okt 2024, 11:18 Uhr, schrieb Luis Paolini:\r\n\r\nduplicate of #34753 <https://github.com/metabase/metabase/issues/34753>\r\n\r\n—\r\nReply to this email directly, view it on GitHub\r\n<https://github.com/metabase/metabase/issues/48436#issuecomment-2399312295>,\r\nor unsubscribe\r\n<https://github.com/notifications/unsubscribe-auth/AYSKBRXAQDU6BUSTWLYUWADZ2OPNRAVCNFSM6AAAAABPRRIIDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGOJZGMYTEMRZGU>\r\n.\r\nYou are receiving this because you authored the thread.Message ID:\r\n***@***.***>', 'created_at': datetime.datetime(2024, 10, 8, 9, 47, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-08 09:17:53 UTC): duplicate of https://github.com/metabase/metabase/issues/34753

guthmpte (Issue Creator) on (2024-10-08 09:47:32 UTC): Hello,

thanks for coming back to me. I am not an expert with Github, so pls. can
you explain what it means that the reported bug is not planned to be
fixed?  Is there any other solution or is considered not to be relevant?

Thank ​yo.

Mit freundlichen Grüßen,

Peter Guthmann
Managing Director | Geschäftsführer

--


Am Puls des Berliner Immobilienmarkts mit den wöchentlich aktualisierten
Guthmann Reports.


Guthmann Report <https://guthmann.estate/de/marktreport/berlin/>

*Peter Guthmann*
*Geschäftsführer*

Guthmann Estate GmbH
Blücherstraße 22
10961 Berlin
Germany

Phone: +49 30 69004240 <00493069004240>
Mail: ***@***.***
LinkedIn: linkedin.com/in/peter-guthmann/
<https://www.linkedin.com/in/peter-guthmann/>

Website: https://guthmann.estate
<https://guthmann.estate/?utm_source=guthmann-estate&utm_medium=email&utm_campaign=signature>
Social Media: LinkedIn <https://www.linkedin.com/company/guthmannestate/> |
Facebook <https://www.facebook.com/GuthmannEstate> | X
<https://twitter.com/guthmannestate>

Geschäftsführer: M.A. Peter Guthmann
Firmensitz: Berlin, Germany
Amtsgericht Berlin-Charlottenburg
HR Nummer: HRB 129720
USt-ID: DE815223623

Am 08. Okt 2024, 11:18 Uhr, schrieb Luis Paolini:

duplicate of #34753 <https://github.com/metabase/metabase/issues/34753>

—
Reply to this email directly, view it on GitHub
<https://github.com/metabase/metabase/issues/48436#issuecomment-2399312295>,
or unsubscribe
<https://github.com/notifications/unsubscribe-auth/AYSKBRXAQDU6BUSTWLYUWADZ2OPNRAVCNFSM6AAAAABPRRIIDWVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGOJZGMYTEMRZGU>
.
You are receiving this because you authored the thread.Message ID:
***@***.***>

"
2572142656,issue,open,,Filter modal is out of sync with the query,"### Describe the bug

https://github.com/user-attachments/assets/65066f99-3c99-4f5d-9690-273e8352f61a


### To Reproduce

1. New > Question > Orders > join Reviews on Product ID = Product ID > Visualize
2. Open Filter modal and go to Products tab (either one)
3. Choose a Category filter and apply
4. Query is updated, filter pill is present
5. Open Filter modal and try to see the filter you applied

It's not there.

----

1. New > Question > Orders > join Reviews on Product ID = Product ID > Visualize
2. Open Filter modal and go to Products tab (either one)
3. Click ""Today""

It does not get selected

-----

1. New > Question > Orders > join Reviews on Product ID = Product ID > Visualize
2. Open Filter modal and go to Products tab (either one)
3. Try to add every filter in that tab
4. Navigate to a different tab and then go back to the Products tab

No filters are present

5. Hit Apply

All the filters are actually applied


### Information about your Metabase installation

master, cd4d764632

### Severity

P1 / P2
",kamilmielnik,2024-10-08 05:44:17+00:00,[],2025-02-04 20:27:16+00:00,,https://github.com/metabase/metabase/issues/48434,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2398909379, 'issue_id': 2572142656, 'author': 'kamilmielnik', 'body': ""It's a broken common feature, but the workaround is quite obvious (use notebook editor) and it's been broken since at least v49 so I'm demoting it to P2."", 'created_at': datetime.datetime(2024, 10, 8, 5, 50, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421038901, 'issue_id': 2572142656, 'author': 'ranquild', 'body': 'This is broken because MBQL lib fails to match field refs', 'created_at': datetime.datetime(2024, 10, 18, 1, 28, 50, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-08 05:50:59 UTC): It's a broken common feature, but the workaround is quite obvious (use notebook editor) and it's been broken since at least v49 so I'm demoting it to P2.

ranquild on (2024-10-18 01:28:50 UTC): This is broken because MBQL lib fails to match field refs

"
2571872172,issue,open,,[Epic] Alert UI Polish,"A collection of issues and adjustments found with the Alert UI after the addition of webhooks. These aren't regressions, but situations that may be more common now that there is a 3rd notification type (Email, Slack, and Webhook)

- [x] https://github.com/metabase/metabase/issues/48428
- [x] https://github.com/metabase/metabase/issues/48407
- [x] https://github.com/metabase/metabase/issues/48406
- [x] https://github.com/metabase/metabase/issues/48402
- [x] #48751
- [x] #48803
",npfitz,2024-10-08 02:10:41+00:00,['npfitz'],2024-10-23 21:03:23+00:00,,https://github.com/metabase/metabase/issues/48430,"[('.Epic', 'Feature Implementation or Project')]",[],
2571866505,issue,open,,Add linter to disallow `System/getenv` -- people should use `env/env` instead,,camsaul,2024-10-08 02:03:58+00:00,['camsaul'],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/48429,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Team/DevEx', '')]",[],
2571767256,issue,closed,completed,Alert Delete Modal doesn't show the name of webhooks when deleting the alert,"### Describe the bug

Alert Delete modal will simply show ""HTTP Channel"" for each webhook that is being deleted

### To Reproduce

Create an alert that uses webhooks
Delete it

### Expected behavior

Should render the names of the webhooks, not the name of the channel

### Logs

_No response_

### Information about your Metabase installation

Current Master
SHA 3964d71e021a7695cbdfc14422ccddf349153b99

### Severity

P2 - Doesn't affect functionality, but it's sloppy

### Additional context

_No response_",npfitz,2024-10-08 00:07:38+00:00,['npfitz'],2024-11-26 18:52:49+00:00,2024-10-08 18:47:38+00:00,https://github.com/metabase/metabase/issues/48428,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Alerts', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2571741829,issue,open,,Mapping a field as foreign key in Metabase model doesn't work,"### Describe the bug

In a Metabase model, if you configure a field with a foreign key to another table, the other model won't show when you click on filtering or grouping. Even auto join doesn't work. 

While all that works fine if you do the same on the underlying table for the Metabase model in table metadata in admin. 

In another word, foreign key mapping doesn't work when configured in Metabase model while it works fine when configured on tables. 

### To Reproduce

1. Create a Metabase model for a table and configure one field as a foreign key to another table
2. Try to use the model for filtering / grouping or join to the other table, notice the foreign key mapping isn't used (other table doesn't show or auto join does't happen). 


### Expected behavior

Foreign key mapping should work exactly the same as when mapped using table metadata in admin. 

### Logs

n/a

### Information about your Metabase installation

Master @ Postgres

### Severity

It reduces usability of Metabase models

### Additional context

_No response_",maxzheng,2024-10-07 23:47:28+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/48427,"[('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2540236236, 'issue_id': 2571741829, 'author': 'maxzheng', 'body': 'Bumped to P1 as it breaks a critical feature of models.', 'created_at': datetime.datetime(2024, 12, 12, 23, 51, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541300711, 'issue_id': 2571741829, 'author': 'mngr', 'body': ""Foreign key mapping doesn't work with models, it's a known limitation, subject to be implemented in [this project](https://www.notion.so/metabase/Foreign-key-mapping-between-models-1764637ef82c478db9c09a6a11a07140?pvs=4)"", 'created_at': datetime.datetime(2024, 12, 13, 12, 4, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541310306, 'issue_id': 2571741829, 'author': 'mngr', 'body': ""Or it's only about mapping the field from a table to a model? Did it work before?"", 'created_at': datetime.datetime(2024, 12, 13, 12, 9, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541890789, 'issue_id': 2571741829, 'author': 'maxzheng', 'body': ""@mngr This is for mapping a foreign key from model to table. Right now, model to table works fine if the mapping is done in table metadata in admin for both tables (table in model and foreign table), but it  doesn't work if you update the model's metadata to do the same mapping (from that model to the foreign table). I don't know if it ever worked before, but it feels like a bug to me -- model is able to inherit the foreign key mapping from table metadata in admin but can't use its own mapping in metadata."", 'created_at': datetime.datetime(2024, 12, 13, 17, 12, 32, tzinfo=datetime.timezone.utc)}]","maxzheng (Issue Creator) on (2024-12-12 23:51:58 UTC): Bumped to P1 as it breaks a critical feature of models.

mngr on (2024-12-13 12:04:49 UTC): Foreign key mapping doesn't work with models, it's a known limitation, subject to be implemented in [this project](https://www.notion.so/metabase/Foreign-key-mapping-between-models-1764637ef82c478db9c09a6a11a07140?pvs=4)

mngr on (2024-12-13 12:09:50 UTC): Or it's only about mapping the field from a table to a model? Did it work before?

maxzheng (Issue Creator) on (2024-12-13 17:12:32 UTC): @mngr This is for mapping a foreign key from model to table. Right now, model to table works fine if the mapping is done in table metadata in admin for both tables (table in model and foreign table), but it  doesn't work if you update the model's metadata to do the same mapping (from that model to the foreign table). I don't know if it ever worked before, but it feels like a bug to me -- model is able to inherit the foreign key mapping from table metadata in admin but can't use its own mapping in metadata.

"
2571688767,issue,open,,Add a linter telling people to name unused parameters like `_driver` instead of `_`,"Code is clearer when it's something like 

```clj
(defmethod driver.sql/default-database-role :redshift
  [_driver _database]
  ""DEFAULT"")
```

instead of 

```clj
(defmethod driver.sql/default-database-role :redshift
  [_ _]
  ""DEFAULT"")
```",camsaul,2024-10-07 23:04:20+00:00,['camsaul'],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/48426,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Team/DevEx', '')]",[],
2571661078,issue,closed,completed,Add Metrics to snowplow stat ping,"# Add Metrics info to Snowplow Stats Ping

The details are [in Notion](https://www.notion.so/metabase/Migrate-Anonymous-Stats-ping-to-Snowplow-18f155e235d34ba09f45518a866336e2?pvs=4#77eb4c912bd449b78b6b72a88d61a329).

This work is:

- [x] Adding the complete schema for everything in the stats ping.
- [x] Adding the data for metrics section to the stats ping.
- [x] Adding an expedited single grouped_metric to track embedding.",escherize,2024-10-07 22:46:02+00:00,['escherize'],2024-10-15 23:41:09+00:00,2024-10-15 20:47:13+00:00,https://github.com/metabase/metabase/issues/48424,"[('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2571492114,issue,open,,Add a prop to disable links to question title in interactive questions and dashboards in the sdk,Add a `disableQuestionTitleLinks` prop to the `InteractiveQuestion` and `InteractiveDashboard` to disable links to questions and dashboards in the SDK.,heypoom,2024-10-07 21:15:13+00:00,[],2025-02-04 20:30:41+00:00,,https://github.com/metabase/metabase/issues/48418,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2570926918,issue,closed,completed,[Epic] Default to Is operator when there are field values,"Product doc https://www.notion.so/metabase/Default-to-Is-operator-when-there-are-field-values-a24ed42ad07244c3856777c3821e251f

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/48412
```",ranquild,2024-10-07 16:31:33+00:00,['ranquild'],2024-10-08 12:20:23+00:00,2024-10-08 12:20:22+00:00,https://github.com/metabase/metabase/issues/48409,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2570856958,issue,closed,completed,Select All follow-ups (dashboards),,ranquild,2024-10-07 15:57:42+00:00,['ranquild'],2024-10-11 02:57:13+00:00,2024-10-10 19:17:23+00:00,https://github.com/metabase/metabase/issues/48408,[],"[{'comment_id': 2397318045, 'issue_id': 2570856958, 'author': 'ranquild', 'body': 'Blocked until there is a green light on https://github.com/metabase/metabase/issues/48395', 'created_at': datetime.datetime(2024, 10, 7, 15, 58, 6, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-10-07 15:58:06 UTC): Blocked until there is a green light on https://github.com/metabase/metabase/issues/48395

"
2570850466,issue,closed,completed,Alert modal should not show Slack as a channel if it is not configured,"### Describe the bug

With an instance with no slack configured, we should not show it as an option when setting up an alert on a question. It's important to note that we want to continue to show Email as an option as a way to nudge users to set up email on their instance, as Metabase is far more usable that way.

### To Reproduce

1. Go to a question and start creating an alert
2. See Slack is showing as an option, but it is not configured on the instance


### Expected behavior

Slack should not be shown as an option

### Logs

_No response_

### Information about your Metabase installation

Current Master
SHA: d6eeaf1ec65d85e9afde0111231ecc7787873e77

### Severity

p3

### Additional context

_No response_",npfitz,2024-10-07 15:55:16+00:00,['npfitz'],2024-11-26 18:52:49+00:00,2024-10-08 18:47:38+00:00,https://github.com/metabase/metabase/issues/48407,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Alerts', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2570840426,issue,closed,completed,Should not be able to save alerts that enable unconfigured channels,"### Describe the bug

If you have an instance where a slack channel is not set up, and then go to create an alert, it's possible to get into a state where you can never update your alert

### To Reproduce

1. Go to a question an open the alert modal
2. Enable and Disable slack, then create an alert as you normally would (email or webhook)
3. Save the alert, then go to edit it, you'll notice that the save button is disabled. Nothing you do will make it clickable


### Expected behavior

You should be able to edit the alert and save updates

### Logs

_No response_

### Information about your Metabase installation

Current master
SHA: d6eeaf1ec65d85e9afde0111231ecc7787873e77

### Severity

p2

### Additional context

Workaround is to delete your alert and make another one",npfitz,2024-10-07 15:51:13+00:00,['npfitz'],2024-10-23 22:27:29+00:00,2024-10-23 21:03:22+00:00,https://github.com/metabase/metabase/issues/48406,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Alerts', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2570761460,issue,closed,completed,Alert Delete modal shows channels that aren't actually active,"### Describe the bug

When deleting an alert, you are required to acknowledge all channels that will no longer receive the alert. However, the modal tends to show an incorrect list of channels.

### To Reproduce

1. Go to a question and set up an alert
2. In the alert modal, enable and disable a few channels, but only leave 1 active (like a webhook)
3. Save the alert, then re-open the modal and hit delete
4. The list in the delete modal has channels that are not actually active


### Expected behavior

The modal should only show channels that are actually used.

### Logs

_No response_

### Information about your Metabase installation

Master Branch
SHA: `d6eeaf1ec65d85e9afde0111231ecc7787873e77`

### Severity

p2

### Additional context

_No response_",npfitz,2024-10-07 15:18:14+00:00,['npfitz'],2024-11-26 18:52:50+00:00,2024-10-08 18:47:39+00:00,https://github.com/metabase/metabase/issues/48402,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2570537089,issue,open,,static viz doesn't work on jvm 23,"### Describe the bug

static viz fails on jvm 23

### To Reproduce

```
❯ java -version
openjdk version ""23"" 2024-09-17
OpenJDK Runtime Environment Temurin-23+37 (build 23+37)
OpenJDK 64-Bit Server VM Temurin-23+37 (build 23+37, mixed mode, sharing)

❯ clj -X:dev:test :only metabase.pulse.render.js-svg-test
Running tests with options {:mode :cli/local, :namespace-pattern #""^(?:(?:metabase.*)|(?:hooks\..*))"", :exclude-directories ["".clj-kondo/src"" ""classes"" ""dev"" ""enterprise/backend/src"" ""local"" ""resources"" ""resources-ee"" ""src"" ""target"" ""test_config"" ""test_resources""], :test-warn-time 3000, :only metabase.pulse.render.js-svg-test}
Running tests in metabase.pulse.render.js-svg-test
Reflection warning, clojurewerkz/quartzite/triggers.clj:85:6 - call to method forJob on org.quartz.TriggerBuilder can't be resolved (argument types: unknown).
Reflection warning, clojurewerkz/quartzite/scheduler.clj:254:3 - call to method checkExists on org.quartz.Scheduler can't be resolved (argument types: unknown).
{:clojure.main/message
 ""Execution error (NoSuchMethodError) at com.oracle.truffle.api.library.LibraryFactory/ensureLibraryInitialized (LibraryFactory.java:384).\n'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'\n"",
```

<details>
<summary> full stacktrace </summary>

```
❯ clj -X:dev:test :only metabase.pulse.render.js-svg-test
Running tests with options {:mode :cli/local, :namespace-pattern #""^(?:(?:metabase.*)|(?:hooks\..*))"", :exclude-directories ["".clj-kondo/src"" ""classes"" ""dev"" ""enterprise/backend/src"" ""local"" ""resources"" ""resources-ee"" ""src"" ""target"" ""test_config"" ""test_resources""], :test-warn-time 3000, :only metabase.pulse.render.js-svg-test}
Running tests in metabase.pulse.render.js-svg-test
Reflection warning, clojurewerkz/quartzite/triggers.clj:85:6 - call to method forJob on org.quartz.TriggerBuilder can't be resolved (argument types: unknown).
Reflection warning, clojurewerkz/quartzite/scheduler.clj:254:3 - call to method checkExists on org.quartz.Scheduler can't be resolved (argument types: unknown).
{:clojure.main/message
 ""Execution error (NoSuchMethodError) at com.oracle.truffle.api.library.LibraryFactory/ensureLibraryInitialized (LibraryFactory.java:384).\n'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'\n"",
 :clojure.main/triage
 {:clojure.error/class java.lang.NoSuchMethodError,
  :clojure.error/line 384,
  :clojure.error/cause ""'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'"",
  :clojure.error/symbol com.oracle.truffle.api.library.LibraryFactory/ensureLibraryInitialized,
  :clojure.error/source ""LibraryFactory.java"",
  :clojure.error/phase :execution},
 :clojure.main/trace
 {:via
  [{:type clojure.lang.Compiler$CompilerException,
    :message ""Syntax error macroexpanding at (js_svg_test.clj:53:23)."",
    :data
    {:clojure.error/phase :execution,
     :clojure.error/line 53,
     :clojure.error/column 23,
     :clojure.error/source ""js_svg_test.clj""},
    :at [clojure.lang.Compiler$InvokeExpr eval ""Compiler.java"" 4183]}
   {:type java.lang.NoSuchMethodError,
    :message ""'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'"",
    :at [com.oracle.truffle.api.library.LibraryFactory ensureLibraryInitialized ""LibraryFactory.java"" 384]}],
  :trace
  [[com.oracle.truffle.api.library.LibraryFactory ensureLibraryInitialized ""LibraryFactory.java"" 384]
   [com.oracle.truffle.api.library.LibraryFactory getUncached ""LibraryFactory.java"" 364]
   [com.oracle.truffle.api.library.LibraryFactory <init> ""LibraryFactory.java"" 210]
   [com.oracle.truffle.api.interop.InteropLibraryGen <init> ""InteropLibraryGen.java"" 175]
   [com.oracle.truffle.api.interop.InteropLibraryGen <clinit> ""InteropLibraryGen.java"" 166]
   [java.lang.Class forName0 ""Class.java"" -2]
   [java.lang.Class forName ""Class.java"" 578]
   [java.lang.Class forName ""Class.java"" 557]
   [com.oracle.truffle.api.library.LibraryFactory loadGeneratedClass ""LibraryFactory.java"" 791]
   [com.oracle.truffle.api.library.LibraryFactory resolveImpl ""LibraryFactory.java"" 740]
   [com.oracle.truffle.api.library.LibraryFactory resolve ""LibraryFactory.java"" 733]
   [com.oracle.truffle.api.interop.InteropLibrary <clinit> ""InteropLibrary.java"" 2873]
   [com.oracle.truffle.polyglot.PolyglotValueDispatch <clinit> ""PolyglotValueDispatch.java"" 156]
   [com.oracle.truffle.polyglot.PolyglotImpl initialize ""PolyglotImpl.java"" 166]
   [org.graalvm.polyglot.impl.AbstractPolyglotImpl setConstructors ""AbstractPolyglotImpl.java"" 271]
   [org.graalvm.polyglot.Engine$1 loadAndValidateProviders ""Engine.java"" 940]
   [org.graalvm.polyglot.Engine$1 run ""Engine.java"" 900]
   [org.graalvm.polyglot.Engine$1 run ""Engine.java"" 894]
   [java.security.AccessController doPrivileged ""AccessController.java"" 319]
   [org.graalvm.polyglot.Engine initEngineImpl ""Engine.java"" 894]
   [org.graalvm.polyglot.Engine$ImplHolder <clinit> ""Engine.java"" 139]
   [org.graalvm.polyglot.Engine getImpl ""Engine.java"" 363]
   [org.graalvm.polyglot.Engine$Builder build ""Engine.java"" 621]
   [org.graalvm.polyglot.Context$Builder build ""Context.java"" 1851]
   [metabase.pulse.render.js_engine$context invokeStatic ""js_engine.clj"" 29]
   [metabase.pulse.render.js_engine$context invoke ""js_engine.clj"" 26]
   [metabase.pulse.render.js_svg$fn__79343 invokeStatic ""js_svg.clj"" 41]
   [metabase.pulse.render.js_svg$fn__79343 invoke ""js_svg.clj"" 41]
   [clojure.lang.Delay realize ""Delay.java"" 44]
   [clojure.lang.Delay deref ""Delay.java"" 59]
   [clojure.core$deref invokeStatic ""core.clj"" 2337]
   [clojure.core$deref invoke ""core.clj"" 2323]
   [metabase.pulse.render.js_svg$context invokeStatic ""js_svg.clj"" 47]
   [metabase.pulse.render.js_svg$context invoke ""js_svg.clj"" 43]
   [clojure.lang.AFn applyToHelper ""AFn.java"" 152]
   [clojure.lang.AFn applyTo ""AFn.java"" 144]
   [clojure.lang.Var applyTo ""Var.java"" 707]
   [clojure.lang.Compiler$InvokeExpr eval ""Compiler.java"" 4178]
   [clojure.lang.Compiler$DefExpr eval ""Compiler.java"" 464]
   [clojure.lang.Compiler eval ""Compiler.java"" 7705]
   [clojure.lang.Compiler load ""Compiler.java"" 8165]
   [clojure.lang.RT loadResourceScript ""RT.java"" 401]
   [clojure.lang.RT loadResourceScript ""RT.java"" 392]
   [clojure.lang.RT load ""RT.java"" 479]
   [clojure.lang.RT load ""RT.java"" 444]
   [clojure.core$load$fn__6931 invoke ""core.clj"" 6189]
   [clojure.core$load invokeStatic ""core.clj"" 6188]
   [clojure.core$load doInvoke ""core.clj"" 6172]
   [clojure.lang.RestFn invoke ""RestFn.java"" 411]
   [clojure.core$load_one invokeStatic ""core.clj"" 5961]
   [clojure.core$load_one invoke ""core.clj"" 5956]
   [clojure.core$load_lib$fn__6873 invoke ""core.clj"" 6003]
   [clojure.core$load_lib invokeStatic ""core.clj"" 6002]
   [clojure.core$load_lib doInvoke ""core.clj"" 5981]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 145]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$load_libs invokeStatic ""core.clj"" 6044]
   [clojure.core$load_libs doInvoke ""core.clj"" 6028]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 140]
   [clojure.core$apply invokeStatic ""core.clj"" 669]
   [clojure.core$require invokeStatic ""core.clj"" 6066]
   [clojure.core$require doInvoke ""core.clj"" 6066]
   [clojure.lang.RestFn invoke ""RestFn.java"" 411]
   [mb.hawk.core$load_test_namespace invokeStatic ""core.clj"" 70]
   [mb.hawk.core$load_test_namespace invoke ""core.clj"" 68]
   [mb.hawk.core$find_tests_for_namespace_symbol invokeStatic ""core.clj"" 99]
   [mb.hawk.core$find_tests_for_namespace_symbol invoke ""core.clj"" 97]
   [mb.hawk.core$eval22445$fn__22446 invoke ""core.clj"" 116]
   [clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
   [mb.hawk.core$find_tests_with_options invokeStatic ""core.clj"" 130]
   [mb.hawk.core$find_tests_with_options invoke ""core.clj"" 123]
   [mb.hawk.core$find_and_run_tests_with_options invokeStatic ""core.clj"" 228]
   [mb.hawk.core$find_and_run_tests_with_options invoke ""core.clj"" 223]
   [mb.hawk.core$find_and_run_tests_cli invokeStatic ""core.clj"" 266]
   [mb.hawk.core$find_and_run_tests_cli invoke ""core.clj"" 258]
   [metabase.test_runner$find_and_run_tests_cli invokeStatic ""test_runner.clj"" 104]
   [metabase.test_runner$find_and_run_tests_cli invoke ""test_runner.clj"" 101]
   [clojure.lang.Var invoke ""Var.java"" 386]
   [clojure.run.exec$exec invokeStatic ""exec.clj"" 89]
   [clojure.run.exec$exec invoke ""exec.clj"" 78]
   [clojure.run.exec$_main$fn__21223 invoke ""exec.clj"" 228]
   [clojure.run.exec$_main invokeStatic ""exec.clj"" 224]
   [clojure.run.exec$_main doInvoke ""exec.clj"" 192]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 140]
   [clojure.lang.Var applyTo ""Var.java"" 707]
   [clojure.core$apply invokeStatic ""core.clj"" 667]
   [clojure.main$main_opt invokeStatic ""main.clj"" 515]
   [clojure.main$main_opt invoke ""main.clj"" 511]
   [clojure.main$main invokeStatic ""main.clj"" 665]
   [clojure.main$main doInvoke ""main.clj"" 617]
   [clojure.lang.RestFn applyTo ""RestFn.java"" 140]
   [clojure.lang.Var applyTo ""Var.java"" 707]
   [clojure.main main ""main.java"" 40]],
  :cause ""'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'"",
  :phase :execution}}

Execution error (NoSuchMethodError) at com.oracle.truffle.api.library.LibraryFactory/ensureLibraryInitialized (LibraryFactory.java:384).
'void sun.misc.Unsafe.ensureClassInitialized(java.lang.Class)'
```
</detail>

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

master, jvm 23

### Severity

p2

### Additional context

_No response_",dpsutton,2024-10-07 14:00:50+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/48396,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2397065819, 'issue_id': 2570537089, 'author': 'piranha', 'body': ""well this seems like JVM 23 needs a newer version of truffle; but we cannot update since it doesn't support java 11..."", 'created_at': datetime.datetime(2024, 10, 7, 14, 18, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596842978, 'issue_id': 2570537089, 'author': 'paoliniluis', 'body': 'GraalVM was just upgraded to support Java 23', 'created_at': datetime.datetime(2025, 1, 16, 20, 36, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598098152, 'issue_id': 2570537089, 'author': 'piranha', 'body': 'Still requires Java 17+, we should actually get back to the issue of dropping support for Java 11 I think.', 'created_at': datetime.datetime(2025, 1, 17, 11, 8, 22, tzinfo=datetime.timezone.utc)}]","piranha on (2024-10-07 14:18:19 UTC): well this seems like JVM 23 needs a newer version of truffle; but we cannot update since it doesn't support java 11...

paoliniluis on (2025-01-16 20:36:55 UTC): GraalVM was just upgraded to support Java 23

piranha on (2025-01-17 11:08:22 UTC): Still requires Java 17+, we should actually get back to the issue of dropping support for Java 11 I think.

"
2570512903,issue,closed,completed,Select All follow-ups (QB),,ranquild,2024-10-07 13:52:27+00:00,['ranquild'],2024-10-08 16:13:22+00:00,2024-10-07 22:46:48+00:00,https://github.com/metabase/metabase/issues/48395,"[('.Team/Querying', '')]",[],
2570501616,issue,closed,completed,[Epic] Select All follow-ups,"Product doc https://www.notion.so/metabase/Select-All-follow-ups-11569354c90180acbf3fff813e26b524
Figma https://www.figma.com/design/pq7Dv7P1lFfXCjI7Wbk8MQ/maz-filters-beautification-idea-sep-2024?node-id=14-262&node-type=section&t=KCBCEY17JahJUw4c-0

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/48398
- [ ] https://github.com/metabase/metabase/issues/48395
- [ ] https://github.com/metabase/metabase/issues/48408
```",ranquild,2024-10-07 13:48:00+00:00,['ranquild'],2024-10-11 03:08:43+00:00,2024-10-11 03:08:43+00:00,https://github.com/metabase/metabase/issues/48394,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2570437137,issue,open,,Ability to set default visibility for pivot table subtotals,"**Is your feature request related to a problem? Please describe.**
Sometimes, Pivot table subtotals will all be open, and others will be closed.

**Describe the solution you'd like**
A customer would want to define a default behavior for subtotals

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal notes [here](https://www.notion.so/metabase/Ellucian-2becbc478e6d49eda446143081a2e820?pvs=4#11369354c90180f08642d776c4e23295).

**Additional context**
N/A
",ignacio-mb,2024-10-07 13:23:30+00:00,[],2025-02-04 20:31:54+00:00,,https://github.com/metabase/metabase/issues/48393,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]",[],
2569563193,issue,closed,completed,Migrate build from depstar,"We should migrate from depstar since it's deprecated and, in particular, prevents updating `org.flatland/ordered`.",piranha,2024-10-07 07:17:02+00:00,['camsaul'],2025-01-27 22:14:26+00:00,2024-11-27 15:32:44+00:00,https://github.com/metabase/metabase/issues/48390,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/DevEx', '')]",[],
2568614818,issue,closed,not_planned,[ABANDONED] Embedding Onboarding Checklist,"## Links
- [Product doc](https://www.notion.so/metabase/Better-Onboarding-via-first-time-UX-7c76eef94d414bb0a864d7cc786229f2)
- [Figma designs](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2701&node-type=canvas&m=dev)
- Feature branch: `better-onboarding-ux-ms4`

### Implementation Plan
TBD",nemanjaglumac,2024-10-06 11:39:29+00:00,[],2024-11-08 16:15:44+00:00,2024-11-08 16:15:37+00:00,https://github.com/metabase/metabase/issues/48388,[],"[{'comment_id': 2465160227, 'issue_id': 2568614818, 'author': 'nemanjaglumac', 'body': ""We're postponing this for later.\nNot planned in the current cycle."", 'created_at': datetime.datetime(2024, 11, 8, 16, 15, 37, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-11-08 16:15:37 UTC): We're postponing this for later.
Not planned in the current cycle.

"
2568614533,issue,closed,completed,[MS1] Admin Onboarding Checklist,"## Links
- [Product doc](https://www.notion.so/metabase/Better-Onboarding-via-first-time-UX-7c76eef94d414bb0a864d7cc786229f2)
- [Figma designs](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2701&node-type=canvas&m=dev)
    - [Admin view](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6364-30843&m=dev)
- Feature branch: `onboarding-checklist-admins`

### Implementation Plan
Introduce a new page/route dedicated to better onboarding in the form of a checklist. ""How to use Metabase"" link should open this page from the main sidebar.

```[tasklist]
### Checklist
- [x] New item in the sidebar
- [x] New (admin guarded) route
- [x] Admin view
- [x] Tailored accordion component
- [x] Remember last visited accordion item
- [x] Smooth scroll opened item into view
- [x] Analytics
```

```[tasklist]
### Potential follow-ups (will be converted to individual sub-issues)
- [ ] Make user control whether or not to show the ""How to use Metabase"" link, rather than the logic being time-based
- [ ] Get rid of CSS accordion hacks
- [ ] Use Loom instead of YouTube for the tutorial videos?
- [ ] Copy adjustment
```",nemanjaglumac,2024-10-06 11:38:45+00:00,['nemanjaglumac'],2024-10-30 08:22:50+00:00,2024-10-28 19:58:04+00:00,https://github.com/metabase/metabase/issues/48387,[],[],
2567490089,issue,closed,completed,[MS1] Better Onboarding: Testing Plan,"# Testing plan for [MS1](https://github.com/metabase/metabase/issues/48335)

## New onboarding section in the main sidebar
### Dimensions
- User action
    - Add a database
    - Upload a spreadsheet
- CSV upload action type
    - create
    - append
    - replace
- Admin Settings
    - Did user already add database
    - Is upload enabled
- Permissions
    - admin
    - non-admin
- Visual real estate on screen
    - Very narrow screen (mobile)
    - Small height or a very busy sidebar
    - Interaction with other UI elements, such as ""What's new"" status
- ""How to use Metabase"" link
- Metabase plan/features
    - DWH enabled
    - Enterprise (whitelabelling - e.g. custom Metabase name)
",nemanjaglumac,2024-10-04 22:27:50+00:00,['nemanjaglumac'],2024-10-10 12:07:23+00:00,2024-10-08 17:40:59+00:00,https://github.com/metabase/metabase/issues/48380,"[('.TestingStrategy/FE', '')]",[],
2567144531,issue,open,,Support Athena-style date coercion,"**Context**
https://github.com/metabase/metabase/issues/21133#issuecomment-2319830308

This is like an inverted coercion, when we cast the filter value rather than the db field.

",luizarakaki,2024-10-04 19:17:17+00:00,[],2025-02-04 20:23:51+00:00,,https://github.com/metabase/metabase/issues/48374,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2567114969,issue,open,,Let users require filter on a field on all MBQL queries,"**Context**
[Product doc](https://www.notion.so/metabase/Let-users-require-filter-on-a-field-on-all-MBQL-queries-11569354c90180c7b1ebdf6a24c1f4bf?pvs=4)

- issue links:
- https://github.com/metabase/metabase/issues/37185
- https://github.com/metabase/metabase/issues/26627
",luizarakaki,2024-10-04 19:04:11+00:00,[],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/48373,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2567086600,issue,open,,Sync Hive partitioned tables on BigQuery,"- issue links:https://github.com/metabase/metabase/issues/40569

",luizarakaki,2024-10-04 18:50:49+00:00,[],2025-02-04 20:23:46+00:00,,https://github.com/metabase/metabase/issues/48372,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2567081733,issue,open,,Automatically hide partition tables and show only the main table,"**Context**
Tables can be partitioned in Postgres. While users usually query only the main table, we still sync and show all partitions.
We should still sync these partitions, but hide them by default.

- issue links: https://github.com/metabase/metabase/issues/28437

",luizarakaki,2024-10-04 18:49:07+00:00,[],2025-02-04 20:23:49+00:00,,https://github.com/metabase/metabase/issues/48371,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2567075538,issue,open,,Expose `_PARTITIONTIME` and `_PARTITIONDATE` as normal fields,"**Context**
When users create ingest-time partitioned tables, two pseudocolumns are created: partitiontime and partitiondate. https://cloud.google.com/bigquery/docs/querying-partitioned-tables#query_an_ingestion-time_partitioned_table

We should expose these columns in the UI so users can filter by them.
In some cases, users configure BigQuery so it is mandatory to filter by these partitions.

- issue links: https://github.com/metabase/metabase/issues/5904

",luizarakaki,2024-10-04 18:46:02+00:00,[],2025-02-04 20:23:51+00:00,,https://github.com/metabase/metabase/issues/48370,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2567066309,issue,open,,[Epic] Support Partitions,,luizarakaki,2024-10-04 18:41:43+00:00,[],2025-02-04 20:25:20+00:00,,https://github.com/metabase/metabase/issues/48368,"[('Database/Postgres', None), ('Database/BigQuery', ''), ('.Epic', 'Feature Implementation or Project'), ('Database/Athena', ''), ('.Team/Drivers', '')]",[],
2566855811,issue,closed,not_planned,[Epic] Tool to migrate questions into dashboards,"[Product doc](https://www.notion.so/metabase/Tool-to-migrate-questions-into-dashboards-11569354c90180b08c4af2662aaf34a8)

- [ ] BE endpoint to get movable questions
- [ ] BE endpoint to move questions
- [ ] FE component to move questions
- [ ] FE callout using the new key-value pair",luizarakaki,2024-10-04 17:16:58+00:00,[],2025-01-17 17:43:33+00:00,2025-01-17 17:43:33+00:00,https://github.com/metabase/metabase/issues/48364,"[('.Epic', 'Feature Implementation or Project')]",[],
2566854594,issue,open,,[Epic] Collections improvements,"adding all the filters, sorting, etc to collection page's table

[product doc: Add filters to tables and improve sorting](https://www.notion.so/metabase/Add-filters-to-tables-and-improve-sorting-8d6847864c87483fb2e6e8579b738853)",luizarakaki,2024-10-04 17:16:31+00:00,[],2024-11-13 18:41:39+00:00,,https://github.com/metabase/metabase/issues/48363,"[('.Epic', 'Feature Implementation or Project')]",[],
2566853158,issue,closed,not_planned,[Epic] Alerts redesign,,luizarakaki,2024-10-04 17:16:12+00:00,[],2024-11-13 18:15:29+00:00,2024-11-13 18:15:29+00:00,https://github.com/metabase/metabase/issues/48362,"[('.Epic', 'Feature Implementation or Project')]",[],
2566799584,issue,open,,"Showing percentages and labels on sunburst chart removes everything, since string is now too long to fit","Our generic logic is to hide data labels when the string is too long to fit in the area on a chart. This works most of the time, but now with the new sunburst, if you toggle on showing data labels on the chart, and leave labels toggled on, you are almost always guaranteed to get nothing. This feels like an unexpected / footgun situation.

My expectation would be to truncate the strings based on available space. That would probably have avoided a lot of confusion.

For more context this was 3) in [this thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1727976022922249).

![Image](https://github.com/user-attachments/assets/db41970d-0bc9-4a93-9723-cbf3dab2cb94)
",cdeweyx,2024-10-04 16:56:58+00:00,[],2025-02-04 20:31:28+00:00,,https://github.com/metabase/metabase/issues/48361,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2566703340,issue,closed,completed,Incorrect Breakouts Generated for Multi Series Viz When Question is Edited,"### Describe the bug

If you have a line chart with a breakout series on the x-axis, then edit the underlying question to add another aggregate, the new aggregate will also be displayed as a y-axis breakout in the viz settings under certain conditions.

This become more impactful when you edit the Question again. The GUI editor hangs when you try to add more aggregates and the question completely breaks. You can refresh the page, but if it doesn't occur to you to do that you feel pretty stuck. Creating a new question just drops you on the notebook editor error page.

https://www.loom.com/share/718c7fea292748f1951592641c55de08?sid=a45aa9cb-f1cd-4548-a549-2553b055bdfb

### To Reproduce

1. Create a question on Sample Product table: sum of price group by by date and category
2. Change viz type to line viz
3. Confirm that X-Axis has ""Created at"" with a breakout of ""Category""
4. Note that y-axis has ""Sum of Price""
5. Save
6. Go back to question editor and add ""Sum of Rating""
7. Click ""Visualize"" and note that there are breakouts for X and Y axis
8. Save it / replace original
9. Refresh
10. Open notebook editor and try to add a new aggregate

### Expected behavior

GUI editor should work. Breakouts should be generated correctly. The notebook editor should be accessible from the ""New"" button after an error like this.

### Logs

_No response_

### Information about your Metabase installation

50.26

### Severity

annoying

### Additional context

This one technically has work arounds but it was really elusive and difficult to reproduce. It also makes ""new question"" feel broken and inaccessible.",ixipixi,2024-10-04 16:03:45+00:00,['kamilmielnik'],2025-01-20 09:38:48+00:00,2025-01-20 07:50:35+00:00,https://github.com/metabase/metabase/issues/48358,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/', ''), ('.Team/Querying', '')]","[{'comment_id': 2396387350, 'issue_id': 2566703340, 'author': 'kamilmielnik', 'body': ""I can reproduce in 50.0.26.\nI cannot reproduce in 50.0.28.\nI cannot reproduce in master at https://github.com/metabase/metabase/commit/7c3f18ddcab9febc2b4d79eb64d6042d174959a9\n\nThis is a P1, but I'll give it a P2 because it seems that it's been fixed in 50.0.27 or 50.0.28.\nWe still need a repro test for it, so assigning Frontend label."", 'created_at': datetime.datetime(2024, 10, 7, 9, 23, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596893964, 'issue_id': 2566703340, 'author': 'ranquild', 'body': 'Repro only needed', 'created_at': datetime.datetime(2025, 1, 16, 21, 10, 5, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Assginee) on (2024-10-07 09:23:16 UTC): I can reproduce in 50.0.26.
I cannot reproduce in 50.0.28.
I cannot reproduce in master at https://github.com/metabase/metabase/commit/7c3f18ddcab9febc2b4d79eb64d6042d174959a9

This is a P1, but I'll give it a P2 because it seems that it's been fixed in 50.0.27 or 50.0.28.
We still need a repro test for it, so assigning Frontend label.

ranquild on (2025-01-16 21:10:05 UTC): Repro only needed

"
2566698996,issue,open,,Non-clickable items appearing to be clickable when hovering over them,"### Describe the bug

A customer reported that there are components in Metabase that are indicated as being clickable but are not.
https://www.loom.com/share/66150229a2a645748487d15d05871db5

### To Reproduce

Go to any component such as View Details that just displays text, hover over text, and see the hand appear as if it was clickable.

![Image](https://github.com/user-attachments/assets/4cf387ac-58d6-40c5-bfee-6c579cdf9cdd)


### Expected behavior

For non-clickable and non-drill through items to not appear as such.

### Logs

_No response_

### Information about your Metabase installation

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse"",
      ""sqlserver"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v1.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Chicago""
  }
}

### Severity

P3

### Additional context

_No response_",FilmonK,2024-10-04 16:01:03+00:00,[],2025-02-04 20:31:34+00:00,,https://github.com/metabase/metabase/issues/48356,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Detail', 'ObjectDetail'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2566640917,issue,open,,Conflicting token info in `token-features` vs `premium-features/token-status`,"### Describe the bug

We have slightly different information in these two values

```clojure
public-settings=> (count (token-features))
27
public-settings=> (-> (premium-features/token-status) :features count)
31
```

Note they have different shapes:

```clojure
public-settings=> (token-features)
{:config_text_file true,
 :sso_google true,
 :sso_jwt true,
 :llm_autodescription false,
 :cache_granular_controls true,
...}

public-settings=> (premium-features/token-status)
{:valid true,
 :status ""Token is valid."",
 :trial true,
 :valid-thru ""date""
 :plan-alias ""plan-alias"",
 :features [""snippet-collections""
            ""sso""
            ""sso-jwt""],
 :store-users [...]}
```

A way that won't _quite_ work:

```clojure
(defsetting token-features
  ""Features registered for this instance's token""
  :visibility :public
  :setter     :none
  :getter     (letfn [(normalize [k] (-> k name (str/replace ""-"" ""_"") (str/replace ""?"" """") keyword))]
                (let [setting-names (into #{}
                                          (comp (filter setting/registered?)
                                                (filter (fn [s]
                                                          (-> s keyword setting/resolve-setting
                                                              :visibility #{:public}))))
                                          (keys (ns-publics 'metabase.public-settings.premium-features)))]
                  (fn []
                    (into {} (for [binding setting-names
                                   :let [setting (setting/resolve-setting (keyword binding))]]
                               [(normalize binding) ((:getter setting))])))))
  :doc        false)
```

This way to automatically get all public settings from premium-settings (and the `define-premium-feature` macro makes public settings) is close but not quite right. Note that the keys used in `token-features` is different from the setting name:

```clojure
:email_allow_list               (premium-features/enable-email-allow-list?)
:hosting                        (premium-features/is-hosted?)
:query_reference_validation     (premium-features/enable-query-reference-validation?)
```

This map is used on the FE in order to set the UI for what features are available, so changing these setting names is probably annoying and reward free. Maybe a test that asserts `(= (count (token-features)) (-> (premium-features/token-status) :features count))` could be more helpful.

As of this writing, the two not used are `#{enable-serialization? enable-enhancements?}`. 

```clojure
(let [used (into #{} (map (comp symbol name first))
                 (vals '{:advanced_permissions           (premium-features/enable-advanced-permissions?)
                         :attached_dwh                   (premium-features/has-attached-dwh?)
                         :audit_app                      (premium-features/enable-audit-app?)
                         :cache_granular_controls        (premium-features/enable-cache-granular-controls?)
                         :collection_cleanup             (premium-features/enable-collection-cleanup?)
                         :config_text_file               (premium-features/enable-config-text-file?)
                         :content_verification           (premium-features/enable-content-verification?)
                         :dashboard_subscription_filters (premium-features/enable-dashboard-subscription-filters?)
                         :disable_password_login         (premium-features/can-disable-password-login?)
                         :email_allow_list               (premium-features/enable-email-allow-list?)
                         :email_restrict_recipients      (premium-features/enable-email-restrict-recipients?)
                         :embedding                      (premium-features/hide-embed-branding?)
                         :embedding_sdk                  (premium-features/enable-embedding-sdk-origins?)
                         :hosting                        (premium-features/is-hosted?)
                         :official_collections           (premium-features/enable-official-collections?)
                         :query_reference_validation     (premium-features/enable-query-reference-validation?)
                         :sandboxes                      (premium-features/enable-sandboxes?)
                         :scim                           (premium-features/enable-scim?)
                         :session_timeout_config         (premium-features/enable-session-timeout-config?)
                         :snippet_collections            (premium-features/enable-snippet-collections?)
                         :sso_google                     (premium-features/enable-sso-google?)
                         :sso_jwt                        (premium-features/enable-sso-jwt?)
                         :sso_ldap                       (premium-features/enable-sso-ldap?)
                         :sso_saml                       (premium-features/enable-sso-saml?)
                         :upload_management              (premium-features/enable-upload-management?)
                         :whitelabel                     (premium-features/enable-whitelabeling?)
                         :llm_autodescription            (premium-features/enable-llm-autodescription?)}))
      available (into #{}
                      (comp (filter setting/registered?)
                            (filter (fn [s]
                                      (-> s keyword setting/resolve-setting
                                          :visibility #{:public}))))
                      (keys (ns-publics 'metabase.public-settings.premium-features)))]
  (set/difference available used))
#{enable-serialization? enable-enhancements?}
```

### To Reproduce

see above

### Expected behavior

we should put all of these into the html?

### Logs

_No response_

### Information about your Metabase installation

master

### Severity

p3

### Additional context

```
❯ http get localhost:3000 | pup 'script#_metabaseBootstrap text{}' | jq '.""token-features""'
{
  ""config_text_file"": true,
  ""sso_google"": true,
  ""sso_jwt"": true,
  ""llm_autodescription"": false,
  ""cache_granular_controls"": true,
  ""email_restrict_recipients"": true,
  ""whitelabel"": true,
  ""sandboxes"": true,
  ""email_allow_list"": true,
  ""upload_management"": true,
  ""scim"": true,
  ""attached_dwh"": false,
  ""hosting"": false,
  ""session_timeout_config"": true,
  ""disable_password_login"": true,
  ""official_collections"": true,
  ""sso_saml"": true,
  ""embedding"": true,
  ""collection_cleanup"": true,
  ""sso_ldap"": true,
  ""content_verification"": true,
  ""dashboard_subscription_filters"": true,
  ""embedding_sdk"": true,
  ""advanced_permissions"": true,
  ""audit_app"": true,
  ""query_reference_validation"": true,
  ""snippet_collections"": true
}
```",dpsutton,2024-10-04 15:27:31+00:00,[],2025-02-05 19:18:00+00:00,,https://github.com/metabase/metabase/issues/48355,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2566624881,issue,closed,completed,Tell the sidesheets never to open on SDK,https://metaboat.slack.com/archives/C063Q3F1HPF/p1728026135262979,rafpaf,2024-10-04 15:18:42+00:00,['WiNloSt'],2024-10-17 07:20:19+00:00,2024-10-16 07:22:15+00:00,https://github.com/metabase/metabase/issues/48354,[],"[{'comment_id': 2397747741, 'issue_id': 2566624881, 'author': 'iethree', 'body': 'IMHO, we should disable the description entrypoint to sidesheets, not add a global behavior to disable certain components in the SDK', 'created_at': datetime.datetime(2024, 10, 7, 19, 44, 6, tzinfo=datetime.timezone.utc)}]","iethree on (2024-10-07 19:44:06 UTC): IMHO, we should disable the description entrypoint to sidesheets, not add a global behavior to disable certain components in the SDK

"
2566624670,issue,open,,Change LastEditInfo in question subhead so it doesn't open the sidesheet on click,https://metaboat.slack.com/archives/C063Q3F1HPF/p1728026135262979,rafpaf,2024-10-04 15:18:35+00:00,[],2024-10-04 15:19:53+00:00,,https://github.com/metabase/metabase/issues/48353,[],[],
2566606973,issue,open,,Several custom destinations on click,"**Is your feature request related to a problem? Please describe.**
Right now we open just a single custom destination when clicking on a chart in a dashboard, but a customer requested that we open a menu of places to click rather than just going to a single place as they want to build their own drilling

**Describe the solution you'd like**
The possibility of adding more destinations when you build a click behavior, so:
![Image](https://github.com/user-attachments/assets/85b44db9-8a0d-41af-b823-c1ec45390f53)

should allow the possibility of entering several dashboards or questions or URL's

**Describe alternatives you've considered**
none currently

**How important is this feature to you?**
It was a request of one of their customers to build their own custom drilling

**Additional context**
None
",paoliniluis,2024-10-04 15:09:09+00:00,[],2025-02-04 20:31:01+00:00,,https://github.com/metabase/metabase/issues/48352,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Reporting/Dashboards/Click Behavior', '')]",[],
2566565335,issue,closed,completed,Custom click behavior on a pivot table will go always to tab 1 on a destination dashboard with several tabs,"### Describe the bug

For some reason we always default to the first tab although you configure Metabase to go to tab number 3

### To Reproduce

1) create a pivot table and another question (the last one doesn't matter which question/viz is it)
2) create a dashboard and add the pivot table on tab 1
3) add 2 other tabs to the dashboard
4) create another dashboard, and in the new dashboard add 3 tabs and another question to tab number 3
5) create in the first dashboard a click behavior on the pivot to go to tab 3 of the second dashboard

see that the click always goes to tab number 1

### Expected behavior

Should go to the tab that we configured

### Logs

NA

### Information about your Metabase installation

v49.x

### Severity

P2

### Additional context

Reported by an enterprise customer",paoliniluis,2024-10-04 14:48:25+00:00,['ranquild'],2024-10-28 15:05:34+00:00,2024-10-28 13:52:21+00:00,https://github.com/metabase/metabase/issues/48351,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Reporting/Dashboards/Click Behavior', ''), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2396351982, 'issue_id': 2566565335, 'author': 'kamilmielnik', 'body': 'I can reproduce in v49 and v50.0.6, I cannot reproduce in `master` at 7c3f18ddcab9febc2b4d79eb64d6042d174959a9', 'created_at': datetime.datetime(2024, 10, 7, 9, 8, 3, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-10-07 09:08:03 UTC): I can reproduce in v49 and v50.0.6, I cannot reproduce in `master` at 7c3f18ddcab9febc2b4d79eb64d6042d174959a9

"
2566516814,issue,closed,completed,Sub totals don't work by default,"### Describe the bug

TBD, pending the repro from an enterprise customer

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

- v49.x

### Severity

P2

### Additional context

_No response_",paoliniluis,2024-10-04 14:25:22+00:00,[],2025-01-17 20:33:09+00:00,2025-01-17 20:33:08+00:00,https://github.com/metabase/metabase/issues/48349,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Visualization/Tables/old-pivoted', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2396942798, 'issue_id': 2566516814, 'author': 'ignacio-mb', 'body': 'Related to https://github.com/metabase/metabase/issues/48393', 'created_at': datetime.datetime(2024, 10, 7, 13, 30, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599144514, 'issue_id': 2566516814, 'author': 'paoliniluis', 'body': 'closing this one in favor of https://github.com/metabase/metabase/issues/52333', 'created_at': datetime.datetime(2025, 1, 17, 20, 33, 8, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-10-07 13:30:21 UTC): Related to https://github.com/metabase/metabase/issues/48393

paoliniluis (Issue Creator) on (2025-01-17 20:33:08 UTC): closing this one in favor of https://github.com/metabase/metabase/issues/52333

"
2566516522,issue,closed,completed,Banner to nudge admins to cleanup their collections,"Collection cleanup is a bit hidden now. We should nudge admins to cleanup their collections.

Add [this banner](https://www.figma.com/design/JIHSbaYBdXjkaNSivUG76T/Enable-saving-questions-directly-to-dashboards-and-make-this-the-default-path?node-id=860-5072&t=EOejdq1unahzgYSn-4)
![Image](https://github.com/user-attachments/assets/3f58834c-3f81-486d-82e0-08530c17664e)
(only with the "" Get rid of unused content"")

When?
- Only admins
- We show the banner until the admin clicks on ""Get rid of unused content"" or ""X""
- We show this banner on each collection
- Only show if there is anything to clean in that collection (with the default parameter to 3 months)

Unrelated change
- [ ] Whenever people open the cleanup modal, the default threshold value should be 3 months. It is 6 months now.

",luizarakaki,2024-10-04 14:25:13+00:00,['sloansparger'],2024-11-21 20:01:17+00:00,2024-11-21 17:20:44+00:00,https://github.com/metabase/metabase/issues/48348,"[('Type:New Feature', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2566500106,issue,open,,"Tooltip gets super long and cut off when lots of series in ""Other""","Tooltip with lots of series looks very bad and cuts off data, namely the total for the ""Other"" slice which is arguably the most important piece. Also happens for pie charts. [More context](https://metaboat.slack.com/archives/C064QMXEV9N/p1727987531630599?thread_ts=1727889819.006119&cid=C064QMXEV9N).

![Image](https://github.com/user-attachments/assets/8666487b-e6ce-4047-9c9b-24c8b4844284)
",cdeweyx,2024-10-04 14:17:58+00:00,[],2025-02-04 20:31:18+00:00,,https://github.com/metabase/metabase/issues/48347,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2566213299,issue,closed,completed,Disable last edit text opening sidebars in sdk,"<@U5A85JL4V> <@U01BP8Z3CVA> It looks like we accidentally surfaced the new sidesheet in the SDK? I think for now we should probably make sure it's hidden in the SDK component.

<https://metaboat.slack.com/archives/C063Q3F1HPF/p1728026135262979>

[Slack Message](https://metaboat.slack.com/archives/C064EB1UE5P/p1728033672858099?thread_ts=1728033672.858099&cid=C064EB1UE5P)",iethree,2024-10-04 12:04:26+00:00,[],2024-11-04 22:28:31+00:00,2024-10-28 13:55:35+00:00,https://github.com/metabase/metabase/issues/48345,"[('Bug:v51', 'bugs or regressions introduced in v51')]","[{'comment_id': 2441661473, 'issue_id': 2566213299, 'author': 'iethree', 'body': 'fixed by https://github.com/metabase/metabase/pull/48630', 'created_at': datetime.datetime(2024, 10, 28, 13, 55, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441667601, 'issue_id': 2566213299, 'author': 'WiNloSt', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/48354', 'created_at': datetime.datetime(2024, 10, 28, 13, 58, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-10-28 13:55:35 UTC): fixed by https://github.com/metabase/metabase/pull/48630

WiNloSt on (2024-10-28 13:58:00 UTC): Duplicate of https://github.com/metabase/metabase/issues/48354

"
2566207685,issue,open,,Allow rollout percentages to affect nightly and beta channels,,iethree,2024-10-04 12:01:21+00:00,[],2024-10-04 12:01:22+00:00,,https://github.com/metabase/metabase/issues/48344,[],[],
2565828920,issue,open,,Make the subscription emails send only the attachments,"**Is your feature request related to a problem? Please describe.**
A customer wants to edit the emails we send in the subscriptions. Their specific request was: ""What we would like to do is to remove most of the email content, change it to a simple text message, and keep only the attachment.""

**Describe the solution you'd like**
Maybe make the mustache files editable in the admin section (this could be a great starting point for https://github.com/metabase/metabase/issues/48047)?

**Describe alternatives you've considered**
Custom build

**How important is this feature to you?**
Requested by an enterprise customer

**Additional context**
NA",paoliniluis,2024-10-04 08:51:13+00:00,[],2025-02-06 15:01:33+00:00,,https://github.com/metabase/metabase/issues/48341,"[('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2410857820, 'issue_id': 2565828920, 'author': 'brunobergher', 'body': ""It's very likely our answer to this will be custom notification emails, similar to #42622, and not to add this specific knob."", 'created_at': datetime.datetime(2024, 10, 14, 10, 55, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411066264, 'issue_id': 2565828920, 'author': 'paoliniluis', 'body': 'Makes absolute sense @brunobergher', 'created_at': datetime.datetime(2024, 10, 14, 12, 17, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639297134, 'issue_id': 2565828920, 'author': 'fabiolanza', 'body': 'This is a very important feature and, in our view, must be implemented to make the e-mail subscription usable. Right now, the e-mails that are shared are not formatted well (especially with table and pivot table), and just makes it look unprofessional. There has to be an option to select the dashboard cards that should appear in the e-mail, allowing for none of them to be selected if desired. We have use cases where a simple line or pie chart would be good to show, and other use cases where just the attachment is needed.\n\nWe are a paying customer and I strongly recommend/vote for this to be implemented.\n\nCan we please have a comment from the product team on when we could see these capabilities released? Again, in our view, this is urgently needed.', 'created_at': datetime.datetime(2025, 2, 6, 9, 39, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2640071737, 'issue_id': 2565828920, 'author': 'brunobergher', 'body': 'Thank you for the input, Fábio!', 'created_at': datetime.datetime(2025, 2, 6, 15, 1, 31, tzinfo=datetime.timezone.utc)}]","brunobergher on (2024-10-14 10:55:50 UTC): It's very likely our answer to this will be custom notification emails, similar to #42622, and not to add this specific knob.

paoliniluis (Issue Creator) on (2024-10-14 12:17:57 UTC): Makes absolute sense @brunobergher

fabiolanza on (2025-02-06 09:39:29 UTC): This is a very important feature and, in our view, must be implemented to make the e-mail subscription usable. Right now, the e-mails that are shared are not formatted well (especially with table and pivot table), and just makes it look unprofessional. There has to be an option to select the dashboard cards that should appear in the e-mail, allowing for none of them to be selected if desired. We have use cases where a simple line or pie chart would be good to show, and other use cases where just the attachment is needed.

We are a paying customer and I strongly recommend/vote for this to be implemented.

Can we please have a comment from the product team on when we could see these capabilities released? Again, in our view, this is urgently needed.

brunobergher on (2025-02-06 15:01:31 UTC): Thank you for the input, Fábio!

"
2565808197,issue,open,,Allow connecting to Spark via an Apache Thrift server,"Seems that we don't allow this due to a missing dependency:
```
2024-10-04 10:51:51,276 ERROR driver.util :: Failed to connect to Database
java.lang.NoClassDefFoundError: org/apache/hadoop/hive/thrift/TFilterTransport
	at java.base/java.lang.ClassLoader.defineClass1(Native Method)
	at java.base/java.lang.ClassLoader.defineClass(ClassLoader.java:1022)
	at java.base/java.security.SecureClassLoader.defineClass(SecureClassLoader.java:174)
	at java.base/java.net.URLClassLoader.defineClass(URLClassLoader.java:555)
	at java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:458)
	at java.base/java.net.URLClassLoader$1.run(URLClassLoader.java:452)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:451)
	at clojure.lang.DynamicClassLoader.findClass(DynamicClassLoader.java:69)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)
	at clojure.lang.DynamicClassLoader.loadClass(DynamicClassLoader.java:77)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	at org.apache.hive.jdbc.HiveConnection.createBinaryTransport(HiveConnection.java:601)
	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:341)
	at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:228)
	at metabase.driver.hive_like.fixed_hive_connection.proxy$org.apache.hive.jdbc.HiveConnection$ff19274a.<init>(Unknown Source)
	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invokeStatic(fixed_hive_connection.clj:9)
	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invoke(fixed_hive_connection.clj:9)
	at metabase.driver.sparksql.SparkSQLDataSource.getConnection(sparksql.clj:98)
	at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372)
	at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274)
	at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111)
	at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093)
	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182)
	at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160)
	at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:326)
	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:323)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_$fn__51103.invoke(connection.clj:335)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__51085.invoke(connection.clj:311)
	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:309)
	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:305)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:334)
	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:330)
	at metabase.driver.sql_jdbc$fn__112703.invokeStatic(sql_jdbc.clj:49)
	at metabase.driver.sql_jdbc$fn__112703.invoke(sql_jdbc.clj:47)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.util$can_connect_with_details_QMARK_$fn__60013.invoke(util.clj:148)
	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
	at clojure.lang.AFn.call(AFn.java:18)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.thrift.TFilterTransport
	at java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)
	at clojure.lang.DynamicClassLoader.findClass(DynamicClassLoader.java:69)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)
	at clojure.lang.DynamicClassLoader.loadClass(DynamicClassLoader.java:77)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 47 more
```

Seems related to https://github.com/metabase/metabase/issues/47048 (?) and https://github.com/metabase/metabase/issues/46793 (?)

",paoliniluis,2024-10-04 08:40:32+00:00,[],2025-02-04 20:30:42+00:00,,https://github.com/metabase/metabase/issues/48340,"[('Type:New Feature', ''), ('Database/Spark', '')]",[],
2565793674,issue,closed,completed,`Lib.ensureFilterStage` does not add a stage when last stage has breakouts without aggregations,"### Describe the bug

There are 2 issues here, see this comment for the other one: https://github.com/metabase/metabase/issues/48339#issuecomment-2393449924

https://github.com/user-attachments/assets/ce310fb2-4092-4ccd-be20-86c683e8156a


### To Reproduce

1. New > Question > Orders > Aggregate by Count > Breakout by Created At: Month > New stage > Aggregate by Count
2. Visualize
3. Open filter modal

There are 2 ""Summaries"" groups

----

1. New > Question > Orders > Aggregate by Count > Breakout by Created At: Month > New stage > Breakout by Created At: Month
2. Visualize
3. Open filter modal

There are 2 ""Summaries"" groups

### Expected behavior

There are 3 ""Summaries"" groups

### Information about your Metabase installation

master, 40ed53e

### Severity

P2

### Additional context

Affects https://github.com/metabase/metabase/issues/47800 and https://github.com/metabase/metabase/issues/46519",kamilmielnik,2024-10-04 08:33:02+00:00,['appleby'],2024-10-25 16:06:09+00:00,2024-10-25 16:06:09+00:00,https://github.com/metabase/metabase/issues/48339,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2393165968, 'issue_id': 2565793674, 'author': 'uladzimirdev', 'body': '@kamilmielnik as I see in the method description\n\n> ""Adds an empty stage to `query` if its last stage contains both breakouts and aggregations.', 'created_at': datetime.datetime(2024, 10, 4, 8, 43, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393169537, 'issue_id': 2565793674, 'author': 'kamilmielnik', 'body': ""@uladzimirdev description matches how it works, but it's not how it should work :)"", 'created_at': datetime.datetime(2024, 10, 4, 8, 45, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393189308, 'issue_id': 2565793674, 'author': 'kamilmielnik', 'body': '> [@kamilmielnik](https://github.com/kamilmielnik) as I see in the method description\n> \n> > ""Adds an empty stage to `query` if its last stage contains both breakouts and aggregations.\n\nOk, adding filter stage does not make much sense when there are only aggregations and no breakouts, because in that case we will only ever get 1 result row. Filtering 1 row can technically give you 0 or 1 row though, so kind of makes sense. OTOH query builder does not allow adding another stage if last query stage only has aggregations. \n\nHowever adding filter stage definitely makes sense when there are breakouts but no aggregations, because in that case we will get multiple result rows. Query builder supports adding another stage if there are only breakouts in the last stage.\n\nSo the issue is valid.', 'created_at': datetime.datetime(2024, 10, 4, 8, 55, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393449924, 'issue_id': 2565793674, 'author': 'kamilmielnik', 'body': 'I tried to fix it myself but it\'s not as simple as changing `and` to `or` [here](https://github.com/metabase/metabase/blob/8b1f884/src/metabase/lib/stage.cljc#L415) as there are more issues at play.\n\n1. `git checkout 47219-dashboard-drills-tests`\n2. New > Question > Orders > Count > Save\n3. Add it to a dashboard\n4. Add Number filter to the dashboard and connect it to ""Count"" column\n5. Save\n6. Set filter value \n\nPOST `/api/dashboard/:id/dashcard/:id/card/:id/query` gives this error: `Cannot determine the source table or query for Field clause`\n\nIf you add one more stage to the query, then the filter will be applied to stage -2 instead of -1.\n\nInterestingly it works correctly if you drill into the question via dashcard header, so it looks like this issue is dashboard-specific.', 'created_at': datetime.datetime(2024, 10, 4, 11, 6, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2423351068, 'issue_id': 2565793674, 'author': 'metamben', 'body': 'I remember that I asked why we require both aggregation and breakout, and the answer was that it was by design.', 'created_at': datetime.datetime(2024, 10, 18, 23, 5, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427910836, 'issue_id': 2565793674, 'author': 'appleby', 'body': '> I remember that I asked why we require both aggregation and breakout, and the answer was that it was by design.\n\nLink to previous discussion:\n\nhttps://github.com/metabase/metabase/pull/46670#discussion_r1724048435', 'created_at': datetime.datetime(2024, 10, 21, 23, 20, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429142134, 'issue_id': 2565793674, 'author': 'kamilmielnik', 'body': 'Conversation with product team in Slack: https://metaboat.slack.com/archives/C0645JP1W81/p1729599523886239', 'created_at': datetime.datetime(2024, 10, 22, 12, 25, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429404622, 'issue_id': 2565793674, 'author': 'kamilmielnik', 'body': 'Conclusion: presence of breakouts in the last query stage is enough for `Lib.ensureFilterStage` to kick in and add an extra stage.\nIf there are aggregations but no breakouts - there should be no extra filter stage.', 'created_at': datetime.datetime(2024, 10, 22, 14, 12, 5, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-10-04 08:43:23 UTC): @kamilmielnik as I see in the method description

kamilmielnik (Issue Creator) on (2024-10-04 08:45:13 UTC): @uladzimirdev description matches how it works, but it's not how it should work :)

kamilmielnik (Issue Creator) on (2024-10-04 08:55:24 UTC): Ok, adding filter stage does not make much sense when there are only aggregations and no breakouts, because in that case we will only ever get 1 result row. Filtering 1 row can technically give you 0 or 1 row though, so kind of makes sense. OTOH query builder does not allow adding another stage if last query stage only has aggregations. 

However adding filter stage definitely makes sense when there are breakouts but no aggregations, because in that case we will get multiple result rows. Query builder supports adding another stage if there are only breakouts in the last stage.

So the issue is valid.

kamilmielnik (Issue Creator) on (2024-10-04 11:06:30 UTC): I tried to fix it myself but it's not as simple as changing `and` to `or` [here](https://github.com/metabase/metabase/blob/8b1f884/src/metabase/lib/stage.cljc#L415) as there are more issues at play.

1. `git checkout 47219-dashboard-drills-tests`
2. New > Question > Orders > Count > Save
3. Add it to a dashboard
4. Add Number filter to the dashboard and connect it to ""Count"" column
5. Save
6. Set filter value 

POST `/api/dashboard/:id/dashcard/:id/card/:id/query` gives this error: `Cannot determine the source table or query for Field clause`

If you add one more stage to the query, then the filter will be applied to stage -2 instead of -1.

Interestingly it works correctly if you drill into the question via dashcard header, so it looks like this issue is dashboard-specific.

metamben on (2024-10-18 23:05:37 UTC): I remember that I asked why we require both aggregation and breakout, and the answer was that it was by design.

appleby (Assginee) on (2024-10-21 23:20:45 UTC): Link to previous discussion:

https://github.com/metabase/metabase/pull/46670#discussion_r1724048435

kamilmielnik (Issue Creator) on (2024-10-22 12:25:21 UTC): Conversation with product team in Slack: https://metaboat.slack.com/archives/C0645JP1W81/p1729599523886239

kamilmielnik (Issue Creator) on (2024-10-22 14:12:05 UTC): Conclusion: presence of breakouts in the last query stage is enough for `Lib.ensureFilterStage` to kick in and add an extra stage.
If there are aggregations but no breakouts - there should be no extra filter stage.

"
2565783968,issue,closed,not_planned,Migration v49.00-015 cannot be run (on mysql) due to Cannot drop index 'idx_api_key_created_by',"### Describe the bug

I am using metabase with mysql as 2 docker containers. When updateing from image: metabase/metabase:v0.48.13 to image: metabase/metabase:v0.49.0 i got an error:

```
Cannot drop index 'idx_api_key_created_by': needed in a foreign key constraint [Failed SQL: (1553) ALTER TABLE `metabase`.`api_key` CHANGE `created_by` `creator_id` INT]
```

Same thing if I do a fresh install with image: metabase/metabase:v0.49.0

Not sure if this is related to mysql (image: mariadb:10.5.3 in my case) or a db setting. But this change cannot be applied 

```yaml
  - changeSet:
      id: v49.00-015
      author: johnswanson
      comment: Rename `created_by` to `creator_id`
      rollback: # not necessary, will be removed with the table
      changes:
        - renameColumn:
            tableName: api_key
            columnDataType: integer
            oldColumnName: created_by
            newColumnName: creator_id
´´´

https://github.com/metabase/metabase/blob/e2b74d79f620a01762e9afa81e21dd999a52a4fe/resources/migrations/001_update_migrations.yaml#L4699



How I solved if for now:

I removed the index fk_api_key_created_by_user_id

```sql
ALTER TABLE `api_key`
	DROP FOREIGN KEY `fk_api_key_created_by_user_id`;
```

Than ran the update again and it finished all migrations.
I readded the key with the name fk_api_key_creator_id_user_id

```sql
ALTER TABLE `api_key`
	ADD CONSTRAINT `fk_api_key_creator_id_user_id` FOREIGN KEY (`creator_id`) REFERENCES `core_user` (`id`) ON UPDATE RESTRICT ON DELETE RESTRICT;
```

And then ""renamed"" the idx_api_key_created_by like this. Strangly that index was already on the new field creator_id and not created_by anymore.
```sql
ALTER TABLE `api_key`
	DROP INDEX `idx_api_key_created_by`,
	ADD INDEX `idx_api_key_creator_id` (`creator_id`) USING BTREE;
```




### To Reproduce

1.  Use this docker-compose.yaml

```yaml
services:
  metabase:
    image: metabase/metabase:v0.49.0
    container_name: metabase
    depends_on:
      - metabasedb
    restart: unless-stopped
    ports:
      - ""3000:3000""
    environment:
      JAVA_TIMEZONE: ""Europe/Berlin""
      MB_DB_TYPE: mysql
      MB_DB_DBNAME: metabase
      MB_DB_PORT: 3306
      MB_DB_USER: metabase
      MB_DB_PASS: blablabla
      MB_DB_HOST: metabasedb
    volumes:
      - ""./services/metabase/data/:/metabase-data""

  metabasedb:
    image: mariadb:10.5.3
    container_name: metabasedb
    restart: unless-stopped
    ports:
      - ""3306:3306""
    environment:
      TZ: ""Europe/Berlin""
      MYSQL_ROOT_PASSWORD: ""blablablaroot""
      MYSQL_ALLOW_EMPTY_PASSWORD: ""no""
      MYSQL_USER: ""metabase""
      MYSQL_PASSWORD: ""blablabla""
      MYSQL_DATABASE: ""metabase""
    volumes:
      - ""./services/metabasedb/conf/conf.d/my.cnf:/etc/mysql/conf.d/my.cnf""
      - ""./services/metabasedb/data:/var/lib/mysql""

```

and this my.cnf

```
[client]
default-character-set = utf8mb4

[mysqld]
character-set-server = utf8mb4
collation-server     = utf8mb4_unicode_ci
character_set_server = utf8mb4
collation_server     = utf8mb4_unicode_ci
```

2. run `docker compose up -d`
3.. run `docker compose logs -f` and see the error message. The container keeps restarting and stopping.

### Expected behavior

THe migration should run without an error.

### Logs

_No response_

### Information about your Metabase installation

This is the file after the update:

```json
{
  ""browser-info"": {
    ""language"": ""de-DE"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-192-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Berlin""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.5.3-MariaDB-1:10.5.3+maria~focal""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```

### Severity

blocking if you use msyql/mariadb as the application database

### Additional context

_No response_",akarikuu,2024-10-04 08:27:51+00:00,[],2024-10-07 10:07:21+00:00,2024-10-07 10:07:20+00:00,https://github.com/metabase/metabase/issues/48338,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2393342649, 'issue_id': 2565783968, 'author': 'paoliniluis', 'body': 'What’s your MySQL database version? Btw: use 49.25', 'created_at': datetime.datetime(2024, 10, 4, 10, 7, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396158009, 'issue_id': 2565783968, 'author': 'akarikuu', 'body': 'I use a docker container from image: mariadb:10.5.3\n\nUsing 49.25 will still try and run this migration https://github.com/metabase/metabase/blob/e2b74d79f620a01762e9afa81e21dd999a52a4fe/resources/migrations/001_update_migrations.yaml#L4699 right? So the problem should be the same.', 'created_at': datetime.datetime(2024, 10, 7, 7, 41, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396487073, 'issue_id': 2565783968, 'author': 'paoliniluis', 'body': 'I have a feeling that the mariadb version was too old, but cool that you sorted it out', 'created_at': datetime.datetime(2024, 10, 7, 10, 7, 20, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-04 10:07:41 UTC): What’s your MySQL database version? Btw: use 49.25

akarikuu (Issue Creator) on (2024-10-07 07:41:18 UTC): I use a docker container from image: mariadb:10.5.3

Using 49.25 will still try and run this migration https://github.com/metabase/metabase/blob/e2b74d79f620a01762e9afa81e21dd999a52a4fe/resources/migrations/001_update_migrations.yaml#L4699 right? So the problem should be the same.

paoliniluis on (2024-10-07 10:07:20 UTC): I have a feeling that the mariadb version was too old, but cool that you sorted it out

"
2565711752,issue,closed,completed,MS 1.1: Add visual elements / components,,nemanjaglumac,2024-10-04 07:51:50+00:00,['nemanjaglumac'],2024-10-04 08:10:24+00:00,2024-10-04 07:54:50+00:00,https://github.com/metabase/metabase/issues/48336,[],"[{'comment_id': 2393070815, 'issue_id': 2565711752, 'author': 'nemanjaglumac', 'body': 'Resolved by #48202', 'created_at': datetime.datetime(2024, 10, 4, 7, 54, 50, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-10-04 07:54:50 UTC): Resolved by #48202

"
2565710503,issue,closed,completed,"[MS1] Better Onboarding: ""Add initial data"" Section in the Main Sidebar","## Links
- [Product doc](https://www.notion.so/metabase/Better-Onboarding-via-first-time-UX-7c76eef94d414bb0a864d7cc786229f2)
- [Figma designs](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2701&node-type=canvas&m=dev)
    - [Main navigation updates](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6297-33793&m=dev)
    - [Add data section](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2723&m=dev)
- Feature branch: `better-onboarding-ux-ms1`

### Implementation Plan
Introduce the new onboarding (footer) section in the main navigation sidebar. To goal is to help admins set up their instances faster by prompting them to (1) add their own database and/or (2) upload CSV. We're also making the link to Metabase Learn content more prominent.

> [!Important]
> In this phase we're making the ""Add data"" section available to **admins only**!

```[tasklist]
## Checklist
- [x] MS 1.1: Add visual elements
- [x] MS 1.2: Logic (Business and Permissions)
- [x] MS 1.3: Simple event schema analytics
- [x] MS 1.4: Tests
- [x] MS 1.5: Final design polish (optional)
```

```[tasklist]
### Add database
- [x] Allow only admins to see this button
- [x] Remove the existing ""Add your own data button""
```

```[tasklist]
### Upload CSV Button
- [x] Allow only admins to see and use this
- [x] Upload to ""Our analytics"" only
- [x] Trigger the upload modal
- [x] Upload types: create, append, replace
- [x] Remove the existing ""Upload CSV"" (for DWH) button
```",nemanjaglumac,2024-10-04 07:51:22+00:00,['nemanjaglumac'],2024-10-24 11:48:40+00:00,2024-10-08 17:40:58+00:00,https://github.com/metabase/metabase/issues/48335,[],[],
2565481445,issue,closed,completed,Cannot find matching FK Table ID for FK Field,"### Describe the bug

https://github.com/user-attachments/assets/b303df96-411e-4d1d-9d8d-ce95b0f1fbab


### To Reproduce

1. Create Q3 question following repro steps from #48298 (there's a video showing repro steps)
2. Open the question in chill mode
3. Open filter modal
4. Open the 2nd ""Product"" group
5. Try to apply any filter from that group

### Expected behavior

Query does not fail

### Information about your Metabase installation

master, 40ed53ef8e9ae774cfbccb818d58f3f59565a232

### Severity

P1

### Additional context

Affects #47800 and #46519

----

POST `/api/dataset` response: [response.json](https://github.com/user-attachments/files/17253777/response.json)
",kamilmielnik,2024-10-04 05:31:01+00:00,[],2024-10-04 05:35:43+00:00,2024-10-04 05:33:35+00:00,https://github.com/metabase/metabase/issues/48334,[],"[{'comment_id': 2392856955, 'issue_id': 2565481445, 'author': 'kamilmielnik', 'body': 'Closing as a duplicate of #48334', 'created_at': datetime.datetime(2024, 10, 4, 5, 33, 35, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-04 05:33:35 UTC): Closing as a duplicate of #48334

"
2565394212,issue,closed,completed,we create and show personal collections for api keys,"### Describe the bug

api keys have personal collections

### To Reproduce

```sql
select c.id, c.name, c.personal_owner_id, u.type from collection c join core_user u on c.personal_owner_id = u.id;
```
![Image](https://github.com/user-attachments/assets/1b2c6e74-e663-4ff6-b973-5f19f0fa6568)

https://github.com/metabase/metabase/blob/master/src/metabase/models/collection.clj#L388

### Expected behavior

we do not create and do not list collections for api keys

### Logs

_No response_

### Information about your Metabase installation

master

### Severity

p2

### Additional context

_No response_",dpsutton,2024-10-04 04:17:11+00:00,['johnswanson'],2025-01-06 14:52:29+00:00,2025-01-06 14:52:27+00:00,https://github.com/metabase/metabase/issues/48332,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2573274543, 'issue_id': 2565394212, 'author': 'dpsutton', 'body': 'closed by https://github.com/metabase/metabase/pull/48638', 'created_at': datetime.datetime(2025, 1, 6, 14, 52, 27, tzinfo=datetime.timezone.utc)}]","dpsutton (Issue Creator) on (2025-01-06 14:52:27 UTC): closed by https://github.com/metabase/metabase/pull/48638

"
2565069306,issue,open,,Allow ci-jekyll builds to trigger off of crush pics commits,"> We could investigate the image-crush action. It fails very rarely around here.
Crush-images almost always works. That's not the issue. The problem is that if crush-images ends in a commit, it short-circuits the required ci-jekyll job. Presumably because automated commits can't trigger the ci-jekyll job.

[Slack Message](https://metaboat.slack.com/archives/C864UT5CZ/p1727991791625389?thread_ts=1727981824.123719&cid=C864UT5CZ)",iethree,2024-10-03 21:59:07+00:00,[],2025-01-17 20:29:45+00:00,,https://github.com/metabase/metabase/issues/48326,[],[],
2565069167,issue,closed,completed,[MS2] Better Onboarding: Expand upload CSV permissions to non-admins,"## Links
- [Product doc](https://www.notion.so/metabase/Better-Onboarding-via-first-time-UX-7c76eef94d414bb0a864d7cc786229f2)
- [Figma designs](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2701&node-type=canvas&m=dev)
    - [Main navigation updates](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6297-33793&m=dev)
    - [Add data section](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2723&m=dev)
- Feature branch: `better-onboarding-ux-ms2`
---
### Implementation Plan
Expand the permission scope for **upload CVSs only** to any non-admin who has a curate collection permissions _in the root (Our analytics) collection_. This should be a rather small PR as the majority of visual changes have already been implemented in #48335

> [!CAUTION]
> Keep an eye on the scenario in which a user has root collection write permissions, but doesn't have data permissions for a database for which uploads are enabled.

```[tasklist]
## Checklist
- [x] MS 2.1: Expand ""upload CSV"" permissions to non-admins
- [x] MS 2.2: Cover extensively with tests
- [x] MS 2.3: Remove the Metabase _learn_ link
```

### Testing plan
Everything should still work the same for admins, so no new tests are needed. We only need to make sure the existing ones are not broken.

For non-admins:
#### ""Add database"" button
- [x] Should never render

#### ""Upload a spreadsheet"" button
- [x] Should not render if a user does not have ""curate"" permissions for Root Collection
- [x] Should not render if a user does not have data access
- [x] Should render if a user has ""curate"" permissions for Root Collection AND
    - [x] has data access to at least one database **if admins didn't enable uploads** OR
    - [x] has permissions to upload specifically to the database for which **uploads are enabled**
",nemanjaglumac,2024-10-03 21:58:58+00:00,['nemanjaglumac'],2024-10-24 11:44:26+00:00,2024-10-09 17:29:39+00:00,https://github.com/metabase/metabase/issues/48325,[],[],
2564973430,issue,closed,completed,Detail views' expand button getting lost when scrolling,"### Describe the bug

related (closed)bug:  https://github.com/metabase/metabase/issues/39477

When scrolling down on a table view and trying to `View Details` for a row, the `View Details` modal shows a different row's data than what was clicked/intended. Also the expand button for `View Details`no longer properly aligned to the rows after scrolling.

Video showing the bug: https://www.loom.com/share/db81edd117a547c88a6f61289b9f3095?sid=36fa2637-5afd-4a54-8643-ef57467897a0 

### To Reproduce

1. Navigate to any table or model. 
2. Scroll down. 
3. Go to the left of a row and see the `View Detail` expand button misalignment. 
  - If you don't see it, scroll down some more / all the way to the buttom and see if the bug appears. 
4. Click to expand `View Details` and see a different row's details appear (the data that appears does not correspond to the row of data that you clicked `View Details` for. 

### Expected behavior

`View Details` expand button should not be misaligned with the rows of data. When I click on `View Details`, the data shown should be for the row that I clicked on. 

### Logs

_No response_

### Information about your Metabase installation

Stats

### Severity

not severe, mostly just annoying

### Additional context

workaround is to click on something like the ID instead to view the details of the row",jessicaul,2024-10-03 20:45:29+00:00,['uladzimirdev'],2024-10-14 17:35:33+00:00,2024-10-14 17:35:33+00:00,https://github.com/metabase/metabase/issues/48323,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2564961676,issue,open,,Viz settings can get into a weird place with a double scrollbar,"For some reason, when I initially go into viz settings, at the top it just has the Data and Display tabs. But when I switch to a different chart type, then back to pie, then open viz settings, I get this Pie Options that normally isn't there, and the double scrollbar

[More context and demo](https://metaboat.slack.com/archives/C064QMXEV9N/p1727976813594069?thread_ts=1727976022.922249&cid=C064QMXEV9N)",cdeweyx,2024-10-03 20:38:15+00:00,[],2025-02-06 14:19:43+00:00,,https://github.com/metabase/metabase/issues/48322,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2639959593, 'issue_id': 2564961676, 'author': 'lorem--ipsum', 'body': '@cdeweyx can you still replicate this?', 'created_at': datetime.datetime(2025, 2, 6, 14, 19, 42, tzinfo=datetime.timezone.utc)}]","lorem--ipsum on (2025-02-06 14:19:42 UTC): @cdeweyx can you still replicate this?

"
2564877451,issue,closed,completed,Wrong value shown in the filter modal,"### Describe the bug

https://www.loom.com/share/93f0b57d440a4bf2a39ead9e469ec1c3

### To Reproduce

1. Browse data -> Sample database -> Orders table
2. Click on Filter to open filter modal
3. Type ""Category"" in the search input field
4. Check Doohickey
5. Type ""Source"" in the search input field
6. You see Doohickey shown in the list and checked
 ![Image](https://github.com/user-attachments/assets/915c1719-2c4b-4e5a-ab1b-30d20fa1e7ed)



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

f256171

### Severity

just something funky

### Additional context

_No response_",mngr,2024-10-03 19:43:46+00:00,['kamilmielnik'],2025-01-29 09:23:48+00:00,2025-01-29 07:24:43+00:00,https://github.com/metabase/metabase/issues/48319,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('.Needs Triage', ''), ('.Team/Querying', '')]","[{'comment_id': 2596897363, 'issue_id': 2564877451, 'author': 'ranquild', 'body': 'FE state bug', 'created_at': datetime.datetime(2025, 1, 16, 21, 12, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613146126, 'issue_id': 2564877451, 'author': 'elaichenkov', 'body': '<img width=""1438"" alt=""Image"" src=""https://github.com/user-attachments/assets/3ab169cc-ce10-4459-8b7b-1f8d94c80479"" />\n\n\n```js\n  it(""should filter by (metabase#48319)"", () => {\n    const sourceOptions = [\n      ""Google"",\n      ""Twitter"",\n      ""Facebook"",\n      ""Organic"",\n      ""Affiliate"",\n    ];\n\n    H.visitQuestionAdhoc(rawQuestionDetails);\n    H.filter();\n\n    H.modal().within(() => {\n      cy.findByText(""Product"").click({ force: true });\n      H.filterField(""Category"").findByText(""Gadget"").click();\n\n      cy.findByPlaceholderText(""Search for a column…"").type(""category"");\n\n      cy.findByTestId(""string-filter-editor"").should(""have.length"", 1);\n\n      cy.findByPlaceholderText(""Search for a column…"").realClick({\n        clickCount: 2,\n      });\n\n      cy.findByPlaceholderText(""Search for a column…"").type(""source"");\n\n      cy.get("".emotion-Checkbox-label"").should($labels => {\n        $labels.each((_, label) => {\n          const labelText = label.textContent;\n\n          expect(sourceOptions).to.contain(labelText);\n        });\n      });\n    });\n  });\n```', 'created_at': datetime.datetime(2025, 1, 24, 18, 29, 24, tzinfo=datetime.timezone.utc)}]","ranquild on (2025-01-16 21:12:10 UTC): FE state bug

elaichenkov on (2025-01-24 18:29:24 UTC): <img width=""1438"" alt=""Image"" src=""https://github.com/user-attachments/assets/3ab169cc-ce10-4459-8b7b-1f8d94c80479"" />


```js
  it(""should filter by (metabase#48319)"", () => {
    const sourceOptions = [
      ""Google"",
      ""Twitter"",
      ""Facebook"",
      ""Organic"",
      ""Affiliate"",
    ];

    H.visitQuestionAdhoc(rawQuestionDetails);
    H.filter();

    H.modal().within(() => {
      cy.findByText(""Product"").click({ force: true });
      H.filterField(""Category"").findByText(""Gadget"").click();

      cy.findByPlaceholderText(""Search for a column…"").type(""category"");

      cy.findByTestId(""string-filter-editor"").should(""have.length"", 1);

      cy.findByPlaceholderText(""Search for a column…"").realClick({
        clickCount: 2,
      });

      cy.findByPlaceholderText(""Search for a column…"").type(""source"");

      cy.get("".emotion-Checkbox-label"").should($labels => {
        $labels.each((_, label) => {
          const labelText = label.textContent;

          expect(sourceOptions).to.contain(labelText);
        });
      });
    });
  });
```

"
2564630946,issue,closed,completed,You can't operate on a closed ResultSet!!! (master),"### Describe the bug

Just tried moving an old 50 I had to master and got:
```
2024-10-03 17:36:51,152 INFO task.sweep-query-analysis :: Recalculating potentially stale analysis
2024-10-03 17:36:51,154 ERROR task.analyze-queries :: Unhandled error when attempting to analyse the next card in the queue
clojure.lang.ExceptionInfo: You can't operate on a closed ResultSet!!! {:toucan2/context-trace [[""read column"" {:thunk #object[toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26091 0x5c82ced5 ""toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26091@5c82ced5""], :model :model/Card}]]}
	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:118)
	at com.mchange.v2.sql.SqlUtils.toSQLException(SqlUtils.java:77)
	at com.mchange.v2.c3p0.impl.NewProxyResultSet.getObject(NewProxyResultSet.java:171)
	at toucan2.jdbc.read$read_column_thunk_primary_method_default$default_read_column_thunk__26091.invoke(read.clj:73)
	at toucan2.jdbc.read$read_column_thunk_after_method_default$fn__26103.invoke(read.clj:79)
	at toucan2.jdbc.read$make_column_thunk$column_thunk__26136.invoke(read.clj:136)
	at toucan2.jdbc.read$make_cached_row_num__GT_i__GT_thunk$row_num__GT_i__GT_thunk_STAR___26145$i__GT_thunk_STAR___26146$cached_column_thunk__26147.invoke(read.clj:180)
	at toucan2.jdbc.row$fetch_column_with_name.invokeStatic(row.clj:36)
	at toucan2.jdbc.row$fetch_column_with_name.invoke(row.clj:26)
	at toucan2.jdbc.row.TransientRow.valAt(row.clj:211)
	at toucan2.jdbc.row.TransientRow.valAt(row.clj:192)
	at clojure.lang.KeywordLookupSite$1.get(KeywordLookupSite.java:45)
	at metabase.util$id.invokeStatic(util.cljc:452)
	at metabase.util$id.invoke(util.cljc:443)
	at metabase.util$the_id.invokeStatic(util.cljc:462)
	at metabase.util$the_id.invoke(util.cljc:455)
	at metabase.task.analyze_queries$analyzer_loop_STAR_.invokeStatic(analyze_queries.clj:44)
	at metabase.task.analyze_queries$analyzer_loop_STAR_.invoke(analyze_queries.clj:40)
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:72)
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:70)
	at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
	at metabase.task.analyze_queries.QueryAnalyzer.execute(analyze_queries.clj:81)
	at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
Caused by: java.sql.SQLException: You can't operate on a closed ResultSet!!!
	... 25 more
Caused by: java.lang.NullPointerException: Cannot invoke ""java.sql.ResultSet.getObject(int)"" because ""this.inner"" is null
	at com.mchange.v2.c3p0.impl.NewProxyResultSet.getObject(NewProxyResultSet.java:165)
	... 22 more

```

### To Reproduce

move to master?

### Expected behavior

Don't hit the error

### Logs

Above

### Information about your Metabase installation

master

### Severity

P1

### Additional context

_No response_",paoliniluis,2024-10-03 17:38:48+00:00,['crisptrutski'],2024-10-21 11:49:09+00:00,2024-10-21 11:49:09+00:00,https://github.com/metabase/metabase/issues/48310,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 2392030307, 'issue_id': 2564630946, 'author': 'crisptrutski', 'body': ""Did a quick scan of the logs on Stats, and don't see it happening there.\n\nI also haven't seen it locally where I've shifted between 50 and master a few times per day.\n\nFailures in the analyzer background process should not interfere with the app in any way, can you confirm that the instance is otherwise responsive?\n\nThe originating exception above seems to come the connection pool management, so perhaps there are other symptoms?"", 'created_at': datetime.datetime(2024, 10, 3, 18, 13, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392033161, 'issue_id': 2564630946, 'author': 'crisptrutski', 'body': 'Do you recall precisely which version of 50 you switched from?', 'created_at': datetime.datetime(2024, 10, 3, 18, 14, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392057036, 'issue_id': 2564630946, 'author': 'paoliniluis', 'body': 'I went from 50.11 to master. The instance worked, yes', 'created_at': datetime.datetime(2024, 10, 3, 18, 27, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393179856, 'issue_id': 2564630946, 'author': 'crisptrutski', 'body': '@paoliniluis can you confirm whether the task throws the same exceptions on subsequent runs?', 'created_at': datetime.datetime(2024, 10, 4, 8, 50, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393370849, 'issue_id': 2564630946, 'author': 'paoliniluis', 'body': 'Sorry @crisptrutski , I dumped the environment 🤦\u200d♂️', 'created_at': datetime.datetime(2024, 10, 4, 10, 23, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399371776, 'issue_id': 2564630946, 'author': 'armgong', 'body': 'Maybe is not a upgrading problem.\nTest master build today  on windows , where started a new instance with new default h2 database, the error still show\nwindows 10 \nopenjdk 17.0.10 2024-01-16\nOpenJDK Runtime Environment Temurin-17.0.10+7 (build 17.0.10+7)\nOpenJDK 64-Bit Server VM Temurin-17.0.10+7 (build 17.0.10+7, mixed mode, sharing)\n~~~\n2024-10-08 17:33:03,955 INFO task.sweep-query-analysis :: Calculating analysis for cards without any\n2024-10-08 17:33:04,021 INFO channel.core :: Loading channel namespace: metabase.channel.http\n2024-10-08 17:33:04,037 INFO channel.core :: Loading channel namespace: metabase.channel.shared\n2024-10-08 17:33:04,040 INFO channel.core :: Loading channel namespace: metabase.channel.slack\n2024-10-08 17:33:04,050 INFO metabase.core :: Metabase Initialization COMPLETE in 43.3 s\n2024-10-08 17:33:05,381 INFO task.sweep-query-analysis :: Recalculating potentially stale analysis\n2024-10-08 17:33:05,381 ERROR task.analyze-queries :: Unhandled error when attempting to analyse the next card in the queue\norg.h2.jdbc.JdbcSQLNonTransientException: The object is already closed [90007-214]\n        at org.h2.message.DbException.getJdbcSQLException(DbException.java:554)\n        at org.h2.message.DbException.getJdbcSQLException(DbException.java:477)\n        at org.h2.message.DbException.get(DbException.java:223)\n        at org.h2.message.DbException.get(DbException.java:199)\n        at org.h2.message.DbException.get(DbException.java:188)\n        at org.h2.jdbc.JdbcResultSet.checkClosed(JdbcResultSet.java:3536)\n        at org.h2.jdbc.JdbcResultSet.getMetaData(JdbcResultSet.java:141)\n        at com.mchange.v2.c3p0.impl.NewProxyResultSet.getMetaData(NewProxyResultSet.java:987)\n        at toucan2.jdbc.read$make_column_thunk$column_thunk__26136.invoke(read.clj:134)\n        at toucan2.jdbc.read$make_cached_row_num__GT_i__GT_thunk$row_num__GT_i__GT_thunk_STAR___26145$i__GT_thunk_STAR___26146$cached_column_thunk__26147.invoke(read.clj:180)\n\n        at toucan2.jdbc.row$fetch_column_with_name.invokeStatic(row.clj:36)\n        at toucan2.jdbc.row$fetch_column_with_name.invoke(row.clj:26)\n        at toucan2.jdbc.row.TransientRow.valAt(row.clj:211)\n        at toucan2.jdbc.row.TransientRow.valAt(row.clj:192)\n        at clojure.lang.KeywordLookupSite$1.get(KeywordLookupSite.java:45)\n        at metabase.util$id.invokeStatic(util.cljc:452)\n        at metabase.util$id.invoke(util.cljc:443)\n        at metabase.util$the_id.invokeStatic(util.cljc:462)\n        at metabase.util$the_id.invoke(util.cljc:455)\n        at metabase.task.analyze_queries$analyzer_loop_STAR_.invokeStatic(analyze_queries.clj:44)\n        at metabase.task.analyze_queries$analyzer_loop_STAR_.invoke(analyze_queries.clj:40)\n        at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:72)\n        at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)\n        at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:70)\n        at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)\n        at metabase.task.analyze_queries.QueryAnalyzer.execute(analyze_queries.clj:81)\n        at org.quartz.core.JobRunShell.run(JobRunShell.java:202)\n        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)\n2024-10-08 17:33:11,439 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.\n2024-10-08 17:33:11,439 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""win10-hyperv1728379970952""\'s failed in-progress jobs.\n2024-10-08 17:33:11,440 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""win10-hyperv1728379976053""\'s failed in-progress jobs.\n~~~', 'created_at': datetime.datetime(2024, 10, 8, 9, 44, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399745055, 'issue_id': 2564630946, 'author': 'crisptrutski', 'body': 'Have a plausible theory, cut a PR.', 'created_at': datetime.datetime(2024, 10, 8, 12, 44, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426449138, 'issue_id': 2564630946, 'author': 'crisptrutski', 'body': ""Resolving as the only report I've seen since was for the beta preceding the related PR."", 'created_at': datetime.datetime(2024, 10, 21, 11, 49, 7, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-10-03 18:13:01 UTC): Did a quick scan of the logs on Stats, and don't see it happening there.

I also haven't seen it locally where I've shifted between 50 and master a few times per day.

Failures in the analyzer background process should not interfere with the app in any way, can you confirm that the instance is otherwise responsive?

The originating exception above seems to come the connection pool management, so perhaps there are other symptoms?

crisptrutski (Assginee) on (2024-10-03 18:14:40 UTC): Do you recall precisely which version of 50 you switched from?

paoliniluis (Issue Creator) on (2024-10-03 18:27:32 UTC): I went from 50.11 to master. The instance worked, yes

crisptrutski (Assginee) on (2024-10-04 08:50:27 UTC): @paoliniluis can you confirm whether the task throws the same exceptions on subsequent runs?

paoliniluis (Issue Creator) on (2024-10-04 10:23:17 UTC): Sorry @crisptrutski , I dumped the environment 🤦‍♂️

armgong on (2024-10-08 09:44:29 UTC): Maybe is not a upgrading problem.
Test master build today  on windows , where started a new instance with new default h2 database, the error still show
windows 10 
openjdk 17.0.10 2024-01-16
OpenJDK Runtime Environment Temurin-17.0.10+7 (build 17.0.10+7)
OpenJDK 64-Bit Server VM Temurin-17.0.10+7 (build 17.0.10+7, mixed mode, sharing)
~~~
2024-10-08 17:33:03,955 INFO task.sweep-query-analysis :: Calculating analysis for cards without any
2024-10-08 17:33:04,021 INFO channel.core :: Loading channel namespace: metabase.channel.http
2024-10-08 17:33:04,037 INFO channel.core :: Loading channel namespace: metabase.channel.shared
2024-10-08 17:33:04,040 INFO channel.core :: Loading channel namespace: metabase.channel.slack
2024-10-08 17:33:04,050 INFO metabase.core :: Metabase Initialization COMPLETE in 43.3 s
2024-10-08 17:33:05,381 INFO task.sweep-query-analysis :: Recalculating potentially stale analysis
2024-10-08 17:33:05,381 ERROR task.analyze-queries :: Unhandled error when attempting to analyse the next card in the queue
org.h2.jdbc.JdbcSQLNonTransientException: The object is already closed [90007-214]
        at org.h2.message.DbException.getJdbcSQLException(DbException.java:554)
        at org.h2.message.DbException.getJdbcSQLException(DbException.java:477)
        at org.h2.message.DbException.get(DbException.java:223)
        at org.h2.message.DbException.get(DbException.java:199)
        at org.h2.message.DbException.get(DbException.java:188)
        at org.h2.jdbc.JdbcResultSet.checkClosed(JdbcResultSet.java:3536)
        at org.h2.jdbc.JdbcResultSet.getMetaData(JdbcResultSet.java:141)
        at com.mchange.v2.c3p0.impl.NewProxyResultSet.getMetaData(NewProxyResultSet.java:987)
        at toucan2.jdbc.read$make_column_thunk$column_thunk__26136.invoke(read.clj:134)
        at toucan2.jdbc.read$make_cached_row_num__GT_i__GT_thunk$row_num__GT_i__GT_thunk_STAR___26145$i__GT_thunk_STAR___26146$cached_column_thunk__26147.invoke(read.clj:180)

        at toucan2.jdbc.row$fetch_column_with_name.invokeStatic(row.clj:36)
        at toucan2.jdbc.row$fetch_column_with_name.invoke(row.clj:26)
        at toucan2.jdbc.row.TransientRow.valAt(row.clj:211)
        at toucan2.jdbc.row.TransientRow.valAt(row.clj:192)
        at clojure.lang.KeywordLookupSite$1.get(KeywordLookupSite.java:45)
        at metabase.util$id.invokeStatic(util.cljc:452)
        at metabase.util$id.invoke(util.cljc:443)
        at metabase.util$the_id.invokeStatic(util.cljc:462)
        at metabase.util$the_id.invoke(util.cljc:455)
        at metabase.task.analyze_queries$analyzer_loop_STAR_.invokeStatic(analyze_queries.clj:44)
        at metabase.task.analyze_queries$analyzer_loop_STAR_.invoke(analyze_queries.clj:40)
        at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:72)
        at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
        at metabase.task.analyze_queries$analyzer_loop_BANG_.invokeStatic(analyze_queries.clj:70)
        at metabase.task.analyze_queries$analyzer_loop_BANG_.invoke(analyze_queries.clj:68)
        at metabase.task.analyze_queries.QueryAnalyzer.execute(analyze_queries.clj:81)
        at org.quartz.core.JobRunShell.run(JobRunShell.java:202)
        at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
2024-10-08 17:33:11,439 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 2 failed or restarted instances.
2024-10-08 17:33:11,439 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""win10-hyperv1728379970952""'s failed in-progress jobs.
2024-10-08 17:33:11,440 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""win10-hyperv1728379976053""'s failed in-progress jobs.
~~~

crisptrutski (Assginee) on (2024-10-08 12:44:08 UTC): Have a plausible theory, cut a PR.

crisptrutski (Assginee) on (2024-10-21 11:49:07 UTC): Resolving as the only report I've seen since was for the beta preceding the related PR.

"
2564619889,issue,closed,completed,send swag for RC,,npfitz,2024-10-03 17:35:45+00:00,[],2024-10-03 17:36:15+00:00,2024-10-03 17:36:14+00:00,https://github.com/metabase/metabase/issues/48309,[],"[{'comment_id': 2391964830, 'issue_id': 2564619889, 'author': 'npfitz', 'body': 'Closed by https://github.com/metabase/metabase/pull/48155', 'created_at': datetime.datetime(2024, 10, 3, 17, 36, 14, tzinfo=datetime.timezone.utc)}]","npfitz (Issue Creator) on (2024-10-03 17:36:14 UTC): Closed by https://github.com/metabase/metabase/pull/48155

"
2564493506,issue,closed,completed,Rename from “Select all” to “select these” if you have an active term in the field for search,Small follow-up for [Select all](https://github.com/metabase/metabase/pull/48086),mngr,2024-10-03 16:42:01+00:00,['ranquild'],2024-11-12 14:01:07+00:00,2024-11-12 14:01:07+00:00,https://github.com/metabase/metabase/issues/48307,"[('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2564486039,issue,open,,[FieldRefs] Filter and chart are broken when multiple breakouts of the same field are re-ordered,"### Describe the bug

Filters after aggregation and chart settings seem to reference the first breakout of the same field, not the actual column


### To Reproduce

1. Go to + New question
2. Pick Orders table
3. Add Summarize - Count, breakout by Created At: Day and then Created At: Day of Year
4. Add a filter on Created At: Day
5. Visualize, pick the first Created At for the x-axis (it should actually show the granularity in the vis settings, but that's probably [another issue](https://github.com/metabase/metabase/issues/47579))
6. Drag the breakouts to re-order first Created At: Day of Year and then Created At: Day
7. The filter changes to be on Created At: Day of Year - should stay for Created At: Day
8. The query actually breaks, because the filter doesn't work anymore
9. Remove the filter, visualize
10. The viz changes to plot Created At: Day of Year along the x-axis - should stay for Created At: Day

### Expected behavior

Filter should be kept on Created At: Day
Viz settings should be kept to use Created At: Day

### Logs

_No response_

### Information about your Metabase installation

0d27f87

### Severity

Breaks my query

### Additional context

_No response_",mngr,2024-10-03 16:37:38+00:00,[],2025-02-04 20:27:16+00:00,,https://github.com/metabase/metabase/issues/48306,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2564470748,issue,closed,completed,Viz settings with long content may have two scrollbars,"**Context**

Viz settings data tab sometimes shows two scrollbars
![Image](https://github.com/user-attachments/assets/d273b188-6a7a-452f-ac8d-deaf63c1f1da)

",alxnddr,2024-10-03 16:28:48+00:00,[],2024-10-03 22:23:41+00:00,2024-10-03 22:23:40+00:00,https://github.com/metabase/metabase/issues/48304,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2392441791, 'issue_id': 2564470748, 'author': 'alxnddr', 'body': 'Closing in favour of https://github.com/metabase/metabase/issues/48322', 'created_at': datetime.datetime(2024, 10, 3, 22, 23, 40, tzinfo=datetime.timezone.utc)}]","alxnddr (Issue Creator) on (2024-10-03 22:23:40 UTC): Closing in favour of https://github.com/metabase/metabase/issues/48322

"
2564285909,issue,closed,completed,Hide entity ID display on instances without `serialization` feature flag,"<@U0697CU8TTP> Another refinement item.

We should only show `entity-id` in the sidesheets when the instance has the `serialization` feature flag.
Essentially, this will remove this component from all OSS and Starter instances

[Slack Message](https://metaboat.slack.com/archives/C07JSTRFRPW/p1727966894639919)",iethree,2024-10-03 14:57:26+00:00,[],2025-01-03 16:56:07+00:00,2025-01-03 16:56:06+00:00,https://github.com/metabase/metabase/issues/48301,[],"[{'comment_id': 2569537163, 'issue_id': 2564285909, 'author': 'iethree', 'body': 'done', 'created_at': datetime.datetime(2025, 1, 3, 16, 56, 6, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2025-01-03 16:56:06 UTC): done

"
2564003900,issue,closed,not_planned,Question gives different results when placed on a dashboard,"### Describe the bug

Dashboard, 1077 rows: [image](https://github.com/user-attachments/assets/19bd689f-19dc-46bb-995a-289218310cef)
Query builder, 4308 rows: [image](https://github.com/user-attachments/assets/26d6639a-73eb-4b40-93aa-5ca75224af39)

https://github.com/user-attachments/assets/fd7e363a-d2f0-4813-a4b6-641d7e6efab8



### To Reproduce

(this surely isn't the minimal example, apologies for this huge query)

1. Create a question Q1 based on Orders table
2. Create a question Q2 based on Q1
3. Create a question Q3 based on Q2 ([image](https://github.com/user-attachments/assets/b19f2b18-1f9e-43fc-9ee9-13ab9727a5e5))
    - join Reviews on Product ID = Product ID
    - add custom column `Net` with this expression: `[Total] - [Tax]`
    - add aggregations: Count and Sum of Total
    - add breakouts: Created At: Month, Product -> Category, User -> Created At: Year
    - join Reviews on Created At: Month = Created At: Month
    - add custom column `5 * Count` with this expression: `5 * [Count]`
    - add Count aggregation
    - add breakouts: Reviews -> Created At: Month -> Reviewer and Product -> Category
4. Visualize, notice rows count is 4308 (⚠ **shouldn't it be limited to 2000?**, see https://github.com/metabase/metabase/issues/48439#issuecomment-2399416349) 
5. Add this question to a dashboard and save it
6. Notice rows count for the question is 1077

### Expected behavior

Rows count is the same in dashboard and in query builder

### Information about your Metabase installation

master, 3a3785d

### Severity

P1/P2

### Additional info

- https://metaboat.slack.com/archives/C07BWMG9C8M/p1727960401955539
- https://metaboat.slack.com/archives/C07A3CC0WUX/p1727959355063309
",kamilmielnik,2024-10-03 12:59:26+00:00,['appleby'],2024-10-16 19:26:20+00:00,2024-10-16 19:12:02+00:00,https://github.com/metabase/metabase/issues/48298,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2415379726, 'issue_id': 2564003900, 'author': 'appleby', 'body': 'A simplified version of the above query that returns the same results is the following ![Image](https://github.com/user-attachments/assets/618daff5-0167-4f39-a53f-f8dce62c8238)\n\n* Create a question Q0 based on the Orders table\n* add aggregations: Count\n* add breakouts: Created At: Month, Product -> Category\n* join Reviews on Created At: Month = Created At: Month\n* add Count aggregation\n* add breakouts: Reviews -> Created At: Month -> Reviewer and Product -> Category\n\nBut I think this is a duplicate of #12522 and any pivot table will do (see the simpler query in that issue, e.g.).\n\nNote that 1,077 = 4,308 / 4, i.e. the number of rows reported in the dashcard (1,077) is equal to the number of rows reported in the query builder (4,308) divided by the number of product categories that we pivot on (4).\n\nInterestingly, if I convert the question to SQL, the 2,000 row limit is respected in the query builder view, and then the number of rows reported in the dashcard is instead 500 = 2,000 / 4.\n\n## Edit\n\nHere is another simple query that reproduces the issue, but unlike the one in #12522, this one has enough rows in the result set to also display the row count when added to a dashboard.\n\n![Image](https://github.com/user-attachments/assets/be6f094a-8bae-4ed5-8e43-3ed59083ed70)\n\nMake sure viz type is set to pivot table and the QB says ""Showing 1,400 rows"" whereas the dashcard will say ""Rows 1-8 of 200"". We\'re pivoting on day-of-week, so 200 = 1,400 / 7.\n\nCause of the discrepancy: query builder in `QuestionRowCount.tsx` reports the `result.row_count` returned by the backend, whereas in the dashcard I think the `TableFooter` component is seeing the start/end of the already-pivoted rows from the `PivotTable` visualization.', 'created_at': datetime.datetime(2024, 10, 16, 0, 15, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417693818, 'issue_id': 2564003900, 'author': 'appleby', 'body': 'Close as dup of #12522 per slack discussion here\n\nhttps://metaboat.slack.com/archives/C0645JP1W81/p1729095615943569', 'created_at': datetime.datetime(2024, 10, 16, 19, 4, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417734880, 'issue_id': 2564003900, 'author': 'mngr', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/12522', 'created_at': datetime.datetime(2024, 10, 16, 19, 12, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417759455, 'issue_id': 2564003900, 'author': 'appleby', 'body': 'As for the row count exceeding the default limit of 2,000 for UI queries, this also appears to be working as designed. Apparently the 2,000 limit is passed as `:max-results-bare-rows` (`HARD_ROW_LIMIT` on the FE) which is only used for queries *without* aggregations.\n\nQueries *with* aggregations instead use `:max-results`, which for this query is 10,000\n\n```json\n""constraints"": {\n    ""max-results"": 10000,\n    ""max-results-bare-rows"": 2000\n},\n```\n\nSee\n\nhttps://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/src/metabase/legacy_mbql/util.cljc#L735\n\nhttps://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/test/metabase/legacy_mbql/util_test.cljc#L804\n\nhttps://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/src/metabase/cmd/env_var_dox.clj#L52', 'created_at': datetime.datetime(2024, 10, 16, 19, 26, 19, tzinfo=datetime.timezone.utc)}]","appleby (Assginee) on (2024-10-16 00:15:17 UTC): A simplified version of the above query that returns the same results is the following ![Image](https://github.com/user-attachments/assets/618daff5-0167-4f39-a53f-f8dce62c8238)

* Create a question Q0 based on the Orders table
* add aggregations: Count
* add breakouts: Created At: Month, Product -> Category
* join Reviews on Created At: Month = Created At: Month
* add Count aggregation
* add breakouts: Reviews -> Created At: Month -> Reviewer and Product -> Category

But I think this is a duplicate of #12522 and any pivot table will do (see the simpler query in that issue, e.g.).

Note that 1,077 = 4,308 / 4, i.e. the number of rows reported in the dashcard (1,077) is equal to the number of rows reported in the query builder (4,308) divided by the number of product categories that we pivot on (4).

Interestingly, if I convert the question to SQL, the 2,000 row limit is respected in the query builder view, and then the number of rows reported in the dashcard is instead 500 = 2,000 / 4.

## Edit

Here is another simple query that reproduces the issue, but unlike the one in #12522, this one has enough rows in the result set to also display the row count when added to a dashboard.

![Image](https://github.com/user-attachments/assets/be6f094a-8bae-4ed5-8e43-3ed59083ed70)

Make sure viz type is set to pivot table and the QB says ""Showing 1,400 rows"" whereas the dashcard will say ""Rows 1-8 of 200"". We're pivoting on day-of-week, so 200 = 1,400 / 7.

Cause of the discrepancy: query builder in `QuestionRowCount.tsx` reports the `result.row_count` returned by the backend, whereas in the dashcard I think the `TableFooter` component is seeing the start/end of the already-pivoted rows from the `PivotTable` visualization.

appleby (Assginee) on (2024-10-16 19:04:03 UTC): Close as dup of #12522 per slack discussion here

https://metaboat.slack.com/archives/C0645JP1W81/p1729095615943569

mngr on (2024-10-16 19:12:02 UTC): Duplicate of https://github.com/metabase/metabase/issues/12522

appleby (Assginee) on (2024-10-16 19:26:19 UTC): As for the row count exceeding the default limit of 2,000 for UI queries, this also appears to be working as designed. Apparently the 2,000 limit is passed as `:max-results-bare-rows` (`HARD_ROW_LIMIT` on the FE) which is only used for queries *without* aggregations.

Queries *with* aggregations instead use `:max-results`, which for this query is 10,000

```json
""constraints"": {
    ""max-results"": 10000,
    ""max-results-bare-rows"": 2000
},
```

See

https://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/src/metabase/legacy_mbql/util.cljc#L735

https://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/test/metabase/legacy_mbql/util_test.cljc#L804

https://github.com/metabase/metabase/blob/94496eb579f860385e38847cfc6d169a4525c008/src/metabase/cmd/env_var_dox.clj#L52

"
2563951593,issue,open,,Non-saved questions never hit the cache,"### Describe the bug

[Context](https://metaboat.slack.com/archives/C06KX7QECN4/p1727816309296519?thread_ts=1727816177.122349&cid=C06KX7QECN4)

We never hit the cache if the question is unsaved.

### To Reproduce

1. Create a global or database caching policy
2. Run slow queries on that DB without saving them
3. See that they never hit the cache


### Expected behavior

It should behave as any other saved question: cache if there is a policy (first check database and then root)

### Logs

_No response_

### Information about your Metabase installation

- 50.26

### Severity

P2

### Additional context

_No response_",luizarakaki,2024-10-03 12:37:55+00:00,[],2025-02-04 20:31:03+00:00,,https://github.com/metabase/metabase/issues/48297,"[('Type:New Feature', ''), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2391422364, 'issue_id': 2563951593, 'author': 'paoliniluis', 'body': 'should we? I think we should signal this but we should never hit the cache', 'created_at': datetime.datetime(2024, 10, 3, 13, 27, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400698810, 'issue_id': 2563951593, 'author': 'luizarakaki', 'body': '> should we? I think we should signal this but we should never hit the cache\n\nWhy not?', 'created_at': datetime.datetime(2024, 10, 8, 19, 51, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401670321, 'issue_id': 2563951593, 'author': 'paoliniluis', 'body': 'now that you say this, I think I would agree that we should hit the cache since otherwise it would cause a difference in the way caching works (non-saved vs saved)', 'created_at': datetime.datetime(2024, 10, 9, 8, 24, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457962951, 'issue_id': 2563951593, 'author': 'luizarakaki', 'body': ""Changing this to new feature as we don't store cache for unsaved questions, so this would need to be added"", 'created_at': datetime.datetime(2024, 11, 5, 19, 12, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-03 13:27:30 UTC): should we? I think we should signal this but we should never hit the cache

luizarakaki (Issue Creator) on (2024-10-08 19:51:37 UTC): Why not?

paoliniluis on (2024-10-09 08:24:37 UTC): now that you say this, I think I would agree that we should hit the cache since otherwise it would cause a difference in the way caching works (non-saved vs saved)

luizarakaki (Issue Creator) on (2024-11-05 19:12:39 UTC): Changing this to new feature as we don't store cache for unsaved questions, so this would need to be added

"
2563915675,issue,closed,not_planned,"error message of ""Your question took too long""","### Describe the bug

I am facing the issue. when i ran the sql query from metabase, its giving timeout after 20mins, still i have added the
jetty:
ASYNC_RESPONSE_TIMEOUT: ""3600000""

also the ingress level time out - nginx.ingress.kubernetes.io/proxy-read-timeout: ""1800""


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

i am using the chrome to access the metabase

### Severity

high

### Additional context

_No response_",reddy2018,2024-10-03 12:21:00+00:00,[],2024-10-04 08:00:36+00:00,2024-10-03 14:16:15+00:00,https://github.com/metabase/metabase/issues/48296,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2391300372, 'issue_id': 2563915675, 'author': 'crisptrutski', 'body': 'Can you please provide more information, for example around the query and the database in question?\n\nIs there anything in the logs related to the execution of the query?', 'created_at': datetime.datetime(2024, 10, 3, 12, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391317948, 'issue_id': 2563915675, 'author': 'reddy2018', 'body': 'clojure.lang.ExceptionInfo: Timed out after 20.0 mins. {:status :timed-out, :type :timed-out}\n\tat metabase.query_processor.context.default$default_timeoutf.invokeStatic(default.clj:90)\n\tat metabase.query_processor.context.default$default_timeoutf.invoke(default.clj:86)\n\tat metabase.query_processor.context$timeoutf.invokeStatic(context.clj:85)\n\tat metabase.query_processor.context$timeoutf.invoke(context.clj:80)\n\tat metabase.query_processor.reducible$wire_up_context_channels_BANG_$fn__66755$state_machine__36873__auto____66764$fn__66766.invoke(reducible.clj:63)\n\tat metabase.query_processor.reducible$wire_up_context_channels_BANG_$fn__66755$state_machine__36873__auto____66764.invoke(reducible.clj:57)\n\tat clojure.core.async.impl.runtime$run_state_machine.invokeStatic(runtime.clj:62)\n\tat clojure.core.async.impl.runtime$run_state_machine.invoke(runtime.clj:61)\n\tat clojure.core.async.impl.runtime$run_state_machine_wrapped.invokeStatic(runtime.clj:66)\n\tat clojure.core.async.impl.runtime$run_state_machine_wrapped.invoke(runtime.clj:64)\n\tat clojure.core.async$ioc_alts_BANG_$fn__33198.invoke(async.clj:423)\n\tat clojure.core.async$do_alts$fn__33137$fn__33140.invoke(async.clj:290)\n\tat clojure.core.async.impl.channels.ManyToManyChannel$fn__32957.invoke(channels.clj:269)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n\tat clojure.core.async.impl.concurrent$counted_thread_factory$reify__32795$fn__32796.invoke(concurrent.clj:29)\n\tat clojure.lang.AFn.run(AFn.java:22)\n\tat java.base/java.lang.Thread.run(Unknown Source)', 'created_at': datetime.datetime(2024, 10, 3, 12, 39, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391353395, 'issue_id': 2563915675, 'author': 'Tony-metabase', 'body': 'How long does it take to run when you run it directly on your DB? and can you share the diagnostic information as well.\n\nAlso it would be more productive for both of us if this kind of issues are flagged in https://discourse.metabase.com/ cause this is not a bug and other users might experience the same problem and provide support', 'created_at': datetime.datetime(2024, 10, 3, 12, 55, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391493649, 'issue_id': 2563915675, 'author': 'reddy2018', 'body': 'when i ran directly in the db, it took almost 40mins.', 'created_at': datetime.datetime(2024, 10, 3, 13, 56, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391497117, 'issue_id': 2563915675, 'author': 'reddy2018', 'body': 'it seems some where in the metabase needs to change the timeout setting to run the query more than 20 mins.\n\nIf anyone faced the same problem please share the solution', 'created_at': datetime.datetime(2024, 10, 3, 13, 57, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391538789, 'issue_id': 2563915675, 'author': 'Tony-metabase', 'body': ""I think you need to increase both the [MB_JETTY_ASYNC_RESPONSE_TIMEOUT](https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_jetty_async_response_timeout) and the [MB_DB_QUERY_TIMEOUT_MINUTES](https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_db_query_timeout_minutes)\n\nNonetheless please don't open Bugs for things related to configuration, you can get better support on Discourse  https://discourse.metabase.com/ \n\nAlso if a query takes around 40mins to run, you need to perform some optimization around that. Imagine having a dashboard with 5 questions that take around 40 min each to run. That means a user has to wait 40 min to see the results."", 'created_at': datetime.datetime(2024, 10, 3, 14, 16, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393006619, 'issue_id': 2563915675, 'author': 'reddy2018', 'body': 'is this the correct way to setup [MB_DB_QUERY_TIMEOUT_MINUTES]\n\nextraEnv:\n  - name: MB_DB_QUERY_TIMEOUT_MINUTES\n    value: ""60""\n#  - name: MB_DB_QUERY_TIMEOUT_SEC\n#    value: ""3600""\n  - name: metabase.query-processor.query-timeout-ms\n    value: ""3600000""\n  - name: MB_DB_CONNECTION_TIMEOUT_MS\n    value: ""3600000""', 'created_at': datetime.datetime(2024, 10, 4, 7, 23, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393044198, 'issue_id': 2563915675, 'author': 'reddy2018', 'body': '@Tony-metabase can you please check my env varaible is correct or not', 'created_at': datetime.datetime(2024, 10, 4, 7, 42, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393081912, 'issue_id': 2563915675, 'author': 'Tony-metabase', 'body': 'Moving the thread to discourse', 'created_at': datetime.datetime(2024, 10, 4, 8, 0, 35, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-10-03 12:31:07 UTC): Can you please provide more information, for example around the query and the database in question?

Is there anything in the logs related to the execution of the query?

reddy2018 (Issue Creator) on (2024-10-03 12:39:42 UTC): clojure.lang.ExceptionInfo: Timed out after 20.0 mins. {:status :timed-out, :type :timed-out}
	at metabase.query_processor.context.default$default_timeoutf.invokeStatic(default.clj:90)
	at metabase.query_processor.context.default$default_timeoutf.invoke(default.clj:86)
	at metabase.query_processor.context$timeoutf.invokeStatic(context.clj:85)
	at metabase.query_processor.context$timeoutf.invoke(context.clj:80)
	at metabase.query_processor.reducible$wire_up_context_channels_BANG_$fn__66755$state_machine__36873__auto____66764$fn__66766.invoke(reducible.clj:63)
	at metabase.query_processor.reducible$wire_up_context_channels_BANG_$fn__66755$state_machine__36873__auto____66764.invoke(reducible.clj:57)
	at clojure.core.async.impl.runtime$run_state_machine.invokeStatic(runtime.clj:62)
	at clojure.core.async.impl.runtime$run_state_machine.invoke(runtime.clj:61)
	at clojure.core.async.impl.runtime$run_state_machine_wrapped.invokeStatic(runtime.clj:66)
	at clojure.core.async.impl.runtime$run_state_machine_wrapped.invoke(runtime.clj:64)
	at clojure.core.async$ioc_alts_BANG_$fn__33198.invoke(async.clj:423)
	at clojure.core.async$do_alts$fn__33137$fn__33140.invoke(async.clj:290)
	at clojure.core.async.impl.channels.ManyToManyChannel$fn__32957.invoke(channels.clj:269)
	at clojure.lang.AFn.run(AFn.java:22)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at clojure.core.async.impl.concurrent$counted_thread_factory$reify__32795$fn__32796.invoke(concurrent.clj:29)
	at clojure.lang.AFn.run(AFn.java:22)
	at java.base/java.lang.Thread.run(Unknown Source)

Tony-metabase on (2024-10-03 12:55:57 UTC): How long does it take to run when you run it directly on your DB? and can you share the diagnostic information as well.

Also it would be more productive for both of us if this kind of issues are flagged in https://discourse.metabase.com/ cause this is not a bug and other users might experience the same problem and provide support

reddy2018 (Issue Creator) on (2024-10-03 13:56:25 UTC): when i ran directly in the db, it took almost 40mins.

reddy2018 (Issue Creator) on (2024-10-03 13:57:57 UTC): it seems some where in the metabase needs to change the timeout setting to run the query more than 20 mins.

If anyone faced the same problem please share the solution

Tony-metabase on (2024-10-03 14:16:15 UTC): I think you need to increase both the [MB_JETTY_ASYNC_RESPONSE_TIMEOUT](https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_jetty_async_response_timeout) and the [MB_DB_QUERY_TIMEOUT_MINUTES](https://www.metabase.com/docs/latest/configuring-metabase/environment-variables#mb_db_query_timeout_minutes)

Nonetheless please don't open Bugs for things related to configuration, you can get better support on Discourse  https://discourse.metabase.com/ 

Also if a query takes around 40mins to run, you need to perform some optimization around that. Imagine having a dashboard with 5 questions that take around 40 min each to run. That means a user has to wait 40 min to see the results.

reddy2018 (Issue Creator) on (2024-10-04 07:23:55 UTC): is this the correct way to setup [MB_DB_QUERY_TIMEOUT_MINUTES]

extraEnv:
  - name: MB_DB_QUERY_TIMEOUT_MINUTES
    value: ""60""
#  - name: MB_DB_QUERY_TIMEOUT_SEC
#    value: ""3600""
  - name: metabase.query-processor.query-timeout-ms
    value: ""3600000""
  - name: MB_DB_CONNECTION_TIMEOUT_MS
    value: ""3600000""

reddy2018 (Issue Creator) on (2024-10-04 07:42:12 UTC): @Tony-metabase can you please check my env varaible is correct or not

Tony-metabase on (2024-10-04 08:00:35 UTC): Moving the thread to discourse

"
2563894002,issue,open,,Inconsistent row count formatting,"### Describe the bug

[query](https://github.com/user-attachments/assets/7980b4bc-ce5f-4a1f-b368-8272bc330344) vs [dashboard](https://github.com/user-attachments/assets/66928cb8-8615-4973-868e-368b06724138)

### To Reproduce

1. Create a question based on Orders table
2. Run it

Notice rows count in bottom-right corner of the screen uses a comma separator: [image](https://github.com/user-attachments/assets/7980b4bc-ce5f-4a1f-b368-8272bc330344)

3. Add this question to a dashboard

Notice rows count in bottom-right corner of the dashcard does not use a comma separator: [image](https://github.com/user-attachments/assets/66928cb8-8615-4973-868e-368b06724138)

### Expected behavior

Rows count is formatted in the same way

### Information about your Metabase installation

master, 3a3785d27b11d2556c22e3c35f9b2767d305ea45

### Severity

P3
",kamilmielnik,2024-10-03 12:10:41+00:00,[],2025-02-04 20:28:43+00:00,,https://github.com/metabase/metabase/issues/48295,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2562915909,issue,open,,Implement attribution badges in SDK and track anonymous analytics for embedding usage,"We should Implement attribution badges in SDK, using the same LogoBadge component as the static and interactive iframe embeddings. We should also track anonymous analytics for embedding usage.",heypoom,2024-10-03 01:06:11+00:00,[],2025-02-04 20:25:56+00:00,,https://github.com/metabase/metabase/issues/48285,"[('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2562755962,issue,closed,completed,Update pre-release version format,"Old:
```
v0.51.0-RC1
v0.51.0-RC2
v0.51.0-RC3
```

New: 

(we only have plans to use `-beta` right now, but I want to build in enough flexibility to allow use of other suffixes if we want)
 ```
v0.51.0-alpha
v0.51.0.1-beta
v0.51.0.2-beta
v0.51.1-beta
v0.51.2-RC
```

Testing plan:
- [x] Should allow manual release with `beta` in the version
- [x] Should be able to auto-release a patch with `beta` in the version when the last version had `beta` in the title
- [x] prereleases should find the right milestone for release notes
- [ ] prereleases should not close milestones",iethree,2024-10-02 22:49:23+00:00,['iethree'],2024-10-07 13:41:36+00:00,2024-10-07 13:41:36+00:00,https://github.com/metabase/metabase/issues/48281,"[('.Building & Releasing', '')]",[],
2562744354,issue,open,,[Epic] Visualizer,"**Links**
- [product doc](https://www.notion.so/metabase/Create-the-Visualizer-for-easier-exploration-and-crafting-charts-a1273d1be0414d43b2e425511e36ba08#11369354c9018002a8c4f2450e169a5a) 
- [eng doc](https://www.notion.so/metabase/Visualizer-Tech-Design-55f42e7f881349a7bde2b161266fbd30?d=10669354c9018010b8d3001c140c562a#29ed58e7860b4c878b59405ccc589c25)
- branch: `feature-visualizer`

**Implementation Plan**

***Milestone 0.1***

- [x] Create visualizer page accessible from New -> Visualizer
- [x] Add the Data Importer stub: search input with list of results that calls the existing search endpoint
- [x] Add the Data Manager which shows questions selected in the Data Importer stub
- [x] Single dataset Funnel chart
  - [x] Render the Canvas that supports only Funnel chart and 1 dataset (as a regular funnel question)
  - [x] Implement Dimension/Metric selection via DnD from Data Manager
  - [x] Support funnel steps reordering via DnD
- [ ] N-scalar datasets Funnel chart
  - [ ] Implement data transformation from N-scalars into a single dataset to match API of the Funnel chart
  - [ ] Update Data Manager UI <> DnD to work sensibly in this case

",alxnddr,2024-10-02 22:39:35+00:00,['kulyk'],2024-10-28 16:36:28+00:00,,https://github.com/metabase/metabase/issues/48280,"[('.Epic', 'Feature Implementation or Project'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2562666961,issue,open,,Metric sourced query does not handle default time dimension correctly,"
With js console opened, create a new question on stats with source metric from my personal collection, named `metric: Orders + People, Count, Filtered by dta is before Feb 1, 2024`.

Metric contains default time dimension. The default breakout is based on custom column, based on joined column, in the metric definition.

When the source metric is resolved, erroneous query is created. This query initially includes the breakout by expression from the metric, but not that expression.

The query is cleaned up -- erroneous clause is removed. On stats, the question executes fine (with browser warnings). Locally however the exception is thrown.

I'm raising this issue because I believe we should not generate the broken query in the first place.

Relevant browser logs:

```
""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages\n  [{:lib/type :mbql.stage/mbql,\n    :source-table 1,\n    :breakout\n    [[:expression\n      {:base-type :type/DateTime, :temporal-unit :month, :lib/uuid \""a658e317-a657-4abf-99bd-2f14f213177b\""}\n      \""dta\""]],\n    :aggregation [[:metric {:lib/uuid \""3ba8dcda-438a-4271-901f-13ded08934eb\""} 19978]]}],\n  :database 1},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages\n   [{:lib/type :mbql.stage/mbql,\n     :source-table 1,\n     :breakout\n     [[:expression\n       {:base-type :type/DateTime, :temporal-unit :month, :lib/uuid \""a658e317-a657-4abf-99bd-2f14f213177b\""}\n       \""dta\""]],\n     :aggregation [[:metric {:lib/uuid \""3ba8dcda-438a-4271-901f-13ded08934eb\""} 19978]]}],\n   :database 1},\n  :errors\n  ({:path [0 0 :stages 0 0 0 0 1 :mbql.stage/mbql 0 4 0],\n    :in [:stages 0],\n    :schema #object[Object [object Object]],\n    :value\n    {:lib/type :mbql.stage/mbql,\n     :source-table 1,\n     :breakout\n     [[:expression\n       {:base-type :type/DateTime, :temporal-unit :month, :lib/uuid \""a658e317-a657-4abf-99bd-2f14f213177b\""}\n       \""dta\""]], \n     :aggregation [[:metric {:lib/uuid \""3ba8dcda-438a-4271-901f-13ded08934eb\""} 19978]]}})}}\n""
```

```
Clean: Removing bad clause due to error! 
Object { M: null, N: 1, shift: 5, root: {…}, yb: (1) […], K: null, C: 167666463, I: 401412 }
 :malli.core/limits {:breakout []}
app-main.0a4170244aa2c6ad.js:1:799069
```

Tested on stats with those warnings. Tested locally on `e12e36044e588761a3fb9aed10900a9d506d7fd6`.

We should not add the default time dimension in the metric sourced question, if that dimension is not available in query after source metric is resolved, or we should make it available.",lbrdnk,2024-10-02 21:27:03+00:00,[],2025-02-04 20:29:30+00:00,,https://github.com/metabase/metabase/issues/48277,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Semantic Model', ''), ('Semantic Model/Metrics', '')]",[],
2562654568,issue,closed,completed,Can't remove a staged Okta user from a Metabase group via SCIM,"### Describe the bug

If you're using Metabase with Okta for user management, you can create a new staged Okta user, sync it to Metabase, and add it to groups via SCIM. But if you try to remove the user from Metabase groups, it won't be reflected in Metabase, _unless_ you activate the user first. 

### To Reproduce

1. Set up Metabase and configure SAML and SCIM with Okta
2. Create a user in Okta, but don't activate them yet
3. Add the user to the Metabase application in Okta, and they should have an account created in Metabase
4. Add the user to a group in Okta that has been linked to a Metabase group and the user should appear in that group in Metabase
5. Remove the user from the group in Okta. They will still be in the Metabase group.
6. Activate the user in Okta, then try adding and removing them again. Now the user will be removed successfully from Metabase.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

Current master (`7821f98`)

### Severity

P2

### Additional context

_No response_",noahmoss,2024-10-02 21:17:19+00:00,[],2024-10-03 18:01:13+00:00,2024-10-03 18:01:12+00:00,https://github.com/metabase/metabase/issues/48276,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2391998140, 'issue_id': 2562654568, 'author': 'noahmoss', 'body': ""Update —\xa0after a little investigation, it seems like Okta isn't sending the correct API request when removing users from groups: https://devforum.okta.com/t/removed-user-still-included-in-group-update/23479"", 'created_at': datetime.datetime(2024, 10, 3, 17, 54, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392009410, 'issue_id': 2562654568, 'author': 'noahmoss', 'body': 'Ok, turns out this is a ""feature"": https://support.okta.com/help/s/article/Group-Push-Common-Issues?language=en_US\n\n> Users deactivated in Okta are not pushed to the downstream app. They must be reactivated, and then the group must be pushed. If the inactive user is part of more than one group, they must be pushed to all groups in which they are members.', 'created_at': datetime.datetime(2024, 10, 3, 18, 1, 12, tzinfo=datetime.timezone.utc)}]","noahmoss (Issue Creator) on (2024-10-03 17:54:39 UTC): Update — after a little investigation, it seems like Okta isn't sending the correct API request when removing users from groups: https://devforum.okta.com/t/removed-user-still-included-in-group-update/23479

noahmoss (Issue Creator) on (2024-10-03 18:01:12 UTC): Ok, turns out this is a ""feature"": https://support.okta.com/help/s/article/Group-Push-Common-Issues?language=en_US

"
2562260067,issue,closed,completed,Add more visible emphasis on hovered area series,"**Context**

[Slack report](https://metaboat.slack.com/archives/C01LQQ2UW03/p1727887388885849)

On a multi-series stacked area chart only lines are being emphasized on hover which may be a bit misleading visually. We need to emphasize hovered polygons as well and blur polygons of other series.

",alxnddr,2024-10-02 17:29:56+00:00,['alxnddr'],2024-10-03 23:25:31+00:00,2024-10-03 15:05:30+00:00,https://github.com/metabase/metabase/issues/48267,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2562240028,issue,open,,Show x-ray icon in x-rayable items in search results,"**Is your feature request related to a problem? Please describe.**
x-rays should be able to be launched from every place you se an x-rayable thing: e.g. search results!

**Describe the solution you'd like**
Be able to launch x-rays from the search results

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
requested by a customer, they give Metabase access to people that does data discoverability with Metabase and they were wondering why they can't actually use x-rays from the search

**Additional context**
NA
",paoliniluis,2024-10-02 17:21:12+00:00,[],2025-02-04 20:30:27+00:00,,https://github.com/metabase/metabase/issues/48266,"[('Type:New Feature', ''), ('Querying/X-rays', ''), ('Organization/Search', '')]","[{'comment_id': 2568157111, 'issue_id': 2562240028, 'author': 'brunobergher', 'body': 'I assume you mean to xray individual entries in the search results, not the whole of the resultset, right?', 'created_at': datetime.datetime(2025, 1, 2, 17, 58, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569537399, 'issue_id': 2562240028, 'author': 'paoliniluis', 'body': 'exactly @brunobergher, e.g. if the result of the search is a question or a model, you should be able to click the x-ray icon from the search results', 'created_at': datetime.datetime(2025, 1, 3, 16, 56, 18, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:58:55 UTC): I assume you mean to xray individual entries in the search results, not the whole of the resultset, right?

paoliniluis (Issue Creator) on (2025-01-03 16:56:18 UTC): exactly @brunobergher, e.g. if the result of the search is a question or a model, you should be able to click the x-ray icon from the search results

"
2561723137,issue,closed,completed,"Distinguish multiple ""Summaries"" column groups in dashboard filter mapping",,kamilmielnik,2024-10-02 13:39:20+00:00,['kamilmielnik'],2024-10-03 13:15:05+00:00,2024-10-03 13:15:05+00:00,https://github.com/metabase/metabase/issues/48260,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2391395364, 'issue_id': 2561723137, 'author': 'kamilmielnik', 'body': 'Closed by #48261', 'created_at': datetime.datetime(2024, 10, 3, 13, 15, 5, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-03 13:15:05 UTC): Closed by #48261

"
2561474974,issue,closed,completed,Dashboard filters on native questions work incorrectly when non-negative stage-number is used,"See e2e failure: https://github.com/metabase/metabase/actions/runs/11142882748?pr=48254

### To reproduce
1. `git checkout 48253-dashboard-filters-all-stages` (or `git checkout dashboard-filter-columns` if #48254 is already merged)
2. run this test: https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/e2e/test/scenarios/dashboard-filters/dashboard-filters-nested.cy.spec.js#L26

### 

Previously FE used to send negative `stage-number` (`-1`) in `parameters` payload to POST `api/dashboard/:id/dashcard/:id/card/:id/query`.
Now FE will send non-negative `stage-number` (`0`) and BE fails to apply that filter correctly to a native query.

### Additional info

I think it's caused by #46935 but I haven't verified this.
",kamilmielnik,2024-10-02 12:22:45+00:00,['appleby'],2024-10-07 16:17:29+00:00,2024-10-07 16:17:29+00:00,https://github.com/metabase/metabase/issues/48258,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2561380998,issue,closed,completed,Broken root collection link in dashboard info sidebar,"### Describe the bug

https://github.com/user-attachments/assets/865876f7-6299-40cb-8d8d-18f4e1ca8df3



### To Reproduce

1. Create a new dashboard and save it in ""Our analytics"" collection
2. Open dashboard
3. Open ""more info"" pane
4. Click link to the collection it's ""Saved in""



### Information about your Metabase installation

master, 3a3785d27b


### Severity

P2",kamilmielnik,2024-10-02 11:50:06+00:00,['iethree'],2024-10-08 16:13:37+00:00,2024-10-03 22:09:43+00:00,https://github.com/metabase/metabase/issues/48257,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Needs Triage', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2388454560, 'issue_id': 2561380998, 'author': 'kamilmielnik', 'body': ""While we're at it: the icon near the link is not interactive. It should be a part of the link.\r\n\r\nhttps://github.com/user-attachments/assets/b9aa1232-af3e-4ab3-9363-713a3a14ae3f"", 'created_at': datetime.datetime(2024, 10, 2, 11, 53, 11, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-02 11:53:11 UTC): While we're at it: the icon near the link is not interactive. It should be a part of the link.

https://github.com/user-attachments/assets/b9aa1232-af3e-4ab3-9363-713a3a14ae3f

"
2560994278,issue,closed,completed,Allow filtering on columns from all stages in dashboards,,kamilmielnik,2024-10-02 08:48:10+00:00,['kamilmielnik'],2024-10-03 13:04:06+00:00,2024-10-03 13:04:05+00:00,https://github.com/metabase/metabase/issues/48253,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2391371623, 'issue_id': 2560994278, 'author': 'kamilmielnik', 'body': 'Closed by #48254', 'created_at': datetime.datetime(2024, 10, 3, 13, 4, 5, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-03 13:04:05 UTC): Closed by #48254

"
2560517447,issue,open,,Set a limit for number of recipients for notification,"Currently users can create an alert / dashboard subscription and send to any number of emails, but most email services have a limit for the number of recipients an email can have (counting all to, cc, bcc).

There are a couple of options we can use to fix this:
1. Prevent users from adding more
2. Split to multiple emails on send
3. Send a single email per email address by

One note is that not all email services have the same limit. Here are the limits for popular services:
- Gmail: 500 for personal email, 2000 for business 
- Microsoft Outlook: 500
- Amazon SES: 50
- SendGrid: 1000
- Zoho Mail: 50 on the free plan and 500 on the paid plan

We can infer the service from the host URL and map it to the correct limit.

**Solution to be implemented:**

- New setting/env_var: MB_MAX_EMAIL_RECIPIENTS default 50 on Cloud, but self-hosted default null (they can change)
- In the FE, we limit the number of recipients based on this setting
-- user can't input the 51st email in the UI, pressing 'enter' doesn't add a new email to the list
-- user is displayed an error message: You can add up to 50 recipients. For larger lists, use email groups.",qnkhuat,2024-10-02 01:46:47+00:00,[],2025-02-04 20:29:30+00:00,,https://github.com/metabase/metabase/issues/48251,"[('Reporting/Pulses', 'Now called Subscriptions'), ('.Correctness', ''), ('Reporting/Alerts', ''), ('Misc/Emails', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2387476349, 'issue_id': 2560517447, 'author': 'qnkhuat', 'body': 'As a quick improvement for our cloud customer, we should implement 1 first. see this [thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1727774259486959?thread_ts=1727117880.551949&cid=C01LQQ2UW03)', 'created_at': datetime.datetime(2024, 10, 2, 1, 47, 26, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-10-02 01:47:26 UTC): As a quick improvement for our cloud customer, we should implement 1 first. see this [thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1727774259486959?thread_ts=1727117880.551949&cid=C01LQQ2UW03)

"
2560349517,issue,open,,"Add ""At Least/On or after"" or ""Within"" filters to dates","**Is your feature request related to a problem? Please describe.**
Dashboard users (i.e. customers) may be confused by the simple semantics of choosing all dates in a month by wanting to choose Aug 1. through Aug. 31, for example. ""After"" August 1 and ""Before"" August 31 (or ""Between"" August 1-31) is quite literally incorrect, but some people will choose this, or want the option, because they expect to choose an inclusive date or they've used SQL between, which is inclusive.

**Describe the solution you'd like**
It would be great to have the options of:
- ""At least"" or ""On or after"" to have an inclusive start date.
- ""At most"" or ""On or before"" to have an inclusive end date.
- ""Within"" to have an inclusive span selection.

**Describe alternatives you've considered**
Right now I just need to educate people that they should treat ""Before"" and ""After"" literally and use the dates abutting those to get the result the want.

**How important is this feature to you?**
Very nice to have.

**Additional context**
Where it might be useful:
<img width=""356"" alt=""image"" src=""https://github.com/user-attachments/assets/44f2601d-df21-4f64-8484-3906c4ffa497"">

👋 Hey guys, hope to see some of you at the conj. Metabase rocks! 👋 

",markbastian,2024-10-01 22:55:38+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/48249,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2559739693,issue,closed,completed,Move managed identity auth to EE namespace and add a feature flag,"feature flag: `database-auth-providers`

- [ ] add a conditional to show `use an authentication provider` if the feature flag is there
- [ ] add a conditional to hide `use an authentication provider` if the instance is hosted in our Cloud
- [ ] gate the appdb managed identity auth behind the feature flag",luizarakaki,2024-10-01 16:44:44+00:00,[],2024-10-08 16:13:26+00:00,2024-10-07 16:13:27+00:00,https://github.com/metabase/metabase/issues/48235,"[('Database/Postgres', None), ('.Team/Drivers', '')]",[],
2559677049,issue,open,,Pivot Table Error: Removing a Measure in GUI Causes Visualization Failure,"### Describe the bug

With an existing pivot table, you will receive an error when you remove a measure/summarized field within the GUI editor and visualize. You can go back to the editor to click visualize again, and the pivot table will display.

Tested this in 1.50.27
In 1.49.24, it works fine without producing an error.

### To Reproduce

1. Create a pivot table and visualize it.

2. Go back to editor and remove a field from Summarize section and click visualize.
<img width=""558"" alt=""Screenshot 2024-10-01 at 9 56 35 AM"" src=""https://github.com/user-attachments/assets/d4dddca1-3286-48e9-b8c2-b24d05fd0f1f"">

3. Go back to the editor and click visualize and the pivot table will display once again.


Loom
https://www.loom.com/share/1a5f5a30cda5447397aef412c1ee0ae4?sid=bcc11b14-947f-414f-b5fd-e8dca977e0df


### Expected behavior

How it worked in previous versions without generating an error.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse"",
      ""sqlserver"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v1.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Chicago""
  }
}
```


### Severity

P3 - Easy workaround but interrupts customer workflow

### Additional context

_No response_",FilmonK,2024-10-01 16:10:23+00:00,[],2025-02-04 20:31:55+00:00,,https://github.com/metabase/metabase/issues/48234,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2559120868,issue,open,,"When creating an alert, we should auto-select the first valid channel","### Describe the bug

![image](https://github.com/user-attachments/assets/5dabe5cd-a20c-4513-b172-c9eb2f920834)

We should select Slack instead of not-configured Email

### To Reproduce

1. Add Slack or Webhook and don't add an Email server
2. Try to set up an alert
3. See that it is selecting Email

### Expected behavior

Select the first valid channel

### Logs

_No response_

### Information about your Metabase installation

```JSON
master 012408e
```


### Severity

P3

### Additional context

_No response_",luizarakaki,2024-10-01 12:45:45+00:00,[],2025-02-04 20:29:31+00:00,,https://github.com/metabase/metabase/issues/48224,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2559059667,issue,closed,completed,[Spike] Detect missing attribution in the SDK,Investigate if it's possible to detect missing attributions in the SDK. See [Notion for the result and proof-of-concept](https://www.notion.so/metabase/Detecting-missing-attributions-in-the-SDK-11469354c90180508524e319db01f988?pvs=4) of this spike.,heypoom,2024-10-01 12:20:27+00:00,['heypoom'],2024-10-03 15:21:29+00:00,2024-10-02 11:38:48+00:00,https://github.com/metabase/metabase/issues/48222,[],[],
2558753012,issue,closed,completed,[Spike] Reusing Metabase E2E tests for embedding SDK,"[Spike doc on Notion](https://www.notion.so/metabase/Spike-Reusing-Metabase-E2E-tests-for-embedding-SDK-11369354c901803ab197d32d26400841)

Based on the project [Detect breaking changes in API](https://www.notion.so/metabase/Detect-breaking-changes-in-API-5775e2b0f423483594c5a4881f688a84), we want to explore if we could reuse existing Metabase E2E tests for embedding SDk.

Some ideas:
- Try testing view-only components with existing tests, some mechanisms might not 100% match the behavior on the app, but they should be pretty close.
- Components that provide interactivity and modification are less likely to match the design for the SDK.
- Maybe we could use Cypress tag, to flag certian tests that could be run on both environments.",WiNloSt,2024-10-01 09:58:04+00:00,['WiNloSt'],2024-10-07 13:19:43+00:00,2024-10-07 13:19:41+00:00,https://github.com/metabase/metabase/issues/48219,[],"[{'comment_id': 2396916095, 'issue_id': 2558753012, 'author': 'WiNloSt', 'body': ""I've concluded this spike on Notion with the [what to do next.](https://www.notion.so/metabase/Spike-Reusing-Metabase-E2E-tests-for-embedding-SDK-11369354c901803ab197d32d26400841?pvs=4#11869354c901804395f2c244fccc6693)"", 'created_at': datetime.datetime(2024, 10, 7, 13, 19, 41, tzinfo=datetime.timezone.utc)}]","WiNloSt (Issue Creator) on (2024-10-07 13:19:41 UTC): I've concluded this spike on Notion with the [what to do next.](https://www.notion.so/metabase/Spike-Reusing-Metabase-E2E-tests-for-embedding-SDK-11369354c901803ab197d32d26400841?pvs=4#11869354c901804395f2c244fccc6693)

"
2558729097,issue,open,,"Filter is not applied on ""ENTER"" keyboard button with ""is / is not"" option.","### Describe the bug

I am encountering an issue with filter functionality. When applying filter values using the keyboard's Enter key, the behavior is inconsistent. Specifically, filters like 'is' and 'is not' do not respond to Enter, while options such as 'greater than' and 'less than' function as expected. Is there a way to ensure consistent Enter key behavior across all filter options?


https://github.com/user-attachments/assets/aa15e359-d224-47b2-af37-bd9342bd3415



### To Reproduce

1. Go to Question and choose Sample database with Orders table
2. Click on Filter and choose ID as filtered column
3. Choose is / is not as option and type any number, then press enter.
4. Filter is not applied.

Now do the same steps 1-2.
3. Choose less than / greater than  and type any number, then press enter.
4. Filter is applied.


### Expected behavior

The expected behavior is for the filter to be applied when the Enter key is pressed, regardless of whether the selected option is 'is' or 'is not.' Currently, this functionality only works for other filter options.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.85+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""sqlserver"",
      ""h2"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.6 (Ubuntu 13.6-1.pgdg20.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-12"",
      ""tag"": ""v0.50.19.4"",
      ""hash"": ""e05a1ea""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

normal

### Additional context

_No response_",DaKoMT,2024-10-01 09:47:44+00:00,[],2025-02-04 20:27:35+00:00,,https://github.com/metabase/metabase/issues/48218,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2557564702,issue,closed,completed,Remove deprecated `MB_API_KEY` used in notify endpoint,"**Context**
We shipped API keys on v49. They should replace this feature.
[Context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1727471920876049)
",luizarakaki,2024-09-30 20:19:42+00:00,['johnswanson'],2024-11-26 18:51:42+00:00,2024-10-14 11:57:35+00:00,https://github.com/metabase/metabase/issues/48210,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2405236203, 'issue_id': 2557564702, 'author': 'johnswanson', 'body': ""@luizarakaki one issue is that you can't currently create an API key programatically. I think we might need to build a solution for that before we can totally remove `MB_API_KEY`, because people might be depending on the ability to set an API key when launching Metabase."", 'created_at': datetime.datetime(2024, 10, 10, 14, 22, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405256733, 'issue_id': 2557564702, 'author': 'luizarakaki', 'body': ""Given the scope of this API key, I'm not too concerned about this. I'd be more concerned if it was an endpoint required for instance setup like permissions or settings.\n\nFwiw I think we should have a way to generate API keys using the CLI or config.yml, but I wouldn't tie these things."", 'created_at': datetime.datetime(2024, 10, 10, 14, 30, 27, tzinfo=datetime.timezone.utc)}]","johnswanson (Assginee) on (2024-10-10 14:22:32 UTC): @luizarakaki one issue is that you can't currently create an API key programatically. I think we might need to build a solution for that before we can totally remove `MB_API_KEY`, because people might be depending on the ability to set an API key when launching Metabase.

luizarakaki (Issue Creator) on (2024-10-10 14:30:27 UTC): Given the scope of this API key, I'm not too concerned about this. I'd be more concerned if it was an endpoint required for instance setup like permissions or settings.

Fwiw I think we should have a way to generate API keys using the CLI or config.yml, but I wouldn't tie these things.

"
2557555590,issue,open,,"Tasks Log Indicates ""Success"" for Slack Alerts that cannot be Delivered b/c Target Channel is missing","### Describe the bug

If you send a Slack alert to a channel that doesn't exist, the files are received by the channel that holds the files multiple times (I would guess once for each retry).

The subscription doesn't deliver to the target channel because it doesn't exist. This is logged in troubleshooting -> Logs"" but if you look in ""Troubleshooting -> Tasks"" that send-pulse tasks indicates a status of ""success"" despite the fact the subscription couldn't be delivered.

### To Reproduce

1. Set up a Slack integration with channel called #metabase_files to hold the images
2. Set up a Slack Subscription to #some_channel
3. Test to illustrate that it works
4. Update the alert to point to a channel that doesn't exist
5. Wait for the scheduled send-pulse task
6. Note that the images from the subscription land in #metabase_files several times over
7. Look in 'Troubleshooting -> Tasks"" and note that the ""send-pulse"" tasks is logged as successful

### Expected behavior

- The send-pulse task should log the failure (and, ideally, why)
- If we are performing a retry on these we probably shouldn't because if the channel doesn't exist we already know the retry will fail.



### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.25
```


### Severity

Defeats the purpsoes of 

### Additional context

_No response_",ixipixi,2024-09-30 20:14:01+00:00,[],2025-02-04 20:26:24+00:00,,https://github.com/metabase/metabase/issues/48209,"[('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Notifications/Slack', ''), ('.Team/Workflows', 'aka BEC')]",[],
2557480714,issue,closed,completed,Swag Button for RC,"**Context**
Shiny new button in the admin app. For VIPs only.

[Slack Thread](https://metaboat.slack.com/archives/C07NW0WQG30/p1727358748619939)

",npfitz,2024-09-30 19:28:30+00:00,['npfitz'],2024-10-08 16:13:50+00:00,2024-10-02 17:45:04+00:00,https://github.com/metabase/metabase/issues/48208,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2557202029,issue,open,,Support for custom IAM Roles in AWS Athena configuration,"**Is your feature request related to a problem? Please describe.**
To extending the AWS Athena driver configuration in Metabase to include the ability to specify an IAM role to be used in the absence of access/secret keys instead of the defaults on the server. 

Currently the AWS Athena driver has the following way to authenticate with AWS:

Using AWS Access and Secret keys if provided
If keys are not provided, driver will try to authenticate using [DefaultAWSCredentialsProviderChain](https://github.com/metabase/metabase/blob/master/modules/drivers/athena/src/metabase/driver/athena.clj#L69) trying to find credentials on machine where Metabase is running 

Now, the limitation is when trying to specify a custom role by providing its ARN.

There are some links about assuming role and using temporary credentials from it:

https://docs.aws.amazon.com/sdkref/latest/guide/feature-assume-role-credentials.html
https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/credentials.html#credentials-specify-provider


**Describe the solution you'd like**
Example:

- in AWS account ""A"" there is a role ""MetabaseRole"", under which Metabase runs

- in AWS account ""B"" there is a role ""AthenaRole"", which has an IAM assigned for Athena along with all other accesses

- in addition, of course, both accounts can connect to each other (appropriate organization policy)

 
Based on its role (""MetabaseRole""), Metabase normally doesn't have access to Athena in account ""B"", so it has to perform an additional AssumeRole for the ""AthenaRole"" role, creating a so-called CredentialsChain (in this case ""MetabaseRole"" -> ""AthenaRole""). Based on this, Metabase can freely connect to Athena.

That's where allowing the option (and setting up logic) to add a custom role by using ARN will do the trick:

![image](https://github.com/user-attachments/assets/b39394c0-b407-46ba-be15-e23a184d7de1)

**Additional context**
The above feature request was defined by a customer and they already have a fork of the Athena driver with modifications to support the above logic",Tony-metabase,2024-09-30 17:01:04+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/48203,"[('Type:New Feature', ''), ('Administration/Databases', ''), ('Database/Athena', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2557021925,issue,closed,completed,Downloading data from Mongo Custom Query breaks the output,"### Describe the bug

When creating a new custom query and downloading the results as CSV/JSON, the data downloaded is broken. The query I'm using is: 

```
[
  { $unwind: ""$events"" },
  {
    $group: {
      _id: {
        numberId: ""$numberId"",
        companyId: ""$companyId""
      },
      eventsMap: {
        $push: {
          k: ""$events.name"",
          v: ""$events.date""
        }
      }
    }
  },
  {
    $project: {
      numberId: ""$_id.numberId"",
      companyId: ""$_id.companyId"",
      events: { $arrayToObject: ""$eventsMap"" },
      _id: 0
    }
  },
  { $limit: 10 }
]
```

this returns values like 

![Screenshot 2024-09-30 122852](https://github.com/user-attachments/assets/e7ff998b-711b-4878-a962-944de9a86767)

At first sight the data seems correct, but when downloading it as JSON I get:

```
    {
        ""numberId"": ""1000025"",
        ""companyId"": ""6579c1d289ad6a000767524f"",
        ""events"": ""{:last-accessed 2024-09-16T01:13:44.484Z, :last-order-created 2024-09-16T01:15:05.930Z}""
    },
```

The ""events"" object is parsed as a string and it is badly constructed too.

### To Reproduce

1. Create a custom mongo query that returns an object such as described above
2. Download data as JSON/CSV


### Expected behavior

It should download a proper JSON/CSV

### Logs

_No response_

### Information about your Metabase installation

```JSON
      ""tag"": ""v0.50.24"",
```


### Severity

blocking

### Additional context

_No response_",cubargh,2024-09-30 15:33:24+00:00,['adam-james-v'],2024-11-07 18:45:31+00:00,2024-10-30 00:09:52+00:00,https://github.com/metabase/metabase/issues/48198,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Visualization/Download', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2556680246,issue,open,,Referencing metrics with same joins apart from condition produces query with only one join,"M1 is a metric with join J1. M2 is a metric with join J2. J1 and J2 are equivalent apart from join condition. Q is a question that (1) uses M1 as source and (2) references M2.

_Problem._ Only join from the first metric is added to the executed query.

There is [a question](https://stats.metabase.com/question/19882-question-to-demonstrate-only-1-join-from-metric-is-used) on stats (in case previous link does not work for you, here is the [question](https://stats.metabase.com/question/23760-question-to-demonstrate-only-1-join-from-metric-is-used-public) in my public collection) that can be used to re-create the setup locally. The metrics can be found in my personal collection.

The preprocessed query (follows) was taken from `metabase.query-processor/process-query**`.

I believe both joins should be added to the executed query.

---

Following is sent from FE:
```
{
  ""database"": 1,
  ""type"": ""query"",
  ""query"": {
    ""source-table"": 5,
    ""aggregation"": [
      [
        ""metric"",
        115
      ],
      [
        ""metric"",
        117
      ]
    ],
    ""breakout"": [
      [
        ""field"",
        41,
        {
          ""base-type"": ""type/DateTime"",
          ""temporal-unit"": ""month""
        }
      ]
    ]
  },
  ""parameters"": []
}
```

Preprocessed query looks as follows (checked locally; names may differ to what's on stats):
```
{:database 1,
 :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
 :info
 {:executed-by 1,
  :context :ad-hoc,
  :query-hash
  [-53, 126, 34, 28, -125, -1, -33, 39, 81, 42, -67, 45, 4, 124, 31, 101, -94, 127, 82, -39, -123, 74, -52, -49, 79, 8,
   -2, -94, 15, 120, -27, 10]},
 :constraints {:max-results 10000, :max-results-bare-rows 2000},
 :type :query,
 :query
 {:source-table 5,
  :aggregation
  [[:aggregation-options [:count] {:name ""m: Orders + Products, Count""}]
   [:aggregation-options
    [:sum [:field 42 {:base-type :type/Float}]]
    {:name ""m: s:orders+not=+products, f:normal, a:sum total, b: c_at month""}]],
  :breakout [[:field 41 {:base-type :type/DateTime, :temporal-unit :month}]],
  :filter
  [:<
   [:field 41 {:base-type :type/DateTime, :temporal-unit :default}]
   [:absolute-datetime #t ""2024-02-01T00:00"" :default]],
  :order-by [[:asc [:field 41 {:base-type :type/DateTime, :temporal-unit :month}]]],
  :joins
  [{:alias ""Products"",
    :strategy :left-join,
    :fields
    [[:field 62 {:join-alias ""Products""}]
     [:field 63 {:join-alias ""Products""}]
     [:field 65 {:join-alias ""Products""}]
     [:field 58 {:join-alias ""Products""}]
     [:field 60 {:join-alias ""Products""}]
     [:field 59 {:join-alias ""Products""}]
     [:field 61 {:join-alias ""Products""}]
     [:field 64 {:join-alias ""Products""}]],
    :condition
    [:= [:field 40 {:base-type :type/Integer}] [:field 62 {:base-type :type/BigInteger, :join-alias ""Products""}]],
    :source-table 8}]}}
```",lbrdnk,2024-09-30 13:25:19+00:00,[],2025-02-04 20:29:26+00:00,,https://github.com/metabase/metabase/issues/48192,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Semantic Model', ''), ('Semantic Model/Metrics', '')]","[{'comment_id': 2614054838, 'issue_id': 2556680246, 'author': 'ericnormand', 'body': 'I cannot access the linked to question on stats. Can you give me access, @lbrdnk ?', 'created_at': datetime.datetime(2025, 1, 25, 18, 20, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614069302, 'issue_id': 2556680246, 'author': 'ericnormand', 'body': 'I cannot reproduce this bug. Here is what I\'ve done:\n\n## M1\n\n<img width=""757"" alt=""Image"" src=""https://github.com/user-attachments/assets/d5c81987-c723-475d-8bad-058e7fb195b1"" />\n\nReviews joined to Product where Reviews.product id = product.id\n\n## M2\n\n<img width=""673"" alt=""Image"" src=""https://github.com/user-attachments/assets/589569eb-f2d6-4dc2-93d3-a547b75ef3a4"" />\n\nReviews joined to Product where Reviews.created at > product. created at\n\n## Question\n\n<img width=""813"" alt=""Image"" src=""https://github.com/user-attachments/assets/a47465d2-670c-4a56-a05a-5e39e1ebba60"" />\n\nThis is posted to `/api/dataset`:\n\n```\n{\n  ""database"": 1,\n  ""type"": ""query"",\n  ""query"": {\n    ""source-table"": 4,\n    ""aggregation"": [\n      [\n        ""metric"",\n        129\n      ],\n      [\n        ""metric"",\n        130\n      ]\n    ],\n    ""breakout"": [\n      [\n        ""field"",\n        55,\n        {\n          ""base-type"": ""type/DateTime"",\n          ""temporal-unit"": ""month""\n        }\n      ]\n    ],\n    ""limit"": 10,\n    ""aggregation-idents"": {\n      ""0"": ""56zrcKLN0kpxfBUtpWbem"",\n      ""1"": ""RglL2ydnPMUDFRMRWer0g""\n    },\n    ""breakout-idents"": {\n      ""0"": ""NXQCh74UXGJVb5GwiUGJ7""\n    }\n  },\n  ""parameters"": []\n}\n```\n\n(Very similar to OP json)\n\nHere is the generated SQL in the SQL Viewer in the editor:\n\n```\nSELECT\n  DATE_TRUNC(\'month\', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") AS ""CREATED_AT"",\n  COUNT(*) AS ""count"",\n  COUNT(*) AS ""count_2""\nFROM\n  ""PUBLIC"".""REVIEWS""\n \nLEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""Products"" ON ""PUBLIC"".""REVIEWS"".""PRODUCT_ID"" = ""Products"".""ID""\n  LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""Products - Created At"" ON DATE_TRUNC(\'month\', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") > DATE_TRUNC(\'month\', ""Products - Created At"".""CREATED_AT"")\nGROUP BY\n  DATE_TRUNC(\'month\', ""PUBLIC"".""REVIEWS"".""CREATED_AT"")\nORDER BY\n  DATE_TRUNC(\'month\', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") ASC\n```\n\nIt clearly has two the two joins.\n\nIs there something in the setup of the metrics that I missed?', 'created_at': datetime.datetime(2025, 1, 25, 19, 9, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616361802, 'issue_id': 2556680246, 'author': 'ericnormand', 'body': 'To reproduce:\n\nMetric M1:\n\n<img width=""905"" alt=""Image"" src=""https://github.com/user-attachments/assets/f72be154-c840-49c6-9f00-5dc694850f9c"" />\n\nMetric M2:\n\n<img width=""951"" alt=""Image"" src=""https://github.com/user-attachments/assets/20c1491b-6baa-4345-afee-08ffa8447362"" />\n\nNotice that the join conditions are OPPOSITE (order.product id != product.id vs order.product id = product.id). The formulas are also different (Sum vs Count).\n\nQuestion:\n\n<img width=""1100"" alt=""Image"" src=""https://github.com/user-attachments/assets/29562d07-4aa6-4def-9fb4-5af788cad0cd"" />\n\nThe cause is the opposite join condition.', 'created_at': datetime.datetime(2025, 1, 27, 16, 56, 10, tzinfo=datetime.timezone.utc)}]","ericnormand on (2025-01-25 18:20:11 UTC): I cannot access the linked to question on stats. Can you give me access, @lbrdnk ?

ericnormand on (2025-01-25 19:09:24 UTC): I cannot reproduce this bug. Here is what I've done:

## M1

<img width=""757"" alt=""Image"" src=""https://github.com/user-attachments/assets/d5c81987-c723-475d-8bad-058e7fb195b1"" />

Reviews joined to Product where Reviews.product id = product.id

## M2

<img width=""673"" alt=""Image"" src=""https://github.com/user-attachments/assets/589569eb-f2d6-4dc2-93d3-a547b75ef3a4"" />

Reviews joined to Product where Reviews.created at > product. created at

## Question

<img width=""813"" alt=""Image"" src=""https://github.com/user-attachments/assets/a47465d2-670c-4a56-a05a-5e39e1ebba60"" />

This is posted to `/api/dataset`:

```
{
  ""database"": 1,
  ""type"": ""query"",
  ""query"": {
    ""source-table"": 4,
    ""aggregation"": [
      [
        ""metric"",
        129
      ],
      [
        ""metric"",
        130
      ]
    ],
    ""breakout"": [
      [
        ""field"",
        55,
        {
          ""base-type"": ""type/DateTime"",
          ""temporal-unit"": ""month""
        }
      ]
    ],
    ""limit"": 10,
    ""aggregation-idents"": {
      ""0"": ""56zrcKLN0kpxfBUtpWbem"",
      ""1"": ""RglL2ydnPMUDFRMRWer0g""
    },
    ""breakout-idents"": {
      ""0"": ""NXQCh74UXGJVb5GwiUGJ7""
    }
  },
  ""parameters"": []
}
```

(Very similar to OP json)

Here is the generated SQL in the SQL Viewer in the editor:

```
SELECT
  DATE_TRUNC('month', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") AS ""CREATED_AT"",
  COUNT(*) AS ""count"",
  COUNT(*) AS ""count_2""
FROM
  ""PUBLIC"".""REVIEWS""
 
LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""Products"" ON ""PUBLIC"".""REVIEWS"".""PRODUCT_ID"" = ""Products"".""ID""
  LEFT JOIN ""PUBLIC"".""PRODUCTS"" AS ""Products - Created At"" ON DATE_TRUNC('month', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") > DATE_TRUNC('month', ""Products - Created At"".""CREATED_AT"")
GROUP BY
  DATE_TRUNC('month', ""PUBLIC"".""REVIEWS"".""CREATED_AT"")
ORDER BY
  DATE_TRUNC('month', ""PUBLIC"".""REVIEWS"".""CREATED_AT"") ASC
```

It clearly has two the two joins.

Is there something in the setup of the metrics that I missed?

ericnormand on (2025-01-27 16:56:10 UTC): To reproduce:

Metric M1:

<img width=""905"" alt=""Image"" src=""https://github.com/user-attachments/assets/f72be154-c840-49c6-9f00-5dc694850f9c"" />

Metric M2:

<img width=""951"" alt=""Image"" src=""https://github.com/user-attachments/assets/20c1491b-6baa-4345-afee-08ffa8447362"" />

Notice that the join conditions are OPPOSITE (order.product id != product.id vs order.product id = product.id). The formulas are also different (Sum vs Count).

Question:

<img width=""1100"" alt=""Image"" src=""https://github.com/user-attachments/assets/29562d07-4aa6-4def-9fb4-5af788cad0cd"" />

The cause is the opposite join condition.

"
2556426050,issue,closed,completed,List metrics in Learn your data,"When the user opens any table or model in the Learn your data section in the SQL editor, if there are metrics defined on this data source, show them in a similar way we show models below the list of the table/model connections

![Captura de ecrã 2024-09-04, às 14 42 27](https://github.com/user-attachments/assets/e6b59dee-a75e-4f36-a9c4-121ad5683e3f)
",romeovs,2024-09-30 11:54:42+00:00,['romeovs'],2024-10-01 16:20:44+00:00,2024-10-01 16:20:44+00:00,https://github.com/metabase/metabase/issues/48190,"[('Type:New Feature', ''), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2556294107,issue,open,,Use Badge from `metabase/ui` once that ships,"Context: https://metaboat.slack.com/archives/C057WD5L0JG/p1726586842672059

We're using some hand made Badge components in both the embed homepage and in the admin settings, we should still have an official Badge component in metabase/ui, once that gets made we should refactor the pages to use that",npretto,2024-09-30 10:57:28+00:00,[],2024-09-30 10:58:35+00:00,,https://github.com/metabase/metabase/issues/48189,"[('.Team/Embedding', '')]",[],
2555621765,issue,open,,Incorrect mouse cursor in command palette actions,"### Describe the bug

![image](https://github.com/user-attachments/assets/cb17340c-5605-4649-b262-d35c12b760ef)

----

![image](https://github.com/user-attachments/assets/5ffc89ac-a449-48ad-accc-21bd4f629311)


### To Reproduce

1. Ctrl + K
2. Hover over ""New question"" action (text or icon)

### Expected behavior

Cursor should be `pointer`

### Information about your Metabase installation

master, e12e36044e588761a3fb9aed10900a9d506d7fd6


### Severity

P3
",kamilmielnik,2024-09-30 05:46:15+00:00,[],2025-02-04 20:27:24+00:00,,https://github.com/metabase/metabase/issues/48186,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2555362880,issue,closed,not_planned,Cannot move content to sub-collection from current collection,"### Describe the bug

I have content in a collection that is not sorted. I would like to create sub-collections and move the content to the appropriate sub-collection. I am unable to move content into sub-collections from the current collection, because it is greyed out/disabled and not selectable--and its sub-collections are also not selectable. I can move to other collections not in the current collection.

Workaround:
- Move content one by one instead of selecting all content and moving.

Problem with Workaround:
- Current State with Workaround
  - 4 clicks per content moved individually
    - `y = 4x`
  - Okay for moving 3 pieces of content
    - 12 clicks for moving 3 pieces of content
  - Not okay for 30+
      - 120 clicks for moving 30 pieces of content
- Corrected State without Workaround
  - 1 click per content moved + 4 clicks for moving as group
  - `y = x + 4`
  - 34 clicks for moving 30 pieces of content (or less if select all used)

Another workaround:
- If moving more than 30 pieces of content to a sub-collection, then can create sub-collection outside of current collection, move content there, then move sub-collection back to original collection.


### To Reproduce

1. View an existing collection with content
2. Create a new sub-collection
3. Select one or more items with checkbox
4. Click 3 dot context menu
5. Click Move
6. Unable to select current collection (and thus unable to select sub-collections)

### Expected behavior

Should be able to:
- ""move"" something to its existing location (i.e. nothing changes)
- ""move"" content to a sub-collection of its current collection

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase Version: v1.50.25.2
```


### Severity

P2: Broken common functionality for creators/power-users; Adds a lot of friction to organizing content into sub-collections

### Additional context

_No response_",likeshumidity,2024-09-30 02:00:39+00:00,[],2025-02-05 19:24:26+00:00,2025-02-05 19:24:08+00:00,https://github.com/metabase/metabase/issues/48184,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2382404828, 'issue_id': 2555362880, 'author': 'crisptrutski', 'body': 'Thanks for the report. \r\n\r\nSince the escrow-collection based solution (""another workaround"") exists with only 4 additional clicks over the ideal solution, if I understand correctly, I\'ve lowered this to a P3 for now.', 'created_at': datetime.datetime(2024, 9, 30, 8, 9, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634898971, 'issue_id': 2555362880, 'author': 'npfitz', 'body': '@likeshumidity Which 3 dot button are you clicking for this operation? Are you able to use the Move action in the bulk actions popover in the bottom of the screen to move the items?', 'created_at': datetime.datetime(2025, 2, 4, 19, 38, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2637837098, 'issue_id': 2555362880, 'author': 'luizarakaki', 'body': ""couldn't repro, will reopen if more details"", 'created_at': datetime.datetime(2025, 2, 5, 19, 24, 25, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-09-30 08:09:45 UTC): Thanks for the report. 

Since the escrow-collection based solution (""another workaround"") exists with only 4 additional clicks over the ideal solution, if I understand correctly, I've lowered this to a P3 for now.

npfitz on (2025-02-04 19:38:24 UTC): @likeshumidity Which 3 dot button are you clicking for this operation? Are you able to use the Move action in the bulk actions popover in the bottom of the screen to move the items?

luizarakaki on (2025-02-05 19:24:25 UTC): couldn't repro, will reopen if more details

"
2554817493,issue,open,,meatabase version problem,"What is the latest version of the JDK 8 that can be used?

",yuanweiGit,2024-09-29 08:51:20+00:00,[],2025-02-04 20:23:52+00:00,,https://github.com/metabase/metabase/issues/48183,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2554535947,issue,open,,"Dashboard click behavior > To other dashbaord with filters: Empty strings cause filtering by ""(empty)"" instead of an empty string","### Describe the bug

**This should be easy to solve:**

Situation: I have a dashboard 1 that contains a visualization 1 with a click behaviour. This click behaviour has a few filters defined that are passed on to the linked other dashbaord 2.

Problem: If the row that's clicked in visualization 1 contains an empty string for any of those passed on values, dashboard 2's filters receive the string ""(empty)"" instead of an empty string, which causes dashboard 2 to ""crash"" because it is told to filter by values that don't exist:

![image](https://github.com/user-attachments/assets/2992bc5a-95bc-4c1d-bd24-0703202096a8)


### To Reproduce

1. Have a dataset with rows that contain empty strings in some columns you want to filter by
2. Create a dashboard that visualizes the dataset
3. Add a click behaviour to the visualization that links to another dashboard which contains a filter for a row where the dataset has some rows containing empty strings.
4. Have fun with ""(empty)"".

### Expected behavior

How it should be:

![image](https://github.com/user-attachments/assets/7d4feaa5-26e3-4a65-9423-af0df5f8f9c5)

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""de"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Debian 16.4-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.12-2-pve"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

Highly confusion-inducing

### Additional context

_No response_",nepomuc,2024-09-28 22:02:51+00:00,[],2025-01-03 15:30:35+00:00,,https://github.com/metabase/metabase/issues/48182,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2382429670, 'issue_id': 2554535947, 'author': 'crisptrutski', 'body': ""Labelling as P2 as there doesn't seem to be a clear workaround."", 'created_at': datetime.datetime(2024, 9, 30, 8, 21, 19, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-09-30 08:21:19 UTC): Labelling as P2 as there doesn't seem to be a clear workaround.

"
2553964983,issue,open,,Atomic Refresh for Persisted Models,"**Is your feature request related to a problem? Please describe.**
Currently when a persisted model is refreshed, the cache is invalidated before the new persisted data is generated. This means if we have a 90 second query that we're caching, the refresh process drops the current persisted data and it takes 90 seconds for the new data to become available. 

Other queries that rely on the cache can't use it during this time. If we're refreshing these models every 15 minutes then users experience slower query times / performance degradation a few times and hour.

**Describe the solution you'd like**
It would be great if the persisted data remained valid until the new data was available.

Currently it look like we do a ""drop / create table as"". Maybe doing a ""create table as tempCache"" then, when it's ready drop the old cache and rename the temp cache to replace it. 

**Describe alternatives you've considered**
Creating persisted tables or materialized views independently of Metabase

",ixipixi,2024-09-28 02:38:11+00:00,[],2025-02-04 20:30:54+00:00,,https://github.com/metabase/metabase/issues/48180,"[('Type:New Feature', ''), ('Querying/Cache', '')]",[],
2553830298,issue,closed,not_planned,.csv Download STATUS_BREAKPOINT Error ,"**Describe the bug**
A clear and concise description of what the bug is.

**Logs**
``` Docker Logs
2024-09-27 22:14:40,260 ERROR middleware.catch-exceptions :: Error processing query: ERROR: canceling statement due to user request
{:database_id 3,
 :started_at #t ""2024-09-27T22:13:39.808193Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Erro ao executar consulta: ERROR: canceling statement due to user request"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__82465$fn__82466.invoke(execute.clj:717)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__82465.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$fn__82269$fn__82270.invoke(execute.clj:398)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
    ""driver.sql_jdbc.execute$fn__82269.invokeStatic(execute.clj:392)""
    ""driver.sql_jdbc.execute$fn__82269.invoke(execute.clj:390)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
    ""driver.sql_jdbc$fn__108283.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__108283.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:60)""
    ""query_processor.execute$run.invoke(execute.clj:54)""
    ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71571.invoke(update_used_cards.clj:60)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__71586.invoke(execute.clj:23)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71591.invoke(execute.clj:34)""
    ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)""
    ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71544.invoke(cache.clj:238)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66185.invoke(permissions.clj:147)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66797.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66807.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__71618.invoke(execute.clj:92)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
    ""query_processor.execute$execute.invoke(execute.clj:87)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76913.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187)""
    ""query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
    ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
    ""query_processor.card$process_query_for_card_default_run_fn$fn__82654$fn__82655.invoke(card.clj:177)""
    ""query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176)""
    ""query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
    ""async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 1 queryType: native queryHash: 8ca855fbf633acdcf1d9f60141f994c8e8d64da9abbfb4ddaf6ec306acdcbfb0""
     ""with dicionario_situacao_cadastral AS (""
     ""  SELECT""
     ""    dicionario_br_me_cnpj.chave AS chave_situacao_cadastral,""
     ""    dicionario_br_me_cnpj.valor AS descricao_situacao_cadastral""
     ""  FROM""
     ""    dados.dicionario_br_me_cnpj""
     ""  WHERE""
     ""    dicionario_br_me_cnpj.nome_coluna = 'situacao_cadastral' :: text""
     ""    AND dicionario_br_me_cnpj.id_tabela = 'estabelecimentos' :: text""
     ""),""
     ""dicionario_motivo_situacao_cadastral AS (""
     ""  SELECT""
     ""    dicionario_br_me_cnpj.chave AS chave_motivo_situacao_cadastral,""
     ""    dicionario_br_me_cnpj.valor AS descricao_motivo_situacao_cadastral""
     ""  FROM""
     ""    dados.dicionario_br_me_cnpj""
     ""  WHERE""
     ""    dicionario_br_me_cnpj.nome_coluna = 'motivo_situacao_cadastral' :: text""
     ""    AND dicionario_br_me_cnpj.id_tabela = 'estabelecimentos' :: text""
     ""),""
     ""dicionario_identificador_matriz_filial AS (""
     ""  SELECT""
     ""    chave AS chave_identificador_matriz_filial,""
     ""    valor AS matriz_filial""
     ""  FROM""
     ""    dados.dicionario_br_me_cnpj""
     ""  WHERE""
     ""    TRUE""
     ""    AND nome_coluna = 'identificador_matriz_filial'""
     ""    AND id_tabela = 'estabelecimentos'""
     ""),""
     ""dicionario_id_pais AS (""
     ""  SELECT""
     ""    chave AS chave_id_pais,""
     ""    valor AS pais""
     ""  FROM""
     ""    dados.dicionario_br_me_cnpj""
     ""  WHERE""
     ""    TRUE""
     ""    AND nome_coluna = 'id_pais'""
     ""    AND id_tabela = 'estabelecimentos'""
     "")""
     ""select""
     ""  mv_empresas.cnpj_basico,""
     ""  razao_social,""
     ""  descricao_natureza_juridica,""
     ""  descricao_qualificacao_responsavel,""
     ""  descricao_porte_2021,""
     ""  descricao_porte_2022,""
     ""  descricao_porte_2023,""
     ""  descricao_porte_2024,""
     ""  ente_federativo,""
     ""  capital_social_2021,""
     ""  capital_social_2022,""
     ""  capital_social_2023,""
     ""  capital_social_2024,""
     ""  data_inicio_atividade,""
     ""  cnpj,""
     ""  cnpj_ordem,""
     ""  cnpj_dv,""
     ""  nome_fantasia,""
     ""  matriz_filial,""
     ""  pais,""
     ""  sigla as sigla_uf,""
     ""  ufs.nome as nome_uf,""
     ""  municipios.id_municipio as id_municipio,""
     ""  municipios.nome as nome_municipio,""
     ""  cnae2021.subclasse_cnae as subclasse_cnae_2021,""
     ""  cnae2021.classe_cnae as classe_cnae_2021,""
     ""  cnae2021.grupo_cnae as grupo_cnae_2021,""
     ""  cnae2021.divisao_cnae as divisao_cnae_2021,""
     ""  cnae2021.secao_cnae as secao_cnae_2021,""
     ""  cnae_fiscal_secundaria_2021,""
     ""  cnae2022.subclasse_cnae as subclasse_cnae_2022,""
     ""  cnae2022.classe_cnae as classe_cnae_2022,""
     ""  cnae2022.grupo_cnae as grupo_cnae_2022,""
     ""  cnae2022.divisao_cnae as divisao_cnae_2022,""
     ""  cnae2022.secao_cnae as secao_cnae_2022,""
     ""  cnae_fiscal_secundaria_2022,""
     ""  cnae2023.subclasse_cnae as subclasse_cnae_2023,""
     ""  cnae2023.classe_cnae as classe_cnae_2023,""
     ""  cnae2023.grupo_cnae as grupo_cnae_2023,""
     ""  cnae2023.divisao_cnae as divisao_cnae_2023,""
     ""  cnae2023.secao_cnae as secao_cnae_2023,""
     ""  cnae_fiscal_secundaria_2023,""
     ""  cnae2024.subclasse_cnae as subclasse_cnae_2024,""
     ""  cnae2024.classe_cnae as classe_cnae_2024,""
     ""  cnae2024.grupo_cnae as grupo_cnae_2024,""
     ""  cnae2024.divisao_cnae as divisao_cnae_2024,""
     ""  cnae2024.secao_cnae as secao_cnae_2024,""
     ""  cnae_fiscal_secundaria_2024,""
     ""  situacao_cadastral_2021,""
     ""  motivo_situacao_cadastral_2021,""
     ""  data_situacao_cadastral_2021,""
     ""  situacao_cadastral_2022,""
     ""  motivo_situacao_cadastral_2022,""
     ""  data_situacao_cadastral_2022,""
     ""  situacao_cadastral_2023,""
     ""  motivo_situacao_cadastral_2023,""
     ""  data_situacao_cadastral_2023,""
     ""  situacao_cadastral_2024,""
     ""  motivo_situacao_cadastral_2024,""
     ""  data_situacao_cadastral_2024,""
     ""  mv_estabelecimentos.datas_extract,""
     ""  data_opcao_simples,""
     ""  data_exclusao_simples,""
     ""  opcao_simples_2021,""
     ""  opcao_simples_2022,""
     ""  opcao_simples_2023,""
     ""  opcao_simples_2024,""
     ""  data_opcao_mei,""
     ""  data_exclusao_mei,""
     ""  opcao_mei_2021,""
     ""  opcao_mei_2022,""
     ""  opcao_mei_2023,""
     ""  opcao_mei_2024""
     ""from""
     ""  dados.mv_estabelecimentos""
     ""  left join dados.mv_empresas on mv_estabelecimentos.cnpj_basico = mv_empresas.cnpj_basico""
     ""  LEFT JOIN dicionario_identificador_matriz_filial ON mv_estabelecimentos.identificador_matriz_filial = chave_identificador_matriz_filial""
     ""  LEFT JOIN dicionario_id_pais ON mv_estabelecimentos.id_pais = chave_id_pais""
     ""  LEFT JOIN dados.ufs ON mv_estabelecimentos.sigla_uf = ufs.sigla""
     ""  LEFT JOIN dados.municipios ON mv_estabelecimentos.id_municipio = municipios.id_municipio""
     ""  LEFT JOIN dados.v_cnae2 cnae2021 ON mv_estabelecimentos.cnae_fiscal_principal_2021 = cnae2021.cnae_fiscal""
     ""  LEFT JOIN dados.v_cnae2 cnae2022 ON mv_estabelecimentos.cnae_fiscal_principal_2022 = cnae2022.cnae_fiscal""
     ""  LEFT JOIN dados.v_cnae2 cnae2023 ON mv_estabelecimentos.cnae_fiscal_principal_2023 = cnae2023.cnae_fiscal""
     ""  LEFT JOIN dados.v_cnae2 cnae2024 ON mv_estabelecimentos.cnae_fiscal_principal_2024 = cnae2024.cnae_fiscal""
     ""  LEFT JOIN dicionario_situacao_cadastral dsc2021 ON situacao_cadastral_2021 = dsc2021.chave_situacao_cadastral""
     ""  LEFT JOIN dicionario_motivo_situacao_cadastral dmsc2021 ON motivo_situacao_cadastral_2021 = dmsc2021.chave_motivo_situacao_cadastral""
     ""  LEFT JOIN dicionario_situacao_cadastral dsc2022 ON situacao_cadastral_2022 = dsc2022.chave_situacao_cadastral""
     ""  LEFT JOIN dicionario_motivo_situacao_cadastral dmsc2022 ON motivo_situacao_cadastral_2022 = dmsc2022.chave_motivo_situacao_cadastral""
     ""  LEFT JOIN dicionario_situacao_cadastral dsc2023 ON situacao_cadastral_2023 = dsc2023.chave_situacao_cadastral""
     ""  LEFT JOIN dicionario_motivo_situacao_cadastral dmsc2023 ON motivo_situacao_cadastral_2023 = dmsc2023.chave_motivo_situacao_cadastral""
     ""  LEFT JOIN dicionario_situacao_cadastral dsc2024 ON situacao_cadastral_2024 = dsc2024.chave_situacao_cadastral""
     ""  LEFT JOIN dicionario_motivo_situacao_cadastral dmsc2024 ON motivo_situacao_cadastral_2024 = dmsc2024.chave_motivo_situacao_cadastral""
     ""WHERE""
     ""  1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""
     ""  AND 1 = 1""],
    :params [],
    :type :invalid-query}}],
 :action_id nil,
 :state ""57014"",
 :error_type :invalid-query,
 :json_query
 {:constraints nil,
  :type :native,
  :middleware
  {:js-int-to-string? false,
   :ignore-cached-results? true,
   :process-viz-settings? true,
   :skip-results-metadata? true,
   :format-rows? true,
   :userland-query? true},
  :cache-strategy {:multiplier 10, :min_duration_ms 1000, :type :ttl, :avg-execution-ms 65237},
  :native
  {:template-tags
   {""descricao_secao""
    {:type :dimension,
     :name ""descricao_secao"",
     :id ""cf5a3f34-43ac-4139-8a0f-b390da01bb0d"",
     :display-name ""Seção"",
     :dimension [:field 40406 nil],
     :widget-type :string/=,
     :options nil,
     :default nil},
    ""natureza_juridica""
    {:type :dimension,
     :name ""natureza_juridica"",
     :id ""7bc82962-c7ab-46a3-bfd5-d70941061409"",
     :display-name ""Natureza Jurídica"",
     :default nil,
     :dimension [:field 40315 nil],
     :widget-type :string/=},
    ""ultima_situacao_cadastral""
    {:type :dimension,
     :name ""ultima_situacao_cadastral"",
     :id ""07611847-5c71-48dc-a6ae-1da442500073"",
     :display-name ""Ultima Situacao Cadastral"",
     :dimension [:field 40282 nil],
     :widget-type :string/=},
    ""descricao_divisao""
    {:type :dimension,
     :name ""descricao_divisao"",
     :id ""1738f758-4eb7-4118-8309-f4e7068960d6"",
     :display-name ""Divisão"",
     :default nil,
     :dimension [:field 40403 nil],
     :widget-type :string/=,
     :options nil},
    ""nome_municipio""
    {:type :dimension,
     :name ""nome_municipio"",
     :id ""2b4d1571-218f-4fbc-8c71-d025d2fbe45b"",
     :display-name ""Município"",
     :dimension [:field 39908 nil],
     :widget-type :string/contains,
     :options {:case-sensitive false}},
    ""descricao_porte""
    {:type :text, :name ""descricao_porte"", :id ""7b41e7d2-98f4-41ba-861f-44d13ff0506d"", :display-name ""Descricao Porte""},
    ""cnpj""
    {:type :dimension,
     :name ""cnpj"",
     :id ""bae3d81f-a19d-4cac-927f-807327af32e7"",
     :display-name ""CNPJ"",
     :dimension [:field 40286 nil],
     :widget-type :string/contains,
     :options {:case-sensitive false}},
    ""opcao_mei"" {:type :text, :name ""opcao_mei"", :id ""0ffbbd4c-a6ff-48a1-a76b-3e720c337021"", :display-name ""MEI""},
    ""opcao_simples""
    {:type :text, :name ""opcao_simples"", :id ""34008417-d52a-4018-9e95-b86f4edad6a6"", :display-name ""Simples""},
    ""razao_social""
    {:type :dimension,
     :name ""razao_social"",
     :id ""b5b7c2f3-c5b2-44d6-b06c-15f332eabf70"",
     :display-name ""Razao Social"",
     :dimension [:field 40312 nil],
     :widget-type :string/contains,
     :options {:case-sensitive false}},
    ""descricao_grupo""
    {:type :dimension,
     :name ""descricao_grupo"",
     :id ""598c2aa7-9f56-4a45-91bd-90a7b3615802"",
     :display-name ""Grupo"",
     :default nil,
     :dimension [:field 40405 nil],
     :widget-type :string/=,
     :options nil},
    ""qualificacao_responsavel""
    {:type :dimension,
     :name ""qualificacao_responsavel"",
     :id ""2bb62ac2-748b-4596-89a6-73b4e9f6db83"",
     :display-name ""Qualificação Resp."",
     :widget-type :string/=,
     :dimension [:field 40316 nil],
     :default nil},
    ""descricao_classe""
    {:type :dimension,
     :name ""descricao_classe"",
     :id ""f1ecb4df-e1e0-4c66-a1fe-984ae1f231df"",
     :display-name ""Classe"",
     :default nil,
     :dimension [:field 40401 nil],
     :widget-type :string/=,
     :options nil},
    ""nome_fantasia""
    {:type :dimension,
     :name ""nome_fantasia"",
     :id ""c9a7e88e-cecd-48ab-a057-ae896d7075d9"",
     :display-name ""Nome Fantasia"",
     :dimension [:field 40287 nil],
     :widget-type :string/contains,
     :options {:case-sensitive false}},
    ""descricao_subclasse""
    {:type :dimension,
     :name ""descricao_subclasse"",
     :id ""f0dbdfe1-bd1f-473a-ad83-c61b53a9c0ac"",
     :display-name ""Subclasse"",
     :default nil,
     :dimension [:field 40402 nil],
     :widget-type :string/=,
     :options nil},
    ""data_inicio_atividade""
    {:type :dimension,
     :name ""data_inicio_atividade"",
     :id ""4c024642-cd21-4891-90f0-a7343612be85"",
     :display-name ""Início Atividade"",
     :default nil,
     :dimension [:field 40281 nil],
     :widget-type :date/all-options},
    ""nome_uf""
    {:widget-type :string/contains,
     :default nil,
     :name ""nome_uf"",
     :type :dimension,
     :id ""d25c6266-ad51-4a15-8487-bb8f097f1e07"",
     :dimension [:field 40397 nil],
     :display-name ""Estado"",
     :options {:case-sensitive false},
     :required false}},
   :query
   ""with \r\ndicionario_situacao_cadastral AS (\r\n        SELECT  dicionario_br_me_cnpj.chave AS chave_situacao_cadastral,\r\n                        dicionario_br_me_cnpj.valor AS descricao_situacao_cadastral\r\n                FROM dados.dicionario_br_me_cnpj\r\n                WHERE dicionario_br_me_cnpj.nome_coluna = 'situacao_cadastral'::text\r\n                  AND dicionario_br_me_cnpj.id_tabela = 'estabelecimentos'::text\r\n),\r\ndicionario_motivo_situacao_cadastral AS (\r\n        SELECT  dicionario_br_me_cnpj.chave AS chave_motivo_situacao_cadastral,\r\n                        dicionario_br_me_cnpj.valor AS descricao_motivo_situacao_cadastral\r\n                FROM dados.dicionario_br_me_cnpj\r\n                WHERE dicionario_br_me_cnpj.nome_coluna = 'motivo_situacao_cadastral'::text\r\n                  AND dicionario_br_me_cnpj.id_tabela = 'estabelecimentos'::text\r\n),\r\ndicionario_identificador_matriz_filial AS (\r\n    SELECT\r\n        chave AS chave_identificador_matriz_filial,\r\n        valor AS matriz_filial\r\n    FROM dados.dicionario_br_me_cnpj\r\n    WHERE\r\n        TRUE\r\n        AND nome_coluna = 'identificador_matriz_filial'\r\n        AND id_tabela = 'estabelecimentos'\r\n),\r\ndicionario_id_pais AS (\r\n    SELECT\r\n        chave AS chave_id_pais,\r\n        valor AS pais\r\n    FROM dados.dicionario_br_me_cnpj\r\n    WHERE\r\n        TRUE\r\n        AND nome_coluna = 'id_pais'\r\n        AND id_tabela = 'estabelecimentos'\r\n)\r\nselect\r\n\tmv_empresas.cnpj_basico,\r\n    razao_social,\r\n\tdescricao_natureza_juridica,\r\n\tdescricao_qualificacao_responsavel,\r\n\tdescricao_porte_2021,\r\n\tdescricao_porte_2022,\r\n\tdescricao_porte_2023,\r\n\tdescricao_porte_2024,\r\n\tente_federativo,\r\n\tcapital_social_2021,\r\n\tcapital_social_2022,\r\n\tcapital_social_2023,\r\n\tcapital_social_2024,\r\n\tdata_inicio_atividade,\r\n\tcnpj,\r\n\tcnpj_ordem,\r\n\tcnpj_dv,\r\n\tnome_fantasia,\r\n\tmatriz_filial,\r\n\tpais,\r\n\tsigla as sigla_uf,\r\n    ufs.nome as nome_uf,\r\n\tmunicipios.id_municipio as id_municipio,\r\n    municipios.nome as nome_municipio,\r\n    cnae2021.subclasse_cnae as subclasse_cnae_2021,\r\n    cnae2021.classe_cnae    as classe_cnae_2021,\r\n    cnae2021.grupo_cnae     as grupo_cnae_2021,\r\n    cnae2021.divisao_cnae   as divisao_cnae_2021,\r\n    cnae2021.secao_cnae as secao_cnae_2021,\r\n    cnae_fiscal_secundaria_2021,\r\n    cnae2022.subclasse_cnae as subclasse_cnae_2022,\r\n    cnae2022.classe_cnae    as classe_cnae_2022,\r\n    cnae2022.grupo_cnae     as grupo_cnae_2022,\r\n    cnae2022.divisao_cnae   as divisao_cnae_2022,\r\n    cnae2022.secao_cnae     as secao_cnae_2022,\r\n    cnae_fiscal_secundaria_2022,\r\n    cnae2023.subclasse_cnae as subclasse_cnae_2023,\r\n    cnae2023.classe_cnae    as classe_cnae_2023,\r\n    cnae2023.grupo_cnae     as grupo_cnae_2023,\r\n    cnae2023.divisao_cnae   as divisao_cnae_2023,\r\n    cnae2023.secao_cnae     as secao_cnae_2023,\r\n    cnae_fiscal_secundaria_2023,\r\n    cnae2024.subclasse_cnae as subclasse_cnae_2024,\r\n    cnae2024.classe_cnae    as classe_cnae_2024,\r\n    cnae2024.grupo_cnae     as grupo_cnae_2024,\r\n    cnae2024.divisao_cnae   as divisao_cnae_2024,\r\n    cnae2024.secao_cnae     as secao_cnae_2024,\r\n\tcnae_fiscal_secundaria_2024,\r\n\tsituacao_cadastral_2021,\r\n    motivo_situacao_cadastral_2021,\r\n    data_situacao_cadastral_2021,\r\n    situacao_cadastral_2022,\r\n    motivo_situacao_cadastral_2022,\r\n    data_situacao_cadastral_2022,\r\n    situacao_cadastral_2023,\r\n    motivo_situacao_cadastral_2023,\r\n    data_situacao_cadastral_2023,\r\n    situacao_cadastral_2024,\r\n    motivo_situacao_cadastral_2024,\r\n    data_situacao_cadastral_2024,\r\n\tmv_estabelecimentos.datas_extract,\r\n\tdata_opcao_simples,\r\n\tdata_exclusao_simples,\r\n    opcao_simples_2021,\r\n    opcao_simples_2022,\r\n    opcao_simples_2023,\r\n    opcao_simples_2024,\r\n    data_opcao_mei,\r\n\tdata_exclusao_mei,\r\n    opcao_mei_2021,\r\n    opcao_mei_2022,\r\n    opcao_mei_2023,\r\n    opcao_mei_2024\r\nfrom dados.mv_estabelecimentos\r\nleft join dados.mv_empresas on mv_estabelecimentos.cnpj_basico = mv_empresas.cnpj_basico \r\nLEFT JOIN dicionario_identificador_matriz_filial ON mv_estabelecimentos.identificador_matriz_filial = chave_identificador_matriz_filial\r\nLEFT JOIN dicionario_id_pais ON mv_estabelecimentos.id_pais = chave_id_pais\r\nLEFT JOIN dados.ufs ON mv_estabelecimentos.sigla_uf = ufs.sigla\r\nLEFT JOIN dados.municipios ON mv_estabelecimentos.id_municipio = municipios.id_municipio\r\nLEFT JOIN dados.v_cnae2 cnae2021 ON mv_estabelecimentos.cnae_fiscal_principal_2021 = cnae2021.cnae_fiscal\r\nLEFT JOIN dados.v_cnae2 cnae2022 ON mv_estabelecimentos.cnae_fiscal_principal_2022 = cnae2022.cnae_fiscal\r\nLEFT JOIN dados.v_cnae2 cnae2023 ON mv_estabelecimentos.cnae_fiscal_principal_2023 = cnae2023.cnae_fiscal\r\nLEFT JOIN dados.v_cnae2 cnae2024 ON mv_estabelecimentos.cnae_fiscal_principal_2024 = cnae2024.cnae_fiscal\r\nLEFT JOIN dicionario_situacao_cadastral dsc2021 ON situacao_cadastral_2021 = dsc2021.chave_situacao_cadastral\r\nLEFT JOIN dicionario_motivo_situacao_cadastral dmsc2021 ON motivo_situacao_cadastral_2021 = dmsc2021.chave_motivo_situacao_cadastral\r\nLEFT JOIN dicionario_situacao_cadastral dsc2022 ON situacao_cadastral_2022 = dsc2022.chave_situacao_cadastral\r\nLEFT JOIN dicionario_motivo_situacao_cadastral dmsc2022 ON motivo_situacao_cadastral_2022 = dmsc2022.chave_motivo_situacao_cadastral\r\nLEFT JOIN dicionario_situacao_cadastral dsc2023 ON situacao_cadastral_2023 = dsc2023.chave_situacao_cadastral\r\nLEFT JOIN dicionario_motivo_situacao_cadastral dmsc2023 ON motivo_situacao_cadastral_2023 = dmsc2023.chave_motivo_situacao_cadastral\r\nLEFT JOIN dicionario_situacao_cadastral dsc2024 ON situacao_cadastral_2024 = dsc2024.chave_situacao_cadastral\r\nLEFT JOIN dicionario_motivo_situacao_cadastral dmsc2024 ON motivo_situacao_cadastral_2024 = dmsc2024.chave_motivo_situacao_cadastral\r\nWHERE 1=1\r\n[[AND (opcao_simples_2021 = {{opcao_simples}} OR opcao_simples_2022 = {{opcao_simples}} OR opcao_simples_2023 = {{opcao_simples}} OR opcao_simples_2024 = {{opcao_simples}})]]\r\n[[AND (opcao_mei_2021 = {{opcao_mei}} OR opcao_mei_2022 = {{opcao_mei}} OR opcao_mei_2023 = {{opcao_mei}} OR opcao_mei_2024 = {{opcao_mei}})]]\r\n[[AND (descricao_porte_2021 like '%'||{{descricao_porte}}||'%' OR descricao_porte_2022 like '%'||{{descricao_porte}}||'%' OR descricao_porte_2023 like '%'||{{descricao_porte}}||'%' OR descricao_porte_2024 like '%'||{{descricao_porte}}||'%')]]\r\nAND {{razao_social}}\r\nAND {{natureza_juridica}}\r\nAND {{qualificacao_responsavel}}\r\nAND {{data_inicio_atividade}}\r\nAND {{cnpj}}\r\nAND {{nome_fantasia}}\r\nAND {{nome_uf}}\r\nAND {{nome_municipio}}\r\nAND {{descricao_secao}}\r\nAND {{descricao_divisao}}\r\nAND {{descricao_grupo}}\r\nAND {{descricao_classe}}\r\nAND {{descricao_subclasse}}\r\nAND {{ultima_situacao_cadastral}} ""},
  :viz-settings {:table.pivot_column ""ente_federativo"", :table.cell_column ""capital_social_medio""},
  :database 3,
  :parameters
  ({:id ""cf5a3f34-43ac-4139-8a0f-b390da01bb0d"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_secao""]]}
   {:id ""7bc82962-c7ab-46a3-bfd5-d70941061409"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""natureza_juridica""]]}
   {:id ""07611847-5c71-48dc-a6ae-1da442500073"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""ultima_situacao_cadastral""]]}
   {:id ""1738f758-4eb7-4118-8309-f4e7068960d6"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_divisao""]]}
   {:id ""2b4d1571-218f-4fbc-8c71-d025d2fbe45b"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""nome_municipio""]],
    :options {:case-sensitive false}}
   {:id ""7b41e7d2-98f4-41ba-861f-44d13ff0506d"",
    :type ""category"",
    :value nil,
    :target [""variable"" [""template-tag"" ""descricao_porte""]]}
   {:id ""bae3d81f-a19d-4cac-927f-807327af32e7"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""cnpj""]],
    :options {:case-sensitive false}}
   {:id ""0ffbbd4c-a6ff-48a1-a76b-3e720c337021"",
    :type ""category"",
    :value nil,
    :target [""variable"" [""template-tag"" ""opcao_mei""]]}
   {:id ""34008417-d52a-4018-9e95-b86f4edad6a6"",
    :type ""category"",
    :value nil,
    :target [""variable"" [""template-tag"" ""opcao_simples""]]}
   {:id ""b5b7c2f3-c5b2-44d6-b06c-15f332eabf70"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""razao_social""]],
    :options {:case-sensitive false}}
   {:id ""598c2aa7-9f56-4a45-91bd-90a7b3615802"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_grupo""]]}
   {:id ""2bb62ac2-748b-4596-89a6-73b4e9f6db83"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""qualificacao_responsavel""]]}
   {:id ""f1ecb4df-e1e0-4c66-a1fe-984ae1f231df"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_classe""]]}
   {:id ""c9a7e88e-cecd-48ab-a057-ae896d7075d9"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""nome_fantasia""]],
    :options {:case-sensitive false}}
   {:id ""f0dbdfe1-bd1f-473a-ad83-c61b53a9c0ac"",
    :type ""string/="",
    :value nil,
    :target [""dimension"" [""template-tag"" ""descricao_subclasse""]]}
   {:id ""4c024642-cd21-4891-90f0-a7343612be85"",
    :type ""date/all-options"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""data_inicio_atividade""]]}
   {:id ""d25c6266-ad51-4a15-8487-bb8f097f1e07"",
    :type ""string/contains"",
    :value nil,
    :target [""dimension"" [""template-tag"" ""nome_uf""]],
    :options {:case-sensitive false}})},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__82395.invokeStatic(execute.clj:570)""
  ""driver.sql_jdbc.execute$fn__82395.invoke(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:578)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:575)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82465$fn__82466.invoke(execute.clj:715)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__82465.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$fn__82269$fn__82270.invoke(execute.clj:398)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)""
  ""driver.sql_jdbc.execute$fn__82269.invokeStatic(execute.clj:392)""
  ""driver.sql_jdbc.execute$fn__82269.invoke(execute.clj:390)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)""
  ""driver.sql_jdbc$fn__108283.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__108283.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
  ""query_processor.execute$run.invoke(execute.clj:54)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71571.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71586.invoke(execute.clj:23)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71591.invoke(execute.clj:34)""
  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)""
  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71544.invoke(cache.clj:238)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66185.invoke(permissions.clj:147)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66797.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66807.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__71618.invoke(execute.clj:92)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
  ""query_processor.execute$execute.invoke(execute.clj:87)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76913.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
  ""query_processor.card$process_query_for_card_default_run_fn$fn__82654$fn__82655.invoke(card.clj:177)""
  ""query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97)""],
 :card_id 33,
 :context :csv-download,
 :error ""ERROR: canceling statement due to user request"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}
```

**To Reproduce**
Steps to reproduce the behavior:
1. Open a big Metabase `question`
2. Click on Download `icon`
3. Choose `.csv`
4. See error

**Expected behavior**
Download the .csv dataset file

**Screenshots**
![image](https://github.com/user-attachments/assets/32079226-8cd9-45ee-98bd-153d3b31a1a7)

![image](https://github.com/user-attachments/assets/73288667-3d04-4f8c-8cf7-0b4b4daa935e)

![image](https://github.com/user-attachments/assets/0cdbd06c-0aca-4dad-b0a0-63172ff12ae2)


**Severity**
The download functionality is one of the most wanted tool to of my user`s company.


**Additional context**
The .xlsx download isn't work. Issue https://github.com/metabase/metabase/issues/48177 opened.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Ubuntu 16.4-0ubuntu0.24.04.2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-45-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",fmercurio,2024-09-27 22:23:18+00:00,[],2024-09-28 14:32:00+00:00,2024-09-28 14:31:59+00:00,https://github.com/metabase/metabase/issues/48178,[],"[{'comment_id': 2380659154, 'issue_id': 2553830298, 'author': 'paoliniluis', 'body': 'your reverse proxy is cutting the connection', 'created_at': datetime.datetime(2024, 9, 28, 14, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-28 14:32:00 UTC): your reverse proxy is cutting the connection

"
2553818665,issue,closed,not_planned,.xlsx Download Error - 504 Gateway Time-out - Client closed connection prematurely,"**Describe the bug**
I cannot download .xlsx datasets.

**Logs**
``` Docker Logs
2024-09-27 22:00:04,117 INFO cache.impl :: Results are too large to cache. 😫
2024-09-27 22:00:05,113 INFO middleware.cache :: Query 4a273c7b took 1.0 mins to run; minimum for cache eligibility is 1000.0 ms; eligible
2024-09-27 22:00:05,113 INFO middleware.cache :: Caching results for next time for query with hash ""4a273c7b"". 💾
2024-09-27 22:00:05,446 ERROR query-processor.streaming :: Client closed connection prematurely
org.eclipse.jetty.io.EofException: Closed
        at org.eclipse.jetty.server.HttpOutput.checkWritable(HttpOutput.java:756)
        at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:780)
        at java.base/java.util.zip.GZIPOutputStream.finish(Unknown Source)
        at java.base/java.util.zip.DeflaterOutputStream.close(Unknown Source)
        at metabase.async.streaming_response$delay_output_stream$fn__52041.invoke(streaming_response.clj:130)
        at metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown Source)
        at metabase.query_processor.streaming.xlsx$fn$reify__70019.finish_BANG_(xlsx.clj:685)
        at metabase.query_processor.streaming$streaming_result_fn$result__70115$fn__70116.invoke(streaming.clj:144)
        at metabase.query_processor.streaming$streaming_result_fn$result__70115.invoke(streaming.clj:143)
        at metabase.query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:81)
        at metabase.query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49)
        at metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71530$fn__71531.invoke(cache.clj:211)
        at metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)
        at metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)
        at metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)
        at metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)
        at metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71530.invoke(cache.clj:207)
        at metabase.query_processor.pipeline$_STAR_run_STAR_$respond__56960.invoke(pipeline.clj:95)
        at metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__82465.invoke(execute.clj:725)
        at metabase.driver.sql_jdbc.execute$fn__82269$fn__82270.invoke(execute.clj:398)
        at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338)
        at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321)
        at metabase.driver.sql_jdbc.execute$fn__82269.invokeStatic(execute.clj:392)
        at metabase.driver.sql_jdbc.execute$fn__82269.invoke(execute.clj:390)
        at clojure.lang.MultiFn.invoke(MultiFn.java:244)
        at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708)
        at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)
        at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705)
        at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694)
        at metabase.driver.sql_jdbc$fn__108283.invokeStatic(sql_jdbc.clj:78)
        at metabase.driver.sql_jdbc$fn__108283.invoke(sql_jdbc.clj:76)
        at clojure.lang.MultiFn.invoke(MultiFn.java:244)
        at metabase.query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)
        at metabase.query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)
        at metabase.query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)
        at metabase.query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)
        at metabase.query_processor.execute$run.invokeStatic(execute.clj:60)
        at metabase.query_processor.execute$run.invoke(execute.clj:54)
        at metabase.query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71571.invoke(update_used_cards.clj:60)
        at metabase.query_processor.execute$add_native_form_to_result_metadata$fn__71586.invoke(execute.clj:23)
        at metabase.query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71591.invoke(execute.clj:34)
        at metabase.query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)
        at metabase.query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)
        at metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71544.invoke(cache.clj:238)
        at metabase.query_processor.middleware.permissions$check_query_permissions$fn__66185.invoke(permissions.clj:147)
        at metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66797.invoke(enterprise.clj:51)
        at metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66807.invoke(enterprise.clj:64)
        at metabase.query_processor.execute$execute$fn__71618.invoke(execute.clj:92)
        at metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)
        at metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)
        at metabase.query_processor.execute$execute.invokeStatic(execute.clj:91)
        at metabase.query_processor.execute$execute.invoke(execute.clj:87)
        at metabase.query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)
        at metabase.query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)
        at metabase.query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96)
        at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103)
        at metabase.query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198)
        at metabase.query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128)
        at metabase.query_processor$process_query$fn__76913.invoke(query_processor.clj:78)
        at metabase.query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187)
        at metabase.query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181)
        at metabase.query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166)
        at metabase.driver$do_with_driver.invokeStatic(driver.clj:104)
        at metabase.driver$do_with_driver.invoke(driver.clj:99)
        at metabase.query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165)
        at metabase.query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151)
        at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)
        at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
        at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)
        at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
        at metabase.query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150)
        at metabase.query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128)
        at metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)
        at metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)
        at metabase.query_processor$process_query.invokeStatic(query_processor.clj:76)
        at metabase.query_processor$process_query.invoke(query_processor.clj:69)
        at metabase.query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)
        at metabase.query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)
        at metabase.query_processor.card$process_query_for_card_default_run_fn$fn__82654$fn__82655.invoke(card.clj:177)
        at metabase.query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176)
        at metabase.query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174)
        at metabase.query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)
        at metabase.query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)
        at metabase.query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990)
        at clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:671)
        at clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)
        at metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)
        at metabase.async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97)
        at clojure.lang.AFn.run(AFn.java:22)
        at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
        at java.base/java.util.concurrent.FutureTask.run(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)
2024-09-27 22:00:05,447 INFO cache.impl :: Results are too large to cache. 😫
2024-09-27 22:00:05,447 INFO cache.impl :: Results are too large to cache. 😫
```


``` Metabase Troubleshoot Logs
[32ca2cef-c797-450f-8cd0-2b9676e037d1] 2024-09-27T19:00:04-03:00 INFO metabase.query-processor.middleware.cache.impl Results are too large to cache. 😫
[32ca2cef-c797-450f-8cd0-2b9676e037d1] 2024-09-27T19:00:05-03:00 INFO metabase.query-processor.middleware.cache Caching results for next time for query with hash ""4a273c7b"". 💾
[32ca2cef-c797-450f-8cd0-2b9676e037d1] 2024-09-27T19:00:05-03:00 INFO metabase.query-processor.middleware.cache Query 4a273c7b took 1.0 mins to run; minimum for cache eligibility is 1000.0 ms; eligible
[32ca2cef-c797-450f-8cd0-2b9676e037d1] 2024-09-27T19:00:05-03:00 ERROR metabase.query-processor.streaming Client closed connection prematurely,org.eclipse.jetty.io.EofException: Closed,	at org.eclipse.jetty.server.HttpOutput.checkWritable(HttpOutput.java:756),	at org.eclipse.jetty.server.HttpOutput.write(HttpOutput.java:780),	at java.base/java.util.zip.GZIPOutputStream.finish(Unknown Source),	at java.base/java.util.zip.DeflaterOutputStream.close(Unknown Source),	at metabase.async.streaming_response$delay_output_stream$fn__52041.invoke(streaming_response.clj:130),	at metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown Source),	at metabase.query_processor.streaming.xlsx$fn$reify__70019.finish_BANG_(xlsx.clj:685),	at metabase.query_processor.streaming$streaming_result_fn$result__70115$fn__70116.invoke(streaming.clj:144),	at metabase.query_processor.streaming$streaming_result_fn$result__70115.invoke(streaming.clj:143),	at metabase.query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:81),	at metabase.query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49),	at metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71530$fn__71531.invoke(cache.clj:211),	at metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83),	at metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54),	at metabase.query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73),	at metabase.query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54),	at metabase.query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71530.invoke(cache.clj:207),	at metabase.query_processor.pipeline$_STAR_run_STAR_$respond__56960.invoke(pipeline.clj:95),	at metabase.driver.sql_jdbc.execute$execute_reducible_query$fn__82465.invoke(execute.clj:725),	at metabase.driver.sql_jdbc.execute$fn__82269$fn__82270.invoke(execute.clj:398),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:338),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:321),	at metabase.driver.sql_jdbc.execute$fn__82269.invokeStatic(execute.clj:392),	at metabase.driver.sql_jdbc.execute$fn__82269.invoke(execute.clj:390),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:708),	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694),	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:705),	at metabase.driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:694),	at metabase.driver.sql_jdbc$fn__108283.invokeStatic(sql_jdbc.clj:78),	at metabase.driver.sql_jdbc$fn__108283.invoke(sql_jdbc.clj:76),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47),	at metabase.query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34),	at metabase.query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97),	at metabase.query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90),	at metabase.query_processor.execute$run.invokeStatic(execute.clj:60),	at metabase.query_processor.execute$run.invoke(execute.clj:54),	at metabase.query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71571.invoke(update_used_cards.clj:60),	at metabase.query_processor.execute$add_native_form_to_result_metadata$fn__71586.invoke(execute.clj:23),	at metabase.query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71591.invoke(execute.clj:34),	at metabase.query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212),	at metabase.query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185),	at metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71544.invoke(cache.clj:238),	at metabase.query_processor.middleware.permissions$check_query_permissions$fn__66185.invoke(permissions.clj:147),	at metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66797.invoke(enterprise.clj:51),	at metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66807.invoke(enterprise.clj:64),	at metabase.query_processor.execute$execute$fn__71618.invoke(execute.clj:92),	at metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225),	at metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216),	at metabase.query_processor.execute$execute.invokeStatic(execute.clj:91),	at metabase.query_processor.execute$execute.invoke(execute.clj:87),	at metabase.query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47),	at metabase.query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43),	at metabase.query_processor.middleware.enterprise$fn__66824$handle_audit_app_internal_queries__66825$fn__66827.invoke(enterprise.clj:96),	at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66835.invoke(enterprise.clj:103),	at metabase.query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76807.invoke(process_userland_query.clj:198),	at metabase.query_processor.middleware.catch_exceptions$catch_exceptions$fn__76876.invoke(catch_exceptions.clj:128),	at metabase.query_processor$process_query$fn__76913.invoke(query_processor.clj:78),	at metabase.query_processor.setup$do_with_canceled_chan$fn__67239.invoke(setup.clj:187),	at metabase.query_processor.setup$do_with_database_local_settings$fn__67234.invoke(setup.clj:181),	at metabase.query_processor.setup$do_with_driver$fn__67229$fn__67230.invoke(setup.clj:166),	at metabase.driver$do_with_driver.invokeStatic(driver.clj:104),	at metabase.driver$do_with_driver.invoke(driver.clj:99),	at metabase.query_processor.setup$do_with_driver$fn__67229.invoke(setup.clj:165),	at metabase.query_processor.setup$do_with_metadata_provider$fn__67222$fn__67225.invoke(setup.clj:151),	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170),	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150),	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159),	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150),	at metabase.query_processor.setup$do_with_metadata_provider$fn__67222.invoke(setup.clj:150),	at metabase.query_processor.setup$do_with_resolved_database$fn__67216.invoke(setup.clj:128),	at metabase.query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232),	at metabase.query_processor.setup$do_with_qp_setup.invoke(setup.clj:216),	at metabase.query_processor$process_query.invokeStatic(query_processor.clj:76),	at metabase.query_processor$process_query.invoke(query_processor.clj:69),	at metabase.query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170),	at metabase.query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166),	at metabase.query_processor.card$process_query_for_card_default_run_fn$fn__82654$fn__82655.invoke(card.clj:177),	at metabase.query_processor.streaming$_streaming_response$fn__70127$fn__70128$fn__70129.invoke(streaming.clj:176),	at metabase.query_processor.streaming$_streaming_response$fn__70127$fn__70128.invoke(streaming.clj:174),	at metabase.query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165),	at metabase.query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152),	at metabase.query_processor.streaming$_streaming_response$fn__70127.invoke(streaming.clj:171),	at clojure.lang.AFn.applyToHelper(AFn.java:156),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:667),	at clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990),	at clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990),	at clojure.lang.RestFn.applyTo(RestFn.java:142),	at clojure.core$apply.invokeStatic(core.clj:671),	at clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020),	at clojure.lang.RestFn.invoke(RestFn.java:421),	at metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78),	at metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76),	at metabase.async.streaming_response$do_f_async$task__52026.invoke(streaming_response.clj:97),	at clojure.lang.AFn.run(AFn.java:22),	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	at java.base/java.lang.Thread.run(Unknown Source)
[32ca2cef-c797-450f-8cd0-2b9676e037d1] 2024-09-27T19:00:05-03:00 INFO metabase.query-processor.middleware.cache.impl Results are too large to cache. 😫
```

**To Reproduce**
Steps to reproduce the behavior:
1. Open a big Metabase `question`;
2. Click on `Download` icon;
3. Choose `.xlsx`
4. Wait for the `can't download message`

**Expected behavior**
Download the dataset on a .xlsx file.

**Screenshots**
![image](https://github.com/user-attachments/assets/91144692-2001-4bd7-b48f-090f2d468e8e)

![image](https://github.com/user-attachments/assets/264fbe2e-a963-46a6-980a-487404a60521)



**Severity**
The download functionality is one of the most wanted tool to of my user`s company.

**Additional context**
I try to download with CSV and I got another error.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36 Edg/129.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Ubuntu 16.4-0ubuntu0.24.04.2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.0-45-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",fmercurio,2024-09-27 22:13:02+00:00,[],2024-09-28 14:31:20+00:00,2024-09-28 14:31:19+00:00,https://github.com/metabase/metabase/issues/48177,[],"[{'comment_id': 2380658916, 'issue_id': 2553818665, 'author': 'paoliniluis', 'body': 'your reverse proxy is cutting the connection, please increase the proxy time or make the queries run faster', 'created_at': datetime.datetime(2024, 9, 28, 14, 31, 19, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-28 14:31:19 UTC): your reverse proxy is cutting the connection, please increase the proxy time or make the queries run faster

"
2553546613,issue,open,,Misc Sidesheet Follow-ups,"- [x] #48385
- [x] Fix link to data source when source is a model (#48315)
- [x] Move Bookmark to dashboard overflow menu (#48312 )
- [x] Add sections to overflow menu in Collections
- [x] Rename make collection official -> Make official (#48313)
- [x] Saved in collection icon should change when collection is official (#48313)
- [x] Show model/table icons in ""Based on"" (#48315)
- [x] We should only show entity-id in the sidesheets when the instance has the serialization feature flag (https://metaboat.slack.com/archives/C07JSTRFRPW/p1727966894639919)
- [ ] Add padding below save/cancel buttons and remove border on cancel button (per https://metaboat.slack.com/archives/C07JSTRFRPW/p1727464973032829?thread_ts=1727461599.287239&cid=C07JSTRFRPW)
- [x] Snowplow
- [ ] Move Bookmark to question overflow menu
- [ ] Move usage insights link to sidesheets (#48283 )
- [ ] #48353
- [x] #48354
- [ ] Look into whether we still support `MB_LOAD_ANALYTICS_CONTENT`, which is mentioned in the docs and BE code. If so, we might need to disable the insights link if that env variable is false.
- [ ] Should we make it so the whole entity id is copied on click?
- [ ] Check that the ""Based on"" icons are the same size

Postponed 
- [ ] Add ""Auto-refresh"" to dashboard overflow menu (https://metaboat.slack.com/archives/C07JSTRFRPW/p1727823942695769)
- [ ] Full width toggle on dashboard settings",iethree,2024-09-27 18:55:42+00:00,['rafpaf'],2024-10-16 07:22:16+00:00,,https://github.com/metabase/metabase/issues/48174,[],[],
2553451441,issue,open,,Redshift average returns integer values for integer columns,"### Describe the bug

[Slack discussion](https://metaboat.slack.com/archives/C01LQQ2UW03/p1727455003198629)

[AVG function in Redshift returns an integer for integer columns](https://docs.aws.amazon.com/redshift/latest/dg/r_AVG.html#r_AVG-data-types) so if you have an integer column with values 1,2,7, Redshift AVG will return 3 instead of  3.33. This behavior is different from most other databases we support or from what people expect of ""average"",  and confusing for non-technical query builder users.

We could cast the column to float before taking the average, like we do with custom expressions that involve division.



### To Reproduce

1. Use Average summary in the QB or AVG in SQL on an integer column in Redshift


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
always worked like that
```


### Severity

Confusing

### Additional context

_No response_",alexyarosh,2024-09-27 17:55:29+00:00,[],2025-02-04 20:25:31+00:00,,https://github.com/metabase/metabase/issues/48173,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Redshift', None), ('.Team/Drivers', '')]","[{'comment_id': 2379791099, 'issue_id': 2553451441, 'author': 'luizarakaki', 'body': ""It is questionable if this is a bug report or a feature request. But the current state isn't what we want"", 'created_at': datetime.datetime(2024, 9, 27, 17, 57, 34, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-09-27 17:57:34 UTC): It is questionable if this is a bug report or a feature request. But the current state isn't what we want

"
2553337920,issue,open,,SQL view is opened when creating a question on small screens,"### Describe the bug

There were 2 separate requirements:
- remember if the sql view is shown or hidden
- on small screens show it instead of the notebook editor, not to the right
But we didn't foresee that when you switch from big screen when you opened the sql view in the sidebar to a small screen if you start a question it is shown by default.

### To Reproduce

1. Open a question
3. Click on 'View the SQL'
4. Open Metabase on small screen
5. Start new question
6. Generated SQL will be shown by default


### Expected behavior

We should remember the view sql toggle state only for big screens and for small screens hide it by default

### Logs

_No response_

### Information about your Metabase installation

```JSON
93cd63a
```


### Severity

Just weird and unexpected

### Additional context

_No response_",mngr,2024-09-27 16:41:57+00:00,[],2025-02-04 20:27:33+00:00,,https://github.com/metabase/metabase/issues/48170,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2553150965,issue,open,,Log in `audit_log` when users create public links,"**Is your feature request related to a problem? Please describe.**
We don't log in the audit_log when someones make a dashboard or question public

**Describe the solution you'd like**
Add a row to the audit_log with data: model type, model id, user id, timestamp

",luizarakaki,2024-09-27 15:00:54+00:00,[],2025-02-04 20:30:42+00:00,,https://github.com/metabase/metabase/issues/48166,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2552971309,issue,closed,completed,[Arc] Better Onboarding via First-Time UX,"## Links
- [product doc](https://www.notion.so/metabase/Better-Onboarding-via-first-time-UX-7c76eef94d414bb0a864d7cc786229f2)
- [Figma designs](https://www.figma.com/design/1QmQUlWK7jACc1oxOfIzxE/Better-onboarding?node-id=6290-2701&node-type=canvas&m=dev)

### Implementation Plan
- The goal is to have these main milestones as separate units so that we can merge them independently. Each milestone should be ""shippable"" on its own.
- Eech milestone will have its own feature branch (`better-onboarding-ux-ms1`, `better-onboarding-ux-ms2`, ..., `better-onboarding-ux-msN`)
- For the full list of Milestones with all the necessary details for that scope, please take a look at sub-issues.

### Milestone Scopes
1. Add new onboarding sidebar section and make adding data available to **admins only**
2. Expand data permissions to regular users who have curate permissions for ""Our analytics""
3. Onboarding checklist (TBD)",nemanjaglumac,2024-09-27 13:37:17+00:00,['nemanjaglumac'],2024-12-12 11:00:58+00:00,2024-12-12 11:00:58+00:00,https://github.com/metabase/metabase/issues/48163,"[('First Experience/Onboarding', ''), ('.Epic', 'Feature Implementation or Project')]",[],
2552348299,issue,closed,completed,"xlsx Export doesn't respect custom column formating, instead format is carried over to the next column","### Describe the bug

Below, attached is a SS, which shows the question result preview, along with the column format (which is set to Percentage)
<img width=""1492"" alt=""image"" src=""https://github.com/user-attachments/assets/a90be0fe-8583-4c57-91d3-6447a727fbd1"">

Now when I download the question into xlsx and open it in excel, then the formating shown in the excel file is very weird. 
<img width=""1455"" alt=""image"" src=""https://github.com/user-attachments/assets/c796120c-138d-4e02-a6ea-5074191b599f"">

Interesting, if I download the question into CSV format and import it in excel, then the formating is shown correctly. 
CSV preview view in MAC -> 
<img width=""1278"" alt=""image"" src=""https://github.com/user-attachments/assets/58ba12ee-8f1b-4695-b598-007e989c7358"">

After Importing the CSV into Excel in MAC ->
<img width=""1465"" alt=""image"" src=""https://github.com/user-attachments/assets/9c7ab11c-d2bf-46fc-97d8-c7a71d358ebb"">

Seems like its working fine when I Download the question in CSV format, but something is broken when I Download the question in xlsx format

### To Reproduce

Metabase version ->  Metabase 0.50.27

1. Open an already created Question, which has Custom Column in it, and Custom Column setting is set to Percentage
2. Now download the Question in xlsx format, and open it in Excel.
3. One can see that the Custom Column which was set to Percentage is not having Percentage format, but the column next to it is having the Percentage formating.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser - Version 129.0.6668.71 (Official Build) (arm64)
- OS - macOS Sonoma 14.6.1
- Databases - Postgres
- Metabase Version 0.50.27
```


### Severity

Annoying, as our Clients are not able to download the data in xlsx format. And now we have to guide them on how to use the CSV format and get the data. 

### Additional context

_No response_",Sidhantp12,2024-09-27 08:35:14+00:00,[],2024-10-22 16:27:03+00:00,2024-10-22 02:46:58+00:00,https://github.com/metabase/metabase/issues/48158,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Download', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2429735076, 'issue_id': 2552348299, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 22, 16, 27, 2, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-22 16:27:02 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2551751060,issue,open,,Visualisation for Multiple response questions,"**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
With questions that have multiple responses (ie. What is your favorite fruit?) the data is stored across multiple fields with true/false values for each record, where each field represents the response (i.e. Apples, Oranges, Bananas etc). Presently I can find no way to visualise this on a single chart to get the aggregated response for each field.

**Describe the solution you'd like**
A clear and concise description of what you want to happen.
As there can be many separate multiple response variable in one data set, there would need to be a way to select the fields that relate to each multiple response question so they can be visualised. I wouldn't think there was a need to retain the original fields as long as filters could make use of the new field collection.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.
There don't seem to be any alternatives for multiple response structured data.

**How important is this feature to you?**
The software is not viable for my usage without this functionality.

**Additional context**
Add any other context or screenshots about the feature request here.
",jade-octopusgroup,2024-09-27 00:20:54+00:00,[],2025-02-04 20:30:53+00:00,,https://github.com/metabase/metabase/issues/48156,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2568154292, 'issue_id': 2551751060, 'author': 'brunobergher', 'body': ""@jade-octopusgroup can you expand on how you'd want to visualize this in a single chart? Is it something like bars for yes/no for each of the questions?"", 'created_at': datetime.datetime(2025, 1, 2, 17, 56, 45, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:56:45 UTC): @jade-octopusgroup can you expand on how you'd want to visualize this in a single chart? Is it something like bars for yes/no for each of the questions?

"
2551045363,issue,closed,not_planned,View_log table stopped being updated,"### Describe the bug

The table stopped being updated on 07/02/2024, but Metabase continues to be used normally.

### To Reproduce

List the contents of the view_log table.

### Expected behavior

The view log table should be updated daily.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""oracle"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Windows Server 2012 R2"",
    ""os.version"": ""6.3"",
    ""user.language"": ""pt"",
    ""user.timezone"": ""GMT-3""
  }
}
```


### Severity

Medium

### Additional context

_No response_",tatusis,2024-09-26 16:24:11+00:00,[],2024-09-26 16:47:46+00:00,2024-09-26 16:47:46+00:00,https://github.com/metabase/metabase/issues/48146,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2377461359, 'issue_id': 2551045363, 'author': 'luizarakaki', 'body': 'Since v49, view_log is only populated on Pro/EE versions', 'created_at': datetime.datetime(2024, 9, 26, 16, 47, 46, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-09-26 16:47:46 UTC): Since v49, view_log is only populated on Pro/EE versions

"
2550916719,issue,closed,completed,We don't detect if metabaseInstanceUrl is not pointing to metabase,"If you set `metabaseInstanceUrl` to a valid url that answers ""200"" to http requests, we don't detect that it's not metabase and we try to work as normal, causing weird issues like component crashing or infinite loaders.
If JWT is setup correctly, we even return `{""status"":""success""}` from `useMetabaseAuthStatus`
![Image](https://github.com/user-attachments/assets/cb8ddcff-326f-47bb-8121-cf25e5859c0b)
",npretto,2024-09-26 15:24:44+00:00,[],2024-11-08 08:57:59+00:00,2024-11-08 08:57:57+00:00,https://github.com/metabase/metabase/issues/48145,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2377430268, 'issue_id': 2550916719, 'author': 'npretto', 'body': 'This snippet would show an error if we detect that /properties doesn\'t return a json, it\'s not perfect but it\'s a start\n```\ndiff --git a/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts b/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts\nindex fe4509737c..b9ae69e5c9 100644\n--- a/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts\n+++ b/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts\n@@ -15,6 +15,7 @@ import api from ""metabase/lib/api"";\n import { refreshSiteSettings } from ""metabase/redux/settings"";\n import { refreshCurrentUser } from ""metabase/redux/user"";\n import registerVisualizations from ""metabase/visualizations/register"";\n+import { t } from ""ttag"";\n \n const registerVisualizationsOnce = _.once(registerVisualizations);\n \n@@ -71,6 +72,18 @@ export const useInitData = ({ config }: InitDataLoaderParameters) => {\n             dispatch(refreshSiteSettings({})),\n           ]);\n \n+          if (typeof siteSettingsResponse.payload !== ""object"") {\n+            dispatch(\n+              setLoginStatus({\n+                status: ""error"",\n+                error: new Error(\n+                  t`Could not connect to metabase, is metabaseInstanceUrl correct?`,\n+                ),\n+              }),\n+            );\n+            return;\n+          }\n+\n           if (\n             userResponse.meta.requestStatus === ""rejected"" ||\n             siteSettingsResponse.meta.requestStatus === ""rejected""\n```\n\n![Image](https://github.com/user-attachments/assets/4723700a-3b52-4eab-b756-6daed9084248)', 'created_at': datetime.datetime(2024, 9, 26, 16, 30, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464166249, 'issue_id': 2550916719, 'author': 'npretto', 'body': '![Image](https://github.com/user-attachments/assets/f57bca35-dd62-4cd1-b682-260d9e0fbd75)\n\nThis seems to be fixed now, most likely by https://github.com/metabase/metabase/pull/49214', 'created_at': datetime.datetime(2024, 11, 8, 8, 57, 58, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-09-26 16:30:18 UTC): This snippet would show an error if we detect that /properties doesn't return a json, it's not perfect but it's a start
```
diff --git a/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts b/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts
index fe4509737c..b9ae69e5c9 100644
--- a/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts
+++ b/enterprise/frontend/src/embedding-sdk/hooks/private/use-init-data.ts
@@ -15,6 +15,7 @@ import api from ""metabase/lib/api"";
 import { refreshSiteSettings } from ""metabase/redux/settings"";
 import { refreshCurrentUser } from ""metabase/redux/user"";
 import registerVisualizations from ""metabase/visualizations/register"";
+import { t } from ""ttag"";
 
 const registerVisualizationsOnce = _.once(registerVisualizations);
 
@@ -71,6 +72,18 @@ export const useInitData = ({ config }: InitDataLoaderParameters) => {
             dispatch(refreshSiteSettings({})),
           ]);
 
+          if (typeof siteSettingsResponse.payload !== ""object"") {
+            dispatch(
+              setLoginStatus({
+                status: ""error"",
+                error: new Error(
+                  t`Could not connect to metabase, is metabaseInstanceUrl correct?`,
+                ),
+              }),
+            );
+            return;
+          }
+
           if (
             userResponse.meta.requestStatus === ""rejected"" ||
             siteSettingsResponse.meta.requestStatus === ""rejected""
```

![Image](https://github.com/user-attachments/assets/4723700a-3b52-4eab-b756-6daed9084248)

npretto (Issue Creator) on (2024-11-08 08:57:58 UTC): ![Image](https://github.com/user-attachments/assets/f57bca35-dd62-4cd1-b682-260d9e0fbd75)

This seems to be fixed now, most likely by https://github.com/metabase/metabase/pull/49214

"
2550874666,issue,closed,completed,Unexpected error while listing all models,"### Describe the bug

On the main page, when clicking on models (/browse/models) I get an unexpected error message.

![image](https://github.com/user-attachments/assets/3873615e-ee11-4337-859f-a4fc38ec74d7)

### To Reproduce

1. Go to the main page.
2. Click on models.

### Expected behavior

All models should be displayed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""oracle"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Windows Server 2012 R2"",
    ""os.version"": ""6.3"",
    ""user.language"": ""pt"",
    ""user.timezone"": ""GMT-3""
  }
}
```


### Severity

Medium

### Additional context

_No response_",tatusis,2024-09-26 15:06:07+00:00,[],2025-01-17 20:44:35+00:00,2025-01-17 20:01:49+00:00,https://github.com/metabase/metabase/issues/48144,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2379463572, 'issue_id': 2550874666, 'author': 'npfitz', 'body': 'Hi @tatusis, Is this still happening? Are you able to provide logs from the JS console or an error message from the API (both would be very helpful)', 'created_at': datetime.datetime(2024, 9, 27, 14, 52, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2379556957, 'issue_id': 2550874666, 'author': 'tatusis', 'body': 'Hi.\r\n\r\nBelow is the print of the network tab:\r\n\r\n![image](https://github.com/user-attachments/assets/f93f494c-ffd2-4e87-a24b-1072ec0daa00)\r\n\r\nConsole tab:\r\n\r\n![image](https://github.com/user-attachments/assets/26c41131-4108-4085-b7c1-1801b846ebaf)\r\n\r\n![image](https://github.com/user-attachments/assets/8d9fcf01-5dec-4f57-a49d-c452e302494b)', 'created_at': datetime.datetime(2024, 9, 27, 15, 33, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2379725730, 'issue_id': 2550874666, 'author': 'tatusis', 'body': ""It looks like the problem is with the user's default language.\r\n\r\nChanging it to English, the listing works perfectly and the error does not appear.\r\n\r\n![image](https://github.com/user-attachments/assets/e025f61c-557f-4522-a6f4-2a42bab47eab)"", 'created_at': datetime.datetime(2024, 9, 27, 17, 13, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578343837, 'issue_id': 2550874666, 'author': 'tatusis', 'body': '[metabase-diagnostic-info-2025-01-08T18_24_44.741Z.json](https://github.com/user-attachments/files/18351458/metabase-diagnostic-info-2025-01-08T18_24_44.741Z.json)', 'created_at': datetime.datetime(2025, 1, 8, 18, 26, 17, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-09-27 14:52:25 UTC): Hi @tatusis, Is this still happening? Are you able to provide logs from the JS console or an error message from the API (both would be very helpful)

tatusis (Issue Creator) on (2024-09-27 15:33:06 UTC): Hi.

Below is the print of the network tab:

![image](https://github.com/user-attachments/assets/f93f494c-ffd2-4e87-a24b-1072ec0daa00)

Console tab:

![image](https://github.com/user-attachments/assets/26c41131-4108-4085-b7c1-1801b846ebaf)

![image](https://github.com/user-attachments/assets/8d9fcf01-5dec-4f57-a49d-c452e302494b)

tatusis (Issue Creator) on (2024-09-27 17:13:04 UTC): It looks like the problem is with the user's default language.

Changing it to English, the listing works perfectly and the error does not appear.

![image](https://github.com/user-attachments/assets/e025f61c-557f-4522-a6f4-2a42bab47eab)

tatusis (Issue Creator) on (2025-01-08 18:26:17 UTC): [metabase-diagnostic-info-2025-01-08T18_24_44.741Z.json](https://github.com/user-attachments/files/18351458/metabase-diagnostic-info-2025-01-08T18_24_44.741Z.json)

"
2550863457,issue,open,,Dragging a card on a dashboard causes spurious text highlighting,"### Describe the bug

Dragging a card on a dashboard in edit mode causes text on the dashcard, as well as sometimes other dashcards, to be temporarily highlighted. 

https://www.loom.com/share/8cc50b0aaf9d470690f1c0ac65cce395?sid=a292d89d-18e4-44e8-858b-986b8e417a0a

### To Reproduce

See video	

### Expected behavior

Dragging a card should not be interpreted as selecting text

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master (2e2e99d7a9f2b090318aaf2f510504c68f0bdf08) on Firefox on Mac OS
```


### Severity

P3

### Additional context

_No response_",noahmoss,2024-09-26 15:01:39+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/48143,"[('Type:Bug', 'Product defects'), ('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2550788507,issue,open,,Customize colors of arrows and number in Trend visualization,"**Is your feature request related to a problem? Please describe.**
Currently, it’s not possible to adjust the colors of the arrows on trend charts that indicate upward or downward changes, but there are situations where this would be helpful. For example (actual request):

> We’d like to tone down the colors to avoid drawing too much attention to negative developments for our customers. We want the information to be available but not too prominent.

**Describe the solution you'd like**
Allow users to customize the color of the arrows for upward and downward trends, ideally separately from the color of the numbers.

**Describe alternatives you've considered**
Conditional formatting on tables can highlight changes more subtly, but for trend visualizations, there aren't any good alternatives.

**How important is this feature to you?**
This was requested by a customer.


",zbodi74,2024-09-26 14:35:57+00:00,[],2025-02-04 20:31:55+00:00,,https://github.com/metabase/metabase/issues/48142,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges')]","[{'comment_id': 2378584875, 'issue_id': 2550788507, 'author': 'onlinebirds2027', 'body': 'Thank you for the request. We will be pleased if the colors are adapted!', 'created_at': datetime.datetime(2024, 9, 27, 7, 21, 36, tzinfo=datetime.timezone.utc)}]","onlinebirds2027 on (2024-09-27 07:21:36 UTC): Thank you for the request. We will be pleased if the colors are adapted!

"
2550766378,issue,closed,completed,Investigate occasional subscriptions failures,"**Context**

[Example failure](https://metaboat.slack.com/archives/C064QMXEV9N/p1727352120474199)

Sometimes dashboard subscriptions fail as in the example above. A manual attempt to send the same dashboard worked fine.
From the failed subscription we can see that tables and scalars that were rendered by clojure code did not fail, only js-based subscriptions failed which signals there can be an issue with out usage of GraalJS.

",alxnddr,2024-09-26 14:26:58+00:00,[],2024-10-01 01:30:21+00:00,2024-10-01 01:30:21+00:00,https://github.com/metabase/metabase/issues/48141,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2384603369, 'issue_id': 2550766378, 'author': 'qnkhuat', 'body': 'see this [thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1727361040757189?thread_ts=1727353490.018049&cid=C064QMXEV9N) for why it happened on our stats.', 'created_at': datetime.datetime(2024, 10, 1, 1, 30, 21, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-10-01 01:30:21 UTC): see this [thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1727361040757189?thread_ts=1727353490.018049&cid=C064QMXEV9N) for why it happened on our stats.

"
2550606883,issue,open,,Metabase Normalize with errors,"**Describe the bug**
I have noticed after upgrading to v50 that I cannot edit my Models' Metadata, the Save button is permanently grayed out and no matter what I do, it does not change.

After some rounds of debugging, I have noticed in the JS Console a sleuth of error messages from the metabase.lib.normalize tool but I have no idea if it is related.

**Logs**
`[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}], :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""`

This error appears at least 3 times per page, in every page.

**To Reproduce**
Steps to reproduce the behavior:
1. Open Dev Tools before login
2. Login
3. See error in Dev Tools

**Expected behavior**
I Should be able to save my models metadata after updating them

**Screenshots**
N/A

**Severity**
While this does not stop my users from using the tool, it is blocking me from writing the documentation needed for them to use the queries more effectively, as I cannot change the names of the columns of my models to be something more descriptive.

**Additional context**
I use Metabase in a Docker environment, with the latest tag.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:130.0) Gecko/20100101 Firefox/130.0"",
    ""vendor"": """"
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mongo""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v0.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.164.1-1.cm2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```",zeh-almeida,2024-09-26 13:32:24+00:00,[],2025-01-24 12:05:36+00:00,,https://github.com/metabase/metabase/issues/48140,[],"[{'comment_id': 2440514196, 'issue_id': 2550606883, 'author': 'LeveL7LLC', 'body': 'I\'m also getting these exact same errors with my docker installation as well. \n\n[metabase.lib.normalize] ""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n""\n\nDoes anyone have any insight yet?', 'created_at': datetime.datetime(2024, 10, 28, 4, 14, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486813194, 'issue_id': 2550606883, 'author': 'apeisa', 'body': 'Same here:\n\n`\n""Error normalizing pMBQL:\\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database],\\n    :schema #object[Object [object Object]],\\n    :value nil,\\n    :type :malli.core/missing-key}\\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\\n    :in [:stages 0], \\n    :schema #object[Object [object Object]], \\n    :value {:lib/type :mbql.stage/mbql}})}}\\n""\n`\n\nWe see these on Dashboard with some filters. When trying to Create a public link for a dashboard that has these on console it fails with this response (500). Not sure if these two problems are related or not.\n\n```\n{\n    ""via"": [\n        {\n            ""type"": ""clojure.lang.ExceptionInfo"",\n            ""message"": "":parameters must be a sequence of maps with :id and :type keys"",\n            ""data"": {\n                ""parameters"": [\n                    {\n                        ""slug"": ""customer"",\n                        ""values_query_type"": ""list"",\n                        ""default"": [\n                            ""Customer & Oy""\n                        ],\n                        ""name"": ""Customer"",\n                        ""isMultiSelect"": false,\n                        ""type"": ""string/="",\n                        ""sectionId"": ""string"",\n                        ""values_source_type"": ""card"",\n                        ""id"": ""65910d91"",\n                        ""values_source_config"": {\n                            ""card_id"": 71,\n                            ""value_field"": [\n                                ""field"",\n                                223,\n                                {\n                                    ""base-type"": ""type/Text""\n                                }\n                            ]\n                        },\n                        ""required"": true\n                    },\n                    {\n                        ""name"": ""Time grouping"",\n                        ""slug"": ""time_grouping"",\n                        ""id"": ""e852a70e"",\n                        ""type"": ""temporal-unit"",\n                        ""sectionId"": ""temporal-unit"",\n                        ""temporal_units"": [\n                            ""day"",\n                            ""week"",\n                            ""month"",\n                            ""quarter"",\n                            ""year"",\n                            ""day-of-week"",\n                            ""day-of-month""\n                        ],\n                        ""default"": ""month""\n                    },\n                    {\n                        ""name"": ""All Options"",\n                        ""slug"": ""all_options"",\n                        ""id"": ""bbcde12e"",\n                        ""type"": ""date/all-options"",\n                        ""sectionId"": ""date"",\n                        ""required"": true,\n                        ""default"": ""past12months""\n                    }\n                ],\n                ""toucan2/context-trace"": [\n                    [\n                        ""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"",\n                        {\n                            ""toucan2.jdbc.query/sql-args"": [\n                                ""SELECT * FROM \\""report_dashboard\\"" WHERE \\""id\\"" = ?"",\n                                7\n                            ]\n                        }\n                    ],\n                    [\n                        ""resolve connection"",\n                        {\n                            ""toucan2.connection/connectable"": ""class metabase.db.connection.ApplicationDB""\n                        }\n                    ],\n                    [\n                        ""resolve connection"",\n                        {\n                            ""toucan2.connection/connectable"": ""default""\n                        }\n                    ],\n                    [\n                        ""resolve connection"",\n                        {\n                            ""toucan2.connection/connectable"": null\n                        }\n                    ],\n                    {\n                        ""toucan2.pipeline/rf"": ""clojure.core$map$fn__5950$fn__5951@67593ab2""\n                    },\n                    [\n                        ""with compiled query"",\n                        {\n                            ""toucan2.pipeline/compiled-query"": [\n                                ""SELECT * FROM \\""report_dashboard\\"" WHERE \\""id\\"" = ?"",\n                                7\n                            ]\n                        }\n                    ],\n                    [\n                        ""with built query"",\n                        {\n                            ""toucan2.pipeline/built-query"": {\n                                ""select"": [\n                                    ""*""\n                                ],\n                                ""from"": [\n                                    [\n                                        ""report_dashboard""\n                                    ]\n                                ],\n                                ""where"": [\n                                    ""="",\n                                    ""id"",\n                                    7\n                                ]\n                            }\n                        }\n                    ],\n                    [\n                        ""apply before-update to matching rows"",\n                        {\n                            ""toucan2.tools.before-update/model"": ""model/Dashboard"",\n                            ""toucan2.tools.before-update/changes"": {\n                                ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",\n                                ""made_public_by_id"": 2\n                            }\n                        }\n                    ],\n                    [\n                        ""with resolved query"",\n                        {\n                            ""toucan2.pipeline/resolved-query"": {}\n                        }\n                    ],\n                    [\n                        ""with parsed args"",\n                        {\n                            ""toucan2.pipeline/query-type"": ""toucan.query-type/update.update-count"",\n                            ""toucan2.pipeline/parsed-args"": {\n                                ""changes"": {\n                                    ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",\n                                    ""made_public_by_id"": 2\n                                },\n                                ""queryable"": {},\n                                ""kv-args"": {\n                                    ""toucan/pk"": 7\n                                }\n                            }\n                        }\n                    ],\n                    [\n                        ""with model"",\n                        {\n                            ""toucan2.pipeline/model"": ""model/Dashboard""\n                        }\n                    ],\n                    [\n                        ""with unparsed args"",\n                        {\n                            ""toucan2.pipeline/query-type"": ""toucan.query-type/update.update-count"",\n                            ""toucan2.pipeline/unparsed-args"": [\n                                ""model/Dashboard"",\n                                7,\n                                {\n                                    ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",\n                                    ""made_public_by_id"": 2\n                                }\n                            ]\n                        }\n                    ]\n                ]\n            },\n            ""at"": [\n                ""metabase.models.params$assert_valid_parameters"",\n                ""invokeStatic"",\n                ""params.clj"",\n                43\n            ]\n        }\n    ],\n   <clip trace>\n}\n```', 'created_at': datetime.datetime(2024, 11, 19, 21, 43, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489356689, 'issue_id': 2550606883, 'author': 'rodrigoGA', 'body': 'I am observing the same error in the JavaScript console.', 'created_at': datetime.datetime(2024, 11, 20, 19, 13, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587955080, 'issue_id': 2550606883, 'author': 'alick-at-ghost', 'body': ""seeing the same error in our JS console - what's the fix here?"", 'created_at': datetime.datetime(2025, 1, 13, 18, 58, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612221426, 'issue_id': 2550606883, 'author': 'ivanELEC', 'body': ""Also getting this in JS console when trying to load certain dashboards - but not enough information in the log to inform us if it's something we've done wrong/can fix"", 'created_at': datetime.datetime(2025, 1, 24, 10, 45, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612369288, 'issue_id': 2550606883, 'author': 'zeh-almeida', 'body': 'While the log messages persist, my problem with the ""immutable"" models happened because I was using a Document DB as the data source.\n\nRegular SQL Data Sources do not have this problem and according to the documentation are also the preferred way to work with Metabase.\n\nIn any case, I will keep this bug report opened because the Log Messages are still happening.', 'created_at': datetime.datetime(2025, 1, 24, 12, 5, 35, tzinfo=datetime.timezone.utc)}]","LeveL7LLC on (2024-10-28 04:14:40 UTC): I'm also getting these exact same errors with my docker installation as well. 

[metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""

Does anyone have any insight yet?

apeisa on (2024-11-19 21:43:33 UTC): Same here:

`
""Error normalizing pMBQL:\n{:value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value {:lib/type :mbql/query, :stages [{:lib/type :mbql.stage/mbql}]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database],\n    :schema #object[Object [object Object]],\n    :value nil,\n    :type :malli.core/missing-key}\n   {:path [0 0 :stages 0 1 0 0 :mbql.stage/mbql],\n    :in [:stages 0], \n    :schema #object[Object [object Object]], \n    :value {:lib/type :mbql.stage/mbql}})}}\n""
`

We see these on Dashboard with some filters. When trying to Create a public link for a dashboard that has these on console it fails with this response (500). Not sure if these two problems are related or not.

```
{
    ""via"": [
        {
            ""type"": ""clojure.lang.ExceptionInfo"",
            ""message"": "":parameters must be a sequence of maps with :id and :type keys"",
            ""data"": {
                ""parameters"": [
                    {
                        ""slug"": ""customer"",
                        ""values_query_type"": ""list"",
                        ""default"": [
                            ""Customer & Oy""
                        ],
                        ""name"": ""Customer"",
                        ""isMultiSelect"": false,
                        ""type"": ""string/="",
                        ""sectionId"": ""string"",
                        ""values_source_type"": ""card"",
                        ""id"": ""65910d91"",
                        ""values_source_config"": {
                            ""card_id"": 71,
                            ""value_field"": [
                                ""field"",
                                223,
                                {
                                    ""base-type"": ""type/Text""
                                }
                            ]
                        },
                        ""required"": true
                    },
                    {
                        ""name"": ""Time grouping"",
                        ""slug"": ""time_grouping"",
                        ""id"": ""e852a70e"",
                        ""type"": ""temporal-unit"",
                        ""sectionId"": ""temporal-unit"",
                        ""temporal_units"": [
                            ""day"",
                            ""week"",
                            ""month"",
                            ""quarter"",
                            ""year"",
                            ""day-of-week"",
                            ""day-of-month""
                        ],
                        ""default"": ""month""
                    },
                    {
                        ""name"": ""All Options"",
                        ""slug"": ""all_options"",
                        ""id"": ""bbcde12e"",
                        ""type"": ""date/all-options"",
                        ""sectionId"": ""date"",
                        ""required"": true,
                        ""default"": ""past12months""
                    }
                ],
                ""toucan2/context-trace"": [
                    [
                        ""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"",
                        {
                            ""toucan2.jdbc.query/sql-args"": [
                                ""SELECT * FROM \""report_dashboard\"" WHERE \""id\"" = ?"",
                                7
                            ]
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": ""class metabase.db.connection.ApplicationDB""
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": ""default""
                        }
                    ],
                    [
                        ""resolve connection"",
                        {
                            ""toucan2.connection/connectable"": null
                        }
                    ],
                    {
                        ""toucan2.pipeline/rf"": ""clojure.core$map$fn__5950$fn__5951@67593ab2""
                    },
                    [
                        ""with compiled query"",
                        {
                            ""toucan2.pipeline/compiled-query"": [
                                ""SELECT * FROM \""report_dashboard\"" WHERE \""id\"" = ?"",
                                7
                            ]
                        }
                    ],
                    [
                        ""with built query"",
                        {
                            ""toucan2.pipeline/built-query"": {
                                ""select"": [
                                    ""*""
                                ],
                                ""from"": [
                                    [
                                        ""report_dashboard""
                                    ]
                                ],
                                ""where"": [
                                    ""="",
                                    ""id"",
                                    7
                                ]
                            }
                        }
                    ],
                    [
                        ""apply before-update to matching rows"",
                        {
                            ""toucan2.tools.before-update/model"": ""model/Dashboard"",
                            ""toucan2.tools.before-update/changes"": {
                                ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",
                                ""made_public_by_id"": 2
                            }
                        }
                    ],
                    [
                        ""with resolved query"",
                        {
                            ""toucan2.pipeline/resolved-query"": {}
                        }
                    ],
                    [
                        ""with parsed args"",
                        {
                            ""toucan2.pipeline/query-type"": ""toucan.query-type/update.update-count"",
                            ""toucan2.pipeline/parsed-args"": {
                                ""changes"": {
                                    ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",
                                    ""made_public_by_id"": 2
                                },
                                ""queryable"": {},
                                ""kv-args"": {
                                    ""toucan/pk"": 7
                                }
                            }
                        }
                    ],
                    [
                        ""with model"",
                        {
                            ""toucan2.pipeline/model"": ""model/Dashboard""
                        }
                    ],
                    [
                        ""with unparsed args"",
                        {
                            ""toucan2.pipeline/query-type"": ""toucan.query-type/update.update-count"",
                            ""toucan2.pipeline/unparsed-args"": [
                                ""model/Dashboard"",
                                7,
                                {
                                    ""public_uuid"": ""03e012c4-7c6a-4c88-8f46-d8454ed4953c"",
                                    ""made_public_by_id"": 2
                                }
                            ]
                        }
                    ]
                ]
            },
            ""at"": [
                ""metabase.models.params$assert_valid_parameters"",
                ""invokeStatic"",
                ""params.clj"",
                43
            ]
        }
    ],
   <clip trace>
}
```

rodrigoGA on (2024-11-20 19:13:11 UTC): I am observing the same error in the JavaScript console.

alick-at-ghost on (2025-01-13 18:58:49 UTC): seeing the same error in our JS console - what's the fix here?

ivanELEC on (2025-01-24 10:45:49 UTC): Also getting this in JS console when trying to load certain dashboards - but not enough information in the log to inform us if it's something we've done wrong/can fix

zeh-almeida (Issue Creator) on (2025-01-24 12:05:35 UTC): While the log messages persist, my problem with the ""immutable"" models happened because I was using a Document DB as the data source.

Regular SQL Data Sources do not have this problem and according to the documentation are also the preferred way to work with Metabase.

In any case, I will keep this bug report opened because the Log Messages are still happening.

"
2550477124,issue,open,,"Filter labels not showing on embedded dashboard, despite being retrieved by browser.","### Describe the bug

### Description:

I have a dashboard with two linked filters. When embedded, one filter is locked.

- In the Metabase UI, the 'entity name' is displayed next to the 'value' in the filter dropdown.
- In the embed, only the value is displayed. The name is not displayed.
- I notice that when I first click on the select field, a request is made to get the values. This correctly contains both the value and name; but the name is not displayed.

Expectation:
- 🐞 Both the option value and name/label should be displayed for each option in the dropdown.

**I think this is a FE bug because the data is available in the FE, but it is not being displayed.**

---

### Evidence:

Metabase UI showing both value and label:
<img width=""636"" alt=""Screenshot 2024-09-26 at 12 55 03"" src=""https://github.com/user-attachments/assets/e6ec5c99-68a6-4eb5-b761-33d2e81051fe"">

Embed showing only value:
<img width=""385"" alt=""Screenshot 2024-09-26 at 12 54 17"" src=""https://github.com/user-attachments/assets/f0b5f7be-6bad-478b-abdf-729c4df53187"">

Request for values:
```
https://analytics.tools.ht1.uk/api/embed/dashboard/.../params/5a4a24bf/values
```
Result:
```
{""values"":[[""F84009"",""Stratford Village Surgery""]],""has_more_values"":false}
```

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome Version 128.0.6613.139 (Official Build) (arm64)
- Mac OSX

Diagnostics:
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.4+7-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.4"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.4+7-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-1.cm2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""mongo"",
      ""duckdb""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-25"",
      ""tag"": ""v1.50.16"",
      ""hash"": ""28de9df""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking some users from using filters

### Additional context

_No response_",jacknewberry,2024-09-26 12:44:16+00:00,[],2025-02-04 20:29:07+00:00,,https://github.com/metabase/metabase/issues/48138,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]",[],
2550256726,issue,closed,completed,Upload CSV containing Cyrillic words with spaces and special characters fail to render,"### Describe the bug

Upload CSV containing Cyrillic words with spaces and special characters fail to render.

### To Reproduce

1. Go to Upload CSV and upload the following CSV [hello.csv](https://github.com/user-attachments/files/17147106/hello.csv) ... You will notice 2 columns having a space and a special character respectively

<img width=""409"" alt=""image"" src=""https://github.com/user-attachments/assets/73f42cef-58f0-4526-b120-7ffeb5c8823d"">

2. You will notice that once you upload the csv you get a strange looking column for the two of them:

<img width=""1507"" alt=""image"" src=""https://github.com/user-attachments/assets/db69b40e-78ea-4897-95f5-4bb2c298fc26"">



### Expected behavior

The proper name gets reflected in the Upload CSV

### Logs

```
{:database 26,
 :type :native,
 :native
 {:query
  ""CREATE TABLE \""uploads\"".\""hello_20240926110149\"" (\""_mb_row_id\"" BIGSERIAL, \""id\"" BOOLEAN, \""%D0%BF%D0%B0%D1%80%D1%82%D0%BD%D0%B5%D1%80\"" BOOLEAN, \""%D0%B0%D0%B4%D1%80%D0%B5%D1%81\"" BOOLEAN, \""unnamed_column\"" BOOLEAN, \""%D0%B4%D0%B0%D1%82%D0%B0%D0%B2_%D1%8B%D0%B5%D0%B7%D0%B4%D0%B0\"" BOOLEAN, \""%D0%BF%D0%BE%D1%87%D0%B8%D0%BD%D0%B8%D0%BB%D0%B8_\"" BOOLEAN, PRIMARY KEY(\""_mb_row_id\""))""}}

[1572d83d-bb19-4bae-9ce7-432773e62486] 2024-09-26T13:01:49+02:00 DEBUG metabase.query-processor.writeback Executing query

{:database 26,
 :type :native,
 :native
 {:query
  ""CREATE TABLE \""uploads\"".\""hello_20240926110149\"" (\""_mb_row_id\"" BIGSERIAL, \""id\"" BOOLEAN, \""%D0%BF%D0%B0%D1%80%D1%82%D0%BD%D0%B5%D1%80\"" BOOLEAN, \""%D0%B0%D0%B4%D1%80%D0%B5%D1%81\"" BOOLEAN, \""unnamed_column\"" BOOLEAN, \""%D0%B4%D0%B0%D1%82%D0%B0%D0%B2_%D1%8B%D0%B5%D0%B7%D0%B4%D0%B0\"" BOOLEAN, \""%D0%BF%D0%BE%D1%87%D0%B8%D0%BD%D0%B8%D0%BB%D0%B8_\"" BOOLEAN, PRIMARY KEY(\""_mb_row_id\""))""}}
```

### Information about your Metabase installation

```JSON
Tested both on 50 and stats
```


### Severity

It blocks cyrillic users from uploading files and forces them to update the file each time

### Additional context

_No response_",Tony-metabase,2024-09-26 11:04:41+00:00,['crisptrutski'],2024-09-27 14:48:12+00:00,2024-09-27 07:30:37+00:00,https://github.com/metabase/metabase/issues/48135,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2376973273, 'issue_id': 2550256726, 'author': 'crisptrutski', 'body': ""The strange looking names are the underlying munged column names we use for the database, which for better or worse is URL encoding. We can't change this format without breaking append to models with even just a space in a column name.\r\n\r\nThe way this is meant to work is that we automatically configure a display name for the column. Its strange that this is only happening for some of the columns, will dig into it."", 'created_at': datetime.datetime(2024, 9, 26, 13, 26, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378019140, 'issue_id': 2550256726, 'author': 'crisptrutski', 'body': ""While we're waiting for the fix to get released, another workaround is to update the display name on the underlying Field in Metabase."", 'created_at': datetime.datetime(2024, 9, 26, 22, 5, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378590883, 'issue_id': 2550256726, 'author': 'Tony-metabase', 'body': 'Will that break subsequent uploads to the same model? Right now the workaround I am suggesting is to remove spaces and special characters where possible', 'created_at': datetime.datetime(2024, 9, 27, 7, 25, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2379001438, 'issue_id': 2550256726, 'author': 'crisptrutski', 'body': 'No, changing the display name is totally safe', 'created_at': datetime.datetime(2024, 9, 27, 10, 53, 1, tzinfo=datetime.timezone.utc)}]","crisptrutski (Assginee) on (2024-09-26 13:26:04 UTC): The strange looking names are the underlying munged column names we use for the database, which for better or worse is URL encoding. We can't change this format without breaking append to models with even just a space in a column name.

The way this is meant to work is that we automatically configure a display name for the column. Its strange that this is only happening for some of the columns, will dig into it.

crisptrutski (Assginee) on (2024-09-26 22:05:46 UTC): While we're waiting for the fix to get released, another workaround is to update the display name on the underlying Field in Metabase.

Tony-metabase (Issue Creator) on (2024-09-27 07:25:17 UTC): Will that break subsequent uploads to the same model? Right now the workaround I am suggesting is to remove spaces and special characters where possible

crisptrutski (Assginee) on (2024-09-27 10:53:01 UTC): No, changing the display name is totally safe

"
2549944422,issue,open,,"Negative values overlap with x-axis labels, making them unreadable","### Describe the bug

In a bar chart, when negative values are displayed, they sometimes overlap with the x-axis labels, making them unreadable. This occurs especially when there are multiple bars with both positive and negative values.

![image](https://github.com/user-attachments/assets/146aad85-2b40-40e3-b33c-0e2a22e16fa0)


### To Reproduce

1. Go to a dashboard with a bar chart visualization.
2. Add data that includes both positive and negative values.
3. Ensure that the bar chart displays values on the x-axis.
4. Notice that negative values overlap with the x-axis labels.


### Expected behavior

Negative values should be positioned below the x-axis, without overlapping with the labels, allowing both the bars and labels to be readable clearly.




### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.146.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-28"",
      ""tag"": ""v0.50.8"",
      ""hash"": ""dc9e68b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

This issue is annoying and impacts the readability of charts when negative values are present, but it does not block core usage of Metabase.

### Additional context

_No response_",DieudonneCesar,2024-09-26 08:52:13+00:00,[],2025-02-04 20:31:23+00:00,,https://github.com/metabase/metabase/issues/48130,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2549675834,issue,open,,"Search configuration options (what to display, predefined rankings, etc)","**Is your feature request related to a problem? Please describe.**

We have thousands of questions and raw db tables. Whenever we make a dashboard it might contain 10 questions with similar related names to the parent dashboard. Quite often that family of related questions will all come from the same model.

When you search, the signal to noise ratio is very low, because the search exposes all of the raw db tables, the models, the questions and the dashboards which are often last or shown lower down in the results. When all we want is to guide users to the dashboard which uses all of those components.

**Describe the solution you'd like**
* [ ] I'd like admin config to completely disable certain categories from being exposed in search. For example I never ever want a raw db table to be found via search, and I never want models exposed in search either. 

* [ ] If a search term matches a question, AND the question is used inside a dashboard, then that should boost the relevance of the dashboard, AND the question should not appear in the results at all

* [ ] A question should only ever be found in the search results if it is not contained inside a dashboard (or a small edge case if you can see the question, but you can't see the dashboard due to permissions - n practice this is very unlikely)

* [ ] Admin config to disable prompting to create new questions / dashboards when searching, I want to guide users to existing content not creating inconsistent duplicates

* [ ] If there does exist questions without parent dashboards along side dashboard which both match search terms then in general dashboards should get higher precedence in the search results

Some 

**Describe alternatives you've considered**
I don't have any workaround.

**How important is this feature to you?**
We have a lot of complaints of thing being hard to find, we have a fairly good structure of collections but search is the main way that people attempt to look for things and most often can't find it and resort to bookmarks and asking around.

**Additional context**
Add any other context or screenshots about the feature request here.
",brendanheywood,2024-09-26 06:50:59+00:00,[],2025-02-04 20:30:56+00:00,,https://github.com/metabase/metabase/issues/48129,"[('Type:New Feature', ''), ('Organization/Search', ''), ('.Product Input Needed', '')]","[{'comment_id': 2449277172, 'issue_id': 2549675834, 'author': 'brendanheywood', 'body': 'As a concrete example, here is a typical search which returns 7 results. Of those 5 are places I never want a typical user to be guided to, and of the 2 left the dashboard should come first. The collection shown contains the dashboard I want, and should be lower down:\n\n![Image](https://github.com/user-attachments/assets/62dedff4-2e5a-4aeb-aa46-b081b984a0c1)\n\nthis is what I want to see:\n\n![Image](https://github.com/user-attachments/assets/9047879c-d395-4941-ba5e-682bd53d40d1)', 'created_at': datetime.datetime(2024, 10, 31, 8, 9, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567736698, 'issue_id': 2549675834, 'author': 'brunobergher', 'body': ""Hey @brendanheywood, while it's still unlikely we'll add these many knobs to control search results, we did ship major improvements to search ranking (and performance) in 52. It may be worth enabling it to see if you still run into these problems."", 'created_at': datetime.datetime(2025, 1, 2, 12, 57, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567785462, 'issue_id': 2549675834, 'author': 'brendanheywood', 'body': ""thanks @brunobergher can you please point me at some docs of what I can enable or tune? We are already on 52 and it's still the same for me.\n\nI'm currently working around it a browser custom search engine using this url and that is working quite well:\n\n```\nhttps://metabase.catalyst-au.net/search?q=%s&type=dashboard\n```\n\nIf was up to me wouldn't add more admin settings either, I'd just implement the logic to only surface the highest level objects first. eg if a question uses a model, then the question should come first in the search. If a dashboard uses a question, then the dashboard comes first before the question. That alone would mean in almost all cases the first link is what you actually want even if there is lots of other results. I think in most cases you could not show any dependent objects if a higher one matches but that might be too controversial as a hard coded behavior."", 'created_at': datetime.datetime(2025, 1, 2, 13, 35, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567842161, 'issue_id': 2549675834, 'author': 'brunobergher', 'body': ""The new search is disabled by default in 53 as we ensure it's all working perfectly and will become default in 53 (but I see we're kind of hiding that right now). You can enable the new search by setting `MB_SEARCH_ENGINE=appdb` when launching the app (subtly mentioned in the [52 release announcement](https://www.metabase.com/releases/metabase-52)).\n\nThe ranking algorithm is still being tweaked, but it takes all of that into consideration (and more)."", 'created_at': datetime.datetime(2025, 1, 2, 14, 16, 47, tzinfo=datetime.timezone.utc)}]","brendanheywood (Issue Creator) on (2024-10-31 08:09:54 UTC): As a concrete example, here is a typical search which returns 7 results. Of those 5 are places I never want a typical user to be guided to, and of the 2 left the dashboard should come first. The collection shown contains the dashboard I want, and should be lower down:

![Image](https://github.com/user-attachments/assets/62dedff4-2e5a-4aeb-aa46-b081b984a0c1)

this is what I want to see:

![Image](https://github.com/user-attachments/assets/9047879c-d395-4941-ba5e-682bd53d40d1)

brunobergher on (2025-01-02 12:57:12 UTC): Hey @brendanheywood, while it's still unlikely we'll add these many knobs to control search results, we did ship major improvements to search ranking (and performance) in 52. It may be worth enabling it to see if you still run into these problems.

brendanheywood (Issue Creator) on (2025-01-02 13:35:21 UTC): thanks @brunobergher can you please point me at some docs of what I can enable or tune? We are already on 52 and it's still the same for me.

I'm currently working around it a browser custom search engine using this url and that is working quite well:

```
https://metabase.catalyst-au.net/search?q=%s&type=dashboard
```

If was up to me wouldn't add more admin settings either, I'd just implement the logic to only surface the highest level objects first. eg if a question uses a model, then the question should come first in the search. If a dashboard uses a question, then the dashboard comes first before the question. That alone would mean in almost all cases the first link is what you actually want even if there is lots of other results. I think in most cases you could not show any dependent objects if a higher one matches but that might be too controversial as a hard coded behavior.

brunobergher on (2025-01-02 14:16:47 UTC): The new search is disabled by default in 53 as we ensure it's all working perfectly and will become default in 53 (but I see we're kind of hiding that right now). You can enable the new search by setting `MB_SEARCH_ENGINE=appdb` when launching the app (subtly mentioned in the [52 release announcement](https://www.metabase.com/releases/metabase-52)).

The ranking algorithm is still being tweaked, but it takes all of that into consideration (and more).

"
2549494299,issue,closed,not_planned,Server-side pagination,"**Is your feature request related to a problem? Please describe.**
We are using this as a BI tool and it requires the usage of going through pages.

**Describe the solution you'd like**
A server-side pagination feature at the bottom right of tables and models.

**Describe alternatives you've considered**
I have not considered any alternatives, and I'm unsure of how to accomplish this.

**How important is this feature to you?**
Very critical and is affecting our decision of using this application right now, as I'm unsure of a work-around either.
",pmessri,2024-09-26 04:40:03+00:00,[],2024-10-29 13:40:18+00:00,2024-10-29 13:40:17+00:00,https://github.com/metabase/metabase/issues/48128,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2444266043, 'issue_id': 2549494299, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/7842 or https://github.com/metabase/metabase/issues/8322\n\nwhy is it limiting the decision to use the app? you can increase the limit of what the api returns', 'created_at': datetime.datetime(2024, 10, 29, 13, 40, 13, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-10-29 13:40:13 UTC): duplicate of https://github.com/metabase/metabase/issues/7842 or https://github.com/metabase/metabase/issues/8322

why is it limiting the decision to use the app? you can increase the limit of what the api returns

"
2549401341,issue,closed,completed,Documentation links in command palette lead to empty pages,"### Describe the bug

The command palette lets you search the documentation for the string you type in:
![image](https://github.com/user-attachments/assets/010fc7a1-d711-4e9d-abce-5ed8bb6cccad)

The ""Search documentation for..."" button leads to URLs like `https://www.metabase.com/search?query=models`.

However, since the LLM search feature went live (which I think was about 15 minutes ago), those pages now have empty results:

![image](https://github.com/user-attachments/assets/44700600-e91e-46c6-b165-200c0f8b0a1c)


### To Reproduce

Open the command palette, type anything, and scroll to the bottom.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""h2"",
      ""postgres""
    ],
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-11"",
      ""src_hash"": ""e75aba344d8b556319a6fb2ccd8cc0fdae2e6893"",
      ""tag"": ""v1.1.37-SNAPSHOT"",
      ""hash"": ""d490322""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```


### Severity

P2 (it's a broken common feature with a straightforward workaround)",rafpaf,2024-09-26 03:07:00+00:00,"['npfitz', 'jeff-bruemmer']",2024-09-27 15:42:08+00:00,2024-09-27 15:42:08+00:00,https://github.com/metabase/metabase/issues/48127,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2549030165,issue,closed,completed,pie chart legend is aggressively truncated,"### Describe the bug

<img width=""972"" alt=""Screenshot 2024-09-25 at 2 07 32 PM"" src=""https://github.com/user-attachments/assets/46c03b68-2417-4236-98fc-2f1749a61557"">


When percentages are shown on the legend of the pie chart, the dimension names are truncated so aggressively you can't really read them.

### To Reproduce

1. Create any pie chart question (e.g. count of orders by product category)
2. Enable show percentages ""in legend"" or ""both"" setting



### Expected behavior

If there's enough space, the whole dimension name and percentage in the legend show be shown. If there isn't enough space, the dimension name should be truncated, but only the end.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Stats commit 2173e65
```


### Severity

Makes the pie chart difficult to use, since you need to be able to read the dimension names from the legend since they aren't on the chart itself

### Additional context

_No response_",EmmadUsmani,2024-09-25 21:27:24+00:00,['EmmadUsmani'],2024-11-18 20:51:15+00:00,2024-11-18 20:04:33+00:00,https://github.com/metabase/metabase/issues/48125,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]","[{'comment_id': 2484104496, 'issue_id': 2549030165, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.4](https://github.com/metabase/metabase/milestone/281)', 'created_at': datetime.datetime(2024, 11, 18, 20, 51, 14, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-18 20:51:14 UTC): 🚀 This should also be released by [v0.51.4](https://github.com/metabase/metabase/milestone/281)

"
2549020613,issue,open,,pie chart flickers when toggling legend,"### Describe the bug

https://github.com/user-attachments/assets/82680d54-6665-4d10-a3c9-9fadca46874b

It might be hard to see but there's a frame where the chart flickers when toggling the legend on/off.


### To Reproduce

Create any pie chart question (e.g. count of orders by product category), turn the legend on and off.


### Expected behavior

The chart should update smoothly, without a flicker in between

### Logs

_No response_

### Information about your Metabase installation

```JSON
Stats commit 2173e65
```


### Severity

Mildly annoying but doesn't come up often

### Additional context

_No response_",EmmadUsmani,2024-09-25 21:20:10+00:00,[],2025-02-04 20:31:39+00:00,,https://github.com/metabase/metabase/issues/48124,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Visualization/Legend', '')]",[],
2549013016,issue,closed,completed,pie chart off centered in query builder,"### Describe the bug

<img width=""1312"" alt=""Screenshot 2024-09-25 at 2 06 41 PM"" src=""https://github.com/user-attachments/assets/f44ee9f7-f026-45ae-b9d1-b25d8cebe657"">

As shown above the pie chart is off centered in the query builder

### To Reproduce

Create any pie chart question (e.g. count of orders by product category), view in query builder with full size window

### Expected behavior

Pie chart should be cenetered

### Logs

_No response_

### Information about your Metabase installation

```JSON
Stats commit 2173e65
```


### Severity

Looks pretty ugly and dashviz team agreed it should be fixed before 51 release

### Additional context

_No response_",EmmadUsmani,2024-09-25 21:14:55+00:00,['EmmadUsmani'],2024-10-08 16:13:59+00:00,2024-10-01 16:29:30+00:00,https://github.com/metabase/metabase/issues/48123,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2548787562,issue,closed,completed,Allow users to set an upgrade channel preference,"
see: https://www.notion.so/metabase/Channel-based-Releases-c50b4a957f474daca8d868d23606d745

Users should be able to choose an upgrade channel for in-product notifications:
- nightly
- beta
- stable/latest

Todo:
- [x] add admin setting ui to select an upgrade channel
- [x] adjust frontend logic to show release notes for the selected release channel
- [x] add release logic to add additional channel information to version-info.json",iethree,2024-09-25 19:08:52+00:00,['iethree'],2024-10-11 15:40:22+00:00,2024-10-11 15:40:22+00:00,https://github.com/metabase/metabase/issues/48121,"[('.Building & Releasing', ''), ('Administration/Settings', '')]",[],
2548493172,issue,closed,completed,missing tooltip for waterfall chart total,"### Describe the bug

Waterfall charts used to have a tooltip for the total bar that would display its value, but after we recently started using the echarts tooltip it's no longer there

https://github.com/user-attachments/assets/ea7e3fc1-9053-40f3-bde2-0651cc4003d3




### To Reproduce

1. Create a waterfall chart, can use the following SQL

```sql
select 'Apples' as product, 10 as profit
union all
select 'Bananas' as product, -4 as profit
union all
select 'Oranges' as product, 15 as profit
union all
select 'Peaches' as product, -7 as profit
union all
select 'Mangos' as product, 2 as profit
```

2. Enable total bar in viz settings
3. Try hovering hover the total bar

### Expected behavior

A tooltip showing the total value should appear when hovering the total bar

### Logs

_No response_

### Information about your Metabase installation

```JSON
Stats commit hash `d2ca545`
```


### Severity

P2 imo, it's important data from the chart that the user has no way of seeing

### Additional context

_No response_",EmmadUsmani,2024-09-25 16:47:15+00:00,['alxnddr'],2024-12-10 00:14:05+00:00,2024-12-06 17:40:15+00:00,https://github.com/metabase/metabase/issues/48118,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2548104348,issue,closed,not_planned,Check table-level query and block permissions,,dpsutton,2024-09-25 14:07:21+00:00,['noahmoss'],2024-12-02 16:03:13+00:00,2024-12-02 16:03:13+00:00,https://github.com/metabase/metabase/issues/48110,[],[],
2547554581,issue,closed,not_planned,DbT Cloud Semantic Layer support,"**Is your feature request related to a problem? Please describe.**
Currently Metabase supports Cube.dev. Whilst this is a great product, another popular Headless BI solution is the DbT Cloud Semantic Layer (former MetricFlow). Not supporting this solution forces a the usage of other tools only to support the Headless BI solution from DbT.

**Describe the solution you'd like**
Integration of the DbT Cloud Semantic Layer.

**Describe alternatives you've considered**
Using other products.

**How important is this feature to you?**
Highly important as this would allow unifying the Data Stack.",Guilherme-B,2024-09-25 10:08:27+00:00,[],2024-10-18 20:03:01+00:00,2024-10-18 20:03:00+00:00,https://github.com/metabase/metabase/issues/48106,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2423151480, 'issue_id': 2547554581, 'author': 'ignacio-mb', 'body': 'Dupe of https://github.com/metabase/metabase/issues/48106', 'created_at': datetime.datetime(2024, 10, 18, 20, 3, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-10-18 20:03:00 UTC): Dupe of https://github.com/metabase/metabase/issues/48106

"
2547368668,issue,closed,completed,[Spike] Investigate if not doing a bundle helps with performances and (customer) bundle size,"We're currently bundling the sdk, and while may need to use webpack for some features (svg, postcss? etc) I think it's worth investigating if going ""many small files"" will help the final customer.

If we publish many small files, the bundler of the host app will probably be smart enough and do some three shaking.


Reference: https://cmdcolin.github.io/posts/2022-05-27-youmaynotneedabundler#why-would-you-not-want-a-bundler-for-your-library

This spike, if successful will un-block:
- better and more accurate e2e tests with component testing
- faster builds
- smaller builds and enabling three shaking on the customer apps",npretto,2024-09-25 08:47:02+00:00,['npretto'],2024-10-14 09:02:21+00:00,2024-10-14 09:02:19+00:00,https://github.com/metabase/metabase/issues/48105,"[('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2394086145, 'issue_id': 2547368668, 'author': 'npretto', 'body': 'I wrote some results of this on notion: https://www.notion.so/metabase/Results-of-spike-about-sdk-un-bundling-and-other-performances-improvement-11569354c901804d8349ea27a2c217a8', 'created_at': datetime.datetime(2024, 10, 4, 16, 39, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410515094, 'issue_id': 2547368668, 'author': 'npretto', 'body': ""Closed as I couldn't make the sdk build without a bundle.\nFollow up work will continue with: [Investigate effect of not bundling node_modules in the sdk, in the build time of the host app](https://github.com/metabase/metabase/issues/48635)"", 'created_at': datetime.datetime(2024, 10, 14, 9, 2, 19, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-10-04 16:39:51 UTC): I wrote some results of this on notion: https://www.notion.so/metabase/Results-of-spike-about-sdk-un-bundling-and-other-performances-improvement-11569354c901804d8349ea27a2c217a8

npretto (Issue Creator) on (2024-10-14 09:02:19 UTC): Closed as I couldn't make the sdk build without a bundle.
Follow up work will continue with: [Investigate effect of not bundling node_modules in the sdk, in the build time of the host app](https://github.com/metabase/metabase/issues/48635)

"
2546836508,issue,open,,Docker build is not working properly for master,"### Docker build is not working

Using windows OS

Cloned repo and pulled the master branch

As per doc, when tried to run the below docker build command,

getting below error,

 DOCKER_BUILDKIT=1 docker build --output container-output/ .
[+] Building 763.4s (16/18)                                                                                            docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                   0.5s
 => => transferring dockerfile: 2.41kB                                                                                                 0.1s
 => [internal] load metadata for docker.io/library/eclipse-temurin:11-jre-alpine                                                       3.6s
 => [internal] load metadata for docker.io/library/node:18-bullseye                                                                    3.4s 
 => [auth] library/node:pull token for registry-1.docker.io                                                                            0.0s
 => [auth] library/eclipse-temurin:pull token for registry-1.docker.io                                                                 0.0s
 => [internal] load .dockerignore                                                                                                      0.6s
 => => transferring context: 298B                                                                                                      0.1s 
 => [internal] load build context                                                                                                      7.1s
 => => transferring context: 4.94MB                                                                                                    6.5s
 => [runner 1/4] FROM docker.io/library/eclipse-temurin:11-jre-alpine@sha256:eeca23b6c113f1817837d3ced7d70405db4664aade6b6f30076160e3  0.0s
 => [builder 1/7] FROM docker.io/library/node:18-bullseye@sha256:df821a38cd058aa8681bdbf8735d3a28688e6336624dbf902e7877d350c7807a      0.0s 
 => CACHED [runner 2/4] RUN apk add -U bash fontconfig curl font-noto font-noto-arabic font-noto-hebrew font-noto-cjk java-cacerts &&  0.0s 
 => CACHED [builder 2/7] WORKDIR /home/node                                                                                            0.0s 
 => CACHED [builder 3/7] RUN apt-get update && apt-get upgrade -y && apt-get install openjdk-11-jdk curl git -y     && curl -O https:  0.0s 
 => [builder 4/7] COPY . .                                                                                                           150.7s 
 => [builder 5/7] RUN git config --global --add safe.directory /home/node                                                              7.0s 
 => [builder 6/7] RUN yarn --frozen-lockfile                                                                                         583.8s 
 => ERROR [builder 7/7] RUN INTERACTIVE=false CI=true MB_EDITION=oss bin/build.sh :version ${VERSION}                                  4.6s 
------
 > [builder 7/7] RUN INTERACTIVE=false CI=true MB_EDITION=oss bin/build.sh :version ${VERSION}:
3.392 ./bin/check-clojure-cli.sh: line 2: $'\r': command not found
------

 4 warnings found (use docker --debug to expand):
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 5)
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 35)
 - FromPlatformFlagConstDisallowed: FROM --platform flag should not use constant value ""linux/amd64"" (line 35)
 - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 37)
Dockerfile:25
--------------------
  23 |     RUN yarn --frozen-lockfile
  24 |
  25 | >>> RUN INTERACTIVE=false CI=true MB_EDITION=$MB_EDITION bin/build.sh :version ${VERSION}
  26 |
  27 |     # ###################
--------------------
ERROR: failed to solve: process ""/bin/sh -c INTERACTIVE=false CI=true MB_EDITION=$MB_EDITION bin/build.sh :version ${VERSION}"" did not complete successfully: exit code: 127




### To Reproduce

Clone git and check out to master
cd metabase
DOCKER_BUILDKIT=1 docker build --output container-output/ .


### Expected behavior

The docker build command should be executed successfully

### Logs

 DOCKER_BUILDKIT=1 docker build --output container-output/ .
[+] Building 763.4s (16/18)                                                                                            docker:desktop-linux
 => [internal] load build definition from Dockerfile                                                                                   0.5s
 => => transferring dockerfile: 2.41kB                                                                                                 0.1s
 => [internal] load metadata for docker.io/library/eclipse-temurin:11-jre-alpine                                                       3.6s
 => [internal] load metadata for docker.io/library/node:18-bullseye                                                                    3.4s 
 => [auth] library/node:pull token for registry-1.docker.io                                                                            0.0s
 => [auth] library/eclipse-temurin:pull token for registry-1.docker.io                                                                 0.0s
 => [internal] load .dockerignore                                                                                                      0.6s
 => => transferring context: 298B                                                                                                      0.1s 
 => [internal] load build context                                                                                                      7.1s
 => => transferring context: 4.94MB                                                                                                    6.5s
 => [runner 1/4] FROM docker.io/library/eclipse-temurin:11-jre-alpine@sha256:eeca23b6c113f1817837d3ced7d70405db4664aade6b6f30076160e3  0.0s
 => [builder 1/7] FROM docker.io/library/node:18-bullseye@sha256:df821a38cd058aa8681bdbf8735d3a28688e6336624dbf902e7877d350c7807a      0.0s 
 => CACHED [runner 2/4] RUN apk add -U bash fontconfig curl font-noto font-noto-arabic font-noto-hebrew font-noto-cjk java-cacerts &&  0.0s 
 => CACHED [builder 2/7] WORKDIR /home/node                                                                                            0.0s 
 => CACHED [builder 3/7] RUN apt-get update && apt-get upgrade -y && apt-get install openjdk-11-jdk curl git -y     && curl -O https:  0.0s 
 => [builder 4/7] COPY . .                                                                                                           150.7s 
 => [builder 5/7] RUN git config --global --add safe.directory /home/node                                                              7.0s 
 => [builder 6/7] RUN yarn --frozen-lockfile                                                                                         583.8s 
 => ERROR [builder 7/7] RUN INTERACTIVE=false CI=true MB_EDITION=oss bin/build.sh :version ${VERSION}                                  4.6s 
------
 > [builder 7/7] RUN INTERACTIVE=false CI=true MB_EDITION=oss bin/build.sh :version ${VERSION}:
3.392 ./bin/check-clojure-cli.sh: line 2: $'\r': command not found
------

 4 warnings found (use docker --debug to expand):
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 5)
 - FromAsCasing: 'as' and 'FROM' keywords' casing do not match (line 35)
 - FromPlatformFlagConstDisallowed: FROM --platform flag should not use constant value ""linux/amd64"" (line 35)
 - LegacyKeyValueFormat: ""ENV key=value"" should be used instead of legacy ""ENV key value"" format (line 37)
Dockerfile:25
--------------------
  23 |     RUN yarn --frozen-lockfile
  24 |
  25 | >>> RUN INTERACTIVE=false CI=true MB_EDITION=$MB_EDITION bin/build.sh :version ${VERSION}
  26 |
  27 |     # ###################
--------------------
ERROR: failed to solve: process ""/bin/sh -c INTERACTIVE=false CI=true MB_EDITION=$MB_EDITION bin/build.sh :version ${VERSION}"" did not complete successfully: exit code: 127

### Information about your Metabase installation

```JSON
Windows OS
Vs Code
docker desktop
```


### Severity

high

### Additional context

_No response_",dhatchan96,2024-09-25 03:52:04+00:00,[],2025-02-04 20:23:40+00:00,,https://github.com/metabase/metabase/issues/48104,"[('Type:Bug', 'Product defects'), ('.Building & Releasing', ''), ('.Team/DevEx', '')]",[],
2546488204,issue,closed,not_planned,Trying to offset on another offset expressions via the GUI removes the Visualization button,"### Describe the bug

If you create a second set of offset custom expressions using the UI option ""Compare to the Past"" the notebook editor breaks and the Visualization button disappears  



### To Reproduce

1.  Create the new question with the orders table
2. Do a count of rows by created at by month 
3. Click the visualize button see that it works great.
4.  Go back to the editor I'm going to add a new summarize option ""Compare to the past"".  Use One week ago both previous value and percentage difference and hit done 
5. Click on visualize.  See that it works
6. Go back to the show editor and then choose ""Compare to the past"" again.  Compare your previously created offset to the Previous month 
7.  You'll notice that the Visualization button is gone and you also can't save the question

https://www.loom.com/share/fb74e39d251e49c79edb0f63177451a1?sid=c36f9346-bc24-4c2a-8ceb-a8ff76932650

### Expected behavior

I'm actually not sure if this is supposed to work.  It lets me do it so, yes?  If that's the case then the question should run.
FWIW, I ran across issue as I was filming a Loom as this might solve a customer problem.

### Logs

core.cljs:4009 [metabase.lib.normalize] ""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages\n  [{:lib/type :mbql.stage/mbql,\n    :aggregation\n    [[:count {:lib/uuid \""def46ba5-7dc9-4c21-980b-a0c65404234a\""}]\n     [:offset\n      {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n       :name \""Count (previous week)\"",\n       :display-name \""Count (previous week)\""}\n      [:count {:lib/uuid \""ce611330-b6c4-4897-9a4e-ae596590b8f0\""}]\n      -1]\n     [:-\n      {:lib/uuid \""b8b9a6da-e4ac-4a87-99ff-86387e851885\"",\n       :name \""Count (% vs previous week)\"",\n       :display-name \""Count (% vs previous week)\""}\n      [:/\n       {:lib/uuid \""2275a725-78c4-4436-8ac7-f440b2abab50\""}\n       [:count {:lib/uuid \""85a9d532-aa09-45ef-991e-ff14fdb80df1\""}]\n       [:offset\n        {:lib/uuid \""ef54afae-0211-4e9f-a016-ec24792a5c8c\""}\n        [:count {:lib/uuid \""92a9f088-460b-415f-9ebd-2b8250edabda\""}]\n        -1]]\n      1]\n     [:offset\n      {:lib/uuid \""201b7803-4505-44a6-83ac-db4d621adbc0\"",\n       :name \""Count (previous week) (7 weeks ago)\"",\n       :display-name \""Count (previous week) (7 weeks ago)\""}\n      [:offset\n       {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n        :name \""Count (previous week)\"",\n        :display-name \""Count (previous week)\""}\n       [:count {:lib/uuid \""046fae3b-158e-42f5-894e-90465c997878\""}]\n       -1]\n      -7]\n     [:-\n      {:lib/uuid \""0801f58c-cfd6-4e62-8848-1a25c138b8a1\"",\n       :name \""Count (previous week) (% vs 7 weeks ago)\"",\n       :display-name \""Count (previous week) (% vs 7 weeks ago)\""}\n      [:/\n       {:lib/uuid \""e6b36b4f-8da3-4a04-8131-ab6bec75697d\""}\n       [:offset\n        {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n         :name \""Count (previous week)\"",\n         :display-name \""Count (previous week)\""}\n        [:count {:lib/uuid \""f1e415fd-ade0-4282-8373-61475c7f4394\""}]\n        -1]\n       [:offset\n        {:lib/uuid \""f6ed0b3a-6843-469f-b6cc-ae1fb14ff719\""}\n        [:offset\n         {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n          :name \""Count (previous week)\"",\n          :display-name \""Count (previous week)\""}\n         [:count {:lib/uuid \""55a06b4f-c462-47ee-b83c-22c262a89e1c\""}]\n         -1]\n        -7]]\n      1]],\n    :breakout\n    [[:field\n      {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :week, :lib/uuid \""1d9da350-f90b-42e7-b459-c4a076d8f68c\""}\n      \""created_at\""]],\n    :filters\n    [[:time-interval\n      {:lib/uuid \""57ed23e1-60ac-47f0-ba95-ee03e9fd884f\""}\n      [:field {:base-type :type/DateTimeWithLocalTZ, :lib/uuid \""bf9a460c-6f6a-404a-856b-f17a7529de09\""} \""created_at\""]\n      -12\n      :month]],\n    :source-card 6759}],\n  :database 26,\n  :lib/metadata #object[b [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages\n   [{:lib/type :mbql.stage/mbql,\n     :aggregation\n     [[:count {:lib/uuid \""def46ba5-7dc9-4c21-980b-a0c65404234a\""}]\n      [:offset\n       {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n        :name \""Count (previous week)\"",\n        :display-name \""Count (previous week)\""}\n       [:count {:lib/uuid \""ce611330-b6c4-4897-9a4e-ae596590b8f0\""}]\n       -1]\n      [:-\n       {:lib/uuid \""b8b9a6da-e4ac-4a87-99ff-86387e851885\"",\n        :name \""Count (% vs previous week)\"",\n        :display-name \""Count (% vs previous week)\""}\n       [:/\n        {:lib/uuid \""2275a725-78c4-4436-8ac7-f440b2abab50\""}\n        [:count {:lib/uuid \""85a9d532-aa09-45ef-991e-ff14fdb80df1\""}]\n        [:offset\n         {:lib/uuid \""ef54afae-0211-4e9f-a016-ec24792a5c8c\""}\n         [:count {:lib/uuid \""92a9f088-460b-415f-9ebd-2b8250edabda\""}]\n         -1]]\n       1]\n      [:offset\n       {:lib/uuid \""201b7803-4505-44a6-83ac-db4d621adbc0\"",\n        :name \""Count (previous week) (7 weeks ago)\"",\n        :display-name \""Count (previous week) (7 weeks ago)\""}\n       [:offset\n        {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n         :name \""Count (previous week)\"",\n         :display-name \""Count (previous week)\""}\n        [:count {:lib/uuid \""046fae3b-158e-42f5-894e-90465c997878\""}]\n        -1]\n       -7]\n      [:-\n       {:lib/uuid \""0801f58c-cfd6-4e62-8848-1a25c138b8a1\"",\n        :name \""Count (previous week) (% vs 7 weeks ago)\"",\n        :display-name \""Count (previous week) (% vs 7 weeks ago)\""}\n       [:/\n        {:lib/uuid \""e6b36b4f-8da3-4a04-8131-ab6bec75697d\""}\n        [:offset\n         {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n          :name \""Count (previous week)\"",\n          :display-name \""Count (previous week)\""}\n         [:count {:lib/uuid \""f1e415fd-ade0-4282-8373-61475c7f4394\""}]\n         -1]\n        [:offset\n         {:lib/uuid \""f6ed0b3a-6843-469f-b6cc-ae1fb14ff719\""}\n         [:offset\n          {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n           :name \""Count (previous week)\"",\n           :display-name \""Count (previous week)\""}\n          [:count {:lib/uuid \""55a06b4f-c462-47ee-b83c-22c262a89e1c\""}]\n          -1]\n         -7]]\n       1]],\n     :breakout\n     [[:field\n       {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :week, :lib/uuid \""1d9da350-f90b-42e7-b459-c4a076d8f68c\""}\n       \""created_at\""]],\n     :filters\n     [[:time-interval\n       {:lib/uuid \""57ed23e1-60ac-47f0-ba95-ee03e9fd884f\""}\n       [:field {:base-type :type/DateTimeWithLocalTZ, :lib/uuid \""bf9a460c-6f6a-404a-856b-f17a7529de09\""} \""created_at\""]\n       -12\n       :month]],\n     :source-card 6759}],\n   :database 26,\n   :lib/metadata #object[b [object Object]]},\n  :errors\n  ({:path [0 1 0],\n    :in [],\n    :schema #object[Object [object Object]],\n    :value\n    {:lib/type :mbql/query,\n     :stages\n     [{:lib/type :mbql.stage/mbql,\n       :aggregation\n       [[:count {:lib/uuid \""def46ba5-7dc9-4c21-980b-a0c65404234a\""}]\n        [:offset\n         {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n          :name \""Count (previous week)\"",\n          :display-name \""Count (previous week)\""}\n         [:count {:lib/uuid \""ce611330-b6c4-4897-9a4e-ae596590b8f0\""}]\n         -1]\n        [:-\n         {:lib/uuid \""b8b9a6da-e4ac-4a87-99ff-86387e851885\"",\n          :name \""Count (% vs previous week)\"",\n          :display-name \""Count (% vs previous week)\""}\n         [:/\n          {:lib/uuid \""2275a725-78c4-4436-8ac7-f440b2abab50\""}\n          [:count {:lib/uuid \""85a9d532-aa09-45ef-991e-ff14fdb80df1\""}]\n          [:offset\n           {:lib/uuid \""ef54afae-0211-4e9f-a016-ec24792a5c8c\""}\n           [:count {:lib/uuid \""92a9f088-460b-415f-9ebd-2b8250edabda\""}]\n           -1]]\n         1]\n        [:offset\n         {:lib/uuid \""201b7803-4505-44a6-83ac-db4d621adbc0\"",\n          :name \""Count (previous week) (7 weeks ago)\"",\n          :display-name \""Count (previous week) (7 weeks ago)\""}\n         [:offset\n          {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n           :name \""Count (previous week)\"",\n           :display-name \""Count (previous week)\""}\n          [:count {:lib/uuid \""046fae3b-158e-42f5-894e-90465c997878\""}]\n          -1]\n         -7]\n        [:-\n         {:lib/uuid \""0801f58c-cfd6-4e62-8848-1a25c138b8a1\"",\n          :name \""Count (previous week) (% vs 7 weeks ago)\"",\n          :display-name \""Count (previous week) (% vs 7 weeks ago)\""}\n         [:/\n          {:lib/uuid \""e6b36b4f-8da3-4a04-8131-ab6bec75697d\""}\n          [:offset\n           {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n            :name \""Count (previous week)\"",\n            :display-name \""Count (previous week)\""}\n           [:count {:lib/uuid \""f1e415fd-ade0-4282-8373-61475c7f4394\""}]\n           -1]\n          [:offset\n           {:lib/uuid \""f6ed0b3a-6843-469f-b6cc-ae1fb14ff719\""}\n           [:offset\n            {:lib/uuid \""7fc73112-b0cc-4a68-91d4-8e51357ded25\"",\n             :name \""Count (previous week)\"",\n             :display-name \""Count (previous week)\""}\n            [:count {:lib/uuid \""55a06b4f-c462-47ee-b83c-22c262a89e1c\""}]\n            -1]\n           -7]]\n         1]],\n       :breakout\n       [[:field\n         {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :week, :lib/uuid \""1d9da350-f90b-42e7-b459-c4a076d8f68c\""}\n         \""created_at\""]],\n       :filters\n       [[:time-interval\n         {:lib/uuid \""57ed23e1-60ac-47f0-ba95-ee03e9fd884f\""}\n         [:field {:base-type :type/DateTimeWithLocalTZ, :lib/uuid \""bf9a460c-6f6a-404a-856b-f17a7529de09\""} \""created_at\""]\n         -12 \n         :month]], \n       :source-card 6759}], \n     :database 26, \n     :lib/metadata #object[b [object Object]]}})}}\n""

### Information about your Metabase installation

```JSON
- seen on stats, master Built on 2024-09-24   Hash: 957f616
```


### Severity

Breaking issue on a new feature - so would be a blocking issue for me for 51 RC

### Additional context

_No response_",cbalusek,2024-09-24 22:09:45+00:00,[],2025-01-16 21:05:59+00:00,2025-01-16 21:05:58+00:00,https://github.com/metabase/metabase/issues/48103,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2383350738, 'issue_id': 2546488204, 'author': 'brunobergher', 'body': ""Yeah, even if this was technically possible (in my tests, it doesn't seem like it is in PG, for example), it's a bit of a contrived scenario –\xa0the user should compare it to the original column and change the offset value.\r\n\r\nSo I'd say that the bug is indeed in allowing users to even do that."", 'created_at': datetime.datetime(2024, 9, 30, 14, 20, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384005096, 'issue_id': 2546488204, 'author': 'bshepherdson', 'body': ""https://github.com/metabase/metabase/pull/48134 removes the `Compare to the past` UI, which makes this problem with nested `offset` expressions much harder to hit.\r\n\r\nYou can still create nested `offset` expressions and hit this error, but I'm dropping this from the 51 blockers list. It's only a blocker for bringing back the `Compare to the past` UI in 52."", 'created_at': datetime.datetime(2024, 9, 30, 19, 36, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596887532, 'issue_id': 2546488204, 'author': 'ranquild', 'body': 'Compare to the past was removed', 'created_at': datetime.datetime(2025, 1, 16, 21, 5, 58, tzinfo=datetime.timezone.utc)}]","brunobergher on (2024-09-30 14:20:51 UTC): Yeah, even if this was technically possible (in my tests, it doesn't seem like it is in PG, for example), it's a bit of a contrived scenario – the user should compare it to the original column and change the offset value.

So I'd say that the bug is indeed in allowing users to even do that.

bshepherdson on (2024-09-30 19:36:43 UTC): https://github.com/metabase/metabase/pull/48134 removes the `Compare to the past` UI, which makes this problem with nested `offset` expressions much harder to hit.

You can still create nested `offset` expressions and hit this error, but I'm dropping this from the 51 blockers list. It's only a blocker for bringing back the `Compare to the past` UI in 52.

ranquild on (2025-01-16 21:05:58 UTC): Compare to the past was removed

"
2546350562,issue,closed,completed,Upsell Sidesheet Tab,"https://www.figma.com/design/NOCVfjRaqkVhNqNq8jL9mX/Rework-the-info-sidebar-and-entity-actions?node-id=5863-45970&t=pMZhODVgqihEKSrC-4

Show only for OSS admins. be sure to follow guidelines in the upsells readme file.

![Screen Shot 2024-09-24 at 2 40 05 PM](https://github.com/user-attachments/assets/392a7cac-8207-494b-a115-0db5724b59d6)
",iethree,2024-09-24 20:35:22+00:00,['rafpaf'],2024-11-26 18:52:37+00:00,2024-10-16 00:09:28+00:00,https://github.com/metabase/metabase/issues/48100,[],[],
2546350102,issue,closed,completed,Collection Info Sidesheet,"design:

I think only description and entity id are possible currently

![Screen Shot 2024-09-24 at 2 32 56 PM](https://github.com/user-attachments/assets/57789f8c-63e2-4d4e-8c97-76e56d59a994)
",iethree,2024-09-24 20:35:03+00:00,['rafpaf'],2024-10-15 10:57:53+00:00,2024-10-15 10:57:53+00:00,https://github.com/metabase/metabase/issues/48099,[],[],
2546114278,issue,closed,completed,Faster sync on BigQuery,"Apply the same optimizations we did for Redshfit on BigQuery
https://github.com/metabase/metabase/issues/39986

[Comparison dashboard](https://stats.metabase.com/dashboard/969-task-performance-all-databases-cloud?database_age_%28in_months%29_greater_than_or_equal_to=1&database_creation_date=&databases=bigquery-cloud-sdk&databases=redshift&date_filter=past12months~)

",snoe,2024-09-24 18:47:03+00:00,['snoe'],2024-10-08 16:14:28+00:00,2024-09-24 18:47:37+00:00,https://github.com/metabase/metabase/issues/48094,[],[],
2546073292,issue,closed,completed,make it easy to remove the query validator,"We don't know if the query validator will be able to ship due to analysis quality. We should make this easy to remove from the release.

https://www.notion.so/metabase/Query-validator-a8981d498f324da5acf9284e7d7ba2f6",npfitz,2024-09-24 18:26:06+00:00,[],2024-10-08 16:14:22+00:00,2024-09-25 18:46:57+00:00,https://github.com/metabase/metabase/issues/48092,[],[],
2545696311,issue,closed,completed,Reset filter when editing default value,,romeovs,2024-09-24 15:14:14+00:00,[],2024-09-27 15:25:31+00:00,2024-09-27 14:51:19+00:00,https://github.com/metabase/metabase/issues/48084,[],[],
2545691715,issue,closed,not_planned,Permissions admin panel changes,"```[tasklist]
### Tasks
- [x] Allow `Query builder and native` to be an option at the schema-level
- [x] Allow `Query builder and native` to be an option at the tabel-level
- [x] Update permissions help copy to reflect changes
- [x] Prevent various changes like sandboxing / blocking tables dropping native permissions from all tables/schemas in db
- [x] Remove warning UI that tells users w/ a blocked table that native permissions are not available for entire db
- [x] Fix existing E2E tests
- [x] Add test coverage
- [ ] update the permissions editor to only allow ""Query builder and native"" for supported databases
```
",dpsutton,2024-09-24 15:12:56+00:00,['sloansparger'],2024-12-02 16:03:33+00:00,2024-12-02 16:03:33+00:00,https://github.com/metabase/metabase/issues/48083,[],[],
2545626551,issue,closed,not_planned,[Epic] Table-level permissions for native queries,"**Links**
- [product doc](https://github.com/metabase/metabase/issues/new?assignees=&labels=.Epic&projects=&template=epic.md&title=%5BEpic%5D+Title)
- [tech doc](https://www.notion.so/metabase/Tech-Doc-Table-level-block-for-native-queries-08e279f3eaca4fcdb2276f1f490483a2)
- [fe tech doc](https://www.notion.so/metabase/Mini-tech-doc-Allow-table-level-blocking-on-the-FE-10a69354c90180d1b147e0a4ded2d343)
- [Slack thread](https://metaboat.slack.com/archives/C06V3JMECH2/p1727117590072569) for more context
- [Meeting notes](https://www.notion.so/metabase/Focus-room-native-query-table-level-permissions-10c69354c901808ab67dd9d25c8b3221) for even more context

```[tasklist]
### Front-end
- [ ] Check native queries via backend permission system
- [ ] https://github.com/metabase/metabase/issues/48083
```

```[tasklist]
### Back-end
- [ ] https://github.com/metabase/metabase/issues/48110
- [x] Block queries on un-synced tables/views when any table-level blocks are set
- [x] Check perms when saving a native question
- [x] Ensure that table-level native perms get cleared on downgrade
- [ ] Block setting table-level native query perms on unsupported DBs
- [ ] https://github.com/metabase/macaw/pull/105
- [ ] https://github.com/metabase/metabase/pull/48990
- [ ] https://github.com/metabase/metabase/pull/49078
- [ ] https://github.com/metabase/macaw/pull/107
```
",piranha,2024-09-24 14:47:05+00:00,['noahmoss'],2024-12-02 16:02:50+00:00,2024-12-02 16:02:49+00:00,https://github.com/metabase/metabase/issues/48080,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]",[],
2545501273,issue,closed,completed,shared public link,"### Describe the bug

we changed the Site URL and are using `/metabase` at the end of URL, but the shared public links are not included this `/metabase` in the URL, therefore it leads to 404 Not found
we are using latest version of metabase.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

creating a shared public link must have Site URL

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version: v0.50.26
```


### Severity

blocking

### Additional context

_No response_",elyasADK,2024-09-24 13:59:37+00:00,[],2024-10-15 13:05:06+00:00,2024-10-15 13:05:06+00:00,https://github.com/metabase/metabase/issues/48076,"[('Type:Bug', 'Product defects'), ('Embedding/Public', 'Simple public iframe embeds'), ('.Team/Embedding', '')]",[],
2545403698,issue,closed,completed,Reset filters when opening dashboard from click action,"When opening the dashboard with click behaviour from another dashboard, first reset all the filter values and then apply what was set by click behavior.",romeovs,2024-09-24 13:22:24+00:00,['romeovs'],2024-09-25 16:51:29+00:00,2024-09-24 16:24:01+00:00,https://github.com/metabase/metabase/issues/48074,"[('Type:New Feature', ''), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2545403091,issue,closed,completed,[Epic] Reset filters follow-ups,"**Links**
- [product doc](https://www.notion.so/metabase/Reset-filters-follow-ups-9689258246954269b7170e092d81ac2e)
- [tech doc](https://www.notion.so/metabase/Tech-Doc-Reset-filters-follow-ups-10b69354c901803ea737fccf796ea09f)
- [testing plan](https://www.notion.so/metabase/Testing-Plan-Reset-filters-follow-ups-10b69354c90180a38931f337159f8912)


**Implementation Plan**


```[tasklist]
### Milestone 1
- [ ] https://github.com/metabase/metabase/issues/48074
- [ ] https://github.com/metabase/metabase/issues/48084
```
",romeovs,2024-09-24 13:22:12+00:00,['romeovs'],2024-09-27 20:20:21+00:00,2024-09-27 20:20:20+00:00,https://github.com/metabase/metabase/issues/48073,"[('.Epic', 'Feature Implementation or Project')]",[],
2544881216,issue,closed,completed,"Select All selects all values, not only filtered","### Describe the bug

When I filter the list by text and click Select All it selects all the values, not filtered values

### To Reproduce

https://www.loom.com/share/a074ee0e877e479abca8b0e414d346e6


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
7f45d2d
```


### Severity

Incorrect

### Additional context

_No response_",mngr,2024-09-24 09:36:57+00:00,['ranquild'],2024-09-24 20:43:47+00:00,2024-09-24 20:43:47+00:00,https://github.com/metabase/metabase/issues/48070,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2544762915,issue,closed,not_planned,ERROR: unsupported startup parameter: options in Postgres additional JDBC connection,"### Describe the bug

I'm setting the Postgres connection to the backend database and trying to specify the Additional JDBC connection string options. If I put the value from the example: https://www.metabase.com/docs/latest/databases/connections/postgresql#additional-jdbc-connection-string-options

I'm getting ERROR: unsupported startup parameter: options

### To Reproduce

1. Go to 'Database Setting'
2. Input the example: options=-c%20key=value in Additional JDBC connection string options
3. Press save
4. See error - ERROR: unsupported startup parameter: options


### Expected behavior

Metabase should allow to specify options to Postgres connections.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.100+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""starburst""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-31"",
      ""tag"": ""v0.49.22"",
      ""hash"": ""04c8190""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking the setting of statement_timeout, affecting the performance of backend DBs

### Additional context

_No response_",RomantsovArtur,2024-09-24 08:47:33+00:00,[],2024-09-24 09:49:52+00:00,2024-09-24 09:49:52+00:00,https://github.com/metabase/metabase/issues/48068,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2370744334, 'issue_id': 2544762915, 'author': 'piranha', 'body': ""Are you using pgbouncer by any chance? Quick googling suggests this could be a problem (I'm unable to reproduce this locally)."", 'created_at': datetime.datetime(2024, 9, 24, 9, 24, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2370779203, 'issue_id': 2544762915, 'author': 'RomantsovArtur', 'body': ""Yes, we're connected to the DBs via PGbouncer. You mean the error comes from it and not from the MB side?"", 'created_at': datetime.datetime(2024, 9, 24, 9, 38, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2370802613, 'issue_id': 2544762915, 'author': 'piranha', 'body': 'Oh, it for sure is not coming from Metabase. :)', 'created_at': datetime.datetime(2024, 9, 24, 9, 49, 18, tzinfo=datetime.timezone.utc)}]","piranha on (2024-09-24 09:24:18 UTC): Are you using pgbouncer by any chance? Quick googling suggests this could be a problem (I'm unable to reproduce this locally).

RomantsovArtur (Issue Creator) on (2024-09-24 09:38:10 UTC): Yes, we're connected to the DBs via PGbouncer. You mean the error comes from it and not from the MB side?

piranha on (2024-09-24 09:49:18 UTC): Oh, it for sure is not coming from Metabase. :)

"
2543935725,issue,open,,Remember Scrollbar position When Navigating back to Previous Dashboard,"**Is your feature request related to a problem? Please describe.**
It is very frustrating that when you click into a question on a dashboard to edit it and then click back out of it, the dashboard reloads back at the top of the dashboard. Ideally it should reload at the location of the question you clicked into.

**Describe the solution you'd like**
I'd like the back button to know the scrollbar position and drop us there when we go back.
**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
 For embedding users working with even less screen real estate this would be especially nice.
",ixipixi,2024-09-23 23:27:45+00:00,[],2025-02-04 20:30:42+00:00,,https://github.com/metabase/metabase/issues/48066,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2543255662,issue,closed,completed,Canceling out of new metric creation crashes,"### Describe the bug

If you cancel out of the new metric creation flow, the UI crashes completely. Reproducible on stats 100% of the time.

### To Reproduce

1. Go to new
2. Click on metric
3. exit out of the query picker
4. click cancel at the top of the screen
5. main ui element crashes

![newmetriccrash](https://github.com/user-attachments/assets/848a2915-99f4-46bf-abb6-4d12cad41f62)

console: 

```
TypeError: Cannot read properties of undefined (reading 'card')
    at createRawSeries (index.ts:162:1)

navigation.js:155 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'query')
```


### Expected behavior

should not crash

### Logs

_No response_

### Information about your Metabase installation

```JSON
master - `ac1a651dd5`
```


### Severity

P1 - core user flow crash

### Additional context

_No response_",iethree,2024-09-23 17:36:24+00:00,[],2024-09-23 17:43:08+00:00,2024-09-23 17:41:29+00:00,https://github.com/metabase/metabase/issues/48059,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Metrics', 'v2')]","[{'comment_id': 2368947463, 'issue_id': 2543255662, 'author': 'iethree', 'body': 'duplicate: https://github.com/metabase/metabase/issues/48024', 'created_at': datetime.datetime(2024, 9, 23, 17, 41, 42, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-09-23 17:41:42 UTC): duplicate: https://github.com/metabase/metabase/issues/48024

"
2542879415,issue,closed,completed,"Error when using Group by ""hour of day"" on an attribute from a join and a custom column","### Describe the bug

When trying to group by ""hour of day"" on an attribute that comes from a join and a custom column, I encounter the following error:

```
ERROR: function pg_catalog.extract(unknown, integer) does not exist
Hint: No function matches the given name and argument types. You might need to add explicit type casts.
Position: 129
```

### To Reproduce

1. Create a query that involves joining tables.
2. Group by ""hour of day"" on an attribute from the joined table.
3. The above error is triggered.

### Expected behavior

I expect Metabase to correctly group by ""hour of day"" without throwing an error.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.12-clevercloud-vm-dirty"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```


### Severity

This issue is annoying but not blocking our usage of Metabase entirely

### Additional context

 Screenshots of the query editor and the generated SQL will be provided.

![Capture d’écran 2024-09-23 à 16 37 38](https://github.com/user-attachments/assets/c1abf849-f481-4239-bd7e-9a2bcd13a365)


```sql
SELECT
  CAST(
    extract(
      hour
      from
        ""source"".""Message Delivery__opened_at_2""
    ) AS integer
  ) AS ""Message Delivery__opened_at"",
  ""source"".""status message"" AS ""status message"",
  COUNT(*) AS ""count""
FROM
  (
    SELECT
      ""public"".""message"".""id"" AS ""id"",
      ""public"".""message"".""name"" AS ""name"",
      CASE
        WHEN ""Message Delivery"".""clicked_at"" IS NOT NULL THEN 'clicked'
        WHEN ""Message Delivery"".""opened_at"" IS NOT NULL THEN 'open'
        WHEN ""Message Delivery"".""delivered_at"" IS NOT NULL THEN 'delivery'
        ELSE 'other'
      END AS ""status message"",
      ""Message Delivery"".""id"" AS ""Message Delivery__id"",
      ""Message Delivery"".""created_at"" AS ""Message Delivery__created_at"",
      ""Message Delivery"".""updated_at"" AS ""Message Delivery__updated_at"",
      ""Message Delivery"".""recipient_id"" AS ""Message Delivery__recipient_id"",
      ""Message Delivery"".""message_id"" AS ""Message Delivery__message_id"",
      ""Message Delivery"".""sent_at"" AS ""Message Delivery__sent_at"",
      ""Message Delivery"".""delivered_at"" AS ""Message Delivery__delivered_at"",
      ""Message Delivery"".""opened_at"" AS ""Message Delivery__opened_at"",
      ""Message Delivery"".""clicked_at"" AS ""Message Delivery__clicked_at"",
      ""Message Delivery"".""failed_at"" AS ""Message Delivery__failed_at"",
      ""Message Delivery"".""error_type"" AS ""Message Delivery__error_type"",
      ""Message Delivery"".""error_msg"" AS ""Message Delivery__error_msg"",
      ""Message Delivery"".""recipient_type"" AS ""Message Delivery__recipient_type"",
      ""Message Delivery"".""email"" AS ""Message Delivery__email"",
      ""Message Delivery"".""mail_code"" AS ""Message Delivery__mail_code"",
      CAST(
        extract(
          hour
          from
            ""Message Delivery"".""opened_at""
        ) AS integer
      ) AS ""Message Delivery__opened_at_2""
    FROM
      ""public"".""message""
     
LEFT JOIN ""public"".""message_delivery"" AS ""Message Delivery"" ON ""public"".""message"".""id"" = ""Message Delivery"".""message_id""
   
WHERE
      ""public"".""message"".""name"" = 'mission-mail-campaign:fdfoct2024'
  ) AS ""source""
GROUP BY
  CAST(
    extract(
      hour
      from
        ""source"".""Message Delivery__opened_at_2""
    ) AS integer
  ),
  ""source"".""status message""
ORDER BY
  CAST(
    extract(
      hour
      from
        ""source"".""Message Delivery__opened_at_2""
    ) AS integer
  ) ASC,
  ""source"".""status message"" ASC
  ```",maximepvrt,2024-09-23 14:40:46+00:00,[],2024-12-10 02:38:59+00:00,2024-12-09 18:15:10+00:00,https://github.com/metabase/metabase/issues/48058,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2371128098, 'issue_id': 2542879415, 'author': 'npfitz', 'body': 'Issue can be replicated with the sample dataset using the setup below. Interestingly, Grouping by hour of day on a column in the initial table works okay, but error happens when doing the group on the joined table.\r\n\r\n![image](https://github.com/user-attachments/assets/117d7b63-9b52-4c60-b93d-72c1b0821d5a)', 'created_at': datetime.datetime(2024, 9, 24, 12, 25, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507861061, 'issue_id': 2542879415, 'author': 'bshepherdson', 'body': 'The issue is that the inner query is already doing the extraction, but the `:temporal-unit` option was not removed. Then the outer query tries to extract it again, which will fail because the column (`People - User__created_at`) is now a number, not a datetime.\n\nI think this might have been fixed in the meantime, so start by trying to repro on current master.', 'created_at': datetime.datetime(2024, 11, 29, 13, 50, 36, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-09-24 12:25:52 UTC): Issue can be replicated with the sample dataset using the setup below. Interestingly, Grouping by hour of day on a column in the initial table works okay, but error happens when doing the group on the joined table.

![image](https://github.com/user-attachments/assets/117d7b63-9b52-4c60-b93d-72c1b0821d5a)

bshepherdson on (2024-11-29 13:50:36 UTC): The issue is that the inner query is already doing the extraction, but the `:temporal-unit` option was not removed. Then the outer query tries to extract it again, which will fail because the column (`People - User__created_at`) is now a number, not a datetime.

I think this might have been fixed in the meantime, so start by trying to repro on current master.

"
2542764868,issue,closed,not_planned,"feature: Multi-Language Support for Dashboards, Questions, Collections, and Columns","### Feature Request: Multi-Language Support for Questions, Collections, and Columns

**Is your feature request related to a problem? Please describe.**
As a Data Analyst in a multinational organization, I need help with language barriers when building and sharing dashboards across different teams. In our company, some teams prefer to use Portuguese, while others (especially executives or international teams) only understand English. This creates communication challenges and increases our workload, as we currently have to create multiple versions of the same dashboard to accommodate both language preferences. This process is cumbersome and doubles our efforts, reducing efficiency and increasing the risk of inconsistencies or translation errors.

**Describe the solution you'd like**
It would be incredibly helpful if Metabase allowed us to provide translations for key elements such as Questions, Collections, and Columns within a Table, and allow users to choose their preferred language. This way, users would see all content translated without having to create multiple versions of the same dashboards. The system could use the translations defined by administrators, automatically switching between languages as per the user's preferences.

**Describe alternatives you've considered**
1. **Create Separate Dashboards**: Currently, the only solution is to duplicate dashboards and translate the content to the required languages. However, this is inefficient, time-consuming, and error-prone as making changes to one version requires duplicating the same adjustments across all languages.
2. **Manual Translation Labels**: Another workaround is to manually include both languages (e.g., English and Portuguese) directly in the naming conventions of questions, collections, and columns. However, this requires careful formatting and is limited by space, cluttering the visual layout of dashboards.

**How important is this feature to you?**
This feature is **essential** for us as a multinational company. We need to ensure that all our global teams and executives can understand and analyze the same dashboards with clarity. Without this, we risk losing valuable insights and efficiency in our reporting processes.

**Additional context**
Ideally, the translation system would allow:
- Administrators will configure translations for question titles, collection names, table column headers, etc.
- Users to select their default language in Metabase settings.
- Automatic fallback to a default language (e.g., English) if a translation is unavailable.
  
This flexibility would greatly enhance the user experience for our diverse workforce and help bridge the language gap in data reporting across our teams.",viniciusdsmello,2024-09-23 14:04:09+00:00,[],2024-12-02 18:01:35+00:00,2024-12-02 18:01:34+00:00,https://github.com/metabase/metabase/issues/48056,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2512227219, 'issue_id': 2542764868, 'author': 'ignacio-mb', 'body': 'Is this a dupe of https://github.com/metabase/metabase/issues/9508?', 'created_at': datetime.datetime(2024, 12, 2, 17, 26, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512304387, 'issue_id': 2542764868, 'author': 'paoliniluis', 'body': 'yes it is', 'created_at': datetime.datetime(2024, 12, 2, 18, 1, 34, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-12-02 17:26:39 UTC): Is this a dupe of https://github.com/metabase/metabase/issues/9508?

paoliniluis on (2024-12-02 18:01:34 UTC): yes it is

"
2542652880,issue,open,,Option to disable saving the last used dashboard parameter values,"**Is your feature request related to a problem? Please describe.**
The automatic saving and application of the last used filters on a dashboard may cause additional costs for users where their workflow requires using new values each time. With the persistence of filter values, the filters from the previous session are being applied automatically when dashboard is opened which leads to unnecessary queries being run.

**Describe the solution you'd like**
Develop an option to disable the automatic saving of filters. With that setting on, a dashboard should open with no filters applied unless default filters are explicitly set by the user.

It might be worth considering supporting this setting both globally and at more specific levels, such as for individual dashboards or even specific filters.

**Describe alternatives you've considered**
There don't seem to be good alternatives since the queries will still run even if a filter is marked as mandatory without a default value.

**How important is this feature to you?**
This is important because the automatic persistence may lead to extra costs on databases that charge per query.
",zbodi74,2024-09-23 13:27:52+00:00,[],2025-02-04 20:29:40+00:00,,https://github.com/metabase/metabase/issues/48055,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2608486206, 'issue_id': 2542652880, 'author': 'ixipixi', 'body': ""Another use case that has come up that's adjacent. Some people choose default values for the dashboard on purpose. Caching the users previous selection means when they revisit the dashboard, the dashboard default isn't applied. The user's last selection is applied instead."", 'created_at': datetime.datetime(2025, 1, 22, 23, 37, 26, tzinfo=datetime.timezone.utc)}]","ixipixi on (2025-01-22 23:37:26 UTC): Another use case that has come up that's adjacent. Some people choose default values for the dashboard on purpose. Caching the users previous selection means when they revisit the dashboard, the dashboard default isn't applied. The user's last selection is applied instead.

"
2540609005,issue,closed,not_planned,subscribe send email unrecognized code,"### Describe the bug

![image](https://github.com/user-attachments/assets/32ffb818-21bb-4069-88fa-ca150d1e53ee)


### To Reproduce

email subscribe send image 中文 乱码


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.9+8-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""17.0.9"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.9+8-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""15.0"",
    ""user.language"": ""zh"",
    ""user.timezone"": ""Asia/Shanghai""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-05-29"",
      ""tag"": ""v0.48.0-SNAPSHOT"",
      ""branch"": ""master"",
      ""hash"": ""64e3895""
    },
    ""settings"": {
      ""report-timezone"": ""Hongkong""
    }
  }
}
```


### Severity

p0

### Additional context

_No response_",wangfpp,2024-09-22 02:50:05+00:00,[],2024-09-24 00:57:08+00:00,2024-09-22 07:49:18+00:00,https://github.com/metabase/metabase/issues/48050,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2365430210, 'issue_id': 2540609005, 'author': 'wangfpp', 'body': '{\r\n  ""browser-info"": {\r\n    ""language"": ""zh-CN"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.23+9"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.23"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.23+9"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""5.10.84-10.2.al8.x86_64"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""Etc/UTC""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""h2"",\r\n      ""mysql"",\r\n      ""mongo""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""mysql"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""MySQL"",\r\n        ""version"": ""5.7.37-log""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""MariaDB Connector/J"",\r\n        ""version"": ""2.7.6""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""version"": {\r\n      ""date"": ""2024-05-29"",\r\n      ""tag"": ""v0.48.0-SNAPSHOT"",\r\n      ""branch"": ""master"",\r\n      ""hash"": ""64e3895""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": null\r\n    }\r\n  }\r\n}', 'created_at': datetime.datetime(2024, 9, 22, 2, 51, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2365844349, 'issue_id': 2540609005, 'author': 'paoliniluis', 'body': 'Upgrade your Metabase and install the fonts you need', 'created_at': datetime.datetime(2024, 9, 22, 7, 49, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2369886445, 'issue_id': 2540609005, 'author': 'wangfpp', 'body': '@paoliniluis I copied the font file in Docker, but the png sent in the email is still garbled\r\n`COPY ./fonts/PingFang.tff /usr/share/fonts/`\r\nneed help...', 'created_at': datetime.datetime(2024, 9, 24, 0, 56, 40, tzinfo=datetime.timezone.utc)}]","wangfpp (Issue Creator) on (2024-09-22 02:51:27 UTC): {
  ""browser-info"": {
    ""language"": ""zh-CN"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.84-10.2.al8.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""5.7.37-log""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.6""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-29"",
      ""tag"": ""v0.48.0-SNAPSHOT"",
      ""branch"": ""master"",
      ""hash"": ""64e3895""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

paoliniluis on (2024-09-22 07:49:18 UTC): Upgrade your Metabase and install the fonts you need

wangfpp (Issue Creator) on (2024-09-24 00:56:40 UTC): @paoliniluis I copied the font file in Docker, but the png sent in the email is still garbled
`COPY ./fonts/PingFang.tff /usr/share/fonts/`
need help...

"
2539757996,issue,closed,completed,Add Diagnostic Info as command palette action,"Can we add ""Download diagnostic information"" as an action in the command palette?

[Slack Message](https://metaboat.slack.com/archives/C064EB1UE5P/p1726857126043729)",iethree,2024-09-20 22:11:38+00:00,['npfitz'],2024-10-11 14:24:31+00:00,2024-10-10 20:43:37+00:00,https://github.com/metabase/metabase/issues/48049,"[('Administration/Troubleshooting', ''), ('Administration/Settings', '')]",[],
2539718614,issue,closed,not_planned,Models not showing values on search box,"### Describe the bug

I`ve create a model and use CASE to change some values:
  CASE
    WHEN auth_ongoing = 0 THEN 'no'
    WHEN auth_ongoing = 1 THEN 'yes'
  END AS auth_status
  But, when I put the filter in query builder, the options 'no' and 'yes' do not appear.
  
  
![image](https://github.com/user-attachments/assets/3d410b41-f437-4e0e-b751-e6cd9f6f7fa7)
![image](https://github.com/user-attachments/assets/5e9b283e-c61d-4e37-87a4-4727f956a87a)

The option for custom mapping for this field not appear. That`s only 2 options to mapping.
![image](https://github.com/user-attachments/assets/82e37316-cd74-4f05-bdee-34fdb12b4c36)

### To Reproduce

1. Go to 'New'
2. Click on 'Model'
3. Create a SQL question
4. Use case to change values
5. Save the Model
6. Create a Question
7. Try to filter the changed field
8. Noting appears to select, requesting to put a text


### Expected behavior

Show the value from the field to selection.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v1.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.90+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

P1

### Additional context

_No response_",fer-batista,2024-09-20 21:37:57+00:00,[],2024-09-24 13:40:22+00:00,2024-09-24 13:40:22+00:00,https://github.com/metabase/metabase/issues/48048,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2371309668, 'issue_id': 2539718614, 'author': 'luizarakaki', 'body': ""Unfortunately, this isn't how this works.\r\n\r\nIf you create a custom column (in native SQL or visual editor custom column) and want to show a dropdown with a list of values, you need to create a custom list of values at the dashboard level:\r\nhttps://www.metabase.com/docs/latest/dashboards/filters#change-a-filters-selectable-values\r\n\r\nCreate the question as you want. Add the question to a dashboard, create a dashboard filter and configure which values are available in the dropdown."", 'created_at': datetime.datetime(2024, 9, 24, 13, 40, 22, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-09-24 13:40:22 UTC): Unfortunately, this isn't how this works.

If you create a custom column (in native SQL or visual editor custom column) and want to show a dropdown with a list of values, you need to create a custom list of values at the dashboard level:
https://www.metabase.com/docs/latest/dashboards/filters#change-a-filters-selectable-values

Create the question as you want. Add the question to a dashboard, create a dashboard filter and configure which values are available in the dropdown.

"
2539298011,issue,open,,Metabase expert mode,"**Is your feature request related to a problem? Please describe.**
I would love that Metabase has an expert mode in which we can toggle query processor features: e.g.
- remove limits https://github.com/metabase/metabase/issues/27855
- define the get-filter-values limit https://github.com/metabase/metabase/issues/35631
- add/remove order bys in sync/scan/get filter values/fingerprint: https://github.com/metabase/metabase/issues/31166
- add/remove order bys in queries: https://github.com/metabase/metabase/issues/28962
- disable syncs and processes https://github.com/metabase/metabase/issues/10398

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**How important is this feature to you?**

**Additional context**
Add any other context or screenshots about the feature request here.
",paoliniluis,2024-09-20 17:28:05+00:00,[],2025-02-04 20:30:55+00:00,,https://github.com/metabase/metabase/issues/48047,"[('Type:New Feature', ''), ('Operation/', ''), ('Administration/', '')]",[],
2539267990,issue,closed,completed,Not renamed fields in a same table join inherit the renamed name in exports,"### Describe the bug

It is very common to do the same table join. And if you export, names of the columns aren't not how they are supposed to be called, and the users might get confused. 

### To Reproduce

1. Create a GUI question Orders and join it to Orders. Same ID in the join.
2. Rename ID from the first table in the join to ""Test ID""
3. Save and export to CSV
4. See that the column that should be named Orders ID is now called Test ID

Viz setting:
<img width=""265"" alt=""Screenshot 2024-09-20 at 12 05 21 PM"" src=""https://github.com/user-attachments/assets/92d29599-9c17-4f04-8b6c-ea2915400194"">

CSV export:
<img width=""721"" alt=""Screenshot 2024-09-20 at 12 06 01 PM"" src=""https://github.com/user-attachments/assets/2ee03a99-8fd9-43a9-8792-5e23da6cae28"">


### Expected behavior

Not-renamed column should be named as it's originally set up to in the viz setting

### Logs

_No response_

### Information about your Metabase installation

```JSON
-50.x
```


### Severity

P1

### Additional context

_No response_",ignacio-mb,2024-09-20 17:09:00+00:00,['appleby'],2024-10-02 15:49:02+00:00,2024-10-02 15:49:01+00:00,https://github.com/metabase/metabase/issues/48046,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Visualization/Chart Settings', ''), ('Reporting/Export', ''), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 2370748915, 'issue_id': 2539267990, 'author': 'mngr', 'body': ""https://metaboat.slack.com/archives/C052ZBWRG3W/p1726852641223079\r\nDoesn't reproduce in master, but needs to be backported to 50 and 49?"", 'created_at': datetime.datetime(2024, 9, 24, 9, 25, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388970408, 'issue_id': 2539267990, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 2, 15, 26, 40, tzinfo=datetime.timezone.utc)}]","mngr on (2024-09-24 09:25:48 UTC): https://metaboat.slack.com/archives/C052ZBWRG3W/p1726852641223079
Doesn't reproduce in master, but needs to be backported to 50 and 49?

github-actions[bot] on (2024-10-02 15:26:40 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2538695115,issue,open,,Synchronize the hover state of multiple cartesian charts in the same dashboard,"**Is your feature request related to a problem? Please describe.**
My work requires me to display multiple series in the same chart very much like this, so much so that its a difficult to read exact values at particular instances for any given value on X axis.

**Describe the solution you'd like**
A slider along the X-axis which we can use and (ideally move a vertical line to) values of different series off of tooltips or someething similar.
![image](https://github.com/user-attachments/assets/f2235c9a-5b51-4bff-9480-93406c1da6ff)
 

**Describe alternatives you've considered**
I havent been able to think of alternatives and same are very much welcome.

Add any other context or screenshots about the feature request here.
",ceyxasm,2024-09-20 12:28:40+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/48041,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('Visualization/Tooltips', '')]",[],
2538650990,issue,open,,Support linked filters for lists generated from Questions/Model,"**Is your feature request related to a problem? Please describe.**

This will solve 2 main problems. That when you read a list form an external question (or table) and specify it as a custom list at filter level you will not be able to use linked filters

![image](https://github.com/user-attachments/assets/d0ce946a-a461-4371-adf4-b15981600155)

![image](https://github.com/user-attachments/assets/43a64468-43aa-4e2e-a309-224af55879ac)

The other problem is for people that want to use arrays. Some time ago we implemented [this] (https://github.com/metabase/metabase/issues/38778), mainly to give an option to users to use arrays by allowing multiple values in contains filters. Users with the need to use arrays always end up creating a custom list so the filter gets populated with the individual tags and not the whole array. They are currently blocked when they want to link such filters.

So supporting linked filters for lists generated from Questions/Model would effectively make us support arrays :)


**Describe the solution you'd like**

I get the same options to link a filter when the list is generated via the option `From connected fields`


**Describe alternatives you've considered**
None you are blocked if you want to use linked filters with this approach. Which is the only approach when working with arrays

**How important is this feature to you?**

Most enterprise customers ask for this and the only option we can give is to flatten all the array elements per application to support filtering, this means that if you have 10 elements in an array per row and 1M of rows the resultant table will end up being around 10M. So you would need to duplicate the entity on each array element, causing table to exponentially grow and make the query slow. I am not sure about how complex the aggregations on the dashboard are but another issue with this approach is that you would need to perform distinct count/aggregations to remove the duplication caused by the flattening approach. In this case you would be able to use linked filters since the filters will behave as a normal table (no more arrays) but it's a headache to manage

**Additional context**
In my opinion this will technically mean that we support arrays! https://github.com/metabase/metabase/issues/2974 via some tweeks",Tony-metabase,2024-09-20 12:09:58+00:00,[],2025-02-04 20:29:42+00:00,,https://github.com/metabase/metabase/issues/48040,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2538280911,issue,open,,"Columns where the name includes an underscore, or - , cannot be selected in the visualization UI","**Describe the bug**
Columns where the name includes an underscore, or - , cannot be selected in the visualization UI 

**Logs**
N/A

**To Reproduce**
Rename a column to include _ or -, and it will not be included in the drop-down for Y-axis in bar visualzation, see screenshot.
I assume this restriction on names did not apply in version 0.49.x

**Expected behavior**
All eligble columns can be selected.

**Screenshots**
![image](https://github.com/user-attachments/assets/e26fc716-b0b4-4b62-9277-385337dfc606)

**Severity**
There is a work-around (rename all affected columns), but this could be very annoying for some customers.

**Additional context**
N/A

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""nb"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.106-116.188.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Oslo""
  }
}
```",sao2015,2024-09-20 09:04:27+00:00,[],2025-01-06 22:52:41+00:00,,https://github.com/metabase/metabase/issues/48038,[],[],
2538175007,issue,open,reopened,Difference of visualisation in trend widgets between native and query builder,"### Describe the bug

When converting a trend widget sql question to native sql the representation / visualisation differs from the one with the query builder. The range is displayed to the user and makes it way clearer than the specific date in the native sql version.

The query builder version:

![Screenshot 2024-09-20 at 10 08 16](https://github.com/user-attachments/assets/5c2768b4-015b-4372-90f5-c137ee778d3c)

The native sql version:

![Screenshot 2024-09-20 at 10 09 25](https://github.com/user-attachments/assets/e890ef50-72e5-4b2d-9d3b-5841b3547dcc)

Note that the date ranges aren't the same in both screenshots. But its purely the visualisation.

### To Reproduce

1. Create a trend widget per week/month/quarter/year/... with the query builder
2. Visualize it
3. Convert it to native sql (by pressing view code / convert question)
4. Visualize the native sql version
5. See the difference


### Expected behavior

Ideally it should display the same range as the query builder visualisation.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-16"",
      ""tag"": ""v1.49.11"",
      ""hash"": ""b894f2d""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

minor

### Additional context

_No response_",vinceve,2024-09-20 08:11:41+00:00,[],2025-02-04 20:31:46+00:00,,https://github.com/metabase/metabase/issues/48036,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2371254250, 'issue_id': 2538175007, 'author': 'npfitz', 'body': ""This appears to be fixed in our current master branch. My guess is that the updates we've made to the querying language solved the issues (they were introduced in v50)"", 'created_at': datetime.datetime(2024, 9, 24, 13, 18, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2371278839, 'issue_id': 2538175007, 'author': 'npfitz', 'body': 'Since there were some very big changes in this area of the codebase, backporting a fix to 49 would be very difficult. Please try upgrading to 50 and let us know if the problem persists.', 'created_at': datetime.datetime(2024, 9, 24, 13, 28, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2385557804, 'issue_id': 2538175007, 'author': 'vinceve', 'body': 'It seems that it is not the same yet. It shows a specific date and not the date range like the query builder version.\r\n\r\n![Screenshot 2024-10-01 at 13 42 55](https://github.com/user-attachments/assets/40143107-609a-4e64-af62-3b6e6a55f9da)\r\n\r\nand the configuration:\r\n\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""en-US"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres""\r\n    ],\r\n    ""run-mode"": ""prod"",\r\n    ""plan-alias"": ""pro-self-hosted-yearly"",\r\n    ""version"": {\r\n      ""date"": ""2024-09-24"",\r\n      ""tag"": ""v1.50.27"",\r\n      ""hash"": ""8b9a8fc""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": null\r\n    },\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""14.12""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.3""\r\n      }\r\n    }\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.24+8"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.24"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.24+8"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""UTC""\r\n  }\r\n}\r\n```\r\n\r\nIs there a possibility to get this range in the native version?\r\n\r\nCC: @npfitz', 'created_at': datetime.datetime(2024, 10, 1, 11, 43, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478672917, 'issue_id': 2538175007, 'author': 'vinceve', 'body': 'Is there any update regarding this issue?', 'created_at': datetime.datetime(2024, 11, 15, 12, 6, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615359345, 'issue_id': 2538175007, 'author': 'lorem--ipsum', 'body': 'This seems to have been implemented on purpose in #38344, to solve #38122. @alxnddr what do you think?', 'created_at': datetime.datetime(2025, 1, 27, 10, 22, 34, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-09-24 13:18:53 UTC): This appears to be fixed in our current master branch. My guess is that the updates we've made to the querying language solved the issues (they were introduced in v50)

npfitz on (2024-09-24 13:28:21 UTC): Since there were some very big changes in this area of the codebase, backporting a fix to 49 would be very difficult. Please try upgrading to 50 and let us know if the problem persists.

vinceve (Issue Creator) on (2024-10-01 11:43:56 UTC): It seems that it is not the same yet. It shows a specific date and not the date range like the query builder version.

![Screenshot 2024-10-01 at 13 42 55](https://github.com/user-attachments/assets/40143107-609a-4e64-af62-3b6e6a55f9da)

and the configuration:

```
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-09-24"",
      ""tag"": ""v1.50.27"",
      ""hash"": ""8b9a8fc""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.217-205.860.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  }
}
```

Is there a possibility to get this range in the native version?

CC: @npfitz

vinceve (Issue Creator) on (2024-11-15 12:06:32 UTC): Is there any update regarding this issue?

lorem--ipsum on (2025-01-27 10:22:34 UTC): This seems to have been implemented on purpose in #38344, to solve #38122. @alxnddr what do you think?

"
2537490398,issue,open,,Trend line won't appear when there are 2 aggregations,"### Describe the bug

Seems that we won't show the trend line if there are 2 aggregations on a chart, even though it should be possible

### To Reproduce

1) create a question like 
![image](https://github.com/user-attachments/assets/0ad5e087-70f2-4ac0-b216-7ddfa0a9fc40)

2) then enable the trend line
![image](https://github.com/user-attachments/assets/50861233-0770-4774-bff0-a9673cb34be7)


### Expected behavior

Trend line should be shown

### Logs

No logs whatsoever

### Information about your Metabase installation

```JSON
v50.26
```


### Severity

P1'ish?

### Additional context

If trend line is not supported we should simply disable it",paoliniluis,2024-09-19 22:52:55+00:00,[],2025-02-04 20:31:18+00:00,,https://github.com/metabase/metabase/issues/48034,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2371201847, 'issue_id': 2537490398, 'author': 'npfitz', 'body': ""This can be simplified a bit (the filter isn't necessary to repro), but we likely shouldn't show the trend line option on questions that contain breakouts."", 'created_at': datetime.datetime(2024, 9, 24, 12, 58, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-09-24 12:58:00 UTC): This can be simplified a bit (the filter isn't necessary to repro), but we likely shouldn't show the trend line option on questions that contain breakouts.

"
2537451567,issue,closed,completed,Can't remove aggregation in the chill mode Summarize,"### Describe the bug

When you use Summarize sidebar you can't remove an aggregation, only change it, the x button just doesn't work

### To Reproduce

1. Browse data
2. Pick Orders table from Sample database
3. Click on Summarize in the chill mode
4. Change the aggregation to Sum of Total
5. Click on x button to remove the aggregation
6. Nothing happens


### Expected behavior

It should remove the aggregation

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5

775d9c9
```


### Severity

Annoying, you have to switch to the notebook editor if you saved it

### Additional context

_No response_",mngr,2024-09-19 22:10:54+00:00,"['ranquild', 'uladzimirdev']",2024-10-08 16:13:59+00:00,2024-10-01 16:47:09+00:00,https://github.com/metabase/metabase/issues/48033,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Querying', ''), ('Frequency:Often', 'Something users bump into often')]","[{'comment_id': 2386074610, 'issue_id': 2537451567, 'author': 'mngr', 'body': 'The behavior seems to be changed since I posted this, now instead of not doing anything clicking on x opens and closes the modal', 'created_at': datetime.datetime(2024, 10, 1, 14, 7, 20, tzinfo=datetime.timezone.utc)}]","mngr (Issue Creator) on (2024-10-01 14:07:20 UTC): The behavior seems to be changed since I posted this, now instead of not doing anything clicking on x opens and closes the modal

"
2537442946,issue,closed,completed,When drilling down into a summary only fields from the first table are shown,"### Describe the bug

If I create a question that joins 2 tables (either explicitly or via modelled relationship), then summarise that result, any drill downs (i.e. ""See these XYZ"") will only include the first table columns.

This seems to be because adding a summary automatically unticks all the fields in the dropdown of the second table in the ""Join data"" section.

The behaviour depends on the order of building the question, if you summarise then join the second table fields are included, if you join then summarise they are not. It also doesn't seem to matter what the summary is or what it's grouped by, it could be grouped by a field in the second table the result is the same.

### To Reproduce

1. Start a new query on Sample database > Orders
2. Join data for People, join clause created automatically as it's modelled
3. View the fields ticked in the dropdown for People, all are ticked
![image](https://github.com/user-attachments/assets/66dc7e13-8e7b-4164-9426-906f8d4b7098)
4. Add a summarize step for a Count, view the fields ticked for People, all are un selected
![image](https://github.com/user-attachments/assets/eaf724a9-2384-4012-bd30-ed5a0c46e18d)
5. Visualize > click the number > See these Orders
6. Table presented is titled ""Orders + People"" but none of the People fields are shown
![image](https://github.com/user-attachments/assets/3b600014-3b21-4f93-9439-231b0d247196)


### Expected behavior

If I've explicitly joined data into a question then I've done so for a reason. I want that data set to be preserved and presented when users drill down for more detail.

I also expect consistent behaviour of the query builder.

### Logs

Nothing of note.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""sqlserver"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-16"",
      ""tag"": ""v0.50.26"",
      ""hash"": ""5a65f46""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Auckland""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows 10"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  }
}
```


### Severity

Frustrating and confusing

### Additional context

This may have been a deliberate design decision but to me it doesn't make sense or match my expectations. Also behaving differently depending on the order you click the UI buttons to build the same query indicates that it's not.

This happens to all joined tables, not just the second.

Removing the Summarise step from the notebook re-ticks all the fields in joined tables. Adding it back removes them.

I see this in v0.49.7 too (our current production).

Work around is to remember to go back and tick ""Select All"" fields on all joined tables. But this is an extra step that isn't intuitive.",notrom,2024-09-19 22:02:59+00:00,['wzimrin'],2024-12-04 17:53:23+00:00,2024-12-04 17:11:29+00:00,https://github.com/metabase/metabase/issues/48032,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2507865932, 'issue_id': 2537442946, 'author': 'bshepherdson', 'body': 'I think this is a missing bit of logic from the ""apply"" action for the `underlying-records` drill.\n\nThe main source is shown because the default for a source with no `:fields` clause is to `SELECT *`; for a join clause it\'s to select nothing. `underlying-records` should be setting `:fields :all` on all the explicit joins in the query after it removes the summaries.', 'created_at': datetime.datetime(2024, 11, 29, 13, 53, 39, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-11-29 13:53:39 UTC): I think this is a missing bit of logic from the ""apply"" action for the `underlying-records` drill.

The main source is shown because the default for a source with no `:fields` clause is to `SELECT *`; for a join clause it's to select nothing. `underlying-records` should be setting `:fields :all` on all the explicit joins in the query after it removes the summaries.

"
2536754606,issue,closed,completed,Crash when discarding new metric,"### Describe the bug

When you start to create a metric and then decide to discard it, app crashes

### To Reproduce

1. Go to + New metric
2. Choose Sample database, Orders table
3. Click Cancel on top
4. Click Discard changes
5. App crashes
[metabase-diagnostic-info-2024-09-19T15_53_51.071Z.json](https://github.com/user-attachments/files/17062386/metabase-diagnostic-info-2024-09-19T15_53_51.071Z.json)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5

775d9c9
```


### Severity

Breaks the app until refresh

### Additional context

_No response_",mngr,2024-09-19 15:55:02+00:00,['ranquild'],2024-09-24 16:45:12+00:00,2024-09-24 16:45:11+00:00,https://github.com/metabase/metabase/issues/48024,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('.Team/Querying', ''), ('Querying/Metrics', 'v2')]","[{'comment_id': 2368949708, 'issue_id': 2536754606, 'author': 'iethree', 'body': ""```\r\nTypeError: Cannot read properties of undefined (reading 'card')\r\n    at createRawSeries (index.ts:162:1)\r\n\r\nnavigation.js:155 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'query')\r\n```"", 'created_at': datetime.datetime(2024, 9, 23, 17, 42, 50, tzinfo=datetime.timezone.utc)}]","iethree on (2024-09-23 17:42:50 UTC): ```
TypeError: Cannot read properties of undefined (reading 'card')
    at createRawSeries (index.ts:162:1)

navigation.js:155 Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'query')
```

"
2536448564,issue,closed,completed,Is Empty / Is Not Empty filters break on Postgres enums,"### Describe the bug

The Is Empty / Is Not Empty filters generate incorrect SQL for Postgres enums.

### To Reproduce

1. On Postgres, create a table with an enum column.
2. Create a GUI question
3. Add a simple 'is empty' or 'not empty' filter for the enum column
<img width=""333"" alt=""image"" src=""https://github.com/user-attachments/assets/a2ba7baa-bf2b-4d26-83da-f604d12c7eca"">

4. Visualize, and see the error: `ERROR: invalid input value for enum mood: """"`

Generated SQL

```
SELECT
  ""public"".""person"".""id"" AS ""id"",
  ""public"".""person"".""name"" AS ""name"",
  ""public"".""person"".""current_mood"" AS ""current_mood"",
  ""public"".""person"".""description"" AS ""description""
FROM
  ""public"".""person""
WHERE
  (""public"".""person"".""current_mood"" IS NULL)
    OR (
    ""public"".""person"".""current_mood"" = CAST('' AS ""mood"")
  )
LIMIT
  1048575
```

### Expected behavior

It should work.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.50.25
```


### Severity

Found it while troubleshooting something else

### Additional context

Custom expressions `isnull()` and `notnull()` can work as a workaround.",zbodi74,2024-09-19 14:03:09+00:00,['wzimrin'],2024-12-05 23:23:03+00:00,2024-12-05 22:23:32+00:00,https://github.com/metabase/metabase/issues/48022,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2507869982, 'issue_id': 2536448564, 'author': 'bshepherdson', 'body': ""I don't know if we capture metadata about Postgres strings vs. enums very clearly. It feels like it should be `:type/Category` but that's a lot broader than formal enums.\n\nWe do have the `db_type` of the column, so at least at the Postgres driver level we can avoid generating the empty string branch for these expressions."", 'created_at': datetime.datetime(2024, 11, 29, 13, 56, 6, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-11-29 13:56:06 UTC): I don't know if we capture metadata about Postgres strings vs. enums very clearly. It feels like it should be `:type/Category` but that's a lot broader than formal enums.

We do have the `db_type` of the column, so at least at the Postgres driver level we can avoid generating the empty string branch for these expressions.

"
2536334144,issue,closed,completed,Regression: y-axis minimum is ignored for stacked 100% histograms,"### Describe the bug

A regression was introduced in the last few versions of Metabase.
For stacked 100% histgrams the y-axis minimum value is now ignored. It used to work.
It was fixed for simple stacked histograms, but not for ""stacked 100%"" histograms.

The following issue is the same bug, but it was only partially fixed:
https://github.com/metabase/metabase/issues/44672#issuecomment-2228586365

### To Reproduce

See reproduction in https://github.com/metabase/metabase/issues/44672.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:130.0) Gecko/20100101 Firefox/130.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.223-212.873.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-12"",
      ""tag"": ""v0.50.12"",
      ""hash"": ""86d4671""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

low

### Additional context

_No response_",Caerbannog,2024-09-19 13:23:33+00:00,[],2025-01-31 19:58:19+00:00,2025-01-31 19:58:19+00:00,https://github.com/metabase/metabase/issues/48021,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2535590705,issue,closed,completed,CSP issue in chrome.,"### Describe the bug

The page goes blank, and we can see CSP errors in chrome console.
Version 128.0.6613.138 (Official Build) (arm64)
Works fine in Safari.
You're on version v0.50.26
Built on 2024-09-16

### To Reproduce

<img width=""1726"" alt=""Screenshot 2024-09-19 at 1 22 48 PM"" src=""https://github.com/user-attachments/assets/5ca5c722-1915-4131-a281-0593d9bc3875"">


### Expected behavior

Page should load normally

### Logs

GET https://metabase.superfone.co.in/app/dist/runtime.5f1e4129a9a1d5c3575e.js net::ERR_ABORTED 404 (Not Found)Understand this error
metabase.superfone.co.in/:1 Refused to execute script from 'https://metabase.superfone.co.in/app/dist/runtime.5f1e4129a9a1d5c3575e.js' because its MIME type ('') is not executable, and strict MIME type checking is enabled.Understand this error
metabase.superfone.co.in/:42 
        
        
       GET https://metabase.superfone.co.in/app/dist/vendor-styles.c6e62ca30b8107c42e2a.js net::ERR_ABORTED 404 (Not Found)Understand this error
metabase.superfone.co.in/:1 Refused to execute script from 'https://metabase.superfone.co.in/app/dist/vendor-styles.c6e62ca30b8107c42e2a.js' because its MIME type ('') is not executable, and strict MIME type checking is enabled.Understand this error
metabase.superfone.co.in/:42 
        
        
       GET https://metabase.superfone.co.in/app/dist/styles.32c2bf2b0dfceff31e0e.js net::ERR_ABORTED 404 (Not Found)Understand this error
metabase.superfone.co.in/:1 Refused to execute script from 'https://metabase.superfone.co.in/app/dist/styles.32c2bf2b0dfceff31e0e.js' because its MIME type ('') is not executable, and strict MIME type checking is enabled.Understand this error
metabase.superfone.co.in/:42 Refused to execute inline event handler because it violates the following Content Security Policy directive: ""script-src 'self' https://maps.google.com https://accounts.google.com https://www.google-analytics.com   'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=' 'sha256-3N2Z+Nu++/yNMVHIl863JigVmt2Nr9gt2doEMJT2Wzk='"". Either the 'unsafe-inline' keyword, a hash ('sha256-...'), or a nonce ('nonce-...') is required to enable inline execution. Note that hashes do not apply to event handlers, style attributes and javascript: navigations unless the 'unsafe-hashes' keyword is present.
Understand this error
metabase.superfone.co.in/:42 Refused to execute inline event handler because it violates the following Content Security Policy directive: ""script-src 'self' https://maps.google.com https://accounts.google.com https://www.google-analytics.com   'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=' 'sha256-3N2Z+Nu++/yNMVHIl863JigVmt2Nr9gt2doEMJT2Wzk='"". Either the 'unsafe-inline' keyword, a hash ('sha256-...'), or a nonce ('nonce-...') is required to enable inline execution. Note that hashes do not apply to event handlers, style attributes and javascript: navigations unless the 'unsafe-hashes' keyword is present.
Understand this error
metabase.superfone.co.in/:42 Refused to execute inline event handler because it violates the following Content Security Policy directive: ""script-src 'self' https://maps.google.com https://accounts.google.com https://www.google-analytics.com   'sha256-9uFLu5CG8mWlvx0LK6lgendCxUX57TuWk3wkgZpBeWU=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=' 'sha256-3N2Z+Nu++/yNMVHIl863JigVmt2Nr9gt2doEMJT2Wzk='"". Either the 'unsafe-inline' keyword, a hash ('sha256-...'), or a nonce ('nonce-...') is required to enable inline execution. Note that hashes do not apply to event handlers, style attributes and javascript: navigations unless the 'unsafe-hashes' keyword is present.
Understand this error
metabase.superfone.co.in/:1 

### Information about your Metabase installation

```JSON
Version 128.0.6613.138 (Official Build) (arm64)
Works fine in Safari.
You're on version v0.50.26
Built on 2024-09-16
metabase
```


### Severity

Blocking in Chrome, everyone is forced to use something else.

### Additional context

Only happens in chrome, but does not happen in safari.
Used to be fine, before upgrade.
",ashoksahoo,2024-09-19 08:01:17+00:00,[],2024-09-19 09:47:33+00:00,2024-09-19 09:47:33+00:00,https://github.com/metabase/metabase/issues/48018,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2360350900, 'issue_id': 2535590705, 'author': 'uladzimirdev', 'body': 'Can it be a mime type error, which means file is not located correctly? Could you please also clear browser cache and try again?', 'created_at': datetime.datetime(2024, 9, 19, 8, 30, 14, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-09-19 08:30:14 UTC): Can it be a mime type error, which means file is not located correctly? Could you please also clear browser cache and try again?

"
2534916879,issue,open,,Redundant Horizontal scroll on query clause popoever,"### Describe the bug

If the screen is small enough, the popover will have a scroll over

### To Reproduce

1. New question
2. Have the screen size small like the screen shot
3. open up Summarize clause picker
4. See the horizontal scorll
<img width=""2118"" alt=""Screenshot 2024-09-18 at 17 56 00"" src=""https://github.com/user-attachments/assets/9905a8c1-0024-4d23-b4c7-1000e3b06801"">
scroll

### Expected behavior

No horizontal scroll please

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

Annoying - P3

### Additional context

_No response_",qnkhuat,2024-09-18 22:58:33+00:00,[],2025-02-04 20:27:34+00:00,,https://github.com/metabase/metabase/issues/48016,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2534887109,issue,closed,not_planned,"When you do drill through on a question created from a model, the drill through does not respect the column order of the model","### Describe the bug

When you create a question from a model and drill through on that question, the detail view does not show the correct column order of the model.  It will hide any hidden columns, but it does not respect column order.

### To Reproduce

1. Create a model
2. Rearrange the columns
3. Create a question from the model with segments
4. Drill into a segment
5. See how the column order is different

Or see:  https://stats.metabase.com/question/19772-question-to-drill-in-and-see-how-the-model-column-order-isnt-respected


### Expected behavior

If I create a question from a model and drill through, the drill through should show the detail records as designed in the model.   It does this currently for some behavior (hidden columns) but not the column order

### Logs

_No response_

### Information about your Metabase installation

```JSON
Tested on:
Build from 2024-09-18
1.48.8
1.50.25.2
v1.49.8
```


### Severity

It's disappointing.  I would have sworn this worked, which is why I tested it on so many versions.  It also is a reason not to use Models.

### Additional context

Reported by a customer",cbalusek,2024-09-18 22:35:39+00:00,[],2024-10-21 14:53:39+00:00,2024-10-21 14:53:37+00:00,https://github.com/metabase/metabase/issues/48015,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Hard', ''), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2359603586, 'issue_id': 2534887109, 'author': 'ranquild', 'body': ""The order of the columns in models is currently implemented (incorrectly) as a viz setting. It doesn't affect anything outside of the model query itself."", 'created_at': datetime.datetime(2024, 9, 18, 23, 8, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2369241205, 'issue_id': 2534887109, 'author': 'TanTan412', 'body': 'is this in the works in the future?', 'created_at': datetime.datetime(2024, 9, 23, 19, 54, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402330037, 'issue_id': 2534887109, 'author': 'paoliniluis', 'body': '@TanTan412 yes', 'created_at': datetime.datetime(2024, 10, 9, 13, 19, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426921646, 'issue_id': 2534887109, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/38523', 'created_at': datetime.datetime(2024, 10, 21, 14, 53, 37, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-09-18 23:08:22 UTC): The order of the columns in models is currently implemented (incorrectly) as a viz setting. It doesn't affect anything outside of the model query itself.

TanTan412 on (2024-09-23 19:54:08 UTC): is this in the works in the future?

paoliniluis on (2024-10-09 13:19:01 UTC): @TanTan412 yes

ranquild on (2024-10-21 14:53:37 UTC): Duplicate of https://github.com/metabase/metabase/issues/38523

"
2534721572,issue,closed,completed,"No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY","### Describe the bug

ran into issue with one of the report, suring upgrade from v0.50.23.1 --> v0.50.23.2
basically report just fail with error like below:

An error occurred in your query
```
400 Bad Request POST https://bigquery.googleapis.com/bigquery/v2/projects/$$$$$$/queries { ""code"": 400, ""errors"": [ { ""domain"": ""global"", ""location"": ""q"", ""locationType"": ""parameter"", ""message"": ""No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY at [49:13]"", ""reason"": ""invalidQuery"" } ], ""message"": ""No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY at [49:13]"", ""status"": ""INVALID_ARGUMENT"" }
```



### To Reproduce

basically, its working good on  v0.50.23.1 and as soon as U update it to v0.50.23.2, it starts to fail

### Expected behavior

_No response_

### Logs

part of the stacktrace:
```

}
],
""message"": ""No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY at [49:13]"",
""status"": ""INVALID_ARGUMENT""
}
{:database_id 102,
:started_at #t ""2024-09-18T20:54:34.218454Z[GMT]"",
:via
[{:status :failed,
:class com.google.cloud.bigquery.BigQueryException,
:error
""No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY at [49:13]"",
:stacktrace
[""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:115)""
""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:771)""
""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1365)""
""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1362)""
""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1361)""
""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1349)""
""--> driver.bigquery_cloud_sdk$execute_bigquery_off_thread$fn__127300$fn__127304.invoke(bigquery_cloud_sdk.clj:421)""
""driver.bigquery_cloud_sdk$execute_bigquery_off_thread$fn__127300.invoke(bigquery_cloud_sdk.clj:418)""]}
{:status :failed,
:class clojure.lang.ExceptionInfo,
:error
""Error executing query: No matching signature for operator >= for argument types: TIMESTAMP, DATETIME. Supported signature: ANY >= ANY at [49:13]"",
:stacktrace
[""--> driver.bigquery_cloud_sdk$throw_invalid_query.invokeStatic(bigquery_cloud_sdk.clj:395)""
""driver.bigquery_cloud_sdk$throw_invalid_query.invoke(bigquery_cloud_sdk.clj:394)""
""driver.bigquery_cloud_sdk$handle_bigquery_exception.invokeStatic(bigquery_cloud_sdk.clj:449)""
""driver.bigquery_cloud_sdk$handle_bigquery_exception.invoke(bigquery_cloud_sdk.clj:436)""
""driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:471)""
""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:453)""
""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:477)""
""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:474)""
""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__127509.invoke(bigquery_cloud_sdk.clj:517)""
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-03"",
      ""tag"": ""v0.50.23.2"",
      ""hash"": ""95f1c3b""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.37-google""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.4.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

3

### Additional context

_No response_",oreststetsiak,2024-09-18 20:59:00+00:00,['lbrdnk'],2024-10-31 17:03:49+00:00,2024-10-18 15:41:42+00:00,https://github.com/metabase/metabase/issues/48010,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('Database/BigQuery', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2359478822, 'issue_id': 2534721572, 'author': 'paoliniluis', 'body': 'Is there any way we can get the column types or the queries used?', 'created_at': datetime.datetime(2024, 9, 18, 22, 0, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2359603879, 'issue_id': 2534721572, 'author': 'oreststetsiak', 'body': 'sure thing @paoliniluis, here is query, it produce a nice dashboard, like an Excel spreadsheet normally\r\n(it has a table names masked offcouse)\r\n```\r\nwith table_of_qwe_open AS (\r\n    SELECT \r\n        TRIM(qq_id) AS qq_id,\r\n\r\n        CONCAT(\'\') AS rr_ID,\r\n        CONCAT(\'\') AS rr_Status,\r\n        CONCAT(\'\') AS tt_Date,\r\n\r\n        CONCAT(a.bb_id) AS bb_id,\r\n        CASE \r\n            WHEN FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") < FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") \r\n                THEN \'Open\'\r\n            ELSE \'Closed\'\r\n        END AS ll_Status,\r\n\r\n        FORMAT_TIMESTAMP(""%F"", a.start_time, ""UTC-7"") as ll_Start_Date,\r\n        FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") as ll_End_Date,\r\n\r\n        p.seller AS Seller\r\n\r\n    FROM uu.ttttt AS p,\r\n        UNNEST(SPLIT(\r\n                replace(p.qq_ids, \'\\\\n\', \',\')\r\n            )) as qq_id\r\n        LEFT JOIN uu.ll AS a ON p.yy_id = a.yy_id\r\n    WHERE TRUE \r\n        AND p.ll = 30\r\n        AND a.is_cancelled = \'F\'\r\n        AND p.created_at >= timestamp_trunc(timestamp_add(current_timestamp(), \r\n            INTERVAL -180 day), day)\r\n\r\n        AND FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") >= FORMAT_TIMESTAMP(""%F"", a.start_time, ""UTC-7"") \r\n        AND FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") <= FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") \r\n        \r\n        [[AND timestamp_trunc(a.start_time, day) >= timestamp_trunc({{var_min_dt}}, day)]]\r\n        [[AND timestamp_trunc(a.initial_end_time, day) <= timestamp_trunc({{var_max_dt}}, day)]]\r\n\r\n    ORDER BY a.bb_id, qq_id, a.start_time, a.initial_end_time\r\n),\r\n\r\ntable_of_pallets_closed as (\r\n    SELECT \r\n        TRIM(qq_id) AS qq_id,\r\n\r\n        CONCAT(`qwerty ee`.`ee_id`) AS ee_ID, \r\n        `qwerty ee`.`status` AS ee_Status,\r\n        FORMAT_TIMESTAMP(""%F"", `qwerty ee`.`tt_At`, ""UTC-7"") as tt_Date,\r\n\r\n        CONCAT(`ll`.`bb_id`) AS bb_id, \r\n        CONCAT(\'Closed\') AS ll_Status,\r\n\r\n        FORMAT_TIMESTAMP(""%F"", `ll`.`start_time`, ""UTC-7"") as ll_Start_Date,\r\n        FORMAT_TIMESTAMP(""%F"", `ll`.`end_time`, ""UTC-7"") as ll_End_Date,\r\n\r\n        `ttttt`.`seller` AS Seller\r\n        \r\n    FROM uu.`qwerty_ee` `qwerty ee`\r\n        LEFT JOIN uu.`ll` `ll` ON `qwerty ee`.`ll` = `ll`.`id`\r\n        LEFT JOIN uu.`ttttt` `ttttt` ON `ll`.`ttttt` = `ttttt`.`id`, \r\n            UNNEST(SPLIT(\r\n                replace(`ttttt`.`qq_ids`, \'\\\\n\', \',\')\r\n            )) as qq_id\r\n        LEFT JOIN uu.`ll` `ll` ON `qwerty ee`.`ll` = `ll`.`id`\r\n    WHERE True \r\n        AND `ll`.`abbreviation` = \'tgt\' \r\n        AND `ll`.`is_cancelled` = \'F\'\r\n        AND `qwerty ee`.`status` != \'Canceled\'\r\n        AND `ll`.`created_at` >= timestamp_trunc(timestamp_add(current_timestamp(), \r\n            INTERVAL -360 day), day)\r\n        [[AND timestamp_trunc(`ll`.`start_time`, day) >= timestamp_trunc({{var_min_dt}}, day)]]\r\n        [[AND timestamp_trunc(`qwerty ee`.ll_end, day) <= timestamp_trunc({{var_max_dt}}, day)]]\r\n        [[AND `qwerty ee`.`ee_id` = {{vrble_ee_id}}]] \r\n        [[AND `ll`.`bb_id` = {{vrble_bb_id}}]] \r\n        [[AND UPPER(`qwerty Order`.`seller`) LIKE UPPER(CONCAT(\'%\', {{vrble_sllr_locn}}, \'%\'))]] \r\n    GROUP BY 1,2,3,4,5,6,7,8,9\r\n    ORDER BY 5, 1, 7, 8\r\n    LIMIT 130000\r\n),\r\n\r\ntable_of_union AS (\r\n    (SELECT *\r\n    FROM table_of_pallets_open \r\n    WHERE ll_Status = \'Open\'  \r\n    )\r\n\r\n    UNION ALL\r\n\r\n    (SELECT *\r\n    FROM table_of_pallets_closed\r\n    ) \r\n)\r\n\r\nSELECT \r\n    qq_id, ff_ID, ff_Status, ww_Date,\r\n    bb_id, ll_Status,\r\n    ll_Start_Date, ll_End_Date,\r\n    Seller\r\nFROM table_of_union\r\nWHERE True \r\n    [[AND UPPER(qq_id) LIKE UPPER(CONCAT(\'%\', {{vrble_qq_id}}, \'%\'))]]\r\nGROUP BY 1,2,3,4,5,6,7,8,9\r\nORDER BY ll_Status DESC, bb_id, qq_id\r\n;\r\n```\r\n\r\nwhen I update to v0.50.23.2, it stopped working\r\nI spend some time to figure out after which it gets broken, and it is v0.50.23.2\r\n\r\n\r\nlet me know if you need more info\r\nI would be happy to provide', 'created_at': datetime.datetime(2024, 9, 18, 23, 8, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364762322, 'issue_id': 2534721572, 'author': 'perivamsi', 'body': '@snoe is this related to https://github.com/metabase/metabase/pull/47423?', 'created_at': datetime.datetime(2024, 9, 20, 23, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400453357, 'issue_id': 2534721572, 'author': 'gocarecx', 'body': 'Thank you, as we just noticed the same issue with our previously working reports after updating Metabase. BigQuery requires:\n\n```AND k.date >= TIMESTAMP(""2023-11-10"")```\n\nbut Metabase is creating the SQL (using a Date variable) as:\n\n```AND k.date >= date ""2023-11-10""```\n\n![Image](https://github.com/user-attachments/assets/1133fa69-f1e2-478a-b56c-0a69bb3678bb)', 'created_at': datetime.datetime(2024, 10, 8, 17, 36, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450388407, 'issue_id': 2534721572, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.1](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 31, 17, 3, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-18 22:00:02 UTC): Is there any way we can get the column types or the queries used?

oreststetsiak (Issue Creator) on (2024-09-18 23:08:40 UTC): sure thing @paoliniluis, here is query, it produce a nice dashboard, like an Excel spreadsheet normally
(it has a table names masked offcouse)
```
with table_of_qwe_open AS (
    SELECT 
        TRIM(qq_id) AS qq_id,

        CONCAT('') AS rr_ID,
        CONCAT('') AS rr_Status,
        CONCAT('') AS tt_Date,

        CONCAT(a.bb_id) AS bb_id,
        CASE 
            WHEN FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") < FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") 
                THEN 'Open'
            ELSE 'Closed'
        END AS ll_Status,

        FORMAT_TIMESTAMP(""%F"", a.start_time, ""UTC-7"") as ll_Start_Date,
        FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") as ll_End_Date,

        p.seller AS Seller

    FROM uu.ttttt AS p,
        UNNEST(SPLIT(
                replace(p.qq_ids, '\\n', ',')
            )) as qq_id
        LEFT JOIN uu.ll AS a ON p.yy_id = a.yy_id
    WHERE TRUE 
        AND p.ll = 30
        AND a.is_cancelled = 'F'
        AND p.created_at >= timestamp_trunc(timestamp_add(current_timestamp(), 
            INTERVAL -180 day), day)

        AND FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") >= FORMAT_TIMESTAMP(""%F"", a.start_time, ""UTC-7"") 
        AND FORMAT_TIMESTAMP(""%F"", CURRENT_TIMESTAMP, ""UTC-7"") <= FORMAT_TIMESTAMP(""%F"", a.initial_end_time, ""UTC-7"") 
        
        [[AND timestamp_trunc(a.start_time, day) >= timestamp_trunc({{var_min_dt}}, day)]]
        [[AND timestamp_trunc(a.initial_end_time, day) <= timestamp_trunc({{var_max_dt}}, day)]]

    ORDER BY a.bb_id, qq_id, a.start_time, a.initial_end_time
),

table_of_pallets_closed as (
    SELECT 
        TRIM(qq_id) AS qq_id,

        CONCAT(`qwerty ee`.`ee_id`) AS ee_ID, 
        `qwerty ee`.`status` AS ee_Status,
        FORMAT_TIMESTAMP(""%F"", `qwerty ee`.`tt_At`, ""UTC-7"") as tt_Date,

        CONCAT(`ll`.`bb_id`) AS bb_id, 
        CONCAT('Closed') AS ll_Status,

        FORMAT_TIMESTAMP(""%F"", `ll`.`start_time`, ""UTC-7"") as ll_Start_Date,
        FORMAT_TIMESTAMP(""%F"", `ll`.`end_time`, ""UTC-7"") as ll_End_Date,

        `ttttt`.`seller` AS Seller
        
    FROM uu.`qwerty_ee` `qwerty ee`
        LEFT JOIN uu.`ll` `ll` ON `qwerty ee`.`ll` = `ll`.`id`
        LEFT JOIN uu.`ttttt` `ttttt` ON `ll`.`ttttt` = `ttttt`.`id`, 
            UNNEST(SPLIT(
                replace(`ttttt`.`qq_ids`, '\\n', ',')
            )) as qq_id
        LEFT JOIN uu.`ll` `ll` ON `qwerty ee`.`ll` = `ll`.`id`
    WHERE True 
        AND `ll`.`abbreviation` = 'tgt' 
        AND `ll`.`is_cancelled` = 'F'
        AND `qwerty ee`.`status` != 'Canceled'
        AND `ll`.`created_at` >= timestamp_trunc(timestamp_add(current_timestamp(), 
            INTERVAL -360 day), day)
        [[AND timestamp_trunc(`ll`.`start_time`, day) >= timestamp_trunc({{var_min_dt}}, day)]]
        [[AND timestamp_trunc(`qwerty ee`.ll_end, day) <= timestamp_trunc({{var_max_dt}}, day)]]
        [[AND `qwerty ee`.`ee_id` = {{vrble_ee_id}}]] 
        [[AND `ll`.`bb_id` = {{vrble_bb_id}}]] 
        [[AND UPPER(`qwerty Order`.`seller`) LIKE UPPER(CONCAT('%', {{vrble_sllr_locn}}, '%'))]] 
    GROUP BY 1,2,3,4,5,6,7,8,9
    ORDER BY 5, 1, 7, 8
    LIMIT 130000
),

table_of_union AS (
    (SELECT *
    FROM table_of_pallets_open 
    WHERE ll_Status = 'Open'  
    )

    UNION ALL

    (SELECT *
    FROM table_of_pallets_closed
    ) 
)

SELECT 
    qq_id, ff_ID, ff_Status, ww_Date,
    bb_id, ll_Status,
    ll_Start_Date, ll_End_Date,
    Seller
FROM table_of_union
WHERE True 
    [[AND UPPER(qq_id) LIKE UPPER(CONCAT('%', {{vrble_qq_id}}, '%'))]]
GROUP BY 1,2,3,4,5,6,7,8,9
ORDER BY ll_Status DESC, bb_id, qq_id
;
```

when I update to v0.50.23.2, it stopped working
I spend some time to figure out after which it gets broken, and it is v0.50.23.2


let me know if you need more info
I would be happy to provide

perivamsi on (2024-09-20 23:56:32 UTC): @snoe is this related to https://github.com/metabase/metabase/pull/47423?

gocarecx on (2024-10-08 17:36:55 UTC): Thank you, as we just noticed the same issue with our previously working reports after updating Metabase. BigQuery requires:

```AND k.date >= TIMESTAMP(""2023-11-10"")```

but Metabase is creating the SQL (using a Date variable) as:

```AND k.date >= date ""2023-11-10""```

![Image](https://github.com/user-attachments/assets/1133fa69-f1e2-478a-b56c-0a69bb3678bb)

github-actions[bot] on (2024-10-31 17:03:46 UTC): 🚀 This should also be released by [v0.51.1](https://github.com/metabase/metabase/milestone/231)

"
2534655427,issue,closed,duplicate,Show the same series on all dashboard cards on hover,"**Is your feature request related to a problem? Please describe.**
Some tools have this and a customer requested if we could show the same series on all dashcards when you hover over those. E.g. let's say that I build 4 cards for a dashboard that has the ""Gizmo"" series or category. If Gizmo is on multiple cards, we should focus on those in other cards when you hover over any

**Describe the solution you'd like**
Above

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer since they had that in a previous tool

**Additional context**
NA
",paoliniluis,2024-09-18 20:26:01+00:00,[],2025-01-03 10:11:02+00:00,2025-01-02 17:53:37+00:00,https://github.com/metabase/metabase/issues/48008,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2568151097, 'issue_id': 2534655427, 'author': 'brunobergher', 'body': 'I think this is pretty much the same as #48041, so closing as duplicate. Let me know otherwise.', 'created_at': datetime.datetime(2025, 1, 2, 17, 53, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568567606, 'issue_id': 2534655427, 'author': 'paoliniluis', 'body': 'Nope, seem like that one is for the same chart and I was looking for the feature on all the charts in the dashboard that have the same series', 'created_at': datetime.datetime(2025, 1, 3, 0, 49, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568985461, 'issue_id': 2534655427, 'author': 'brunobergher', 'body': 'That\'s what that is: ""Synchronize the hover state of **multiple cartesian charts** in the same dashboard""', 'created_at': datetime.datetime(2025, 1, 3, 10, 11, 1, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:53:37 UTC): I think this is pretty much the same as #48041, so closing as duplicate. Let me know otherwise.

paoliniluis (Issue Creator) on (2025-01-03 00:49:43 UTC): Nope, seem like that one is for the same chart and I was looking for the feature on all the charts in the dashboard that have the same series

brunobergher on (2025-01-03 10:11:01 UTC): That's what that is: ""Synchronize the hover state of **multiple cartesian charts** in the same dashboard""

"
2534246839,issue,open,,[FieldRefs] We fail to identify the correct source column on nested models,"### Describe the bug

we generate wrongly the query when there are many nested models

### To Reproduce

1) create the following table structure:
```
drop table if exists bu;
CREATE TABLE bu
(
    branch_db_name    varchar(404),
    bu_uq_gescom_code varchar(500),
    bu_gescom_code    varchar(500),
    bu_name           varchar(1000),
    bu_region         varchar(1000),
    bu_isocountrycode varchar(3),
    bu_group_sales    varchar(50),
    bu_group_delivery varchar(50),
    bu_group_hr       varchar(50),
    bu_id             uuid
    PRIMARY KEY
);

drop table if exists employee;
CREATE TABLE employee
(
    employee_bu_id uuid references bu (bu_id),
    employee_id    uuid
    PRIMARY KEY
);

drop table if exists project;
CREATE TABLE project
(
    bu_sales_id      uuid references bu (bu_id),
    project_site_url varchar(500),
    project_id       uuid
    PRIMARY KEY
);

drop table if exists employee_monthly;
CREATE TABLE employee_monthly
(
    employee_id         uuid references employee (employee_id),
    employee_monthly_id uuid,
    bu_id               uuid references bu (bu_id)
    PRIMARY KEY
);

drop table if exists allocation;
CREATE TABLE allocation
(
    employee_id   uuid references employee (employee_id),
    period        date,
    project_id    uuid references project (project_id),
    allocation_id uuid
    PRIMARY KEY
);
```
2) Create this model
![image](https://github.com/user-attachments/assets/4b16a692-fe5c-45de-be15-1054f67b6f6b)

3) Then this other model
![image](https://github.com/user-attachments/assets/665daa4a-df58-4902-a4bc-7ffaa83f0f18)

MAKE SURE YOU UNCHECK all columns in BU, Allocation and Project before saving the model

4) then create this question
![image](https://github.com/user-attachments/assets/eab88c11-dd2a-447e-94ea-90bfda466aab)

BUT MAKE SURE YOU SELECT THE FIRST BU NAME in the model, not in the linked table

see the error in the compilation
![image](https://github.com/user-attachments/assets/7ed682db-02d5-414f-b32c-2efba454dc67)

![image](https://github.com/user-attachments/assets/101a0df0-e903-45ff-84d2-fe8975f0bcfd)



### Expected behavior

we should generate the queries correctly

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-09-18 17:01:15+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/48001,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2359238076, 'issue_id': 2534246839, 'author': 'paoliniluis', 'body': 'related to https://github.com/metabase/metabase/issues/47988', 'created_at': datetime.datetime(2024, 9, 18, 19, 23, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605755574, 'issue_id': 2534246839, 'author': 'paoliniluis', 'body': 'related to https://github.com/metabase/metabase/issues/52465', 'created_at': datetime.datetime(2025, 1, 21, 21, 16, 3, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-09-18 19:23:15 UTC): related to https://github.com/metabase/metabase/issues/47988

paoliniluis (Issue Creator) on (2025-01-21 21:16:03 UTC): related to https://github.com/metabase/metabase/issues/52465

"
2534109011,issue,open,,Increase verbosity in the metabase.email namespace,"**Is your feature request related to a problem? Please describe.**
We need to see why there are failures when pulses are sent, but the metabase.email doesn't log anything

**Describe the solution you'd like**
We need to increase the verbosity when sending emails. E.g. connecting to the smtp gateway, confirming that emails were sent, etc

**Describe alternatives you've considered**
None

**How important is this feature to you?**
We've had a few issues with pulses and we never know when it's being sent

**Additional context**
NA
",paoliniluis,2024-09-18 15:50:50+00:00,[],2025-02-04 20:30:49+00:00,,https://github.com/metabase/metabase/issues/47995,"[('Type:New Feature', ''), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]","[{'comment_id': 2568144217, 'issue_id': 2534109011, 'author': 'brunobergher', 'body': 'Related #51701', 'created_at': datetime.datetime(2025, 1, 2, 17, 47, 30, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:47:30 UTC): Related #51701

"
2533693498,issue,closed,completed,Serialization exports questions with bad (?) references,"### Describe the bug

Second time in 2 days where we get a report of a failed serialization due to to the fact that the card doesn't exist and it's probably on a personal collection.  We need to signal this on the export process and prevent the issue

### To Reproduce

1) make a question and save it on the personal collection
2) make a second question which uses the question of the personal collection as the source
3) export and import
4) see the process failing due to a failing reference

### Expected behavior

Signal this on the export process and even more, do not export the card with the invalid reference!

### Logs

NA

### Information about your Metabase installation

```JSON
It's been always like this
```


### Severity

P1

### Additional context

Reported 2 times 2 days. Related to https://github.com/metabase/metabase/issues/47976",paoliniluis,2024-09-18 13:05:21+00:00,['piranha'],2024-10-21 08:02:32+00:00,2024-10-17 13:26:51+00:00,https://github.com/metabase/metabase/issues/47991,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2376556504, 'issue_id': 2533693498, 'author': 'piranha', 'body': ""UPD: Ohhh, there is no error message, when you export everything, but personal stuff is still not exported.\r\n\r\n----\r\n\r\nWhen I try to reproduce, on export I get an error:\r\n\r\n```\r\n2024-09-26 10:24:55,350 WARN v2.extract :: Failed to export Cards based on questions outside requested collections: Card 109 (External Checkins from collection 2: Examples) -> Card 108 (Personal Checkins from collection 5: sanya's Personal Collection)\r\n```"", 'created_at': datetime.datetime(2024, 9, 26, 10, 26, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383237615, 'issue_id': 2533693498, 'author': 'piranha', 'body': ""While working on the issue I figured out that escape analysis we do is very incomplete - it checks only for `source-card` and then lets everything else through. And then serialization code figures out all descendants of a card - checking parameters and snippets - and exports data from other collections anyway.\n\nWhy is this a problem: I'm merging two different codepaths for extracting data, and it turned out that we have two different ways to limit outgoing data. If you supplied targets, we'll do escape analysis, if you did not - we'll instead limit by public collections (adding user collection if user was supplied).\n\nSo now there is one codepath with both of those limits and this breaks one of our tests, where it extracted some cards from non-related collections anyways. I can fix the test no problems, my issue is that there is a good chance we will break someone's workflow.\n\n/cc @luizarakaki"", 'created_at': datetime.datetime(2024, 9, 30, 13, 43, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384021816, 'issue_id': 2533693498, 'author': 'luizarakaki', 'body': 'You the user selects collections, we should serialize only content from those collections...\r\nIf they have dependents elsewhere, we should error and explain why.\r\n\r\nWdyt?', 'created_at': datetime.datetime(2024, 9, 30, 19, 46, 54, tzinfo=datetime.timezone.utc)}]","piranha (Assginee) on (2024-09-26 10:26:24 UTC): UPD: Ohhh, there is no error message, when you export everything, but personal stuff is still not exported.

----

When I try to reproduce, on export I get an error:

```
2024-09-26 10:24:55,350 WARN v2.extract :: Failed to export Cards based on questions outside requested collections: Card 109 (External Checkins from collection 2: Examples) -> Card 108 (Personal Checkins from collection 5: sanya's Personal Collection)
```

piranha (Assginee) on (2024-09-30 13:43:54 UTC): While working on the issue I figured out that escape analysis we do is very incomplete - it checks only for `source-card` and then lets everything else through. And then serialization code figures out all descendants of a card - checking parameters and snippets - and exports data from other collections anyway.

Why is this a problem: I'm merging two different codepaths for extracting data, and it turned out that we have two different ways to limit outgoing data. If you supplied targets, we'll do escape analysis, if you did not - we'll instead limit by public collections (adding user collection if user was supplied).

So now there is one codepath with both of those limits and this breaks one of our tests, where it extracted some cards from non-related collections anyways. I can fix the test no problems, my issue is that there is a good chance we will break someone's workflow.

/cc @luizarakaki

luizarakaki on (2024-09-30 19:46:54 UTC): You the user selects collections, we should serialize only content from those collections...
If they have dependents elsewhere, we should error and explain why.

Wdyt?

"
2533618899,issue,closed,completed,NullPointerException in BigQuery still in > 50.25,"### Describe the bug

A customer just reported that they had this issue and 

### To Reproduce

Seems like this is a native query in BigQuery, but I don't know the conditions (yet)

### Expected behavior

Should work

### Logs

```
2024-09-18 11:20:21.264	
 :data {:rows [], :cols []}}
2024-09-18 11:20:21.264	
 :running_time 0,
2024-09-18 11:20:21.264	
 :row_count 0,
2024-09-18 11:20:21.264	
 :error nil,
2024-09-18 11:20:21.264	
 :context :question,
2024-09-18 11:20:21.264	
 :card_id 1924,
2024-09-18 11:20:21.264	
  ""async.streaming_response$do_f_async$task__52029.invoke(streaming_response.clj:97)""],
2024-09-18 11:20:21.264	
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
2024-09-18 11:20:21.264	
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
2024-09-18 11:20:21.264	
  ""query_processor.streaming$_streaming_response$fn__70064.invoke(streaming.clj:171)""
2024-09-18 11:20:21.264	
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
2024-09-18 11:20:21.264	
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
2024-09-18 11:20:21.264	
  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065.invoke(streaming.clj:174)""
2024-09-18 11:20:21.264	
  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065$fn__70066.invoke(streaming.clj:176)""
2024-09-18 11:20:21.264	
  ""query_processor.card$process_query_for_card_default_run_fn$fn__84624$fn__84625.invoke(card.clj:177)""
2024-09-18 11:20:21.264	
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
2024-09-18 11:20:21.264	
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
2024-09-18 11:20:21.264	
  ""query_processor$process_query.invoke(query_processor.clj:69)""
2024-09-18 11:20:21.264	
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_resolved_database$fn__67153.invoke(setup.clj:128)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_metadata_provider$fn__67159.invoke(setup.clj:150)""
2024-09-18 11:20:21.264	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-09-18 11:20:21.264	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
2024-09-18 11:20:21.264	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-09-18 11:20:21.264	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_metadata_provider$fn__67159$fn__67162.invoke(setup.clj:151)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_driver$fn__67166.invoke(setup.clj:165)""
2024-09-18 11:20:21.264	
  ""driver$do_with_driver.invoke(driver.clj:99)""
2024-09-18 11:20:21.264	
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_driver$fn__67166$fn__67167.invoke(setup.clj:166)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_database_local_settings$fn__67171.invoke(setup.clj:181)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_canceled_chan$fn__67176.invoke(setup.clj:187)""
2024-09-18 11:20:21.264	
  ""query_processor$process_query$fn__76850.invoke(query_processor.clj:78)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76813.invoke(catch_exceptions.clj:128)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76744.invoke(process_userland_query.clj:198)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66772.invoke(enterprise.clj:103)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.enterprise$fn__66761$handle_audit_app_internal_queries__66762$fn__66764.invoke(enterprise.clj:96)""
2024-09-18 11:20:21.264	
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
2024-09-18 11:20:21.264	
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$execute.invoke(execute.clj:87)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
2024-09-18 11:20:21.264	
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$execute$fn__71555.invoke(execute.clj:92)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66744.invoke(enterprise.clj:64)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66734.invoke(enterprise.clj:51)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.permissions$check_query_permissions$fn__66122.invoke(permissions.clj:147)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71481.invoke(cache.clj:238)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71528.invoke(execute.clj:34)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71523.invoke(execute.clj:23)""
2024-09-18 11:20:21.264	
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71508.invoke(update_used_cards.clj:60)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$run.invoke(execute.clj:54)""
2024-09-18 11:20:21.264	
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
2024-09-18 11:20:21.264	
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
2024-09-18 11:20:21.264	
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
2024-09-18 11:20:21.264	
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
2024-09-18 11:20:21.264	
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$fn__130633.invoke(bigquery_cloud_sdk.clj:537)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$fn__130633.invokeStatic(bigquery_cloud_sdk.clj:545)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:506)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:529)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__130626.invoke(bigquery_cloud_sdk.clj:516)""
2024-09-18 11:20:21.264	
  ""driver.bigquery_cloud_sdk$post_process_native.invoke(bigquery_cloud_sdk.clj:483)""
2024-09-18 11:20:21.264	
 [""--> driver.bigquery_cloud_sdk$post_process_native.invokeStatic(bigquery_cloud_sdk.clj:490)""
2024-09-18 11:20:21.264	
 :stacktrace
2024-09-18 11:20:21.264	
 :class java.lang.NullPointerException,
2024-09-18 11:20:21.264	
 :status :failed,
2024-09-18 11:20:21.264	
    :target [""dimension"" [""template-tag"" ""do_not_show_if_flag_set""]]}]},
2024-09-18 11:20:21.264	
    :value nil,
2024-09-18 11:20:21.264	
    :type ""string/="",
2024-09-18 11:20:21.264	
   {:id ""533f8232-d909-44cc-99e5-fe21289ca6f7"",
2024-09-18 11:20:21.264	
    :target [""dimension"" [""template-tag"" ""only_show_if_flag_set""]]}
2024-09-18 11:20:21.264	
    :value nil,
2024-09-18 11:20:21.264	
    :type ""string/="",
2024-09-18 11:20:21.264	
   {:id ""b7fa68c9-e7c4-4867-a40e-9eb51bb8efbc"",
2024-09-18 11:20:21.264	
    :target [""dimension"" [""template-tag"" ""stages_to_hide""]]}
2024-09-18 11:20:21.264	
    :value nil,
2024-09-18 11:20:21.264	
    :type ""string/="",
2024-09-18 11:20:21.264	
   {:id ""03a87557-989b-4a7a-aa80-472778dfae4e"",
2024-09-18 11:20:21.264	
    :target [""dimension"" [""template-tag"" ""flag_with_underscores""]]}
2024-09-18 11:20:21.264	
    :value [""plan_page_hide_slot_booker_for_new_users_with_no_connection""],
2024-09-18 11:20:21.264	
    :type ""string/="",
2024-09-18 11:20:21.264	
   {:id ""84e7a90e-0c58-4b7a-bf63-d04470b67035"",
2024-09-18 11:20:21.264	
    :target [""variable"" [""template-tag"" ""after""]]}
2024-09-18 11:20:21.264	
    :value ""2024-09-02"",
2024-09-18 11:20:21.264	
    :type ""date/single"",
2024-09-18 11:20:21.264	
  [{:id ""5d575d6f-4489-492b-9d42-72ce63e548e4"",
2024-09-18 11:20:21.264	
  :parameters
2024-09-18 11:20:21.264	
  :database 2,
2024-09-18 11:20:21.264	
   :stackable.stack_type nil},
2024-09-18 11:20:21.264	
   :graph.dimensions [""stage"" ""test_group""],
2024-09-18 11:20:21.264	
    :cash_per_user {:color ""#689636""}},
2024-09-18 11:20:21.264	
    :arpu {:color ""#88BF4D""},
2024-09-18 11:20:21.264	
    :trial_cancelled {:color ""#EF8C8C""},
2024-09-18 11:20:21.264	
    :trial_started {:color ""#88BF4D""},
2024-09-18 11:20:21.264	
   {:monthly_arpu {:color ""#88BF4D""},
2024-09-18 11:20:21.264	
   :series_settings
2024-09-18 11:20:21.264	
    ""[\""name\"",\""cash_per_user\""]"" {:number_style ""currency""}},
2024-09-18 11:20:21.264	
    ""[\""name\"",\""monthly_arpu\""]"" {:number_style ""currency""},
2024-09-18 11:20:21.264	
    ""[\""name\"",\""arpu\""]"" {:number_style ""currency""},
2024-09-18 11:20:21.264	
    ""[\""name\"",\""revenue\""]"" {:number_style ""currency""},
2024-09-18 11:20:21.264	
   {""[\""name\"",\""percentage\""]"" {:number_style ""percent""},
2024-09-18 11:20:21.264	
   :column_settings
2024-09-18 11:20:21.264	
   :table.pivot_column ""variation"",
2024-09-18 11:20:21.264	
   :graph.series_order nil,
2024-09-18 11:20:21.264	
   :graph.metrics [""percentage""],
2024-09-18 11:20:21.264	
   :graph.series_order_dimension nil,
2024-09-18 11:20:21.264	
   :table.cell_column ""users"",
2024-09-18 11:20:21.264	
  {:graph.show_values true,
2024-09-18 11:20:21.264	
  :viz-settings
2024-09-18 11:20:21.264	
<redacted>
2024-09-18 11:20:21.264	
   :query
2024-09-18 11:20:21.264	
     :widget-type :string/=}},
2024-09-18 11:20:21.264	
     :dimension [:field 124503 nil],
2024-09-18 11:20:21.264	
     :display-name ""Do Not Show If Flag Set"",
2024-09-18 11:20:21.264	
     :id ""533f8232-d909-44cc-99e5-fe21289ca6f7"",
2024-09-18 11:20:21.264	
     :name ""do_not_show_if_flag_set"",
2024-09-18 11:20:21.264	
    {:type :dimension,
2024-09-18 11:20:21.264	
    ""do_not_show_if_flag_set""
2024-09-18 11:20:21.264	
     :options nil},
2024-09-18 11:20:21.264	
     :widget-type :string/=,
2024-09-18 11:20:21.264	
     :dimension [:field 124503 nil],
2024-09-18 11:20:21.264	
     :default nil,
2024-09-18 11:20:21.264	
     :display-name ""Only Show If Flag Set"",
2024-09-18 11:20:21.264	
     :id ""b7fa68c9-e7c4-4867-a40e-9eb51bb8efbc"",
2024-09-18 11:20:21.264	
     :name ""only_show_if_flag_set"",
2024-09-18 11:20:21.264	
    {:type :dimension,
2024-09-18 11:20:21.264	
    ""only_show_if_flag_set""
2024-09-18 11:20:21.264	
     :widget-type :string/=},
2024-09-18 11:20:21.264	
     :dimension [:field 115709 nil],
2024-09-18 11:20:21.264	
     :display-name ""Stages To Hide"",
2024-09-18 11:20:21.264	
     :id ""03a87557-989b-4a7a-aa80-472778dfae4e"",
2024-09-18 11:20:21.264	
     :name ""stages_to_hide"",
2024-09-18 11:20:21.264	
    {:type :dimension,
2024-09-18 11:20:21.264	
    ""stages_to_hide""
2024-09-18 11:20:21.264	
     :widget-type :string/=},
2024-09-18 11:20:21.264	
     :dimension [:field 124503 nil],
2024-09-18 11:20:21.264	
     :default nil,
2024-09-18 11:20:21.264	
     :display-name ""Flag (with underscores)"",
2024-09-18 11:20:21.264	
     :id ""84e7a90e-0c58-4b7a-bf63-d04470b67035"",
2024-09-18 11:20:21.264	
     :name ""flag_with_underscores"",
2024-09-18 11:20:21.264	
    {:type :dimension,
2024-09-18 11:20:21.264	
    ""flag_with_underscores""
2024-09-18 11:20:21.264	
     :widget-type nil},
2024-09-18 11:20:21.264	
     :default nil,
2024-09-18 11:20:21.264	
     :display-name ""After"",
2024-09-18 11:20:21.264	
     :id ""5d575d6f-4489-492b-9d42-72ce63e548e4"",
2024-09-18 11:20:21.264	
     :name ""after"",
2024-09-18 11:20:21.264	
    {:type :date,
2024-09-18 11:20:21.264	
   {""after""
2024-09-18 11:20:21.264	
  {:template-tags
2024-09-18 11:20:21.264	
  :native
2024-09-18 11:20:21.264	
  :cache-strategy {:multiplier 20, :min_duration_ms 1, :type :ttl, :avg-execution-ms 639109},
2024-09-18 11:20:21.264	
  {:js-int-to-string? true, :ignore-cached-results? true, :process-viz-settings? false, :userland-query? true},
2024-09-18 11:20:21.264	
  :middleware
2024-09-18 11:20:21.264	
  :type :native,
2024-09-18 11:20:21.264	
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
2024-09-18 11:20:21.264	
 :json_query
2024-09-18 11:20:21.264	
 :action_id nil,
2024-09-18 11:20:21.264	
 :started_at #t ""2024-09-18T11:16:10.188873Z[GMT]"",
2024-09-18 11:20:21.264	
{:database_id 2,
2024-09-18 11:20:21.264	
2024-09-18 11:20:21,263 ERROR middleware.catch-exceptions :: Error processing query: Error running query
```

### Information about your Metabase installation

```JSON
v50.25.x
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-09-18 12:33:24+00:00,['snoe'],2024-10-04 18:11:05+00:00,2024-10-02 21:46:50+00:00,https://github.com/metabase/metabase/issues/47990,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/BigQuery', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2362062713, 'issue_id': 2533618899, 'author': 'snoe', 'body': 'https://github.com/metabase/metabase/issues/47339 made it into 50.26 so we should look there.', 'created_at': datetime.datetime(2024, 9, 19, 19, 55, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2362191756, 'issue_id': 2533618899, 'author': 'paoliniluis', 'body': '@snoe now I\'m seeing\r\n```\r\n2024-09-19 20:55:19.351\t\r\n2024-09-19 20:55:19.351\t\r\n :data {:rows [], :cols []}}\r\n2024-09-19 20:55:19.351\t\r\n   :aggregation [[:aggregation-options [:count] {:name ""count""}]]}},\r\n2024-09-19 20:55:19.351\t\r\n   :order-by [[:desc [:aggregation 0]] [:asc [:expression ""slug""]]],\r\n2024-09-19 20:55:19.351\t\r\n   :breakout [[:expression ""slug""]],\r\n2024-09-19 20:55:19.351\t\r\n   :expressions {""slug"" [:replace [:replace [:field 3075 nil] ""/reviews"" """"] ""/brands/"" """"]},\r\n2024-09-19 20:55:19.351\t\r\n   :source-table 172,\r\n2024-09-19 20:55:19.351\t\r\n    [:= [:expression ""slug""] [:value ""split-nutrition"" nil]]],\r\n2024-09-19 20:55:19.351\t\r\n    [:< [:field 3078 {:temporal-unit :default}] [:relative-datetime 1 :month]]\r\n2024-09-19 20:55:19.351\t\r\n    [:>= [:field 3078 {:temporal-unit :default}] [:relative-datetime -6 :month]]\r\n2024-09-19 20:55:19.351\t\r\n     {:case-sensitive false}]\r\n2024-09-19 20:55:19.351\t\r\n       :name ""context_page_path""}]\r\n2024-09-19 20:55:19.351\t\r\n       :database_type ""STRING"",\r\n2024-09-19 20:55:19.351\t\r\n       :semantic_type :type/Category,\r\n2024-09-19 20:55:19.351\t\r\n       :coercion_strategy nil,\r\n2024-09-19 20:55:19.351\t\r\n       :effective_type :type/Text,\r\n2024-09-19 20:55:19.351\t\r\n      {:base_type :type/Text,\r\n2024-09-19 20:55:19.351\t\r\n      ""/brands/""\r\n2024-09-19 20:55:19.351\t\r\n     [:value\r\n2024-09-19 20:55:19.351\t\r\n     [:field 3075 nil]\r\n2024-09-19 20:55:19.351\t\r\n    [:contains\r\n2024-09-19 20:55:19.351\t\r\n   [:and\r\n2024-09-19 20:55:19.351\t\r\n   :filter\r\n2024-09-19 20:55:19.351\t\r\n     :source-table 7044}],\r\n2024-09-19 20:55:19.351\t\r\n     :condition [:= [:expression ""slug""] [:field 45366 {:join-alias ""brands""}]],\r\n2024-09-19 20:55:19.351\t\r\n     :fields [[:field 45403 {:join-alias ""brands""}]],\r\n2024-09-19 20:55:19.351\t\r\n     :strategy :left-join,\r\n2024-09-19 20:55:19.351\t\r\n   [{:alias ""brands"",\r\n2024-09-19 20:55:19.351\t\r\n   :joins\r\n2024-09-19 20:55:19.351\t\r\n  {:limit 1,\r\n2024-09-19 20:55:19.351\t\r\n  :query\r\n2024-09-19 20:55:19.351\t\r\n  :database 3,\r\n2024-09-19 20:55:19.351\t\r\n   :visualization-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""}},\r\n2024-09-19 20:55:19.351\t\r\n   :dashboard-id 1255,\r\n2024-09-19 20:55:19.351\t\r\n   :card-name ""# of times reviews have been read"",\r\n2024-09-19 20:55:19.351\t\r\n   :card-id 6721,\r\n2024-09-19 20:55:19.351\t\r\n  {:context :embedded-dashboard,\r\n2024-09-19 20:55:19.351\t\r\n  :info\r\n2024-09-19 20:55:19.351\t\r\n  :viz-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""},\r\n2024-09-19 20:55:19.351\t\r\n    :target [:dimension [:expression ""slug""]]}],\r\n2024-09-19 20:55:19.351\t\r\n    :id ""a9621052"",\r\n2024-09-19 20:55:19.351\t\r\n    :slug ""slug"",\r\n2024-09-19 20:55:19.351\t\r\n    :type :string/=,\r\n2024-09-19 20:55:19.351\t\r\n   {:value [:split-nutrition],\r\n2024-09-19 20:55:19.351\t\r\n    :target [:dimension [:field 3078 nil]]}\r\n2024-09-19 20:55:19.351\t\r\n    :id ""aede3cf4"",\r\n2024-09-19 20:55:19.351\t\r\n    :slug ""date_filter"",\r\n2024-09-19 20:55:19.351\t\r\n    :type :date/all-options,\r\n2024-09-19 20:55:19.351\t\r\n  [{:value ""past6months~"",\r\n2024-09-19 20:55:19.351\t\r\n  :user-parameters\r\n2024-09-19 20:55:19.351\t\r\n  :cache-strategy {:multiplier 10, :min-duration-ms 60000, :type :ttl, :avg-execution-ms 0},\r\n2024-09-19 20:55:19.351\t\r\n  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},\r\n2024-09-19 20:55:19.351\t\r\n  :type :query,\r\n2024-09-19 20:55:19.351\t\r\n {:constraints {:max-results 10000, :max-results-bare-rows 2000},\r\n2024-09-19 20:55:19.351\t\r\n :preprocessed\r\n2024-09-19 20:55:19.351\t\r\n :running_time 0,\r\n2024-09-19 20:55:19.351\t\r\n :row_count 0,\r\n2024-09-19 20:55:19.351\t\r\n :error ""Assert failed: (some? %)"",\r\n2024-09-19 20:55:19.351\t\r\n :context :embedded-dashboard,\r\n2024-09-19 20:55:19.351\t\r\n :card_id 6721,\r\n2024-09-19 20:55:19.351\t\r\n  ""async.streaming_response$do_f_async$task__52030.invoke(streaming_response.clj:97)""],\r\n2024-09-19 20:55:19.351\t\r\n  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""\r\n2024-09-19 20:55:19.351\t\r\n  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.streaming$_streaming_response$fn__70131.invoke(streaming.clj:171)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.streaming$_streaming_response$fn__70131$fn__70132.invoke(streaming.clj:174)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.streaming$_streaming_response$fn__70131$fn__70132$fn__70133.invoke(streaming.clj:176)""\r\n2024-09-19 20:55:19.351\t\r\n  ""api.public$process_query_for_card_with_id_run_fn$run__97095$fn__97096.invoke(public.clj:139)""\r\n2024-09-19 20:55:19.351\t\r\n  ""server.middleware.session$do_with_current_user.invoke(session.clj:405)""\r\n2024-09-19 20:55:19.351\t\r\n  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)""\r\n2024-09-19 20:55:19.351\t\r\n  ""api.public$process_query_for_card_with_id_run_fn$run__97095$fn__97096$fn__97097.invoke(public.clj:140)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor$process_query.invoke(query_processor.clj:69)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_resolved_database$fn__67220.invoke(setup.clj:128)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_metadata_provider$fn__67226.invoke(setup.clj:150)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_metadata_provider$fn__67226$fn__67229.invoke(setup.clj:151)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_driver$fn__67233.invoke(setup.clj:165)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver$do_with_driver.invoke(driver.clj:99)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver$do_with_driver.invokeStatic(driver.clj:104)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_driver$fn__67233$fn__67234.invoke(setup.clj:166)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_database_local_settings$fn__67238.invoke(setup.clj:181)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_canceled_chan$fn__67243.invoke(setup.clj:187)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor$process_query$fn__76917.invoke(query_processor.clj:78)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76880.invoke(catch_exceptions.clj:128)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76811.invoke(process_userland_query.clj:198)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66839.invoke(enterprise.clj:103)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.enterprise$fn__66828$handle_audit_app_internal_queries__66829$fn__66831.invoke(enterprise.clj:96)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$execute.invoke(execute.clj:87)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$execute$fn__71622.invoke(execute.clj:92)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66811.invoke(enterprise.clj:64)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66801.invoke(enterprise.clj:51)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.permissions$check_query_permissions$fn__66189.invoke(permissions.clj:147)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71548.invoke(cache.clj:238)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71595.invoke(execute.clj:34)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$add_native_form_to_result_metadata$fn__71590.invoke(execute.clj:23)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71575.invoke(update_used_cards.clj:60)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$run.invoke(execute.clj:54)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.execute$run.invokeStatic(execute.clj:60)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$fn__128745.invoke(bigquery_cloud_sdk.clj:540)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$fn__128745.invokeStatic(bigquery_cloud_sdk.clj:548)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:509)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:532)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128736.invoke(bigquery_cloud_sdk.clj:519)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$post_process_native.invoke(bigquery_cloud_sdk.clj:484)""\r\n2024-09-19 20:55:19.351\t\r\n  ""driver.bigquery_cloud_sdk$post_process_native.invokeStatic(bigquery_cloud_sdk.clj:505)""\r\n2024-09-19 20:55:19.351\t\r\n  ""query_processor.pipeline$_STAR_run_STAR_$respond__56964.invoke(pipeline.clj:95)""\r\n2024-09-19 20:55:19.351\t\r\n [""--> query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71534.invoke(cache.clj:204)""\r\n2024-09-19 20:55:19.351\t\r\n :stacktrace\r\n2024-09-19 20:55:19.351\t\r\n :class java.lang.AssertionError,\r\n2024-09-19 20:55:19.351\t\r\n :status :failed,\r\n2024-09-19 20:55:19.351\t\r\n  :mbql? true},\r\n2024-09-19 20:55:19.351\t\r\n  :table-name ""review_read"",\r\n2024-09-19 20:55:19.351\t\r\n  :params (""/reviews"" """" ""/brands/"" """" ""/reviews"" """" ""/brands/"" """" ""%/brands/%"" ""split-nutrition""),\r\n2024-09-19 20:55:19.351\t\r\n  ""SELECT `source`.`slug` AS `slug`, COUNT(*) AS `count` FROM (SELECT `client_prod.review_read`.`context_page_path` AS `context_page_path`, `client_prod.review_read`.`timestamp` AS `timestamp`, REPLACE(REPLACE(`client_prod.review_read`.`context_page_path`, ?, ?), ?, ?) AS `slug`, `brands`.`id` AS `brands__id`, `brands`.`slug` AS `brands__slug` FROM `client_prod.review_read` LEFT JOIN `postgres_production.brands` AS `brands` ON REPLACE(REPLACE(`client_prod.review_read`.`context_page_path`, ?, ?), ?, ?) = `brands`.`slug`) AS `source` WHERE (LOWER(`source`.`context_page_path`) LIKE ?) AND (`source`.`timestamp` >= TIMESTAMP_TRUNC(TIMESTAMP(DATETIME_ADD(CURRENT_DATETIME(\'UTC\'), INTERVAL -6 month), \'UTC\'), month, \'UTC\')) AND (`source`.`timestamp` < TIMESTAMP_TRUNC(TIMESTAMP(DATETIME_ADD(CURRENT_DATETIME(\'UTC\'), INTERVAL 1 month), \'UTC\'), month, \'UTC\')) AND (`source`.`slug` = ?) GROUP BY `slug` ORDER BY `count` DESC, `slug` ASC LIMIT 1"",\r\n2024-09-19 20:55:19.351\t\r\n {:query\r\n2024-09-19 20:55:19.351\t\r\n :native\r\n2024-09-19 20:55:19.351\t\r\n    :target [:dimension [:expression ""slug""]]}]},\r\n2024-09-19 20:55:19.351\t\r\n    :id ""a9621052"",\r\n2024-09-19 20:55:19.351\t\r\n    :slug ""slug"",\r\n2024-09-19 20:55:19.351\t\r\n    :value [""split-nutrition""],\r\n2024-09-19 20:55:19.351\t\r\n   {:type :string/=,\r\n2024-09-19 20:55:19.351\t\r\n    :target [:dimension [:field 3078 nil]]}\r\n2024-09-19 20:55:19.351\t\r\n    :id ""aede3cf4"",\r\n2024-09-19 20:55:19.351\t\r\n    :slug ""date_filter"",\r\n2024-09-19 20:55:19.351\t\r\n    :value ""past6months~"",\r\n2024-09-19 20:55:19.351\t\r\n  [{:type :date/all-options,\r\n2024-09-19 20:55:19.351\t\r\n  :parameters\r\n2024-09-19 20:55:19.351\t\r\n   :filter [:contains [:field 3075 nil] ""/brands/"" {:case-sensitive false}]},\r\n2024-09-19 20:55:19.351\t\r\n   :aggregation [[:count]],\r\n2024-09-19 20:55:19.351\t\r\n   :order-by [[:desc [:aggregation 0]]],\r\n2024-09-19 20:55:19.351\t\r\n   :breakout [[:expression ""slug""]],\r\n2024-09-19 20:55:19.351\t\r\n   :expressions {""slug"" [:replace [:replace [:field 3075 nil] ""/reviews"" """"] ""/brands/"" """"]},\r\n2024-09-19 20:55:19.351\t\r\n   :source-table 172,\r\n2024-09-19 20:55:19.351\t\r\n     :source-table 7044}],\r\n2024-09-19 20:55:19.351\t\r\n     :condition [:= [:expression ""slug""] [:field 45366 {:join-alias ""brands""}]],\r\n2024-09-19 20:55:19.351\t\r\n     :alias ""brands"",\r\n2024-09-19 20:55:19.351\t\r\n   [{:fields [[:field 45403 {:join-alias ""brands""}]],\r\n2024-09-19 20:55:19.351\t\r\n   :joins\r\n2024-09-19 20:55:19.351\t\r\n  {:limit 1,\r\n2024-09-19 20:55:19.351\t\r\n  :query\r\n2024-09-19 20:55:19.351\t\r\n  :database 3,\r\n2024-09-19 20:55:19.351\t\r\n  :viz-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""},\r\n2024-09-19 20:55:19.351\t\r\n  :cache-strategy {:multiplier 10, :min_duration_ms 60000, :type :ttl, :avg-execution-ms 0},\r\n2024-09-19 20:55:19.351\t\r\n  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},\r\n2024-09-19 20:55:19.351\t\r\n  :type :query,\r\n2024-09-19 20:55:19.351\t\r\n {:constraints {:max-results 10000, :max-results-bare-rows 2000},\r\n2024-09-19 20:55:19.351\t\r\n :json_query\r\n2024-09-19 20:55:19.351\t\r\n :action_id nil,\r\n2024-09-19 20:55:19.351\t\r\n :started_at #t ""2024-09-19T20:55:18.302507Z[GMT]"",\r\n2024-09-19 20:55:19.351\t\r\n{:database_id 3,\r\n2024-09-19 20:55:19.351\t\r\n2024-09-19 20:55:19,350 ERROR middleware.catch-exceptions :: Error processing query: Assert failed: (some? %)\r\n```\r\n\r\ndefinitely a different issue but there are errors on the logs which I think cause issues on the query run', 'created_at': datetime.datetime(2024, 9, 19, 21, 2, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364560766, 'issue_id': 2533618899, 'author': 'snoe', 'body': ""@paoliniluis have you had any luck reproducing this? I could get stacktraces like this by modifying the code, but maybe there's something about the datasets."", 'created_at': datetime.datetime(2024, 9, 20, 20, 21, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389408797, 'issue_id': 2533618899, 'author': 'lzrdbrain', 'body': 'I just started experiencing this issue last night around 7:00 PM MDT.  Did something change last night?\n\nhere is my diagnostic info. \n{\n  ""browser-info"": {\n    ""language"": ""en-US"",\n    ""platform"": ""MacIntel"",\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",\n    ""vendor"": ""Google Inc.""\n  },\n  ""metabase-info"": {\n    ""databases"": [\n      ""postgres"",\n      ""h2"",\n      ""bigquery-cloud-sdk""\n    ],\n    ""run-mode"": ""prod"",\n    ""plan-alias"": ""pro-cloud"",\n    ""version"": {\n      ""date"": ""2024-09-12"",\n      ""tag"": ""v1.50.25.2"",\n      ""hash"": ""e7db719""\n    },\n    ""settings"": {\n      ""report-timezone"": ""US/Eastern""\n    },\n    ""hosting-env"": ""unknown"",\n    ""application-database"": ""postgres""\n  }\n}\n\nHere is the error message from the logs:\n[ea493f04-a921-49bf-aac5-3afe609291ed] 2024-10-02T09:24:12-06:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Error running query\n{:database_id 34,\n :started_at #t ""2024-10-02T15:23:57.581596Z[GMT]"",\n :action_id nil,\n :json_query\n {:constraints {:max-results 10000, :max-results-bare-rows 2000},\n  :type :native,\n  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},\n  :cache-strategy nil,\n  :native\n  {:template-tags\n   {""org_id_ext_str""\n    {:type :dimension,\n     :name ""org_id_ext_str"",\n     :id ""10401e4f-6511-4b1d-978f-18bc09242612"",\n     :display-name ""Org ID Ext Str"",\n     :widget-type :string/=,\n     :dimension [:field 21428 nil]}},\n   :collection ""marketing_contacts"",\n   :query\n   ""SELECT\\n CASE \\nWHEN `age` <20 THEN \'<20\'\\nWHEN `age` <30 THEN \'20-30\'\\nWHEN `age` <40 THEN \'30-40\'\\nWHEN `age` <50 THEN \'40-50\'\\nWHEN `age` <60 THEN \'50-60\'\\nWHEN `age` <70 THEN \'60-70\'\\nWHEN `age` <80 THEN \'70-80\'\\nWHEN `age` >= 80 THEN \'80+\'\\nELSE \'Other\'\\nEND as age_bucket,\\nCOUNT(*) as customers\\nFROM\\n  `richard_experimental_dataset.demo_cache_marketing_ltv`\\n  \\nWHERE `age` IS NOT NULL\\nAND {{org_id_ext_str}}\\nGROUP BY\\n`age`\\nORDER BY\\n  `age` ASC\\n\\n  \\n""},\n  :viz-settings\n  {:graph.show_values true,\n   :graph.dimensions [""age_bucket""],\n   :graph.x_axis.title_text ""Age Bucket"",\n   :graph.y_axis.title_text ""# customers"",\n   :graph.metrics [""customers""],\n   :card.title ""Most Common Customer Age Group""},\n  :database 34,\n  :parameters\n  [{:type :string/=,\n    :value [""org_Nqc3Db3p5N1""],\n    :slug ""org_id_ext_str"",\n    :id ""bfec6736"",\n    :target [:dimension [:template-tag ""org_id_ext_str""]]}]},\n :status :failed,\n :class java.lang.NullPointerException,\n :stacktrace\n [""--> driver.bigquery_cloud_sdk$post_process_native.invokeStatic(bigquery_cloud_sdk.clj:490)""\n  ""driver.bigquery_cloud_sdk$post_process_native.invoke(bigquery_cloud_sdk.clj:483)""\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__130626.invoke(bigquery_cloud_sdk.clj:516)""\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:529)""\n  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:506)""\n  ""driver.bigquery_cloud_sdk$fn__130633.invokeStatic(bigquery_cloud_sdk.clj:545)""\n  ""driver.bigquery_cloud_sdk$fn__130633.invoke(bigquery_cloud_sdk.clj:537)""\n  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""\n  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""\n  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""\n  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""\n  ""query_processor.execute$run.invokeStatic(execute.clj:60)""\n  ""query_processor.execute$run.invoke(execute.clj:54)""\n  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71508.invoke(update_used_cards.clj:60)""\n  ""query_processor.execute$add_native_form_to_result_metadata$fn__71523.invoke(execute.clj:23)""\n  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71528.invoke(execute.clj:34)""\n  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71481.invoke(cache.clj:239)""\n  ""query_processor.middleware.permissions$check_query_permissions$fn__66122.invoke(permissions.clj:147)""\n  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__108749$check_download_permissions__108750$fn__108751.invoke(permissions.clj:90)""\n  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66734.invoke(enterprise.clj:51)""\n  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__110580$maybe_apply_column_level_perms_check__110581$fn__110582.invoke(column_level_perms_check.clj:38)""\n  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66744.invoke(enterprise.clj:64)""\n  ""query_processor.execute$execute$fn__71555.invoke(execute.clj:92)""\n  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""\n  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""\n  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""\n  ""query_processor.execute$execute.invoke(execute.clj:87)""\n  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""\n  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""\n  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__82876$handle_audit_app_internal_queries__82877$fn__82878.invoke(handle_audit_queries.clj:145)""\n  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66772.invoke(enterprise.clj:103)""\n  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76744.invoke(process_userland_query.clj:198)""\n  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76813.invoke(catch_exceptions.clj:128)""\n  ""query_processor$process_query$fn__76850.invoke(query_processor.clj:78)""\n  ""query_processor.setup$do_with_canceled_chan$fn__67176.invoke(setup.clj:187)""\n  ""query_processor.setup$do_with_database_local_settings$fn__67171.invoke(setup.clj:181)""\n  ""query_processor.setup$do_with_driver$fn__67166$fn__67167.invoke(setup.clj:166)""\n  ""driver$do_with_driver.invokeStatic(driver.clj:104)""\n  ""driver$do_with_driver.invoke(driver.clj:99)""\n  ""query_processor.setup$do_with_driver$fn__67166.invoke(setup.clj:165)""\n  ""query_processor.setup$do_with_metadata_provider$fn__67159$fn__67162.invoke(setup.clj:151)""\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\n  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""\n  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\n  ""query_processor.setup$do_with_metadata_provider$fn__67159.invoke(setup.clj:150)""\n  ""query_processor.setup$do_with_resolved_database$fn__67153.invoke(setup.clj:128)""\n  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""\n  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""\n  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""\n  ""query_processor$process_query.invoke(query_processor.clj:69)""\n  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""\n  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""\n  ""api.public$process_query_for_card_with_id_run_fn$run__97015$fn__97016$fn__97017.invoke(public.clj:140)""\n  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)""\n  ""server.middleware.session$do_with_current_user.invoke(session.clj:405)""\n  ""api.public$process_query_for_card_with_id_run_fn$run__97015$fn__97016.invoke(public.clj:139)""\n  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065$fn__70066.invoke(streaming.clj:176)""\n  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065.invoke(streaming.clj:174)""\n  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""\n  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""\n  ""query_processor.streaming$_streaming_response$fn__70064.invoke(streaming.clj:171)""\n  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""\n  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""\n  ""async.streaming_response$do_f_async$task__52029.invoke(streaming_response.clj:97)""],\n :card_id 414,\n :context :embedded-dashboard,\n :error nil,\n :row_count 0,\n :running_time 0,\n :data {:rows [], :cols []}}', 'created_at': datetime.datetime(2024, 10, 2, 18, 25, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390709333, 'issue_id': 2533618899, 'author': 'paoliniluis', 'body': '@lzrdbrain please contact support so we can help', 'created_at': datetime.datetime(2024, 10, 3, 7, 25, 52, tzinfo=datetime.timezone.utc)}]","snoe (Assginee) on (2024-09-19 19:55:53 UTC): https://github.com/metabase/metabase/issues/47339 made it into 50.26 so we should look there.

paoliniluis (Issue Creator) on (2024-09-19 21:02:33 UTC): @snoe now I'm seeing
```
2024-09-19 20:55:19.351	
2024-09-19 20:55:19.351	
 :data {:rows [], :cols []}}
2024-09-19 20:55:19.351	
   :aggregation [[:aggregation-options [:count] {:name ""count""}]]}},
2024-09-19 20:55:19.351	
   :order-by [[:desc [:aggregation 0]] [:asc [:expression ""slug""]]],
2024-09-19 20:55:19.351	
   :breakout [[:expression ""slug""]],
2024-09-19 20:55:19.351	
   :expressions {""slug"" [:replace [:replace [:field 3075 nil] ""/reviews"" """"] ""/brands/"" """"]},
2024-09-19 20:55:19.351	
   :source-table 172,
2024-09-19 20:55:19.351	
    [:= [:expression ""slug""] [:value ""split-nutrition"" nil]]],
2024-09-19 20:55:19.351	
    [:< [:field 3078 {:temporal-unit :default}] [:relative-datetime 1 :month]]
2024-09-19 20:55:19.351	
    [:>= [:field 3078 {:temporal-unit :default}] [:relative-datetime -6 :month]]
2024-09-19 20:55:19.351	
     {:case-sensitive false}]
2024-09-19 20:55:19.351	
       :name ""context_page_path""}]
2024-09-19 20:55:19.351	
       :database_type ""STRING"",
2024-09-19 20:55:19.351	
       :semantic_type :type/Category,
2024-09-19 20:55:19.351	
       :coercion_strategy nil,
2024-09-19 20:55:19.351	
       :effective_type :type/Text,
2024-09-19 20:55:19.351	
      {:base_type :type/Text,
2024-09-19 20:55:19.351	
      ""/brands/""
2024-09-19 20:55:19.351	
     [:value
2024-09-19 20:55:19.351	
     [:field 3075 nil]
2024-09-19 20:55:19.351	
    [:contains
2024-09-19 20:55:19.351	
   [:and
2024-09-19 20:55:19.351	
   :filter
2024-09-19 20:55:19.351	
     :source-table 7044}],
2024-09-19 20:55:19.351	
     :condition [:= [:expression ""slug""] [:field 45366 {:join-alias ""brands""}]],
2024-09-19 20:55:19.351	
     :fields [[:field 45403 {:join-alias ""brands""}]],
2024-09-19 20:55:19.351	
     :strategy :left-join,
2024-09-19 20:55:19.351	
   [{:alias ""brands"",
2024-09-19 20:55:19.351	
   :joins
2024-09-19 20:55:19.351	
  {:limit 1,
2024-09-19 20:55:19.351	
  :query
2024-09-19 20:55:19.351	
  :database 3,
2024-09-19 20:55:19.351	
   :visualization-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""}},
2024-09-19 20:55:19.351	
   :dashboard-id 1255,
2024-09-19 20:55:19.351	
   :card-name ""# of times reviews have been read"",
2024-09-19 20:55:19.351	
   :card-id 6721,
2024-09-19 20:55:19.351	
  {:context :embedded-dashboard,
2024-09-19 20:55:19.351	
  :info
2024-09-19 20:55:19.351	
  :viz-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""},
2024-09-19 20:55:19.351	
    :target [:dimension [:expression ""slug""]]}],
2024-09-19 20:55:19.351	
    :id ""a9621052"",
2024-09-19 20:55:19.351	
    :slug ""slug"",
2024-09-19 20:55:19.351	
    :type :string/=,
2024-09-19 20:55:19.351	
   {:value [:split-nutrition],
2024-09-19 20:55:19.351	
    :target [:dimension [:field 3078 nil]]}
2024-09-19 20:55:19.351	
    :id ""aede3cf4"",
2024-09-19 20:55:19.351	
    :slug ""date_filter"",
2024-09-19 20:55:19.351	
    :type :date/all-options,
2024-09-19 20:55:19.351	
  [{:value ""past6months~"",
2024-09-19 20:55:19.351	
  :user-parameters
2024-09-19 20:55:19.351	
  :cache-strategy {:multiplier 10, :min-duration-ms 60000, :type :ttl, :avg-execution-ms 0},
2024-09-19 20:55:19.351	
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
2024-09-19 20:55:19.351	
  :type :query,
2024-09-19 20:55:19.351	
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
2024-09-19 20:55:19.351	
 :preprocessed
2024-09-19 20:55:19.351	
 :running_time 0,
2024-09-19 20:55:19.351	
 :row_count 0,
2024-09-19 20:55:19.351	
 :error ""Assert failed: (some? %)"",
2024-09-19 20:55:19.351	
 :context :embedded-dashboard,
2024-09-19 20:55:19.351	
 :card_id 6721,
2024-09-19 20:55:19.351	
  ""async.streaming_response$do_f_async$task__52030.invoke(streaming_response.clj:97)""],
2024-09-19 20:55:19.351	
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
2024-09-19 20:55:19.351	
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
2024-09-19 20:55:19.351	
  ""query_processor.streaming$_streaming_response$fn__70131.invoke(streaming.clj:171)""
2024-09-19 20:55:19.351	
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
2024-09-19 20:55:19.351	
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
2024-09-19 20:55:19.351	
  ""query_processor.streaming$_streaming_response$fn__70131$fn__70132.invoke(streaming.clj:174)""
2024-09-19 20:55:19.351	
  ""query_processor.streaming$_streaming_response$fn__70131$fn__70132$fn__70133.invoke(streaming.clj:176)""
2024-09-19 20:55:19.351	
  ""api.public$process_query_for_card_with_id_run_fn$run__97095$fn__97096.invoke(public.clj:139)""
2024-09-19 20:55:19.351	
  ""server.middleware.session$do_with_current_user.invoke(session.clj:405)""
2024-09-19 20:55:19.351	
  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)""
2024-09-19 20:55:19.351	
  ""api.public$process_query_for_card_with_id_run_fn$run__97095$fn__97096$fn__97097.invoke(public.clj:140)""
2024-09-19 20:55:19.351	
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
2024-09-19 20:55:19.351	
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
2024-09-19 20:55:19.351	
  ""query_processor$process_query.invoke(query_processor.clj:69)""
2024-09-19 20:55:19.351	
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_resolved_database$fn__67220.invoke(setup.clj:128)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_metadata_provider$fn__67226.invoke(setup.clj:150)""
2024-09-19 20:55:19.351	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-09-19 20:55:19.351	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
2024-09-19 20:55:19.351	
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
2024-09-19 20:55:19.351	
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_metadata_provider$fn__67226$fn__67229.invoke(setup.clj:151)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_driver$fn__67233.invoke(setup.clj:165)""
2024-09-19 20:55:19.351	
  ""driver$do_with_driver.invoke(driver.clj:99)""
2024-09-19 20:55:19.351	
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_driver$fn__67233$fn__67234.invoke(setup.clj:166)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_database_local_settings$fn__67238.invoke(setup.clj:181)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_canceled_chan$fn__67243.invoke(setup.clj:187)""
2024-09-19 20:55:19.351	
  ""query_processor$process_query$fn__76917.invoke(query_processor.clj:78)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76880.invoke(catch_exceptions.clj:128)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76811.invoke(process_userland_query.clj:198)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66839.invoke(enterprise.clj:103)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.enterprise$fn__66828$handle_audit_app_internal_queries__66829$fn__66831.invoke(enterprise.clj:96)""
2024-09-19 20:55:19.351	
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
2024-09-19 20:55:19.351	
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$execute.invoke(execute.clj:87)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
2024-09-19 20:55:19.351	
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$execute$fn__71622.invoke(execute.clj:92)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66811.invoke(enterprise.clj:64)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66801.invoke(enterprise.clj:51)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.permissions$check_query_permissions$fn__66189.invoke(permissions.clj:147)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71548.invoke(cache.clj:238)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:185)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:212)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71595.invoke(execute.clj:34)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71590.invoke(execute.clj:23)""
2024-09-19 20:55:19.351	
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71575.invoke(update_used_cards.clj:60)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$run.invoke(execute.clj:54)""
2024-09-19 20:55:19.351	
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
2024-09-19 20:55:19.351	
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
2024-09-19 20:55:19.351	
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
2024-09-19 20:55:19.351	
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
2024-09-19 20:55:19.351	
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$fn__128745.invoke(bigquery_cloud_sdk.clj:540)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$fn__128745.invokeStatic(bigquery_cloud_sdk.clj:548)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:509)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:532)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128736.invoke(bigquery_cloud_sdk.clj:519)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$post_process_native.invoke(bigquery_cloud_sdk.clj:484)""
2024-09-19 20:55:19.351	
  ""driver.bigquery_cloud_sdk$post_process_native.invokeStatic(bigquery_cloud_sdk.clj:505)""
2024-09-19 20:55:19.351	
  ""query_processor.pipeline$_STAR_run_STAR_$respond__56964.invoke(pipeline.clj:95)""
2024-09-19 20:55:19.351	
 [""--> query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___71534.invoke(cache.clj:204)""
2024-09-19 20:55:19.351	
 :stacktrace
2024-09-19 20:55:19.351	
 :class java.lang.AssertionError,
2024-09-19 20:55:19.351	
 :status :failed,
2024-09-19 20:55:19.351	
  :mbql? true},
2024-09-19 20:55:19.351	
  :table-name ""review_read"",
2024-09-19 20:55:19.351	
  :params (""/reviews"" """" ""/brands/"" """" ""/reviews"" """" ""/brands/"" """" ""%/brands/%"" ""split-nutrition""),
2024-09-19 20:55:19.351	
  ""SELECT `source`.`slug` AS `slug`, COUNT(*) AS `count` FROM (SELECT `client_prod.review_read`.`context_page_path` AS `context_page_path`, `client_prod.review_read`.`timestamp` AS `timestamp`, REPLACE(REPLACE(`client_prod.review_read`.`context_page_path`, ?, ?), ?, ?) AS `slug`, `brands`.`id` AS `brands__id`, `brands`.`slug` AS `brands__slug` FROM `client_prod.review_read` LEFT JOIN `postgres_production.brands` AS `brands` ON REPLACE(REPLACE(`client_prod.review_read`.`context_page_path`, ?, ?), ?, ?) = `brands`.`slug`) AS `source` WHERE (LOWER(`source`.`context_page_path`) LIKE ?) AND (`source`.`timestamp` >= TIMESTAMP_TRUNC(TIMESTAMP(DATETIME_ADD(CURRENT_DATETIME('UTC'), INTERVAL -6 month), 'UTC'), month, 'UTC')) AND (`source`.`timestamp` < TIMESTAMP_TRUNC(TIMESTAMP(DATETIME_ADD(CURRENT_DATETIME('UTC'), INTERVAL 1 month), 'UTC'), month, 'UTC')) AND (`source`.`slug` = ?) GROUP BY `slug` ORDER BY `count` DESC, `slug` ASC LIMIT 1"",
2024-09-19 20:55:19.351	
 {:query
2024-09-19 20:55:19.351	
 :native
2024-09-19 20:55:19.351	
    :target [:dimension [:expression ""slug""]]}]},
2024-09-19 20:55:19.351	
    :id ""a9621052"",
2024-09-19 20:55:19.351	
    :slug ""slug"",
2024-09-19 20:55:19.351	
    :value [""split-nutrition""],
2024-09-19 20:55:19.351	
   {:type :string/=,
2024-09-19 20:55:19.351	
    :target [:dimension [:field 3078 nil]]}
2024-09-19 20:55:19.351	
    :id ""aede3cf4"",
2024-09-19 20:55:19.351	
    :slug ""date_filter"",
2024-09-19 20:55:19.351	
    :value ""past6months~"",
2024-09-19 20:55:19.351	
  [{:type :date/all-options,
2024-09-19 20:55:19.351	
  :parameters
2024-09-19 20:55:19.351	
   :filter [:contains [:field 3075 nil] ""/brands/"" {:case-sensitive false}]},
2024-09-19 20:55:19.351	
   :aggregation [[:count]],
2024-09-19 20:55:19.351	
   :order-by [[:desc [:aggregation 0]]],
2024-09-19 20:55:19.351	
   :breakout [[:expression ""slug""]],
2024-09-19 20:55:19.351	
   :expressions {""slug"" [:replace [:replace [:field 3075 nil] ""/reviews"" """"] ""/brands/"" """"]},
2024-09-19 20:55:19.351	
   :source-table 172,
2024-09-19 20:55:19.351	
     :source-table 7044}],
2024-09-19 20:55:19.351	
     :condition [:= [:expression ""slug""] [:field 45366 {:join-alias ""brands""}]],
2024-09-19 20:55:19.351	
     :alias ""brands"",
2024-09-19 20:55:19.351	
   [{:fields [[:field 45403 {:join-alias ""brands""}]],
2024-09-19 20:55:19.351	
   :joins
2024-09-19 20:55:19.351	
  {:limit 1,
2024-09-19 20:55:19.351	
  :query
2024-09-19 20:55:19.351	
  :database 3,
2024-09-19 20:55:19.351	
  :viz-settings {:scalar.field ""count"", :table.cell_column ""count"", :table.pivot_column ""slug""},
2024-09-19 20:55:19.351	
  :cache-strategy {:multiplier 10, :min_duration_ms 60000, :type :ttl, :avg-execution-ms 0},
2024-09-19 20:55:19.351	
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
2024-09-19 20:55:19.351	
  :type :query,
2024-09-19 20:55:19.351	
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
2024-09-19 20:55:19.351	
 :json_query
2024-09-19 20:55:19.351	
 :action_id nil,
2024-09-19 20:55:19.351	
 :started_at #t ""2024-09-19T20:55:18.302507Z[GMT]"",
2024-09-19 20:55:19.351	
{:database_id 3,
2024-09-19 20:55:19.351	
2024-09-19 20:55:19,350 ERROR middleware.catch-exceptions :: Error processing query: Assert failed: (some? %)
```

definitely a different issue but there are errors on the logs which I think cause issues on the query run

snoe (Assginee) on (2024-09-20 20:21:09 UTC): @paoliniluis have you had any luck reproducing this? I could get stacktraces like this by modifying the code, but maybe there's something about the datasets.

lzrdbrain on (2024-10-02 18:25:10 UTC): I just started experiencing this issue last night around 7:00 PM MDT.  Did something change last night?

here is my diagnostic info. 
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2"",
      ""bigquery-cloud-sdk""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-cloud"",
    ""version"": {
      ""date"": ""2024-09-12"",
      ""tag"": ""v1.50.25.2"",
      ""hash"": ""e7db719""
    },
    ""settings"": {
      ""report-timezone"": ""US/Eastern""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}

Here is the error message from the logs:
[ea493f04-a921-49bf-aac5-3afe609291ed] 2024-10-02T09:24:12-06:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Error running query
{:database_id 34,
 :started_at #t ""2024-10-02T15:23:57.581596Z[GMT]"",
 :action_id nil,
 :json_query
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :native,
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :cache-strategy nil,
  :native
  {:template-tags
   {""org_id_ext_str""
    {:type :dimension,
     :name ""org_id_ext_str"",
     :id ""10401e4f-6511-4b1d-978f-18bc09242612"",
     :display-name ""Org ID Ext Str"",
     :widget-type :string/=,
     :dimension [:field 21428 nil]}},
   :collection ""marketing_contacts"",
   :query
   ""SELECT\n CASE \nWHEN `age` <20 THEN '<20'\nWHEN `age` <30 THEN '20-30'\nWHEN `age` <40 THEN '30-40'\nWHEN `age` <50 THEN '40-50'\nWHEN `age` <60 THEN '50-60'\nWHEN `age` <70 THEN '60-70'\nWHEN `age` <80 THEN '70-80'\nWHEN `age` >= 80 THEN '80+'\nELSE 'Other'\nEND as age_bucket,\nCOUNT(*) as customers\nFROM\n  `richard_experimental_dataset.demo_cache_marketing_ltv`\n  \nWHERE `age` IS NOT NULL\nAND {{org_id_ext_str}}\nGROUP BY\n`age`\nORDER BY\n  `age` ASC\n\n  \n""},
  :viz-settings
  {:graph.show_values true,
   :graph.dimensions [""age_bucket""],
   :graph.x_axis.title_text ""Age Bucket"",
   :graph.y_axis.title_text ""# customers"",
   :graph.metrics [""customers""],
   :card.title ""Most Common Customer Age Group""},
  :database 34,
  :parameters
  [{:type :string/=,
    :value [""org_Nqc3Db3p5N1""],
    :slug ""org_id_ext_str"",
    :id ""bfec6736"",
    :target [:dimension [:template-tag ""org_id_ext_str""]]}]},
 :status :failed,
 :class java.lang.NullPointerException,
 :stacktrace
 [""--> driver.bigquery_cloud_sdk$post_process_native.invokeStatic(bigquery_cloud_sdk.clj:490)""
  ""driver.bigquery_cloud_sdk$post_process_native.invoke(bigquery_cloud_sdk.clj:483)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__130626.invoke(bigquery_cloud_sdk.clj:516)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:529)""
  ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:506)""
  ""driver.bigquery_cloud_sdk$fn__130633.invokeStatic(bigquery_cloud_sdk.clj:545)""
  ""driver.bigquery_cloud_sdk$fn__130633.invoke(bigquery_cloud_sdk.clj:537)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:60)""
  ""query_processor.execute$run.invoke(execute.clj:54)""
  ""query_processor.middleware.update_used_cards$update_used_cards_BANG_$fn__71508.invoke(update_used_cards.clj:60)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__71523.invoke(execute.clj:23)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__71528.invoke(execute.clj:34)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71481.invoke(cache.clj:239)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66122.invoke(permissions.clj:147)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__108749$check_download_permissions__108750$fn__108751.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__66734.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__110580$maybe_apply_column_level_perms_check__110581$fn__110582.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__66744.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__71555.invoke(execute.clj:92)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:91)""
  ""query_processor.execute$execute.invoke(execute.clj:87)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__82876$handle_audit_app_internal_queries__82877$fn__82878.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__66772.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__76744.invoke(process_userland_query.clj:198)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__76813.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76850.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__67176.invoke(setup.clj:187)""
  ""query_processor.setup$do_with_database_local_settings$fn__67171.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__67166$fn__67167.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__67166.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__67159$fn__67162.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:170)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:159)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.setup$do_with_metadata_provider$fn__67159.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__67153.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
  ""api.public$process_query_for_card_with_id_run_fn$run__97015$fn__97016$fn__97017.invoke(public.clj:140)""
  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:422)""
  ""server.middleware.session$do_with_current_user.invoke(session.clj:405)""
  ""api.public$process_query_for_card_with_id_run_fn$run__97015$fn__97016.invoke(public.clj:139)""
  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065$fn__70066.invoke(streaming.clj:176)""
  ""query_processor.streaming$_streaming_response$fn__70064$fn__70065.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__70064.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:76)""
  ""async.streaming_response$do_f_async$task__52029.invoke(streaming_response.clj:97)""],
 :card_id 414,
 :context :embedded-dashboard,
 :error nil,
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}

paoliniluis (Issue Creator) on (2024-10-03 07:25:52 UTC): @lzrdbrain please contact support so we can help

"
2533485669,issue,open,,Ability to set maximum decimal places in charts,"**Is your feature request related to a problem? Please describe.**
I want to have a pie chart that shows percentages to the nearest 2 decimal places. As it stands, I can set the visualisation to have a minimum number of decimal places - but there's no clear way to set a maximum, the shown number of decimal places depends purely on the size of the chart. 

**Describe the solution you'd like**
I would like a setting in the visualisation settings of any chart to specify the max number of decimal places alongside the other style settings
![image](https://github.com/user-attachments/assets/b278bd21-3e76-4ce1-a7a6-91646e0d2521)


**Describe alternatives you've considered**
I cannot think of other alternatives for this

**How important is this feature to you?**
This is quite important for accessibility and consistency in reporting

**Additional context**
Add any other context or screenshots about the feature request here.
",ivanELEC,2024-09-18 11:34:35+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/47989,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2568149131, 'issue_id': 2533485669, 'author': 'brunobergher', 'body': ""@ivanELEC we recently changed this setting to be the exact number of decimal places, instead of minimum. It's not exactly what you're asking for, but it does lead to the consistency you mentioned.\n\nDoes it address your need?"", 'created_at': datetime.datetime(2025, 1, 2, 17, 51, 49, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:51:49 UTC): @ivanELEC we recently changed this setting to be the exact number of decimal places, instead of minimum. It's not exactly what you're asking for, but it does lead to the consistency you mentioned.

Does it address your need?

"
2533437078,issue,open,,Question Query Builder fails with missing column when joining two models.,"### Describe the bug

I believe this might be related to this issue, the problem seem similar https://github.com/metabase/metabase/issues/40553

When I connect 2 data models we get an error about a column used on the join being missing :

```
ERROR: column source.email does not exist
  Position: 2092
```

We can see the SQL being generated now and the issue is coming from the renaming of the column on the `source` part of the query and then being used with the original name on the join:

I'll add a snippet of the query below :


```
SELECT
 (...)
FROM
  (
    SELECT
      (...)
      ""Core User - User"".""email"" AS ""Core User - User__email""
    FROM
      ""public"".""view_log""
    LEFT JOIN ""public"".""report_card"" AS ""Report Card"" ON ""public"".""view_log"".""model_id"" = ""Report Card"".""id""
    LEFT JOIN ""public"".""core_user"" AS ""Core User - User"" ON ""public"".""view_log"".""user_id"" = ""Core User - User"".""id""
  ) AS ""source""
  LEFT JOIN (
    SELECT
     (....)
  ) AS ""Users - Viewer"" ON ""source"".""email"" = ""Users - Viewer"".""email""
(...)
```


As you can see the `email` field was renamed to `Core User - User__email` the join is using `source.email`

### To Reproduce

1. Create metabase models with multiple tables within 
2. Create a new question based on these models
3. Join the models together
4. Error will be flagged as column being missing


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""athena"",
      ""postgres"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-29"",
      ""tag"": ""v0.50.23"",
      ""hash"": ""7040ff1""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8-alpine-r0"",
    ""java.vendor"": ""Alpine"",
    ""java.vendor.url"": ""https://alpinelinux.org/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8-alpine-r0"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.213-201.855.amzn2.aarch64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",cgg-pwdt,2024-09-18 11:11:05+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/47988,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]",[],
2532089980,issue,closed,completed,Add debugUnreturnedConnectionStackTraces to the product,"### Describe the bug

Please check https://www.mchange.com/projects/c3p0/#unreturnedConnectionTimeout and add the stack trace so we can finally start tracking what's going on at the conn pool level

### To Reproduce

We still have connection pool stuff going haywire, we need to know more about what's going on

### Expected behavior

Kill this problem forever

### Logs

NA

### Information about your Metabase installation

```JSON
Going since forever
```


### Severity

P1

### Additional context

NA",paoliniluis,2024-09-17 20:29:24+00:00,['appleby'],2024-11-08 23:38:44+00:00,2024-11-08 22:23:33+00:00,https://github.com/metabase/metabase/issues/47981,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2531673206,issue,closed,not_planned,Option to easily include All Personal Collections in Serialization Export,"**Is your feature request related to a problem? Please describe.**
It can be frustrating when you need to export personal collections via the serialization API, as there is no way to export all personal collections at once. Currently, you have to manually identify and export them one by one, which is time-consuming and error-prone, especially in environments with many users.

Additionally, some customers build questions in public collections that depend on models located in personal collections. When the models in personal collections don’t get exported, the import fails due to missing dependencies. The error messaging only provides an entity ID, which makes it difficult and cumbersome to trace where the missing model is coming from.

**Describe the solution you'd like**
I would like an option in the serialization API to allow the export of all personal collections in a single request. This would ensure that all dependent models and collections are included in exports, simplifying migrations and avoiding import failures due to missing dependencies.

**Describe alternatives you've considered**
The alternative is to manually list and export personal collections by ID, but this requires additional effort and custom scripting, especially in large environments. Manually identifying and exporting the dependencies for public questions that rely on personal collections is also cumbersome and prone to error due to limited error messaging.

**How important is this feature to you?**
This feature is important because it would streamline backup, migration, and dependency management processes for instances with many users, ensuring personal collections and models are not overlooked and aid in prevention of import errors.

**Additional context**
Personal collections contain important user data and dependencies for public collections. Having an easy way to include them in exports would improve administrative efficiency and reduce the risk of missing critical data during migrations or backups.",ixipixi,2024-09-17 17:12:04+00:00,[],2024-11-01 17:39:11+00:00,2024-11-01 17:39:11+00:00,https://github.com/metabase/metabase/issues/47976,"[('Type:New Feature', ''), ('.Needs Triage', '')]",[],
2531471098,issue,open,,Link in XLSX exports should be clickable,"**Is your feature request related to a problem? Please describe.**
Right now the links in the table are clickable while the exports to excel don't

**Describe the solution you'd like**
E.g. create a sql question like
select 'https://www.google.com' as link1,'https://www.google.com/something' as link2

and then export that to excel, the links should be clickable

**Describe alternatives you've considered**
None currently

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-09-17 15:30:37+00:00,[],2025-02-04 20:30:30+00:00,,https://github.com/metabase/metabase/issues/47972,"[('Type:New Feature', ''), ('Reporting/Export', '')]",[],
2531168274,issue,open,,"If you set a display type under visualization -> data -> style, you cannot reset the chart so the general-level display type is respected","### Describe the bug

* If you set a display type under visualization -> data -> style, you cannot reset the chart so the general-level display type is respected. 
* This is really annoying. there should be a way to reset chart settings to default
* 

### To Reproduce

* Make a graph with ""line"" setting
* Then under visualisation settings -> data tab --> click the line ""..."" --> style --> display type as bar by mistake, or just to test out
* Then go back to visualisation --> change to ""area"". This is NOT respected

For some reason, this query will forever be stuck under ""bar""/ the setting chosen within the data tab, and never will respect the general visualisation setting

### Expected behavior

When general visualisation settings is changed, this should be respected. OR there should be a way to reset to default settings

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.223-212.873.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking

### Additional context

_No response_",aarthi-subramanian,2024-09-17 13:26:25+00:00,[],2025-02-04 20:31:25+00:00,,https://github.com/metabase/metabase/issues/47968,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2356682720, 'issue_id': 2531168274, 'author': 'paoliniluis', 'body': 'sorry, are you using v48?', 'created_at': datetime.datetime(2024, 9, 17, 19, 2, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2356772135, 'issue_id': 2531168274, 'author': 'aarthi-subramanian', 'body': 'Ah yes in the json above- `""tag"": ""v0.48.8"",`', 'created_at': datetime.datetime(2024, 9, 17, 19, 51, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-17 19:02:51 UTC): sorry, are you using v48?

aarthi-subramanian (Issue Creator) on (2024-09-17 19:51:39 UTC): Ah yes in the json above- `""tag"": ""v0.48.8"",`

"
2530967180,issue,open,,Text box on mobile too small,"### Describe the bug

How it looks on Desktop:
![image](https://github.com/user-attachments/assets/dd2a37ce-6793-4cc0-833a-87d2a84afa16)

How it looks on mobile:
![image](https://github.com/user-attachments/assets/632b417f-9095-4540-94ad-4e5aca6e66b6)


### To Reproduce

Just create a text box with an image and a larger text and you will see that the text box container will stay small and cut off the content in a uncomfortable way.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""de"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""h2""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-09-10"",
      ""tag"": ""v0.50.25"",
      ""hash"": ""473a7ca""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.4 (Debian 16.4-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.8.12-1-pve"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

annoying

### Additional context

_No response_",nepomuc,2024-09-17 12:00:14+00:00,[],2025-02-04 20:28:40+00:00,,https://github.com/metabase/metabase/issues/47965,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2529860199,issue,closed,not_planned,varieties in maps or how to implement in metabase,"Hi, I don't know if I should go this way, but I need to implement more varieties of maps in the metabase...
like heat maps, or that the pins are variable in color, in size according to the variables that are adjusted...
I apologize if it already exists but I couldn't find documentation to implement this...

Thank you very much in advance",gustavosobol,2024-09-17 02:44:40+00:00,[],2024-09-17 13:16:17+00:00,2024-09-17 13:16:17+00:00,https://github.com/metabase/metabase/issues/47964,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2355760003, 'issue_id': 2529860199, 'author': 'paoliniluis', 'body': '@gustavosobol we know that. Please add your upvote on the corresponding map that you want in the issue tracker', 'created_at': datetime.datetime(2024, 9, 17, 13, 16, 17, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-17 13:16:17 UTC): @gustavosobol we know that. Please add your upvote on the corresponding map that you want in the issue tracker

"
2529673619,issue,closed,not_planned,"Oracle DB complains if native query ends with "";""","### Describe the bug

If native query for Oracle DB ends in "";"", we get the error: ""ORA-00933: SQL command not properly ended"", this is not the case for other databases.

### To Reproduce

- Native query for Oracle DB
- Running `SELECT 1 FROM DUAL;` produces the error (`SELECT 1 FROM DUAL` works fine)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
v1.50.25
The Oracle DB I'm connecting to is on RDS (Engine: Oracle Standard Edition Two, version 19)
```


### Severity

Med-low

### Additional context

_No response_",vvaezian,2024-09-16 23:34:13+00:00,[],2025-01-21 18:06:41+00:00,2025-01-16 20:36:09+00:00,https://github.com/metabase/metabase/issues/47962,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Oracle', None), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2596841807, 'issue_id': 2529673619, 'author': 'paoliniluis', 'body': ""@vvaezian isn't this a user problem? I don't see this as a Metabase problem"", 'created_at': datetime.datetime(2025, 1, 16, 20, 36, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605416765, 'issue_id': 2529673619, 'author': 'vvaezian', 'body': '@paoliniluis Other DBs work with 0 or more "";"" at the end. \nIs Metabase adding a "";"" at the end automatically? This may be the cause of issue for Oracle, as it seems it accepts only one "";"" at the end.', 'created_at': datetime.datetime(2025, 1, 21, 18, 6, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2025-01-16 20:36:09 UTC): @vvaezian isn't this a user problem? I don't see this as a Metabase problem

vvaezian (Issue Creator) on (2025-01-21 18:06:39 UTC): @paoliniluis Other DBs work with 0 or more "";"" at the end. 
Is Metabase adding a "";"" at the end automatically? This may be the cause of issue for Oracle, as it seems it accepts only one "";"" at the end.

"
2529665708,issue,open,,We're re-sending the subscriptions again to all recipients when 1 recipient fails,"### Describe the bug

A customer reported that they got the same email over and over again on the same day. The issue is that we simply retry all recipients when a single one fails, causing lots of emails to be sent.

E.g. imagine that a subscription has 3 recipients: a, b and c. If the recipient b fails, then we retry again a,b,c, causing a to receive the subscription twice

### To Reproduce

This is a theoretical reproduction since I'm not able to repro unless I cause a failure to the email gateway:
1) set up metabase with an smtp server
2) make a dashboard and a subscription adding 3 recipients
3) when you send the test subscription, cut the connection to the email server

you should see the issue and A should have 2 emails, while b and c only one

### Expected behavior

We should keep track of every recipient to send the emails only once

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

Why did emails start failing on v50 more?",paoliniluis,2024-09-16 23:25:38+00:00,[],2025-02-04 20:29:30+00:00,,https://github.com/metabase/metabase/issues/47961,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2361367743, 'issue_id': 2529665708, 'author': 'qnkhuat', 'body': 'Can we check if all recipient emails are valid?', 'created_at': datetime.datetime(2024, 9, 19, 15, 38, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2362015941, 'issue_id': 2529665708, 'author': 'qnkhuat', 'body': 'Might be useful to backport https://github.com/metabase/metabase/pull/46218 to 50, it records error of each retry failure', 'created_at': datetime.datetime(2024, 9, 19, 19, 27, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2369412729, 'issue_id': 2529665708, 'author': 'ixipixi', 'body': 'Maybe related: https://github.com/metabase/metabase/issues/47949', 'created_at': datetime.datetime(2024, 9, 23, 21, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450304805, 'issue_id': 2529665708, 'author': 'ixipixi', 'body': 'Relevant because we send a lot of unnecessary emails:\n\n- Suppress New Login emails after first X sent: https://github.com/metabase/metabase/issues/30242\n- Allow suppressing LOGIN FROM NEW DEVICE emails: https://github.com/metabase/metabase/issues/36667', 'created_at': datetime.datetime(2024, 10, 31, 16, 26, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450315620, 'issue_id': 2529665708, 'author': 'ixipixi', 'body': 'We have cloud customers hitting rate limits:\n\n`Error sending to email channel. Retrying..."",""exception"":{""exception_class"":""com.sun.mail.smtp.SMTPSendFailedException"",""exception_message"":""454 Throttling failure: Maximum sending rate exceeded...`\n\nThis behavior is very likely compounding the issue.', 'created_at': datetime.datetime(2024, 10, 31, 16, 31, 24, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-09-19 15:38:36 UTC): Can we check if all recipient emails are valid?

qnkhuat on (2024-09-19 19:27:06 UTC): Might be useful to backport https://github.com/metabase/metabase/pull/46218 to 50, it records error of each retry failure

ixipixi on (2024-09-23 21:19:17 UTC): Maybe related: https://github.com/metabase/metabase/issues/47949

ixipixi on (2024-10-31 16:26:19 UTC): Relevant because we send a lot of unnecessary emails:

- Suppress New Login emails after first X sent: https://github.com/metabase/metabase/issues/30242
- Allow suppressing LOGIN FROM NEW DEVICE emails: https://github.com/metabase/metabase/issues/36667

ixipixi on (2024-10-31 16:31:24 UTC): We have cloud customers hitting rate limits:

`Error sending to email channel. Retrying..."",""exception"":{""exception_class"":""com.sun.mail.smtp.SMTPSendFailedException"",""exception_message"":""454 Throttling failure: Maximum sending rate exceeded...`

This behavior is very likely compounding the issue.

"
2528837502,issue,closed,not_planned,Dashboards crashing since updating to 1.50.24,"### Describe the bug

Dashboards crash when a customer has filters applied to their dashboards. This started happening when they updated from 1.49.24 to 1.50.24 and they're currently on 1.50.25.
I'm not able to replicate the issue on my end but can in their environment.

They're using BigQuery as the base for the questions and I wasn't able to test against their postgres data but that's not in use at the moment.


### To Reproduce

1. Create dashboard
2. Create filters
3. Apply ""Hide this card if there are no results"" setting to cards
4. Apply filters


I'm not 100% but I think it has to do with the visualization option in the dashboard.
""Hide this card if there are no results""
 
Reasons I think that:
While logs did have references to closed connections, some of the other typical symptoms associated with these types of issues listed in the logs are not found.
I ran queries with multiple combinations of filters, with at least 5 values in each filter, against the questions individually and none of them ever failed.

I duplicated dashboard 595 to [my personal collection](https://www.platform.serenlabs.io/collection/2014-metabase-success-engineer-s-personal-collection) and ran into the same issue immediately.
I duplicated the dashboard manually and added the questions manually one at a time to test the filters, and did NOT run into any issues. 
The differences here are the ""Hide this card if there are no results"" aren't added by default
I enabled the setting and immediately ran into the issue
I then [created one more exact duplicate](https://www.platform.serenlabs.io/dashboard/4525-organization-search-duplicate-four?organization_name=&organization_type=&organization_sector=&topics_contain=&topics_exactly_match=&city=&state=Virginia&state=Vizcaya&state=Warwickshire&state=West%20Virginia&state=Western&country=&technology_category=&omit_organizations=) and just disabled the visualization settings and it ran with no issue.
 
I started to go down the differences in maybe how we handled parameters and values with special characters and nulls between versions, but gave up on that after seeing the issue was happening regardless of the value. I even tested narrowing it down to questions with none of the above.

### Expected behavior

For the Dashboards to not crash when filters have been applied.

### Logs

https://gist.github.com/FilmonK/2bfb2e6affaebe322544690a84d9d1f7

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""mongo""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-cloud"",
    ""version"": {
      ""date"": ""2024-09-12"",
      ""tag"": ""v1.50.25.2"",
      ""hash"": ""e7db719""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres""
  }
}
```


### Severity

P1 - Interfering with their customer's ability to use dashboards

### Additional context

_No response_",FilmonK,2024-09-16 15:48:31+00:00,['metamben'],2024-11-19 15:36:24+00:00,2024-11-19 15:36:22+00:00,https://github.com/metabase/metabase/issues/47955,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Database/BigQuery', ''), ('.Backend', ''), ('Querying/', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2353373272, 'issue_id': 2528837502, 'author': 'metamben', 'body': '@FilmonK I have no access to the collection or the dashboard in the description. Are there logs in the console log? Is there something interesting/unusual in the network tab?', 'created_at': datetime.datetime(2024, 9, 16, 16, 22, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354187155, 'issue_id': 2528837502, 'author': 'FilmonK', 'body': '@metamben \r\nI can give you access to the environment if you need.\r\n\r\nConsole log is:\r\n""Error normalizing pMBQL:\\n{:value\\n {:lib/type :mbql/query,\\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n  :lib/metadata #object[p [object Object]]},\\n :schema #object[Object [object Object]],\\n :explain\\n {:schema #object[Object [object Object]],\\n  :value\\n  {:lib/type :mbql/query,\\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \\""\\""}],\\n   :lib/metadata #object[p [object Object]]},\\n  :errors\\n  ({:path [0 0 :database],\\n    :in [:database], \\n    :schema #object[Object [object Object]], \\n    :value nil, \\n    :type :malli.core/missing-key})}}\\n""\r\n\r\n\r\nNetwork tab doesn\'t appear to have anything unusual as you see query calls for each card on the dashboard, and then a call to api/util/bug_report_details is done to generate a report.', 'created_at': datetime.datetime(2024, 9, 16, 23, 11, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2356008832, 'issue_id': 2528837502, 'author': 'metamben', 'body': '> you see query calls for each card on the dashboard, and then a call to api/util/bug_report_details is done to generate a report.\r\n\r\nDo those calls succeed? If you give me access, I can have a look myself.', 'created_at': datetime.datetime(2024, 9, 17, 14, 25, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2356378700, 'issue_id': 2528837502, 'author': 'FilmonK', 'body': ""@metamben ping me on Slack and I'll get you situated."", 'created_at': datetime.datetime(2024, 9, 17, 16, 19, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2358856640, 'issue_id': 2528837502, 'author': 'metamben', 'body': 'The dashboard crashes when one of the queries returns an invalid JSON: in the response, the prefix\r\n```\r\n{\r\n    ""data"": {\r\n        ""rows"": [\r\n```\r\noccurs twice, i.e., it starts with\r\n```\r\n{\r\n    ""data"": {\r\n        ""rows"": [\r\n            {\r\n                ""data"": {\r\n                    ""rows"": [\r\n                    ],\r\n```\r\nThe part after the extra prefix is a valid JSON.\r\n\r\nSuch invalid responses can be returned regardless of the Hide this card if there are no results"" flag, but if it\'s not set, the FE displays a spinner instead of crashing.', 'created_at': datetime.datetime(2024, 9, 18, 15, 58, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2362086503, 'issue_id': 2528837502, 'author': 'metamben', 'body': 'Not saying they are sharing a root cause, but this is somewhat similar to #46071.', 'created_at': datetime.datetime(2024, 9, 19, 20, 10, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2436168655, 'issue_id': 2528837502, 'author': 'metamben', 'body': 'I\'ve experimented a little, and it turns out that calling `begin!` twice on a JSON `qp.si/StreamingResultsWriter` doesn\'t result in an invalid JSON. (It seems the underlying JSON generator keeps track of the opened objects and arrays, and adds the corresponding closing brace or bracket when it\'s closed.) This suggests that two different JSON generators write to the same stream. How that\'s possible needs further investigation.\n\nDetails: I tried changing `begin!` in two different ways:\n```\n(begin! [_ _ _]\n  (.write os (.getBytes ""{\\""data\\"":{\\""rows\\"":[""))\n  (doto jgen\n    (.writeStartObject)\n    (.writeFieldName ""data"")\n    (.writeStartObject)\n    (.writeFieldName ""rows"")\n    (.writeStartArray)))\n```\nand\n```\n(begin! [_ _ _]\n  (doto jgen\n    (.writeStartObject)\n    (.writeFieldName ""data"")\n    (.writeStartObject)\n    (.writeFieldName ""rows"")\n    (.writeStartArray))\n  (doto jgen\n    (.writeStartObject)\n    (.writeFieldName ""data"")\n    (.writeStartObject)\n    (.writeFieldName ""rows"")\n    (.writeStartArray)))\n```\nThe first one results in an invalid JSON (the two extra objects are not closed), this has the shape we saw in the broken dashboard.\nThe second one results in a valid JSON (which of course is not what the FE needs).', 'created_at': datetime.datetime(2024, 10, 24, 19, 20, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457290464, 'issue_id': 2528837502, 'author': 'uladzimirdev', 'body': 'my 2 cents: \n\n- the issue is reproducible on a single question (no dashboard required)\n- query to BigQuery should take more than 10s\n- more context on the [thread](https://metaboat.slack.com/archives/C052ZBWRG3W/p1730710823390559?thread_ts=1726501892.483959&cid=C052ZBWRG3W) \n- no way to simulate it with cypress atm', 'created_at': datetime.datetime(2024, 11, 5, 14, 14, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468194889, 'issue_id': 2528837502, 'author': 'metamben', 'body': '@uladzimirdev did you reproduce the issue by running a single query once, or were more than one requests issued?', 'created_at': datetime.datetime(2024, 11, 11, 13, 34, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468996301, 'issue_id': 2528837502, 'author': 'uladzimirdev', 'body': '@metamben to me any query that took more than 10s failed', 'created_at': datetime.datetime(2024, 11, 11, 20, 48, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470568373, 'issue_id': 2528837502, 'author': 'metamben', 'body': '@uladzimirdev even if no other query was running?', 'created_at': datetime.datetime(2024, 11, 12, 13, 44, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472704516, 'issue_id': 2528837502, 'author': 'uladzimirdev', 'body': '> even if no other query was running?\n\nyes', 'created_at': datetime.datetime(2024, 11, 13, 7, 38, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486053604, 'issue_id': 2528837502, 'author': 'perivamsi', 'body': 'Closing as per https://metaboat.slack.com/archives/C052ZBWRG3W/p1732027465046819?thread_ts=1726501892.483959&cid=C052ZBWRG3W\n\n(customer no longer facing this issue)', 'created_at': datetime.datetime(2024, 11, 19, 15, 36, 22, tzinfo=datetime.timezone.utc)}]","metamben (Assginee) on (2024-09-16 16:22:27 UTC): @FilmonK I have no access to the collection or the dashboard in the description. Are there logs in the console log? Is there something interesting/unusual in the network tab?

FilmonK (Issue Creator) on (2024-09-16 23:11:31 UTC): @metamben 
I can give you access to the environment if you need.

Console log is:
""Error normalizing pMBQL:\n{:value\n {:lib/type :mbql/query,\n  :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n  :lib/metadata #object[p [object Object]]},\n :schema #object[Object [object Object]],\n :explain\n {:schema #object[Object [object Object]],\n  :value\n  {:lib/type :mbql/query,\n   :stages [{:lib/type :mbql.stage/native, :template-tags {}, :native \""\""}],\n   :lib/metadata #object[p [object Object]]},\n  :errors\n  ({:path [0 0 :database],\n    :in [:database], \n    :schema #object[Object [object Object]], \n    :value nil, \n    :type :malli.core/missing-key})}}\n""


Network tab doesn't appear to have anything unusual as you see query calls for each card on the dashboard, and then a call to api/util/bug_report_details is done to generate a report.

metamben (Assginee) on (2024-09-17 14:25:07 UTC): Do those calls succeed? If you give me access, I can have a look myself.

FilmonK (Issue Creator) on (2024-09-17 16:19:44 UTC): @metamben ping me on Slack and I'll get you situated.

metamben (Assginee) on (2024-09-18 15:58:54 UTC): The dashboard crashes when one of the queries returns an invalid JSON: in the response, the prefix
```
{
    ""data"": {
        ""rows"": [
```
occurs twice, i.e., it starts with
```
{
    ""data"": {
        ""rows"": [
            {
                ""data"": {
                    ""rows"": [
                    ],
```
The part after the extra prefix is a valid JSON.

Such invalid responses can be returned regardless of the Hide this card if there are no results"" flag, but if it's not set, the FE displays a spinner instead of crashing.

metamben (Assginee) on (2024-09-19 20:10:05 UTC): Not saying they are sharing a root cause, but this is somewhat similar to #46071.

metamben (Assginee) on (2024-10-24 19:20:01 UTC): I've experimented a little, and it turns out that calling `begin!` twice on a JSON `qp.si/StreamingResultsWriter` doesn't result in an invalid JSON. (It seems the underlying JSON generator keeps track of the opened objects and arrays, and adds the corresponding closing brace or bracket when it's closed.) This suggests that two different JSON generators write to the same stream. How that's possible needs further investigation.

Details: I tried changing `begin!` in two different ways:
```
(begin! [_ _ _]
  (.write os (.getBytes ""{\""data\"":{\""rows\"":[""))
  (doto jgen
    (.writeStartObject)
    (.writeFieldName ""data"")
    (.writeStartObject)
    (.writeFieldName ""rows"")
    (.writeStartArray)))
```
and
```
(begin! [_ _ _]
  (doto jgen
    (.writeStartObject)
    (.writeFieldName ""data"")
    (.writeStartObject)
    (.writeFieldName ""rows"")
    (.writeStartArray))
  (doto jgen
    (.writeStartObject)
    (.writeFieldName ""data"")
    (.writeStartObject)
    (.writeFieldName ""rows"")
    (.writeStartArray)))
```
The first one results in an invalid JSON (the two extra objects are not closed), this has the shape we saw in the broken dashboard.
The second one results in a valid JSON (which of course is not what the FE needs).

uladzimirdev on (2024-11-05 14:14:31 UTC): my 2 cents: 

- the issue is reproducible on a single question (no dashboard required)
- query to BigQuery should take more than 10s
- more context on the [thread](https://metaboat.slack.com/archives/C052ZBWRG3W/p1730710823390559?thread_ts=1726501892.483959&cid=C052ZBWRG3W) 
- no way to simulate it with cypress atm

metamben (Assginee) on (2024-11-11 13:34:15 UTC): @uladzimirdev did you reproduce the issue by running a single query once, or were more than one requests issued?

uladzimirdev on (2024-11-11 20:48:22 UTC): @metamben to me any query that took more than 10s failed

metamben (Assginee) on (2024-11-12 13:44:45 UTC): @uladzimirdev even if no other query was running?

uladzimirdev on (2024-11-13 07:38:41 UTC): yes

perivamsi on (2024-11-19 15:36:22 UTC): Closing as per https://metaboat.slack.com/archives/C052ZBWRG3W/p1732027465046819?thread_ts=1726501892.483959&cid=C052ZBWRG3W

(customer no longer facing this issue)

"
2528793129,issue,open,,Sending subscriptions is slow,"### Describe the bug

I've always wondered why sending the first subscription right after Metabase initializes) is so slow, but now I was able to trace it down with pyroscope
![image](https://github.com/user-attachments/assets/82edd9dd-d13a-4049-81b7-969d9d28da0d)
![image](https://github.com/user-attachments/assets/b2dfe4f7-1f1e-4d32-96c8-ab56443bce40)
![image](https://github.com/user-attachments/assets/2645a742-6741-41f0-8ffe-8c3699b23e7e)


### To Reproduce

1) start up metabase and a mail server
2) create a new dashboard via an x-ray
3) send a test subscription (the first one takes a looong time)

4) now create that subscription and leave it till it's fired
5) see the traces

### Expected behavior

it should be fast

### Logs

Attaching the tempo traces
[Trace-c5152b-2024-09-16 12_27_11.json](https://github.com/user-attachments/files/17015587/Trace-c5152b-2024-09-16.12_27_11.json)


### Information about your Metabase installation

```JSON
vxx (I believe it has always been like this)
```


### Severity

P2

### Additional context

As a comparison: just running all queries in a dashboard take milliseconds, but the entire subscription takes 4 seconds... it's a lot",paoliniluis,2024-09-16 15:30:01+00:00,[],2025-02-04 20:29:32+00:00,,https://github.com/metabase/metabase/issues/47954,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2528446155,issue,open,,"Linking a dashboard filter to multiple dashboard tiles, and viewing as a grouped user causes entity keys to appear in the dropdown filter in place of entity names.","### Describe the bug

When viewing a dashboard with a filter that is linked to multiple questions as a users with grouped permission access, the filters display entity keys rather than entity names.

### To Reproduce

1. Create a new permission group and give it ""Can view"" access to the ""Accounts"", ""Feedback"" and ""Invoices"" sample database tables.

![Screenshot 2024-09-16 134807](https://github.com/user-attachments/assets/e9eeae1d-f039-4d83-a667-30329c85f430)

2. Verify that the ""Account ID"" fields within the ""Feedback"" and ""Invoices"" tables are linked to ""Accounts -> ID"", that ""filtering on this field"" is set to ""a list of all values"" and that the display value is set to ""Use foreign key-> First Name""

![Screenshot 2024-09-16 134859](https://github.com/user-attachments/assets/9db3262f-ddac-48f3-84ae-6b879df39791)

3. Create a new user and assign it to the group created in step 1 (don't log into it yet).

![Screenshot 2024-09-16 135344](https://github.com/user-attachments/assets/4ce198d7-baf8-4d66-90f2-3e37aa011d81)

4. Create a new collection (and allow the user created in step 3 ""View"" access), and create two simple GUI questions against the Feedback and Invoices tables.

<img width=""197"" alt=""image"" src=""https://github.com/user-attachments/assets/43ff992c-b155-472f-a45a-3f1104a32c69"">

5. Create a new dashboard, and add The Feedback and Invoices questions created in step 4. Add a new ""ID"" filter and link it to the ""Invoices.Account ID"" field.

![Screenshot 2024-09-16 135144](https://github.com/user-attachments/assets/a1cc2800-bc66-4b70-96b5-6a00e9edf87d)

6. Log into the account you created in step 3, and verify that the filter correctly loads the first names.

![Screenshot 2024-09-16 135213](https://github.com/user-attachments/assets/7e4136d2-32e5-4c33-86af-34797b35c904)

7. Log back into the admin account, unlink the ""ID"" filter from the Invoices question, and link it to the ""Feedback.Account ID"" field.

![Screenshot 2024-09-16 135233](https://github.com/user-attachments/assets/77ed5f64-cb0d-4fa8-a7dd-9aa86de9b064)

8. Log back into the account you created in step 3, and verify that the filter still correctly loads the first names.

![Screenshot 2024-09-16 135243](https://github.com/user-attachments/assets/35342aad-7497-4eb4-8346-ac141af5a575)

9. At this point, we have verified that the filter works correctly when assigned to either the Invoices or Feedback questions. But, now log back into the admin account, and assign the ""ID"" filter to **both** the ""Invoices.Account ID"" and Feedback.Account ID"" fields together.

![Screenshot 2024-09-16 135251](https://github.com/user-attachments/assets/81f03a24-61bd-44f0-97e5-042ed71a4e97)

10. Log back into the account you created in step 3, and you will now find that the filter displays a list of entity keys rather than entity names.

![Screenshot 2024-09-16 135310](https://github.com/user-attachments/assets/af71010b-d747-4694-bc20-6b361f924c93)



### Expected behavior

When a filter is linked to multiple fields on multiple tiles, the entity names should still display in the filter dropdown when viewed as a user with grouped permission access.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-09-10"",
      ""tag"": ""v1.50.25"",
      ""hash"": ""473a7ca""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/London""
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.39-0ubuntu0.22.04.1""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.5.0-1023-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```


### Severity

High

### Additional context

_No response_",JamesPoel,2024-09-16 13:15:39+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/47951,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2353382015, 'issue_id': 2528446155, 'author': 'paoliniluis', 'body': ""@JamesPoel if you're a paid customer, please write to our support email"", 'created_at': datetime.datetime(2024, 9, 16, 16, 26, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2369611677, 'issue_id': 2528446155, 'author': 'ixipixi', 'body': 'This doesn\'t necessarily seem to be tied to whether or not users are in a group - but whether or not the user has query access to the table that contains the target field. In the above example, if you add ""GUI query"" access to the accounts tables then the filters begin to work. But the issue only presents when the filter is linked to multiple questions.\r\n\r\nAnother work around is to add the a question built on the accounts table to the dashboard. Then the filter displays the remapped names regardless of whether or not the user has GUI query access to the accounts table.', 'created_at': datetime.datetime(2024, 9, 23, 22, 9, 36, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-09-16 16:26:42 UTC): @JamesPoel if you're a paid customer, please write to our support email

ixipixi on (2024-09-23 22:09:36 UTC): This doesn't necessarily seem to be tied to whether or not users are in a group - but whether or not the user has query access to the table that contains the target field. In the above example, if you add ""GUI query"" access to the accounts tables then the filters begin to work. But the issue only presents when the filter is linked to multiple questions.

Another work around is to add the a question built on the accounts table to the dashboard. Then the filter displays the remapped names regardless of whether or not the user has GUI query access to the accounts table.

"
