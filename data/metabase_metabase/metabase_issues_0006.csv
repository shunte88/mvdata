id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2465543597,issue,closed,completed,SDK Filter component is cut off,"### Describe the bug

![image](https://github.com/user-attachments/assets/9e3c1254-824e-4611-ab6c-cecd8732da6e)


The filter component is cut off in the shoppy app. We need to ensure that the user can see an adequate amount of information before forcing them to scroll.

[Reported on Slack](https://metaboat.slack.com/archives/C063Q3F1HPF/p1722024143174429)

### To Reproduce

Open the shoppy app and go to an interactive question, then click the ""Filter"" button. You will see only 1/3 of the filter component and you will need to scroll to see everything

### Expected behavior

It should show all of the options for filtering without scroll or cutoff

### Logs

_No response_

### Information about your Metabase installation

```JSON
{}
```


### Severity

P3

### Additional context

_No response_",oisincoveney,2024-08-14 11:09:33+00:00,[],2024-10-08 16:16:39+00:00,2024-08-23 08:12:14+00:00,https://github.com/metabase/metabase/issues/46825,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2465476568,issue,open,,Prepopulate github issues with diagnostics information,[context](https://metaboat.slack.com/archives/C078VLFKM/p1723630043347399?thread_ts=1723620709.396639&cid=C078VLFKM),uladzimirdev,2024-08-14 10:34:44+00:00,[],2024-08-14 10:35:08+00:00,,https://github.com/metabase/metabase/issues/46823,[],[],
2464507782,issue,open,,Column name of my model has weirdly changed,"### Describe the bug

I created my model some months ago. I named my column ""Delay between date xxx and date yyy"".
Today, I notice that the name of the column has changed into ""Delay between date xxx and date l'099cv"" (hexadecimal code ?).

This happens on several columns.

For instance :
![image](https://github.com/user-attachments/assets/3c9c1884-9238-4db4-8c32-529df5f038ae)


### To Reproduce

I don't know how to reproduce the problem. It happens once for me...

### Expected behavior

The name of the column should not have been changed.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Firefox : 115.6.0esr
- Windows 11
- Database : postgresql
- Metabase : v0.49
```


### Severity

Minor

### Additional context

_No response_",caillepi,2024-08-13 23:58:18+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/46807,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Unable to Reproduce', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]",[],
2464268097,issue,open,,Notebook editor clears the query when using browser back button,"### Describe the bug

When switching back from the viz to query if it's not saved sometimes you lose the blocks you added

### To Reproduce

1. Click on + New question
2. Choose Sample database -> Accounts
3. Click Visualize
4. Click Visualization
5. Choose Pivot
6. Click Notebook editor button
7. Add a custom column
8. Click Visualize
9. Click browser back button
10. Your custom column is lost


### Expected behavior

It should show again the query I built

### Logs

_No response_

### Information about your Metabase installation

```JSON
460ac41
```


### Severity

It's a big no-no to lose the work

### Additional context

_No response_",mngr,2024-08-13 21:36:57+00:00,[],2025-02-04 20:27:49+00:00,,https://github.com/metabase/metabase/issues/46801,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2296282879, 'issue_id': 2464268097, 'author': 'nemanjaglumac', 'body': ""@mngr isn't this the same as https://github.com/metabase/metabase/issues/46906 that you also opened?"", 'created_at': datetime.datetime(2024, 8, 19, 10, 51, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296295366, 'issue_id': 2464268097, 'author': 'mngr', 'body': ""> @mngr isn't this the same as #46906 that you also opened?\r\n\r\nMaybe the underlying problem is the same. But here the changes in query are just cleared. In 46906 it asks if the user wants to discard the changes. Steps to reproduce are different. But the expected result is the same, to open query with last changes."", 'created_at': datetime.datetime(2024, 8, 19, 10, 58, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302643764, 'issue_id': 2464268097, 'author': 'nemanjaglumac', 'body': '> It should show again the query I built.\r\n\r\n> But the expected result is the same, to open query with last changes.\r\n\r\nClick the ""Show Notebook"" button for that.\r\n\r\n\r\nMore [context in Slack](https://metaboat.slack.com/archives/C0645JP1W81/p1724261675440449) for when/if we come back to this.', 'created_at': datetime.datetime(2024, 8, 21, 17, 49, 38, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-08-19 10:51:39 UTC): @mngr isn't this the same as https://github.com/metabase/metabase/issues/46906 that you also opened?

mngr (Issue Creator) on (2024-08-19 10:58:18 UTC): Maybe the underlying problem is the same. But here the changes in query are just cleared. In 46906 it asks if the user wants to discard the changes. Steps to reproduce are different. But the expected result is the same, to open query with last changes.

nemanjaglumac on (2024-08-21 17:49:38 UTC): Click the ""Show Notebook"" button for that.


More [context in Slack](https://metaboat.slack.com/archives/C0645JP1W81/p1724261675440449) for when/if we come back to this.

"
2464237016,issue,closed,completed,Display type info for endpoint parameters that use custom types in generated docs,"In our API docs, we should display type information for endpoint parameters that accept custom types to make it easier for people to work with the endpoints.

Currently, docs generated from our endpoints lose type information for custom types.

For example, in the `card` endpoint, the `type` is missing info. The generated doc just supplies that the type is `:metabase.api.card/card-type`, which isn't useful to people working with the endpoint.

```
## `POST /api/card/`

Create a new `Card`.

### PARAMS:

-  **`visualization_settings`** Value must be a map.

-  **`parameters`** nullable sequence of parameter must be a map with :id and :type keys.

-  **`description`** nullable value must be a non-blank string.

-  **`collection_position`** nullable value must be an integer greater than zero.

-  **`result_metadata`** nullable :metabase.analyze.query-results/ResultsMetadata.

-  **`collection_id`** nullable value must be an integer greater than zero.

-  **`name`** value must be a non-blank string.

-  **`type`** nullable :metabase.api.card/card-type.

-  **`cache_ttl`** nullable value must be an integer greater than zero.

-  **`dataset_query`** Value must be a map.

-  **`parameter_mappings`** nullable sequence of parameter_mapping must be a map with :parameter_id and :target keys.

-  **`display`** value must be a non-blank string.
```

When generated via Rapidocs, we have a similar issue:

![image](https://github.com/user-attachments/assets/ae3fd25f-27e8-4b37-9871-1117a0a390b5)

Ideally, the `type` parameter docs would specify the acceptable values (in this case, the values would be `question`, `model`, or `metric`.)

What else would be cool: if we could include docstrings for these parameters (or types) in the source code, so that we could include notes for key params in the generated docs.",jeff-bruemmer,2024-08-13 21:16:04+00:00,['camsaul'],2024-10-01 22:19:23+00:00,2024-09-05 07:36:02+00:00,https://github.com/metabase/metabase/issues/46799,"[('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.DX', 'Developer experience and QoL related.'), ('.Team/DevEx', '')]",[],
2464189449,issue,open,,Sort order of columns in table view is not obeying the SQL,"### Describe the bug

* I have a query outputing a bunch of columns in table form
* When i look at table view, the sort order of columns obeys the sort order in query
* When i look at graph view (choosing the table type), the sort order of columns DOES NOT obey the sort order in query
Why is this happening? How can i reset 

### To Reproduce

* I believe just write a basic query outputting some fields in a given order
* Select table view- see the order of columns respecting that order
* Select graph view and select table type - see the order of columns NOT respecting that order and not matching the above table view

### Expected behavior

If selecting chart as table, the sort order should obey the sort order specify in the code!



### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.220-209.867.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking some users

### Additional context

* See here sort order specified in code and table view respecting this order: <img width=""1440"" alt=""image"" src=""https://github.com/user-attachments/assets/fe224f45-70a9-4cf0-bb85-a241d92db23a"">
* See here sort order specified in code and chart view of table type NOT respecting that order: <img width=""1438"" alt=""image"" src=""https://github.com/user-attachments/assets/848c808a-05eb-4046-a1fe-25d128c05674"">

",aarthi-subramanian,2024-08-13 20:46:40+00:00,[],2025-02-04 20:31:56+00:00,,https://github.com/metabase/metabase/issues/46795,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Product Input Needed', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2287240286, 'issue_id': 2464189449, 'author': 'paoliniluis', 'body': 'check if the question has a visualization setting, e.g. if you manually reordered the table', 'created_at': datetime.datetime(2024, 8, 13, 22, 21, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288007913, 'issue_id': 2464189449, 'author': 'crisptrutski', 'body': ""routed to the associated team, in case it's not due to viz setting"", 'created_at': datetime.datetime(2024, 8, 14, 7, 7, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289648505, 'issue_id': 2464189449, 'author': 'aarthi-subramanian', 'body': 'Ok yes i think someone may have manually reordered the order of the table 🙏 . In this case, how can i reset it to scratch? So that the order in the code is respected', 'created_at': datetime.datetime(2024, 8, 14, 19, 13, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310607497, 'issue_id': 2464189449, 'author': 'aarthi-subramanian', 'body': 'Hi bump on this! This is interfering with our work. Any workaround? The only workaround i can see is totally nuking the query and creating a new query. But this will lose all query change history', 'created_at': datetime.datetime(2024, 8, 26, 16, 31, 44, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-13 22:21:58 UTC): check if the question has a visualization setting, e.g. if you manually reordered the table

crisptrutski on (2024-08-14 07:07:50 UTC): routed to the associated team, in case it's not due to viz setting

aarthi-subramanian (Issue Creator) on (2024-08-14 19:13:39 UTC): Ok yes i think someone may have manually reordered the order of the table 🙏 . In this case, how can i reset it to scratch? So that the order in the code is respected

aarthi-subramanian (Issue Creator) on (2024-08-26 16:31:44 UTC): Hi bump on this! This is interfering with our work. Any workaround? The only workaround i can see is totally nuking the query and creating a new query. But this will lose all query change history

"
2464170319,issue,open,,Connection to Spark SQL fails with exception java.lang.NoSuchMethodError in logs,"### Describe the bug

Trying to connect to an apache spark cluster on my local network, and it fails with `'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)'`.


### To Reproduce

1. Go to '/admin/databases'
2. Click on 'Add database'
3. Fill in required information for connection
4. Press 'Save'
5. 'Save' button changes to 'Failed' and error message appears below


### Expected behavior

Successfully connect to Spark SQL source as it did in 0.47.13.

### Logs

[7fb73f6e-13ed-4d6d-b105-d1f04164d725] 2024-08-13T13:56:51-06:00 ERROR metabase.driver.util Failed to connect to Database,java.lang.NoSuchMethodError: 'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)',	at org.apache.hive.jdbc.HiveConnection.createHttpTransport(HiveConnection.java:372),	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:341),	at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:228),	at metabase.driver.hive_like.fixed_hive_connection.proxy$org.apache.hive.jdbc.HiveConnection$ff19274a.<init>(Unknown Source),	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invokeStatic(fixed_hive_connection.clj:9),	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invoke(fixed_hive_connection.clj:9),	at metabase.driver.sparksql.SparkSQLDataSource.getConnection(sparksql.clj:96),	at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372),	at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274),	at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111),	at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093),	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182),	at clojure.java.jdbc$query.invoke(jdbc.clj:1144),	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160),	at clojure.java.jdbc$query.invoke(jdbc.clj:1144),	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:349),	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:346),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_$fn__81580.invoke(connection.clj:358),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__81562.invoke(connection.clj:334),	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165),	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:329),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:325),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:357),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:353),	at metabase.driver.sql_jdbc$fn__109733.invokeStatic(sql_jdbc.clj:49),	at metabase.driver.sql_jdbc$fn__109733.invoke(sql_jdbc.clj:47),	at clojure.lang.MultiFn.invoke(MultiFn.java:234),	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56078.invoke(util.clj:167),	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047),	at clojure.lang.AFn.call(AFn.java:18),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	at java.base/java.lang.Thread.run(Unknown Source)
[7fb73f6e-13ed-4d6d-b105-d1f04164d725] 2024-08-13T13:56:51-06:00 ERROR metabase.api.database Cannot connect to Database,clojure.lang.ExceptionInfo: 'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)' {:message ""'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)'""},	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:184),	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155),	at clojure.lang.RestFn.invoke(RestFn.java:442),	at metabase.api.database$test_database_connection.invokeStatic(database.clj:728),	at metabase.api.database$test_database_connection.doInvoke(database.clj:718),	at clojure.lang.RestFn.invoke(RestFn.java:425),	at metabase.api.database$test_connection_details.invokeStatic(database.clj:782),	at metabase.api.database$test_connection_details.invoke(database.clj:762),	at metabase.api.database$fn__100719.invokeStatic(database.clj:803),	at metabase.api.database$fn__100719.invoke(database.clj:786),	at compojure.core$wrap_response$fn__52905.invoke(core.clj:160),	at compojure.core$wrap_route_middleware$fn__52889.invoke(core.clj:132),	at compojure.core$wrap_route_info$fn__52894.invoke(core.clj:139),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:151),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:152),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917.invoke(core.clj:200),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at metabase.server.middleware.auth$enforce_authentication$fn__97044.invoke(auth.clj:18),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917.invoke(core.clj:200),	at compojure.core$make_context$handler__52945.invoke(core.clj:290),	at compojure.core$make_context$fn__52949.invoke(core.clj:300),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$make_context$fn__52949.invoke(core.clj:301),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:153),	at clojure.lang.Var.invoke(Var.java:393),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at metabase.api.routes$fn__104631$fn__104634.invoke(routes.clj:73),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917.invoke(core.clj:200),	at clojure.lang.AFn.applyToHelper(AFn.java:160),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:667),	at clojure.core$apply.invoke(core.clj:662),	at metabase.server.routes$fn__104911$fn__104912.doInvoke(routes.clj:73),	at clojure.lang.RestFn.invoke(RestFn.java:436),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917.invoke(core.clj:200),	at compojure.core$make_context$handler__52945.invoke(core.clj:290),	at compojure.core$make_context$fn__52949.invoke(core.clj:300),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:153),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:153),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:153),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at compojure.core$wrap_route_matches$fn__52898.invoke(core.clj:153),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917$f__52918$respond_SINGLEQUOTE___52919.invoke(core.clj:197),	at metabase.server.routes$fn__104894$fn__104896.invoke(routes.clj:47),	at compojure.core$routes$fn__52917$f__52918.invoke(core.clj:198),	at compojure.core$routes$fn__52917.invoke(core.clj:200),	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__101025.invoke(exceptions.clj:107),	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__101022.invoke(exceptions.clj:96),	at metabase.server.middleware.log$log_api_call$fn__105191$fn__105192$fn__105193.invoke(log.clj:236),	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18),	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12),	at metabase.server.middleware.log$log_api_call$fn__105191$fn__105192.invoke(log.clj:227),	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112),	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103),	at metabase.server.middleware.log$log_api_call$fn__105191.invoke(log.clj:226),	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__108461.invoke(browser_cookie.clj:40),	at metabase.server.middleware.security$add_security_headers$fn__100981.invoke(security.clj:240),	at ring.middleware.json$wrap_json_body$fn__108720.invoke(json.clj:64),	at metabase.server.middleware.offset_paging$handle_paging$fn__87236.invoke(offset_paging.clj:43),	at metabase.server.middleware.json$wrap_streamed_json_response$fn__54437.invoke(json.clj:83),	at ring.middleware.keyword_params$wrap_keyword_params$fn__108809.invoke(keyword_params.clj:55),	at ring.middleware.params$wrap_params$fn__108828.invoke(params.clj:77),	at metabase.server.middleware.misc$maybe_set_site_url$fn__70382.invoke(misc.clj:60),	at metabase.server.middleware.session$reset_session_timeout$fn__77502.invoke(session.clj:552),	at metabase.server.middleware.session$bind_current_user$fn__77468$fn__77469.invoke(session.clj:446),	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:425),	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:408),	at metabase.server.middleware.session$bind_current_user$fn__77468.invoke(session.clj:445),	at metabase.server.middleware.session$wrap_current_user_info$fn__77447.invoke(session.clj:383),	at metabase.server.middleware.session$wrap_session_id$fn__77419.invoke(session.clj:259),	at metabase.server.middleware.auth$wrap_static_api_key$fn__97052.invoke(auth.clj:32),	at ring.middleware.cookies$wrap_cookies$fn__108648.invoke(cookies.clj:200),	at metabase.server.middleware.misc$add_content_type$fn__70364.invoke(misc.clj:28),	at metabase.server.middleware.misc$disable_streaming_buffering$fn__70390.invoke(misc.clj:77),	at ring.middleware.gzip$wrap_gzip$fn__108690.invoke(gzip.clj:86),	at metabase.server.middleware.misc$bind_request$fn__70393.invoke(misc.clj:94),	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__108477.invoke(ssl.clj:41),	at metabase.server$async_proxy_handler$fn__70728.invoke(server.clj:77),	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source),	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173),	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122),	at org.eclipse.jetty.server.Server.handle(Server.java:563),	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598),	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753),	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501),	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287),	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314),	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100),	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277),	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199),	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411),	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194),	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149),	at java.base/java.lang.Thread.run(Unknown Source),Caused by: java.lang.NoSuchMethodError: 'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)',	at org.apache.hive.jdbc.HiveConnection.createHttpTransport(HiveConnection.java:372),	at org.apache.hive.jdbc.HiveConnection.openTransport(HiveConnection.java:341),	at org.apache.hive.jdbc.HiveConnection.<init>(HiveConnection.java:228),	at metabase.driver.hive_like.fixed_hive_connection.proxy$org.apache.hive.jdbc.HiveConnection$ff19274a.<init>(Unknown Source),	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invokeStatic(fixed_hive_connection.clj:9),	at metabase.driver.hive_like.fixed_hive_connection$fixed_hive_connection.invoke(fixed_hive_connection.clj:9),	at metabase.driver.sparksql.SparkSQLDataSource.getConnection(sparksql.clj:96),	at clojure.java.jdbc$get_connection.invokeStatic(jdbc.clj:372),	at clojure.java.jdbc$get_connection.invoke(jdbc.clj:274),	at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1111),	at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093),	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182),	at clojure.java.jdbc$query.invoke(jdbc.clj:1144),	at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160),	at clojure.java.jdbc$query.invoke(jdbc.clj:1144),	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invokeStatic(connection.clj:349),	at metabase.driver.sql_jdbc.connection$can_connect_with_spec_QMARK_.invoke(connection.clj:346),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_$fn__81580.invoke(connection.clj:358),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection$fn__81562.invoke(connection.clj:334),	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165),	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invokeStatic(connection.clj:329),	at metabase.driver.sql_jdbc.connection$do_with_connection_spec_for_testing_connection.invoke(connection.clj:325),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invokeStatic(connection.clj:357),	at metabase.driver.sql_jdbc.connection$can_connect_QMARK_.invoke(connection.clj:353),	at metabase.driver.sql_jdbc$fn__109733.invokeStatic(sql_jdbc.clj:49),	at metabase.driver.sql_jdbc$fn__109733.invoke(sql_jdbc.clj:47),	at clojure.lang.MultiFn.invoke(MultiFn.java:234),	at metabase.driver.util$can_connect_with_details_QMARK_$fn__56078.invoke(util.clj:167),	at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047),	at clojure.lang.AFn.call(AFn.java:18),	at java.base/java.util.concurrent.FutureTask.run(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source),	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source),	... 1 more
[7fb73f6e-13ed-4d6d-b105-d1f04164d725] 2024-08-13T13:56:51-06:00 DEBUG metabase.server.middleware.log POST /api/database 400 1.0 s (1 DB calls) {:metabase-user-id 1} 
{:message ""'void org.apache.thrift.transport.THttpClient.<init>(java.lang.String, org.apache.http.client.HttpClient)'""}

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.153.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-06"",
      ""tag"": ""v0.50.19"",
      ""hash"": ""0b97bf8""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking an upgrade

### Additional context

Screenshot including error at bottom:
![image](https://github.com/user-attachments/assets/48d0941b-3038-4313-9301-433c15121188)",EVRAZ-ahmad,2024-08-13 20:33:04+00:00,[],2025-02-04 20:25:31+00:00,,https://github.com/metabase/metabase/issues/46793,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Spark', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2288029074, 'issue_id': 2464170319, 'author': 'crisptrutski', 'body': ""I don't believe that we've updated our hive version since 47, but passing on to our drivers team to follow up."", 'created_at': datetime.datetime(2024, 8, 14, 7, 21, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288159044, 'issue_id': 2464170319, 'author': 'lbrdnk', 'body': '1. This specific error is shown with `transportMode=http` option set.\r\n2. Properties passed to `HiveConnection` (see the `metabase.driver.hive-like.fixed-hive-connection` ns) seems to contain kv pairs used by Metabase, not meant for the connection (eg. `advanced-options`).\r\n\r\n```\r\n{""let-user-control-scheduling"" ""false"", ""password"" ""asdf"", ""advanced-options"" ""true"", ""dbname"" ""xix"", ""tunnel-enabled"" ""false"", ""engine"" ""sparksql"", ""user"" ""xix""}\r\n```', 'created_at': datetime.datetime(2024, 8, 14, 8, 30, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408523772, 'issue_id': 2464170319, 'author': 'Charonxin', 'body': 'I met the same problem just now, when will this problem been fixed? Before the problem has been fixed, is there any other way to connect to apache hive using metabase?', 'created_at': datetime.datetime(2024, 10, 12, 11, 5, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2448893841, 'issue_id': 2464170319, 'author': 'guicailiao', 'body': 'Tried `transportMode=binary`, it did unblock us for using sparksql.', 'created_at': datetime.datetime(2024, 10, 31, 2, 27, 27, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-14 07:21:08 UTC): I don't believe that we've updated our hive version since 47, but passing on to our drivers team to follow up.

lbrdnk on (2024-08-14 08:30:50 UTC): 1. This specific error is shown with `transportMode=http` option set.
2. Properties passed to `HiveConnection` (see the `metabase.driver.hive-like.fixed-hive-connection` ns) seems to contain kv pairs used by Metabase, not meant for the connection (eg. `advanced-options`).

```
{""let-user-control-scheduling"" ""false"", ""password"" ""asdf"", ""advanced-options"" ""true"", ""dbname"" ""xix"", ""tunnel-enabled"" ""false"", ""engine"" ""sparksql"", ""user"" ""xix""}
```

Charonxin on (2024-10-12 11:05:19 UTC): I met the same problem just now, when will this problem been fixed? Before the problem has been fixed, is there any other way to connect to apache hive using metabase?

guicailiao on (2024-10-31 02:27:27 UTC): Tried `transportMode=binary`, it did unblock us for using sparksql.

"
2463941916,issue,closed,completed,Setup permissions and sandboxing via embedding cli,"- Ask the user if they need to setup multi-tenancy permissions based on columns. “Is your tenancy isolation based on a column, e.g. your tables have a customer_id column to isolate tenants? yes/no”
    1. If yes
        - bonus points: sample actual values we can use later, e.g. `select count(*), owner_id from table`
        - setup permissions
            - ask for multi-tenancy column for each of the tables previously selected. Starting from the 2nd table, suggest the previously used column by default if it exists.
            - Configure Our analytics and examples to be no access by “All Users”
            - Create 3 customer collections, e.g. “Customer A”, “Customer B”, “Customer C”
            - Create 3 groups “Customer A group”, “Customer B group”, ""Customer C group” w/ permissions for data sandboxing for the tables chosen by the user, filtering by the selected tenancy column, and curate access to the corresponding collection
            - Create SSO group syncing mappings, e.g/ ""customer a” → “Customer A group”
            - Generate a single file Express app with a mock SSO endpoint that can sign three different hardcoded users in
            - Each user is assigned part of one of the groups
            - Each user is assigned one of the previously sampled values for the tenancy column
            - TBD: How to switch users?",heypoom,2024-08-13 18:16:02+00:00,['heypoom'],2024-10-08 16:16:12+00:00,2024-08-28 16:13:59+00:00,https://github.com/metabase/metabase/issues/46788,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2463702813,issue,closed,completed,[BE] Cleanup MBQL lib and remove metric-as-data-sources,,ranquild,2024-08-13 16:01:52+00:00,['metamben'],2024-10-08 16:17:32+00:00,2024-08-14 14:04:39+00:00,https://github.com/metabase/metabase/issues/46782,[],[],
2463668345,issue,closed,completed,[BE] Cleanup QP and remove metric-as-data-sources,,metamben,2024-08-13 15:44:22+00:00,['metamben'],2024-10-08 16:17:47+00:00,2024-08-13 18:21:39+00:00,https://github.com/metabase/metabase/issues/46781,[],[],
2463527461,issue,closed,completed,Add aggregation button shown when there's no aggregations to add,"### Describe the bug

![image](https://github.com/user-attachments/assets/754bd391-a206-4b44-a1e1-d29a0f19021a)


### To Reproduce

1. New > Question > Products
2. Add breakouts on every column possible

The add aggregation button is still displayed. After clicking it a pointless popover is shown.

### Expected behavior

The add aggregation button is not shown.



### Information about your Metabase installation

master, 6764487


### Severity

P3
",kamilmielnik,2024-08-13 14:39:33+00:00,[],2024-08-13 14:42:33+00:00,2024-08-13 14:42:32+00:00,https://github.com/metabase/metabase/issues/46777,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2463447559,issue,closed,completed,EntityPicker switches tabs when loading,"### Describe the bug

When EntityPicker is loading data, it might switch between tabs. Demo https://www.loom.com/share/6649c22e3f9342c1a29c64fd90635e6b

### To Reproduce

1. Make sure you have models & saved questions in your instance
2. Reload the page
3. New -> Question
4. See the picker changing tabs

### Expected behavior

The picker should load all required data before removing the loader. The selected tab should be final unless the user changes it.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master (v50+), 2024-08-13, `4c3df61`
```


### Severity

P2

### Additional context

_No response_",ranquild,2024-08-13 14:05:19+00:00,['npfitz'],2024-10-07 15:11:00+00:00,2024-10-03 13:56:58+00:00,https://github.com/metabase/metabase/issues/46775,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2463426007,issue,open,,Cannot find matching FK Table ID for FK Field,"### Describe the bug

![image](https://github.com/user-attachments/assets/49bb4473-37fa-48a0-91bd-06342916b15c)


### To Reproduce

1. New > Question > Orders > Join Reviews on Product ID = Product ID
2. Click to add new filter (notice that Products table is listed twice in the dropdown) and choose Products (**first entry**) > Category > Check ""Doohickey"" and ""Gadget"" and apply
3. Click to add new filter and choose Products (**second entry**) > Category > Check ""Doohickey"" and apply
4. Visualize


### Expected behavior

No error. Only Doohickey Products are returned. 


### Information about your Metabase installation

master, 6764487


### Severity

P2

### Additional context

Payload sent to POST `/api/dataset`

```
{
    ""database"": 1,
    ""type"": ""query"",
    ""query"": {
        ""source-table"": 5,
        ""joins"": [
            {
                ""fields"": ""all"",
                ""strategy"": ""left-join"",
                ""alias"": ""Reviews - Product"",
                ""condition"": [
                    ""="",
                    [
                        ""field"",
                        40,
                        {
                            ""base-type"": ""type/Integer""
                        }
                    ],
                    [
                        ""field"",
                        71,
                        {
                            ""base-type"": ""type/Integer"",
                            ""join-alias"": ""Reviews - Product""
                        }
                    ]
                ],
                ""source-table"": 4
            }
        ],
        ""filter"": [
            ""and"",
            [
                ""="",
                [
                    ""field"",
                    58,
                    {
                        ""base-type"": ""type/Text"",
                        ""source-field"": 40
                    }
                ],
                ""Doohickey""
            ],
            [
                ""="",
                [
                    ""field"",
                    58,
                    {
                        ""base-type"": ""type/Text"",
                        ""source-field"": 71
                    }
                ],
                ""Gadget""
            ]
        ]
    },
    ""parameters"": []
}
```
",kamilmielnik,2024-08-13 13:56:07+00:00,[],2025-02-04 20:27:51+00:00,,https://github.com/metabase/metabase/issues/46774,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2392857258, 'issue_id': 2463426007, 'author': 'kamilmielnik', 'body': 'I hit this again today: #48334', 'created_at': datetime.datetime(2024, 10, 4, 5, 33, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2437234105, 'issue_id': 2463426007, 'author': 'kamilmielnik', 'body': 'When working on it please search for `https://github.com/metabase/metabase/issues/46774` in code and uncomment related assertions.', 'created_at': datetime.datetime(2024, 10, 25, 8, 45, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616126619, 'issue_id': 2463426007, 'author': 'lbrdnk', 'body': 'As per [this thread](https://metaboat.slack.com/archives/C0645JP1W81/p1737989914732509), returning only the first column group for a table is not desired fix. It should be possible to pick which foreign key field is used to join the products table (as in the reproduction), `orders->product_id` or `reviews->product_id`.', 'created_at': datetime.datetime(2025, 1, 27, 15, 49, 48, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-04 05:33:56 UTC): I hit this again today: #48334

kamilmielnik (Issue Creator) on (2024-10-25 08:45:39 UTC): When working on it please search for `https://github.com/metabase/metabase/issues/46774` in code and uncomment related assertions.

lbrdnk on (2025-01-27 15:49:48 UTC): As per [this thread](https://metaboat.slack.com/archives/C0645JP1W81/p1737989914732509), returning only the first column group for a table is not desired fix. It should be possible to pick which foreign key field is used to join the products table (as in the reproduction), `orders->product_id` or `reviews->product_id`.

"
2463226968,issue,open,,Dashboard target column popover empty state UX,"### Describe the bug

https://github.com/user-attachments/assets/98b1e8bd-06d7-4baa-b484-0ae0815b3182



### To Reproduce

1. New > Question > Orders > Join People on `User ID = People > ID` > Join Products on `Product ID = Products > ID` > Join Invoices on `User ID = Invoices > Account Id` > Join Feedback on `ID = Feedback > Account ID`  ([image](https://github.com/user-attachments/assets/6ea1c0a5-20e8-4407-82d4-fd5db056dfa5))
2. Save and add to dashboard
3. Edit dashboard
4. Add Text parameter to dashboard and select it
5. Click ""Column to filter on""
6. Search input gets focused
7. Type ""aa""


### Expected behavior

- Empty sections should not be shown when there are no results
- Empty sections should not be shown when are results in other sections (confirm with product team first)
- ""Didn't find any results"" text should be grey, not blue (similar to #46667)
- Popover's scrollability should be predictable (see how height of the popover changes in the video when typing ""xxx"" - this is not easy to reproduce - you need to interact with the popover before it happens, sometimes a lot)



### Information about your Metabase installation

master, 6764487

### Severity

P3
",kamilmielnik,2024-08-13 12:25:56+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/46767,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('Querying/Forms', 'Actions'), ('.Team/Querying', '')]",[],
2463179643,issue,closed,completed,"""Add dashboard filter"" popover does not close on click outside","### Describe the bug

![image](https://github.com/user-attachments/assets/cdb95f94-4552-40fc-aaeb-68068e531132)


### To Reproduce

1. Edit dashboard
2. Click ""Add a filter"" button
3. Popover opens
4. Click outside the popover to close it

Nothing happens

### Expected behavior

Popover closes on click outside

### Information about your Metabase installation

master, 67644874f3

### Severity

P3
",kamilmielnik,2024-08-13 12:03:13+00:00,['oisincoveney'],2024-10-08 16:17:39+00:00,2024-08-14 09:59:35+00:00,https://github.com/metabase/metabase/issues/46765,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]",[],
2462669791,issue,closed,completed,Embedding CLI should open the metabase store to sign-up for a free trial,"1. Take user to store to start a trial and get a token
    1. ""Please sign up for a free trial of Metabase Pro self-hosted or purchase a license. Click Enter to be taken to the store. ” Takes user to `https://store.metabase.com/checkout?plan=pro&deployment=self-hosted?utm_source=product&utm_medium=checkout&utm_campaign=embedding-sdk&utm_content=embedding-sdk-cli`
    2. Add it to the list in Product UTM Instrumentation
2. User pastes token, we activate the license
    1. move the license activation step here from where it is today earlier in the flow
    2. “Enter your Metabase Pro license key: “

[Product doc](https://www.notion.so/metabase/CLI-sets-permissions-and-a-mock-SSO-implementation-2cdce524908140a394a528e035e4c6b1?pvs=4)",heypoom,2024-08-13 07:59:06+00:00,['heypoom'],2024-10-08 16:16:55+00:00,2024-08-21 10:36:54+00:00,https://github.com/metabase/metabase/issues/46761,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2462219938,issue,closed,not_planned,Automatic email sending is not working,"**Describe the bug**
A clear and concise description of what the bug is Automatic email sending is not working

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)



**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'spcific dashboard', 
2. Click on 'Subscription
3. Scroll down to send email now and click send email now
4. See error - sending email failed 


[
[pp-analytics-wfa.sequoia.com.har.zip](https://github.com/user-attachments/files/16593555/pp-analytics-wfa.sequoia.com.har.zip)
](url)


**Expected behavior**
email should send successfully, 

**Screenshots**
no screen shot, har file attached for the api response

**Severity**
Major

**Additional context**
cause: ""Multiple methods in multimethod 'global-type-settings' match dispatch value: :type/SnowflakeVariant -> :type/Temporal and :type/Number, and neither is preferred""

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-IN"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.220-209.869.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.35""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-30"",
      ""tag"": ""v1.50.18"",
      ""hash"": ""c323ffc""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",lrkarthi,2024-08-13 02:08:17+00:00,[],2024-08-13 10:41:01+00:00,2024-08-13 10:41:00+00:00,https://github.com/metabase/metabase/issues/46758,[],"[{'comment_id': 2285934672, 'issue_id': 2462219938, 'author': 'paoliniluis', 'body': 'Please send us an email to help at metabase dot com', 'created_at': datetime.datetime(2024, 8, 13, 10, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-13 10:41:00 UTC): Please send us an email to help at metabase dot com

"
2462050479,issue,open,,Add/remove a single column in a model with tables joined by themselves adds/removes all columns,"### Describe the bug

Adding or removing a single column in a model with tables joined by themselves adds/removes all columns.

### To Reproduce

1. Create new GUI model
2. Choose Products (table) and join it with itself
3. Save model
4. Open visualization settings
5. Click ""Add or remove columns""
6. Click to remove any SINGLE column
7. Notice that ALL columns are now unticked

### Expected behavior

Clicking on a single column should add or remove only that one column.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, 63295ce, H2, Sample Database
```


### Severity

P2

### Additional context

P2 only because @ranquild realized that the query is actually correct. It's just the UI issue.

Reproducible in x.50.19 as well!",nemanjaglumac,2024-08-12 23:19:57+00:00,[],2025-02-04 20:27:17+00:00,,https://github.com/metabase/metabase/issues/46756,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]","[{'comment_id': 2301319659, 'issue_id': 2462050479, 'author': 'nemanjaglumac', 'body': 'The culprit seems to be this\r\n```\r\nexport function toggleColumnInQuery(\r\n  query: Lib.Query,\r\n  stageIndex: number,\r\n  { column, isSelected }: ColumnItem,\r\n) {\r\n  return isSelected\r\n    ? Lib.removeField(query, stageIndex, column)\r\n    : Lib.addField(query, stageIndex, column);\r\n```', 'created_at': datetime.datetime(2024, 8, 21, 7, 20, 55, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-08-21 07:20:55 UTC): The culprit seems to be this
```
export function toggleColumnInQuery(
  query: Lib.Query,
  stageIndex: number,
  { column, isSelected }: ColumnItem,
) {
  return isSelected
    ? Lib.removeField(query, stageIndex, column)
    : Lib.addField(query, stageIndex, column);
```

"
2461906160,issue,closed,completed,There's no way to change the series color in multi-metric no-breakout chart,"### Context
Color selector icon is missing from viz settings in this example with multiple metrics, not from a breakout. Can't reproduce this from scratch but has occurred for at least one existing question.

[Slack thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1723408262771839)
[See it in Stats](https://stats.metabase.com/question/18146-webinar-registrants-vs-watched-replay-vs-attended-live)",cdeweyx,2024-08-12 21:13:30+00:00,['alxnddr'],2025-01-31 21:01:52+00:00,2025-01-31 02:27:36+00:00,https://github.com/metabase/metabase/issues/46750,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2414196197, 'issue_id': 2461906160, 'author': 'zbodi74', 'body': ""A customer has reported this as well. It looks like the color picker doesn't appear when the source column is set to the Category type.\n\nTo reproduce:\n- Use the sample database\n- Set column type of Products.Rating to Category\n- Create a GUI query: Products, group by: Category, summarize: Average of Rating, Average of price\n- Visualize the results and see the color selector missing for Average of Rating"", 'created_at': datetime.datetime(2024, 10, 15, 15, 4, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414212266, 'issue_id': 2461906160, 'author': 'ixipixi', 'body': 'https://github.com/metabase/metabase/issues/41795', 'created_at': datetime.datetime(2024, 10, 15, 15, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628392043, 'issue_id': 2461906160, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 1, 31, 21, 1, 50, tzinfo=datetime.timezone.utc)}]","zbodi74 on (2024-10-15 15:04:23 UTC): A customer has reported this as well. It looks like the color picker doesn't appear when the source column is set to the Category type.

To reproduce:
- Use the sample database
- Set column type of Products.Rating to Category
- Create a GUI query: Products, group by: Category, summarize: Average of Rating, Average of price
- Visualize the results and see the color selector missing for Average of Rating

ixipixi on (2024-10-15 15:08:00 UTC): https://github.com/metabase/metabase/issues/41795

github-actions[bot] on (2025-01-31 21:01:50 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2461463377,issue,closed,completed,[Epic] Reduce the number of choices in onboarding flow,"**Links**
- [product doc](https://www.notion.so/metabase/Reduce-the-number-of-choices-in-onboarding-flow-f74849658dce4cceb9a9fd33b243f820)
- [eng doc](https://www.notion.so/metabase/Tech-Reduce-the-number-of-choices-in-onboarding-flow-9def6e76d62d4c4f86b269191324ce69)


**Implementation Plan**



```[tasklist]
### Milestone 1 - newsletter
- [ ] https://github.com/metabase/metabase/pull/46834
- [ ] https://github.com/metabase/metabase/pull/46783
- [ ] https://github.com/metabase/metabase/pull/47021
```

```[tasklist]
### Milestone 2 - hide data consent step
- [ ] https://github.com/metabase/metabase/pull/46965
- [ ] https://github.com/metabase/metabase/pull/47055
```


UPDATE: this was supposed to be backported to v50, so there's the backport PR: https://github.com/metabase/metabase/pull/47067",npretto,2024-08-12 16:43:48+00:00,['npretto'],2024-08-22 11:27:21+00:00,2024-08-22 11:27:20+00:00,https://github.com/metabase/metabase/issues/46741,"[('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2304433354, 'issue_id': 2461463377, 'author': 'npretto', 'body': 'Closed by the backport here: [Reduce the number of choices in onboarding flow [backport] (+316 −239)](https://github.com/metabase/metabase/pull/47067)', 'created_at': datetime.datetime(2024, 8, 22, 11, 27, 21, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-08-22 11:27:21 UTC): Closed by the backport here: [Reduce the number of choices in onboarding flow [backport] (+316 −239)](https://github.com/metabase/metabase/pull/47067)

"
2461437307,issue,closed,completed,SDK CLI: make sure we're not using an old container,"**Context**

https://metaboat.slack.com/archives/C063Q3F1HPF/p1723460192661559

I had a old metabase-enterprise:latest image downloaded, the CLI used it but it was almost 1 year old and it didn't support some of the features we need.

We probably don't want to pull the latest version, as we may accidentally update (and possibly break) some other container running on the developer machine.

One solution could be to use a new tag

",npretto,2024-08-12 16:28:43+00:00,[],2024-10-08 16:17:52+00:00,2024-08-13 07:12:36+00:00,https://github.com/metabase/metabase/issues/46738,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2461193730,issue,closed,completed,Invalid expression Bug,"### Describe the bug

![image](https://github.com/user-attachments/assets/c37fef9c-1c4c-4614-a10c-e124f9d8ea21)

Custom column that worked in 0.46 is not working now.


### To Reproduce

![image](https://github.com/user-attachments/assets/c37fef9c-1c4c-4614-a10c-e124f9d8ea21)

Custom column that worked in 0.46 is not working now.


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""tr-TR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.5.0-1022-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4 (Debian 15.4-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-06"",
      ""tag"": ""v0.50.19"",
      ""hash"": ""0b97bf8""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

10

### Additional context

_No response_",alperengunes,2024-08-12 14:41:07+00:00,[],2024-08-12 17:37:32+00:00,2024-08-12 15:49:32+00:00,https://github.com/metabase/metabase/issues/46728,"[('Type:Bug', 'Product defects')]",[],
2461172214,issue,open,,Serialization does not stop when the request is cancelled,"### Describe the bug

If you use serialization via the api and the process starts on a request, then cancelling the request does not stop the process. This is problematic on big instances, as the user that can do an export might cancel and start over the process if it's taking a long time, which ends up with 2 exports happening in parallel (or more, leading to a DoS)

### To Reproduce

1) make a big instance, something with 30K collections
2) fire the serialization via the api
3) cancel it
4) fire it again, see that you now have 2 processes happening at the same time

### Expected behavior

the process should stop when the request is cancelled

### Logs

NA

### Information about your Metabase installation

```JSON
v4+
```


### Severity

P2

### Additional context

This should be done asynchronously with a queue, much like big batch processes work",paoliniluis,2024-08-12 14:32:31+00:00,[],2025-02-04 20:26:37+00:00,,https://github.com/metabase/metabase/issues/46727,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]",[],
2461111323,issue,closed,completed,"No space between ""Field to Map To"" and ""(required)"" ","### Describe the bug

There is no space between ""Field to Map To"" and ""(required)"" when mapping field filters in version 50.



### To Reproduce

Create a SQL question with a field filter variable.

![no_space](https://github.com/user-attachments/assets/bd370393-727f-4206-8d69-1ed556f0c53e)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50
```


### Severity

cosmetic

### Additional context

_No response_",ixipixi,2024-08-12 14:07:53+00:00,['nemanjaglumac'],2024-08-13 05:59:39+00:00,2024-08-13 05:25:21+00:00,https://github.com/metabase/metabase/issues/46724,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2284101256, 'issue_id': 2461111323, 'author': 'nemanjaglumac', 'body': 'Not just release v50. This happens in master as well.', 'created_at': datetime.datetime(2024, 8, 12, 14, 12, 59, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Assginee) on (2024-08-12 14:12:59 UTC): Not just release v50. This happens in master as well.

"
2460829621,issue,closed,not_planned,Cannot connect to backend database after EC2 update,"### Describe the bug

Increased the EC2 instance size and then tried to relaunch Metabase. Getting an error connecting to our database. 

### To Reproduce

1. SSH into Metabase
2. Stop the current docker image.
3. Restart a new one


### Expected behavior

_No response_

### Logs

ubuntu@ip-172-32-6-194:/home/natashamathur$ docker logs metabase
Picked up JAVA_TOOL_OPTIONS: -Xmx4g
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-08-12 12:07:54,585 INFO metabase.util :: Maximum memory available to JVM: 4.0 GB
2024-08-12 12:07:57,745 INFO util.encryption :: Saved credentials encryption is ENABLED for this Metabase instance. 🔐 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-08-12 12:08:04,385 INFO driver.impl :: Registered abstract driver :sql  🚚
2024-08-12 12:08:04,393 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) 🚚
2024-08-12 12:08:04,400 INFO metabase.util :: Load driver :sql-jdbc took 47.1 ms
2024-08-12 12:08:04,401 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:04,601 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:04,681 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:06,744 INFO metabase.core :: 
Metabase v0.50.15 (c6697cf) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-08-12 12:08:06,754 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-08-12 12:08:06,807 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

2024-08-12 12:08:06,862 INFO metabase.core :: Starting Metabase version v0.50.15 (c6697cf) ...
2024-08-12 12:08:06,869 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Linux"",
 ""os.version"" ""6.5.0-1023-aws"",
 ""user.language"" ""en"",
 ""user.timezone"" ""GMT""}

2024-08-12 12:08:06,872 INFO metabase.plugins :: Loading plugins in /plugins...
2024-08-12 12:08:07,166 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-08-12 12:08:07,727 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-08-12 12:08:07,762 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-08-12 12:08:08,030 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-08-12 12:08:08,041 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-08-12 12:08:08,119 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-08-12 12:08:08,123 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-08-12 12:08:08,191 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-08-12 12:08:08,193 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-08-12 12:08:08,213 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-08-12 12:08:08,220 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-08-12 12:08:08,221 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-08-12 12:08:08,315 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-08-12 12:08:08,591 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-08-12 12:08:08,592 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) 🚚
2024-08-12 12:08:08,618 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-08-12 12:08:08,619 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,661 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-08-12 12:08:08,662 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,673 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-08-12 12:08:08,673 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,674 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-08-12 12:08:08,674 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) 🚚
2024-08-12 12:08:08,682 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-08-12 12:08:08,685 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-08-12 12:08:08,686 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]
2024-08-12 12:08:08,690 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-08-12 12:08:08,691 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) 🚚
2024-08-12 12:08:08,700 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-08-12 12:08:08,700 INFO driver.impl :: Registered driver :mongo  🚚
2024-08-12 12:08:08,703 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-08-12 12:08:08,704 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,711 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-08-12 12:08:08,712 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,716 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-08-12 12:08:08,717 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-08-12 12:08:08,717 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]
2024-08-12 12:08:08,720 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-08-12 12:08:08,721 INFO driver.impl :: Registered driver :druid  🚚
2024-08-12 12:08:08,725 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-08-12 12:08:08,725 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,737 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-08-12 12:08:08,737 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) 🚚
2024-08-12 12:08:08,744 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-08-12 12:08:08,747 INFO db.setup :: Verifying postgres Database Connection ...
2024-08-12 12:08:09,430 ERROR middleware.log :: GET /api/health 503 1.2 ms (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:09,976 ERROR middleware.log :: GET /api/health 503 270.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:10,633 ERROR middleware.log :: GET /api/health 503 293.2 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:11,158 ERROR middleware.log :: GET /api/health 503 338.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:11,692 ERROR middleware.log :: GET /api/health 503 280.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:12,217 ERROR middleware.log :: GET /api/health 503 275.7 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:12,741 ERROR middleware.log :: GET /api/health 503 353.9 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:13,264 ERROR middleware.log :: GET /api/health 503 248.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:13,795 ERROR middleware.log :: GET /api/health 503 344.4 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:14,328 ERROR middleware.log :: GET /api/health 503 323.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:14,863 ERROR middleware.log :: GET /api/health 503 477.6 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:15,389 ERROR middleware.log :: GET /api/health 503 272.1 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:15,916 ERROR middleware.log :: GET /api/health 503 241.9 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:16,439 ERROR middleware.log :: GET /api/health 503 239.6 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:16,962 ERROR middleware.log :: GET /api/health 503 317.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:17,496 ERROR middleware.log :: GET /api/health 503 235.1 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:18,027 ERROR middleware.log :: GET /api/health 503 244.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:18,553 ERROR middleware.log :: GET /api/health 503 260.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:19,085 ERROR middleware.log :: GET /api/health 503 244.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:19,612 ERROR middleware.log :: GET /api/health 503 259.7 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:20,142 ERROR middleware.log :: GET /api/health 503 257.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:20,672 ERROR middleware.log :: GET /api/health 503 235.6 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:21,204 ERROR middleware.log :: GET /api/health 503 320.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:21,748 ERROR middleware.log :: GET /api/health 503 254.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:22,276 ERROR middleware.log :: GET /api/health 503 251.4 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:22,807 ERROR middleware.log :: GET /api/health 503 282.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:23,341 ERROR middleware.log :: GET /api/health 503 241.4 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:23,865 ERROR middleware.log :: GET /api/health 503 243.7 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:24,388 ERROR middleware.log :: GET /api/health 503 291.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:24,911 ERROR middleware.log :: GET /api/health 503 248.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:25,442 ERROR middleware.log :: GET /api/health 503 258.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:25,973 ERROR middleware.log :: GET /api/health 503 231.2 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:26,504 ERROR middleware.log :: GET /api/health 503 221.5 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:27,031 ERROR middleware.log :: GET /api/health 503 296.4 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:27,559 ERROR middleware.log :: GET /api/health 503 260.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:28,081 ERROR middleware.log :: GET /api/health 503 242.1 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:28,611 ERROR middleware.log :: GET /api/health 503 364.7 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:29,134 ERROR middleware.log :: GET /api/health 503 249.3 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:29,669 ERROR middleware.log :: GET /api/health 503 302.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:30,204 ERROR middleware.log :: GET /api/health 503 240.2 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:30,735 ERROR middleware.log :: GET /api/health 503 309.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:31,257 ERROR middleware.log :: GET /api/health 503 273.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:31,792 ERROR middleware.log :: GET /api/health 503 225.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:32,323 ERROR middleware.log :: GET /api/health 503 235.5 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:32,854 ERROR middleware.log :: GET /api/health 503 221.5 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:33,384 ERROR middleware.log :: GET /api/health 503 217.1 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:33,908 ERROR middleware.log :: GET /api/health 503 230.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:34,438 ERROR middleware.log :: GET /api/health 503 242.9 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:34,959 ERROR middleware.log :: GET /api/health 503 275.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:35,486 ERROR middleware.log :: GET /api/health 503 245.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:36,012 ERROR middleware.log :: GET /api/health 503 220.9 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:36,555 ERROR middleware.log :: GET /api/health 503 255.9 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:37,074 ERROR middleware.log :: GET /api/health 503 239.0 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:37,597 ERROR middleware.log :: GET /api/health 503 229.1 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:38,121 ERROR middleware.log :: GET /api/health 503 240.7 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}

2024-08-12 12:08:38,644 ERROR middleware.log :: GET /api/health 503 291.8 µs (0 DB calls) {:metabase-user-id nil} 
{:status ""initializing"", :progress 0.3}


### Information about your Metabase installation

```JSON
I can't log into this right now.
```


### Severity

Blocking usage of metabase entirely

### Additional context

_No response_",natashamathur,2024-08-12 12:12:27+00:00,[],2024-08-12 17:36:47+00:00,2024-08-12 13:02:15+00:00,https://github.com/metabase/metabase/issues/46716,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2283926887, 'issue_id': 2460829621, 'author': 'paoliniluis', 'body': 'Please post questions in the forums, thanks', 'created_at': datetime.datetime(2024, 8, 12, 13, 2, 15, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-12 13:02:15 UTC): Please post questions in the forums, thanks

"
2460819601,issue,closed,completed,"Can't use ""starting from"" or ""include (period)"" in admin > table metadata > segments","### Describe the bug

As of #45671, it is no longer possible to set ""Starting from"" or to ""include (period)"" in the relative date picker for segments.

### To Reproduce

1. Go to `/admin/datamodel/segment/create`
2. Choose ""Orders""
3. Filter by ""Created At""
4. Choose ""Relative dates...""
5. Choose either ""Previous"" or ""Next"" (it doesn't matter)
6. Click on the ""ellipsis"" menu and try choosing ""Starting from""
7. The popover simply disappears after the click on ""Starting from"" (or ""include today"") and the filter is not applied


### Expected behavior

Offset should work, just like it did in 558a983

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, 3313704, H2, Sample Database
```


### Severity

P1

### Additional context

Regression after #45671 cc @oisincoveney 

This hasn't been backported so it doesn't affect the current release branch.",nemanjaglumac,2024-08-12 12:07:45+00:00,['oisincoveney'],2024-10-08 16:17:42+00:00,2024-08-14 08:30:12+00:00,https://github.com/metabase/metabase/issues/46714,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metrics & Segments', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Embedding', '')]",[],
2460629402,issue,closed,not_planned,How to maintain formatting and display long text,"There is a field in my MySQL database that contains a long amount of text content with many carriage returns and line breaks. I used a metabase to display this field, but it couldn't display carriage returns and line breaks. All the text was displayed on one line, which looked very inconvenient，How can I configure to keep displaying carriage returns and line breaks format！",wypdao,2024-08-12 10:34:48+00:00,[],2024-08-13 02:56:25+00:00,2024-08-12 13:03:01+00:00,https://github.com/metabase/metabase/issues/46710,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2283928683, 'issue_id': 2460629402, 'author': 'paoliniluis', 'body': 'Duplicate of text wrap feature request', 'created_at': datetime.datetime(2024, 8, 12, 13, 3, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285248091, 'issue_id': 2460629402, 'author': 'wypdao', 'body': '@paoliniluis I have provided you with the email address paoliniluis@gmail.com, I sent you an email with my metabase address and account', 'created_at': datetime.datetime(2024, 8, 13, 2, 56, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-12 13:03:01 UTC): Duplicate of text wrap feature request

wypdao (Issue Creator) on (2024-08-13 02:56:25 UTC): @paoliniluis I have provided you with the email address paoliniluis@gmail.com, I sent you an email with my metabase address and account

"
2460376917,issue,closed,not_planned,Issue when upgrade from v0.49.x to v0.50.x,"### Describe the bug

when upgrade i got stuck error in here

```
2024-08-12 08:17:41,897 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'cbc3c490d8bb1723450661875'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-08-12 08:17:41,897 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-08-12 08:17:41,897 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-08-12 08:17:41,922 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.
2024-08-12 08:17:41,923 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""df6176c08bd11723450317911""'s failed in-progress jobs.
2024-08-12 08:17:41,938 INFO jdbcjobstore.JobStoreTX :: ClusterManager: ......Freed 1 acquired trigger(s).
2024-08-12 08:17:41,942 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_cbc3c490d8bb1723450661875 started.
2024-08-12 08:17:41,966 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_cbc3c490d8bb1723450661875 shutting down.
2024-08-12 08:17:41,966 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_cbc3c490d8bb1723450661875 paused.
2024-08-12 08:17:41,977 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_cbc3c490d8bb1723450661875 shutdown complete.
2024-08-12 08:17:41,986 INFO db.custom-migrations :: No forward migration for DeleteSendPulseTaskOnDowngrade
2024-08-12 08:17:41,996 INFO db.custom-migrations :: No forward migration for DeleteInitSendPulseTriggersOnDowngrade
```



### To Reproduce

change docker image from v0.49.x to v0.50.x

### Expected behavior

upgrade can work normally

### Logs

_No response_

### Information about your Metabase installation

```JSON
Server : Ubuntu 22.04
Database : Postgresql 16.2
Running on docker
```


### Severity

Medium

### Additional context

_No response_",itsnanrabban,2024-08-12 08:39:28+00:00,[],2025-01-06 10:20:01+00:00,2025-01-06 10:20:01+00:00,https://github.com/metabase/metabase/issues/46707,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Operation/', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2283546910, 'issue_id': 2460376917, 'author': 'crisptrutski', 'body': 'Thanks for reporting. Are you able to downgrade again and run the previous version for now?', 'created_at': datetime.datetime(2024, 8, 12, 9, 55, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283557843, 'issue_id': 2460376917, 'author': 'crisptrutski', 'body': 'Also it would be very useful if you could clarify exactly which versions of 49 / 50 you migrated from / to.', 'created_at': datetime.datetime(2024, 8, 12, 10, 1, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283573350, 'issue_id': 2460376917, 'author': 'crisptrutski', 'body': 'Are there not any WARN or ERROR log lines shown later in the shutdown process?', 'created_at': datetime.datetime(2024, 8, 12, 10, 9, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283681074, 'issue_id': 2460376917, 'author': 'paoliniluis', 'body': '@itsnanrabban please increase the memory, you’re probably running oom', 'created_at': datetime.datetime(2024, 8, 12, 11, 9, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283704693, 'issue_id': 2460376917, 'author': 'crisptrutski', 'body': ""It's also possible you're running into a slow migration issue (like [this one](https://github.com/metabase/metabase/issues/46497)), and could try giving the process more time to complete them."", 'created_at': datetime.datetime(2024, 8, 12, 11, 22, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285192299, 'issue_id': 2460376917, 'author': 'itsnanrabban', 'body': '> Also it would be very useful if you could clarify exactly which versions of 49 / 50 you migrated from / to.\r\n\r\nfrom v0.49.22 to v0.50.1', 'created_at': datetime.datetime(2024, 8, 13, 1, 51, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310788750, 'issue_id': 2460376917, 'author': 'luizarakaki', 'body': '@itsnanrabban any updates? Did you manage to migrate to the new version adding more memory?', 'created_at': datetime.datetime(2024, 8, 26, 18, 14, 36, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-12 09:55:47 UTC): Thanks for reporting. Are you able to downgrade again and run the previous version for now?

crisptrutski on (2024-08-12 10:01:36 UTC): Also it would be very useful if you could clarify exactly which versions of 49 / 50 you migrated from / to.

crisptrutski on (2024-08-12 10:09:52 UTC): Are there not any WARN or ERROR log lines shown later in the shutdown process?

paoliniluis on (2024-08-12 11:09:43 UTC): @itsnanrabban please increase the memory, you’re probably running oom

crisptrutski on (2024-08-12 11:22:50 UTC): It's also possible you're running into a slow migration issue (like [this one](https://github.com/metabase/metabase/issues/46497)), and could try giving the process more time to complete them.

itsnanrabban (Issue Creator) on (2024-08-13 01:51:43 UTC): from v0.49.22 to v0.50.1

luizarakaki on (2024-08-26 18:14:36 UTC): @itsnanrabban any updates? Did you manage to migrate to the new version adding more memory?

"
2460297165,issue,open,,consider using ESM or browser as a target in shadow-cljs,,uladzimirdev,2024-08-12 07:59:28+00:00,['bshepherdson'],2024-08-19 20:50:19+00:00,,https://github.com/metabase/metabase/issues/46706,[],"[{'comment_id': 2297102338, 'issue_id': 2460297165, 'author': 'bshepherdson', 'body': '@uladzimirdev can you expand a bit on what this might give us?\r\n\r\nSo far as I understand the shadow-cljs configuration, since we take the unusual (in the CLJS world) of consuming our CLJS output from JS, we need to export as a JS module that can be consumed by webpack. At least when I last looked at it, ESM support on that path was not great.', 'created_at': datetime.datetime(2024, 8, 19, 17, 43, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297432617, 'issue_id': 2460297165, 'author': 'uladzimirdev', 'body': ""@bshepherdson when we consume cljs, tree-shaking doesn't work, so even if we do not use some functions from cljs, they will be included into the bundle. I expect faster startup, faster bundling, smaller bundle"", 'created_at': datetime.datetime(2024, 8, 19, 20, 50, 18, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-08-19 17:43:38 UTC): @uladzimirdev can you expand a bit on what this might give us?

So far as I understand the shadow-cljs configuration, since we take the unusual (in the CLJS world) of consuming our CLJS output from JS, we need to export as a JS module that can be consumed by webpack. At least when I last looked at it, ESM support on that path was not great.

uladzimirdev (Issue Creator) on (2024-08-19 20:50:18 UTC): @bshepherdson when we consume cljs, tree-shaking doesn't work, so even if we do not use some functions from cljs, they will be included into the bundle. I expect faster startup, faster bundling, smaller bundle

"
2459964341,issue,open,,"When changing the variable value, the backend did not trigger a re query","### Describe the bug

I created an SQL query and set a variable, hoping that when the value of the variable changes, the query results will change in a timely manner. The value of the variable comes from a view
After completing the settings, when I update the variables, the backend log prints as:
2024-08-12 10:58:31988 DEBUG middleware. log: POST/app/card/36/query 202 [ASYNC: completed] 431.3 ms (19 database calls) Application database connection: 3/15 Jetty thread. 2/50 (4 idle, 0 queued) (85 total active threads) In flight queries: 0. (0 queues); mysql DB 3 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}
Is it a bug that the query results displayed on the page have not changed?
We are using version 0.50.19

### To Reproduce

1. Go to 'My custom question 'Display results for a certain day''
2. Click on 'selected Date'
3. Scroll down to 'The date you want to query'
4. See error
The page display result has not changed,the backend log prints as:
2024-08-12 10:58:31988 DEBUG middleware. log: POST/app/card/36/query 202 [ASYNC: completed] 431.3 ms (19 database calls) Application database connection: 3/15 Jetty thread. 2/50 (4 idle, 0 queued) (85 total active threads) In flight queries: 0. (0 queues); mysql DB 3 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}
Is it a bug that the query results displayed on the page have not changed?

### Expected behavior

After I selected a new date, the results displayed on the page changed

### Logs

2024-08-12 10:58:31988 DEBUG middleware. log: POST/app/card/36/query 202 [ASYNC: completed] 431.3 ms (19 database calls) Application database connection: 3/15 Jetty thread. 2/50 (4 idle, 0 queued) (85 total active threads) In flight queries: 0. (0 queues); mysql DB 3 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}

### Information about your Metabase installation

```JSON
my computer:win11-x64
database:mysql5.7.44
metabase:0.50.19
browser:chrome127.0.6533.100-x64
```


### Severity

serious

### Additional context

_No response_",wypdao,2024-08-12 03:26:30+00:00,[],2025-02-04 20:28:23+00:00,,https://github.com/metabase/metabase/issues/46703,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('Querying/Cache', ''), ('.Team/Querying', '')]","[{'comment_id': 2283937382, 'issue_id': 2459964341, 'author': 'crisptrutski', 'body': 'This sounds like it could be a caching issue.', 'created_at': datetime.datetime(2024, 8, 12, 13, 6, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284332159, 'issue_id': 2459964341, 'author': 'paoliniluis', 'body': ""@wypdao please post a video/screenshots, I'm not able to understand the issue"", 'created_at': datetime.datetime(2024, 8, 12, 15, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285247742, 'issue_id': 2459964341, 'author': 'wypdao', 'body': '@paoliniluis I have provided you with the email address paoliniluis@gmail.com, I sent you an email with my metabase address and account', 'created_at': datetime.datetime(2024, 8, 13, 2, 55, 56, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-12 13:06:49 UTC): This sounds like it could be a caching issue.

paoliniluis on (2024-08-12 15:48:50 UTC): @wypdao please post a video/screenshots, I'm not able to understand the issue

wypdao (Issue Creator) on (2024-08-13 02:55:56 UTC): @paoliniluis I have provided you with the email address paoliniluis@gmail.com, I sent you an email with my metabase address and account

"
2459428411,issue,closed,completed,How to connect my sqlserver,"### Describe the bug

Hello, I would like to use Metabase to connect to SQL Server (2008 R2 or 2014), but no matter how many times I reinstall and compile, and regardless of what configurations I make, I still can't add this database. First of all, my database server is functioning properly, and I've also followed many other configuration tutorials. However, the result is always “Time out after 10.0 s” when I try to add it.Has anyone else encountered this issue? If so, could you please share your solution? I would greatly appreciate it.
    tips:All configurations were done according to the Metabase documentation, and my SQL Server(2008r2 and 2014) can be remotely connected via SSMS. However, when trying to add this database in Metabase, I keep getting the error ""Time out after 10.0 s.""

### To Reproduce

1. Run chromium
2. Type ""metabaseIP:3000"", and login
3. Click ""add database""
4. Type my sqlserver infomation, and click ""save""
5. Wait minute, then print ""Time out after 10.0 s""(in metabase server log print: 2024-08-11 13:09:22,043 DEBUG middleware.log :: POST /api/database 400 20.0 s (0 DB calls) {:metabase-user-id 1} 
{:message ""Timed o
![截图 2024-08-11 13-14-01](https://github.com/user-attachments/assets/acedc47d-2b9b-44dd-9d79-7e3d0576ca46)
ut after 10.0 s""}

2024-08-11 13:09:22,494 DEBUG middleware.log :: GET /api/database 200 43.9 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 5/50 (2 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
)

### Expected behavior

_No response_

### Logs

at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at compojure.core$make_context$handler__12317.invoke(core.clj:290)
	at compojure.core$make_context$fn__12321.invoke(core.clj:300)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240)
	at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60)
	at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568)
	at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)
	at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461)
	at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385)
	at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31)
	at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86)
	at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9)
	at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41)
	at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-08-11 13:09:22,029 ERROR driver.util :: Failed to connect to Database
java.util.concurrent.TimeoutException: Timed out after 10.0 s
	at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287)
	at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279)
	at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294)
	at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290)
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:166)
	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155)
	at clojure.lang.RestFn.invoke(RestFn.java:442)
	at metabase.api.database$test_database_connection.invokeStatic(database.clj:725)
	at metabase.api.database$test_database_connection.doInvoke(database.clj:715)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.api.database$fn__127803$test_connection_details127802__127804.invoke(database.clj:779)
	at metabase.api.database$fn__127803$fn__127811.invoke(database.clj:759)
	at metabase.api.database$fn__127826.invokeStatic(database.clj:800)
	at metabase.api.database$fn__127826.invoke(database.clj:783)
	at compojure.core$wrap_response$fn__12237.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__12221.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__12226.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.server.middleware.auth$enforce_authentication$fn__118711.invoke(auth.clj:18)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at compojure.core$make_context$handler__12317.invoke(core.clj:290)
	at compojure.core$make_context$fn__12321.invoke(core.clj:300)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at compojure.core$make_context$handler__12317.invoke(core.clj:290)
	at compojure.core$make_context$fn__12321.invoke(core.clj:300)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240)
	at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60)
	at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568)
	at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)
	at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461)
	at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385)
	at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31)
	at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86)
	at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9)
	at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41)
	at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:840)
2024-08-11 13:09:22,034 ERROR api.database :: Cannot connect to Database
clojure.lang.ExceptionInfo: Timed out after 10.0 s {:message ""Timed out after 10.0 s""}
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:184)
	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155)
	at clojure.lang.RestFn.invoke(RestFn.java:442)
	at metabase.api.database$test_database_connection.invokeStatic(database.clj:725)
	at metabase.api.database$test_database_connection.doInvoke(database.clj:715)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.api.database$fn__127803$test_connection_details127802__127804.invoke(database.clj:779)
	at metabase.api.database$fn__127803$fn__127811.invoke(database.clj:759)
	at metabase.api.database$fn__127826.invokeStatic(database.clj:800)
	at metabase.api.database$fn__127826.invoke(database.clj:783)
	at compojure.core$wrap_response$fn__12237.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__12221.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__12226.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:152)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.server.middleware.auth$enforce_authentication$fn__118711.invoke(auth.clj:18)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at compojure.core$make_context$handler__12317.invoke(core.clj:290)
	at compojure.core$make_context$fn__12321.invoke(core.clj:300)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$make_context$fn__12321.invoke(core.clj:301)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at compojure.core$make_context$handler__12317.invoke(core.clj:290)
	at compojure.core$make_context$fn__12321.invoke(core.clj:300)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197)
	at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47)
	at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198)
	at compojure.core$routes$fn__12249.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240)
	at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64)
	at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60)
	at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568)
	at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424)
	at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461)
	at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385)
	at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31)
	at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32)
	at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200)
	at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77)
	at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86)
	at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9)
	at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41)
	at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.util.concurrent.TimeoutException: Timed out after 10.0 s
	at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287)
	at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279)
	at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294)
	at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290)
	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:166)
	... 185 more
2024-08-11 13:09:22,043 DEBUG middleware.log :: POST /api/database 400 20.0 s (0 DB calls) {:metabase-user-id 1} 
{:message ""Timed out after 10.0 s""}

2024-08-11 13:09:22,494 DEBUG middleware.log :: GET /api/database 200 43.9 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 5/50 (2 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}




### Information about your Metabase installation

```JSON
2024-08-11 13:05:30,526 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""17.0.12+7-Debian-2deb12u1"",
 ""java.vendor"" ""Debian"",
 ""java.vendor.url"" ""https://tracker.debian.org/openjdk-17"",
 ""java.version"" ""17.0.12"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""17.0.12+7-Debian-2deb12u1"",
 ""os.name"" ""Linux"",
 ""os.version"" ""6.1.0-23-amd64"",
 ""user.language"" ""zh"",
 ""user.timezone"" ""Asia/Shanghai""}
```


### Severity

blocking your usage of Metabase entirely

### Additional context

All configurations were done according to the Metabase documentation, and my SQL Server(2008r2 and 2014) can be remotely connected via SSMS. ",tumbler-x,2024-08-11 05:16:03+00:00,[],2024-08-12 11:13:03+00:00,2024-08-11 06:32:52+00:00,https://github.com/metabase/metabase/issues/46701,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2282642417, 'issue_id': 2459428411, 'author': 'tumbler-x', 'body': ""Sorry, it's OK"", 'created_at': datetime.datetime(2024, 8, 11, 6, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282642485, 'issue_id': 2459428411, 'author': 'tumbler-x', 'body': '> ### Describe the bug\r\n> Hello, I would like to use Metabase to connect to SQL Server (2008 R2 or 2014), but no matter how many times I reinstall and compile, and regardless of what configurations I make, I still can\'t add this database. First of all, my database server is functioning properly, and I\'ve also followed many other configuration tutorials. However, the result is always “Time out after 10.0 s” when I try to add it.Has anyone else encountered this issue? If so, could you please share your solution? I would greatly appreciate it. tips:All configurations were done according to the Metabase documentation, and my SQL Server(2008r2 and 2014) can be remotely connected via SSMS. However, when trying to add this database in Metabase, I keep getting the error ""Time out after 10.0 s.""\r\n> \r\n> ### To Reproduce\r\n> 1. Run chromium\r\n> 2. Type ""metabaseIP:3000"", and login\r\n> 3. Click ""add database""\r\n> 4. Type my sqlserver infomation, and click ""save""\r\n> 5. Wait minute, then print ""Time out after 10.0 s""(in metabase server log print: 2024-08-11 13:09:22,043 DEBUG middleware.log :: POST /api/database 400 20.0 s (0 DB calls) {:metabase-user-id 1}\r\n>    {:message ""Timed o\r\n>    ![截图 2024-08-11 13-14-01](https://private-user-images.githubusercontent.com/155147039/356852340-acedc47d-2b9b-44dd-9d79-7e3d0576ca46.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjMzNTgwNDIsIm5iZiI6MTcyMzM1Nzc0MiwicGF0aCI6Ii8xNTUxNDcwMzkvMzU2ODUyMzQwLWFjZWRjNDdkLTJiOWItNDRkZC05ZDc5LTdlM2QwNTc2Y2E0Ni5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwODExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDgxMVQwNjI5MDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zM2RjMzlhMDYzZmUxNDY4NWViMDc5ZmFlMWRiYTZlZWI3NTUxZTE5ZWU3YWQ2MWU4YjY1NGNlNTQwZDlmYzRkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.SjpezaxLlAcR6LnTxal4c1psNhflKUpAMXnZffNvYiY)\r\n>    ut after 10.0 s""}\r\n> \r\n> 2024-08-11 13:09:22,494 DEBUG middleware.log :: GET /api/database 200 43.9 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 5/50 (2 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1} )\r\n> \r\n> ### Expected behavior\r\n> _No response_\r\n> \r\n> ### Logs\r\n> at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.core$apply.invokeStatic(core.clj:667) at clojure.core$apply.invoke(core.clj:662) at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at compojure.core$make_context$handler__12317.invoke(core.clj:290) at compojure.core$make_context$fn__12321.invoke(core.clj:300) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107) at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227) at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112) at toucan2.execute$do_with_call_counts.invoke(execute.clj:103) at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226) at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40) at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240) at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64) at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49) at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88) at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55) at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77) at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60) at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568) at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462) at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441) at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424) at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461) at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385) at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31) at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261) at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32) at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200) at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28) at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77) at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86) at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9) at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94) at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41) at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77) at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source) at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) at org.eclipse.jetty.server.Server.handle(Server.java:563) at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598) at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287) at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314) at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100) at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149) at java.base/java.lang.Thread.run(Thread.java:840) 2024-08-11 13:09:22,029 ERROR driver.util :: Failed to connect to Database java.util.concurrent.TimeoutException: Timed out after 10.0 s at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287) at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279) at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294) at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290) at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:166) at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155) at clojure.lang.RestFn.invoke(RestFn.java:442) at metabase.api.database$test_database_connection.invokeStatic(database.clj:725) at metabase.api.database$test_database_connection.doInvoke(database.clj:715) at clojure.lang.RestFn.invoke(RestFn.java:425) at metabase.api.database$fn__127803$test_connection_details127802__127804.invoke(database.clj:779) at metabase.api.database$fn__127803$fn__127811.invoke(database.clj:759) at metabase.api.database$fn__127826.invokeStatic(database.clj:800) at metabase.api.database$fn__127826.invoke(database.clj:783) at compojure.core$wrap_response$fn__12237.invoke(core.clj:160) at compojure.core$wrap_route_middleware$fn__12221.invoke(core.clj:132) at compojure.core$wrap_route_info$fn__12226.invoke(core.clj:139) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:151) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:152) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at metabase.server.middleware.auth$enforce_authentication$fn__118711.invoke(auth.clj:18) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at compojure.core$make_context$handler__12317.invoke(core.clj:290) at compojure.core$make_context$fn__12321.invoke(core.clj:300) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.core$apply.invokeStatic(core.clj:667) at clojure.core$apply.invoke(core.clj:662) at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at compojure.core$make_context$handler__12317.invoke(core.clj:290) at compojure.core$make_context$fn__12321.invoke(core.clj:300) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107) at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227) at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112) at toucan2.execute$do_with_call_counts.invoke(execute.clj:103) at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226) at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40) at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240) at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64) at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49) at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88) at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55) at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77) at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60) at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568) at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462) at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441) at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424) at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461) at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385) at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31) at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261) at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32) at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200) at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28) at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77) at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86) at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9) at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94) at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41) at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77) at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source) at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) at org.eclipse.jetty.server.Server.handle(Server.java:563) at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598) at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287) at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314) at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100) at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149) at java.base/java.lang.Thread.run(Thread.java:840) 2024-08-11 13:09:22,034 ERROR api.database :: Cannot connect to Database clojure.lang.ExceptionInfo: Timed out after 10.0 s {:message ""Timed out after 10.0 s""} at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:184) at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:155) at clojure.lang.RestFn.invoke(RestFn.java:442) at metabase.api.database$test_database_connection.invokeStatic(database.clj:725) at metabase.api.database$test_database_connection.doInvoke(database.clj:715) at clojure.lang.RestFn.invoke(RestFn.java:425) at metabase.api.database$fn__127803$test_connection_details127802__127804.invoke(database.clj:779) at metabase.api.database$fn__127803$fn__127811.invoke(database.clj:759) at metabase.api.database$fn__127826.invokeStatic(database.clj:800) at metabase.api.database$fn__127826.invoke(database.clj:783) at compojure.core$wrap_response$fn__12237.invoke(core.clj:160) at compojure.core$wrap_route_middleware$fn__12221.invoke(core.clj:132) at compojure.core$wrap_route_info$fn__12226.invoke(core.clj:139) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:151) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:152) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at metabase.server.middleware.auth$enforce_authentication$fn__118711.invoke(auth.clj:18) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at compojure.core$make_context$handler__12317.invoke(core.clj:290) at compojure.core$make_context$fn__12321.invoke(core.clj:300) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$make_context$fn__12321.invoke(core.clj:301) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.lang.AFunction$1.doInvoke(AFunction.java:31) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at clojure.lang.Var.invoke(Var.java:393) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.api.routes$fn__138790$fn__138793.invoke(routes.clj:72) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at clojure.lang.AFn.applyToHelper(AFn.java:160) at clojure.lang.AFn.applyTo(AFn.java:144) at clojure.core$apply.invokeStatic(core.clj:667) at clojure.core$apply.invoke(core.clj:662) at metabase.server.routes$fn__139078$fn__139079.doInvoke(routes.clj:73) at clojure.lang.RestFn.invoke(RestFn.java:436) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at compojure.core$make_context$handler__12317.invoke(core.clj:290) at compojure.core$make_context$fn__12321.invoke(core.clj:300) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at compojure.core$wrap_route_matches$fn__12230.invoke(core.clj:153) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249$f__12250$respond_SINGLEQUOTE___12251.invoke(core.clj:197) at metabase.server.routes$fn__139061$fn__139063.invoke(routes.clj:47) at compojure.core$routes$fn__12249$f__12250.invoke(core.clj:198) at compojure.core$routes$fn__12249.invoke(core.clj:200) at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__118951.invoke(exceptions.clj:107) at metabase.server.middleware.exceptions$catch_api_exceptions$fn__118948.invoke(exceptions.clj:96) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184$fn__119185.invoke(log.clj:236) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18) at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12) at metabase.server.middleware.log$log_api_call$fn__119183$fn__119184.invoke(log.clj:227) at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112) at toucan2.execute$do_with_call_counts.invoke(execute.clj:103) at metabase.server.middleware.log$log_api_call$fn__119183.invoke(log.clj:226) at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__118757.invoke(browser_cookie.clj:40) at metabase.server.middleware.security$add_security_headers$fn__118899.invoke(security.clj:240) at ring.middleware.json$wrap_json_body$fn__139373.invoke(json.clj:64) at metabase.server.middleware.offset_paging$handle_paging$fn__119218.invoke(offset_paging.clj:49) at metabase.server.middleware.json$wrap_streamed_json_response$fn__72858.invoke(json.clj:88) at ring.middleware.keyword_params$wrap_keyword_params$fn__139470.invoke(keyword_params.clj:55) at ring.middleware.params$wrap_params$fn__139497.invoke(params.clj:77) at metabase.server.middleware.misc$maybe_set_site_url$fn__81287.invoke(misc.clj:60) at metabase.server.middleware.session$reset_session_timeout$fn__98537.invoke(session.clj:568) at metabase.server.middleware.session$bind_current_user$fn__98495$fn__98496.invoke(session.clj:462) at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:441) at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:424) at metabase.server.middleware.session$bind_current_user$fn__98495.invoke(session.clj:461) at metabase.server.middleware.session$wrap_current_user_info$fn__98466.invoke(session.clj:385) at metabase.analytics.sdk$bind_embedding_mw$bound_embedding__48252.invoke(sdk.clj:31) at metabase.server.middleware.session$wrap_session_id$fn__98438.invoke(session.clj:261) at metabase.server.middleware.auth$wrap_static_api_key$fn__118719.invoke(auth.clj:32) at ring.middleware.cookies$wrap_cookies$fn__139285.invoke(cookies.clj:200) at metabase.server.middleware.misc$add_content_type$fn__81269.invoke(misc.clj:28) at metabase.server.middleware.misc$disable_streaming_buffering$fn__81295.invoke(misc.clj:77) at ring.middleware.gzip$wrap_gzip$fn__139335.invoke(gzip.clj:86) at metabase.server.middleware.request_id$wrap_request_id$fn__119233.invoke(request_id.clj:9) at metabase.server.middleware.misc$bind_request$fn__81298.invoke(misc.clj:94) at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__119256.invoke(ssl.clj:41) at metabase.server$async_proxy_handler$fn__73915.invoke(server.clj:77) at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source) at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173) at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122) at org.eclipse.jetty.server.Server.handle(Server.java:563) at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598) at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753) at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501) at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287) at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314) at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100) at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53) at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194) at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149) at java.base/java.lang.Thread.run(Thread.java:840) Caused by: java.util.concurrent.TimeoutException: Timed out after 10.0 s at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287) at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279) at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294) at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290) at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:166) ... 185 more 2024-08-11 13:09:22,043 DEBUG middleware.log :: POST /api/database 400 20.0 s (0 DB calls) {:metabase-user-id 1} {:message ""Timed out after 10.0 s""}\r\n> \r\n> 2024-08-11 13:09:22,494 DEBUG middleware.log :: GET /api/database 200 43.9 ms (1 DB calls) App DB connections: 0/4 Jetty threads: 5/50 (2 idle, 0 queued) (35 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n> \r\n> ### Information about your Metabase installation\r\n> ```json\r\n> 2024-08-11 13:05:30,526 INFO metabase.core :: System info:\r\n>  {""file.encoding"" ""UTF-8"",\r\n>  ""java.runtime.name"" ""OpenJDK Runtime Environment"",\r\n>  ""java.runtime.version"" ""17.0.12+7-Debian-2deb12u1"",\r\n>  ""java.vendor"" ""Debian"",\r\n>  ""java.vendor.url"" ""https://tracker.debian.org/openjdk-17"",\r\n>  ""java.version"" ""17.0.12"",\r\n>  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",\r\n>  ""java.vm.version"" ""17.0.12+7-Debian-2deb12u1"",\r\n>  ""os.name"" ""Linux"",\r\n>  ""os.version"" ""6.1.0-23-amd64"",\r\n>  ""user.language"" ""zh"",\r\n>  ""user.timezone"" ""Asia/Shanghai""}\r\n> ```\r\n> \r\n> ### Severity\r\n> blocking your usage of Metabase entirely\r\n> \r\n> ### Additional context\r\n> All configurations were done according to the Metabase documentation, and my SQL Server(2008r2 and 2014) can be remotely connected via SSMS.', 'created_at': datetime.datetime(2024, 8, 11, 6, 29, 22, tzinfo=datetime.timezone.utc)}]","tumbler-x (Issue Creator) on (2024-08-11 06:29:00 UTC): Sorry, it's OK

tumbler-x (Issue Creator) on (2024-08-11 06:29:22 UTC): 

"
2459022009,issue,closed,not_planned,how to connect sqlserver 2008r2?,"Hello, I would like to use Metabase to connect to SQL Server 2008 R2, but no matter how many times I reinstall and compile, and regardless of what configurations I make, I still can't add this database. First of all, my database server is functioning properly, and I've also followed many other configuration tutorials. However, the result is always “Time out after 10.0 s” when I try to add it. I suspect that the issue might be due to the built-in JDBC driver in Metabase being too new, causing incompatibility with the older version of SQL Server. Has anyone else encountered this issue? If so, could you please share your solution? I would greatly appreciate it.",tumbler-x,2024-08-10 10:18:27+00:00,[],2024-08-10 18:13:15+00:00,2024-08-10 18:13:15+00:00,https://github.com/metabase/metabase/issues/46700,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2280853086, 'issue_id': 2459022009, 'author': 'tumbler-x', 'body': 'All configurations were done according to the Metabase documentation, and my SQL Server can be remotely connected via SSMS. However, when trying to add this database in Metabase, I keep getting the error ""Time out after 10.0 s.""', 'created_at': datetime.datetime(2024, 8, 10, 10, 23, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282232678, 'issue_id': 2459022009, 'author': 'paoliniluis', 'body': 'please start a thread in our forums, this is for raising issues, not questions', 'created_at': datetime.datetime(2024, 8, 10, 18, 13, 15, tzinfo=datetime.timezone.utc)}]","tumbler-x (Issue Creator) on (2024-08-10 10:23:57 UTC): All configurations were done according to the Metabase documentation, and my SQL Server can be remotely connected via SSMS. However, when trying to add this database in Metabase, I keep getting the error ""Time out after 10.0 s.""

paoliniluis on (2024-08-10 18:13:15 UTC): please start a thread in our forums, this is for raising issues, not questions

"
2458855945,issue,open,,/api/collection/graph is slow when there are a lot of collections,"### Describe the bug

This is interesting since we fixed [https://github.com/metabase/metabase/issues/39997](https://github.com/metabase/metabase/issues/39997) as we were returning a massive response before, but now the issue is that although the response is small, it takes a lot of time to generate a response, and pegs a single core while doing so

### To Reproduce

1. create 30K collections like in [https://github.com/metabase/metabase/issues/46695](https://github.com/metabase/metabase/issues/46695)
2. then go to settings->admin->permissions
3. see the endpoint taking a lot of time

### Expected behavior

It should be fastj

### Logs

NA

### Information about your Metabase installation

```JSON
v50.19
```

### Severity

P1

### Additional context

Queries are super fast

![image](https://uploads.linear.app/aa0b7104-d385-47b7-bfc6-015760e1d91e/e478d793-e5d0-472c-bc09-1f9aaff0f0e6/626fbc09-92fa-4e9f-b4f1-dd9bd363c1cd?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiL2FhMGI3MTA0LWQzODUtNDdiNy1iZmM2LTAxNTc2MGUxZDkxZS9lNDc4ZDc5My1lNWQwLTQ3MmMtYmMwOS0xZjlhYWZmMGYwZTYvNjI2ZmJjMDktOTJmYS00ZTlmLWI0ZjEtZGQ5YmQzNjNjMWNkIiwiaWF0IjoxNzM3NTU0NDk5LCJleHAiOjMzMzA4MTE0NDk5fQ.s8PB-M8AG9jZizozyVjhg6Hv2huIMXpD-khM9J-xrX4)

![image](https://uploads.linear.app/aa0b7104-d385-47b7-bfc6-015760e1d91e/e6dd5699-094b-4334-91a0-ee051f8c23d2/cf512b46-1f68-4099-82ba-5976e6b325db?signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJwYXRoIjoiL2FhMGI3MTA0LWQzODUtNDdiNy1iZmM2LTAxNTc2MGUxZDkxZS9lNmRkNTY5OS0wOTRiLTQzMzQtOTFhMC1lZTA1MWY4YzIzZDIvY2Y1MTJiNDYtMWY2OC00MDk5LTgyYmEtNTk3NmU2YjMyNWRiIiwiaWF0IjoxNzM3NTU0NDk5LCJleHAiOjMzMzA4MTE0NDk5fQ.TRShhxR8Zgig01WlZVE2z7iQSbCCCEkSnwCQg_PwLaQ)

This could be exacerbated",paoliniluis,2024-08-10 02:22:13+00:00,[],2025-02-05 19:22:48+00:00,,https://github.com/metabase/metabase/issues/46697,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2458847751,issue,closed,not_planned,"Something is fishy with /api/collection/root, /api/search?models=dataset&limit=1, /api/activity/recent_views and /api/activity/popular_items","### Describe the bug

After checking https://github.com/metabase/metabase/issues/46695, I saw that those endpoints can take 500ms or 4 seconds, and there's no clear reason about why so much difference with the same resources and a single user

### To Reproduce

1) Do the same repro as https://github.com/metabase/metabase/issues/46695
2) On the main screen, reload entirely the frame, several times
3) see the difference (probably cpu bound?)

![image](https://github.com/user-attachments/assets/f7cdd799-7ba3-4e21-939e-f07acf39d054)
![image](https://github.com/user-attachments/assets/b1f9c19f-6348-467d-9558-04a3eaa278b7)
![image](https://github.com/user-attachments/assets/c3a5b94d-bd13-4159-ae8e-dc5e96c655dc)


### Expected behavior

Endpoints should always respond in the same time (considering the same amount of resources and concurrency)

### Logs

![image](https://github.com/user-attachments/assets/22ca50ad-79d3-4277-b75b-cccda54bcf60)
![image](https://github.com/user-attachments/assets/1810f7ee-e401-4d37-be36-ec7d77627b0d)


### Information about your Metabase installation

```JSON
v50.19
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-08-10 01:55:38+00:00,['johnswanson'],2025-02-05 19:01:38+00:00,2025-02-05 19:01:38+00:00,https://github.com/metabase/metabase/issues/46696,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Misc/API', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2283712738, 'issue_id': 2458847751, 'author': 'crisptrutski', 'body': '@paoliniluis just wanted to double check you really want this as a P1 (from the description)', 'created_at': datetime.datetime(2024, 8, 12, 11, 25, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284156063, 'issue_id': 2458847751, 'author': 'paoliniluis', 'body': ""@crisptrutski I have the feeling this might be a P1 soon (very soon) as these endpoints should take the same amount of time every time they're hit. Let's move it to a P2, but keep it on the radar"", 'created_at': datetime.datetime(2024, 8, 12, 14, 34, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2338927964, 'issue_id': 2458847751, 'author': 'iethree', 'body': 'I\'m not sure this is a ""bug"" per se. Couldn\'t this just be a result of underlying DB query caching?', 'created_at': datetime.datetime(2024, 9, 9, 19, 36, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339051340, 'issue_id': 2458847751, 'author': 'paoliniluis', 'body': '@iethree nope, the difference is massive', 'created_at': datetime.datetime(2024, 9, 9, 20, 42, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405747630, 'issue_id': 2458847751, 'author': 'johnswanson', 'body': ""I've been trying to repro this and haven't been able to.\n\nI did the repro specified for https://github.com/metabase/metabase/issues/46695, specifically creating 30k collections.\n\nUsing hyperfine, I tested each endpoint:\n- `/api/collection/root`\n\n```\nTime (mean ± σ):     291.8 ms ±  46.3 ms    [User: 4.3 ms, System: 6.9 ms]\n  Range (min … max):   241.1 ms … 377.9 ms    20 runs\n```\n\n- `/api/search?models=dataset&limit=1`\n\n```\n  Time (mean ± σ):     392.5 ms ±  18.5 ms    [User: 4.2 ms, System: 6.7 ms]\n  Range (min … max):   378.0 ms … 444.6 ms    20 runs\n```\n\n- `/api/activity/popular_items`\n\n```\n  Time (mean ± σ):      17.8 ms ±   1.6 ms    [User: 2.9 ms, System: 4.5 ms]\n  Range (min … max):    14.8 ms …  22.8 ms    119 runs\n```\n\n- `/api/activity/recents?context=views`\n\n```\n  Time (mean ± σ):      14.7 ms ±   6.7 ms    [User: 2.6 ms, System: 3.9 ms]\n  Range (min … max):    12.4 ms …  93.5 ms    144 runs\n```\n\nThese seem like pretty normal distributions to me, so I think we should probably close this unless I'm doing something wrong in my repro attempts."", 'created_at': datetime.datetime(2024, 10, 10, 18, 10, 6, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-12 11:25:45 UTC): @paoliniluis just wanted to double check you really want this as a P1 (from the description)

paoliniluis (Issue Creator) on (2024-08-12 14:34:21 UTC): @crisptrutski I have the feeling this might be a P1 soon (very soon) as these endpoints should take the same amount of time every time they're hit. Let's move it to a P2, but keep it on the radar

iethree on (2024-09-09 19:36:18 UTC): I'm not sure this is a ""bug"" per se. Couldn't this just be a result of underlying DB query caching?

paoliniluis (Issue Creator) on (2024-09-09 20:42:44 UTC): @iethree nope, the difference is massive

johnswanson (Assginee) on (2024-10-10 18:10:06 UTC): I've been trying to repro this and haven't been able to.

I did the repro specified for https://github.com/metabase/metabase/issues/46695, specifically creating 30k collections.

Using hyperfine, I tested each endpoint:
- `/api/collection/root`

```
Time (mean ± σ):     291.8 ms ±  46.3 ms    [User: 4.3 ms, System: 6.9 ms]
  Range (min … max):   241.1 ms … 377.9 ms    20 runs
```

- `/api/search?models=dataset&limit=1`

```
  Time (mean ± σ):     392.5 ms ±  18.5 ms    [User: 4.2 ms, System: 6.7 ms]
  Range (min … max):   378.0 ms … 444.6 ms    20 runs
```

- `/api/activity/popular_items`

```
  Time (mean ± σ):      17.8 ms ±   1.6 ms    [User: 2.9 ms, System: 4.5 ms]
  Range (min … max):    14.8 ms …  22.8 ms    119 runs
```

- `/api/activity/recents?context=views`

```
  Time (mean ± σ):      14.7 ms ±   6.7 ms    [User: 2.6 ms, System: 3.9 ms]
  Range (min … max):    12.4 ms …  93.5 ms    144 runs
```

These seem like pretty normal distributions to me, so I think we should probably close this unless I'm doing something wrong in my repro attempts.

"
2458846314,issue,closed,completed,/api/collection takes too much time in v50,"### Describe the bug

There seems to be an issue in /api/collection (you hit this endpoint as soon as the save question modal appears): the query to the DB seems super fast, but we take a lot of time to send it back to the user
![image](https://github.com/user-attachments/assets/03b5c4cb-2bc7-4515-85a0-de5254e10263)


### To Reproduce

1) set up Metabase v50
2) add a lot of collections (10K would be fine, I used 30K to make it worse)
3) create a question and click on save, to make the modal window appear
4) see the /api/collection endpoint hitting, it should take a considerable amount of time (takes 25 secs on my example and returns a 11MB JSON). (uses 100% of a single CPU so I believe it's building JSON)

![image](https://github.com/user-attachments/assets/1a3fbf63-5299-4abf-ac33-73c8fae1035a)

![image](https://github.com/user-attachments/assets/5ce0c7e8-f6c7-457e-b9b2-491dd3abc817)



### Expected behavior

Should be fast

### Logs

NA

### Information about your Metabase installation

```JSON
v50.19
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-08-10 01:50:36+00:00,['iethree'],2024-08-21 20:05:44+00:00,2024-08-19 14:48:55+00:00,https://github.com/metabase/metabase/issues/46695,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Organization/Collections', ''), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2458394172,issue,closed,completed,[BE] Change how new metric-based queries are created in MBQL lib,,metamben,2024-08-09 17:50:08+00:00,['metamben'],2024-10-08 16:17:46+00:00,2024-08-13 18:21:38+00:00,https://github.com/metabase/metabase/issues/46687,[],[],
2458207388,issue,open,,Burn admins retina with a red ribbon if they're running Metabase with H2,"**Is your feature request related to a problem? Please describe.**
We need to stop admins from running Metabase with the H2 database. There's people that simply don't read the docs and we need to catch that problem before it's too late

**Describe the solution you'd like**
I would like a red ribbon in the top of every page that tells admins that they're running Metabase in test mode, and they need to consider using a proper application database

**Describe alternatives you've considered**
None

**How important is this feature to you?**
We need to stop people from using H2

**Additional context**
NA
",paoliniluis,2024-08-09 15:46:38+00:00,[],2025-02-04 20:30:43+00:00,,https://github.com/metabase/metabase/issues/46682,"[('Type:New Feature', ''), ('Administration/', '')]",[],
2458013156,issue,open,,Metabase SQL preview is not consistent with the query being sent - MYSQL specific,"### Describe the bug

There is something odd going on with the preview and MYSQL. It gives you the impression you are running a query which in fact you are not.



### To Reproduce

1) Connect with a MYSQL Database
2) Go to New -> SQL Question -> Paste `Select {{date_}} from large_table` -> Set it as a Date Filter and set a Date and Time like so:

<img width=""1510"" alt=""image"" src=""https://github.com/user-attachments/assets/f8a31aa7-6196-4deb-a02f-3868e7e9829c"">

3) Now notice the preview and you will see that metabase is saying it's adding a `timestamp` infront of the Date:

<img width=""1479"" alt=""image"" src=""https://github.com/user-attachments/assets/929805b9-bb96-4f3d-9a45-de2e68f6bd88"">

Which is fine but if you execute the query in metabase and monitor the MYSQL logs you will see the timestamp is net being added.

4) You can also confirm this by adding a timestamp in the SQL and execute it, the preview will say it run `Select timestamp timestamp '2024-08-13 12:30:00.000' from large_table` and in fact metabase runs

<img width=""1511"" alt=""image"" src=""https://github.com/user-attachments/assets/9d35cfce-070d-4c59-94ee-a562546e7f4f"">

 but if you execute that query into any IDE you will get an error:

<img width=""1129"" alt=""image"" src=""https://github.com/user-attachments/assets/468f8729-2048-4940-b9fb-67f3304f4c29"">

This doesn't happen on Postgres and metabase is consistent in the preview vs what is actually being sent, adding multiple timestamps causes error as expected:

<img width=""1499"" alt=""image"" src=""https://github.com/user-attachments/assets/3e0bd1dc-25e2-4129-b78f-946162b0392c"">





### Expected behavior

The SQL that gets executes is the same as being shown in the preview.

### Logs

None that are relevant

### Information about your Metabase installation

```JSON
Happens in 48 and also in master
```


### Severity

This might look like a cosmetic bug but this small example can have performance implications if the `timestamp` keyword is skipped and there are a lot of Date operations

### Additional context

Added the P2 cause a customer was able to improve the query from 56 sec to 38 sec simply by adding these `timestamp` keywords in front of the filters manually. Which is something that we should do automatically (at least we say we do)",Tony-metabase,2024-08-09 14:08:54+00:00,[],2025-02-04 20:27:14+00:00,,https://github.com/metabase/metabase/issues/46680,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Database/MySQL', None), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2457824401,issue,closed,completed,Draft join can cause invalid queries,"### Describe the bug

![image](https://github.com/user-attachments/assets/a0373d6d-a3f2-419b-815d-396fcabf34b0)


### To Reproduce

1. New > Question > Orders
2. Join > Reviews > Choose right join column: ""Created At"" (don't choose the left one)
3. Change join table to Invoices
4. Choose left join column, e.g. ""Created At""
5. Visualize

Error:
""Column ""Invoices - Created At.CREATED_AT"" not found""


### Information about your Metabase installation

master, e6b84e42e05a051f357d8c20ca438ef4e387216c


### Severity

P2
",kamilmielnik,2024-08-09 12:35:27+00:00,['ranquild'],2024-10-22 18:46:41+00:00,2024-10-22 16:33:41+00:00,https://github.com/metabase/metabase/issues/46675,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', ''), ('Frequency:Often', 'Something users bump into often')]","[{'comment_id': 2346758971, 'issue_id': 2457824401, 'author': 'mngr', 'body': ""the dropdown value should be cleared if the newly chosen table doesn't support it\r\nwe should clear local state immediately in this case"", 'created_at': datetime.datetime(2024, 9, 12, 16, 32, 53, tzinfo=datetime.timezone.utc)}]","mngr on (2024-09-12 16:32:53 UTC): the dropdown value should be cleared if the newly chosen table doesn't support it
we should clear local state immediately in this case

"
2457702616,issue,closed,not_planned,My personal collection has wrong title in the entity picker,"### Describe the bug

In the entity picker my personal collection is shown as Gleb Sologub's Personal Collection instead of Your personal collection

### To Reproduce

1. Open the entity picker from anywhere (data picker in the notebook editor or saving question for example)
2. In the Recents tab items from my personal collection are marked with Gleb Sologub's Personal Collection
3. Open any other tab with collections, you'll see the same


### Expected behavior

Should be shown as Your Personal Collection

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Just not so nice and might be confusing

### Additional context

_No response_",mngr,2024-08-09 11:21:39+00:00,[],2025-01-22 14:02:02+00:00,2025-01-22 14:02:02+00:00,https://github.com/metabase/metabase/issues/46672,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Misc/API', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2436038013, 'issue_id': 2457702616, 'author': 'rafpaf', 'body': 'We usually call the user\'s own personal collection by its canonical name, ""[Name]\'s personal collection"", except in the sidebar and saved entity picker, so I think we can probably leave this as is.', 'created_at': datetime.datetime(2024, 10, 24, 18, 8, 5, tzinfo=datetime.timezone.utc)}]","rafpaf on (2024-10-24 18:08:05 UTC): We usually call the user's own personal collection by its canonical name, ""[Name]'s personal collection"", except in the sidebar and saved entity picker, so I think we can probably leave this as is.

"
2457695191,issue,closed,completed,Setting user_group_memberships in API endpoint /api/user always fails in Metabase Pro,"### Describe the bug

Since our Update to Metabase Pro, Metabase seems unable to update Group Membership via user_group_memberships in api/user. 

""You cannot add or remove users to/from the 'All Users' group."" always appears. 

### To Reproduce

`PUT api/user/13371344`
Data: `{""user_group_memberships"": [{""id"": 33}, {""id"": 1}, {""id"": 34}, {""id"": 36}, {""id"": 3}, {""id"": 5}, {""id"": 41}, {""id"": 11}, {""id"": 16}, {""id"": 29}]}`

**Response:** 
`You cannot add or remove users to/from the 'All Users' group.`


If I try to remove gid=1 (All Users), the error still remains...


`PUT api/user/13371344`
Data: `{""user_group_memberships"": [{""id"": 33}, {""id"": 34}, {""id"": 36}, {""id"": 3}, {""id"": 5}, {""id"": 41}, {""id"": 11}, {""id"": 16}, {""id"": 29}]}`

**Response:** 
`You cannot add or remove users to/from the 'All Users' group.`


### Expected behavior

The request should be executed the same way as before in the non-pro version

### Logs

2024-08-09 12:58:17,358 [DEBUG] cron-metabase-ldap-sync: MB request details: put /api/user/13371344

Request data: 
{'user_group_memberships': [{'id': 33}, {'id': 1}, {'id': 34}, {'id': 36}, {'id': 3}, {'id': 5}, {'id': 41}, {'id': 11}, {'id': 16}, {'id': 29}]}

Response data: (code=400) 
You cannot add or remove users to/from the 'All Users' group.



2024-08-09 13:12:40,496 [DEBUG] cron-metabase-ldap-sync: MB request details: put /api/user/13371344

Request data: 
{'user_group_memberships': [{'id': 33}, {'id': 34}, {'id': 36}, {'id': 3}, {'id': 5}, {'id': 41}, {'id': 11}, {'id': 16}, {'id': 29}]}

Response data: (code=400) 
You cannot add or remove users to/from the 'All Users' group.

### Information about your Metabase installation

```JSON
v1.50.11
Built on 2024-07-09
```


### Severity

blocking

### Additional context

_No response_",s-huk,2024-08-09 11:16:55+00:00,['johnswanson'],2025-02-04 02:57:08+00:00,2025-02-03 23:21:46+00:00,https://github.com/metabase/metabase/issues/46671,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('.Team/Drivers', '')]","[{'comment_id': 2278043408, 'issue_id': 2457695191, 'author': 'dpsutton', 'body': '@s-huk that\'s really annoying. Sorry about that. This is a subtle bug in the checks we do about which groups are new and which are missing (and therefore to be removed).\r\n\r\nThe good news is that there is a workaround while we prepare a fix\r\n\r\n```\r\n❯ echo \'{""user_group_memberships"": [{""id"": 1}]}\' | http put localhost:3000/api/user/1 x-api-key:$API_KEY -pb\r\nYou cannot add or remove users to/from the \'All Users\' group.\r\n\r\n❯ echo \'{""user_group_memberships"": [{""id"": 1, ""is_group_manager"": false}]}\' | http put localhost:3000/api/user/1 x-api-key:$API_KEY -pb\r\n{\r\n...\r\n    ""id"": 1,\r\n    ""is_active"": true,\r\n    ""is_qbnewb"": true,\r\n...\r\n    ""user_group_memberships"": [\r\n        {\r\n            ""id"": 1,\r\n            ""is_group_manager"": false\r\n        }\r\n    ]\r\n}\r\n```\r\n\r\nIf you include `""is_group_manager"": <bool>` on each of the groups you are sending over it will succeed.\r\n\r\nIt\'s because in the [oss version](https://github.com/metabase/metabase/blob/master/src/metabase/models/user.clj#L436-L437) we\'re careful about only comparing ids whereas in [enterprise](https://github.com/metabase/metabase/blob/master/enterprise/backend/src/metabase_enterprise/advanced_permissions/models/permissions/group_manager.clj#L34) we do not consider the absence of the group manager information and therefore thing that group is removed.', 'created_at': datetime.datetime(2024, 8, 9, 14, 12, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283450024, 'issue_id': 2457695191, 'author': 's-huk', 'body': 'It works fine if I add ""is_group_manager"" uniformly to every `user_group_memberships` entry. And thanks for pointing out the code for Metabase Enterprise. So, Im lucky, but you generally might want to improve the API\'s quality, because, e.g., if I mix up `user_group_memberships` entries with and without `is_group_manager` property (non-uniformly), then really dangerously bad conditions appear...\r\n\r\n**Reuest:**\r\n{""user_group_memberships"": [{""id"": 33}, {""id"": 1, ""is_group_manager"": false}, {""id"": 34}, {""id"": 36}, {""id"": 3}, {""id"": 5}, {""id"": 41}, {""id"": 11}, {""id"": 16}, {""id"": 29}]}\r\n\r\n**Response: 500**\r\n```\r\n{\r\n\t""via"": [\r\n\t\t{\r\n\t\t\t""type"": ""clojure.lang.ExceptionInfo"",\r\n\t\t\t""message"": ""(conn=708120) Column \'is_group_manager\' cannot be null"",\r\n\t\t\t""data"": {\r\n\t\t\t\t""toucan2/context-trace"": [\r\n\t\t\t\t\t[\r\n\t\t\t\t\t\t""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"",\r\n\t\t\t\t\t\t{\r\n\t\t\t\t\t\t\t""toucan2.jdbc.query/sql-args"": [\r\n\t\t\t\t\t\t\t\t""INSERT INTO `permissions_group_membership` (`user_id`, `group_id`, `is_group_manager`) VALUES (?, ?, NULL)"",\r\n\t\t\t\t\t\t\t\t13371344,\r\n\t\t\t\t\t\t\t\t33\r\n\t\t\t\t\t\t\t]\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t],\r\n\t\t\t\t\t...\r\n```\r\n\r\nI would suggest to validate request data against a JSON Schema for example.', 'created_at': datetime.datetime(2024, 8, 12, 9, 4, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2632707476, 'issue_id': 2457695191, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 2, 4, 2, 57, 7, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-08-09 14:12:29 UTC): @s-huk that's really annoying. Sorry about that. This is a subtle bug in the checks we do about which groups are new and which are missing (and therefore to be removed).

The good news is that there is a workaround while we prepare a fix

```
❯ echo '{""user_group_memberships"": [{""id"": 1}]}' | http put localhost:3000/api/user/1 x-api-key:$API_KEY -pb
You cannot add or remove users to/from the 'All Users' group.

❯ echo '{""user_group_memberships"": [{""id"": 1, ""is_group_manager"": false}]}' | http put localhost:3000/api/user/1 x-api-key:$API_KEY -pb
{
...
    ""id"": 1,
    ""is_active"": true,
    ""is_qbnewb"": true,
...
    ""user_group_memberships"": [
        {
            ""id"": 1,
            ""is_group_manager"": false
        }
    ]
}
```

If you include `""is_group_manager"": <bool>` on each of the groups you are sending over it will succeed.

It's because in the [oss version](https://github.com/metabase/metabase/blob/master/src/metabase/models/user.clj#L436-L437) we're careful about only comparing ids whereas in [enterprise](https://github.com/metabase/metabase/blob/master/enterprise/backend/src/metabase_enterprise/advanced_permissions/models/permissions/group_manager.clj#L34) we do not consider the absence of the group manager information and therefore thing that group is removed.

s-huk (Issue Creator) on (2024-08-12 09:04:59 UTC): It works fine if I add ""is_group_manager"" uniformly to every `user_group_memberships` entry. And thanks for pointing out the code for Metabase Enterprise. So, Im lucky, but you generally might want to improve the API's quality, because, e.g., if I mix up `user_group_memberships` entries with and without `is_group_manager` property (non-uniformly), then really dangerously bad conditions appear...

**Reuest:**
{""user_group_memberships"": [{""id"": 33}, {""id"": 1, ""is_group_manager"": false}, {""id"": 34}, {""id"": 36}, {""id"": 3}, {""id"": 5}, {""id"": 41}, {""id"": 11}, {""id"": 16}, {""id"": 29}]}

**Response: 500**
```
{
	""via"": [
		{
			""type"": ""clojure.lang.ExceptionInfo"",
			""message"": ""(conn=708120) Column 'is_group_manager' cannot be null"",
			""data"": {
				""toucan2/context-trace"": [
					[
						""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"",
						{
							""toucan2.jdbc.query/sql-args"": [
								""INSERT INTO `permissions_group_membership` (`user_id`, `group_id`, `is_group_manager`) VALUES (?, ?, NULL)"",
								13371344,
								33
							]
						}
					],
					...
```

I would suggest to validate request data against a JSON Schema for example.

github-actions[bot] on (2025-02-04 02:57:07 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2457544545,issue,closed,completed,"Add moving average option to ""compare to the past"" modal",,romeovs,2024-08-09 09:49:05+00:00,[],2024-10-08 16:17:33+00:00,2024-08-14 13:42:01+00:00,https://github.com/metabase/metabase/issues/46669,[],[],
2457527994,issue,closed,completed,Wrong menu item color on hover,"### Describe the bug

![image](https://github.com/user-attachments/assets/b06c273d-3df7-49af-a801-846c4f663774)


### To Reproduce

1. Create dashboard and edit it
2. Open dropdown for the dashboard tab
3. Hover dropdown menu item

Menu item background should be light blue, not dark.

### Information about your Metabase installation

master, ea677b3


### Severity

P3
",kamilmielnik,2024-08-09 09:39:59+00:00,[],2025-01-08 14:53:33+00:00,2025-01-08 14:53:30+00:00,https://github.com/metabase/metabase/issues/46668,"[('Type:Bug', 'Product defects'), ('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Embedding', '')]","[{'comment_id': 2577868477, 'issue_id': 2457527994, 'author': 'WiNloSt', 'body': ""tested in master a0ae2a8f289d4ad1b7baf962e28ebabfa00e0121 and v0.52.5. This doesn't seem to happen anymore.\n![Image](https://github.com/user-attachments/assets/53598266-88c9-4713-bc73-21721d63539b)"", 'created_at': datetime.datetime(2025, 1, 8, 14, 53, 30, tzinfo=datetime.timezone.utc)}]","WiNloSt on (2025-01-08 14:53:30 UTC): tested in master a0ae2a8f289d4ad1b7baf962e28ebabfa00e0121 and v0.52.5. This doesn't seem to happen anymore.
![Image](https://github.com/user-attachments/assets/53598266-88c9-4713-bc73-21721d63539b)

"
2457298042,issue,closed,completed,Wrong text color in breakout column search empty state,"### Describe the bug

[v50.0 for comparison](https://github.com/user-attachments/assets/289ac07f-ccbc-493d-8a39-36a12bd58465)

![image](https://github.com/user-attachments/assets/1318520b-09e5-4496-b0d1-448616dfd6fb)




### To Reproduce

1. New > Question > Orders
2. Try to search for a breakout column
3. Type gibberish in the search so there are no results
4. See empty state

### Expected behavior

Text color is gray

### Information about your Metabase installation

master, ea677b3696

(it works correctly in v50.0)

### Severity

P3

",kamilmielnik,2024-08-09 07:29:54+00:00,['sanex3339'],2025-01-20 10:18:16+00:00,2025-01-20 09:41:16+00:00,https://github.com/metabase/metabase/issues/46667,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Embedding', ''), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2579234016, 'issue_id': 2457298042, 'author': 'kartik-raj7', 'body': 'Hey Could you please assign me this issue', 'created_at': datetime.datetime(2025, 1, 9, 5, 53, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597932148, 'issue_id': 2457298042, 'author': 'sanex3339', 'body': ""UPD: yep, it's not a feature, but the bug\n\n~From what I see, the color of the `no-result` message matches the color of its parent button that opens the picker.~"", 'created_at': datetime.datetime(2025, 1, 17, 10, 34, 10, tzinfo=datetime.timezone.utc)}]","kartik-raj7 on (2025-01-09 05:53:04 UTC): Hey Could you please assign me this issue

sanex3339 (Assginee) on (2025-01-17 10:34:10 UTC): UPD: yep, it's not a feature, but the bug

~From what I see, the color of the `no-result` message matches the color of its parent button that opens the picker.~

"
2456664440,issue,closed,completed,It's possible to add a private question to a shared dashboard from the Recents,"### Describe the bug

I created a question and saved it in My personal collection, then when I was asked if I want to add it to a dashboard I was able to pick a dashboard which sits in Our analytics from the Recents tab of the entity picker.

### To Reproduce

1. Open any dashboard in Our analytics
2. Create a question
3. Save it in your personal collection
4. Start adding it to a dashboard
5. Click on the dropdown to choose a collection
6. Entity picker is showing the dashboard you visited previously in Recents
7. Pick this dashboard
8. Your private question is added to the shared dashboard


### Expected behavior

You should not be able to add private questions to shared dashboards.
Since 0.48 you would not even see shared dashboards as an option https://github.com/metabase/metabase/issues/34733, so in this sense it's a bug of Recents.
I'm also surprised we don't have any backend check.
Although from the product point of view I would show them but suggest to move to the same shared collection when adding to the dashboard.

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.50.6 and later, at least up to
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Permission issue

### Additional context

_No response_",mngr,2024-08-08 21:37:16+00:00,['npfitz'],2025-01-31 18:47:14+00:00,2025-01-31 18:47:14+00:00,https://github.com/metabase/metabase/issues/46661,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2456575835,issue,closed,completed,v0.50.19 can no longer start due to a SQL syntax error in a Liquibase migration,"### Describe the bug

After upgrading to v0.50.19, the app can no longer start:

```
2024-08-08T20:26:12.458161083Z 2024-08-08 20:26:12,457 INFO db.setup :: Running Database Migrations...
2024-08-08T20:26:12.458377439Z 2024-08-08 20:26:12,458 INFO db.setup :: Setting up Liquibase...
2024-08-08T20:26:12.716135150Z 2024-08-08 20:26:12,715 INFO db.setup :: Liquibase is ready.
2024-08-08T20:26:12.716447024Z 2024-08-08 20:26:12,716 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-08-08T20:26:13.252124297Z 2024-08-08 20:26:13,251 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-08-08T20:26:15.279696837Z 2024-08-08 20:26:15,279 WARN util.jvm :: [31mauto-retry metabase.db.liquibase$wait_for_migration_lock$fn__44398@142c8d98: Database has migration lock; cannot run migrations. You can force-release these locks by running `java -jar metabase.jar migrate release-locks`.[0m
2024-08-08T20:26:15.336285083Z 2024-08-08 20:26:15,335 WARN db.liquibase :: Migration lock was acquired after 1 retries.
2024-08-08T20:26:15.642619835Z 2024-08-08 20:26:15,631 INFO db.liquibase :: Running 10 migrations ...
2024-08-08T20:26:15.965540636Z 2024-08-08 20:26:15,958 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.
2024-08-08T20:26:15.965582334Z liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
2024-08-08T20:26:15.965590389Z   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
2024-08-08T20:26:15.965596801Z   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
2024-08-08T20:26:15.965603193Z ) STORED]
2024-08-08T20:26:15.965609154Z 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
2024-08-08T20:26:15.965617891Z 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
2024-08-08T20:26:15.965624693Z 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
2024-08-08T20:26:15.965630855Z 	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
2024-08-08T20:26:15.965637116Z 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
2024-08-08T20:26:15.965642927Z 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
2024-08-08T20:26:15.965648829Z 	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
2024-08-08T20:26:15.965668295Z 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
2024-08-08T20:26:15.965675268Z 	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
2024-08-08T20:26:15.965681249Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-08-08T20:26:15.965686940Z 	at liquibase.Scope.child(Scope.java:195)
2024-08-08T20:26:15.965692400Z 	at liquibase.Scope.child(Scope.java:185)
2024-08-08T20:26:15.965698151Z 	at liquibase.Scope.child(Scope.java:164)
2024-08-08T20:26:15.965704172Z 	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
2024-08-08T20:26:15.965709863Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-08-08T20:26:15.965715423Z 	at liquibase.Scope.child(Scope.java:195)
2024-08-08T20:26:15.965721124Z 	at liquibase.Scope.child(Scope.java:185)
2024-08-08T20:26:15.965726644Z 	at liquibase.Scope.child(Scope.java:164)
2024-08-08T20:26:15.965732245Z 	at liquibase.Scope.child(Scope.java:252)
2024-08-08T20:26:15.965737945Z 	at liquibase.Scope.child(Scope.java:256)
2024-08-08T20:26:15.965743967Z 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
2024-08-08T20:26:15.965750098Z 	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
2024-08-08T20:26:15.965756139Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-08-08T20:26:15.965761710Z 	at liquibase.Scope.child(Scope.java:195)
2024-08-08T20:26:15.965767511Z 	at liquibase.Scope.child(Scope.java:185)
2024-08-08T20:26:15.965775045Z 	at liquibase.Scope.child(Scope.java:164)
2024-08-08T20:26:15.965781046Z 	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
2024-08-08T20:26:15.965786707Z 	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
2024-08-08T20:26:15.965792888Z 	at liquibase.command.CommandScope.execute(CommandScope.java:217)
2024-08-08T20:26:15.965798409Z 	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
2024-08-08T20:26:15.965804069Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-08-08T20:26:15.965809620Z 	at liquibase.Scope.child(Scope.java:195)
2024-08-08T20:26:15.965815140Z 	at liquibase.Scope.child(Scope.java:185)
2024-08-08T20:26:15.965820911Z 	at liquibase.Scope.child(Scope.java:164)
2024-08-08T20:26:15.965826391Z 	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
2024-08-08T20:26:15.965832082Z 	at liquibase.Liquibase.update(Liquibase.java:234)
2024-08-08T20:26:15.965837832Z 	at liquibase.Liquibase.update(Liquibase.java:212)
2024-08-08T20:26:15.965843263Z 	at liquibase.Liquibase.update(Liquibase.java:194)
2024-08-08T20:26:15.965849044Z 	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44437.invoke(liquibase.clj:360)
2024-08-08T20:26:15.965867338Z 	at metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:325)
2024-08-08T20:26:15.965873299Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-08-08T20:26:15.965878749Z 	at liquibase.Scope.child(Scope.java:195)
2024-08-08T20:26:15.965885662Z 	at liquibase.Scope.child(Scope.java:185)
2024-08-08T20:26:15.965891323Z 	at liquibase.Scope.child(Scope.java:164)
2024-08-08T20:26:15.965897394Z 	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
2024-08-08T20:26:15.965903856Z 	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
2024-08-08T20:26:15.965910208Z 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
2024-08-08T20:26:15.965915809Z 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
2024-08-08T20:26:15.965922050Z 	at metabase.db.setup$migrate_BANG_$fn__53373.invoke(setup.clj:84)
2024-08-08T20:26:15.965928032Z 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:140)
2024-08-08T20:26:15.965934063Z 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
2024-08-08T20:26:15.965939984Z 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
2024-08-08T20:26:15.965945835Z 	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
2024-08-08T20:26:15.965951445Z 	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
2024-08-08T20:26:15.965956735Z 	at clojure.lang.RestFn.invoke(RestFn.java:425)
2024-08-08T20:26:15.965961995Z 	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
2024-08-08T20:26:15.965967275Z 	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
2024-08-08T20:26:15.965973156Z 	at metabase.db.setup$setup_db_BANG_$fn__53401$fn__53402.invoke(setup.clj:167)
2024-08-08T20:26:15.965978466Z 	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
2024-08-08T20:26:15.965985078Z 	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
2024-08-08T20:26:15.965990549Z 	at metabase.db.setup$setup_db_BANG_$fn__53401.invoke(setup.clj:161)
2024-08-08T20:26:15.965995979Z 	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
2024-08-08T20:26:15.966001389Z 	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
2024-08-08T20:26:15.966006769Z 	at metabase.db$setup_db_BANG_$fn__53426.invoke(db.clj:86)
2024-08-08T20:26:15.966012289Z 	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
2024-08-08T20:26:15.966017699Z 	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
2024-08-08T20:26:15.966022949Z 	at clojure.lang.RestFn.invoke(RestFn.java:421)
2024-08-08T20:26:15.966028219Z 	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
2024-08-08T20:26:15.966046774Z 	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
2024-08-08T20:26:15.966052104Z 	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
2024-08-08T20:26:15.966057414Z 	at metabase.core$init_BANG_.invoke(core.clj:165)
2024-08-08T20:26:15.966062664Z 	at metabase.core$start_normally.invokeStatic(core.clj:182)
2024-08-08T20:26:15.966067934Z 	at metabase.core$start_normally.invoke(core.clj:176)
2024-08-08T20:26:15.966073133Z 	at metabase.core$entrypoint.invokeStatic(core.clj:215)
2024-08-08T20:26:15.966079054Z 	at metabase.core$entrypoint.doInvoke(core.clj:209)
2024-08-08T20:26:15.966085256Z 	at clojure.lang.RestFn.invoke(RestFn.java:397)
2024-08-08T20:26:15.966091538Z 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
2024-08-08T20:26:15.966097359Z 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
2024-08-08T20:26:15.966103310Z 	at clojure.lang.Var.applyTo(Var.java:705)
2024-08-08T20:26:15.966108930Z 	at clojure.core$apply.invokeStatic(core.clj:667)
2024-08-08T20:26:15.966114851Z 	at clojure.core$apply.invoke(core.clj:662)
2024-08-08T20:26:15.966120903Z 	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
2024-08-08T20:26:15.966126924Z 	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
2024-08-08T20:26:15.966132805Z 	at clojure.lang.RestFn.invoke(RestFn.java:397)
2024-08-08T20:26:15.966138656Z 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
2024-08-08T20:26:15.966144687Z 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
2024-08-08T20:26:15.966150518Z 	at metabase.bootstrap.main(Unknown Source)
2024-08-08T20:26:15.966156079Z Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""(""
2024-08-08T20:26:15.966162360Z   Position: 87
2024-08-08T20:26:15.966168191Z 	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
2024-08-08T20:26:15.966174133Z 	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
2024-08-08T20:26:15.966180004Z 	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
2024-08-08T20:26:15.966186075Z 	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
2024-08-08T20:26:15.966193449Z 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
2024-08-08T20:26:15.966199570Z 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
2024-08-08T20:26:15.966205531Z 	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
2024-08-08T20:26:15.966211663Z 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
2024-08-08T20:26:15.966217714Z 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
2024-08-08T20:26:15.966223565Z 	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
2024-08-08T20:26:15.966236650Z 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
2024-08-08T20:26:15.966243162Z 	... 86 more
2024-08-08T20:26:15.989398062Z
2024-08-08T20:26:15.989434230Z UPDATE SUMMARY
2024-08-08T20:26:15.989454287Z Run:                         10
2024-08-08T20:26:15.989460910Z Previously run:             342
2024-08-08T20:26:15.989467251Z Filtered out:                50
2024-08-08T20:26:15.989473493Z -------------------------------
2024-08-08T20:26:15.989479695Z Total change sets:          402
2024-08-08T20:26:15.989485446Z
2024-08-08T20:26:15.989491187Z
2024-08-08T20:26:15.989497147Z FILTERED CHANGE SETS SUMMARY
2024-08-08T20:26:15.989503059Z DBMS mismatch:               50
2024-08-08T20:26:15.989509130Z
2024-08-08T20:26:16.068351942Z 2024-08-08 20:26:16,066 ERROR metabase.core :: Metabase Initialization FAILED
```

### To Reproduce

Upgrade to latest

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase v0.50.19 (0b97bf8) via Docker
```


### Severity

Critical

### Additional context

_No response_",dkrylovsb,2024-08-08 20:31:24+00:00,[],2024-08-12 11:16:10+00:00,2024-08-09 19:45:24+00:00,https://github.com/metabase/metabase/issues/46658,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2276619701, 'issue_id': 2456575835, 'author': 'dpsutton', 'body': '@dkrylovsb can you tell me what version you were upgrading from and what version of postgres you are using as your application db?', 'created_at': datetime.datetime(2024, 8, 8, 20, 42, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276626296, 'issue_id': 2456575835, 'author': 'dkrylovsb', 'body': 'Hi @dpsutton I am upgrading from `metabase/metabase:v0.50.7`. It is Postgres 11 in Azure.', 'created_at': datetime.datetime(2024, 8, 8, 20, 47, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276639151, 'issue_id': 2456575835, 'author': 'dpsutton', 'body': ""thanks @dkrylovsb \r\n\r\nI've run 0.50.7 and then 0.50.19 right after (only difference upping the liquibase log level) and seeing this on startup \r\n\r\n```\r\n2024-08-08 15:53:12,644 INFO db.liquibase :: Running 17 migrations ...\r\n...\r\n2024-08-08 15:53:12,885 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:06::calherries ran successfully in 2ms\r\n2024-08-08 15:53:12,894 INFO liquibase.changelog :: Custom SQL executed\r\n2024-08-08 15:53:12,896 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries ran successfully in 10ms\r\n2024-08-08 15:53:12,901 INFO liquibase.changelog :: Unique constraint added to metabase_field(name, table_id, unique_field_helper)\r\n2024-08-08 15:53:12,901 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:08::calherries ran successfully in 3ms\r\n2024-08-08 15:53:12,906 INFO liquibase.changelog :: Custom SQL executed\r\n...\r\n```\r\n\r\nThe substance of `v49.2024-06-27T00:00:07` is\r\n\r\n```sql\r\nALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (\r\n  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END\r\n) STORED;\r\n```\r\n\r\nThis works for me locally with postgres 14. Let me investigate.\r\n\r\n(I'm also curious why you have 10 migrations and I have 17)"", 'created_at': datetime.datetime(2024, 8, 8, 20, 57, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276661739, 'issue_id': 2456575835, 'author': 'dpsutton', 'body': 'Ok. I can recreate:\r\n\r\n```\r\n❯ docker run -it -e POSTGRES_PASSWORD=password -d -p 5433:5432 postgres:11\r\n❯ psql -p ""5433"" -h ""0.0.0.0"" -U postgres\r\npostgres=# create database no_upgrade;\r\nCREATE DATABASE\r\npostgres=#\r\n```\r\n\r\nThen \r\n\r\nnote my logging info in the jar has been changed to\r\n```\r\n<Logger name=""liquibase"" level=""INFO""/>\r\n```\r\n\r\n```\r\nMB_DB_CONNECTION_URI=""postgres://postgres:password@0.0.0.0:5433/no_upgrade"" MB_JETTY_PORT=3050 java -jar 0.50.19.jar\r\n\r\n...\r\n2024-08-08 16:10:30,587 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.\r\nliquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""\r\n  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (\r\n  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END\r\n) STORED]\r\n...\r\n2024-08-08 16:10:30,639 ERROR metabase.core :: Metabase Initialization FAILED\r\nliquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:\r\n     Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""\r\n  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (\r\n  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END\r\n) STORED]\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:253)\r\n\tat liquibase.Liquibase.lambda$update$0(Liquibase.java:245)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n...\r\n2024-08-08 16:10:30,641 INFO metabase.core :: Metabase Shutting Down ...\r\n2024-08-08 16:10:30,641 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\n2024-08-08 16:10:30,646 WARN db.liquibase :: ()\r\n2024-08-08 16:10:30,646 INFO metabase.core :: Metabase Shutdown COMPLETE\r\n```', 'created_at': datetime.datetime(2024, 8, 8, 21, 14, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276663752, 'issue_id': 2456575835, 'author': 'notrom', 'body': 'Same as #45367 maybe? Postresql version requirement has been quietly bumped.', 'created_at': datetime.datetime(2024, 8, 8, 21, 15, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278429324, 'issue_id': 2456575835, 'author': 'dkrylovsb', 'body': 'Since we are using Postgres 11, are we out of luck with getting a fix for this one? 🙏', 'created_at': datetime.datetime(2024, 8, 9, 17, 40, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278632968, 'issue_id': 2456575835, 'author': 'dpsutton', 'body': 'Unfortunately so. Postgres 11 is [no longer supported](https://www.postgresql.org/support/versioning/) and we remove it from our test matrix.', 'created_at': datetime.datetime(2024, 8, 9, 19, 45, 24, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-08-08 20:42:59 UTC): @dkrylovsb can you tell me what version you were upgrading from and what version of postgres you are using as your application db?

dkrylovsb (Issue Creator) on (2024-08-08 20:47:46 UTC): Hi @dpsutton I am upgrading from `metabase/metabase:v0.50.7`. It is Postgres 11 in Azure.

dpsutton on (2024-08-08 20:57:19 UTC): thanks @dkrylovsb 

I've run 0.50.7 and then 0.50.19 right after (only difference upping the liquibase log level) and seeing this on startup 

```
2024-08-08 15:53:12,644 INFO db.liquibase :: Running 17 migrations ...
...
2024-08-08 15:53:12,885 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:06::calherries ran successfully in 2ms
2024-08-08 15:53:12,894 INFO liquibase.changelog :: Custom SQL executed
2024-08-08 15:53:12,896 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries ran successfully in 10ms
2024-08-08 15:53:12,901 INFO liquibase.changelog :: Unique constraint added to metabase_field(name, table_id, unique_field_helper)
2024-08-08 15:53:12,901 INFO liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:08::calherries ran successfully in 3ms
2024-08-08 15:53:12,906 INFO liquibase.changelog :: Custom SQL executed
...
```

The substance of `v49.2024-06-27T00:00:07` is

```sql
ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED;
```

This works for me locally with postgres 14. Let me investigate.

(I'm also curious why you have 10 migrations and I have 17)

dpsutton on (2024-08-08 21:14:02 UTC): Ok. I can recreate:

```
❯ docker run -it -e POSTGRES_PASSWORD=password -d -p 5433:5432 postgres:11
❯ psql -p ""5433"" -h ""0.0.0.0"" -U postgres
postgres=# create database no_upgrade;
CREATE DATABASE
postgres=#
```

Then 

note my logging info in the jar has been changed to
```
<Logger name=""liquibase"" level=""INFO""/>
```

```
MB_DB_CONNECTION_URI=""postgres://postgres:password@0.0.0.0:5433/no_upgrade"" MB_JETTY_PORT=3050 java -jar 0.50.19.jar

...
2024-08-08 16:10:30,587 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.
liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
...
2024-08-08 16:10:30,639 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
     Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
...
2024-08-08 16:10:30,641 INFO metabase.core :: Metabase Shutting Down ...
2024-08-08 16:10:30,641 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-08-08 16:10:30,646 WARN db.liquibase :: ()
2024-08-08 16:10:30,646 INFO metabase.core :: Metabase Shutdown COMPLETE
```

notrom on (2024-08-08 21:15:35 UTC): Same as #45367 maybe? Postresql version requirement has been quietly bumped.

dkrylovsb (Issue Creator) on (2024-08-09 17:40:08 UTC): Since we are using Postgres 11, are we out of luck with getting a fix for this one? 🙏

dpsutton on (2024-08-09 19:45:24 UTC): Unfortunately so. Postgres 11 is [no longer supported](https://www.postgresql.org/support/versioning/) and we remove it from our test matrix.

"
2456537511,issue,closed,completed,[FE] Update PulseChannelEdit component to functional / typed component,,npfitz,2024-08-08 20:06:26+00:00,['npfitz'],2024-08-15 11:48:28+00:00,2024-08-14 19:41:08+00:00,https://github.com/metabase/metabase/issues/46657,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2456491598,issue,open,,Unnecessary 'cast as date' on timestamp columns when 'Unbinned' option is selected,"### Describe the bug

To describe my issue I will use `Accounts` table in `Sample Database`. Raw data:
![image](https://github.com/user-attachments/assets/9c47b637-c9e2-4a22-9df0-f57a3d3ff817)

I'd like to group data by timestamp column `Created at` with unbinned option selected without losing precision. Query looks as simple as that:
![image](https://github.com/user-attachments/assets/d6fc528e-4f89-4e98-8002-d78552864bba)

Generated SQL query:
``` sql
SELECT
  CAST(""PUBLIC"".""ACCOUNTS"".""CREATED_AT"" AS date) AS ""CREATED_AT"",
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""ACCOUNTS""
GROUP BY
  CAST(""PUBLIC"".""ACCOUNTS"".""CREATED_AT"" AS date)
ORDER BY
  CAST(""PUBLIC"".""ACCOUNTS"".""CREATED_AT"" AS date) ASC
```

Getting this result:
![image](https://github.com/user-attachments/assets/3bc76d51-ad44-4110-b6e8-76785457530d)

Why is it truncating `Created at` to day?


### To Reproduce

1. Use the query from description on `Sample Database`


### Expected behavior

I'd like to see the original values from database without casting to date and losing precision.

Expected SQL query is:
``` sql
SELECT
  ""PUBLIC"".""ACCOUNTS"".""CREATED_AT"",
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""ACCOUNTS""
GROUP BY
  ""PUBLIC"".""ACCOUNTS"".""CREATED_AT""
ORDER BY
  ""PUBLIC"".""ACCOUNTS"".""CREATED_AT"" ASC
```

### Logs

_No response_

### Information about your Metabase installation

```JSON
Client:
- Google Crome 127.0.6533.89
- Windows 11 Pro 22631.3880

Server:
- Latest metabase docker image
```


### Severity

I believe current behavior is unexpected and confusing. I have to explain this to users every time

### Additional context

_No response_",shnipov,2024-08-08 19:34:56+00:00,[],2025-02-04 20:27:51+00:00,,https://github.com/metabase/metabase/issues/46656,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2283675624, 'issue_id': 2456491598, 'author': 'crisptrutski', 'body': ""Tried to reproduce, and I believe the behavior may have been changed already. I recorded a [quick video demonstrating the behavior in our development branch](https://www.loom.com/share/0b9954443c8a4ad6bc6d8b9c389c6840?sid=6c574718-8a8e-440f-8fbf-74d208942759). \r\n\r\nI'll pass this on to the query builder team for further discussion."", 'created_at': datetime.datetime(2024, 8, 12, 11, 6, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284748512, 'issue_id': 2456491598, 'author': 'shnipov', 'body': '@crisptrutski on video ""minute"" is selected, not ""unbinned""\r\nCould you please check ""unbinned"" option?', 'created_at': datetime.datetime(2024, 8, 12, 19, 23, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285030405, 'issue_id': 2456491598, 'author': 'nemanjaglumac', 'body': '@shnipov I was able to reproduce with unbinned.\r\nRe-assigned to the backend team.', 'created_at': datetime.datetime(2024, 8, 12, 22, 50, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2579844675, 'issue_id': 2456491598, 'author': 'joeledwardson', 'body': ""can we get this fixed please?\n![Image](https://github.com/user-attachments/assets/97161626-1db9-4618-b4bb-27d1eca28cb3)\n\nUsing the latest version at the moment\n```\nYou're on version v1.52.4.7\n\nBuilt on 2025-01-07\n\nHash: cc77eeb\n```"", 'created_at': datetime.datetime(2025, 1, 9, 11, 0, 30, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-12 11:06:34 UTC): Tried to reproduce, and I believe the behavior may have been changed already. I recorded a [quick video demonstrating the behavior in our development branch](https://www.loom.com/share/0b9954443c8a4ad6bc6d8b9c389c6840?sid=6c574718-8a8e-440f-8fbf-74d208942759). 

I'll pass this on to the query builder team for further discussion.

shnipov (Issue Creator) on (2024-08-12 19:23:17 UTC): @crisptrutski on video ""minute"" is selected, not ""unbinned""
Could you please check ""unbinned"" option?

nemanjaglumac on (2024-08-12 22:50:31 UTC): @shnipov I was able to reproduce with unbinned.
Re-assigned to the backend team.

joeledwardson on (2025-01-09 11:00:30 UTC): can we get this fixed please?
![Image](https://github.com/user-attachments/assets/97161626-1db9-4618-b4bb-27d1eca28cb3)

Using the latest version at the moment
```
You're on version v1.52.4.7

Built on 2025-01-07

Hash: cc77eeb
```

"
2456437859,issue,closed,completed,Bad error messages on api-key setup form,"### Describe the bug

<img width=""490"" alt=""image"" src=""https://github.com/user-attachments/assets/0928cab1-82b1-4d17-8d8f-d8746d4d4263"">

type a name, tab to pick group, shift-tab back to name and see the error message about numbers rather than choices

Additionally, if you give the key a name that is already used, the BE will reply with a 400 error, but the FE will display the success modal (""Copy and save the API key""), leaving the key blank.

![Image](https://github.com/user-attachments/assets/93bc2414-dad1-419b-818b-bbcdf18b0a72)


### To Reproduce

* Type a name, tab to pick group, shift-tab back to name and see the error message about numbers rather than choices
* Next, create an API key with a previously used name

### Expected behavior

* It should have messaging like ""make a choice"", not complain about numbers and NaN
* It should display an error message when an key collision occurs

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p3

### Additional context

_No response_",dpsutton,2024-08-08 18:58:09+00:00,[],2025-01-22 14:07:20+00:00,2025-01-22 14:07:20+00:00,https://github.com/metabase/metabase/issues/46654,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2607343814, 'issue_id': 2456437859, 'author': 'luizarakaki', 'body': 'Unable to reproduce', 'created_at': datetime.datetime(2025, 1, 22, 14, 7, 17, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-22 14:07:17 UTC): Unable to reproduce

"
2456430774,issue,closed,not_planned,Conditional Formatting for Dots on Line Chart,"**Is your feature request related to a problem? Please describe.**
We'd like to be able to plot multiple lines on a line chart and, for each line, change the color of the plots points based on a KPI. So, for example, one line might have conditional formatting for the plot points that indicate under 10% is green and over 10% is red. This give s a visual for when KPIs were hit or missed over time across multiple series.

**Describe the solution you'd like**
We'd like to apply conditional formatting to change the color of the dots/plot points of a line chart.

**Describe alternatives you've considered**
There is a workaround to do this in PowerBI but we would like similar functionality in Metabase.

",ixipixi,2024-08-08 18:53:15+00:00,[],2024-11-05 15:46:21+00:00,2024-11-05 15:46:20+00:00,https://github.com/metabase/metabase/issues/46653,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]","[{'comment_id': 2457522929, 'issue_id': 2456430774, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/11461', 'created_at': datetime.datetime(2024, 11, 5, 15, 46, 20, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-11-05 15:46:20 UTC): duplicate of https://github.com/metabase/metabase/issues/11461

"
2456130725,issue,closed,completed,Add missing color mapping to the SDK,"### Describe the bug

After merging 2 milestones of [[Epic] Re-design transparent theme for static embedding and public links](https://github.com/metabase/metabase/issues/43838#top), some SDK color mappings are missing.

![image](https://github.com/user-attachments/assets/7f81063c-ec57-45c3-910f-e192593ef94d)

### To Reproduce

1. Run the SDK in dev mode with:
    ```
    yarn build-release:cljs && yarn build-embedding-sdk:watch
    ```
1. After the bundle is built, run shoppy app with:
    ```
    yarn dev:link && yarn dev
    ```
1. Vistit http://localhost:3004/admin/products/1
1. Click on a bar in the chart
1. Click the date filter
1. See the date filter popover

### Expected behavior

Date filter popover background should be what's define in the SDK's `colors.background`

### Logs

_No response_

### Information about your Metabase installation

```JSON
master @ 5e549cf5acd4dbd5e316b8577bfb68cf64d5ec7f
```


### Severity

blocking

### Additional context

_No response_",WiNloSt,2024-08-08 15:47:51+00:00,['WiNloSt'],2024-10-08 16:18:10+00:00,2024-08-09 14:11:38+00:00,https://github.com/metabase/metabase/issues/46648,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2456052676,issue,closed,not_planned,Metabase unable to create own application tables in a schema other than `public` on startup. Migrations fail.,"### Describe the bug

Hello. We've been using metabase version `0.46.8` on PostgeSQL for some time. The important point here is that we want metabase to create its application tables on startup in a schema called `metabase` (i.e. **not** in the `public` schema).

We were able to achieve that by setting the following env var:

```
MB_DB_CONNECTION_URI=jdbc:postgresql://${DATABASE_USER}:${DATABASE_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE}?options=-csearch_path%3Dmetabase
```

Then, all of metbases' application tables would be created in the metabase schema. Great!

However, recently we moved to `0.50.9` and this stopped working.

When starting with an empty metabase schema, what  happen is that metabase creates some tables, like:

  * action
  * databasechangelog
  * databasechangeloglock
 
in the correct `metabase` schema, but also creates some other tables in the `public` schema. Eventually, the intialization process fails with errors like this one:

```
Caused by: liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE)]
        at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
        at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
        at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
        at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
        at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
        at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
        ... 81 more
Caused by: org.postgresql.util.PSQLException: ERROR: relation ""metabase.report_card"" does not exist
        at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
        at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
        at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
        at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
        at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
        at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
        at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
        ... 86 more
```

where a migration tries to create a table `metabase.query_action` in the right schema, but that table references a table (`metabase.report_card`) that doesn't exist. Well, it actually does exist, but in the wrong schema (i.e. `public`) so the migration fails.

This seems to be an issue caused by the migration code ignoring the target schema for some migrations.
We also tried the latest version at the time of writing (0.50.19) and the problem was still there







### To Reproduce

1. Create a schema `metabase` in your postgres database, and grant all permissions on it to your database user 
2. export MB_DB_CONNECTION_URI=jdbc:postgresql://${DATABASE_USER}:${DATABASE_PASSWORD}@${DATABASE_HOST}:${DATABASE_PORT}/${DATABASE}?options=-csearch_path%3Dmetabase
3. java -jar metabase.jar 

### Expected behavior

The migrations should run successfully, and all of metbases' own tables should be created in the `metabase` schema

### Logs

2024-08-08 17:04:15,004 INFO metabase.util :: Maximum memory available to JVM: 8,0 GB
2024-08-08 17:04:16,008 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. 🔓 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-08-08 17:04:18,374 INFO driver.impl :: [34mRegistered abstract driver :sql[0m  🚚
2024-08-08 17:04:18,389 INFO driver.impl :: [34mRegistered abstract driver :sql-jdbc[0m (parents: [:sql]) 🚚
2024-08-08 17:04:18,392 INFO metabase.util :: [32mLoad driver :sql-jdbc took 4,9 ms[0m
2024-08-08 17:04:18,392 INFO driver.impl :: [34mRegistered driver :h2[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:18,462 INFO driver.impl :: [34mRegistered driver :mysql[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:18,475 INFO driver.impl :: [34mRegistered driver :postgres[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,205 INFO metabase.core :: 
Metabase v0.50.19 (0b97bf8) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-08-08 17:04:19,209 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-08-08 17:04:19,228 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000}

2024-08-08 17:04:19,251 INFO metabase.core :: Starting Metabase version v0.50.19 (0b97bf8) ...
2024-08-08 17:04:19,253 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""22.0.2"",
 ""java.vendor"" ""Homebrew"",
 ""java.vendor.url"" ""https://github.com/Homebrew/homebrew-core/issues"",
 ""java.version"" ""22.0.2"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""22.0.2"",
 ""os.name"" ""Mac OS X"",
 ""os.version"" ""14.6"",
 ""user.language"" ""en"",
 ""user.timezone"" ""Europe/Berlin""}

2024-08-08 17:04:19,255 INFO metabase.plugins :: Loading plugins in /Users/mmarcon/tb-ii/plugins...
2024-08-08 17:04:19,444 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :bigquery-cloud-sdk...[0m
2024-08-08 17:04:19,444 INFO driver.impl :: [34mRegistered driver :bigquery-cloud-sdk[0m (parents: [:sql]) 🚚
2024-08-08 17:04:19,466 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :snowflake...[0m
2024-08-08 17:04:19,466 INFO driver.impl :: [34mRegistered driver :snowflake[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,470 INFO plugins.dependencies :: [31mMetabase cannot initialize plugin Metabase Oracle Driver due to required dependencies.[0m Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-08-08 17:04:19,471 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-08-08 17:04:19,471 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Oracle Driver""][0m
2024-08-08 17:04:19,475 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :mongo...[0m
2024-08-08 17:04:19,475 INFO driver.impl :: [34mRegistered driver :mongo[0m  🚚
2024-08-08 17:04:19,477 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid...[0m
2024-08-08 17:04:19,477 INFO driver.impl :: [34mRegistered driver :druid[0m  🚚
2024-08-08 17:04:19,481 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :redshift...[0m
2024-08-08 17:04:19,481 INFO driver.impl :: [34mRegistered driver :redshift[0m (parents: [:postgres]) 🚚
2024-08-08 17:04:19,483 INFO plugins.dependencies :: [31mMetabase cannot initialize plugin Metabase Vertica Driver due to required dependencies.[0m Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-08-08 17:04:19,483 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-08-08 17:04:19,483 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""][0m
2024-08-08 17:04:19,484 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlite...[0m
2024-08-08 17:04:19,485 INFO driver.impl :: [34mRegistered driver :sqlite[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,489 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto-jdbc...[0m
2024-08-08 17:04:19,489 INFO driver.impl :: [34mRegistered driver :presto-jdbc[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,492 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid-jdbc...[0m
2024-08-08 17:04:19,492 INFO driver.impl :: [34mRegistered driver :druid-jdbc[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,493 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlserver...[0m
2024-08-08 17:04:19,494 INFO driver.impl :: [34mRegistered driver :sqlserver[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,506 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :athena...[0m
2024-08-08 17:04:19,506 INFO driver.impl :: [34mRegistered driver :athena[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,509 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :hive-like...[0m
2024-08-08 17:04:19,510 INFO driver.impl :: [34mRegistered abstract driver :hive-like[0m (parents: [:sql-jdbc]) 🚚
2024-08-08 17:04:19,510 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sparksql...[0m
2024-08-08 17:04:19,510 INFO driver.impl :: [34mRegistered driver :sparksql[0m (parents: [:hive-like]) 🚚
2024-08-08 17:04:19,512 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-08-08 17:04:19,512 INFO db.setup :: [36mVerifying postgres Database Connection ...[0m
2024-08-08 17:04:19,699 INFO db.setup :: Successfully verified PostgreSQL 16.2 application database connection. ✅
2024-08-08 17:04:19,699 INFO db.setup :: [36mChecking if a database downgrade is required...[0m
2024-08-08 17:04:20,031 INFO db.setup :: Running Database Migrations...
2024-08-08 17:04:20,032 INFO db.setup :: Setting up Liquibase...
2024-08-08 17:04:20,142 INFO db.liquibase :: Updating liquibase table to reflect consolidated changeset filenames
2024-08-08 17:04:20,152 INFO db.liquibase :: No migration lock found.
2024-08-08 17:04:20,152 INFO db.liquibase :: Migration lock acquired.
2024-08-08 17:04:20,163 INFO db.setup :: Liquibase is ready.
2024-08-08 17:04:20,163 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-08-08 17:04:20,393 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-08-08 17:04:20,407 INFO db.liquibase :: No migration lock found.
2024-08-08 17:04:20,407 INFO db.liquibase :: Migration lock acquired.
2024-08-08 17:04:20,528 INFO db.liquibase :: Running 352 migrations ...
2024-08-08 17:04:21,439 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v45.00-002::snoe encountered an exception.
liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE)]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44437.invoke(liquibase.clj:360)
	at metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:325)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
	at metabase.db.setup$migrate_BANG_$fn__53373.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:140)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53401$fn__53402.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53401.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53426.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: relation ""metabase.report_card"" does not exist
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more

UPDATE SUMMARY
Run:                        352
Previously run:               0
Filtered out:                50
-------------------------------
Total change sets:          402


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               50

2024-08-08 17:04:21,477 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v45.00-002::snoe:
     Reason: liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE)]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44437.invoke(liquibase.clj:360)
	at metabase.db.liquibase$run_in_scope_locked$reify__44433.run(liquibase.clj:325)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
	at metabase.db.setup$migrate_BANG_$fn__53373.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44374.invoke(liquibase.clj:140)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53401$fn__53402.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53401.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53426.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v45.00-002::snoe:
     Reason: liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE)]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 58 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v45.00-002::snoe:
     Reason: liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE)]
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: ERROR: relation ""metabase.report_card"" does not exist [Failed SQL: (0) CREATE TABLE ""metabase"".""query_action"" (""action_id"" INTEGER NOT NULL, ""card_id"" INTEGER NOT NULL, CONSTRAINT ""fk_query_action_ref_card_id"" FOREIGN KEY (""card_id"") REFERENCES ""metabase"".""report_card""(""id"") ON DELETE CASCADE, CONSTRAINT ""fk_query_action_ref_action_id"" FOREIGN KEY (""action_id"") REFERENCES ""metabase"".""action""(""id"") ON DELETE CASCADE)]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 81 more
Caused by: org.postgresql.util.PSQLException: ERROR: relation ""metabase.report_card"" does not exist
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
2024-08-08 17:04:21,479 INFO metabase.core :: Metabase Shutting Down ...
2024-08-08 17:04:21,479 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-08-08 17:04:21,483 WARN db.liquibase :: ()
2024-08-08 17:04:21,483 INFO metabase.core :: Metabase Shutdown COMPLETE


### Information about your Metabase installation

```JSON
- Metabase versions: 0.50.9 and 0.50.19
- Hosting environment: Docker and MacOS
- Database: PostgreSQL
```


### Severity

Severe, it's preventing metabase from initializing a new database

### Additional context

_No response_",maxmarcon,2024-08-08 15:09:32+00:00,[],2024-08-08 16:09:19+00:00,2024-08-08 16:09:18+00:00,https://github.com/metabase/metabase/issues/46646,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2276188892, 'issue_id': 2456052676, 'author': 'paoliniluis', 'body': 'dupe of https://github.com/metabase/metabase/issues/37836', 'created_at': datetime.datetime(2024, 8, 8, 16, 9, 19, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-08 16:09:19 UTC): dupe of https://github.com/metabase/metabase/issues/37836

"
2455986389,issue,closed,completed,[BE] Support multiple breakouts of the same column when there is no `fields` clause,"Currently when a question used for data source contains multiple breakouts for the same column, only one breakout is returned in query results unless there is an explicit `fields` clause:
```
// does not work, not all breakouts are returned
{
  ""source-table"": ""card__1""
}

// works
{
  ""source-table"": ""card__1"",
  ""fields"": [
    [""field"", ""CREATED_AT"", {""base-type"": ""type/DateTime""}],
    [""field"", ""CREATED_AT_2"", {""base-type"": ""type/DateTime""}]
  ]
}

// does not work
{
  ""source-query"": {
    ""source-table"": ""card__1"",
    ""fields"": [
      [""field"", ""CREATED_AT"", {""base-type"": ""type/DateTime""}],
      [""field"", ""CREATED_AT_2"", {""base-type"": ""type/DateTime""}]
    ]
  }
}
```

I think what happens here is that the QP is forced to work with ""broken card references"", i.e. field id-based references. We just recently switched this legacy behavior off in MBQL lib. We can't do the same in the QP yet - but maybe we can fix expanding of an empty `fields` clause for queries that contain multiple breakouts of the same column?",ranquild,2024-08-08 14:40:30+00:00,['metamben'],2024-10-08 16:16:09+00:00,2024-08-28 22:41:09+00:00,https://github.com/metabase/metabase/issues/46644,[],[],
2455947305,issue,open,,Add permissions information to Metabase Analytics,"**Is your feature request related to a problem? Please describe.**
Currently, it is not possible to generate reports in Metabase Analytics that detail which Metabase resources or database tables a group or specific user has access to. 

**Describe the solution you'd like**
Expose in application permissions in Metabase Analytics, with collection permissions being joinable with the Content model and data access permissions joinable to Tables.

Ideally we should also expose data lineage, either in the Content view or in a separate view, by showing which tables questions or models refer to.

**Describe alternatives you've considered**
Self-hosting customers could query the application database directly but this would requires a detailed understanding of how permissions are represented.

**How important is this feature to you?**
This is a common audit requirement.

**Additional context**
An actual user request:
> Yes, that would be a great feature to have in Metabase. The report should include but not limited to:
> 
> Role Group Name
> users in each role group name
> timestamp of when each user was added to the role group name
> what collection each group name can access",zbodi74,2024-08-08 14:24:21+00:00,[],2025-02-04 20:30:17+00:00,,https://github.com/metabase/metabase/issues/46642,"[('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2307726700, 'issue_id': 2455947305, 'author': 'ixipixi', 'body': ""In another recent request for this, the customer also needs timestamp of when users were added/removed to groups. It doesn't look like we currently track group membership history so, even with app DB access, they couldn't produce this component of their audit requirements."", 'created_at': datetime.datetime(2024, 8, 23, 19, 56, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339045771, 'issue_id': 2455947305, 'author': 'paoliniluis', 'body': 'pretty easy to do actually, should be an easy addition to the metabase analytics collection and just 1-2 hours of work', 'created_at': datetime.datetime(2024, 9, 9, 20, 39, 35, tzinfo=datetime.timezone.utc)}]","ixipixi on (2024-08-23 19:56:19 UTC): In another recent request for this, the customer also needs timestamp of when users were added/removed to groups. It doesn't look like we currently track group membership history so, even with app DB access, they couldn't produce this component of their audit requirements.

paoliniluis on (2024-09-09 20:39:35 UTC): pretty easy to do actually, should be an easy addition to the metabase analytics collection and just 1-2 hours of work

"
2455907305,issue,closed,completed,Create Shared Sidesheet components,"Create components, storybook stories and unit tests for:

- [ ] `Sidesheet`
- [ ] `SidesheetHeader`
- [ ] `SidesheetBody`
- [ ] `SidesheetTabs`
- [ ] `SidesheetCard`
- [ ] `SidesheetCardSection`

Also need to handle ""sublevels"" or ""pages"" within a sidesheet.

All of these will be separately exported and used as the building blocks for particular Sidesheets


![Screen Shot 2024-08-08 at 8 09 18 AM](https://github.com/user-attachments/assets/f9af199c-bfba-44b3-b346-e370f6e67aa1)

",iethree,2024-08-08 14:06:33+00:00,"['rafpaf', 'iethree']",2024-10-08 16:15:14+00:00,2024-09-06 20:53:21+00:00,https://github.com/metabase/metabase/issues/46639,[],[],
2455894583,issue,open,,Dashboard as collection home.,"**Is your feature request related to a problem? Please describe.**
Hey! It would be awesome to add dashboards to the collection home. It would be the same feature available now to make a dashboard the Metabase home, but for specific collections.

**Describe the solution you'd like**
Add a dashboard as the collection home.

**How important is this feature to you?**
We can live without it, but it would help us organize our official data collection for users.

",subzet,2024-08-08 14:01:10+00:00,[],2025-02-04 20:30:22+00:00,,https://github.com/metabase/metabase/issues/46638,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Organization/Collections', '')]","[{'comment_id': 2568129496, 'issue_id': 2455894583, 'author': 'brunobergher', 'body': ""@subzet Do you mean to configure a dashboard to be shown by default when a user goes to a collection, instead of the list of items? Mind sharing what you're trying to accomplish there? And how would you imagine users would go to the collection itself?\n\nIt's worth sharing that something we're shipping in the next release is the ability (also the default) to save questions _in_ dashboards, instead of in collections and then be referenced in the dashboards. That should turn many collections which today have 1 dashboard and many questions into just 1 dashboard, which might address your need."", 'created_at': datetime.datetime(2025, 1, 2, 17, 35, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577621792, 'issue_id': 2455894583, 'author': 'subzet', 'body': ""Hey @brunobergher ! That's a great feature. What I mean is to be able to set a specific dashboard as the default view when you enter a collection. It is now posible to add a dashboard as the default metabase home, I'd like the same but when entering a collection, instead of seeing the list of questions stored in the collection."", 'created_at': datetime.datetime(2025, 1, 8, 13, 2, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577648354, 'issue_id': 2455894583, 'author': 'brunobergher', 'body': 'Yup, I think I understand it. But how do you see users then getting to the collection itself? And what are you ultimately trying to accomplish? Something like creating a curated index for that collection, through which people would navigate?', 'created_at': datetime.datetime(2025, 1, 8, 13, 15, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577652906, 'issue_id': 2455894583, 'author': 'subzet', 'body': 'Exactly! We use the home like a quick overview about the collection domain and we provide links to other related collections or questions as well. Maybe for collections you can provide two views, a dashboard with quick overviews and the questions contained in that collection, and the user can switch between both?', 'created_at': datetime.datetime(2025, 1, 8, 13, 18, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577677822, 'issue_id': 2455894583, 'author': 'brunobergher', 'body': ""Got it! Not sure we'll do this exactly, but passing on the feedback to the team."", 'created_at': datetime.datetime(2025, 1, 8, 13, 30, 17, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-02 17:35:03 UTC): @subzet Do you mean to configure a dashboard to be shown by default when a user goes to a collection, instead of the list of items? Mind sharing what you're trying to accomplish there? And how would you imagine users would go to the collection itself?

It's worth sharing that something we're shipping in the next release is the ability (also the default) to save questions _in_ dashboards, instead of in collections and then be referenced in the dashboards. That should turn many collections which today have 1 dashboard and many questions into just 1 dashboard, which might address your need.

subzet (Issue Creator) on (2025-01-08 13:02:44 UTC): Hey @brunobergher ! That's a great feature. What I mean is to be able to set a specific dashboard as the default view when you enter a collection. It is now posible to add a dashboard as the default metabase home, I'd like the same but when entering a collection, instead of seeing the list of questions stored in the collection.

brunobergher on (2025-01-08 13:15:56 UTC): Yup, I think I understand it. But how do you see users then getting to the collection itself? And what are you ultimately trying to accomplish? Something like creating a curated index for that collection, through which people would navigate?

subzet (Issue Creator) on (2025-01-08 13:18:10 UTC): Exactly! We use the home like a quick overview about the collection domain and we provide links to other related collections or questions as well. Maybe for collections you can provide two views, a dashboard with quick overviews and the questions contained in that collection, and the user can switch between both?

brunobergher on (2025-01-08 13:30:17 UTC): Got it! Not sure we'll do this exactly, but passing on the feedback to the team.

"
2455847304,issue,closed,not_planned,"Metabase Initialization FAILED PSQLException: ERROR: relation ""databasechangelog"" does not exist","### Describe the bug

Hi Team,

We have deployed metabase in Openshift environment and it is connecting to postgres db public schema. Now we are trying to connect to a different schema but the metabase deployment is failing with below error. Can someone please help.

2024-08-06 15:06:43,868 INFO db.setup :: �[36mVerifying postgres Database Connection ...�[0m
2024-08-06 15:06:44,745 INFO db.setup :: Successfully verified PostgreSQL 13.11 application database connection. ✅
2024-08-06 15:06:44,745 INFO db.setup :: �[36mChecking if a database downgrade is required...�[0m
2024-08-06 15:06:44,819 ERROR metabase.core :: ****Metabase Initialization FAILED
org.postgresql.util.PSQLException: ERROR: relation ""databasechangelog"" does not exist**

### To Reproduce

appVersion: v0.49.7

Connect metabase to postgres DB -> it connects to public schema successfully
Now try to connect to a different schema, it throws error.ERROR: relation ""databasechangelog"" does not exist**

### Expected behavior

It should connect to the new schema successfully without any issues.

### Logs

2024-08-06 15:06:43,868 INFO db.setup :: �[36mVerifying postgres Database Connection ...�[0m
2024-08-06 15:06:44,745 INFO db.setup :: **Successfully verified PostgreSQL 13.11 application database connection. ✅**
2024-08-06 15:06:44,745 INFO db.setup :: �[36mChecking if a database downgrade is required...�[0m
2024-08-06 15:06:44,819 ERROR metabase.core :: **Metabase Initialization FAILED
org.postgresql.util.PSQLException: ERROR: relation ""databasechangelog"" does not exist**

### Information about your Metabase installation

```JSON
We are using below helm charts for openshift deployment
https://github.com/pmint93/helm-charts/ 

Chart version: 2.14.3
appVersion: v0.49.7
```


### Severity

High - blocking Cloud migration. 

### Additional context

We are using below helm charts for openshift deployment
https://github.com/pmint93/helm-charts/ ",skfathima87,2024-08-08 13:41:05+00:00,[],2024-08-08 16:42:35+00:00,2024-08-08 16:28:18+00:00,https://github.com/metabase/metabase/issues/46635,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2276191507, 'issue_id': 2455847304, 'author': 'paoliniluis', 'body': 'you might be hitting https://github.com/metabase/metabase/issues/37836, please confirm', 'created_at': datetime.datetime(2024, 8, 8, 16, 10, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276205453, 'issue_id': 2455847304, 'author': 'skfathima87', 'body': 'Yes correct. So do we need to downgrade to v0.46.8 with currentSchema and then upgrade to 49 version. \r\nOr the metabase does not support connecting to any other schema other than Public. Please clarify.', 'created_at': datetime.datetime(2024, 8, 8, 16, 18, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276221212, 'issue_id': 2455847304, 'author': 'paoliniluis', 'body': 'Metabase does not support other schema than public', 'created_at': datetime.datetime(2024, 8, 8, 16, 28, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276232184, 'issue_id': 2455847304, 'author': 'skfathima87', 'body': 'Thanks for clarifying, is there any plan to support this feature in future releases.', 'created_at': datetime.datetime(2024, 8, 8, 16, 34, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276240151, 'issue_id': 2455847304, 'author': 'paoliniluis', 'body': 'Check the issue I posted, this is not under discussion right now in the team but we might address it at some point if this is requested often', 'created_at': datetime.datetime(2024, 8, 8, 16, 39, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276245174, 'issue_id': 2455847304, 'author': 'skfathima87', 'body': 'Thank you so much for the quick response, really appreciate your support. You can close the ticket.', 'created_at': datetime.datetime(2024, 8, 8, 16, 42, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-08 16:10:41 UTC): you might be hitting https://github.com/metabase/metabase/issues/37836, please confirm

skfathima87 (Issue Creator) on (2024-08-08 16:18:48 UTC): Yes correct. So do we need to downgrade to v0.46.8 with currentSchema and then upgrade to 49 version. 
Or the metabase does not support connecting to any other schema other than Public. Please clarify.

paoliniluis on (2024-08-08 16:28:12 UTC): Metabase does not support other schema than public

skfathima87 (Issue Creator) on (2024-08-08 16:34:36 UTC): Thanks for clarifying, is there any plan to support this feature in future releases.

paoliniluis on (2024-08-08 16:39:29 UTC): Check the issue I posted, this is not under discussion right now in the team but we might address it at some point if this is requested often

skfathima87 (Issue Creator) on (2024-08-08 16:42:34 UTC): Thank you so much for the quick response, really appreciate your support. You can close the ticket.

"
2455823499,issue,open,,Disabling Google SSO Locks out Previously Provisioned SSO Users,"### Describe the bug

If an SSO account is provisioned externally and password authentication is enabled for the instance - the SSO user nor the admin can initiate a password reset to allow the user to begin using password auth. The reset email indicates that a password can't be set because the user has an SSO account.

### To Reproduce

1. Set up Google SSO such that users are provisioned when the account is created
2. Log in as a user
3. Enabled password auth on the instance
4. Try to initiate a pw reset for the provisioned user
5. See that the email indicates that the user should contact the admin for help setting a password



### Expected behavior
If an admin disables Google Auth then password reset functionality should work for the users provisions via SSO.

A point of confusion: docs indicate that enabling password auth applies to all users but this isn't the case:
https://www.metabase.com/docs/latest/people-and-groups/authenticating-with-jwt#disabling-password-logins

### Logs

_No response_

### Information about your Metabase installation

```JSON
v49
```


### Severity

annoying

### Additional context

Currently, when admins want to disable Google SSO & enable password auth they have to hack the core-user table to remove the ""sso_auth"" indicator. Otherwise password resets will not work.",ixipixi,2024-08-08 13:32:16+00:00,[],2025-02-05 19:06:33+00:00,,https://github.com/metabase/metabase/issues/46634,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Product Input Needed', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2607357575, 'issue_id': 2455823499, 'author': 'luizarakaki', 'body': 'Need to investigate this further to understand security consequences', 'created_at': datetime.datetime(2025, 1, 22, 14, 12, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617210071, 'issue_id': 2455823499, 'author': 'ixipixi', 'body': 'Related: https://github.com/metabase/metabase/issues/11322\n\n@luizarakaki it\'s probably also worth noting that the ""Authentication"" setup page in the admin panel says:\n\n""Allows users with existing Metabase accounts to login with a Google account that matches their email address _in addition_ to their Metabase username and password.""', 'created_at': datetime.datetime(2025, 1, 27, 23, 52, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-22 14:12:46 UTC): Need to investigate this further to understand security consequences

ixipixi (Issue Creator) on (2025-01-27 23:52:00 UTC): Related: https://github.com/metabase/metabase/issues/11322

@luizarakaki it's probably also worth noting that the ""Authentication"" setup page in the admin panel says:

""Allows users with existing Metabase accounts to login with a Google account that matches their email address _in addition_ to their Metabase username and password.""

"
2455194912,issue,closed,not_planned,"Metabase analytics fail with ""ERROR: relation ""public.*"" does not exist""","**Describe the bug**
We recently upgraded Metabase from 0.47 to 0.50 and afterwards bought an Enterprise license (effectively running `v1.50.13` now). When trying to access the Metabase analytics, none of the charts are loading. Inspecting the network requests and/or Metabase logs shows errors like this one:
```
Error processing query: ERROR: relation ""public.v_audit_log"" does not exist
```
(full stack trace below)

Indeed, this relation does not exist, because the schema we're running the Metabase application database in is called `data`, not `public` (which is the default setting for the [zalando postgres-operator](https://github.com/zalando/postgres-operator) that we're using to deploy the database). I can see that the requested views are present in the `data` schema, but by the looks of the files in [`resources/instance_analytics`](https://github.com/metabase/metabase/tree/master/resources/instance_analytics/databases/Internal%20Metabase%20Database/schemas/public/tables) it seems that these are hardcoded to use the `public` schema. 

**Logs**
<details><summary>Full stack trace here</summary>

```
	
Error processing query: ERROR: relation ""public.v_audit_log"" does not exist
  Position: 938
{:database_id 13371337,
 :started_at #t ""2024-08-08T07:21:15.725225Z[UTC]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: ERROR: relation \""public.v_audit_log\"" does not exist\n  Position: 938"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__81473$fn__81474.invoke(execute.clj:716)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__81473.invoke(execute.clj:713)""
    ""driver.sql_jdbc.execute$fn__81266$fn__81267.invoke(execute.clj:397)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
    ""driver.sql_jdbc.execute$fn__81266.invokeStatic(execute.clj:391)""
    ""driver.sql_jdbc.execute$fn__81266.invoke(execute.clj:389)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc$fn__115410.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__115410.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:61)""
    ""query_processor.execute$run.invoke(execute.clj:55)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__69967.invoke(execute.clj:24)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__69972.invoke(execute.clj:35)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___69958.invoke(cache.clj:242)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__63949.invoke(permissions.clj:118)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__110035$check_download_permissions__110036$fn__110037.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64547.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111874$maybe_apply_column_level_perms_check__111875$fn__111876.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64557.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__69999.invoke(execute.clj:93)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
    ""query_processor.execute$execute.invoke(execute.clj:88)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81842$handle_audit_app_internal_queries__81843$fn__81844.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64585.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75773.invoke(process_userland_query.clj:186)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75842.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__75879.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__64989.invoke(setup.clj:189)""
    ""query_processor.setup$do_with_database_local_settings$fn__64984.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__64979$fn__64980.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__64979.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__64972$fn__64975.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.setup$do_with_metadata_provider$fn__64972.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__64966.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""api.dataset$run_streaming_query$fn__98348.invoke(dataset.clj:84)""
    ""query_processor.streaming$_streaming_response$fn__68442$fn__68443$fn__68444.invoke(streaming.clj:175)""
    ""query_processor.streaming$_streaming_response$fn__68442$fn__68443.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__68442.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
    ""async.streaming_response$do_f_async$task__52253.invoke(streaming_response.clj:87)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 443 queryType: MBQL queryHash: 85ab3c0c0182024387e72608bc2ed44525b540d47b799d208bf15e3167c9ca66""
     ""SELECT""
     ""  \""source\"".\""id\"" AS \""id\"",""
     ""  \""source\"".\""topic\"" AS \""topic\"",""
     ""  \""source\"".\""timestamp\"" AS \""timestamp\"",""
     ""  \""source\"".\""end_timestamp\"" AS \""end_timestamp\"",""
     ""  \""source\"".\""user_id\"" AS \""user_id\"",""
     ""  \""source\"".\""entity_type\"" AS \""entity_type\"",""
     ""  \""source\"".\""entity_id\"" AS \""entity_id\"",""
     ""  \""source\"".\""entity_qualified_id\"" AS \""entity_qualified_id\"",""
     ""  \""source\"".\""details\"" AS \""details\""""
     ""FROM""
     ""  (""
     ""    SELECT""
     ""      \""public\"".\""v_audit_log\"".\""id\"" AS \""id\"",""
     ""      \""public\"".\""v_audit_log\"".\""topic\"" AS \""topic\"",""
     ""      \""public\"".\""v_audit_log\"".\""timestamp\"" AS \""timestamp\"",""
     ""      \""public\"".\""v_audit_log\"".\""end_timestamp\"" AS \""end_timestamp\"",""
     ""      \""public\"".\""v_audit_log\"".\""user_id\"" AS \""user_id\"",""
     ""      \""public\"".\""v_audit_log\"".\""entity_type\"" AS \""entity_type\"",""
     ""      \""public\"".\""v_audit_log\"".\""entity_id\"" AS \""entity_id\"",""
     ""      \""public\"".\""v_audit_log\"".\""entity_qualified_id\"" AS \""entity_qualified_id\"",""
     ""      \""public\"".\""v_audit_log\"".\""details\"" AS \""details\""""
     ""    FROM""
     ""      \""public\"".\""v_audit_log\""""
     ""    ORDER BY""
     ""      \""public\"".\""v_audit_log\"".\""timestamp\"" DESC""
     ""  ) AS \""source\""""
     ""LIMIT""
     ""  2000""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :state ""42P01"",
 :error_type :invalid-query,
 :json_query
 {:database 13371337,
  :type ""query"",
  :query {:source-table ""card__15589""},
  :parameters [],
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""source\"".\""id\"" AS \""id\"", \""source\"".\""topic\"" AS \""topic\"", \""source\"".\""timestamp\"" AS \""timestamp\"", \""source\"".\""end_timestamp\"" AS \""end_timestamp\"", \""source\"".\""user_id\"" AS \""user_id\"", \""source\"".\""entity_type\"" AS \""entity_type\"", \""source\"".\""entity_id\"" AS \""entity_id\"", \""source\"".\""entity_qualified_id\"" AS \""entity_qualified_id\"", \""source\"".\""details\"" AS \""details\"" FROM (SELECT \""public\"".\""v_audit_log\"".\""id\"" AS \""id\"", \""public\"".\""v_audit_log\"".\""topic\"" AS \""topic\"", \""public\"".\""v_audit_log\"".\""timestamp\"" AS \""timestamp\"", \""public\"".\""v_audit_log\"".\""end_timestamp\"" AS \""end_timestamp\"", \""public\"".\""v_audit_log\"".\""user_id\"" AS \""user_id\"", \""public\"".\""v_audit_log\"".\""entity_type\"" AS \""entity_type\"", \""public\"".\""v_audit_log\"".\""entity_id\"" AS \""entity_id\"", \""public\"".\""v_audit_log\"".\""entity_qualified_id\"" AS \""entity_qualified_id\"", \""public\"".\""v_audit_log\"".\""details\"" AS \""details\"" FROM \""public\"".\""v_audit_log\"" ORDER BY \""public\"".\""v_audit_log\"".\""timestamp\"" DESC) AS \""source\"" LIMIT 2000"",
  :params nil},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__81392.invokeStatic(execute.clj:569)""
  ""driver.sql_jdbc.execute$fn__81392.invoke(execute.clj:567)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:577)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:574)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81473$fn__81474.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81473.invoke(execute.clj:713)""
  ""driver.sql_jdbc.execute$fn__81266$fn__81267.invoke(execute.clj:397)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
  ""driver.sql_jdbc.execute$fn__81266.invokeStatic(execute.clj:391)""
  ""driver.sql_jdbc.execute$fn__81266.invoke(execute.clj:389)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc$fn__115410.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__115410.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:61)""
  ""query_processor.execute$run.invoke(execute.clj:55)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__69967.invoke(execute.clj:24)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__69972.invoke(execute.clj:35)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___69958.invoke(cache.clj:242)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__63949.invoke(permissions.clj:118)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__110035$check_download_permissions__110036$fn__110037.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64547.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111874$maybe_apply_column_level_perms_check__111875$fn__111876.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64557.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__69999.invoke(execute.clj:93)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
  ""query_processor.execute$execute.invoke(execute.clj:88)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81842$handle_audit_app_internal_queries__81843$fn__81844.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64585.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75773.invoke(process_userland_query.clj:186)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75842.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__75879.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__64989.invoke(setup.clj:189)""
  ""query_processor.setup$do_with_database_local_settings$fn__64984.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__64979$fn__64980.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__64979.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__64972$fn__64975.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.setup$do_with_metadata_provider$fn__64972.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__64966.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""api.dataset$run_streaming_query$fn__98348.invoke(dataset.clj:84)""
  ""query_processor.streaming$_streaming_response$fn__68442$fn__68443$fn__68444.invoke(streaming.clj:175)""
  ""query_processor.streaming$_streaming_response$fn__68442$fn__68443.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__68442.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
  ""async.streaming_response$do_f_async$task__52253.invoke(streaming_response.clj:87)""],
 :card_id 15589,
 :context :ad-hoc,
 :error ""ERROR: relation \""public.v_audit_log\"" does not exist\n  Position: 938"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
  :qp/source-card-id 15589,
  :info
  {:executed-by 443,
   :context :ad-hoc,
   :card-id 15589,
   :metadata/model-metadata
   [{:semantic_type :type/PK,
     :name ""id"",
     :field_ref [:field 591566 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591566,
     :visibility_type :normal,
     :display_name ""ID"",
     :base_type :type/Integer}
    {:semantic_type :type/Category,
     :name ""topic"",
     :field_ref [:field 591565 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591565,
     :visibility_type :normal,
     :display_name ""Topic"",
     :base_type :type/Text}
    {:semantic_type :type/CreationTimestamp,
     :unit :default,
     :name ""timestamp"",
     :field_ref [:field 591568 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}],
     :effective_type :type/DateTimeWithLocalTZ,
     :id 591568,
     :visibility_type :normal,
     :display_name ""Timestamp"",
     :base_type :type/DateTimeWithLocalTZ}
    {:name ""end_timestamp"",
     :field_ref [:field 591572 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591572,
     :visibility_type :normal,
     :display_name ""End Timestamp"",
     :base_type :type/Text}
    {:name ""user_id"",
     :field_ref [:field 591570 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591570,
     :visibility_type :normal,
     :display_name ""User ID"",
     :base_type :type/Integer}
    {:semantic_type :type/Category,
     :name ""entity_type"",
     :field_ref [:field 591569 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591569,
     :visibility_type :normal,
     :display_name ""Entity Type"",
     :base_type :type/Text}
    {:semantic_type :type/Category,
     :name ""entity_id"",
     :field_ref [:field 591573 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591573,
     :visibility_type :normal,
     :display_name ""Entity ID"",
     :base_type :type/Integer}
    {:semantic_type :type/Category,
     :name ""entity_qualified_id"",
     :field_ref [:field 591571 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591571,
     :visibility_type :normal,
     :display_name ""Entity Qualified ID"",
     :base_type :type/Text}
    {:semantic_type :type/Category,
     :name ""details"",
     :field_ref [:field 591567 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591567,
     :visibility_type :normal,
     :display_name ""Details"",
     :base_type :type/Text}]},
  :database 13371337,
  :type :query,
  :query
  {:qp/stage-had-source-card 15589,
   :source-query/model? true,
   :source-metadata
   [{:database_type ""int4"",
     :semantic_type :type/PK,
     :table_id 6608,
     :name ""id"",
     :field_ref [:field 591566 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591566,
     :position 0,
     :visibility_type :normal,
     :display_name ""ID"",
     :base_type :type/Integer}
    {:database_type ""varchar"",
     :semantic_type :type/Category,
     :table_id 6608,
     :name ""topic"",
     :field_ref [:field 591565 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591565,
     :position 1,
     :visibility_type :normal,
     :display_name ""Topic"",
     :base_type :type/Text}
    {:database_type ""timestamptz"",
     :semantic_type :type/CreationTimestamp,
     :table_id 6608,
     :unit :default,
     :name ""timestamp"",
     :field_ref [:field 591568 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}],
     :effective_type :type/DateTimeWithLocalTZ,
     :id 591568,
     :position 2,
     :visibility_type :normal,
     :display_name ""Timestamp"",
     :base_type :type/DateTimeWithLocalTZ}
    {:database_type ""text"",
     :table_id 6608,
     :name ""end_timestamp"",
     :field_ref [:field 591572 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591572,
     :position 3,
     :visibility_type :normal,
     :display_name ""End Timestamp"",
     :base_type :type/Text}
    {:database_type ""int4"",
     :table_id 6608,
     :name ""user_id"",
     :field_ref [:field 591570 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591570,
     :position 4,
     :visibility_type :normal,
     :display_name ""User ID"",
     :base_type :type/Integer}
    {:database_type ""text"",
     :semantic_type :type/Category,
     :table_id 6608,
     :name ""entity_type"",
     :field_ref [:field 591569 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591569,
     :position 5,
     :visibility_type :normal,
     :display_name ""Entity Type"",
     :base_type :type/Text}
    {:database_type ""int4"",
     :semantic_type :type/Category,
     :table_id 6608,
     :name ""entity_id"",
     :field_ref [:field 591573 {:base-type :type/Integer}],
     :effective_type :type/Integer,
     :id 591573,
     :position 6,
     :visibility_type :normal,
     :display_name ""Entity ID"",
     :base_type :type/Integer}
    {:database_type ""text"",
     :semantic_type :type/Category,
     :table_id 6608,
     :name ""entity_qualified_id"",
     :field_ref [:field 591571 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591571,
     :position 7,
     :visibility_type :normal,
     :display_name ""Entity Qualified ID"",
     :base_type :type/Text}
    {:database_type ""text"",
     :semantic_type :type/Category,
     :table_id 6608,
     :name ""details"",
     :field_ref [:field 591567 {:base-type :type/Text}],
     :effective_type :type/Text,
     :id 591567,
     :position 8,
     :visibility_type :normal,
     :display_name ""Details"",
     :base_type :type/Text}],
   :fields
   [[:field 591566 {:base-type :type/Integer}]
    [:field 591565 {:base-type :type/Text}]
    [:field 591568 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}]
    [:field 591572 {:base-type :type/Text}]
    [:field 591570 {:base-type :type/Integer}]
    [:field 591569 {:base-type :type/Text}]
    [:field 591573 {:base-type :type/Integer}]
    [:field 591571 {:base-type :type/Text}]
    [:field 591567 {:base-type :type/Text}]],
   :source-query
   {:fields
    [[:field 591566 {:base-type :type/Integer}]
     [:field 591565 {:base-type :type/Text}]
     [:field 591568 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}]
     [:field 591572 {:base-type :type/Text}]
     [:field 591570 {:base-type :type/Integer}]
     [:field 591569 {:base-type :type/Text}]
     [:field 591573 {:base-type :type/Integer}]
     [:field 591571 {:base-type :type/Text}]
     [:field 591567 {:base-type :type/Text}]],
    :order-by [[:desc [:field 591568 {:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}]]],
    :source-table 6608,
    :qp/stage-is-from-source-card 15589},
   :limit 2000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :data {:rows [], :cols []}}
```

</details>

**To Reproduce**
Steps to reproduce the behavior:
1. Deploy postgres with a metabase database and a schema different than `public`
2. Hook up Metabase Enterprise to that database and schema
3. Navigate to the analytics dashboard
4. See error (in browser dev tools network and Metabase logs)

**Expected behavior**
The analytics dashboard should pick up the tables/views from the other schema.

**~~Screenshots~~**

**Severity**
Not having the analytics would be a dealbreaker for us and would lead to cancelling the subscription. We're currently evaluating whether we can rename the schema without much effort, but it should really not cause trouble in the first place.

**~~Additional context~~**


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.30-flatcar"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""clickhouse""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.6 (Ubuntu 15.6-1.pgdg22.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""pro-self-hosted-yearly"",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v1.50.13"",
      ""hash"": ""2086968""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```",Gerrit-K,2024-08-08 08:28:54+00:00,[],2024-08-09 10:22:54+00:00,2024-08-08 15:27:23+00:00,https://github.com/metabase/metabase/issues/46620,"[('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2276107763, 'issue_id': 2455194912, 'author': 'Tony-metabase', 'body': ""Hey @Gerrit-K I do understand this but we never intentionally allowed alternative schemas in older versions and I think we all assumed everybody was using public since that is common practice.\r\n \r\nI have to say though that there's no reason in particular we wouldn't be able to let you use a different schema if you were changing the default schema in your app DB connection details or something ... we just had no idea people were doing it or wanted to do it and never thought about supporting it. We could remove all those public. things from the SQL file and then you should be able to use something else if you want but it's not something that can be changed all of a sudden. What you are hitting is the below issue:\r\n \r\nhttps://github.com/metabase/metabase/issues/37836\r\n\r\nWe will make a note about this but for now please change that to public so you can get unblocked"", 'created_at': datetime.datetime(2024, 8, 8, 15, 27, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277585436, 'issue_id': 2455194912, 'author': 'Gerrit-K', 'body': ""Hi @Tony-metabase, thanks for the prompt response 🙏  I see. We would have probably noticed sooner if it was a scratch new instance (due to the schema initialization scripts). But since we've upgraded an older instance that already existed prior to 0.48, it worked fine until trying to access the pro analytics.\r\n\r\n> I think we all assumed everybody was using public since that is common practice\r\n\r\nIt might be the default, but I can imagine especially in corporate context, where people are more likely to go for Metabase Pro, they might be using a non-default schema more often, so it would make sense to support this. Also, I would recommend to document this limitation somewhere in the setup guides (e.g. on [metabase-in-production](https://www.metabase.com/learn/metabase-basics/administration/administration-and-operation/metabase-in-production) or [configuring-application-database](https://www.metabase.com/docs/latest/installation-and-operation/configuring-application-database)).\r\n\r\nWe will try to rename the schema then 👍"", 'created_at': datetime.datetime(2024, 8, 9, 9, 55, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277634468, 'issue_id': 2455194912, 'author': 'Tony-metabase', 'body': 'That is a very good point! I will mention it to the writers so it can be included :) ... Thanks for the feedback and again sorry for impacting you!', 'created_at': datetime.datetime(2024, 8, 9, 10, 22, 53, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-08-08 15:27:23 UTC): Hey @Gerrit-K I do understand this but we never intentionally allowed alternative schemas in older versions and I think we all assumed everybody was using public since that is common practice.
 
I have to say though that there's no reason in particular we wouldn't be able to let you use a different schema if you were changing the default schema in your app DB connection details or something ... we just had no idea people were doing it or wanted to do it and never thought about supporting it. We could remove all those public. things from the SQL file and then you should be able to use something else if you want but it's not something that can be changed all of a sudden. What you are hitting is the below issue:
 
https://github.com/metabase/metabase/issues/37836

We will make a note about this but for now please change that to public so you can get unblocked

Gerrit-K (Issue Creator) on (2024-08-09 09:55:16 UTC): Hi @Tony-metabase, thanks for the prompt response 🙏  I see. We would have probably noticed sooner if it was a scratch new instance (due to the schema initialization scripts). But since we've upgraded an older instance that already existed prior to 0.48, it worked fine until trying to access the pro analytics.


It might be the default, but I can imagine especially in corporate context, where people are more likely to go for Metabase Pro, they might be using a non-default schema more often, so it would make sense to support this. Also, I would recommend to document this limitation somewhere in the setup guides (e.g. on [metabase-in-production](https://www.metabase.com/learn/metabase-basics/administration/administration-and-operation/metabase-in-production) or [configuring-application-database](https://www.metabase.com/docs/latest/installation-and-operation/configuring-application-database)).

We will try to rename the schema then 👍

Tony-metabase on (2024-08-09 10:22:53 UTC): That is a very good point! I will mention it to the writers so it can be included :) ... Thanks for the feedback and again sorry for impacting you!

"
2454486303,issue,closed,not_planned,Feature: Add a quick launch mode for demoing / debugging,"**Is your feature request related to a problem? Please describe.**
Not related to a problem. Very often (via Docker), I include Metabase in projects just to quickly and easily interface with some database data. The only downside is needing to signup with a fake account on the self-hosted Metabase instance. 

I usually keep the Metabase database and the project database underneath the same Postgres server, usually the example below. This is convenient, but it has the side effect that clearing the projects database also means you have to sign up for Metabase again.

**Describe the solution you'd like**
Without cannibalizing the existing paid config file feature, I'd like to see something such as a ""demo account"" that can be activated with an environment variable. Also, if we could set up a single database connection via environment variables, it would be nice. This way, we can prepare a demo completely with docker.

**Describe alternatives you've considered**
It is possible to keep the Metabase's data in a separate RDBMS instance from the project. I prefer to keep these together though. Also, managing them separately would not address this whole feature request; it would only prevent the need to sign-up again.

**How important is this feature to you?**
nice to have

**Additional context**
Example:
```
services:
  storage:
    image: postgres:14-alpine
    ports:
      - 5432:5432
    volumes:
      - ./storage-postgres/data:/var/lib/postgresql/data/
      - ./storage-postgres/sql/MyProjectDatabase.sql:/docker-entrypoint-initdb.d/init.sql
    environment:
      POSTGRES_PASSWORD: admin
      POSTGRES_USER: admin
      POSTGRES_DB: metabase
    healthcheck:
      test: [""CMD-SHELL"", ""pg_isready -U admin -d MyProjectDatabase -h 127.0.0.1""]
      interval: 5s
      timeout: 10s
      retries: 5
    profiles:
      - fullstack
      - storage
    metabase:
      image: metabase/metabase:latest
      container_name: metabase
      volumes:
        - /dev/urandom:/dev/random:ro
        - /metabase-data/:/metabase
      ports:
        - 3000:3000
      environment:
        MB_DB_TYPE: postgres
        MB_DB_USER: admin
        MB_DB_PASS: admin
        MB_DB_HOST: storage
        MB_DB_PORT: 5432
        MB_DB_DBNAME: metabase
      depends_on:
        - storage
      profiles:
        - metabase
```
",MrChadMWood,2024-08-07 22:59:28+00:00,[],2024-08-08 01:05:42+00:00,2024-08-08 01:05:42+00:00,https://github.com/metabase/metabase/issues/46611,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2274683496, 'issue_id': 2454486303, 'author': 'paoliniluis', 'body': 'Please check all my demos here: https://github.com/paoliniluis/', 'created_at': datetime.datetime(2024, 8, 8, 1, 5, 42, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-08 01:05:42 UTC): Please check all my demos here: https://github.com/paoliniluis/

"
2454466550,issue,closed,completed,"Testing plan for ""Allow multiple breakouts of the same column""","Product doc https://www.notion.so/metabase/Allow-multiple-breakouts-of-the-same-column-9b6c5b715f8a4434b74501f13271be89

In this project we allow to create multiple breakouts for the same column with different temporal unit. Let's say, `Created At (year)` and `Created At (month)`. The main challenge is that field refs are nearly identical in this case and we need to make sure we can differentiate between the columns across the app. 

## Dimensions

Column source:
- current stage/previous stage/data source/joins
- question/model (for data source only)

Temporal units:
- `month`, ... that do not change `effective-type`
- `year`, ... that change `effective-type`

Query builder:
- notebook/viz settings/filter modal/summarize sidebar/timeseries chrome
- pivot tables with an explicit ""pivot column split""

Model editor:
- metadata overrides (would be surprised if it works)

Dashboards:
- Dashboard type - regular / public / embedded
- Parameter mapping  (regular dashboard only)
- Parameter type - regular/temporal unit
- Drills
- Click behaviors - update filter / open dashboard / open question / custom link

## Cases

### Current stage

#### Notebook

- [x] should allow to add multiple breakouts for the same column
- [x] should ignore duplicate columns
- [x] should allow to reorder multiple breakouts for the same column
- [x] should allow to add same-stage sort clauses

#### Viz settings
- [x] should allow to enable different formatting settings for breakouts for the same column
- [x] should allow to create a pivot table with > 2 breakouts of the same column and change the order of the columns

#### Summarize sidebar
- [x] should show multiple breakouts for the same column and allow to change them

#### Timeseries chrome
- [x] should work with the first breakout for a temporal column if there are multiple breakouts

#### Dashboards
- [x] can map temporal unit parameters to different breakouts of the same column and drill-thru in regular/public/embedded

### Previous stage

#### Notebook
- [x] should allow to add post-aggregation joins/expressions/filters/aggregations/breakouts/sort/limit clauses

#### Filter modal
- [x] should allow to add post-aggregation filters

#### Viz settings
- [x] should allow to toggle breakouts from the previous stage

#### Dashboards
- [x] filters / title drills

### Data source

#### Notebook
- [x] should allow to use a question with multiple breakouts as data source and toggle its fields
- [x] should allow to join a question with multiple breakouts and toggle its fields
- [x] should allow to add same-stage clauses

#### Viz settings
- [x] toggle fields
",ranquild,2024-08-07 22:37:35+00:00,[],2024-09-03 18:07:44+00:00,2024-09-03 18:07:44+00:00,https://github.com/metabase/metabase/issues/46610,"[('.TestingStrategy/FE', '')]",[],
2454434007,issue,open,,Allow Keystore files for Digital Signing of SSO Requests to be Uploaded to Cloud Instances,"**Is your feature request related to a problem? Please describe.**
We allow the configuration of digital signing for SSO requests in SAML settings. However, the keystore settings on the SAML setup page require an absolute path to a file hosted on the server. This means, for cloud instances, you can't set up digital signing.

**Describe the solution you'd like**
Upload the keystore file to the instance

**Additional context**
This would also be an issue for folks who want to set up single logout with a service like Okta. Okta only allows SLO on digitally signed requests. 
",ixipixi,2024-08-07 22:06:37+00:00,[],2025-02-04 20:31:03+00:00,,https://github.com/metabase/metabase/issues/46606,"[('Type:New Feature', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('Deployment/MetabaseCloud', 'Issue only affects users of Metabase Cloud')]",[],
2454428384,issue,open,,Single Logout Fails for Okta,"### Describe the bug

If you enabled SLO for Okta the logout fails when initiated from Metabase.



### To Reproduce

1. Set up Metabase v49
2. Create a keystore for signing SSO requests & export the cert in PEM format
3. Set up a test SAML application in Okta
Enable single logout in Okta (it requires digital signing)
4. Set up SAML in Metabase with the keystore you created and the Okta settings
5. Set up a test Okta user
6. Login via SSO as the test user in Okta
7. Note that logging in with the signed request works as expected
8. Try to logout
9. See ""error 400"" page


### Expected behavior

SLO should work with Okta

### Logs

_No response_

### Information about your Metabase installation

```JSON
v49
```


### Severity

annoying

### Additional context

I suspect that we're failing to sign the the SLO request and that we're supposed to be directing the logout request to Oktas SLO endpoint (it looks like we may be hitting their sso endpoint instead).**Handy links**

**Okta docs:**
- [Enable SLO for SAML integrations](https://help.okta.com/en-us/content/topics/apps/apps_single_logout.htm)
- [Configure Single Lgout](https://developer.okta.com/docs/guides/single-logout/saml2/main/)

Quick run through in Loom:
https://www.loom.com/share/9bf0882488ba480c8016a08b5e8002bd

![error](https://github.com/user-attachments/assets/27279557-2d0f-411d-be5d-6f2353ff5c6b)
![settings_okta](https://github.com/user-attachments/assets/fa678fcb-56e1-46fd-a7f4-15bae51f4cbe)
",ixipixi,2024-08-07 22:02:02+00:00,[],2025-02-05 19:21:04+00:00,,https://github.com/metabase/metabase/issues/46605,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2274431422, 'issue_id': 2454428384, 'author': 'ixipixi', 'body': 'Also relevant: https://github.com/metabase/metabase/issues/46606', 'created_at': datetime.datetime(2024, 8, 7, 22, 6, 54, tzinfo=datetime.timezone.utc)}]","ixipixi (Issue Creator) on (2024-08-07 22:06:54 UTC): Also relevant: https://github.com/metabase/metabase/issues/46606

"
2454369472,issue,closed,completed,Admin / Performance pages have an incomplete document title,"![Image](https://github.com/user-attachments/assets/85fc6714-daac-476f-b1f2-3eb6ca1a2ae1)

The title here is just 'Admin' but it should be 'Database caching - Performance - Admin'",rafpaf,2024-08-07 21:19:24+00:00,['rafpaf'],2024-08-13 18:31:58+00:00,2024-08-09 17:37:37+00:00,https://github.com/metabase/metabase/issues/46603,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2453913790,issue,open,,Bars overlap when applying non-linear scale to x-axis,"[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1723013899156829)

![Image](https://github.com/user-attachments/assets/42c9fea6-3623-4572-8ac8-f766fbc125cd)

",cdeweyx,2024-08-07 16:47:54+00:00,[],2025-02-04 20:31:25+00:00,,https://github.com/metabase/metabase/issues/46592,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Product Input Needed', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2273912555, 'issue_id': 2453913790, 'author': 'cdeweyx', 'body': 'This was broken prior to the ECharts migration. Expected behavior is unclear.', 'created_at': datetime.datetime(2024, 8, 7, 16, 57, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273939525, 'issue_id': 2453913790, 'author': 'cdeweyx', 'body': '[More discussion](https://metaboat.slack.com/archives/C064QMXEV9N/p1723049310887629)', 'created_at': datetime.datetime(2024, 8, 7, 17, 11, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274178561, 'issue_id': 2453913790, 'author': 'cdeweyx', 'body': 'One idea: For histograms maybe we could have 1px width bars to show the distribution.', 'created_at': datetime.datetime(2024, 8, 7, 19, 16, 52, tzinfo=datetime.timezone.utc)}]","cdeweyx (Issue Creator) on (2024-08-07 16:57:37 UTC): This was broken prior to the ECharts migration. Expected behavior is unclear.

cdeweyx (Issue Creator) on (2024-08-07 17:11:16 UTC): [More discussion](https://metaboat.slack.com/archives/C064QMXEV9N/p1723049310887629)

cdeweyx (Issue Creator) on (2024-08-07 19:16:52 UTC): One idea: For histograms maybe we could have 1px width bars to show the distribution.

"
2453594912,issue,closed,completed,Remove some os information in hosted ,"Let's remove some of the information about systems when hosted in cloud. 

<img width=""1212"" alt=""image"" src=""https://github.com/user-attachments/assets/716a5611-db21-44f3-bff6-fa027bde1c83"">

This is useful for people to send to us on their own hardware. But when hosted in cloud, we don't need them to report this to us nor do we need to expose it to them.

Check `metabase.troubleshooting/metabase-info` and use `metabase.public-settings.premium-features/is-hosted?` to remove some of the details about host.",dpsutton,2024-08-07 14:12:28+00:00,['escherize'],2024-08-15 20:09:21+00:00,2024-08-15 19:16:19+00:00,https://github.com/metabase/metabase/issues/46580,"[('Priority:P2', 'Average run of the mill bug'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2453506767,issue,closed,completed,Pivot Table not showing sub row totals - when using models,"### Describe the bug

This is a bug which causes row totals to not show ... What makes it more complex is that it happens for Models based questions that carry a join. There might be other combinations that cause this though

### To Reproduce

There is an example [here](https://stats.metabase.com/question/19076-non-working-pivot-row-total) 

<img width=""1512"" alt=""image"" src=""https://github.com/user-attachments/assets/b3ea03ca-8774-41cb-bf4e-2320dff5b398"">

 
But in summary:

a) Create a model as follows:

![image](https://github.com/user-attachments/assets/3f37c583-7c3c-46cb-8526-14c8afabe55f)

b)  Create a question as follows:

![image](https://github.com/user-attachments/assets/eb8b280a-f9d4-48af-b7b1-9922e7377aa8)

Then Visualise as a Pivot with the combination int he link above. 


What is more confusing is that instead of the model column you use the implicit join for the Users -> Name 

<img width=""931"" alt=""image"" src=""https://github.com/user-attachments/assets/c55d6f9f-f678-4e19-90f3-ad39b47ca6d3"">

You get the proper output

<img width=""782"" alt=""image"" src=""https://github.com/user-attachments/assets/e90b47cb-469d-472f-be2b-78ae28b2403d"">


### Expected behavior

Row totals show up

### Logs

None that are relevant

### Information about your Metabase installation

```JSON
Master happens also on 50
```


### Severity

Annoying 

### Additional context

_No response_",Tony-metabase,2024-08-07 13:36:08+00:00,['adam-james-v'],2024-10-01 21:56:35+00:00,2024-09-27 14:38:54+00:00,https://github.com/metabase/metabase/issues/46575,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2341346283, 'issue_id': 2453506767, 'author': 'zbodi74', 'body': 'Escalating - as this is a blocking issue for a paying customer.', 'created_at': datetime.datetime(2024, 9, 10, 15, 57, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341764453, 'issue_id': 2453506767, 'author': 'alxnddr', 'body': '> What is more confusing is that instead of the model column you use the implicit join for the Users -> Name You get the proper output\r\n\r\nEven simple reordering of columns here to make the question dirty make it work because dirty queries go to `/api/dataset/pivot` endpoint which works correctly for the same query and the same viz settings.\r\n<img width=""346"" alt=""Screenshot 2024-09-10 at 2 44 38\u202fPM"" src=""https://github.com/user-attachments/assets/a589afae-1bdb-4482-8961-219c930f8f34"">\r\n\r\nI assume there is a bug in `/api/card/pivot/:cardId/query` endpoint', 'created_at': datetime.datetime(2024, 9, 10, 18, 47, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387147075, 'issue_id': 2453506767, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)', 'created_at': datetime.datetime(2024, 10, 1, 21, 56, 33, tzinfo=datetime.timezone.utc)}]","zbodi74 on (2024-09-10 15:57:56 UTC): Escalating - as this is a blocking issue for a paying customer.

alxnddr on (2024-09-10 18:47:24 UTC): Even simple reordering of columns here to make the question dirty make it work because dirty queries go to `/api/dataset/pivot` endpoint which works correctly for the same query and the same viz settings.
<img width=""346"" alt=""Screenshot 2024-09-10 at 2 44 38 PM"" src=""https://github.com/user-attachments/assets/a589afae-1bdb-4482-8961-219c930f8f34"">

I assume there is a bug in `/api/card/pivot/:cardId/query` endpoint

github-actions[bot] on (2024-10-01 21:56:33 UTC): 🚀 This should also be released by [v0.51](https://github.com/metabase/metabase/milestone/231)

"
2453412467,issue,closed,completed,"v0.50.x - question crashes with numeric type and oracle database ""TypeError: e.toFixed is not a function""","### Describe the bug

Since v0.50.x hovering over the header of a NUMBER typed column causes a frontend error that crashes the displayed question. This happens when using an oracle DB and when the column metadata is not set or set to a numeric type.

![metabase-crash-1](https://github.com/user-attachments/assets/2de72fd1-c7af-48c0-af6b-ce2472d4e447)

![grafik](https://github.com/user-attachments/assets/2b333627-ad58-45bf-a471-4823db484f1f)


### To Reproduce

1. Set up a new metabase instance with docker putting an oracle-jdbc-driver into the plugins folder.
2. Set up a table with a `NUMBER` column on the oracle database
3. Connect metabase to the Oracle database
4. Create a question for the previously created table and hover over the column headers

I used the latest [ojdbc11.jar](https://download.oracle.com/otn-pub/otn_software/jdbc/234/ojdbc11.jar) as jdbc driver.
To reproduce the error i used [Oracle Database XE Release 21c](https://container-registry.oracle.com/ords/f?p=113:4:116595847545161:::4:P4_REPOSITORY,AI_REPOSITORY,AI_REPOSITORY_NAME,P4_REPOSITORY_NAME,P4_EULA_ID,P4_BUSINESS_AREA_ID:803,803,Oracle%20Database%20Express%20Edition,Oracle%20Database%20Express%20Edition,1,0&cs=31RJ2Qrbu6s3cv9VTJmRigJuIm2BglixteP4I7m8uBo7s1uurGg1td0jk0Lhlme1etvT9Qc-v5-O6uA1el6SuSA)

In my setup to reproduce the error i started a fresh metabase with a fresh oracle-xe Database with the following docker compose file:

```
version: ""2""

services:
  metabase:
    image: metabase/metabase:v0.50.18
    depends_on:
      - oracle-xe
    ports:
      - 3000:3000
    volumes:
      - type: bind
        source: ./plugins
        target: /plugins

  oracle-xe:
    image: container-registry.oracle.com/database/express:21.3.0-xe
    ports:
      - 1521:1521
      - 5500:5500
    environment:
      - ORACLE_PWD=test
```

Make sure u have a plugins folder with the ojdbc.jar in the folder you have the docker compose.yml.
Start it with docker compose up.
You can connect to the oracle database on:

    url: oracle-xe
    port: 1521
    service: XE
    user: system
    password: test

I set up a table in the database with this sql (schema was called DBSFWUSER by default):

```
CREATE TABLE DBSFWUSER.TEST_TABLE (ID NUMBER(10,0), TEST_COLUMN NUMBER);
INSERT INTO DBSFWUSER.TEST_TABLE(ID) VALUES (1);
```

When loading this table into a question everything seems to work fine. When hovering over the column header the question crashes.

### Expected behavior

Hovering over the column headers should show the column metadata.

![grafik](https://github.com/user-attachments/assets/494bee77-7561-487c-9e48-1b86f28b28ce)


### Logs

frontend log - the error appears to be here
```
TypeError: e.toFixed is not a function
    T NumberFingerprint.tsx:56
    D NumberFingerprint.tsx:21
    React 7
    unstable_runWithPriority scheduler.production.min.js:18
    React 5
    onOpen DelayGroup.tsx:44
    y Popover.tsx:46
    s use-disclosure.js:9
    React 2
    s use-disclosure.js:7
    setTimeout handler*openDropdown use-delayed-hover.js:15
    r create-event-handler.js:4
    React 11
    unstable_runWithPriority scheduler.production.min.js:18
    React 9
    f5 app.js:68
    f2 app.js:99
    45600 app-main.js:24
    Webpack 6
 
Object { componentStack: ""\nD@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:28:11574\nN@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:28:12608\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\nL@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:28:13754\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n21761/g<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:104000\nd@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:144281\nx@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:356487\ndiv\ng@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:255104\nw@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:256160\nZ@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:249565\ntf@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:119:478545\ny@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:154136\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\n84976/i/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:451671\nen@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:252000\n84976/i/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:451671\nB@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:155975\nh@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:28:18037\na@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:246:62920\ndiv\n21761/g<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:104000\nb@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:83:325047\ng@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:83:320089\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\ndiv\nt@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:125:36922\ndiv\n21761/g<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:104000\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\nt@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:125:124022\ntI@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:119:480406\nfy@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:246:24613\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\na@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:21:29151\n79576/fj</fj@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:246:41972\nfA@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:246:47697\ndiv\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ns@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:7:128559\neY@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:119:527665\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\na@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:21:29151\nHr@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:193:135242\ndiv\ndiv\nHa@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:193:137551\ndiv\ndiv\nV8@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:196:1400\na@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:21:29151\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\nmain\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\nenV@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:215:25378\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\na@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:21:29151\n45600/enG<@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:215:34343\n45600/Bg/</<@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:193:77475\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:186456\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:186456\nn@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:185245\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\nb@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:167292\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:169239\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:173511\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\nConnect(Favicon)\nh@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:21:49493\nb@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:167292\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:169239\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:173511\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\nConnect(Favicon)\n45600/edl<@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:228:13550\ni@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:139:13331\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\ni@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:139:13331\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\nmain\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\ndiv\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\n77466/t.KBarProvider@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:76:232414\nc6@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:127:83592\nwithRouter(c6)\ns@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:7:128559\n45600/p6<@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:127:159185\nc@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:106:5990\n@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:32:186456\nRouterContext\nRouter\nd@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:419457\ntZ@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:119:479228\nh@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:63004\n$@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:434369\n10/u/<@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:7:62661\n7138/t.DragDropContextProvider@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:83:176867\ntW@http://localhost:3000/app/dist/app-main.9fae825abe7ec0b12735.js:228:53554\nN@http://localhost:3000/app/dist/vendor.78be941a71c4863ea2f6.js:110:468"" }
console.js:13:4
```

server-log - no error here
```
[4482d035-bba0-4597-905a-9d4ae730d5ec] 2024-08-07T14:42:58+02:00 DEBUG metabase.server.middleware.log GET /api/alert/question/30 200 2.2 ms (1 DB calls) App DB connections: 0/7 Jetty threads: 5/50 (7 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
[4482d035-bba0-4597-905a-9d4ae730d5ec] 2024-08-07T14:42:58+02:00 DEBUG metabase.server.middleware.log GET /api/card/30/query_metadata 200 84.4 ms (21 DB calls) App DB connections: 0/7 Jetty threads: 5/50 (7 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
[4482d035-bba0-4597-905a-9d4ae730d5ec] 2024-08-07T14:42:59+02:00 DEBUG metabase.server.middleware.log POST /api/card/30/query 202 [ASYNC: completed] 63.1 ms (22 DB calls) App DB connections: 0/7 Jetty threads: 4/50 (7 idle, 0 queued) (93 total active threads) Queries in flight: 0 (0 queued); oracle DB 4 connections: 0/1 (0 threads blocked) {:metabase-user-id 1}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""de"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.19.128-microsoft-standard"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""oracle""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-30"",
      ""tag"": ""v0.50.18"",
      ""hash"": ""c323ffc""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

The issue is blocking some of our users. A workaround exits using a (wrong) text-type for column metadata.

### Additional context

Error only seen using an Oracle database. When testing with version v0.49.13 everything worked fine.",maximilian-zollbrecht,2024-08-07 12:52:18+00:00,['romeovs'],2024-08-07 16:29:29+00:00,2024-08-07 15:53:21+00:00,https://github.com/metabase/metabase/issues/46574,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2453312276,issue,closed,completed,Dashboard parameter dropdown does not apply background color theming in the embedding sdk,"When using the following theme options, the dashboard parameter dropdown does not take into account the background color (`colors.background`) - so it's taking a white background color instead of the themed dark color.

```ts
    colors: {
      brand: '#509EE3',
      filter: '#7172AD',
      border: '#5A5F6B',
      background: '#2D353A',
      'background-hover': '#2D353A',
      positive: '#84BB4C',
      negative: '#ED6E6E',
    },
```

![Image](https://github.com/user-attachments/assets/33d51139-0fbc-40a3-8c6a-2b0e0f84ee1a)

PS. Looks like the text color is being followed correctly, but because the background is not set correctly, it looks broken:

```ts
      'text-primary': '#FFFFFF',
      'text-secondary': '#FFFFFF',
      'text-tertiary': '#FFFFFF',
```

![Image](https://github.com/user-attachments/assets/ca694901-0b4d-4aed-905d-765d5cc5d514)

",heypoom,2024-08-07 12:02:28+00:00,[],2024-09-05 08:14:19+00:00,2024-09-05 07:45:59+00:00,https://github.com/metabase/metabase/issues/46572,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2330837186, 'issue_id': 2453312276, 'author': 'heypoom', 'body': 'Already fixed as of [SDK v0.1.33](https://www.npmjs.com/package/@metabase/embedding-sdk-react).', 'created_at': datetime.datetime(2024, 9, 5, 7, 45, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330891240, 'issue_id': 2453312276, 'author': 'heypoom', 'body': 'The dropdown looks correct as of v0.1.33\n\n![Image](https://github.com/user-attachments/assets/8a242152-c682-41cd-b673-fb3103efaaa1)', 'created_at': datetime.datetime(2024, 9, 5, 8, 13, 56, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-09-05 07:45:59 UTC): Already fixed as of [SDK v0.1.33](https://www.npmjs.com/package/@metabase/embedding-sdk-react).

heypoom (Issue Creator) on (2024-09-05 08:13:56 UTC): The dropdown looks correct as of v0.1.33

![Image](https://github.com/user-attachments/assets/8a242152-c682-41cd-b673-fb3103efaaa1)

"
2453256508,issue,closed,completed,Clearing a dashboard filter closes the entire browser tab,"### Describe the bug

Clearing a dashboard filter closes the entire browser tab. This applies only to dashboards (questions seem unaffected). From basic testing, issue appears to be isolated to Chrome Browser (Windows and Mac at least). 

### To Reproduce

1. Go to any dashboard with an applied filter.
2. Click on the 'X' icon in the filter box to clear it.
3. See that the browser tab completely closes down.


### Expected behavior

Filter box should be cleared/reset as per the expected behaviour, and the browser tab should not be closed.

### Logs

No browser logs unfortunately as the closing of the tab means we lose that information from Chrome Devtools.

### Information about your Metabase installation

```JSON
Chrome 127.0.6533.89
{""arch"":""arm64"",""os"":""mac""}

Mac OS X: 14.6.0

Metabase version: v0.50.19
Metabase hosting environment: AWS ECS
Metabase DB: Amazon Aurora
```


### Severity

Annoying, but can work around it.

### Additional context

_No response_",cgddrd-gardin,2024-08-07 11:32:14+00:00,['alxnddr'],2024-08-13 19:52:40+00:00,2024-08-13 19:52:40+00:00,https://github.com/metabase/metabase/issues/46570,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2273269604, 'issue_id': 2453256508, 'author': 'paoliniluis', 'body': 'Please post a video', 'created_at': datetime.datetime(2024, 8, 7, 11, 40, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273471129, 'issue_id': 2453256508, 'author': 'npfitz', 'body': ""@cgddrd-gardin I'm not able to reproduce locally, but it's possible there could be a bug specific to the settings your dashboard is using. As @paoliniluis mentioned, a video would be very helpful, along with any other details like what kind of filter you're clearing, and what kinds of questions are in the dashboard"", 'created_at': datetime.datetime(2024, 8, 7, 13, 25, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273884971, 'issue_id': 2453256508, 'author': 'kochalex', 'body': ""We are seeing this as well, however FWIW I only personally see it on Arc (a chrome based browser) but not Chrome proper.\r\n\r\nHere's a potentially useful log from Chrome's console after clicking the X for the filter:\r\n\r\n```\r\nParameterValueWidget.jsx:158 Scripts may close only the windows that were opened by them.\r\nonClick @ ParameterValueWidget.jsx:158\r\n\r\n```"", 'created_at': datetime.datetime(2024, 8, 7, 16, 41, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273923265, 'issue_id': 2453256508, 'author': 'cgddrd-gardin', 'body': ""Thanks for your responses @paoliniluis, @npfitz - I'll sorting out a video for you, weirdly having closed my Chrome browser and reopening it on my Mac, the problem isn't happening now, but it is still happening for a colleague running MS Edge on Windows 11. \r\n\r\nI don't want to waste anyone's time so let me get to a point where I can (hopefully) reliably reproduce this (I thought I could before) and will come back to you shortly."", 'created_at': datetime.datetime(2024, 8, 7, 17, 3, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2275809718, 'issue_id': 2453256508, 'author': 'TLazarevic', 'body': ""Just encountered the issue 4 times, on 2 different dashboards. Clearing the selected date filter option closed the whole browser tab. The behavior just stopped as I was trying to take a recording.\r\n\r\nBrowser: Firefox 128.0.3 (64-bit)\r\nMetabase: v0.50.19.1\r\nOS: macOS 14.5\r\n\r\nNot much to record though, the 'last 30 days' date range filter was selected, and while a dashboard was loading, clicking on 'x' to clear the filter closed the tab. The behavior continued, and now I cannot reproduce."", 'created_at': datetime.datetime(2024, 8, 8, 13, 20, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277855204, 'issue_id': 2453256508, 'author': 'cheyuriy', 'body': 'Same problem with several dashboards.\r\n\r\nIt\'s closed by this call to `close()` inside onClick handler:\r\n<img width=""1512"" alt=""Screenshot 2024-08-09 at 10 03 50"" src=""https://github.com/user-attachments/assets/14d4ca40-2ee3-4a47-9a2a-972a3fdb7e7c"">\r\n\r\nAnd in dashboards which are not closing in the same case, `close()` is marked with a warning that ""Scripts may close only the windows that were opened by them"":\r\n<img width=""258"" alt=""Screenshot 2024-08-09 at 10 04 46"" src=""https://github.com/user-attachments/assets/8b1c62a4-14e5-45eb-ac1d-758d510157e6"">', 'created_at': datetime.datetime(2024, 8, 9, 12, 39, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277968504, 'issue_id': 2453256508, 'author': 'cheyuriy', 'body': ""Also found out that it's related to the way you open a dashboard. If it was direct URL, then this issue appears. However if I open it from navigation/search, or just switch tabs in dashboard (in other words, anything that changes URL in browser programmatically), then everything works fine."", 'created_at': datetime.datetime(2024, 8, 9, 13, 39, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278003935, 'issue_id': 2453256508, 'author': 'cgddrd-gardin', 'body': ""> Also found out that it's related to the way you open a dashboard. If it was direct URL, then this issue appears. However if I open it from navigation/search, or just switch tabs in dashboard (in other words, anything that changes URL in browser programmatically), then everything works fine.\r\n\r\nGreat find @cheyuriy!\r\n\r\nConfirming this behaviour with below video @npfitz, @paoliniluis. First tab I navigate to dashboard from within Metabase. Second tab I jump straight to dashboard via URL. Issue occurs on Tab 2 only as mentioned.\r\n\r\nhttps://github.com/user-attachments/assets/0c205614-244f-415c-8f15-8fa5fc3224d1"", 'created_at': datetime.datetime(2024, 8, 9, 13, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284269343, 'issue_id': 2453256508, 'author': 'turbotankist', 'body': ""The same issue with v0.50.19. \r\nAnd doesn't exists in v0.50.18"", 'created_at': datetime.datetime(2024, 8, 12, 15, 21, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284328637, 'issue_id': 2453256508, 'author': 'paoliniluis', 'body': 'Prioritized, this is a core flow and many users are hitting this', 'created_at': datetime.datetime(2024, 8, 12, 15, 47, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284332666, 'issue_id': 2453256508, 'author': 'cgddrd-gardin', 'body': 'Thanks @paoliniluis!', 'created_at': datetime.datetime(2024, 8, 12, 15, 49, 6, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-07 11:40:34 UTC): Please post a video

npfitz on (2024-08-07 13:25:33 UTC): @cgddrd-gardin I'm not able to reproduce locally, but it's possible there could be a bug specific to the settings your dashboard is using. As @paoliniluis mentioned, a video would be very helpful, along with any other details like what kind of filter you're clearing, and what kinds of questions are in the dashboard

kochalex on (2024-08-07 16:41:47 UTC): We are seeing this as well, however FWIW I only personally see it on Arc (a chrome based browser) but not Chrome proper.

Here's a potentially useful log from Chrome's console after clicking the X for the filter:

```
ParameterValueWidget.jsx:158 Scripts may close only the windows that were opened by them.
onClick @ ParameterValueWidget.jsx:158

```

cgddrd-gardin (Issue Creator) on (2024-08-07 17:03:22 UTC): Thanks for your responses @paoliniluis, @npfitz - I'll sorting out a video for you, weirdly having closed my Chrome browser and reopening it on my Mac, the problem isn't happening now, but it is still happening for a colleague running MS Edge on Windows 11. 

I don't want to waste anyone's time so let me get to a point where I can (hopefully) reliably reproduce this (I thought I could before) and will come back to you shortly.

TLazarevic on (2024-08-08 13:20:25 UTC): Just encountered the issue 4 times, on 2 different dashboards. Clearing the selected date filter option closed the whole browser tab. The behavior just stopped as I was trying to take a recording.

Browser: Firefox 128.0.3 (64-bit)
Metabase: v0.50.19.1
OS: macOS 14.5

Not much to record though, the 'last 30 days' date range filter was selected, and while a dashboard was loading, clicking on 'x' to clear the filter closed the tab. The behavior continued, and now I cannot reproduce.

cheyuriy on (2024-08-09 12:39:53 UTC): Same problem with several dashboards.

It's closed by this call to `close()` inside onClick handler:
<img width=""1512"" alt=""Screenshot 2024-08-09 at 10 03 50"" src=""https://github.com/user-attachments/assets/14d4ca40-2ee3-4a47-9a2a-972a3fdb7e7c"">

And in dashboards which are not closing in the same case, `close()` is marked with a warning that ""Scripts may close only the windows that were opened by them"":
<img width=""258"" alt=""Screenshot 2024-08-09 at 10 04 46"" src=""https://github.com/user-attachments/assets/8b1c62a4-14e5-45eb-ac1d-758d510157e6"">

cheyuriy on (2024-08-09 13:39:01 UTC): Also found out that it's related to the way you open a dashboard. If it was direct URL, then this issue appears. However if I open it from navigation/search, or just switch tabs in dashboard (in other words, anything that changes URL in browser programmatically), then everything works fine.

cgddrd-gardin (Issue Creator) on (2024-08-09 13:55:43 UTC): Great find @cheyuriy!

Confirming this behaviour with below video @npfitz, @paoliniluis. First tab I navigate to dashboard from within Metabase. Second tab I jump straight to dashboard via URL. Issue occurs on Tab 2 only as mentioned.

https://github.com/user-attachments/assets/0c205614-244f-415c-8f15-8fa5fc3224d1

turbotankist on (2024-08-12 15:21:29 UTC): The same issue with v0.50.19. 
And doesn't exists in v0.50.18

paoliniluis on (2024-08-12 15:47:11 UTC): Prioritized, this is a core flow and many users are hitting this

cgddrd-gardin (Issue Creator) on (2024-08-12 15:49:06 UTC): Thanks @paoliniluis!

"
2453142063,issue,open,,Support maps in static viz,"**Is your feature request related to a problem? Please describe.**
As part of the recent subscription charts overhaul in v0.50, rendering was updated for some base charts. 
For map visualisation, subscriptions are still sent as table which is an unreadable and bad option. 
As part of an [older issue](https://github.com/metabase/metabase/issues/5493) it was decided to open separate issues for each visualisation type. I haven't found an open issue for maps, and I have confirmed they still don't work in v0.50.18 both on Slack and Email subscriptions, hence I am opening one.

**Describe the solution you'd like**
I would like maps to be rendered in the dashboard subscriptions the same as they are on Metabase UI.

**Describe alternatives you've considered**
Sending the results as bar charts for region maps, for pin maps, not sure.

**How important is this feature to you?**
The importance varies. Currently, it is important for my use case.
",TLazarevic,2024-08-07 10:30:15+00:00,[],2025-02-04 20:31:56+00:00,,https://github.com/metabase/metabase/issues/46567,"[('Type:New Feature', ''), ('Visualization/Maps', ''), ('Visualization/Static', 'Subscriptions/pulse generated image')]",[],
2453097882,issue,closed,completed,API - Searching for archived card with pagination doesn't work,"### Describe the bug

When i ask the API for archived cards, I only get the first 2000 results (always the same so), with this 

```https://***.metabaseapp.com/api/card?f=archived```

But i know that i have more than 2000 cards archived. So i wanted to get next page of results or full result maybe (like with json card query). But nothing seems to work.
I've tried requests like this one:

```https://***.metabaseapp.com/api/card?f=archived&offset=2000```
or
```https://***.metabaseapp.com/api/card?f=archived&offset=2000&limit=1000```
Both not working

### To Reproduce

1. Have more than 2000 questions archived
2. Use your API keys to request your archived questions
3. try to access to the 2001+ questions archived

### Expected behavior

Maybe be query filter are not limit & offset. Nothing in doc or wasn't able to find how pagination works.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Cloud version
```


### Severity

very annoying

### Additional context

I use this to know wich questions i can automatically force cache refresh. Without correct & complete results, i can't do my work correctly",MathRobin,2024-08-07 10:08:06+00:00,[],2024-08-26 21:56:04+00:00,2024-08-23 13:25:21+00:00,https://github.com/metabase/metabase/issues/46564,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2273538560, 'issue_id': 2453097882, 'author': 'dpsutton', 'body': 'On a recent master, I see\r\n\r\n```shell\r\n❯ http get ""localhost:3000/api/card?f=archived"" x-api-key:$API_KEY -pb  | jq \'length\'\r\n3108\r\n```\r\n\r\nOn 0.49.15,\r\n\r\n```shell\r\n❯ http get \'localhost:3049/api/card?f=archived\' x-api-key:$API_KEY -pb | jq \'length\'\r\n3000\r\n```\r\n\r\nChecking on 0.50.17:\r\n\r\n```shell\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$API_KEY -pb | jq \'length\'\r\n3000\r\n```\r\n\r\nI""m not sure I\'m able to reproduce.\r\n\r\n(if the 3,000 number looks suspicious, i just created that many in a fresh 49 instance and then upgraded to 50)\r\n```clojure\r\ncard=> (let [coll (t2/insert-returning-instance! :model/Collection {:name ""lots-of-archived-cards""})]\r\n         (t2/insert! :model/Card (repeatedly 3000 (fn [] {:name (str (gensym ""archived-card""))\r\n                                                          :dataset_query {}\r\n                                                          :collection_id (:id coll)\r\n                                                          :archived true\r\n                                                          :database_id 1\r\n                                                          :display :table\r\n                                                          :visualization_settings {}\r\n                                                          :creator_id 1}))))\r\n3000\r\n```\r\n\r\nIn the version based on master, was a local dev instance with some other cruft in it which is why count is 3108.\r\n\r\nEDIT:\r\nAnd just to make sure non-admins didn\'t have some other restriction, I added a non-admin key in the ""all users"" group and see\r\n\r\n```shell\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$NON_ADMIN_API_KEY -pb | jq \'length\'\r\n3000\r\n```', 'created_at': datetime.datetime(2024, 8, 7, 13, 55, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284168815, 'issue_id': 2453097882, 'author': 'MathRobin', 'body': ""@dpsutton maybe i'm wrong, maybe i misunderstood your answer. For me, you're talking about counting hits possible, not the real results.\r\nImagine limit is not 2000 but 2 (for our readability). Your full table is :\r\n```\r\nA\r\nB\r\nC\r\nD\r\nE\r\n```\r\nWith the current API call, i will get :\r\n\r\n- without any param\r\n```\r\nA\r\nB\r\n```\r\n- with any other param combination inside (count, limit, offset, page...)\r\n```\r\nA\r\nB\r\n```\r\nsame result, yes.\r\nMy hope was to get this when \r\n```\r\napi/card?f=archived&offset=2&limit=2\r\nC\r\nD\r\n```"", 'created_at': datetime.datetime(2024, 8, 12, 14, 39, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296952821, 'issue_id': 2453097882, 'author': 'dpsutton', 'body': '@MathRobin I\'m pushing back on your original complaint.\r\n\r\n> When i ask the API for archived cards, I only get the first 2000 results (always the same so), with this\r\n\r\nI demonstrate that this is false. I get 3000 results back and do not see any limit. \r\n\r\n> For me, you\'re talking about counting hits possible, not the real results. The api is sending back 3000 archived cards.\r\n\r\nI\'m using `jq` to count the number of ""real results"" that come back.\r\n\r\nTo your original repro:\r\n\r\n> To Reproduce\r\n>    Have more than 2000 questions archived\r\n>    Use your API keys to request your archived questions\r\n>    try to access to the 2001+ questions archived\r\n\r\nI piped 3000 cards through `jq` and counted them.\r\n\r\nNote here\r\n\r\n```\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$API_KEY | jq \'length\'\r\n3000\r\n```\r\nIs getting all 3000 archived cards back from the api\r\n\r\nHere\'s the last one, using `jq \'.[-1]\'`\r\n\r\n```\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$API_KEY | jq \'.[-1]\'\r\n{\r\n  ""cache_invalidated_at"": null,\r\n  ""description"": null,\r\n  ""archived"": true,\r\n  ""view_count"": 0,\r\n  ""collection_position"": null,\r\n  ""table_id"": null,\r\n  ""result_metadata"": null,\r\n  ""creator"": {\r\n    ""email"": ""dan@metabase.com"",\r\n    ""first_name"": ""dan"",\r\n    ""last_login"": ""2024-08-19T11:07:02.960006-05:00"",\r\n    ""is_qbnewb"": true,\r\n    ""is_superuser"": true,\r\n    ""id"": 1,\r\n    ""last_name"": ""sutton"",\r\n    ""date_joined"": ""2024-08-19T11:07:02.849951-05:00"",\r\n    ""common_name"": ""dan sutton""\r\n  },\r\n  ""initially_published_at"": null,\r\n  ""database_id"": 1,\r\n  ""enable_embedding"": false,\r\n  ""collection_id"": 3,\r\n  ""query_type"": null,\r\n  ""name"": ""archived-card4302"",\r\n  ""last_used_at"": null,\r\n  ""type"": ""question"",\r\n  ""creator_id"": 1,\r\n  ""updated_at"": ""2024-08-19T11:08:32.451865-05:00"",\r\n  ""made_public_by_id"": null,\r\n  ""embedding_params"": null,\r\n  ""cache_ttl"": null,\r\n  ""dataset_query"": {},\r\n  ""id"": 3026,\r\n  ""parameter_mappings"": [],\r\n  ""display"": ""table"",\r\n  ""entity_id"": ""N8k6V_IFTDk_yJt2b_SAM"",\r\n  ""collection_preview"": true,\r\n  ""visualization_settings"": {},\r\n  ""collection"": {\r\n    ""authority_level"": null,\r\n    ""description"": null,\r\n    ""archived"": false,\r\n    ""slug"": ""lots_of_archived_cards"",\r\n    ""name"": ""lots-of-archived-cards"",\r\n    ""personal_owner_id"": null,\r\n    ""type"": null,\r\n    ""is_sample"": false,\r\n    ""id"": 3,\r\n    ""entity_id"": ""Z7mBS2qDfqLw9tagqOw0L"",\r\n    ""location"": ""/"",\r\n    ""namespace"": null,\r\n    ""created_at"": ""2024-08-19T11:08:30.711111-05:00""\r\n  },\r\n  ""metabase_version"": ""v0.50.19 (0b97bf8)"",\r\n  ""parameters"": [],\r\n  ""created_at"": ""2024-08-19T11:08:32.451865-05:00"",\r\n  ""public_uuid"": null\r\n}\r\n```\r\n\r\n\r\n```\r\n# I\'m getting 3,880,955 characters back from the API\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$API_KEY  | wc\r\n       0    6001 3880955\r\n\r\n# pretty print it with `jq` and it\'s 177,000 lines!\r\n❯ http get \'localhost:3050/api/card?f=archived\' x-api-key:$API_KEY  |jq |  wc -l\r\n  177002\r\n```\r\n\r\nI think all of this demonstrates that I\'m getting _all_ cards back from the endpoint\r\n\r\n```\r\nWhen i ask the API for archived cards, I only get the first 2000 results (always the same so), with this\r\n\r\nhttps://***.metabaseapp.com/api/card?f=archived\r\n```\r\nSo I believe that this is false.\r\n\r\nThe API is not paginated at all. There is no expectation to get the second page because you get all cards. I\'m not sure why you are seeing only 2,000 results but it doesn\'t seem to be the standard behavior for Metabase.', 'created_at': datetime.datetime(2024, 8, 19, 16, 17, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297408716, 'issue_id': 2453097882, 'author': 'paoliniluis', 'body': 'I just did a test:\r\n1) archived all the questions\r\n![image](https://github.com/user-attachments/assets/62ba2fdb-bbee-460f-b49a-c131d8de0a1f)\r\n\r\n2) hit the endpoint and sent it to a json file\r\n![image](https://github.com/user-attachments/assets/b1ca2d08-2923-48a0-840c-ec4443c98023)\r\n\r\n3) counted how many ""result_ metadata"" keys I got\r\n![image](https://github.com/user-attachments/assets/fda64368-415e-43c6-b9c4-09e381095414)\r\n\r\n\r\ntl,dr; we\'re not paginating the results of this endpoint unless you\'re using anything in the middle\r\n\r\np.s. tested with 50.20.3', 'created_at': datetime.datetime(2024, 8, 19, 20, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307091841, 'issue_id': 2453097882, 'author': 'dpsutton', 'body': 'Closing this as it seems we provide all cards and there is no expectation to paginate at the moment.', 'created_at': datetime.datetime(2024, 8, 23, 13, 25, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307733272, 'issue_id': 2453097882, 'author': 'MathRobin', 'body': ""Are hou kidding me ? I've more than 3k questions archived. And i confirm that pagination should be there."", 'created_at': datetime.datetime(2024, 8, 23, 20, 1, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307735666, 'issue_id': 2453097882, 'author': 'MathRobin', 'body': 'I dont understand how as database query tool, you can say ""no pagination need"". It\'s the first useful thing when querying results', 'created_at': datetime.datetime(2024, 8, 23, 20, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310234869, 'issue_id': 2453097882, 'author': 'dpsutton', 'body': '@MathRobin I\'m confused by your response. We send all cards in the response. I\'ve demonstrated that above. Thus at the moment there is no need for pagination to see all results because all results are sent over. \r\n\r\nI\'m demonstrating here that I\'m able to get all 6,640 archived cards in a cloud hosted instance of Metabase.\r\n\r\n```shell\r\n❯ http get ""$CLOUD_HOST/api/card?f=archived"" x-api-key:$API_KEY -pb | jq \'length\'\r\n6640\r\n```\r\n\r\nWe seem to be talking past each other here. I\'ve show that I\'m able to get all archived cards both in the cloud and locally hosted.\r\n\r\nIt seems for some reason you are unable to get all of your archived cards. I don\'t know why this is the case but it is not the design or implementation of Metabase to paginate these results at the moment. I do not understand why you are not seeing every archived card in your instance.\r\n\r\nVerifying against a 49.10 jar I also see similarly:\r\n\r\n```\r\n# created 3015 archived cards in the app db\r\n# user=> (t2/count :model/Card :archived true) run from the repl\r\n# 3015\r\n\r\n❯ http get ""localhost:3049/api/card?f=archived"" x-api-key:$API_KEY -pb | jq \'length\'\r\n3015\r\n```\r\n\r\n\r\nAll of this is to say that I\'m unable to recreate your issue. I can retrieve _all_ archived cards from the `<HOST>/api/card?f=archived` endpoint. I do not know why you are seeing a 2,000 limit. It is not due to pagination though.\r\n\r\n\r\nEDIT:\r\n\r\nfrom the issue description:\r\n\r\n> When i ask the API for archived cards, I only get the first 2000 results (always the same so), with this\r\n\r\nCan I ask how you are consuming the results? How are you counting the results you get back? How are you using them? I wonder if there\'s a limit in some other tooling?', 'created_at': datetime.datetime(2024, 8, 26, 13, 35, 25, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-08-07 13:55:11 UTC): On a recent master, I see

```shell
❯ http get ""localhost:3000/api/card?f=archived"" x-api-key:$API_KEY -pb  | jq 'length'
3108
```

On 0.49.15,

```shell
❯ http get 'localhost:3049/api/card?f=archived' x-api-key:$API_KEY -pb | jq 'length'
3000
```

Checking on 0.50.17:

```shell
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$API_KEY -pb | jq 'length'
3000
```

I""m not sure I'm able to reproduce.

(if the 3,000 number looks suspicious, i just created that many in a fresh 49 instance and then upgraded to 50)
```clojure
card=> (let [coll (t2/insert-returning-instance! :model/Collection {:name ""lots-of-archived-cards""})]
         (t2/insert! :model/Card (repeatedly 3000 (fn [] {:name (str (gensym ""archived-card""))
                                                          :dataset_query {}
                                                          :collection_id (:id coll)
                                                          :archived true
                                                          :database_id 1
                                                          :display :table
                                                          :visualization_settings {}
                                                          :creator_id 1}))))
3000
```

In the version based on master, was a local dev instance with some other cruft in it which is why count is 3108.

EDIT:
And just to make sure non-admins didn't have some other restriction, I added a non-admin key in the ""all users"" group and see

```shell
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$NON_ADMIN_API_KEY -pb | jq 'length'
3000
```

MathRobin (Issue Creator) on (2024-08-12 14:39:37 UTC): @dpsutton maybe i'm wrong, maybe i misunderstood your answer. For me, you're talking about counting hits possible, not the real results.
Imagine limit is not 2000 but 2 (for our readability). Your full table is :
```
A
B
C
D
E
```
With the current API call, i will get :

- without any param
```
A
B
```
- with any other param combination inside (count, limit, offset, page...)
```
A
B
```
same result, yes.
My hope was to get this when 
```
api/card?f=archived&offset=2&limit=2
C
D
```

dpsutton on (2024-08-19 16:17:42 UTC): @MathRobin I'm pushing back on your original complaint.


I demonstrate that this is false. I get 3000 results back and do not see any limit. 


I'm using `jq` to count the number of ""real results"" that come back.

To your original repro:


I piped 3000 cards through `jq` and counted them.

Note here

```
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$API_KEY | jq 'length'
3000
```
Is getting all 3000 archived cards back from the api

Here's the last one, using `jq '.[-1]'`

```
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$API_KEY | jq '.[-1]'
{
  ""cache_invalidated_at"": null,
  ""description"": null,
  ""archived"": true,
  ""view_count"": 0,
  ""collection_position"": null,
  ""table_id"": null,
  ""result_metadata"": null,
  ""creator"": {
    ""email"": ""dan@metabase.com"",
    ""first_name"": ""dan"",
    ""last_login"": ""2024-08-19T11:07:02.960006-05:00"",
    ""is_qbnewb"": true,
    ""is_superuser"": true,
    ""id"": 1,
    ""last_name"": ""sutton"",
    ""date_joined"": ""2024-08-19T11:07:02.849951-05:00"",
    ""common_name"": ""dan sutton""
  },
  ""initially_published_at"": null,
  ""database_id"": 1,
  ""enable_embedding"": false,
  ""collection_id"": 3,
  ""query_type"": null,
  ""name"": ""archived-card4302"",
  ""last_used_at"": null,
  ""type"": ""question"",
  ""creator_id"": 1,
  ""updated_at"": ""2024-08-19T11:08:32.451865-05:00"",
  ""made_public_by_id"": null,
  ""embedding_params"": null,
  ""cache_ttl"": null,
  ""dataset_query"": {},
  ""id"": 3026,
  ""parameter_mappings"": [],
  ""display"": ""table"",
  ""entity_id"": ""N8k6V_IFTDk_yJt2b_SAM"",
  ""collection_preview"": true,
  ""visualization_settings"": {},
  ""collection"": {
    ""authority_level"": null,
    ""description"": null,
    ""archived"": false,
    ""slug"": ""lots_of_archived_cards"",
    ""name"": ""lots-of-archived-cards"",
    ""personal_owner_id"": null,
    ""type"": null,
    ""is_sample"": false,
    ""id"": 3,
    ""entity_id"": ""Z7mBS2qDfqLw9tagqOw0L"",
    ""location"": ""/"",
    ""namespace"": null,
    ""created_at"": ""2024-08-19T11:08:30.711111-05:00""
  },
  ""metabase_version"": ""v0.50.19 (0b97bf8)"",
  ""parameters"": [],
  ""created_at"": ""2024-08-19T11:08:32.451865-05:00"",
  ""public_uuid"": null
}
```


```
# I'm getting 3,880,955 characters back from the API
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$API_KEY  | wc
       0    6001 3880955

# pretty print it with `jq` and it's 177,000 lines!
❯ http get 'localhost:3050/api/card?f=archived' x-api-key:$API_KEY  |jq |  wc -l
  177002
```

I think all of this demonstrates that I'm getting _all_ cards back from the endpoint

```
When i ask the API for archived cards, I only get the first 2000 results (always the same so), with this

https://***.metabaseapp.com/api/card?f=archived
```
So I believe that this is false.

The API is not paginated at all. There is no expectation to get the second page because you get all cards. I'm not sure why you are seeing only 2,000 results but it doesn't seem to be the standard behavior for Metabase.

paoliniluis on (2024-08-19 20:37:54 UTC): I just did a test:
1) archived all the questions
![image](https://github.com/user-attachments/assets/62ba2fdb-bbee-460f-b49a-c131d8de0a1f)

2) hit the endpoint and sent it to a json file
![image](https://github.com/user-attachments/assets/b1ca2d08-2923-48a0-840c-ec4443c98023)

3) counted how many ""result_ metadata"" keys I got
![image](https://github.com/user-attachments/assets/fda64368-415e-43c6-b9c4-09e381095414)


tl,dr; we're not paginating the results of this endpoint unless you're using anything in the middle

p.s. tested with 50.20.3

dpsutton on (2024-08-23 13:25:21 UTC): Closing this as it seems we provide all cards and there is no expectation to paginate at the moment.

MathRobin (Issue Creator) on (2024-08-23 20:01:24 UTC): Are hou kidding me ? I've more than 3k questions archived. And i confirm that pagination should be there.

MathRobin (Issue Creator) on (2024-08-23 20:03:21 UTC): I dont understand how as database query tool, you can say ""no pagination need"". It's the first useful thing when querying results

dpsutton on (2024-08-26 13:35:25 UTC): @MathRobin I'm confused by your response. We send all cards in the response. I've demonstrated that above. Thus at the moment there is no need for pagination to see all results because all results are sent over. 

I'm demonstrating here that I'm able to get all 6,640 archived cards in a cloud hosted instance of Metabase.

```shell
❯ http get ""$CLOUD_HOST/api/card?f=archived"" x-api-key:$API_KEY -pb | jq 'length'
6640
```

We seem to be talking past each other here. I've show that I'm able to get all archived cards both in the cloud and locally hosted.

It seems for some reason you are unable to get all of your archived cards. I don't know why this is the case but it is not the design or implementation of Metabase to paginate these results at the moment. I do not understand why you are not seeing every archived card in your instance.

Verifying against a 49.10 jar I also see similarly:

```
# created 3015 archived cards in the app db
# user=> (t2/count :model/Card :archived true) run from the repl
# 3015

❯ http get ""localhost:3049/api/card?f=archived"" x-api-key:$API_KEY -pb | jq 'length'
3015
```


All of this is to say that I'm unable to recreate your issue. I can retrieve _all_ archived cards from the `<HOST>/api/card?f=archived` endpoint. I do not know why you are seeing a 2,000 limit. It is not due to pagination though.


EDIT:

from the issue description:


Can I ask how you are consuming the results? How are you counting the results you get back? How are you using them? I wonder if there's a limit in some other tooling?

"
2452838131,issue,closed,completed,Exports of Pivot Table contains pivot-grouping on version 0.50.15,"### Describe the bug

When downloading results from a pivot table (.csv, .xlsx or .json) the results are coming with a `pivot-grouping` column which is not available in the question. The results do not match what the question is displaying.

### To Reproduce

1. Go to any pivot table question in a dashboard or the question itself
2. Click on ""Download results"" (*if on dashboard*) or ""Download full results"" (*in the question*)
3. Select the download format (*.csv, .xlsx, or .json*) and download the results
4. Open the downloaded file, there will be a `pivot-grouping` column in it


### Expected behavior

Don't expose system data like pivot-grouping to users.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1026-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-23"",
      ""tag"": ""v0.50.15"",
      ""hash"": ""c6697cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",VictorOmondi1997,2024-08-07 08:02:41+00:00,[],2024-09-24 12:08:47+00:00,2024-09-17 19:26:32+00:00,https://github.com/metabase/metabase/issues/46561,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2283761749, 'issue_id': 2452838131, 'author': 'natashamathur', 'body': 'Hello! @cdeweyx @perivamsi Is there any update on this - could we get a timeline for when it will be looked into?', 'created_at': datetime.datetime(2024, 8, 12, 11, 51, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288577233, 'issue_id': 2452838131, 'author': 'perivamsi', 'body': ""@natashamathur sorry, we don't have a timeline yet. will keep you posted. what is your use case?"", 'created_at': datetime.datetime(2024, 8, 14, 12, 11, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288656422, 'issue_id': 2452838131, 'author': 'natashamathur', 'body': 'Our users use the CSV exports as inputs into a data pipeline and expect it to be consistent. Since this bug was introduced the data format is coming out with duplicates that are not present in the dashboard and also with additional columns.', 'created_at': datetime.datetime(2024, 8, 14, 12, 50, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2327881066, 'issue_id': 2452838131, 'author': 'tm-anndee-atendido', 'body': 'Hello, also encountering this issue. Can we have an explanation what the `pivot-grouping` column is (i.e. what do these values represent) so that our team may implement an appropriate workaround while the issue is being fixed.', 'created_at': datetime.datetime(2024, 9, 4, 4, 18, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2340782933, 'issue_id': 2452838131, 'author': 'Tony-metabase', 'body': 'Increasing the priority since it\'s not just about the pivot grouping column anymore but the download is adding duplicate rows. Making the result very confusing. In the below example the pivot grouping 2 is the addition of the first two in group 0\r\n\r\n<img width=""575"" alt=""image"" src=""https://github.com/user-attachments/assets/82c717a2-5391-4c0b-80da-bf16fdd2b027"">\r\n\r\nSo if you don\'t know about the problem and decide to add them in csv the amounts don\'t match', 'created_at': datetime.datetime(2024, 9, 10, 13, 26, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341269657, 'issue_id': 2452838131, 'author': 'adam-james-v', 'body': ""I'll work on a fix for this.\n\nIn the meantime, an explanation for what the pivot-grouping column is:\nIt denotes where the particular row's data is meant to end up. To use the data effectively, you will want to only look at rows with pivot-grouping = 0, these rows will be equivalent to the output of your question if you change the viz to a regular table.\n\nPivot-grouping numbers > 0 are indicative of a sub-total of some kind, perhaps for a subtotal in a particular row group, or a column total, or even the grand total. \n\nThese rows should be filtered out if you wish to do some aggregating on your own."", 'created_at': datetime.datetime(2024, 9, 10, 15, 31, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2353467487, 'issue_id': 2452838131, 'author': 'paoliniluis', 'body': '@adam-james-v the subscriptions are also rendering really bad due to this, e.g.\r\n![image](https://github.com/user-attachments/assets/9d05d987-aeed-48dd-9dc3-489d3114d293)\r\n\r\nwill your fixes also fix subscriptions?', 'created_at': datetime.datetime(2024, 9, 16, 17, 8, 19, tzinfo=datetime.timezone.utc)}]","natashamathur on (2024-08-12 11:51:19 UTC): Hello! @cdeweyx @perivamsi Is there any update on this - could we get a timeline for when it will be looked into?

perivamsi on (2024-08-14 12:11:41 UTC): @natashamathur sorry, we don't have a timeline yet. will keep you posted. what is your use case?

natashamathur on (2024-08-14 12:50:47 UTC): Our users use the CSV exports as inputs into a data pipeline and expect it to be consistent. Since this bug was introduced the data format is coming out with duplicates that are not present in the dashboard and also with additional columns.

tm-anndee-atendido on (2024-09-04 04:18:27 UTC): Hello, also encountering this issue. Can we have an explanation what the `pivot-grouping` column is (i.e. what do these values represent) so that our team may implement an appropriate workaround while the issue is being fixed.

Tony-metabase on (2024-09-10 13:26:55 UTC): Increasing the priority since it's not just about the pivot grouping column anymore but the download is adding duplicate rows. Making the result very confusing. In the below example the pivot grouping 2 is the addition of the first two in group 0

<img width=""575"" alt=""image"" src=""https://github.com/user-attachments/assets/82c717a2-5391-4c0b-80da-bf16fdd2b027"">

So if you don't know about the problem and decide to add them in csv the amounts don't match

adam-james-v on (2024-09-10 15:31:53 UTC): I'll work on a fix for this.

In the meantime, an explanation for what the pivot-grouping column is:
It denotes where the particular row's data is meant to end up. To use the data effectively, you will want to only look at rows with pivot-grouping = 0, these rows will be equivalent to the output of your question if you change the viz to a regular table.

Pivot-grouping numbers > 0 are indicative of a sub-total of some kind, perhaps for a subtotal in a particular row group, or a column total, or even the grand total. 

These rows should be filtered out if you wish to do some aggregating on your own.

paoliniluis on (2024-09-16 17:08:19 UTC): @adam-james-v the subscriptions are also rendering really bad due to this, e.g.
![image](https://github.com/user-attachments/assets/9d05d987-aeed-48dd-9dc3-489d3114d293)

will your fixes also fix subscriptions?

"
2451831785,issue,closed,completed,Models with UUID Columns as Join Keys Generate Invalid SQL,"### Describe the bug

If you have two tables with UUID columns, create questions and promote them to models - you cannot join on the UUID columns in the models. The generated SQL is invalid.

### To Reproduce

1. Run a copy of Metabase v50
2. Generate some test tables in Postgres

```
CREATE TABLE test_parent
(
	name varchar(404),
	id uuid default gen_random_uuid (),
	PRIMARY KEY(id)
); 

CREATE TABLE test_child
(
	name varchar(100),
	id uuid default gen_random_uuid (),
	test_parent_id uuid  references test_parent(id),
	PRIMARY KEY(id)
); 
```

3. Create questions from each table
4. Promote them to models
5. From the Question builder, join the two questions
6. View the invalid SQL / attempt to run the Question to see the bad join:

`AS ""Test Child Model"" ON CAST(""source"".""id"" AS varchar) = ""Test Child Model"".""test_parent_id""`

https://www.loom.com/share/886dcef3a7a1475da0d681f55f814295

### Expected behavior

Valid SQL should be generated

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.18
```


### Severity

Blocking some users

### Additional context

This worked correctly in v49",ixipixi,2024-08-06 23:13:04+00:00,['snoe'],2024-08-28 02:09:03+00:00,2024-08-08 22:05:41+00:00,https://github.com/metabase/metabase/issues/46558,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2274120038, 'issue_id': 2451831785, 'author': 'snoe', 'body': 'Likely caused by https://github.com/metabase/metabase/pull/45575', 'created_at': datetime.datetime(2024, 8, 7, 18, 45, 52, tzinfo=datetime.timezone.utc)}]","snoe (Assginee) on (2024-08-07 18:45:52 UTC): Likely caused by https://github.com/metabase/metabase/pull/45575

"
2451755306,issue,closed,not_planned,QP - Allow multiple breakouts of the same column,,ranquild,2024-08-06 21:57:54+00:00,[],2024-08-06 22:29:27+00:00,2024-08-06 22:29:27+00:00,https://github.com/metabase/metabase/issues/46554,[],[],
2451755260,issue,closed,not_planned,Allow multiple breakouts of the same column,,ranquild,2024-08-06 21:57:50+00:00,[],2024-08-07 21:11:50+00:00,2024-08-07 21:11:50+00:00,https://github.com/metabase/metabase/issues/46553,[],[],
2451623917,issue,closed,completed,Metabase doesn't report correct heath status when additional databases added by config-file,"### Describe the bug

In case when data warehouses added using a [config file](https://www.metabase.com/docs/latest/configuring-metabase/config-file) Metabase reports non-ready state until it will finish indexing and fingerprinting all added databases:
```
2024-08-06 19:45:51,962 INFO analyze.fingerprint :: Fingerprinting 7 fields in table Table 26 ''upload_list_of_languages_by_total_number_of_speak_20240717175013''
2024-08-06 19:45:52,154 INFO sync.analyze :: fingerprint-fields Analyzed [***************···································] 😕   31% Table 27 ''upload_summer_olympic_medals_20240717175027''
2024-08-06 19:45:52,166 INFO analyze.fingerprint :: Fingerprinting 9 fields in table Table 27 ''upload_summer_olympic_medals_20240717175027''
2024-08-06 19:45:52,702 ERROR middleware.log :: GET /api/health 503 334.8 µs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.65}
```
The problem here is that it can take a significant amount of time which can cause a timeout for health check watcher. 
Metadata extraction and fingerprinting starts right after a driver loading.
If several types of DBs added - the process will start after loading of each driver.

### To Reproduce

1. Launch metabase with a [config file](https://www.metabase.com/docs/latest/configuring-metabase/config-file) which contains additional DBs.
2. Start Metabase.
3. During starting call `/api/health`.
4. Metabase will return 503 until it will finish indexing of additional DBs.

### Expected behavior

_No response_

### Logs

2024-08-06 19:44:41,141 INFO advanced-config.file :: Initializing :users from config file... 🗄️
2024-08-06 19:44:41,170 INFO file.users :: Creating the first User for this instance. The first user is always created as an admin.
2024-08-06 19:44:41,171 INFO file.users :: Creating new User ""Metabase CI"" with email ""test@test.com""
2024-08-06 19:44:41,306 INFO driver.impl :: Initializing driver :sql...
2024-08-06 19:44:41,306 INFO driver.impl :: Initializing driver :sql-jdbc...
2024-08-06 19:44:41,307 INFO driver.impl :: Initializing driver :postgres...
2024-08-06 19:44:41,358 INFO models.user :: Setting User 1's last_acknowledged_version to v1.50.19, the current version
2024-08-06 19:44:41,431 INFO models.user :: Adding User 1 to All Users permissions group...
2024-08-06 19:44:41,431 INFO models.user :: Adding User 1 to All Users permissions group...
2024-08-06 19:44:41,452 INFO advanced-config.file :: Initializing :databases from config file... 🗄️
2024-08-06 19:44:41,503 INFO file.databases :: Creating new postgres Database ""DB1""
2024-08-06 19:44:41,879 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""DB1"" has been enabled with schedule: ""0 27 * * * ? *""
2024-08-06 19:44:41,880 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""DB1"" has been enabled with schedule: ""0 0 10 * * ? *""
2024-08-06 19:44:41,894 INFO sync.util :: STARTING: Sync postgres Database 2 ''DB1''
2024-08-06 19:44:41,897 INFO sync.util :: STARTING: Sync metadata for postgres Database 2 ''DB1''
2024-08-06 19:44:42,177 INFO sync.util :: STARTING: step ''sync-dbms-version'' for postgres Database 2 ''DB1''
2024-08-06 19:44:42,284 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""DB1"" has been enabled with schedule: ""0 27 * * * ? *""
2024-08-06 19:44:42,285 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""DB1"" has been enabled with schedule: ""0 0 10 * * ? *""
2024-08-06 19:44:42,323 INFO sync.util :: FINISHED: step ''sync-dbms-version'' for postgres Database 2 ''DB1'' (145.6 ms)
2024-08-06 19:44:42,324 INFO sync.util :: STARTING: step ''sync-timezone'' for postgres Database 2 ''DB1''
2024-08-06 19:44:42,350 INFO sync-metadata.sync-timezone :: :postgres database 2 default timezone is ""GMT""
2024-08-06 19:44:42,392 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""DB1"" has been enabled with schedule: ""0 27 * * * ? *""
2024-08-06 19:44:42,393 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""DB1"" has been enabled with schedule: ""0 0 10 * * ? *""
2024-08-06 19:44:42,410 INFO sync.util :: FINISHED: step ''sync-timezone'' for postgres Database 2 ''DB1'' (85.7 ms)
2024-08-06 19:44:42,412 INFO sync.util :: STARTING: step ''sync-tables'' for postgres Database 2 ''DB1''
2024-08-06 19:44:42,473 INFO sync-metadata.tables :: Found new table: Table  ''bookings.ticket_flights''
2024-08-06 19:44:42,475 INFO sync-metadata.tables :: Found new table: Table  ''bookings.tickets''
2024-08-06 19:44:42,475 INFO sync-metadata.tables :: Found new table: Table  ''bookings.routes''
2024-08-06 19:44:42,475 INFO sync-metadata.tables :: Found new table: Table  ''bookings.aircrafts''
2024-08-06 19:44:42,476 INFO sync-metadata.tables :: Found new table: Table  ''bookings.boarding_passes''
2024-08-06 19:44:42,476 INFO sync-metadata.tables :: Found new table: Table  ''bookings.aircrafts_data''
2024-08-06 19:44:42,476 INFO sync-metadata.tables :: Found new table: Table  ''bookings.flights''
2024-08-06 19:44:42,476 INFO sync-metadata.tables :: Found new table: Table  ''bookings.flights_v''
2024-08-06 19:44:42,477 INFO sync-metadata.tables :: Found new table: Table  ''bookings.airports''
2024-08-06 19:44:42,477 INFO sync-metadata.tables :: Found new table: Table  ''bookings.airports_data''
2024-08-06 19:44:42,477 INFO sync-metadata.tables :: Found new table: Table  ''bookings.seats''
2024-08-06 19:44:42,477 INFO sync-metadata.tables :: Found new table: Table  ''bookings.bookings''
2024-08-06 19:44:42,704 ERROR middleware.log :: GET /api/health 503 773.2 µs (0 DB calls) {:metabase-user-id nil}
{:status ""initializing"", :progress 0.65}
.......
024-08-06 19:45:49,349 INFO sync.util :: FINISHED: Sync postgres Database 3 ''Postgres'' (18.7 s)
2024-08-06 19:45:49,353 INFO driver.impl :: Initializing driver :mysql...
2024-08-06 19:45:49,511 INFO file.databases :: Creating new mysql Database ""MySQL""
2024-08-06 19:45:49,639 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""MySQL"" has been enabled with schedule: ""0 11 * * * ? *""
2024-08-06 19:45:49,640 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""MySQL"" has been enabled with schedule: ""0 0 11 * * ? *""
2024-08-06 19:45:49,648 INFO sync.util :: STARTING: Sync mysql Database 4 ''MySQL''
2024-08-06 19:45:49,650 INFO sync.util :: STARTING: Sync metadata for mysql Database 4 ''MySQL''
2024-08-06 19:45:49,760 INFO sync.util :: STARTING: step ''sync-dbms-version'' for mysql Database 4 ''MySQL''
2024-08-06 19:45:49,808 INFO task.sync-databases :: A trigger for ""Sync and Analyze"" of Database ""MySQL"" has been enabled with schedule: ""0 11 * * * ? *""
2024-08-06 19:45:49,809 INFO task.sync-databases :: A trigger for ""Scan Field Values"" of Database ""MySQL"" has been enabled with schedule: ""0 0 11 * * ? *""

### Information about your Metabase installation

```JSON
Metabase version - 0.50.19
```


### Severity

Annoying

### Additional context

_No response_",Onlinehead,2024-08-06 20:17:55+00:00,['noahmoss'],2024-10-02 17:31:57+00:00,2024-10-01 13:01:46+00:00,https://github.com/metabase/metabase/issues/46548,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2272078207, 'issue_id': 2451623917, 'author': 'paoliniluis', 'body': 'good find', 'created_at': datetime.datetime(2024, 8, 6, 20, 19, 35, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-06 20:19:35 UTC): good find

"
2451390384,issue,open,,Reset Dashboard Filters If Coming From a Custom Destination Click,"### Describe the bug

If I have opened a dashboard and chose some filters there in the past, and then after a while I appear on that dashboard after clicking from another dashboard it shows me a mix of what I had chosen before and what is set by click behavior. It is unlikely that the user wants to see both the new passed in filter in addition to whatever filter they were looking at the last time they were on that dashboard.

### To Reproduce

1. Create 2 dashboards, both with filters.
2. Change the click behavior of a column in the first dashboard to a custom destination that goes to the second dashboard and passes in a filter.
3. Go to the second dashboard and change a filter that won't be passed in.
4. Click on a column in the first dashboard that has the click behavior.
5. See a weird combination of filters in the second dashboard that you did not intend. 
https://www.loom.com/share/502b27ebf99949e88278dcfbb1bfbbca?sid=bc8f256e-0e3c-4934-96c8-f413077a3846 

### Expected behavior

I would expect the filters of the destination dashboard to reset in this case and I would only see the filter that were passed in from the first dashboard. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
on Stats
```


### Severity

not severe

### Additional context

_No response_",jessicaul,2024-08-06 17:40:46+00:00,[],2025-02-04 20:29:07+00:00,,https://github.com/metabase/metabase/issues/46541,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2476212151, 'issue_id': 2451390384, 'author': 'iamalexanderkim', 'body': ""Hi! Any updates on the issue? I've upgraded to 0.50.32 version and experience the similar bug. \nDashboard kinda remembers previously selected filters instead of using the default values. \n\nMoreover, for some reason whenever I open a dashboard it bugs out. It remembers old filters but even with old filters the dash should work. Once I reset filters, the dashboard works correctly"", 'created_at': datetime.datetime(2024, 11, 14, 12, 18, 27, tzinfo=datetime.timezone.utc)}]","iamalexanderkim on (2024-11-14 12:18:27 UTC): Hi! Any updates on the issue? I've upgraded to 0.50.32 version and experience the similar bug. 
Dashboard kinda remembers previously selected filters instead of using the default values. 

Moreover, for some reason whenever I open a dashboard it bugs out. It remembers old filters but even with old filters the dash should work. Once I reset filters, the dashboard works correctly

"
2451371147,issue,open,,Metabase should run field value scanning on Metabase analytics views,"### Describe the bug

[Slack context](https://metaboat.slack.com/archives/C04K1LEUPC5/p1722504740103779)

We disable fingerprinting and scanning on Metabase internal database views. We should run scan on these tables
https://github.com/metabase/metabase/blob/master/src/metabase/task/sync_databases.clj#L306
https://github.com/metabase/metabase/blob/master/src/metabase/task/sync_databases.clj#L163

### To Reproduce

In a Pro/EE instances:
- add a new database with a different name from other DBs
- go to Metabase analytics > Databases and try to filter by name
- The newly added database isn't there


### Expected behavior

We should scan for field values in the same cadence we do on other databases

### Logs

_No response_

### Information about your Metabase installation

```JSON
- v50.18
```


### Severity

P2

### Additional context

_No response_",luizarakaki,2024-08-06 17:28:32+00:00,[],2025-02-05 19:30:29+00:00,,https://github.com/metabase/metabase/issues/46540,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2271851755, 'issue_id': 2451371147, 'author': 'escherize', 'body': 'To fix this, instead of not scheduling any tasks [here](https://github.com/metabase/metabase/blob/master/src/metabase/task/sync_databases.clj#L306), we should schedule the `field-values-task-info` task, like so:\r\n\r\n```clojure\r\n    (update-db-trigger-if-needed! database field-values-task-info)\r\n```', 'created_at': datetime.datetime(2024, 8, 6, 18, 3, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354573232, 'issue_id': 2451371147, 'author': 'a78239636', 'body': '@escherize Hi, I would like to work on resolving this issue.', 'created_at': datetime.datetime(2024, 9, 17, 5, 40, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2368399716, 'issue_id': 2451371147, 'author': 'Tony-metabase', 'body': 'Another option here is to set all the field types to a search box instead of dropdown filter. So each time you click on the filter it will get the latest data. No need to perform scans', 'created_at': datetime.datetime(2024, 9, 23, 14, 13, 18, tzinfo=datetime.timezone.utc)}]","escherize on (2024-08-06 18:03:10 UTC): To fix this, instead of not scheduling any tasks [here](https://github.com/metabase/metabase/blob/master/src/metabase/task/sync_databases.clj#L306), we should schedule the `field-values-task-info` task, like so:

```clojure
    (update-db-trigger-if-needed! database field-values-task-info)
```

a78239636 on (2024-09-17 05:40:48 UTC): @escherize Hi, I would like to work on resolving this issue.

Tony-metabase on (2024-09-23 14:13:18 UTC): Another option here is to set all the field types to a search box instead of dropdown filter. So each time you click on the filter it will get the latest data. No need to perform scans

"
2451205327,issue,closed,completed,[Epic] Allow multiple breakouts of the same column,"Product doc https://www.notion.so/metabase/Allow-multiple-breakouts-of-the-same-column-9b6c5b715f8a4434b74501f13271be89

### Milestone 1 - support multiple breakouts without allowing them in the UI

Can be merged to master directly since we don't change the existing behavior until milestone 2.

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/46594
- [ ] https://github.com/metabase/metabase/pull/46555
- [ ] https://github.com/metabase/metabase/issues/46644
```

### Milestone 2 - allow multiple breakouts in the UI

Actually allow multiple columns in the notebook editor.

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/46776
- [ ] https://github.com/metabase/metabase/issues/46610
```

### Milestone 3 - MBQL lib bugs

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/47575
```
",ranquild,2024-08-06 15:48:30+00:00,['ranquild'],2024-09-06 18:19:35+00:00,2024-09-06 18:11:55+00:00,https://github.com/metabase/metabase/issues/46536,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2451198989,issue,open,,MongoDB Date Format not working in Excel but CSV,"### Describe the bug

Hello,

We have a MongoDB database that includes date values. When we export data from a question in Metabase to an XLSX file, Excel displays the date values in ISO format instead of as dates. However, the dates are correctly formatted when we export to CSV. We are using the latest version of Metabase (0.50.18).

![image](https://github.com/user-attachments/assets/af1506ce-3571-4834-992c-2adf9be5eac1)

### To Reproduce

1. Have a MongoDB with Date Values connected
2. Make a Question to get the Dates
3. Download the Result as XLSX

### Expected behavior

The Date values should format to a Date

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-117-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-30"",
      ""tag"": ""v0.50.18"",
      ""hash"": ""c323ffc""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying Bug

### Additional context

_No response_",domi-bue,2024-08-06 15:44:55+00:00,[],2025-02-04 20:31:54+00:00,,https://github.com/metabase/metabase/issues/46535,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Export', ''), ('.Backend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2302543512, 'issue_id': 2451198989, 'author': 'atonyma7', 'body': 'Did you ever find a solution for this besides manually editing all your questions with a custom date format?', 'created_at': datetime.datetime(2024, 8, 21, 16, 50, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304369297, 'issue_id': 2451198989, 'author': 'domi-bue', 'body': '> Did you ever find a solution for this besides manually editing all your questions with a custom date format?\r\n\r\nSadly not', 'created_at': datetime.datetime(2024, 8, 22, 10, 53, 28, tzinfo=datetime.timezone.utc)}]","atonyma7 on (2024-08-21 16:50:38 UTC): Did you ever find a solution for this besides manually editing all your questions with a custom date format?

domi-bue (Issue Creator) on (2024-08-22 10:53:28 UTC): Sadly not

"
2451073056,issue,closed,completed,"Auto select time-based breakout when none is set for ""compare to the past""",,romeovs,2024-08-06 14:44:30+00:00,[],2024-10-08 16:17:42+00:00,2024-08-14 08:25:23+00:00,https://github.com/metabase/metabase/issues/46532,[],[],
2451072721,issue,closed,completed,"Show ""compare to"" presets when the modal opens: Previous Month, Previous year, Custom... and edit breakout directly",,romeovs,2024-08-06 14:44:20+00:00,[],2024-10-08 16:16:57+00:00,2024-08-21 09:11:44+00:00,https://github.com/metabase/metabase/issues/46531,[],[],
2450970233,issue,closed,completed,FE - e2e - Cover custom click behavior with tests,,kamilmielnik,2024-08-06 14:00:24+00:00,['kamilmielnik'],2024-11-05 08:26:37+00:00,2024-11-05 08:26:36+00:00,https://github.com/metabase/metabase/issues/46528,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2456528059, 'issue_id': 2450970233, 'author': 'kamilmielnik', 'body': 'Closed by #48828', 'created_at': datetime.datetime(2024, 11, 5, 8, 26, 36, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-11-05 08:26:36 UTC): Closed by #48828

"
2450970077,issue,closed,completed,FE - e2e - Cover dashboard filters with tests,,kamilmielnik,2024-08-06 14:00:20+00:00,['kamilmielnik'],2024-09-02 08:58:17+00:00,2024-09-02 08:58:17+00:00,https://github.com/metabase/metabase/issues/46527,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2324195866, 'issue_id': 2450970077, 'author': 'kamilmielnik', 'body': 'Closed by #46958', 'created_at': datetime.datetime(2024, 9, 2, 8, 58, 17, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-09-02 08:58:17 UTC): Closed by #46958

"
2450952070,issue,closed,completed,FE - Cover Unit of Time in `getParameterColumns` with tests,Part of testing plan: https://github.com/metabase/metabase/issues/46520,kamilmielnik,2024-08-06 13:52:27+00:00,['kamilmielnik'],2024-08-08 14:32:32+00:00,2024-08-08 13:25:06+00:00,https://github.com/metabase/metabase/issues/46526,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2450736777,issue,closed,completed,Query builder notebook component in the embedding sdk is slow due to network request on every interaction,"The query builder `Notebook` component has become really slow when adding filters and summarizing. This is reproducible by going to the Shoppy app, going to the interactive question component, and adding new filters and summarization.

This could be potentially caused by the new loader functions used in the `useLoadQuestion` hook. The extracted functions is supposed to mirror what is there in the main app's redux actions. This might be caused by how the dependency comparison or caching didn't work as expected, so it's always submitting a network request rather than skipping some requests.

See video in https://metaboat.slack.com/files/U0511SKLXCN/F07F9BS3L87/cleanshot_2024-08-06_at_14.45.07.mp4

",heypoom,2024-08-06 12:15:07+00:00,['heypoom'],2024-10-08 16:17:35+00:00,2024-08-14 13:12:39+00:00,https://github.com/metabase/metabase/issues/46523,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2450723799,issue,closed,completed,FE - Allow to use in dashboard filters both pre- and post- last aggregation columns,"- the actual feature
- unit tests for `getParameterColumns`",kamilmielnik,2024-08-06 12:08:40+00:00,['kamilmielnik'],2024-08-23 07:52:27+00:00,2024-08-23 07:52:27+00:00,https://github.com/metabase/metabase/issues/46522,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2306506065, 'issue_id': 2450723799, 'author': 'kamilmielnik', 'body': 'Closed by #46670', 'created_at': datetime.datetime(2024, 8, 23, 7, 52, 27, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-08-23 07:52:27 UTC): Closed by #46670

"
2450715886,issue,closed,completed,Date picker's selected dates does not follow theming in embedding sdk,"The selected dates in the date picker component is using `#fff` instead of the correct colors from the theme. This can be seen when going to the Shoppy app, using theStitch's theme.

![Image](https://github.com/user-attachments/assets/102ad6ea-a6c5-47f8-b3ba-331edf055363)
",heypoom,2024-08-06 12:04:41+00:00,['WiNloSt'],2024-10-08 16:17:31+00:00,2024-08-14 15:27:50+00:00,https://github.com/metabase/metabase/issues/46521,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2450676114,issue,closed,completed,[Testing plan] Show columns from all stages in the dashboard filters,"Testing plan for #46519

### Dimensions
- [x] Entity type
  - [x] Question
  - [x] Model
- [x] Queries
  - [x] Number of stages
    - [x] 1
    - [x] 2
    - [x] ~3~ 
  - [x] Last stage breakouts & aggregations:
    - [x] only breakouts
    - [x] only aggregations
    - [x] breakouts & aggregations
- [x] Column source
  - [x] Data source
    - [x] Question
    - [x] Model
  - [x] Explicit joins
  - [x] Implicit joins
  - [x] Implicit joins due to explicit joins
  - [x] Custom column
  - [x] Aggregation
  - [x] Breakout
- [x] Filter type: Unit of Time (only covering existing functionality in unit tests; excluded from e2e tests)
- [x] Dashboard type
  - [x] Regular
  - [x] Public
  - [x] Embedded
- [x] Dashcard title drill
- [x] Unit of time parameter + filter on 1st-stage column in a multi-stage query
- [x] Click behavior - open question

### Unit tests

- [x] `getParameterColumns` - Existing behavior (Unit of Time filter)

### E2e tests

- [x] Can map filters to the same columns as QB filter modal shows for a given question/model
  - [x] Shows section headers as in QB filter modal
  - [x] Applying filters to columns from all possible sources from all possible stages works
    - [x] Drilling via title dashcard works
- [x] Custom click behavior (open question) allows to map filters to the same columns as QB filter modal
  - [x] Click behavior works

",kamilmielnik,2024-08-06 11:43:37+00:00,['kamilmielnik'],2024-10-30 07:53:37+00:00,2024-10-30 07:53:35+00:00,https://github.com/metabase/metabase/issues/46520,"[('.TestingStrategy/FE', '')]","[{'comment_id': 2446095981, 'issue_id': 2450676114, 'author': 'kamilmielnik', 'body': 'Closed by #49280', 'created_at': datetime.datetime(2024, 10, 30, 7, 53, 35, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-30 07:53:35 UTC): Closed by #49280

"
2450672349,issue,closed,completed,[Epic] Show columns from all stages in the dashboard filters,"**Links**
- Product doc: https://www.notion.so/metabase/Allow-to-use-in-dashboard-filters-both-pre-and-post-last-aggregation-columns-b32a6bb5cebc4723b8b9b81870217a79
- Tech doc: https://www.notion.so/metabase/Tech-Allow-to-use-both-pre-and-post-last-aggregation-columns-in-dashboard-filters-1f8c3309aa824463827a38bedcd47ac6
- Testing plan: #46520
- Feature branch: `dashboard-filter-columns`
  - PR with feature branch: #47167
- Links:
  - Fixes #19744
  - Follow up epic: #48681

### Milestone 1

```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/issues/46914
- [ ] https://github.com/metabase/metabase/issues/47304
- [ ] https://github.com/metabase/metabase/issues/47184
- [ ] https://github.com/metabase/metabase/issues/48258
- [ ] https://github.com/metabase/metabase/issues/48441
- [ ] https://github.com/metabase/metabase/issues/48884
- [ ] https://github.com/metabase/metabase/issues/48339
- [ ] https://github.com/metabase/metabase/issues/48734
- [ ] https://github.com/metabase/metabase/issues/49282
- [ ] https://github.com/metabase/metabase/issues/48613
- [ ] https://github.com/metabase/metabase/issues/49110
```

```[tasklist]
### Frontend
- [ ] https://github.com/metabase/metabase/pull/46719
- [ ] https://github.com/metabase/metabase/pull/46721
- [ ] https://github.com/metabase/metabase/issues/46522
- [ ] https://github.com/metabase/metabase/issues/46915
- [ ] https://github.com/metabase/metabase/issues/47166
- [ ] https://github.com/metabase/metabase/issues/48253
- [ ] https://github.com/metabase/metabase/issues/48260
- [ ] https://github.com/metabase/metabase/issues/47235
- [ ] https://github.com/metabase/metabase/issues/48787
- [ ] https://github.com/metabase/metabase/issues/48885
- [ ] https://github.com/metabase/metabase/issues/49218
```

```[tasklist]
### Tests
- [ ] https://github.com/metabase/metabase/issues/46526
- [ ] https://github.com/metabase/metabase/issues/46527
- [ ] https://github.com/metabase/metabase/issues/47219
- [ ] https://github.com/metabase/metabase/issues/48445
- [ ] https://github.com/metabase/metabase/issues/49022
- [ ] https://github.com/metabase/metabase/issues/49233
- [ ] https://github.com/metabase/metabase/issues/47234
- [ ] https://github.com/metabase/metabase/issues/46520
- [ ] https://github.com/metabase/metabase/issues/46528
```

```[tasklist]
### Bugs that will be fixed when this epic is merged
- [ ] https://github.com/metabase/metabase/issues/19744
```
",kamilmielnik,2024-08-06 11:41:38+00:00,"['appleby', 'kamilmielnik', 'metamben']",2024-11-26 07:23:58+00:00,2024-11-22 22:49:11+00:00,https://github.com/metabase/metabase/issues/46519,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2450129890,issue,closed,completed,Fix some unintentional color changes,"### Describe the bug

It's been reported in a couple of places, but this might affect a lot more components.
- https://metaboat.slack.com/archives/C505ZNNH4/p1722889750138379
- https://metaboat.slack.com/archives/C505ZNNH4/p1722880290738879
- https://metaboat.slack.com/archives/C01LQQ2UW03/p1722960713070159

### To Reproduce

For the first issue: API key hover row color
1. Go to `/admin/settings/authentication/api-keys`
2. Create an API key and hover over the API key entry row

For the second issue: Permission backdrop missing color
1. Go to admin > permission
2. Change some settings
4. Navigate away
5. The modal backdrop doesn't have any color

For the third issue: Summarize button color
1. Go to a question
2. Click summarize
3. The button should stays green, not blue

### Expected behavior

1. All UI colors look the same
2. There is a modal backdrop color
3. Summarize button stay green when clicked.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master @ a792ca29d934b4f813b68b826f72552ab34999b8

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-08-01"",
      ""src_hash"": ""d9eff1dbab57c6c0e0362ff48276d79fd51f4ebe"",
      ""tag"": ""v1.1.26-SNAPSHOT"",
      ""hash"": ""d3c8f46""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Just missing and unexpected colors

### Additional context

_No response_",WiNloSt,2024-08-06 07:14:36+00:00,['WiNloSt'],2024-10-08 16:18:25+00:00,2024-08-08 09:01:08+00:00,https://github.com/metabase/metabase/issues/46513,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Embedding', '')]",[],
2449750610,issue,open,,Breadcrumbs aren't shown in collections when sidebar is closed,"### Describe the bug

If you are on a question and the left menu is closed you see a crumb trail like this:

![image](https://github.com/user-attachments/assets/e7970587-61c3-42da-beba-52bc12ff938f)

but when you navigate up a level you would expect the see the same crumbtrail minus one item but you don't:

![image](https://github.com/user-attachments/assets/c143644d-77a4-44f2-9354-1f88acad40d0)




### To Reproduce

1. Go to and question or dashboard which is deep in some nested collections
2. Close the left menu
3. Confirm you see a crumb trail showing your current location
4. Click the 'parent' in the crumb trail
5. Confirm you do NOT see the remaining crumb trail now when you should


### Expected behavior

You should always see the crumb trail when the left menu is closed when viewing collections the same as when viewing questions or dashboards or models.

Honestly I think you should *always* see the crumb trail even if the left menu is open too. That real estate isn't used for anything else and it would improve the consistently of the navigation experience and help when you have a very deep and large nested collection structure.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.220-209.867.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Australia/Melbourne""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.9""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v1.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

A small annoyance

### Additional context

_No response_",brendanheywood,2024-08-06 01:34:39+00:00,[],2025-02-05 19:23:42+00:00,,https://github.com/metabase/metabase/issues/46512,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('Organization/', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2270245761, 'issue_id': 2449750610, 'author': 'brendanheywood', 'body': 'I have also tested this in our stage instance which is the latest version and the bug is the same there', 'created_at': datetime.datetime(2024, 8, 6, 2, 23, 54, tzinfo=datetime.timezone.utc)}]","brendanheywood (Issue Creator) on (2024-08-06 02:23:54 UTC): I have also tested this in our stage instance which is the latest version and the bug is the same there

"
2449615569,issue,closed,completed,Non-admin requests to /api/search?models=dataset&limit=1 time out for non-admin users on v0.49.20,"### Describe the bug

It takes 60s for non-admin users on our metabase to open up the dropdown menu for ""Select a database"" after hitting ""new question"" or ""new SQL question."" After opening up the network panel, we see a request to /api/search?models=dataset&limit=1 time out with a ""504 Gateway Time-out"" 

- this route returns quickly for admins. it's only slow for non-admins. switching a user from non-admin to admin will speed things up
- while tailing logs, I don't see this route getting hit
- I don't see any slow queries in metabase's database

https://github.com/metabase/metabase/issues/38557 describes some concerns with performance for this endpoint, but 

A few quick notes about our setup:

- we upgraded to v0.50 before downgrading to v0.49 after seeing a lot of performance problems with v0.50.
- we're backed by a postgresql database
- we have a staging cluster that we can easily destroy and recreate if there are any theories that you'd like us to test
- we're running on k8s (EKS)

### To Reproduce

1. Log in with a non-admin user on a v0.49.20 metabase connected to postgresql
2. Query  /api/search?models=dataset&limit=1 

It should time out. (Sorry this isn't a better repro! I'm not sure what about our setup makes this slow)

<img width=""828"" alt=""Screenshot 2024-08-05 at 3 25 48 PM"" src=""https://github.com/user-attachments/assets/906be56c-73cd-4ef2-835b-17ba0751b72a"">


### Expected behavior

This route should return just as fast for non-admin as admins. 

### Logs

There's nothing interesting in the JavaScript console:

```
Failed to load resource: the server responded with a status of 504 /api/search?models=dataset&limit=1:1
app-main.64b70b1268cea597e09b.js:29 Request entities,search_list,{""models"":""dataset"",""limit"":1},fetch failed
```

Surprisingly, I don't see anything in the metabase container's logs either. I _can't_ find any of the /api/search logs when querying as a non-admin user, but I do see them when querying as an admin user:

```
...
2024-08-05 22:55:34,145 DEBUG middleware.log :: GET /api/health 200 1.6 ms (0 DB calls) App DB connections: 3/13 Jetty threads: 31/50 (2 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)
2024-08-05 22:55:37,907 DEBUG middleware.log :: GET /api/health 200 1.7 ms (0 DB calls) App DB connections: 3/13 Jetty threads: 32/50 (2 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)
2024-08-05 22:55:38,240 DEBUG middleware.log :: GET /api/health 200 329.5 ms (0 DB calls) App DB connections: 3/13 Jetty threads: 32/50 (2 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)
```

I also can't find any slow queries in the Postgresql database or any indication that /api/search is reaching the backing DB.

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1064-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""mysql"",
      ""athena"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.15""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v0.49.20"",
      ""hash"": ""af03591""
    },
    ""settings"": {
      ""report-timezone"": ""US/Pacific""
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",KelWill,2024-08-05 23:03:15+00:00,['johnswanson'],2024-09-03 16:27:34+00:00,2024-09-03 16:27:33+00:00,https://github.com/metabase/metabase/issues/46510,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2270121881, 'issue_id': 2449615569, 'author': 'perivamsi', 'body': ""@KelWill could you email me at vamsi@metabase.com please? I'll invite you to Slack and we can debug it faster there, if that works for you."", 'created_at': datetime.datetime(2024, 8, 6, 0, 1, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326952332, 'issue_id': 2449615569, 'author': 'johnswanson', 'body': 'After https://github.com/metabase/metabase/pull/47395 performance on `/api/search` and other endpoints that involve lots of collection permissions should be much improved.', 'created_at': datetime.datetime(2024, 9, 3, 16, 27, 33, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-08-06 00:01:56 UTC): @KelWill could you email me at vamsi@metabase.com please? I'll invite you to Slack and we can debug it faster there, if that works for you.

johnswanson (Assginee) on (2024-09-03 16:27:33 UTC): After https://github.com/metabase/metabase/pull/47395 performance on `/api/search` and other endpoints that involve lots of collection permissions should be much improved.

"
2448806256,issue,closed,completed,"Move ""compare to the past"" to bottom of summarisation dropdown as action and hide it if it does not apply","- Make the ""Compare to the past"" dropdown item an action and move it to the bottom
- Simplify the label to just be ""Compare to the past""
- Only show the ""Compare to the past"" button when, there either is a) a temporal column used as the first breakout, or b) there are temporal columns that _can be added_ as breakouts later (we will auto-select one in a follow up PR).",romeovs,2024-08-05 15:12:30+00:00,['romeovs'],2024-10-08 16:18:11+00:00,2024-08-09 09:24:09+00:00,https://github.com/metabase/metabase/issues/46499,[],[],
2448786697,issue,closed,completed,v50 data permissions migrations are slow,The data migrations are slow and can take up to several hours in their current form.,dpsutton,2024-08-05 15:04:46+00:00,[],2024-08-15 13:33:02+00:00,2024-08-15 13:33:02+00:00,https://github.com/metabase/metabase/issues/46497,"[('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2291276537, 'issue_id': 2448786697, 'author': 'dpsutton', 'body': 'closed by https://github.com/metabase/metabase/pull/46826', 'created_at': datetime.datetime(2024, 8, 15, 13, 33, 2, tzinfo=datetime.timezone.utc)}]","dpsutton (Issue Creator) on (2024-08-15 13:33:02 UTC): closed by https://github.com/metabase/metabase/pull/46826

"
2448736405,issue,closed,completed,add cypress-terminal-report,,uladzimirdev,2024-08-05 14:43:22+00:00,[],2024-08-08 06:46:27+00:00,2024-08-07 14:53:21+00:00,https://github.com/metabase/metabase/issues/46494,[],[],
2448720868,issue,closed,completed,[Epic] Moving average and other compare UI follow-ons,"**Links**
- [product doc](https://www.notion.so/metabase/Moving-average-and-other-compare-UI-follow-ons-fa4fc378e4cc43f5ab0ae1cf0eb20ecb)
- [testing plan](https://www.notion.so/metabase/Testing-plan-Moving-average-and-other-compare-UI-follow-ons-3153275f9d3d404eac0be2a9182558db)
- feature branch: 

**Implementation Plan**

```[tasklist]
### Milestone 1: Compare values follow ons
- [ ] https://github.com/metabase/metabase/issues/46499
- [ ] https://github.com/metabase/metabase/issues/46531
- [ ] https://github.com/metabase/metabase/issues/46532
```

```[tasklist]
### Milestone 2: Moving average
- [ ] https://github.com/metabase/metabase/issues/46669
```",romeovs,2024-08-05 14:36:26+00:00,['romeovs'],2024-08-21 10:09:42+00:00,2024-08-21 10:09:41+00:00,https://github.com/metabase/metabase/issues/46493,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2448718778,issue,closed,completed,re-enable recordings,,uladzimirdev,2024-08-05 14:35:29+00:00,['uladzimirdev'],2024-08-06 10:04:25+00:00,2024-08-05 21:32:04+00:00,https://github.com/metabase/metabase/issues/46492,[],[],
2448655167,issue,closed,not_planned,Pie chart not working in email subscriptions,"### Describe the bug

When sending pie charts via email subscriptions, the chart fails to render.
Message attached. 
![Screenshot 2024-08-05 at 16 02 51](https://github.com/user-attachments/assets/20124c7e-a62f-481e-9b43-ab15a0808a50)

Changing viz of the same question to a bar chart renders the chart in subscription successfully.

I tried changing the display options like legend and percentages, minimal slice percentage, etc, nothing helped.

### To Reproduce

1. Go to a dashboard with a bar chart
2. Set up email subscription
3. Click on Send email now
4. See error - Subscription chart is broken


### Expected behavior

Subscription renders pie charts successfully

### Logs

_No response_

### Information about your Metabase installation

```JSON
I am reporting for Metabase v0.50.18.3, but I noticed the same behavior in 49.1. It was one of the reasons for the upgrade.
```


### Severity

Severe for me.

### Additional context

_No response_",TLazarevic,2024-08-05 14:06:53+00:00,[],2024-08-06 07:30:19+00:00,2024-08-05 17:46:33+00:00,https://github.com/metabase/metabase/issues/46489,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2269192286, 'issue_id': 2448655167, 'author': 'Tony-metabase', 'body': 'Is it possible you are hitting this issue https://github.com/metabase/metabase/issues/28568', 'created_at': datetime.datetime(2024, 8, 5, 14, 17, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269228438, 'issue_id': 2448655167, 'author': 'TLazarevic', 'body': '@Tony-metabase Possible, since I think I saw numbers and strings being mentioned in the logs once, will try updating the query and report back, thanks for the blazing fast response', 'created_at': datetime.datetime(2024, 8, 5, 14, 33, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269245098, 'issue_id': 2448655167, 'author': 'Tony-metabase', 'body': ""You're welcome! Let us know :)"", 'created_at': datetime.datetime(2024, 8, 5, 14, 41, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269319438, 'issue_id': 2448655167, 'author': 'TLazarevic', 'body': ""@Tony-metabase Confirming as fixed by swapping column order, you can close this one and I'll upvote the original issue. Thanks again"", 'created_at': datetime.datetime(2024, 8, 5, 15, 15, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269590472, 'issue_id': 2448655167, 'author': 'npfitz', 'body': 'Labelled as a duplicate', 'created_at': datetime.datetime(2024, 8, 5, 17, 46, 33, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-08-05 14:17:35 UTC): Is it possible you are hitting this issue https://github.com/metabase/metabase/issues/28568

TLazarevic (Issue Creator) on (2024-08-05 14:33:57 UTC): @Tony-metabase Possible, since I think I saw numbers and strings being mentioned in the logs once, will try updating the query and report back, thanks for the blazing fast response

Tony-metabase on (2024-08-05 14:41:23 UTC): You're welcome! Let us know :)

TLazarevic (Issue Creator) on (2024-08-05 15:15:05 UTC): @Tony-metabase Confirming as fixed by swapping column order, you can close this one and I'll upvote the original issue. Thanks again

npfitz on (2024-08-05 17:46:33 UTC): Labelled as a duplicate

"
2448193588,issue,closed,completed,Introduce base color shades and tints,"- [Slack discussion](https://metaboat.slack.com/archives/C02H619CJ8K/p1721999045118829)
- [Figma file](https://www.figma.com/design/OlyKP09vro7EkQ2ZzXDDla/color-playground?node-id=0-1&t=E2Q2tQJawLSqEBXo-0)",WiNloSt,2024-08-05 10:25:46+00:00,['WiNloSt'],2024-08-08 11:57:49+00:00,2024-08-08 11:57:49+00:00,https://github.com/metabase/metabase/issues/46479,[],[],
2448106266,issue,closed,completed,N+1 when batched update cards,"Batched updating cards is inefficient
```clojure
(mt/with-temp [:model/Card {card-1 :id} {}
               :model/Card {card-2 :id} {}
               :model/Card {card-3 :id} {}]
  (t2/with-call-count [call-count]
    (t2/update! :model/Card :id [:in [card-1 card-2 card-3]] {:name ""new name""})
    (call-count)))
;; => 10
```

Optimizing is needed because we're doing a lots of batch updating `report_card, report_dashboard` in https://github.com/metabase/metabase/pull/45007

Look at the queries it generates

query | params
-- | --
SELECT * FROM ""parameter_card""   WHERE ""card_id"" = ? | [1]
SELECT * FROM ""parameter_card""   WHERE ""card_id"" = ? | [2]
SELECT * FROM ""parameter_card""   WHERE ""card_id"" = ? | [3]
SELECT * FROM ""report_card""   WHERE ""id"" IN (?, ?, ?) | [1 3 2]
UPDATE ""report_card"" SET   ""updated_at"" = NOW() WHERE ""id"" IN (?, ?, ?) | [1 3 2]
SELECT   ""report_card"".""id"",   ""report_card"".""archived"",   ""report_card"".""dataset_query"" FROM   ""report_card"" WHERE ""id"" = ? | [1]
INSERT INTO ""query_analysis""   (""card_id"") VALUES (?) | [1]
SELECT ""t"".""id"" AS   ""table-id"", ""t"".""name"" AS ""table"",   ""f"".""id"" AS ""field-id"",   ""f"".""name"" AS ""column"" FROM   ""metabase_field"" AS ""f"" INNER JOIN   ""metabase_table"" AS ""t"" ON ""t"".""id"" =   ""f"".""table_id"" WHERE ""f"".""id"" IN (?,   ?, ?, ?) | [62 39 40 41]
INSERT INTO ""query_field""   (""card_id"", ""analysis_id"", ""table"",   ""column"", ""table_id"", ""field_id"",   ""explicit_reference"") VALUES (?, ?, ?, ?, ?, ?, TRUE), (?, ?, ?, ?,   ?, ?, TRUE), (?, ?, ?, ?, ?, ?, TRUE), (?, ?, ?, ?, ?, ?, TRUE) | [1 85 ""ORDERS"" ""QUANTITY"" 5 39 1 85   ""ORDERS"" ""PRODUCT_ID"" 5 40 1 85 ""ORDERS""   ""CREATED_AT"" 5 41 1 85 ""PRODUCTS"" ""ID"" 8 62]
INSERT INTO ""query_table""   (""card_id"", ""analysis_id"", ""schema"",   ""table"", ""table_id"") VALUES (?, ?, NULL, ?, ?), (?, ?,   NULL, ?, ?), (?, ?, NULL, ?, ?), (?, ?, NULL, ?, ?) | [1 85 ""ORDERS"" 5 1 85 ""ORDERS"" 5 1 85   ""ORDERS"" 5 1 85 ""PRODUCTS"" 8]
DELETE FROM ""query_analysis""   WHERE (""card_id"" = ?) AND (""id"" <> ?) | [1 85]
SELECT   ""report_card"".""id"",   ""report_card"".""archived"",   ""report_card"".""dataset_query"" FROM   ""report_card"" WHERE ""id"" = ? | [2]
INSERT INTO ""query_analysis""   (""card_id"") VALUES (?) | [2]
SELECT ""t"".""id"" AS   ""table-id"", ""t"".""name"" AS ""table"",   ""f"".""id"" AS ""field-id"",   ""f"".""name"" AS ""column"" FROM   ""metabase_field"" AS ""f"" INNER JOIN   ""metabase_table"" AS ""t"" ON ""t"".""id"" =   ""f"".""table_id"" WHERE ""f"".""id"" IN (?,   ?, ?) | [46 43 49]
INSERT INTO ""query_field""   (""card_id"", ""analysis_id"", ""table"",   ""column"", ""table_id"", ""field_id"",   ""explicit_reference"") VALUES (?, ?, ?, ?, ?, ?, TRUE), (?, ?, ?, ?,   ?, ?, TRUE), (?, ?, ?, ?, ?, ?, TRUE) | [2 86 ""ORDERS"" ""USER_ID"" 5 43 2 86 ""PEOPLE""   ""ID"" 3 46 2 86 ""PEOPLE"" ""BIRTH_DATE"" 3 49]
INSERT INTO ""query_table""   (""card_id"", ""analysis_id"", ""schema"",   ""table"", ""table_id"") VALUES (?, ?, NULL, ?, ?), (?, ?,   NULL, ?, ?), (?, ?, NULL, ?, ?) | [2 86 ""ORDERS"" 5 2 86 ""PEOPLE"" 3 2 86   ""PEOPLE"" 3]
DELETE FROM ""query_analysis""   WHERE (""card_id"" = ?) AND (""id"" <> ?) | [2 86]
SELECT   ""report_card"".""id"",   ""report_card"".""archived"",   ""report_card"".""dataset_query"" FROM   ""report_card"" WHERE ""id"" = ? | [3]
INSERT INTO ""query_analysis""   (""card_id"") VALUES (?) | [3]
DELETE FROM ""query_analysis""   WHERE (""card_id"" = ?) AND (""id"" <> ?) | [3 87]
SELECT * FROM ""report_card""   WHERE ""id"" IN (?, ?, ?) | [1 2 3]
UPDATE ""report_card"" SET   ""updated_at"" = NOW() WHERE ""id"" IN (?, ?, ?) | [1 3 2]

Updating a card name shouldn't update: parameter card, query_field, query_analysis",qnkhuat,2024-08-05 09:44:42+00:00,['qnkhuat'],2024-08-06 08:20:44+00:00,2024-08-05 21:49:42+00:00,https://github.com/metabase/metabase/issues/46477,"[('.Performance', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]",[],
2447930936,issue,closed,not_planned,Long running Metabase instance suddenly had an authentication issue,"**Describe the bug**
This metabase instance has been up and running for years now. We recently upgraded the backend Postgres to the latest version. Over the weekend, the instance went down and there was a 503 error. The only bug I could see in the logs was:

GET /api/user/current 401 10.6 ms (0 DB calls) {:metabase-user-id nil}

**Logs**
Picked up JAVA_TOOL_OPTIONS: -Xmx4g
Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-08-05 07:24:16,048 INFO metabase.util :: Maximum memory available to JVM: 4.0 GB
2024-08-05 07:24:20,820 INFO util.encryption :: Saved credentials encryption is ENABLED for this Metabase instance. 🔐 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-08-05 07:24:29,681 INFO driver.impl :: Registered abstract driver :sql  🚚
2024-08-05 07:24:29,694 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) 🚚
2024-08-05 07:24:29,705 INFO metabase.util :: Load driver :sql-jdbc took 81.2 ms
2024-08-05 07:24:29,706 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:29,999 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:30,062 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:33,042 INFO metabase.core :: 
Metabase v0.50.15 (c6697cf) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-08-05 07:24:33,057 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-08-05 07:24:33,140 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

2024-08-05 07:24:33,227 INFO metabase.core :: Starting Metabase version v0.50.15 (c6697cf) ...
2024-08-05 07:24:33,240 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Linux"",
 ""os.version"" ""5.15.0-1026-aws"",
 ""user.language"" ""en"",
 ""user.timezone"" ""GMT""}

2024-08-05 07:24:33,243 INFO metabase.plugins :: Loading plugins in /plugins...
2024-08-05 07:24:33,520 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-08-05 07:24:34,181 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-08-05 07:24:34,228 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-08-05 07:24:34,577 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-08-05 07:24:34,589 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-08-05 07:24:34,657 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-08-05 07:24:34,662 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-08-05 07:24:34,753 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-08-05 07:24:34,755 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-08-05 07:24:34,782 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-08-05 07:24:34,796 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-08-05 07:24:34,798 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-08-05 07:24:34,918 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-08-05 07:24:35,263 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-08-05 07:24:35,263 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) 🚚
2024-08-05 07:24:35,290 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-08-05 07:24:35,291 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,341 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-08-05 07:24:35,342 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,353 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-08-05 07:24:35,354 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,355 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-08-05 07:24:35,356 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) 🚚
2024-08-05 07:24:35,367 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Oracle Driver due to required dependencies. Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.

2024-08-05 07:24:35,374 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-08-05 07:24:35,378 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver""]
2024-08-05 07:24:35,383 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-08-05 07:24:35,387 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) 🚚
2024-08-05 07:24:35,405 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-08-05 07:24:35,409 INFO driver.impl :: Registered driver :mongo  🚚
2024-08-05 07:24:35,414 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-08-05 07:24:35,418 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,427 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-08-05 07:24:35,429 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,439 INFO plugins.dependencies :: Metabase cannot initialize plugin Metabase Vertica Driver due to required dependencies. Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.

2024-08-05 07:24:35,440 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-08-05 07:24:35,441 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]
2024-08-05 07:24:35,453 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-08-05 07:24:35,456 INFO driver.impl :: Registered driver :druid  🚚
2024-08-05 07:24:35,462 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-08-05 07:24:35,463 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,479 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-08-05 07:24:35,481 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) 🚚
2024-08-05 07:24:35,492 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-08-05 07:24:35,494 INFO db.setup :: Verifying postgres Database Connection ...
2024-08-05 07:24:36,037 INFO db.setup :: Successfully verified PostgreSQL 13.13 application database connection. ✅
2024-08-05 07:24:36,038 INFO db.setup :: Checking if a database downgrade is required...
2024-08-05 07:24:37,291 INFO db.setup :: Running Database Migrations...
2024-08-05 07:24:37,292 INFO db.setup :: Setting up Liquibase...
2024-08-05 07:24:37,720 INFO db.setup :: Liquibase is ready.
2024-08-05 07:24:37,721 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-08-05 07:24:38,752 INFO db.liquibase :: No unrun migrations found.
2024-08-05 07:24:38,755 INFO db.setup :: Database Migrations Current ... ✅
2024-08-05 07:24:38,756 INFO metabase.util :: Database setup took 3.3 s
2024-08-05 07:24:40,568 INFO driver.impl :: Initializing driver :sql...
2024-08-05 07:24:40,570 INFO driver.impl :: Initializing driver :sql-jdbc...
2024-08-05 07:24:40,571 INFO driver.impl :: Initializing driver :h2...
2024-08-05 07:24:40,758 INFO util.files :: Extract file /sample-database.db.mv.db -> /plugins/sample-database.db.mv.db
2024-08-05 07:24:40,831 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-08-05 07:24:40,852 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-08-05 07:24:40,853 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-08-05 07:24:40,854 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-08-05 07:24:40,857 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-08-05 07:24:40,858 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId '5394e7a99df01722842680833'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-08-05 07:24:40,858 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-08-05 07:24:40,858 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-08-05 07:24:41,016 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5394e7a99df01722842680833 paused.
2024-08-05 07:24:41,017 INFO metabase.task :: Task scheduler initialized into standby mode.
2024-08-05 07:24:41,111 INFO metabase.task :: Initializing task Cache 📆
2024-08-05 07:24:41,112 INFO metabase.task :: Initializing task SyncDatabases 📆
2024-08-05 07:24:41,149 INFO task.sync-databases :: Updated default schedules for 0 databases
2024-08-05 07:24:41,151 INFO metabase.task :: Initializing task PersistRefresh 📆
2024-08-05 07:24:41,168 INFO driver.impl :: Initializing driver :postgres...
2024-08-05 07:24:41,199 INFO driver.impl :: Initializing driver :snowflake...
2024-08-05 07:24:41,200 INFO plugins.classloader :: Added URL file:/plugins/snowflake.metabase-driver.jar to classpath
2024-08-05 07:24:41,201 DEBUG plugins.init-steps :: Loading plugin namespace metabase.driver.snowflake...
2024-08-05 07:24:41,250 INFO driver.impl :: Registered abstract driver :metabase.driver.sql-jdbc.execute.legacy-impl/use-legacy-classes-for-read-and-set  🚚
2024-08-05 07:24:41,265 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc :metabase.driver.sql-jdbc.execute.legacy-impl/use-legacy-classes-for-read-and-set]) 🚚
2024-08-05 07:24:41,335 DEBUG plugins.jdbc-proxy :: Registering JDBC proxy driver for net.snowflake.client.jdbc.SnowflakeDriver...
2024-08-05 07:24:41,337 INFO metabase.util :: Load lazy loading driver :snowflake took 135.4 ms
2024-08-05 07:24:41,337 INFO driver.impl :: Initializing driver :metabase.driver.sql-jdbc.execute.legacy-impl/use-legacy-classes-for-read-and-set...
2024-08-05 07:24:41,380 INFO driver.impl :: Initializing driver :mysql...
2024-08-05 07:24:41,413 INFO metabase.task :: Initializing task CheckForNewVersions 📆
2024-08-05 07:24:41,470 INFO metabase.task :: Initializing task PersistPrune 📆
2024-08-05 07:24:41,492 INFO metabase.task :: Initializing task SendAnonymousUsageStats 📆
2024-08-05 07:24:41,534 INFO metabase.task :: Initializing task ModelIndexValues 📆
2024-08-05 07:24:41,540 INFO metabase.task :: Initializing task RefreshSlackChannelsAndUsers 📆
2024-08-05 07:24:41,592 INFO metabase.task :: Initializing task TruncateAuditTables 📆
2024-08-05 07:24:41,615 INFO metabase.task :: Initializing task SendPulses 📆
2024-08-05 07:24:41,630 INFO metabase.task :: Initializing task SendFollowUpEmails 📆
2024-08-05 07:24:41,655 INFO metabase.task :: Initializing task SendCreatorSentimentEmails 📆
2024-08-05 07:24:41,668 INFO metabase.task :: Initializing task SendLegacyNoSelfServiceEmail 📆
2024-08-05 07:24:41,671 INFO metabase.task :: Initializing task TaskHistoryCleanup 📆
2024-08-05 07:24:41,687 INFO metabase.task :: Initializing task SendWarnPulseRemovalEmail 📆
2024-08-05 07:24:41,707 INFO jdbcjobstore.JobStoreTX :: ClusterManager: detected 1 failed or restarted instances.
2024-08-05 07:24:41,707 INFO jdbcjobstore.JobStoreTX :: ClusterManager: Scanning for instance ""6f63374e565a1721837932469""'s failed in-progress jobs.
2024-08-05 07:24:41,718 INFO jdbcjobstore.JobStoreTX :: ClusterManager: ......Cleaned-up 2 other failed job(s).
2024-08-05 07:24:41,722 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_5394e7a99df01722842680833 started.
2024-08-05 07:24:41,724 INFO metabase.task :: Task scheduler started
2024-08-05 07:24:41,726 INFO metabase.core :: Metabase Initialization COMPLETE in 34.1 s
2024-08-05 07:24:41,760 INFO jdbcjobstore.JobStoreTX :: Handling 7 trigger(s) that missed their scheduled fire-time.
2024-08-05 07:24:41,854 INFO task.refresh-slack-channel-user-cache :: Starting Slack user/channel startup cache refresh...
2024-08-05 07:24:41,855 INFO integrations.slack :: Refreshing slack channels and usernames.
2024-08-05 07:24:42,205 INFO i18n.impl :: Reading available locales from locales.clj...
2024-08-05 07:24:42,837 INFO util.fonts :: Reading available fonts from /frontend_client/app/fonts
2024-08-05 07:24:44,247 INFO task.refresh-slack-channel-user-cache :: Slack user/channel startup cache refreshed with 641 entries, took 2392ms.
2024-08-05 07:24:45,538 DEBUG middleware.log :: GET /api/user/current 401 10.6 ms (0 DB calls) {:metabase-user-id nil} 
""Unauthenticated""

**Severity**
This prevents our usage of Metabase completely, which is an issue because we use Metabase both for daily operations and for visualization. 


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1026-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-23"",
      ""tag"": ""v0.50.15"",
      ""hash"": ""c6697cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",natashamathur,2024-08-05 08:26:14+00:00,[],2025-01-16 21:06:07+00:00,2025-01-16 21:06:06+00:00,https://github.com/metabase/metabase/issues/46472,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2269587113, 'issue_id': 2447930936, 'author': 'npfitz', 'body': 'Hi @natashamathur, Any chance you could tell me how the login was happening? Was it via SSO or simple Email/Password combo? Are you still unable to log in? The message you see below happens when the session cookie is not present with requests being made to Metabase. So even if you don\'t have any session timeout set, if something happens on the local machine and that cookie is cleared, it will essentially cause you to be logged out\n```\n2024-08-05 07:24:45,538 DEBUG middleware.log :: GET /api/user/current 401 10.6 ms (0 DB calls) {:metabase-user-id nil}\n""Unauthenticated""\n```', 'created_at': datetime.datetime(2024, 8, 5, 17, 44, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270530331, 'issue_id': 2447930936, 'author': 'natashamathur', 'body': 'This came up when I was updating the removing and re launching the Docker\r\nimage to update the version.\r\n\r\nOn Mon, Aug 5, 2024 at 8:44\u202fPM Nick Fitzpatrick ***@***.***>\r\nwrote:\r\n\r\n> Hi @natashamathur <https://github.com/natashamathur>, Any chance you\r\n> could tell me how the login was happening? Was it via SSO or simple\r\n> Email/Password combo? Are you still unable to log in? The message you see\r\n> below happens when the session cookie is not present with requests being\r\n> made to Metabase. So even if you don\'t have any session timeout set, if\r\n> something happens on the local machine and that cookie is cleared, it will\r\n> essentially cause you to be logged out\r\n>\r\n> 2024-08-05 07:24:45,538 DEBUG middleware.log :: GET /api/user/current 401 10.6 ms (0 DB calls) {:metabase-user-id nil}\r\n> ""Unauthenticated""\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/46472#issuecomment-2269587113>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AIO2SK6F6V7CBS776WDXG7TZP62ZBAVCNFSM6AAAAABL7ZSEE2VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENRZGU4DOMJRGM>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n\r\n\r\n-- \r\n\r\nNatasha Mathur\r\n\r\nDirector of Data\r\n\r\n*Calendly <https://calendly.com/natashamathur/30-minute-meeting>*\r\n\r\nTechnology Advancing Primary Care', 'created_at': datetime.datetime(2024, 8, 6, 7, 1, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2272878703, 'issue_id': 2447930936, 'author': 'natashamathur', 'body': ""It was via SSO. I am able to log in now - I was always able to log in, but could not restart the Docker instance. This came up because we got a 505 error on Metabase, and I'm trying to figure out what caused that 505 error."", 'created_at': datetime.datetime(2024, 8, 7, 8, 9, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2334301098, 'issue_id': 2447930936, 'author': 'paoliniluis', 'body': ""@natashamathur I don't see the 505 in the logs"", 'created_at': datetime.datetime(2024, 9, 6, 15, 26, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596887741, 'issue_id': 2447930936, 'author': 'paoliniluis', 'body': 'Closing due to non-response', 'created_at': datetime.datetime(2025, 1, 16, 21, 6, 6, tzinfo=datetime.timezone.utc)}]","npfitz on (2024-08-05 17:44:26 UTC): Hi @natashamathur, Any chance you could tell me how the login was happening? Was it via SSO or simple Email/Password combo? Are you still unable to log in? The message you see below happens when the session cookie is not present with requests being made to Metabase. So even if you don't have any session timeout set, if something happens on the local machine and that cookie is cleared, it will essentially cause you to be logged out
```
2024-08-05 07:24:45,538 DEBUG middleware.log :: GET /api/user/current 401 10.6 ms (0 DB calls) {:metabase-user-id nil}
""Unauthenticated""
```

natashamathur (Issue Creator) on (2024-08-06 07:01:38 UTC): This came up when I was updating the removing and re launching the Docker
image to update the version.

On Mon, Aug 5, 2024 at 8:44 PM Nick Fitzpatrick ***@***.***>
wrote:



-- 

Natasha Mathur

Director of Data

*Calendly <https://calendly.com/natashamathur/30-minute-meeting>*

Technology Advancing Primary Care

natashamathur (Issue Creator) on (2024-08-07 08:09:58 UTC): It was via SSO. I am able to log in now - I was always able to log in, but could not restart the Docker instance. This came up because we got a 505 error on Metabase, and I'm trying to figure out what caused that 505 error.

paoliniluis on (2024-09-06 15:26:13 UTC): @natashamathur I don't see the 505 in the logs

paoliniluis on (2025-01-16 21:06:06 UTC): Closing due to non-response

"
2447419034,issue,open,,Secondary x-axis Parameter Does Not Get Legend in Pulse,"### Describe the bug

- When creating a bar/line chart, if secondary x-axis only a single class, pulse does not show it's legend.

### To Reproduce

1. Go to 'Sample Database -> ORDERS'
2. Filter out CREATED_AT in previous month and USER_ID is 1. (or any other query that only return one class for the secondary x-axis parameter)
3. Summarize Average of TOTAL by USER_ID and CREATED_AT: Month
4. Click Visualize and you will see a legend named ""1"" on top left.
5. Send a e-mail and you won't see such legend on the card.


### Expected behavior

Card/Dashboard/Pulse's legend should have same behavior. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase Version: v0.50.17
```


### Severity

Mild

### Additional context

_No response_",ojjj13,2024-08-05 01:32:21+00:00,[],2025-02-04 20:31:51+00:00,,https://github.com/metabase/metabase/issues/46471,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/', ''), ('.Frontend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.Team/DashViz', 'Dashboard and Viz team'), ('Visualization/Legend', '')]","[{'comment_id': 2269869290, 'issue_id': 2447419034, 'author': 'cdeweyx', 'body': 'Reproduced here: https://stats.metabase.com/question/19030-cd-gh-46471\r\n\r\nWould expect to still include the legend in static viz in this case', 'created_at': datetime.datetime(2024, 8, 5, 20, 34, 13, tzinfo=datetime.timezone.utc)}]","cdeweyx on (2024-08-05 20:34:13 UTC): Reproduced here: https://stats.metabase.com/question/19030-cd-gh-46471

Would expect to still include the legend in static viz in this case

"
2445802257,issue,closed,completed,verified filter is applied to recents even when no verified models exist,"Screencast showing the bug on master: https://www.loom.com/share/2b1fc3016b684f628e063867d6be7e49?sid=7283d0a3-fd3b-4048-8fb7-33b30c34fbf2 
",rafpaf,2024-08-02 21:44:16+00:00,['rafpaf'],2024-08-07 21:00:34+00:00,2024-08-07 02:56:36+00:00,https://github.com/metabase/metabase/issues/46464,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2445507739,issue,open,,"In Command palette, the trash and root collection can't be found in non-English locales","

![Image](https://github.com/user-attachments/assets/b77a373f-d8bf-4f4d-979a-e05c36e1b9b0)


![Image](https://github.com/user-attachments/assets/f67ab6fd-f57c-4fa8-a61c-a65034451ca7)


",rafpaf,2024-08-02 18:05:42+00:00,[],2025-02-04 20:26:59+00:00,,https://github.com/metabase/metabase/issues/46456,"[('Priority:P2', 'Average run of the mill bug'), ('Customization/i18n', ''), ('Organization/Trash', 'Where deleted items go')]","[{'comment_id': 2265942692, 'issue_id': 2445507739, 'author': 'rafpaf', 'body': 'Seems like a BE issue https://metaboat.slack.com/archives/C064EB1UE5P/p1722623574119819', 'created_at': datetime.datetime(2024, 8, 2, 18, 39, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2377142747, 'issue_id': 2445507739, 'author': 'johnswanson', 'body': '@rafpaf I think we could fix this in a hacky way on the BE, but a better fix would involve some (small) frontend work.\n\nThe fundamental problem here is that the trash\'s name in the database is not localized (and can\'t be since users might have varying locales). We could do something funky, where we check to see whether `(trs user-query)` is ""Trash"" - but that\'s not going to work for partial matches (e.g. the user types ""Rifiut"" and expects to see ""Rifiuti"" pop up).\n\nI started thinking about how this works for something like ""Browse models"". In this case you can do a partial search in Italian and the link pops up:\n\n![Image](https://github.com/user-attachments/assets/25fd66e5-ff93-484f-9f0c-ddf583fd2f1e)\n\nI assume that this is because the frontend has a hardcoded list of navigation options, which are localized, and then you can search through the localized navigations as well as the results from `/api/search`. I think it would make sense to do the same thing for the Trash:\n\n- BE: remove the Trash collection from search results (so it doesn\'t appear twice)\n- FE: include ""Trash"" as a hardcoded navigation option the same way we include ""Browse Models"" or ""Create a new model""\n\nWhat do you think?', 'created_at': datetime.datetime(2024, 9, 26, 14, 30, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-08-02 18:39:45 UTC): Seems like a BE issue https://metaboat.slack.com/archives/C064EB1UE5P/p1722623574119819

johnswanson on (2024-09-26 14:30:00 UTC): @rafpaf I think we could fix this in a hacky way on the BE, but a better fix would involve some (small) frontend work.

The fundamental problem here is that the trash's name in the database is not localized (and can't be since users might have varying locales). We could do something funky, where we check to see whether `(trs user-query)` is ""Trash"" - but that's not going to work for partial matches (e.g. the user types ""Rifiut"" and expects to see ""Rifiuti"" pop up).

I started thinking about how this works for something like ""Browse models"". In this case you can do a partial search in Italian and the link pops up:

![Image](https://github.com/user-attachments/assets/25fd66e5-ff93-484f-9f0c-ddf583fd2f1e)

I assume that this is because the frontend has a hardcoded list of navigation options, which are localized, and then you can search through the localized navigations as well as the results from `/api/search`. I think it would make sense to do the same thing for the Trash:

- BE: remove the Trash collection from search results (so it doesn't appear twice)
- FE: include ""Trash"" as a hardcoded navigation option the same way we include ""Browse Models"" or ""Create a new model""

What do you think?

"
2445437360,issue,closed,completed,Advanced view permissions do not save if you also make changes to create query permissions in the same edit,"### Describe the bug

Advanced permissions are not saving correctly if first edit an entity to have advanced view permissions and then subsequently edit the create queries permissions to be something different. After save the UI will reflect the previous view permissions.

### To Reproduce

If you set a table to be ""Sandboxed"" and then subsequently change create queries permissions from ""No"" to ""Query builder only"", the sandbox doesn't get included in the POST request and thus doesn't get persisted.

Similarly if you set a database to ""Impersonated"" then change create queries permissions from ""No"" to ""Query builder only"", the impersonation does not get saved.

The above was reproduced on v50. I can reproduce the issue with impersonation on 49 when subsequent edits to the ""download results"" or ""manage table metadata"" columns, but table sandboxing works as expect <=v49.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""22.0.2"",
    ""java.vendor"": ""Homebrew"",
    ""java.vendor.url"": ""https://github.com/Homebrew/homebrew-core/issues"",
    ""java.version"": ""22.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""22.0.2"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.2.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1 (Debian 16.1-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-08-02"",
      ""src_hash"": ""24950de29df4c37be0dadec431aa7d88e19c644c"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""5607dc9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",sloansparger,2024-08-02 17:14:41+00:00,['sloansparger'],2024-08-05 15:35:42+00:00,2024-08-02 22:06:34+00:00,https://github.com/metabase/metabase/issues/46450,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2266181979, 'issue_id': 2445437360, 'author': 'iethree', 'body': 'could this be related to https://github.com/metabase/metabase/issues/46170 ?', 'created_at': datetime.datetime(2024, 8, 2, 21, 45, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266184358, 'issue_id': 2445437360, 'author': 'sloansparger', 'body': 'unlikely', 'created_at': datetime.datetime(2024, 8, 2, 21, 47, 59, tzinfo=datetime.timezone.utc)}]","iethree on (2024-08-02 21:45:13 UTC): could this be related to https://github.com/metabase/metabase/issues/46170 ?

sloansparger (Issue Creator) on (2024-08-02 21:47:59 UTC): unlikely

"
2445352576,issue,closed,completed,"FE doesn't handle API errors in the ""Edit user"" modal","### Describe the bug

If anything goes wrong during the `PUT /api/user/:id` request (e.g. #46446), frontend doesn't properly handle that error. It leaks the error details in the ""Edit user"" modal.

### To Reproduce

1. Go to `/admin/people`
2. Click on `...` menu for ANY user and click ""Edit user""
3. Trigger the API error* by clicking on the ""Update"" button in the modal
4. See the error leaking in the modal itself

*Examples:
- Try to use an empty string for a first/last name `""   ""`
- Set the browser connection to offline

---
Chrome browser family
![image](https://github.com/user-attachments/assets/1ef30511-3f53-4fac-938b-b3ab421c5026)

Firefox
![image](https://github.com/user-attachments/assets/b2e884aa-7fb8-4626-b345-dedf340b14ce)


### Expected behavior

FE should be more flexible (expect that this request can fail).
FE should not leak abstract error details in the UI.

### Logs

```
console.js:13 TypeError: Cannot read properties of undefined (reading 'id')
    at user.ts:46:1
    at redux-toolkit.modern.mjs:719:1
    at Immer2.produce (immer.mjs:571:1)
    at redux-toolkit.modern.mjs:718:1
    at Array.reduce (<anonymous>)
    at reducer (redux-toolkit.modern.mjs:699:1)
    at combination (redux.mjs:315:1)
    at hu (<anonymous>:3:1043)
    at yu (<anonymous>:3:1331)
    at <anonymous>:3:4637
```

`Request entities,users,2,update failed:`
```
{
  ""status"": 400,
  ""data"": {
    ""errors"": {
      ""first_name"": ""nullable value must be a non-blank string.""
    },
    ""specific-errors"": {
      ""first_name"": [
        ""should be at least 1 characters, received: \""\"""",
        ""non-blank string, received: \""\""""
      ]
    }
  },
  ""isCancelled"": false
}
```

### Information about your Metabase installation

```JSON
local dev, `master`, da92a62, H2, Sample Database
```


### Severity

P2

### Additional context

Not sure if this is a regression or not, but I suspect not.
",nemanjaglumac,2024-08-02 16:26:52+00:00,[],2024-11-08 14:58:38+00:00,2024-11-07 15:35:12+00:00,https://github.com/metabase/metabase/issues/46449,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2295874567, 'issue_id': 2445352576, 'author': 'kamilmielnik', 'body': 'Also reported as #46938', 'created_at': datetime.datetime(2024, 8, 19, 7, 40, 26, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-08-19 07:40:26 UTC): Also reported as #46938

"
2445327633,issue,closed,completed,Not possible to update user details without both the first and the last name being set,"### Describe the bug

We've removed the requirement for the user's first and last name a few years ago.
So it's totally ok to create a user with only an email.

Trying to update such user using the UI will fail because the frontend sends empty strings instead of `null` for first/last name values.

### To Reproduce

1. Create new user with only an email
2. Click on `...` and edit user
3. Try to set only the first name, only the last name or to change anything else about this user (what matters is that we trigger `PUT` request)
4. The request will fail `400` because frontend sends empty strings

The response if we try to update only the last name:
```
{
  ""first_name"": ""nullable value must be a non-blank string.""
}
```


### Expected behavior

Frontend should send `null` as a value when first and/last names are missing.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, da92a62, H2, Sample Database
```


### Severity

P1

### Additional context

It is confirmed that this is a pure FE bug. The BE expects either `null` or non-empty string.
![image](https://github.com/user-attachments/assets/5471e18d-4010-48b6-be66-ee8b38f215c0)

This was still possible in v47 (I tried 47.6), but it broke in v48.",nemanjaglumac,2024-08-02 16:14:26+00:00,['iethree'],2024-08-06 23:35:20+00:00,2024-08-06 23:01:20+00:00,https://github.com/metabase/metabase/issues/46446,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2445240700,issue,closed,completed,Can not open model page after create a new model when language is Chinese,"### Describe the bug

Set language to Chinese， then create a model， then the model page crash

### To Reproduce

1. Set language to Chinese
2. Then create a model
3. Then the model page crash

### Expected behavior

Can display the model page

### Logs

[metabase-diagnostic-info-2024-08-02T15_27_59.927Z.json](https://github.com/user-attachments/files/16472400/metabase-diagnostic-info-2024-08-02T15_27_59.927Z.json)


### Information about your Metabase installation

```JSON
- Chrome 127
- WIndow10
- Postgres
- v0.50.18.1
- K3S
- Postgres
```


### Severity

P0

### Additional context
![1](https://github.com/user-attachments/assets/0867805b-06ce-4a2d-975e-3eaa3d4adc50)

_No response_",ouchuji,2024-08-02 15:34:56+00:00,['dpsutton'],2024-08-19 12:13:35+00:00,2024-08-06 15:49:42+00:00,https://github.com/metabase/metabase/issues/46440,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Customization/i18n', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2270898132, 'issue_id': 2445240700, 'author': 'ouchuji', 'body': 'Thank you for repair @dpsutton , and  when the pr can merge ?', 'created_at': datetime.datetime(2024, 8, 6, 10, 6, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271618895, 'issue_id': 2445240700, 'author': 'dpsutton', 'body': '@ouchuji the PR is merged to the main branch. Waiting on a merge to the release branch (https://github.com/metabase/metabase/pull/46537) and then i need to update the strings in poeditor.com.', 'created_at': datetime.datetime(2024, 8, 6, 15, 52, 9, tzinfo=datetime.timezone.utc)}]","ouchuji (Issue Creator) on (2024-08-06 10:06:36 UTC): Thank you for repair @dpsutton , and  when the pr can merge ?

dpsutton (Assginee) on (2024-08-06 15:52:09 UTC): @ouchuji the PR is merged to the main branch. Waiting on a merge to the release branch (https://github.com/metabase/metabase/pull/46537) and then i need to update the strings in poeditor.com.

"
2445055399,issue,open,,Visualization: Venn Diagram ,"**Is your feature request related to a problem? Please describe.**
I would like to show my users how my customers fall into various groups by showing overlapping group memberships. A Venn diagram visualization would be perfect for this this.

**Describe the solution you'd like**
Given data like this

Customer ID   |   Group Membership
----------------------------------------
001 | Frequent Buyers
001 | High Spenders
002 | Frequent Buyers
002 | Low Spenders
003 | Infrequent Buyers
003 | High Spenders

I would like to see a Venn diagram showing groups as coloured convex shapes. The shapes should overlap when one or more customers is in both groups. The count of customers in the groups/overlapping groups should be indicated with a count. A standard notion of a Venn diagram.


**Describe alternatives you've considered**
No found any alternatives.

**How important is this feature to you?**

Nice to have.

**Additional context**

Example showing counts and group labels

![image](https://github.com/user-attachments/assets/dbfbbef1-fd62-4168-8c43-d3acfb65d3ff)

",janekdb,2024-08-02 14:15:21+00:00,[],2025-02-04 20:30:28+00:00,,https://github.com/metabase/metabase/issues/46434,"[('Visualization/', ''), ('Type:New Feature', '')]","[{'comment_id': 2354003377, 'issue_id': 2445055399, 'author': 'stephanie-parade', 'body': '+1 would love this', 'created_at': datetime.datetime(2024, 9, 16, 20, 48, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568091837, 'issue_id': 2445055399, 'author': 'brunobergher', 'body': ""This isn't natively supported by ECharts, the library we use under the hood, but I'll keep it tracked."", 'created_at': datetime.datetime(2025, 1, 2, 17, 5, 13, tzinfo=datetime.timezone.utc)}]","stephanie-parade on (2024-09-16 20:48:37 UTC): +1 would love this

brunobergher on (2025-01-02 17:05:13 UTC): This isn't natively supported by ECharts, the library we use under the hood, but I'll keep it tracked.

"
2445038906,issue,open,,Support JSON Unfolding for Athena,"**Is your feature request related to a problem? Please describe.**
Users need to explore JSON data stored in Athena to perform analysis in Metabase

**Describe the solution you'd like**
JSON Unfolding support for Athena

**Describe alternatives you've considered**
Writing report views that explicit flatten every JSON column into a report view before syncing it into Metabase.

**How important is this feature to you?**

**Additional context**

",ixipixi,2024-08-02 14:06:37+00:00,[],2025-02-04 20:30:59+00:00,,https://github.com/metabase/metabase/issues/46433,"[('Type:New Feature', ''), ('Database/Athena', '')]","[{'comment_id': 2271578317, 'issue_id': 2445038906, 'author': 'cabarria', 'body': ""This is one of our use-cases: https://docs.aws.amazon.com/athena/latest/ug/waf-logs.html\r\n\r\nThere are several JSON objects on the table, so our users are finding other ways to deal with it outside metabase.\r\n\r\nWe have to do queries like these to unfold the JSON objects today:\r\nSELECT \r\n    p_account_id,\r\n    webaclid,\r\n    httprequest.requestid,\r\n    rl.rulegroupid,\r\n    rl.terminatingrule.ruleid AS terminating_rule_id,\r\n    rl.terminatingrule.action AS terminating_rule_action,\r\n    rmd.conditiontype AS terminating_rule_condition_type,\r\n    rmd.sensitivitylevel AS terminating_rule_sensitivity_level,\r\n    rmd.location AS terminating_rule_location,\r\n    rmd.matcheddata AS terminating_rule_matched_data,\r\n    nt.ruleid AS nonterminating_rule_id,\r\n    nt.action AS nonterminating_rule_action,\r\n    nt.overriddenaction AS nonterminating_rule_overridden_action,\r\n    ntrmd.conditiontype AS nonterminating_rule_condition_type,\r\n    ntrmd.sensitivitylevel AS nonterminating_rule_sensitivity_level,\r\n    ntrmd.location AS nonterminating_rule_location,\r\n    ntrmd.matcheddata AS nonterminating_rule_matched_data,\r\n    nt.challengeresponse.responsecode AS nonterminating_rule_challenge_response_code,\r\n    nt.challengeresponse.solvetimestamp AS nonterminating_rule_challenge_solve_timestamp,\r\n    nt.captcharesponse.responsecode AS nonterminating_rule_captcha_response_code,\r\n    nt.captcharesponse.solvetimestamp AS nonterminating_rule_captcha_solve_timestamp,\r\n    rl.excludedrules\r\nFROM \r\n    waflogs_raw_2hr\r\nCROSS JOIN UNNEST(rulegrouplist) AS t(rl)\r\nLEFT JOIN UNNEST(rl.terminatingrule.rulematchdetails) AS tm(rmd) ON TRUE\r\nLEFT JOIN UNNEST(rl.nonterminatingmatchingrules) AS nm(nt) ON TRUE\r\nLEFT JOIN UNNEST(nt.rulematchdetails) AS nmd(ntrmd) ON TRUE\r\nWHERE \r\n    p_account_id = '012345678901' AND action = 'BLOCK'\r\n    AND p_webaclname = 'somewaf' \r\n    AND p_date_min >= format_datetime(date_add('minute', -120, current_timestamp), 'yyyy/MM/dd/HH/mm') \r\nORDER BY \r\n    from_unixtime(timestamp / 1000) DESC;"", 'created_at': datetime.datetime(2024, 8, 6, 15, 31, 46, tzinfo=datetime.timezone.utc)}]","cabarria on (2024-08-06 15:31:46 UTC): This is one of our use-cases: https://docs.aws.amazon.com/athena/latest/ug/waf-logs.html

There are several JSON objects on the table, so our users are finding other ways to deal with it outside metabase.

We have to do queries like these to unfold the JSON objects today:
SELECT 
    p_account_id,
    webaclid,
    httprequest.requestid,
    rl.rulegroupid,
    rl.terminatingrule.ruleid AS terminating_rule_id,
    rl.terminatingrule.action AS terminating_rule_action,
    rmd.conditiontype AS terminating_rule_condition_type,
    rmd.sensitivitylevel AS terminating_rule_sensitivity_level,
    rmd.location AS terminating_rule_location,
    rmd.matcheddata AS terminating_rule_matched_data,
    nt.ruleid AS nonterminating_rule_id,
    nt.action AS nonterminating_rule_action,
    nt.overriddenaction AS nonterminating_rule_overridden_action,
    ntrmd.conditiontype AS nonterminating_rule_condition_type,
    ntrmd.sensitivitylevel AS nonterminating_rule_sensitivity_level,
    ntrmd.location AS nonterminating_rule_location,
    ntrmd.matcheddata AS nonterminating_rule_matched_data,
    nt.challengeresponse.responsecode AS nonterminating_rule_challenge_response_code,
    nt.challengeresponse.solvetimestamp AS nonterminating_rule_challenge_solve_timestamp,
    nt.captcharesponse.responsecode AS nonterminating_rule_captcha_response_code,
    nt.captcharesponse.solvetimestamp AS nonterminating_rule_captcha_solve_timestamp,
    rl.excludedrules
FROM 
    waflogs_raw_2hr
CROSS JOIN UNNEST(rulegrouplist) AS t(rl)
LEFT JOIN UNNEST(rl.terminatingrule.rulematchdetails) AS tm(rmd) ON TRUE
LEFT JOIN UNNEST(rl.nonterminatingmatchingrules) AS nm(nt) ON TRUE
LEFT JOIN UNNEST(nt.rulematchdetails) AS nmd(ntrmd) ON TRUE
WHERE 
    p_account_id = '012345678901' AND action = 'BLOCK'
    AND p_webaclname = 'somewaf' 
    AND p_date_min >= format_datetime(date_add('minute', -120, current_timestamp), 'yyyy/MM/dd/HH/mm') 
ORDER BY 
    from_unixtime(timestamp / 1000) DESC;

"
2444716588,issue,closed,completed,Automatically sync private with a main repo,"[context](https://metaboat.slack.com/archives/C0669P4AF9N/p1722595743400879)
",uladzimirdev,2024-08-02 11:01:35+00:00,[],2024-08-02 11:02:56+00:00,2024-08-02 11:02:56+00:00,https://github.com/metabase/metabase/issues/46425,[],"[{'comment_id': 2265122856, 'issue_id': 2444716588, 'author': 'uladzimirdev', 'body': 'duplicated', 'created_at': datetime.datetime(2024, 8, 2, 11, 2, 56, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-08-02 11:02:56 UTC): duplicated

"
2444716461,issue,open,,Automatically sync private with a main repo,[context](https://metaboat.slack.com/archives/C0669P4AF9N/p1722595743400879),uladzimirdev,2024-08-02 11:01:30+00:00,[],2024-08-02 11:03:55+00:00,,https://github.com/metabase/metabase/issues/46424,[],[],
2444701934,issue,closed,completed,Address feedback left on milestone branch,"```[tasklist]
### Tasks
- [x] Fixing type of dashboardId https://github.com/metabase/metabase/pull/46335/files#r1701489460
- [x] Add support for accessed_via sdk in https://github.com/metabase/metabase/pull/46335/files#r1700996545
```
",npretto,2024-08-02 10:53:26+00:00,['npretto'],2024-08-02 15:01:16+00:00,2024-08-02 14:51:05+00:00,https://github.com/metabase/metabase/issues/46422,[],[],
2444585865,issue,closed,completed,Remove experimental base color shades,"[From a review.](https://github.com/metabase/metabase/pull/45813#pullrequestreview-2199981367)

We started to work on some crucial [color shades and tints](https://metaboat.slack.com/archives/C02H619CJ8K/p1722531314495159?thread_ts=1721999045.118829&cid=C02H619CJ8K), but they're not ready yet.

We should remove the experiment shade, and keep only the colors in the shades we used for dark them.",WiNloSt,2024-08-02 09:56:51+00:00,['WiNloSt'],2024-08-05 10:22:30+00:00,2024-08-02 12:44:14+00:00,https://github.com/metabase/metabase/issues/46419,[],[],
2444510060,issue,closed,completed,Generate sample React component files via the embedding sdk's cli,"Modify the embedding sdk's cli to generate React component files with cards that open the x-ray as embedded dashboards. 

- Provide an ability to switch between predefined themes
- Include a link to ”edit this dashboard” that can be deleted later

[Product doc.](https://www.notion.so/metabase/CLI-connects-DB-creates-models-and-X-rays-to-embed-07c8cdd62ebf4ec7989460e000f0b9c1?pvs=4)",heypoom,2024-08-02 09:22:34+00:00,['heypoom'],2024-10-08 16:17:49+00:00,2024-08-13 13:30:14+00:00,https://github.com/metabase/metabase/issues/46417,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2444493257,issue,closed,completed,Ability to create models and x-rays from selected tables in the embedding sdk's cli,"Provide an ability for the embedding sdk's cli to allow the SDK user to select a couple of tables from their database, create models for them, and do x-rays on each model to generate dashboards for these models.

- List the database tables from the scanned database in the previous step
- Let the developer pick a couple of tables we've found
- We create models for each of these tables as-is, i.e. without any filter or summarization applied to the models.
- We perform x-rays against each of the created models from the previous step.

[Product doc.](https://www.notion.so/metabase/CLI-connects-DB-creates-models-and-X-rays-to-embed-07c8cdd62ebf4ec7989460e000f0b9c1?pvs=4)",heypoom,2024-08-02 09:15:18+00:00,['heypoom'],2024-08-08 09:34:26+00:00,2024-08-08 09:34:26+00:00,https://github.com/metabase/metabase/issues/46416,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2444448321,issue,open,,Only run markdown links tasks when md files are changed + on master,[context](https://metaboat.slack.com/archives/C5XHN8GLW/p1722522257937729),uladzimirdev,2024-08-02 08:57:34+00:00,[],2025-01-17 20:29:46+00:00,,https://github.com/metabase/metabase/issues/46415,[],[],
2444386845,issue,closed,completed,Add new database connections from the embedding sdk's cli,"Update the embedding sdk's CLI to add an ability to add new database connections for embedding their data:

- Ask the developer if they have a DB we can connect to, to embed their data: yes/no
- If yes, prompt the developer to select the type of DB (e.g. postgres, mysql, etc.); we will restrict to the top database engines to make data entry easier.
- Let the developer enter the connection details.
- Try to connect to the DB. Return to the previous step if the connection fails.
- If connection is successful, sync the DB.

[Product doc.](https://www.notion.so/metabase/CLI-connects-DB-creates-models-and-X-rays-to-embed-07c8cdd62ebf4ec7989460e000f0b9c1?pvs=4)",heypoom,2024-08-02 08:25:07+00:00,['heypoom'],2024-10-08 16:18:24+00:00,2024-08-08 09:30:44+00:00,https://github.com/metabase/metabase/issues/46412,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2444309266,issue,closed,completed,OOM errors during sync field values,"During fingerprint, we set `metabase_field.has_field_values = auto-list` for fields that have less than 1K distinct values.
Then during `update-field-values` step, we'll fetch the distinct values for these fields and insert into FieldValues table. 

The problem here is that for text fields, we don't know how long each text entry are and it's possible that it's so big that fetching 1K rows like this will blow up memory. Even though we already have a guard to not save field values if the total char length exceed `metabase.models.field-values/*total-max-length*` but this is done in clojure land, which requires fetching all rows into memory.

We should optimize this so that we cut off the field values so that it does not exceed `metabase.models.field-values/*total-max-length*` char length during query execution.",qnkhuat,2024-08-02 07:44:32+00:00,['qnkhuat'],2024-08-16 12:25:07+00:00,2024-08-08 10:34:10+00:00,https://github.com/metabase/metabase/issues/46411,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Memory Usage', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2293417261, 'issue_id': 2444309266, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.20](https://github.com/metabase/metabase/milestone/262)', 'created_at': datetime.datetime(2024, 8, 16, 12, 25, 6, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-08-16 12:25:06 UTC): 🚀 This should also be released by [v0.50.20](https://github.com/metabase/metabase/milestone/262)

"
2444281319,issue,open,,Column picker button height mismatches data picker button height on macOS,"### Describe the bug

Works fine in Chrome/Firefox on Ubuntu.
Looks like it affects only macOS.

![image](https://github.com/user-attachments/assets/84cb283c-b2ff-46b1-98b6-7fe862cdf873)

### To Reproduce

1. New > Question > Orders

### Expected behavior

Column picker button should have the same height as the data source picker button

### Information about your Metabase installation

master, a5cd7d04b8

### Severity

P3

### Additional context

Original report: https://github.com/metabase/metabase/pull/46350#discussion_r1699563080",kamilmielnik,2024-08-02 07:30:59+00:00,[],2025-02-04 20:27:52+00:00,,https://github.com/metabase/metabase/issues/46408,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2444256629,issue,open,,Notebook editor unusable after choosing data source,"### Describe the bug

I can only reproduce it in stats, and not 100% of the time.

![image](https://github.com/user-attachments/assets/693f19a5-9647-4757-aaf4-407931b2c5ce)



### To Reproduce

1. Go to stats
2. New > Question
3. Search for [""Content"" model](https://stats.metabase.com/model/14230-content) in ""Metabase analytics"" collection and choose it. Entity picker modal will get closed.
4. Notebook editor only contains the data step

If this didn't reproduce the issue, go back to main page in stats, refresh the page, and repeat the repro steps.

### Expected behavior

It's possible to add more steps in the notebook editor

### Information about your Metabase installation

master, a5cd7d04b8


### Severity

P2
",kamilmielnik,2024-08-02 07:17:24+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/46406,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2427004454, 'issue_id': 2444256629, 'author': 'ranquild', 'body': ""Managed to reproduce it using this model. It seems that it should be the same case with any audit v2 model.\n\nThe underlying problem is that `/api/table/card__:id/query_metadata` doesn't not hydrate the database now. Please note that that database should be hydrated (i.e. including in the table) only for this endpoint and not batch `query_metadata` endpoints because there is a separate list of databases returned with each call."", 'created_at': datetime.datetime(2024, 10, 21, 15, 24, 42, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-10-21 15:24:42 UTC): Managed to reproduce it using this model. It seems that it should be the same case with any audit v2 model.

The underlying problem is that `/api/table/card__:id/query_metadata` doesn't not hydrate the database now. Please note that that database should be hydrated (i.e. including in the table) only for this endpoint and not batch `query_metadata` endpoints because there is a separate list of databases returned with each call.

"
2444202899,issue,open,,Improve TypeScript Typing and Code Consistency in Styled Components,"
frontend/src/metabase/visualizations/components/TableSimple/TableCell.styled.tsx

- Ensure that all props are correctly typed throughout the components.
- Use more descriptive class names or component names to improve readability and maintainability.
- possibly look at changing fixed units like rem for padding and margins if the design requires more flexibility. ",jmoore191,2024-08-02 06:48:32+00:00,[],2024-08-02 06:48:32+00:00,,https://github.com/metabase/metabase/issues/46405,[],[],
2443999480,issue,closed,completed,OOM when sending anon stats,"We have an OOM case while sending anon stats.

Looking at the stack trace, it points to this [line](https://github.com/metabase/metabase/blob/72a201819b3255c3753591297f90f05819d200cc/src/metabase/analytics/stats.clj#L368) in which we do a reducible select on QueryExecution table.

Even though we're selecting reducible, I suspect the OOM is caused by:
- the fact that this table is unbounded (e.g: we have 3M rows on stat) asking product whether we can bound this query [here](https://metaboat.slack.com/archives/C01LQQ2UW03/p1722572166303169)
- query_execution.error is a text field that often has a long stack trace

see [this](https://metaboat.slack.com/archives/C010ZSXQY87/p1721999716487909?thread_ts=1721939174.598129&cid=C010ZSXQY87) for stacktrace",qnkhuat,2024-08-02 04:22:55+00:00,[],2024-08-05 07:27:56+00:00,2024-08-02 09:29:03+00:00,https://github.com/metabase/metabase/issues/46403,"[('Priority:P2', 'Average run of the mill bug'), ('.Memory Usage', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2268364793, 'issue_id': 2443999480, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)', 'created_at': datetime.datetime(2024, 8, 5, 7, 27, 55, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-08-05 07:27:55 UTC): 🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)

"
2443610963,issue,open,,Navigating to question + `/notebook` should result in permission error screen for users without write query permissions,"### Describe the bug

User has curate collection permissions. No query permissions.
If they open a question, we show them a simple mode, and the notebook icon is hidden. All is good.

However, that user can manually add `/notebook` to the url.
We will show them notebook without the ""visualize"" button and without the ability to save their changes. Nothing unpredictable happens, but it would probably be more correct to show them the permissions error screen instead.

### To Reproduce

1. Log in as a user with curate collection permissions and no query permissions
2. Open any question
3. Notice that the notebook icon is missing
4. Append the `/notebook` to the url
5. You will land on a notebook mode of that question, but you can't save your changes (which is correct)


### Expected behavior

""You don't have permissions to do/see that"" page should be shown instead.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, cd6cadf, H2, Sample Database
```


### Severity

P3

### Additional context

_No response_",nemanjaglumac,2024-08-01 22:42:15+00:00,[],2024-08-02 01:16:24+00:00,,https://github.com/metabase/metabase/issues/46398,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Permissions', 'Collection or Data permissions'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2443543603,issue,closed,completed,Stacked Row Chart Includes Empty Values in Tooltip,"### Describe the bug

If there are empty values in the results for a row in a stacked chart - the empty row is included in the tooltip.

### To Reproduce

1. Set up Metabase v50
2. Create a question that can be used to emulate empty results for some fields in a breakout:

`SELECT  CITY,  STATE,  COUNT(*) AS COUNT
FROM PUBLIC.PEOPLE
GROUP BY CITY, STATE
UNION
SELECT  CITY,  'XX' AS STATE,  NULL AS COUNT
FROM PUBLIC.PEOPLE
GROUP BY CITY, 'XX'
LIMIT 25`

3. Display the results as a stacked row chart
4. Hover over one of the bars and see the empty values are displayed in the tooltip

![stacked_row](https://github.com/user-attachments/assets/643367df-d6ea-4c76-8c8f-0b389985eb69)

### Expected behavior

The empty fields shouldn't be hidden from the tooltip

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.13
```


### Severity

annoying

### Additional context

_No response_",ixipixi,2024-08-01 21:51:24+00:00,['alxnddr'],2024-09-04 14:08:35+00:00,2024-08-28 01:59:55+00:00,https://github.com/metabase/metabase/issues/46396,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Visualization/Charts/Row', ''), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2442829978,issue,closed,completed,Permissions modal cannot be dismissed if network request fails,"### Describe the bug

If for some reason, the request `/api/setting/show-updated-permission-modal` errors, users are unable to access the permissions page because the modal cannot be dismissed

### To Reproduce

Not generally reproduceable. The call to `/api/setting/show-updated-permission-modal` would need to be intercepted and stubbed with a 500 error.


### Expected behavior

The modal should be dismissable regardless of of network status

### Logs

_No response_

### Information about your Metabase installation

```JSON
Current master
SHA: 8005283addc6f364199dce96d62a2cd6a73a5d6b
```


### Severity

P1 when it happens

### Additional context

_No response_",npfitz,2024-08-01 16:01:29+00:00,['npfitz'],2024-08-02 09:33:44+00:00,2024-08-01 17:23:03+00:00,https://github.com/metabase/metabase/issues/46380,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2442814335,issue,closed,completed,"No Permissions Migration Path for  a DB with ""All Users = Blocked"" and ""OtherGroup = Granular Access"" (if it includes NSS)","### Describe the bug

There is no permissions migration path for users in a combination of groups where DB access is se tup such that:

- ""All Users"" on ""ThisDB"" = Blocked
- ""OtherGroup"" on ""ThisDB"" has Granular access that includes ""No Self Service""

Loom recording: https://www.loom.com/share/05d6cf4b094149ffaf1040532df89144

### To Reproduce

In version 49 if you have permissions such that:

- ""All Users"" for TestDB 2 is set to ""Blocked""
- ""Some Group"" has ""No Self Service"" permissions for 3 tables in TestDB
- ""Some Group"" has ""Can View"" for the remaining tables in TestDB

The behavior in 49 is:

- Any Questions built on the 3 tables w/ ""No Self Service"" will not load for the user
- The user is presented with ""Blocked: you are not allowed to run queries against Database 2.""

Now we migrate to 50:
The migration does what we expect:

- ""All Users"" for TestDB 2 is still set to ""Blocked""
- ""Some Group"" has ""No Self Service (Deprecated)"" permissions for 3 tables in TestDB
- ""Some Group"" has ""Can View"" for the remaining tables in TestDB

The behavior in v50 now is:

- Any Questions built on the 3 tables w/ ""No Self Service (Deprecated)"" will not load for the user
- The user is still presented with ""Blocked: you are not allowed to run queries against Database 2.""


Given the above scenario:

Once the granular tables permissions are migrated to ""No Self Service"" there is no selection the customer can make in the new permissions model that preserve the behavior they had in v49. If they set the DB to ""Block"", the tables with view permissions become blocked. If they change the ""No Self Service (Deprecated"" to a viewable setting then it grants users access they didn't have in 49.

### Expected behavior

Customers need a path to map the prior behavior in 49 to the permissions available in 50.

### Logs

_No response_

### Information about your Metabase installation

```JSON
v49 -> v50
```


### Severity

The migrated behavior works

### Additional context

Technically, when we migrate to 50 the behavior is preserved as long as the ""No Self Service (Deprecated)"" permissions is never change don the table. However, we indicated in our communication to the customers and the docs that we will auto migrate these to ""Blocked"" if no action is taken. It's unclear what this migration will look like in a scenario where the database access is granular. It seems like if we migrate in a way that fits the current permission model it would be a breaking change for customers.

Slack convo: https://metaboat.slack.com/archives/C01LQQ2UW03/p1722464765960849",ixipixi,2024-08-01 15:53:31+00:00,[],2024-08-19 22:42:05+00:00,2024-08-19 22:42:05+00:00,https://github.com/metabase/metabase/issues/46379,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2442755320,issue,closed,completed,Polishing,"```[tasklist]
### Tasks
- [x] Align Metabase badge with cards on dashboard (easy)
- [x] Don't rerender preview when changing dashboard with tabs' look and feel options (easy)
```
",WiNloSt,2024-08-01 15:24:51+00:00,['WiNloSt'],2024-08-02 09:56:15+00:00,2024-08-02 09:56:15+00:00,https://github.com/metabase/metabase/issues/46378,[],[],
2442698131,issue,open,,Security middleware cannot parse urls ending with a slash,"Checking logs and seeing lots of logs like this on every request:

```
ERROR middleware.security :: Invalid URL: https://<URL>/
ERROR middleware.security :: Invalid URL: https://<URL>/
ERROR middleware.security :: Invalid URL: http://localhost:3456/
ERROR middleware.security :: Invalid URL: http://localhost:8080/
ERROR middleware.security :: Invalid URL: http://localhost:9000/
```

and checking the `parse-url` function:

```clojure
security=> (parse-url ""http://localhost:9000/"")
nil
security=> (parse-url ""http://localhost:9000"")
{:protocol ""http"", :domain ""localhost"", :port ""9000""}
```

This trailing slash should not be load-bearing.",dpsutton,2024-08-01 14:59:28+00:00,[],2025-02-05 19:04:20+00:00,,https://github.com/metabase/metabase/issues/46377,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2442598777,issue,closed,completed,Embedded dashboard with optional locked filter doesn't work anymore when no value provided for this filter,"### Describe the bug

I have an embedded dashboard that has three filters (two are locked and one is editable).
We always provide a value for the first filter so no issue here. The third filter (a date filter) works fine and as expected.
The issue comes from the second filter which is an optional locked text filter. When in the Metabase dashboard, the dashboard loads fine without inputting any value in that filter. Though, when getting the url for the embedded dashboard from the API, when we do not provide a value for that filter, the API responds with a 400 and an issue that looks something like 'You must provide in the JWT a value for :commercantId' (the name of our filter).

This worked perfectly fine in v.0.50.13 but starting to fail as soon as I upgraded to v.0.50.18. As this is live in our production environment, I'd rather not try again until traffic on our website is lower so I don't have the exact logs. I had to downgrade back to v0.50.13 to make it work.

Thanks in advance for your help,
Arnaud Baboulin

### To Reproduce

1. Make sure you're in v0.50.18
2. Create a dashboard with an optional text filter
3. Publish it to make it available for embedding
4. Set that filter to locked 
5. Try getting the corresponding url from the API without giving any value to the filter

### Expected behavior

It should work as previously (v0.50.13), an optional filter should not prevent the dashboard to be loaded even if no value is provided for it

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-94-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v0.50.13"",
      ""hash"": ""2086968""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking our users, preventing us from upgrading to any version after v0.50.13

### Additional context

_No response_",ArnaudBab,2024-08-01 14:15:58+00:00,[],2024-08-01 17:57:18+00:00,2024-08-01 17:51:49+00:00,https://github.com/metabase/metabase/issues/46375,"[('Type:Bug', 'Product defects'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2263632846, 'issue_id': 2442598777, 'author': 'albertoperdomo', 'body': 'Hello @ArnaudBab,\r\n\r\nwe recently tightened the usage of locked params to fix some other issues. The behavior you are describing (omitting the locked param value in the JWT) was unintended.\r\n\r\nFrom [the docs](https://www.metabase.com/docs/latest/embedding/static-embedding-parameters#include-all-locked-parameters-in-your-server-code):\r\n\r\n>Once you publish a chart or dashboard with a locked parameter, **you must include the name of the locked parameter in your server code.**\r\n\r\nTL;DR\r\n* If you include a locked filter, you need to pass a value in the JWT\r\n* If you want to skip the effect of that locked filter, you can pass `[]` as value in the JWT\r\n\r\nI think this is the change you need to do in order for it to work with the latest version. Please let me know if you have any follow up questions or comments.', 'created_at': datetime.datetime(2024, 8, 1, 17, 51, 49, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-08-01 17:51:49 UTC): Hello @ArnaudBab,

we recently tightened the usage of locked params to fix some other issues. The behavior you are describing (omitting the locked param value in the JWT) was unintended.

From [the docs](https://www.metabase.com/docs/latest/embedding/static-embedding-parameters#include-all-locked-parameters-in-your-server-code):


TL;DR
* If you include a locked filter, you need to pass a value in the JWT
* If you want to skip the effect of that locked filter, you can pass `[]` as value in the JWT

I think this is the change you need to do in order for it to work with the latest version. Please let me know if you have any follow up questions or comments.

"
2442489317,issue,open,,auto-connected message has unexpected scroll on dashcard parameter mapping,"**Context**

if you enable auto-wire on dashcard mapping page and  a message ""auto-connected"" is shown, it has unexpected scoll

<img width=""693"" alt=""image"" src=""https://github.com/user-attachments/assets/5e90f03c-84a7-4177-ba45-26b72cbdd847"">
<img width=""656"" alt=""image"" src=""https://github.com/user-attachments/assets/f986a713-1082-426c-bf13-d4db869e5114"">


- issue links: 
introduced seems in https://github.com/metabase/metabase/issues/45550
",uladzimirdev,2024-08-01 13:35:28+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/46372,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2442478521,issue,open,,Browse follow-ups,"```[tasklist]
- [x] Move the browsing node on left nav to the bottom after collections (https://github.com/metabase/metabase/pull/46457)
- [x] Change the browsing models page to full width from previously centered and fixed width. https://github.com/metabase/metabase/pull/46458
- [x] Change the models table to 3 evenly-distributed columns with a responsive priority from left to right. When screen is large, show 3 columns. Then hide descriptions, and finally collections. Always show names. https://github.com/metabase/metabase/pull/46458
- [x] Change the recent cards from previous fixed width to 4 cards per row up to 8 cards totally. Make them responsive when screen is smaller to 3, 2 and 1 cards accordingly. https://github.com/metabase/metabase/pull/46458
- [x] Simplify collection paths #46530
- [ ] Don't pull all recents but just the recent models using the new API
```",rafpaf,2024-08-01 13:31:37+00:00,[],2025-01-14 18:57:53+00:00,,https://github.com/metabase/metabase/issues/46371,[],[],
2442332172,issue,closed,completed,Sorting after Aggregation breaks Questions used to populate Filter Values,"### Describe the bug

If you create a question that has a sort after an aggregate and you proceed to use this question to populate a filter value it will simply break. This was working on 49 and breaks in 50 so upgrading will simply break your filters

### To Reproduce

1. Create a question with an aggregate like [this](https://stats.metabase.com/question/18989-products-grouped-and-sorted-by-count/notebook)

<img width=""939"" alt=""image"" src=""https://github.com/user-attachments/assets/185ba3f3-31ba-4f3a-a778-71a119db359d"">

2. Use this question as a base to populate a filter dropdown -> [New Dashboard](https://stats.metabase.com/dashboard/2553-test-filter-dropdown?text=) -> Add Text Filter -> Edit Dropdown list -> Add the question above:

<img width=""1421"" alt=""image"" src=""https://github.com/user-attachments/assets/22d65406-8510-47cd-b62d-88c1f3078f18"">



### Expected behavior

Able to connect the question with a drop down filter similar to verison 49

### Logs

`Error creating query from legacy query: Error converting :aggregation reference: no aggregation at index 0`

Full logs:

```
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message
   ""Error preprocessing query in #'metabase.query-processor.middleware.normalize-query/normalize-preprocessing-middleware: Error normalizing query: Error creating query from legacy query: Error converting :aggregation reference: no aggregation at index 0"",
   :data
   {:fn #'metabase.query-processor.middleware.normalize-query/normalize-preprocessing-middleware,
    :query
    {:database 1,
     :type :query,
     :query
     {:source-table 3,
      :breakout [[""field"" 16 {:base-type ""type/Text""}]],
      :order-by [[:asc [:aggregation 0]]],
      :limit 1000,
      :filter [:and [:not-empty [""field"" 16 {:base-type ""type/Text""}]] nil]},
     :middleware {:disable-remaps? true}},
    :type :qp},
   :at [metabase.query_processor.preprocess$preprocess$fn__69298$fn__69299 invoke ""preprocess.clj"" 150]}
  {:type clojure.lang.ExceptionInfo,
   :message
   ""Error normalizing query: Error creating query from legacy query: Error converting :aggregation reference: no aggregation at index 0"",
   :data
   {:type :qp,
    :query
    {:database 1,
     :type :query,
     :query
     {:source-table 3,
      :breakout [[""field"" 16 {:base-type ""type/Text""}]],
      :order-by [[:asc [:aggregation 0]]],
      :limit 1000,
      :filter [:and [:not-empty [""field"" 16 {:base-type ""type/Text""}]] nil]},
     :middleware {:disable-remaps? true}}},
   :at
   [metabase.query_processor.middleware.normalize_query$normalize_preprocessing_middleware
    invokeStatic
    ""normalize_query.clj""
    41]}
  {:type clojure.lang.ExceptionInfo,
   :message
   ""Error creating query from legacy query: Error converting :aggregation reference: no aggregation at index 0"",
   :data
   {:legacy-query
    {:database 1,
     :type :query,
     :query
     {:source-table 3,
      :breakout [[""field"" 16 {:base-type ""type/Text""}]],
      :order-by [[:asc [:aggregation 0]]],
      :limit 1000,
      :filter [:and [:not-empty [""field"" 16 {:base-type ""type/Text""}]] nil]},
     :middleware {:disable-remaps? true}}},
   :at [metabase.lib.query$query_from_legacy_query invokeStatic ""query.cljc"" 167]}
  {:type clojure.lang.ExceptionInfo,
   :message ""Error converting :aggregation reference: no aggregation at index 0"",
   :data {:clause [:aggregation 0]},
   :at [metabase.lib.convert$fn__30413 invokeStatic ""convert.cljc"" 280]}],
 :trace
 [[metabase.lib.convert$fn__30413 invokeStatic ""convert.cljc"" 280]
  [metabase.lib.convert$fn__30413 invoke ""convert.cljc"" 276]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 229]
  [clojure.core$map$fn__5931$fn__5932 invoke ""core.clj"" 2759]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8234 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8234 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$transduce invokeStatic ""core.clj"" 6948]
  [clojure.core$into invokeStatic ""core.clj"" 6963]
  [clojure.core$into invoke ""core.clj"" 6951]
  [metabase.lib.convert$default_MBQL_clause__GT_pMBQL invokeStatic ""convert.cljc"" 112]
  [metabase.lib.convert$default_MBQL_clause__GT_pMBQL invoke ""convert.cljc"" 104]
  [metabase.lib.convert$fn__30327 invokeStatic ""convert.cljc"" 118]
  [metabase.lib.convert$fn__30327 invoke ""convert.cljc"" 114]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 229]
  [clojure.core$mapv$fn__8535 invoke ""core.clj"" 6980]
  [clojure.lang.PersistentVector reduce ""PersistentVector.java"" 343]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$mapv invokeStatic ""core.clj"" 6971]
  [clojure.core$mapv invoke ""core.clj"" 6971]
  [metabase.lib.convert$fn__30375 invokeStatic ""convert.cljc"" 221]
  [metabase.lib.convert$fn__30375 invoke ""convert.cljc"" 219]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 229]
  [clojure.core$update invokeStatic ""core.clj"" 6232]
  [clojure.core$update invoke ""core.clj"" 6224]
  [metabase.lib.convert$fn__30353$fn__30360$fn__30361 invoke ""convert.cljc"" 197]
  [clojure.core.protocols$iter_reduce invokeStatic ""protocols.clj"" 49]
  [clojure.core.protocols$fn__8230 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8230 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [metabase.lib.convert$fn__30353$fn__30360 invoke ""convert.cljc"" 193]
  [metabase.lib.convert$do_with_aggregation_list invokeStatic ""convert.cljc"" 170]
  [metabase.lib.convert$do_with_aggregation_list invoke ""convert.cljc"" 157]
  [metabase.lib.convert$fn__30353 invokeStatic ""convert.cljc"" 189]
  [metabase.lib.convert$fn__30353 invoke ""convert.cljc"" 179]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 229]
  [clojure.core$mapv$fn__8535 invoke ""core.clj"" 6980]
  [clojure.lang.PersistentVector reduce ""PersistentVector.java"" 343]
  [clojure.core$reduce invokeStatic ""core.clj"" 6886]
  [clojure.core$mapv invokeStatic ""core.clj"" 6971]
  [clojure.core$mapv invoke ""core.clj"" 6971]
  [metabase.lib.convert$fn__30377$fn__30378 invoke ""convert.cljc"" 228]
  [clojure.core$update invokeStatic ""core.clj"" 6232]
  [clojure.core$update invoke ""core.clj"" 6224]
  [metabase.lib.convert$fn__30377 invokeStatic ""convert.cljc"" 227]
  [metabase.lib.convert$fn__30377 invoke ""convert.cljc"" 223]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 229]
  [metabase.lib.query$query_from_legacy_query$fn__30725 invoke ""query.cljc"" 161]
  [metabase.lib.query$query_from_legacy_query invokeStatic ""query.cljc"" 160]
  [metabase.lib.query$query_from_legacy_query invoke ""query.cljc"" 157]
  [metabase.lib.query$fn__30735 invokeStatic ""query.cljc"" 181]
  [metabase.lib.query$fn__30735 invoke ""query.cljc"" 179]
  [clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
  [metabase.lib.query$query invokeStatic ""query.cljc"" 280]
  [metabase.lib.query$query invoke ""query.cljc"" 274]
  [metabase.query_processor.middleware.normalize_query$normalize_STAR_ invokeStatic ""normalize_query.clj"" 21]
  [metabase.query_processor.middleware.normalize_query$normalize_STAR_ invoke ""normalize_query.clj"" 13]
  [metabase.query_processor.middleware.normalize_query$normalize_preprocessing_middleware
   invokeStatic
   ""normalize_query.clj""
   38]
  [metabase.query_processor.middleware.normalize_query$normalize_preprocessing_middleware
   invoke
   ""normalize_query.clj""
   33]
  [clojure.lang.Var invoke ""Var.java"" 384]
  [metabase.query_processor.preprocess$preprocess$fn__69298$fn__69299 invoke ""preprocess.clj"" 134]
  [clojure.lang.PersistentVector reduce ""PersistentVector.java"" 343]
  [clojure.core$transduce invokeStatic ""core.clj"" 6947]
  [clojure.core$transduce invoke ""core.clj"" 6934]
  [metabase.query_processor.preprocess$preprocess$fn__69298 invoke ""preprocess.clj"" 124]
  [metabase.query_processor.setup$do_with_qp_setup invokeStatic ""setup.clj"" 225]
  [metabase.query_processor.setup$do_with_qp_setup invoke ""setup.clj"" 216]
  [metabase.query_processor.preprocess$preprocess invokeStatic ""preprocess.clj"" 122]
  [metabase.query_processor.preprocess$preprocess invoke ""preprocess.clj"" 118]
  [metabase.query_processor$process_query_STAR__STAR_ invokeStatic ""query_processor.clj"" 46]
  [metabase.query_processor$process_query_STAR__STAR_ invoke ""query_processor.clj"" 44]
  [metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__82833$handle_audit_app_internal_queries__82834$fn__82835
   invoke
   ""handle_audit_queries.clj""
   145]
  [metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__68441
   invoke
   ""enterprise.clj""
   103]
  [metabase.query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__73777
   invoke
   ""process_userland_query.clj""
   182]
  [metabase.query_processor.middleware.catch_exceptions$catch_exceptions$fn__73832 invoke ""catch_exceptions.clj"" 121]
  [metabase.query_processor$process_query$fn__73871 invoke ""query_processor.clj"" 80]
  [metabase.query_processor.setup$do_with_canceled_chan$fn__68845 invoke ""setup.clj"" 189]
  [metabase.query_processor.setup$do_with_database_local_settings$fn__68840 invoke ""setup.clj"" 181]
  [metabase.query_processor.setup$do_with_driver$fn__68835$fn__68836 invoke ""setup.clj"" 166]
  [metabase.driver$do_with_driver invokeStatic ""driver.clj"" 106]
  [metabase.driver$do_with_driver invoke ""driver.clj"" 101]
  [metabase.query_processor.setup$do_with_driver$fn__68835 invoke ""setup.clj"" 165]
  [metabase.query_processor.setup$do_with_metadata_provider$fn__68828$fn__68831 invoke ""setup.clj"" 151]
  [metabase.query_processor.store$do_with_metadata_provider invokeStatic ""store.clj"" 171]
  [metabase.query_processor.store$do_with_metadata_provider invoke ""store.clj"" 151]
  [metabase.query_processor.store$do_with_metadata_provider invokeStatic ""store.clj"" 160]
  [metabase.query_processor.store$do_with_metadata_provider invoke ""store.clj"" 151]
  [metabase.query_processor.setup$do_with_metadata_provider$fn__68828 invoke ""setup.clj"" 150]
  [metabase.query_processor.setup$do_with_resolved_database$fn__68822 invoke ""setup.clj"" 128]
  [metabase.query_processor.setup$do_with_qp_setup invokeStatic ""setup.clj"" 232]
  [metabase.query_processor.setup$do_with_qp_setup invoke ""setup.clj"" 216]
  [metabase.query_processor$process_query invokeStatic ""query_processor.clj"" 78]
  [metabase.query_processor$process_query invoke ""query_processor.clj"" 71]
  [metabase.query_processor$process_query invokeStatic ""query_processor.clj"" 74]
  [metabase.query_processor$process_query invoke ""query_processor.clj"" 71]
  [metabase.models.params.custom_values$values_from_card invokeStatic ""custom_values.clj"" 109]
  [metabase.models.params.custom_values$values_from_card invoke ""custom_values.clj"" 88]
  [metabase.models.params.custom_values$card_values invokeStatic ""custom_values.clj"" 121]
  [metabase.models.params.custom_values$card_values invoke ""custom_values.clj"" 116]
  [metabase.models.params.custom_values$parameter__GT_values invokeStatic ""custom_values.clj"" 144]
  [metabase.models.params.custom_values$parameter__GT_values invoke ""custom_values.clj"" 131]
  [metabase.api.dataset$parameter_values invokeStatic ""dataset.clj"" 215]
  [metabase.api.dataset$parameter_values invoke ""dataset.clj"" 211]
  [metabase.api.dataset$fn__98107 invokeStatic ""dataset.clj"" 224]
  [metabase.api.dataset$fn__98107 invoke ""dataset.clj"" 219]
  [compojure.core$wrap_response$fn__52477 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__52461 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__52466 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__98122 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52517 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [metabase.api.routes$fn__105628$fn__105629 invoke ""routes.clj"" 69]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__105904$fn__105905 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52517 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52470 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52517 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489$f__52490$respond_SINGLEQUOTE___52491 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52521 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52489$f__52490 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52489 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__102178 invoke ""exceptions.clj"" 107]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__102175 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__108350$fn__108351$fn__108352 invoke ""log.clj"" 236]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__108350$fn__108351 invoke ""log.clj"" 227]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__108350 invoke ""log.clj"" 226]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__114765 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__102134 invoke ""security.clj"" 240]
  [ring.middleware.json$wrap_json_body$fn__115024 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__88323 invoke ""offset_paging.clj"" 49]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54030 invoke ""json.clj"" 88]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__115113 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__115132 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__71498 invoke ""misc.clj"" 60]
  [metabase.server.middleware.session$reset_session_timeout$fn__78182 invoke ""session.clj"" 568]
  [metabase.server.middleware.session$bind_current_user$fn__78148$fn__78149 invoke ""session.clj"" 462]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 441]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 424]
  [metabase.server.middleware.session$bind_current_user$fn__78148 invoke ""session.clj"" 461]
  [metabase.server.middleware.session$wrap_current_user_info$fn__78123 invoke ""session.clj"" 385]
  [metabase.analytics.sdk$bind_embedding_mw$bound_embedding__35244 invoke ""sdk.clj"" 31]
  [metabase.server.middleware.session$wrap_session_id$fn__78095 invoke ""session.clj"" 261]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__98130 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__114952 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__71480 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__71506 invoke ""misc.clj"" 77]
  [ring.middleware.gzip$wrap_gzip$fn__114994 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.request_id$wrap_request_id$fn__106316 invoke ""request_id.clj"" 9]
  [metabase.server.middleware.misc$bind_request$fn__71509 invoke ""misc.clj"" 94]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__114781 invoke ""ssl.clj"" 51]
  [metabase.server$async_proxy_handler$fn__71844 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause ""Error converting :aggregation reference: no aggregation at index 0"",
 :data {:clause [:aggregation 0]},
 :message
 ""Error preprocessing query in #'metabase.query-processor.middleware.normalize-query/normalize-preprocessing-middleware: Error normalizing query: Error creating query from legacy query: Error converting :aggregation reference: no aggregation at index 0"",
 :fn #'metabase.query-processor.middleware.normalize-query/normalize-preprocessing-middleware,
 :query
 {:database 1,
  :type :query,
  :query
  {:source-table 3,
   :breakout [[""field"" 16 {:base-type ""type/Text""}]],
   :order-by [[:asc [:aggregation 0]]],
   :limit 1000,
   :filter [:and [:not-empty [""field"" 16 {:base-type ""type/Text""}]] nil]},
  :middleware {:disable-remaps? true}}}
```

### Information about your Metabase installation

```JSON
master
```


### Severity

Blocker cause it breaks dashboards

### Additional context

_No response_",Tony-metabase,2024-08-01 12:30:17+00:00,['lbrdnk'],2024-08-28 02:09:03+00:00,2024-08-02 17:24:01+00:00,https://github.com/metabase/metabase/issues/46369,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Escalation', ''), ('.Team/Querying', '')]",[],
2442224927,issue,closed,completed,Keys with null values are missing in `last_used_param_values`,"### Describe the bug

https://github.com/user-attachments/assets/946697d0-b31e-4388-8175-a57b1e353684



### To Reproduce

1. Create a question based on Orders table and add it to a dashboard
2. Create a non-required dashboard filter with default value and connect it to the question, save dashboard
3. Clear filter value
4. Close the dashboard 
5. Open it again (e.g. from command palette)

Actual: filter value is the default value
Expected: filter value should be empty


### Information about your Metabase installation

master, 683faf64e9122ee964e2740b29246e755e02140a


### Severity

P2

### Additional context

Original report: https://metaboat.slack.com/archives/C0645JP1W81/p1722447097137469?thread_ts=1722436543.931399&cid=C0645JP1W81

Related product doc: https://www.notion.so/metabase/Preserve-dashboard-filter-states-for-users-0f89ff0da0c24026a3692b0f9d704fed
Related PR: #40415

It looks like `last_used_param_values` do not include keys with `null` values (GET `/api/dashboard/:id`).",kamilmielnik,2024-08-01 11:36:35+00:00,[],2024-08-09 02:05:35+00:00,2024-08-09 00:44:36+00:00,https://github.com/metabase/metabase/issues/46368,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2442032729,issue,open,,BE: Introduce a mechanism that alerts when sync + fingerprinting fully finished,"**Is your feature request related to a problem? Please describe.**
There is currently no way to reliably determine when all fields metadata and values are populated.
We have the `database.initial_sync_status` and `table.initial_sync_status` but that still doesn't mean we have the field values.

The process currently works like this (as explained by @qnkhuat )
```
start sync
sync table and fields
mark initial_sync_status to complete
analyze db (fingerprinting stuff)
sync field values
done sync
```

Sync has three steps
1. sync metadata (tables , fields)
2. analyze (fingerprint the fields)
3. sync field values

What we need is another signal from a backend after this whole chain finishes successfully.

**Describe the solution you'd like**
Something similar to `initial_sync_status`.

**How important is this feature to you?**
P1.
We're seeing some false positives or even plain wrong E2E tests because there is no way to reliably determine when all fields metadata and values are populated.

**Additional context**
[This is an example](https://github.com/metabase/metabase/pull/45887#discussion_r1690066853) of yet another patch/tweak we've introduced to the E2E database helpers because we realized we don't have the necessary field information. A few E2E tests changed behavior as a result of this intervention!

Additionally, [it this Slack thread](https://metaboat.slack.com/archives/C05MPF0TM3L/p1722504739157009) we're discussing intermittent failures of a test that's been marked as flaky when in reality it's literally wrong. tl;dr It shows a plain input field instead of a dropdown because it's missing field values.",nemanjaglumac,2024-08-01 10:00:43+00:00,[],2025-02-04 20:30:44+00:00,,https://github.com/metabase/metabase/issues/46364,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', ''), ('Administration/Table Metadata', ''), ('.Team/Querying', '')]","[{'comment_id': 2322093621, 'issue_id': 2442032729, 'author': 'paoliniluis', 'body': 'Another use case for the webhook @luizarakaki', 'created_at': datetime.datetime(2024, 8, 30, 18, 14, 4, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-08-30 18:14:04 UTC): Another use case for the webhook @luizarakaki

"
2441282236,issue,closed,not_planned,"When using API keys, we use a lot of CPU time for cryptographic operations","### Describe the bug

Something I just discovered doing load testing: when using API keys, there's a lot of CPU time for crypto operations, which doesn't happen if you're using a normal session token. The load was so big that it was using all the cpu's for a small amount of users


### To Reproduce

1) do a load test with an api key
![image](https://github.com/user-attachments/assets/630d3529-206f-4ee2-a746-01f6e6a837df)


### Expected behavior

It shouldn't be this hard for the CPU

### Logs

NA

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-08-01 02:14:01+00:00,[],2024-08-01 08:24:44+00:00,2024-08-01 08:24:44+00:00,https://github.com/metabase/metabase/issues/46358,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2262347376, 'issue_id': 2441282236, 'author': 'darksciencebase', 'body': 'from @dpsutton \r\n>this is by design and necessary.\r\nWhen a user logs in once, we don’t compare their password to a copy of it in the db, we do some cryptographic work on it and compare that. The point is that we don’t have a copy of a way to become that user. You must know it.\r\nOnce proven that the password hashes to what we have in the db, we give them a once time token that we compare for equality. This does live in the app-db (in the session table) but new ones are generated on each login.\r\nFor an API key, there’s no negotiation like this: the key must always work. So there are two options for how this can work:\r\nGenerate a token and compare that to the database each time. This is really quick: just fetch the db and compare two strings. The problem here is that anyone with db access can act as that user in our system.\r\nHave keys in the headers, but require them to go through the same hashing work that happens when a user logs in but do it on every API request. We do this work here.\r\nThe consequence of this is that we are doing the work of a login on every request.', 'created_at': datetime.datetime(2024, 8, 1, 8, 24, 44, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-08-01 08:24:44 UTC): from @dpsutton 
When a user logs in once, we don’t compare their password to a copy of it in the db, we do some cryptographic work on it and compare that. The point is that we don’t have a copy of a way to become that user. You must know it.
Once proven that the password hashes to what we have in the db, we give them a once time token that we compare for equality. This does live in the app-db (in the session table) but new ones are generated on each login.
For an API key, there’s no negotiation like this: the key must always work. So there are two options for how this can work:
Generate a token and compare that to the database each time. This is really quick: just fetch the db and compare two strings. The problem here is that anyone with db access can act as that user in our system.
Have keys in the headers, but require them to go through the same hashing work that happens when a user logs in but do it on every API request. We do this work here.
The consequence of this is that we are doing the work of a login on every request.

"
2441164184,issue,closed,not_planned,Duplicate tables in filter modal when summarizing by a foreign key column ,"### Describe the bug

When summarizing by a foreign key column, the filter modal shows the joined table twice. 

[See slack thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1722451325908009)

![image](https://github.com/user-attachments/assets/89f0c09d-b7aa-4120-9baa-144d81fc292a)

For comparison, when summarizing by the same column but picked from the auto-joined table instead, the joined table is only shown once.


### To Reproduce

1. Create a GUI question in the sample database: Count` of Orders` by Product ID. Use the `Product ID` column or Orders. (not `Product->ID `column from Products)
3. In the table view, open the filter modal
4. Products table will appear in the modal twice

_Note: if summarizing by `Product->ID` instead, the Products table will only appear in the modal once_

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.12-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1 (Debian 16.1-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-30"",
      ""tag"": ""v1.50.18"",
      ""hash"": ""c323ffc""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Confusing

### Additional context


https://github.com/user-attachments/assets/8c3ad5fd-998b-42bb-89df-9f401c6479ca

",alexyarosh,2024-08-01 00:14:06+00:00,[],2024-08-21 19:00:34+00:00,2024-08-21 19:00:33+00:00,https://github.com/metabase/metabase/issues/46357,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2276492896, 'issue_id': 2441164184, 'author': 'nemanjaglumac', 'body': 'The list of columns is coming straight from the backend. The duplication should be fixed there.\r\nThe FE is simply displaying them.\r\n\r\nhttps://github.com/metabase/metabase/blob/master/frontend/src/metabase/querying/components/FilterModal/utils/filters.ts#L24', 'created_at': datetime.datetime(2024, 8, 8, 19, 15, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302771771, 'issue_id': 2441164184, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/46845', 'created_at': datetime.datetime(2024, 8, 21, 19, 0, 33, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-08-08 19:15:16 UTC): The list of columns is coming straight from the backend. The duplication should be fixed there.
The FE is simply displaying them.

https://github.com/metabase/metabase/blob/master/frontend/src/metabase/querying/components/FilterModal/utils/filters.ts#L24

ranquild on (2024-08-21 19:00:33 UTC): Duplicate of https://github.com/metabase/metabase/issues/46845

"
2441034541,issue,closed,completed,"Custom Expression where one divides a ""Cumulative sum"" over another ""Cumulative sum"" leads to ""Double compilation error""","### Describe the bug

Custom Expression where one divides a ""Cumulative sum"" over another ""Cumulative sum"" leads to ""Double compilation error""

### To Reproduce

1. Join any two tables that each have at least 1 numerical value column, on a column ""shared"" by both tables
2. Perform 2 different cumulative summarizations utilizing a numerical column from each table, grouped by a shared column
3. Create custom expression where ones tries to divide one cumulative sum by the other
4. See error

Sample database error:
<img width=""1262"" alt=""samplemetabug"" src=""https://github.com/user-attachments/assets/bdef957a-1261-44e5-95a6-0031a13c16ee"">
Original error:
<img width=""1250"" alt=""metabug"" src=""https://github.com/user-attachments/assets/26958263-932c-4d7a-ac69-03bff9668248"">



### Expected behavior

I am able to divide a timegrouped cumulative sum over another cumulative sum in order to get the timegrouped cumulative ratio data I need.

### Logs

ERROR: ""metabase.driver.sql.query-processor/->honeysql called on something already compiled to Honey SQL. See metabase.driver.sql.query-processor/throw-double-compilation-error for more info.""

SERVER LOGS (for sample database):
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:49:51-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 471.5 ms (21 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:06-04:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 9.6 ms (10 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:06-04:00 INFO metabase.public-settings.premium-features Checking with the MetaStore to see whether token 'b455...70c7' is valid...
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:06-04:00 DEBUG metabase.server.middleware.log GET /api/collection/root 200 4.3 ms (2 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:06-04:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 68.5 ms (7 DB calls) App DB connections: 3/15 Jetty threads: 5/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/search 200 30.6 ms (5 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/database 200 4.5 ms (3 DB calls) App DB connections: 3/15 Jetty threads: 6/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/bookmark 200 1.4 ms (1 DB calls) App DB connections: 3/15 Jetty threads: 5/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 8.7 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 3.2 ms (1 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/activity/recent_views 200 7.3 ms (5 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:07-04:00 DEBUG metabase.server.middleware.log GET /api/activity/popular_items 200 22.8 ms (10 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:10-04:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 2.9 ms (3 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:10-04:00 DEBUG metabase.server.middleware.log GET /api/database 200 17.1 ms (11 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:14-04:00 DEBUG metabase.server.middleware.log GET /api/collection/tree 200 12.7 ms (8 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:14-04:00 DEBUG metabase.server.middleware.log GET /api/collection/root/items 200 6.0 ms (4 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (1 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:19-04:00 DEBUG metabase.server.middleware.log GET /api/database/1/schemas 200 6.6 ms (4 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:19-04:00 DEBUG metabase.server.middleware.log GET /api/database/1/schema/PUBLIC 200 5.4 ms (4 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:23-04:00 DEBUG metabase.server.middleware.log GET /api/table/2/query_metadata 200 25.8 ms (11 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:23-04:00 DEBUG metabase.server.middleware.log GET /api/table/5/query_metadata 200 17.1 ms (9 DB calls) App DB connections: 3/15 Jetty threads: 5/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:23-04:00 DEBUG metabase.server.middleware.log GET /api/table/1/query_metadata 200 12.0 ms (9 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:28-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 38.4 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:41-04:00 DEBUG metabase.server.middleware.log GET /api/table/6/query_metadata 200 14.0 ms (11 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:41-04:00 DEBUG metabase.server.middleware.log GET /api/table/7/query_metadata 200 14.7 ms (9 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:42-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 30.3 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:47-04:00 DEBUG metabase.server.middleware.log GET /api/table/3/query_metadata 200 14.1 ms (11 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:48-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 29.0 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:52:56-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 30.3 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (120 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.task.sync-databases Starting sync task for Database 1.
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: Sync metadata for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database'' (152.2 µs)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-dbms-version'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-timezone'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-timezone'' for h2 Database 1 ''Sample Database'' (91.5 µs)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-tables'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.sync-timezone :h2 database 1 default timezone is ""GMT""
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 1 ''PUBLIC.PRODUCTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-tables'' for h2 Database 1 ''Sample Database'' (3.1 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-fields'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 2 ''PUBLIC.ORDERS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 3 ''PUBLIC.ANALYTIC_EVENTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 4 ''PUBLIC.FEEDBACK''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 5 ''PUBLIC.PEOPLE''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 6 ''PUBLIC.INVOICES''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 7 ''PUBLIC.ACCOUNTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.sync-metadata.tables Updating table metadata for Table 8 ''PUBLIC.REVIEWS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-fields'' for h2 Database 1 ''Sample Database'' (47.8 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-fks'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-fks'' for h2 Database 1 ''Sample Database'' (16.5 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-indexes'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-indexes'' for h2 Database 1 ''Sample Database'' (29.6 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-metabase-metadata'' for h2 Database 1 ''Sample Database'' (312.9 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database'' (83.5 µs)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''sync-table-privileges'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: Sync metadata for h2 Database 1 ''Sample Database'' (441.1 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: Analyze data for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze fingerprint-fields Analyzed [*****·············································] 😢   12% Table 5 ''PUBLIC.PEOPLE''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze fingerprint-fields Analyzed [***********·······································] 😒   24% Table 7 ''PUBLIC.ACCOUNTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''fingerprint-fields'' for h2 Database 1 ''Sample Database'' (11.2 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''classify-fields'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-fields Analyzed [******************································] 😕   36% Table 1 ''PUBLIC.PRODUCTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-fields Analyzed [***********************···························] 😬   48% Table 8 ''PUBLIC.REVIEWS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-fields Analyzed [******************************····················] 😌   60% Table 4 ''PUBLIC.FEEDBACK''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-tables Analyzed [************************************··············] 😋   72% Table 2 ''PUBLIC.ORDERS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''classify-fields'' for h2 Database 1 ''Sample Database'' (7.1 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util STARTING: step ''classify-tables'' for h2 Database 1 ''Sample Database''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-tables Analyzed [***********************************************···] 😎   96% Table 3 ''PUBLIC.ANALYTIC_EVENTS''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.analyze classify-tables Analyzed [*****************************************·········] 😊   84% Table 6 ''PUBLIC.INVOICES''
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: step ''classify-tables'' for h2 Database 1 ''Sample Database'' (1.3 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:00-04:00 INFO metabase.sync.util FINISHED: Analyze data for h2 Database 1 ''Sample Database'' (36.6 ms)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:08-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 34.7 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (3 idle, 0 queued) (118 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:27-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 34.8 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (3 idle, 0 queued) (118 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:53:41-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 31.5 ms (15 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (3 idle, 0 queued) (118 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:54:03-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 47.0 ms (17 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (3 idle, 0 queued) (118 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:55:12-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 148.5 ms (16 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:55:34-04:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: metabase.driver.sql.query-processor/->honeysql called on something already compiled to Honey SQL. See metabase.driver.sql.query-processor/throw-double-compilation-error for more info.
{:database_id 1,
 :started_at #t ""2024-07-31T21:55:33.975834Z[GMT]"",
 :action_id nil,
 :error_type :driver,
 :json_query
 {:database 1,
  :type ""query"",
  :query
  {:expressions
   {:cum sum over cum sum [""/"" [""field"" ""sum"" {:base-type ""type/Float""}] [""field"" ""sum_2"" {:base-type ""type/Float""}]]},
   :limit 10,
   :source-query
   {:source-table 2,
    :joins
    [{:alias ""People - User"",
      :condition
      [""=""
       [""field"" 43 {:base-type ""type/Integer""}]
       [""field"" 46 {:base-type ""type/BigInteger"", :join-alias ""People - User""}]],
      :source-table 5}],
    :aggregation
    [[""cum-sum"" [""field"" 40 {:base-type ""type/Float""}]]
     [""cum-sum"" [""field"" 57 {:base-type ""type/Float"", :join-alias ""People - User""}]]],
    :breakout [[""field"" 37 {:base-type ""type/BigInteger""}]]}},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> driver.sql.query_processor$throw_double_compilation_error.invokeStatic(query_processor.clj:468)""
  ""driver.sql.query_processor$throw_double_compilation_error.invoke(query_processor.clj:446)""
  ""driver.sql.query_processor$fn__66030.invokeStatic(query_processor.clj:479)""
  ""driver.sql.query_processor$fn__66030.invoke(query_processor.clj:475)""
  ""driver.sql.query_processor$fn__66371.invokeStatic(query_processor.clj:838)""
  ""driver.sql.query_processor$fn__66371.invoke(query_processor.clj:836)""
  ""driver.sql.query_processor$fn__66483$iter__66485__66489$fn__66490$fn__66491.invoke(query_processor.clj:1016)""
  ""driver.sql.query_processor$fn__66483$iter__66485__66489$fn__66490.invoke(query_processor.clj:1015)""
  ""driver.sql.query_processor$fn__66483.invokeStatic(query_processor.clj:1015)""
  ""driver.sql.query_processor$fn__66483.invoke(query_processor.clj:1013)""
  ""driver.sql.query_processor$apply_top_level_clauses$fn__66742.invoke(query_processor.clj:1407)""
  ""driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1401)""
  ""driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1394)""
  ""driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1398)""
  ""driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1394)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1464)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$apply_source_query.invokeStatic(query_processor.clj:1428)""
  ""driver.sql.query_processor$apply_source_query.invoke(query_processor.clj:1413)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1460)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$apply_source_query.invokeStatic(query_processor.clj:1428)""
  ""driver.sql.query_processor$apply_source_query.invoke(query_processor.clj:1413)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1460)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$mbql__GT_honeysql.invokeStatic(query_processor.clj:1484)""
  ""driver.sql.query_processor$mbql__GT_honeysql.invoke(query_processor.clj:1478)""
  ""driver.sql.query_processor$mbql__GT_native.invokeStatic(query_processor.clj:1493)""
  ""driver.sql.query_processor$mbql__GT_native.invoke(query_processor.clj:1489)""
  ""driver.sql$fn__84453.invokeStatic(sql.clj:49)""
  ""driver.sql$fn__84453.invoke(sql.clj:47)""
  ""query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic(mbql_to_native.clj:14)""
  ""query_processor.middleware.mbql_to_native$query__GT_native_form.invoke(mbql_to_native.clj:9)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:21)""
  ""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""
  ""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___63247.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___63259.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__95087.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53862$fn__53864.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53862.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""metabase.driver.sql.query-processor/->honeysql called on something already compiled to Honey SQL. See metabase.driver.sql.query-processor/throw-double-compilation-error for more info."",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 1,
  :type :query,
  :query
  {:expressions
   {""cum sum over cum sum"" [:/ [:field ""sum"" {:base-type :type/Float}] [:field ""sum_2"" {:base-type :type/Float}]]},
   :limit 10,
   :source-metadata
   [{:semantic_type :type/PK,
     :table_id 2,
     :coercion_strategy nil,
     :name ""ID"",
     :settings nil,
     :field_ref [:field 37 {:base-type :type/BigInteger}],
     :effective_type :type/BigInteger,
     :nfc_path nil,
     :parent_id nil,
     :id 37,
     :display_name ""ID"",
     :fingerprint nil,
     :base_type :type/BigInteger}
    {:name ""sum"",
     :display_name ""Cumulative sum of Total"",
     :base_type :type/Float,
     :semantic_type nil,
     :settings nil,
     :field_ref [:aggregation 0]}
    {:name ""sum_2"",
     :display_name ""Cumulative sum of People - User → Longitude"",
     :base_type :type/Float,
     :semantic_type :type/Longitude,
     :settings nil,
     :field_ref [:aggregation 1]}],
   :fields
   [[:field 37 {:base-type :type/BigInteger}]
    [:field ""sum"" {:base-type :type/Float}]
    [:field ""sum_2"" {:base-type :type/Float}]
    [:expression ""cum sum over cum sum""]],
   :source-query
   {:source-table 2,
    :aggregation
    [[:aggregation-options [:cum-sum [:field 40 {:base-type :type/Float}]] {:name ""sum""}]
     [:aggregation-options
      [:cum-sum [:field 57 {:base-type :type/Float, :join-alias ""People - User""}]]
      {:name ""sum_2""}]],
    :breakout [[:field 37 {:base-type :type/BigInteger}]],
    :order-by [[:asc [:field 37 {:base-type :type/BigInteger}]]],
    :joins
    [{:alias ""People - User"",
      :strategy :left-join,
      :condition
      [:=
       [:field 43 {:base-type :type/Integer}]
       [:field 46 {:base-type :type/BigInteger, :join-alias ""People - User""}]],
      :source-table 5}]}},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 1, :context :ad-hoc}},
 :ex-data
 {:driver :h2,
  :expr
  [:cum-sum
   [:field
    40
    {:base-type :type/Float,
     :metabase.query-processor.util.add-alias-info/source-table 2,
     :metabase.query-processor.util.add-alias-info/source-alias ""TOTAL""}]],
  :type :driver},
 :data {:rows [], :cols []}}

[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:55:34-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 124.7 ms (15 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:55:43-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 41.9 ms (16 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:56:26-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 34.5 ms (16 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:56:36-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 42.9 ms (17 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:56:39-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 117.6 ms (17 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued); h2 DB 1 connections: 0/1 (0 threads blocked)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:56:42-04:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: metabase.driver.sql.query-processor/->honeysql called on something already compiled to Honey SQL. See metabase.driver.sql.query-processor/throw-double-compilation-error for more info.
{:database_id 1,
 :started_at #t ""2024-07-31T21:56:41.995277Z[GMT]"",
 :action_id nil,
 :error_type :driver,
 :json_query
 {:database 1,
  :type ""query"",
  :query
  {:expressions
   {:cum sum over cum sum [""/"" [""field"" ""sum"" {:base-type ""type/Float""}] [""field"" ""sum_2"" {:base-type ""type/Float""}]]},
   :limit 10,
   :source-query
   {:source-table 2,
    :joins
    [{:alias ""People - User"",
      :fields ""all"",
      :condition
      [""=""
       [""field"" 43 {:base-type ""type/Integer""}]
       [""field"" 46 {:base-type ""type/BigInteger"", :join-alias ""People - User""}]],
      :source-table 5}],
    :aggregation
    [[""cum-sum"" [""field"" 40 {:base-type ""type/Float""}]]
     [""cum-sum"" [""field"" 57 {:base-type ""type/Float"", :join-alias ""People - User""}]]],
    :breakout [[""field"" 37 {:base-type ""type/BigInteger""}]]}},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native nil,
 :status :failed,
 :class clojure.lang.ExceptionInfo,
 :stacktrace
 [""--> driver.sql.query_processor$throw_double_compilation_error.invokeStatic(query_processor.clj:468)""
  ""driver.sql.query_processor$throw_double_compilation_error.invoke(query_processor.clj:446)""
  ""driver.sql.query_processor$fn__66030.invokeStatic(query_processor.clj:479)""
  ""driver.sql.query_processor$fn__66030.invoke(query_processor.clj:475)""
  ""driver.sql.query_processor$fn__66371.invokeStatic(query_processor.clj:838)""
  ""driver.sql.query_processor$fn__66371.invoke(query_processor.clj:836)""
  ""driver.sql.query_processor$fn__66483$iter__66485__66489$fn__66490$fn__66491.invoke(query_processor.clj:1016)""
  ""driver.sql.query_processor$fn__66483$iter__66485__66489$fn__66490.invoke(query_processor.clj:1015)""
  ""driver.sql.query_processor$fn__66483.invokeStatic(query_processor.clj:1015)""
  ""driver.sql.query_processor$fn__66483.invoke(query_processor.clj:1013)""
  ""driver.sql.query_processor$apply_top_level_clauses$fn__66742.invoke(query_processor.clj:1407)""
  ""driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1401)""
  ""driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1394)""
  ""driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1398)""
  ""driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1394)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1464)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$apply_source_query.invokeStatic(query_processor.clj:1428)""
  ""driver.sql.query_processor$apply_source_query.invoke(query_processor.clj:1413)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1460)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$apply_source_query.invokeStatic(query_processor.clj:1428)""
  ""driver.sql.query_processor$apply_source_query.invoke(query_processor.clj:1413)""
  ""driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1460)""
  ""driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1452)""
  ""driver.sql.query_processor$mbql__GT_honeysql.invokeStatic(query_processor.clj:1484)""
  ""driver.sql.query_processor$mbql__GT_honeysql.invoke(query_processor.clj:1478)""
  ""driver.sql.query_processor$mbql__GT_native.invokeStatic(query_processor.clj:1493)""
  ""driver.sql.query_processor$mbql__GT_native.invoke(query_processor.clj:1489)""
  ""driver.sql$fn__84453.invokeStatic(sql.clj:49)""
  ""driver.sql$fn__84453.invoke(sql.clj:47)""
  ""query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic(mbql_to_native.clj:14)""
  ""query_processor.middleware.mbql_to_native$query__GT_native_form.invoke(mbql_to_native.clj:9)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:21)""
  ""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""
  ""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___63247.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___63259.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__95087.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53862$fn__53864.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53862.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""metabase.driver.sql.query-processor/->honeysql called on something already compiled to Honey SQL. See metabase.driver.sql.query-processor/throw-double-compilation-error for more info."",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 1,
  :type :query,
  :query
  {:expressions
   {""cum sum over cum sum"" [:/ [:field ""sum"" {:base-type :type/Float}] [:field ""sum_2"" {:base-type :type/Float}]]},
   :limit 10,
   :source-metadata
   [{:semantic_type :type/PK,
     :table_id 2,
     :coercion_strategy nil,
     :name ""ID"",
     :settings nil,
     :field_ref [:field 37 {:base-type :type/BigInteger}],
     :effective_type :type/BigInteger,
     :nfc_path nil,
     :parent_id nil,
     :id 37,
     :display_name ""ID"",
     :fingerprint nil,
     :base_type :type/BigInteger}
    {:name ""sum"",
     :display_name ""Cumulative sum of Total"",
     :base_type :type/Float,
     :semantic_type nil,
     :settings nil,
     :field_ref [:aggregation 0]}
    {:name ""sum_2"",
     :display_name ""Cumulative sum of People - User → Longitude"",
     :base_type :type/Float,
     :semantic_type :type/Longitude,
     :settings nil,
     :field_ref [:aggregation 1]}],
   :fields
   [[:field 37 {:base-type :type/BigInteger}]
    [:field ""sum"" {:base-type :type/Float}]
    [:field ""sum_2"" {:base-type :type/Float}]
    [:expression ""cum sum over cum sum""]],
   :source-query
   {:source-table 2,
    :aggregation
    [[:aggregation-options [:cum-sum [:field 40 {:base-type :type/Float}]] {:name ""sum""}]
     [:aggregation-options
      [:cum-sum [:field 57 {:base-type :type/Float, :join-alias ""People - User""}]]
      {:name ""sum_2""}]],
    :breakout [[:field 37 {:base-type :type/BigInteger}]],
    :order-by [[:asc [:field 37 {:base-type :type/BigInteger}]]],
    :joins
    [{:alias ""People - User"",
      :strategy :left-join,
      :fields
      [[:field 46 {:join-alias ""People - User""}]
       [:field 48 {:join-alias ""People - User""}]
       [:field 47 {:join-alias ""People - User""}]
       [:field 54 {:join-alias ""People - User""}]
       [:field 49 {:join-alias ""People - User""}]
       [:field 50 {:join-alias ""People - User""}]
       [:field 57 {:join-alias ""People - User""}]
       [:field 53 {:join-alias ""People - User""}]
       [:field 51 {:join-alias ""People - User""}]
       [:field 56 {:temporal-unit :default, :join-alias ""People - User""}]
       [:field 55 {:join-alias ""People - User""}]
       [:field 52 {:join-alias ""People - User""}]
       [:field 45 {:temporal-unit :default, :join-alias ""People - User""}]],
      :condition
      [:=
       [:field 43 {:base-type :type/Integer}]
       [:field 46 {:base-type :type/BigInteger, :join-alias ""People - User""}]],
      :source-table 5}]}},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 1, :context :ad-hoc}},
 :ex-data
 {:driver :h2,
  :expr
  [:cum-sum
   [:field
    40
    {:base-type :type/Float,
     :metabase.query-processor.util.add-alias-info/source-table 2,
     :metabase.query-processor.util.add-alias-info/source-alias ""TOTAL""}]],
  :type :driver},
 :data {:rows [], :cols []}}

[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T17:56:42-04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed] 155.0 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:00-04:00 INFO metabase.task.send-pulses Sending scheduled pulses...
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:00-04:00 INFO metabase.public-settings.premium-features Checking with the MetaStore to see whether token 'b455...70c7' is valid...
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:00-04:00 DEBUG metabase.server.middleware.log GET /api/setting 200 67.6 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:00-04:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 71.9 ms (6 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (2 idle, 0 queued) (117 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:00-04:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 10.6 ms (9 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)
[3a712050-ef90-4931-888f-a12c74e01aaa] 2024-07-31T18:00:13-04:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 3.2 ms (1 DB calls) App DB connections: 2/15 Jetty threads: 4/50 (2 idle, 0 queued) (119 total active threads) Queries in flight: 0 (0 queued)

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v1.49.21"",
      ""hash"": ""a8b4d96""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Severe/Blocking an upgrade/Need this functionality to implement time-sensitive important visualizations

### Additional context

_No response_",jojayala,2024-07-31 22:14:03+00:00,['camsaul'],2024-08-28 02:09:02+00:00,2024-08-12 20:04:32+00:00,https://github.com/metabase/metabase/issues/46354,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 2284813447, 'issue_id': 2441034541, 'author': 'camsaul', 'body': 'Basically a duplicate of #15118; fixed in 0.50.0 by #40752', 'created_at': datetime.datetime(2024, 8, 12, 20, 4, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284813898, 'issue_id': 2441034541, 'author': 'camsaul', 'body': 'Fixed by #40752', 'created_at': datetime.datetime(2024, 8, 12, 20, 4, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2292621862, 'issue_id': 2441034541, 'author': 'jojayala', 'body': 'This is not the same problem as the linked issues, and has not been fixed. The query is not even able to compile in this issue, much less spit out a wrong answer. In fact, even attempting to use CumulativeSum in a simple model causes the double-compilation error when viewing the model results outside of model details. Please reopen.\r\n<img width=""857"" alt=""image"" src=""https://github.com/user-attachments/assets/684e5d4a-35c4-40e2-b4fc-a9e9ffcecf5d"">\r\n<img width=""994"" alt=""image"" src=""https://github.com/user-attachments/assets/78a3da06-71ba-47ad-9d7e-aed72ea95aa2"">\r\n<img width=""1256"" alt=""image"" src=""https://github.com/user-attachments/assets/40d3abe8-96cb-49ba-aa44-cb56605885df"">', 'created_at': datetime.datetime(2024, 8, 16, 2, 31, 58, tzinfo=datetime.timezone.utc)}]","camsaul (Assginee) on (2024-08-12 20:04:32 UTC): Basically a duplicate of #15118; fixed in 0.50.0 by #40752

camsaul (Assginee) on (2024-08-12 20:04:50 UTC): Fixed by #40752

jojayala (Issue Creator) on (2024-08-16 02:31:58 UTC): This is not the same problem as the linked issues, and has not been fixed. The query is not even able to compile in this issue, much less spit out a wrong answer. In fact, even attempting to use CumulativeSum in a simple model causes the double-compilation error when viewing the model results outside of model details. Please reopen.
<img width=""857"" alt=""image"" src=""https://github.com/user-attachments/assets/684e5d4a-35c4-40e2-b4fc-a9e9ffcecf5d"">
<img width=""994"" alt=""image"" src=""https://github.com/user-attachments/assets/78a3da06-71ba-47ad-9d7e-aed72ea95aa2"">
<img width=""1256"" alt=""image"" src=""https://github.com/user-attachments/assets/40d3abe8-96cb-49ba-aa44-cb56605885df"">

"
2440929665,issue,open,,X-ray takes a lot of time to save and generates thousands of queries to the app db,"### Describe the bug

I think we have another performance problem here, but I haven't compared to v49 yet

### To Reproduce

1) create a model with orders + people + products + reviews
2) then generate an x-ray based on this model
3) save it, see that it takes > 7 seconds and generates thousands of db calls

### Expected behavior

it should be fast

### Logs

![image](https://github.com/user-attachments/assets/599e5a39-d2bc-456d-a557-7ee94dce4a89)


### Information about your Metabase installation

```JSON
v50
```


### Severity

P2

### Additional context

the generation of the x-ray pegs the 2 cores of the cpu or more and also the saving of it also pegs a single core",paoliniluis,2024-07-31 20:47:57+00:00,"['noahmoss', 'metamben']",2025-02-04 20:27:15+00:00,,https://github.com/metabase/metabase/issues/46346,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('Querying/MBQL', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2261514671, 'issue_id': 2440929665, 'author': 'ranquild', 'body': '```\r\n0.49.22\r\nPOST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/10 Jetty threads: 5/50 (2 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)\r\n\r\n0.50.1\r\nPOST /api/dashboard/save 200 4.4 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.10\r\nPOST /api/dashboard/save 200 4.6 s (840 DB calls) App DB connections: 0/13 Jetty threads: 5/50 (3 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.12\r\nPOST /api/dashboard/save 200 4.5 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (91 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.13\r\nPOST /api/dashboard/save 200 3.0 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.14\r\nPOST /api/dashboard/save 200 5.0 s (1,321 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.15\r\nPOST /api/dashboard/save 200 10.0 s (2,588 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (1 idle, 0 queued) (104 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\n0.50.17\r\nPOST /api/dashboard/save 200 10.0 s (2,588 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (108 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n```', 'created_at': datetime.datetime(2024, 7, 31, 21, 45, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261648497, 'issue_id': 2440929665, 'author': 'ranquild', 'body': '0.50.x\r\n1. 0.50.14 `1321` -> 0.50.15 `2588` caused by https://github.com/metabase/metabase/commit/71f4ff591f4ea1a695afc08edfc5a04e50d6791d (backport of https://github.com/metabase/metabase/pull/45909)\r\n2. 0.50.13 `840` -> 0.50.14 `1321` caused by https://github.com/metabase/metabase/commit/a598ba5dc0f280125e749b3ff1e1c4eb34669bd5 (backport of https://github.com/metabase/metabase/pull/45601)', 'created_at': datetime.datetime(2024, 7, 31, 23, 22, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261703550, 'issue_id': 2440929665, 'author': 'ranquild', 'body': '0.49.x -> 0.50.x\r\n\r\nRoot cause:\r\n\r\nMarch 8\r\n2dccd287b18d1ace1acdfe6b2626ec0ec1e6e54f\r\nConvert QP to MLv2 (Part 1) (#39613)\r\nPOST /api/dashboard/save 200 2.5 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (4 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nFull bisect log:\r\n\r\n```\r\nJune\r\n94703f0ae8ca7c98caa627d8d827ccee2b161113\r\nPOST /api/dashboard/save 200 4.3 s (846 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\nMay 15\r\n214a59894e903783bb0bfb2f8759a276bc12167c\r\nPOST /api/dashboard/save 200 4.4 s (887 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (3 idle, 0 queued) (90 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\nApril 16\r\n176f631782b9d7dd53e391086f8bdf228dab30e6\r\nPOST /api/dashboard/save 200 2.6 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (3 idle, 0 queued) (86 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\nMarch 18\r\n15a411c241bef7b5650c6c95dbee4fbd82df7cb1\r\nPOST /api/dashboard/save 200 2.8 s (860 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (105 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}\r\n\r\nMarch 11\r\nef9fb057848a7da9a550869131713d985cdab0f2\r\nPOST /api/dashboard/save 200 2.5 s (860 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 8\r\n2dccd287b18d1ace1acdfe6b2626ec0ec1e6e54f\r\nConvert QP to MLv2 (Part 1) (#39613)\r\nPOST /api/dashboard/save 200 2.5 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (4 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 8\r\nbf3e899e19065d283cd9c0787233e540016cbaeb\r\nSpecify GH project board per team (#39631)\r\nPOST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/10 Jetty threads: 5/50 (3 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 8\r\n80703aa63aa1b0b503a8703371453a14be2c882a\r\nPOST /api/dashboard/save 200 2.2 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 8\r\n77b649dbcbe295b497b3265b50d97928fe9b6da6\r\nPOST /api/dashboard/save 200 2.3 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 7\r\n819fe3da75c7c4d122d5f9470938116be9492555\r\nPOST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 6\r\n22917f3dd3b415f1214e3487588cc3b5da31e214\r\nPOST /api/dashboard/save 200 2.2 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)\r\n\r\nMarch 4\r\nb88b1ade62b94b6b5f172b31f8809d944c4d6f22\r\nPOST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (104 total active threads) Queries in flight: 0 (0 queued)\r\n\r\n```', 'created_at': datetime.datetime(2024, 8, 1, 0, 22, 10, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-31 21:45:42 UTC): ```
0.49.22
POST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/10 Jetty threads: 5/50 (2 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)

0.50.1
POST /api/dashboard/save 200 4.4 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.10
POST /api/dashboard/save 200 4.6 s (840 DB calls) App DB connections: 0/13 Jetty threads: 5/50 (3 idle, 0 queued) (92 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.12
POST /api/dashboard/save 200 4.5 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (91 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.13
POST /api/dashboard/save 200 3.0 s (840 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.14
POST /api/dashboard/save 200 5.0 s (1,321 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (107 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.15
POST /api/dashboard/save 200 10.0 s (2,588 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (1 idle, 0 queued) (104 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

0.50.17
POST /api/dashboard/save 200 10.0 s (2,588 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (108 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
```

ranquild on (2024-07-31 23:22:30 UTC): 0.50.x
1. 0.50.14 `1321` -> 0.50.15 `2588` caused by https://github.com/metabase/metabase/commit/71f4ff591f4ea1a695afc08edfc5a04e50d6791d (backport of https://github.com/metabase/metabase/pull/45909)
2. 0.50.13 `840` -> 0.50.14 `1321` caused by https://github.com/metabase/metabase/commit/a598ba5dc0f280125e749b3ff1e1c4eb34669bd5 (backport of https://github.com/metabase/metabase/pull/45601)

ranquild on (2024-08-01 00:22:10 UTC): 0.49.x -> 0.50.x

Root cause:

March 8
2dccd287b18d1ace1acdfe6b2626ec0ec1e6e54f
Convert QP to MLv2 (Part 1) (#39613)
POST /api/dashboard/save 200 2.5 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (4 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued)

Full bisect log:

```
June
94703f0ae8ca7c98caa627d8d827ccee2b161113
POST /api/dashboard/save 200 4.3 s (846 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (2 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

May 15
214a59894e903783bb0bfb2f8759a276bc12167c
POST /api/dashboard/save 200 4.4 s (887 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (3 idle, 0 queued) (90 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

April 16
176f631782b9d7dd53e391086f8bdf228dab30e6
POST /api/dashboard/save 200 2.6 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (3 idle, 0 queued) (86 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

March 18
15a411c241bef7b5650c6c95dbee4fbd82df7cb1
POST /api/dashboard/save 200 2.8 s (860 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (105 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}

March 11
ef9fb057848a7da9a550869131713d985cdab0f2
POST /api/dashboard/save 200 2.5 s (860 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)

March 8
2dccd287b18d1ace1acdfe6b2626ec0ec1e6e54f
Convert QP to MLv2 (Part 1) (#39613)
POST /api/dashboard/save 200 2.5 s (857 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (4 idle, 0 queued) (88 total active threads) Queries in flight: 0 (0 queued)

March 8
bf3e899e19065d283cd9c0787233e540016cbaeb
Specify GH project board per team (#39631)
POST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/10 Jetty threads: 5/50 (3 idle, 0 queued) (85 total active threads) Queries in flight: 0 (0 queued)

March 8
80703aa63aa1b0b503a8703371453a14be2c882a
POST /api/dashboard/save 200 2.2 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)

March 8
77b649dbcbe295b497b3265b50d97928fe9b6da6
POST /api/dashboard/save 200 2.3 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued)

March 7
819fe3da75c7c4d122d5f9470938116be9492555
POST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (102 total active threads) Queries in flight: 0 (0 queued)

March 6
22917f3dd3b415f1214e3487588cc3b5da31e214
POST /api/dashboard/save 200 2.2 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (5 idle, 0 queued) (103 total active threads) Queries in flight: 0 (0 queued)

March 4
b88b1ade62b94b6b5f172b31f8809d944c4d6f22
POST /api/dashboard/save 200 2.1 s (426 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (6 idle, 0 queued) (104 total active threads) Queries in flight: 0 (0 queued)

```

"
2440824056,issue,open,,Milestone 3: Create a better loading experience for tables,"Problem:
https://github.com/user-attachments/assets/075994db-d2e5-45b4-a6a1-2e6f4692bc54

Solution from Design:
- We should use [Skeleton](https://www.figma.com/design/CSbCYr3G4CwrUrpaWEJjdB/Loading-states?node-id=0-1&t=pblidAyBme9xh0JM-1) for table loading (page content loading).
- For refreshing a table or changing a selector to reload the table content, show the skeleton (not the prior content). When the new table content is fetched, immediately display the content.
- Add a delay before showing loading state to avoid flashing loading states for fast loading content.
- As we have skeleton for the table loading, there is no need to show spinner on the selector control for time periods.",sloansparger,2024-07-31 19:46:42+00:00,[],2024-07-31 19:51:07+00:00,,https://github.com/metabase/metabase/issues/46345,[],[],
2440822082,issue,closed,not_planned,Engineering Doc - Spec out a reusable table component,https://www.notion.so/metabase/Reusable-Table-Component-c0afb3427838465f9193b836a97bf7b4?pvs=4,sloansparger,2024-07-31 19:45:27+00:00,[],2025-02-05 16:57:49+00:00,2025-02-05 16:57:49+00:00,https://github.com/metabase/metabase/issues/46344,[],[],
2440821255,issue,open,,[Epic] Improve tables,"**Links**
- eng doc: **WIP** https://www.notion.so/metabase/Reusable-Table-Component-c0afb3427838465f9193b836a97bf7b4?pvs=4
- feature branch: TBD

**Problem**
We have multiple places in Metabase where we need to show a table of information, however each places implements its own table resulting in discrepancies in visuals and implementation logic. We'd like to both solve the poor developer experience that results from having to build a new table for every feature and provide an core solution that makes it easier to create higher quality tables. Currently tables suffer from a few common issue around pagination bugs, selection logic being incorrect, sub-par loading experiences, and more. By the end of this epic those things should all be resolved.

**Implementation Plan**

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/issues/46344
- [ ] Milestone 1: Add a core table implementation
- [ ] Milestone 2: Port existing tables to table solutions
- [ ] https://github.com/metabase/metabase/issues/46345
```
",sloansparger,2024-07-31 19:44:56+00:00,"['npfitz', 'sloansparger']",2024-10-03 01:27:56+00:00,,https://github.com/metabase/metabase/issues/46343,"[('.Epic', 'Feature Implementation or Project'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2440659116,issue,closed,completed,Can't change default filter date options on SQL questions,"### Describe the bug

When trying to set a default value for a date filter, clicking on the 3 dots to specify current day/week/etc and to choose if it starts from X previous days/weeks/etc shows up behind the dialog, so i can't properly click on it, seems to be a CSS bug?

![image](https://github.com/user-attachments/assets/54a9e0ad-a16e-4c59-bac5-40f0d3877881)


### To Reproduce

Create a field filter with type ""Date filter"" and try to filter on it
![image](https://github.com/user-attachments/assets/7788a58a-fd24-49df-9895-5290556cd45e)


### Expected behavior

I should be able to select the options same as in the report itself
![image](https://github.com/user-attachments/assets/f1db81db-4b93-43f3-9a6c-2b8493fe3b89)


### Logs

This happens in the frontend

### Information about your Metabase installation

```JSON
v0.50.17
```


### Severity

Annoying because i can't properly set default values for date filters

### Additional context

_No response_",sicarul,2024-07-31 18:20:00+00:00,['nemanjaglumac'],2024-08-12 23:05:52+00:00,2024-08-12 22:39:47+00:00,https://github.com/metabase/metabase/issues/46342,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Team/Querying', '')]","[{'comment_id': 2261181740, 'issue_id': 2440659116, 'author': 'noahmoss', 'body': 'I can repro on 50.17 but not on master', 'created_at': datetime.datetime(2024, 7, 31, 18, 45, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261266896, 'issue_id': 2440659116, 'author': 'sicarul', 'body': 'Just upgraded to 0.50.18 and still seeing the same behavior.', 'created_at': datetime.datetime(2024, 7, 31, 19, 25, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285020064, 'issue_id': 2440659116, 'author': 'nemanjaglumac', 'body': 'Fixed by https://github.com/metabase/metabase/pull/46702.\r\nIt was a silly z-index issue caused by having a mix of new and old popovers. New has z-index 300, and the old one has z-index 4.\r\n\r\nShould go out in v0.50.20, so @sicarul keep an eye on it 👀 .', 'created_at': datetime.datetime(2024, 8, 12, 22, 39, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285044928, 'issue_id': 2440659116, 'author': 'sicarul', 'body': ""> Fixed by #46702. It was a silly z-index issue caused by having a mix of new and old popovers. New has z-index 300, and the old one has z-index 4.\r\n> \r\n> Should go out in v0.50.20, so @sicarul keep an eye on it 👀 .\r\n\r\nI imagined something with a z-index being faulty but i don't know enough about Metabase's source code to make a PR yet 😅  Thanks!"", 'created_at': datetime.datetime(2024, 8, 12, 23, 5, 51, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-07-31 18:45:23 UTC): I can repro on 50.17 but not on master

sicarul (Issue Creator) on (2024-07-31 19:25:30 UTC): Just upgraded to 0.50.18 and still seeing the same behavior.

nemanjaglumac (Assginee) on (2024-08-12 22:39:47 UTC): Fixed by https://github.com/metabase/metabase/pull/46702.
It was a silly z-index issue caused by having a mix of new and old popovers. New has z-index 300, and the old one has z-index 4.

Should go out in v0.50.20, so @sicarul keep an eye on it 👀 .

sicarul (Issue Creator) on (2024-08-12 23:05:51 UTC): I imagined something with a z-index being faulty but i don't know enough about Metabase's source code to make a PR yet 😅  Thanks!

"
2440641748,issue,closed,completed,[FE] Enable Channel Based Alerts for questions,,npfitz,2024-07-31 18:13:51+00:00,[],2024-08-30 04:23:20+00:00,2024-08-30 04:23:20+00:00,https://github.com/metabase/metabase/issues/46341,[],"[{'comment_id': 2319999146, 'issue_id': 2440641748, 'author': 'qnkhuat', 'body': 'PR https://github.com/metabase/metabase/pull/47022', 'created_at': datetime.datetime(2024, 8, 30, 4, 23, 20, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-08-30 04:23:20 UTC): PR https://github.com/metabase/metabase/pull/47022

"
2440482150,issue,open,,Fix N^2 in toucan,PR https://github.com/camsaul/toucan2/pull/172,ranquild,2024-07-31 16:48:01+00:00,['bshepherdson'],2024-08-14 22:55:00+00:00,,https://github.com/metabase/metabase/issues/46339,[],"[{'comment_id': 2290077688, 'issue_id': 2440482150, 'author': 'camsaul', 'body': '@bshepherdson there are test failures in that PR, ping me once you get it green', 'created_at': datetime.datetime(2024, 8, 14, 22, 54, 59, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-08-14 22:54:59 UTC): @bshepherdson there are test failures in that PR, ping me once you get it green

"
2440363073,issue,open,,Invalid XRay Generated if Join Column in Underlying Models is not also Selected,"### Describe the bug

If you created a model that joins two tables on an ID column, but do not also include the column in the ""select"" - invalid x-rays are generated downstream.

### To Reproduce

1. Spin up Metabase (this was reproduce on 49 and 50)
2. Create a Question with the Sample DB:
- Join orders.user_id to + to people.id
- Deselect user_id from the column picker for the orders table
3. Promote the Question to a Model
4. X-ray the model
5. Note that invalid SQL is generated for cards on the x-ray dashboard (Column ""source.USER_ID"" not found;)

Loom recording of a similar flow:
https://www.loom.com/share/40f7587c08254fc9b72b05231842750d?sid=9187d5de-1af7-4b30-b01c-b660e1482a25

### Expected behavior

The xray should work

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.13
```


### Severity

annoying

### Additional context

You can work around this by converting the model back to a question, adding the ID columns back to the question and promoting it back to a model.",ixipixi,2024-07-31 15:41:28+00:00,[],2025-02-04 20:28:42+00:00,,https://github.com/metabase/metabase/issues/46337,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Querying/X-rays', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2440053651,issue,closed,not_planned,Field filters are not getting cached in saved questions,"### Describe the bug

Drop down field filters are not getting cached in saved questions. When I reload the question and try accessing the drop down menu, it triggers a new query every time. 

### To Reproduce

1. Go to any saved question with a field filter
2. Click on the filter drop down
3. Let the query run and filter populate
4. Reload the page
5. Click on the filter drop down again


### Expected behavior

Once the field filter is populated with values, the second reload should fetch these values from cache and not fetch it from DB again

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser: `Version 126.0.6478.127`
- Operating system: Mac OS
- Database: Trino with Startburst driver
- Metabase version: 0.50.4
- Hosting: Kubernetes
- Internal database: MySQL
```


### Severity

Blocking as each time a user clicks on field filter drop down, it triggers a new query which is very slow due to full table scan

### Additional context

_No response_",harshith-bolar-rapido,2024-07-31 13:22:36+00:00,[],2024-08-26 07:36:08+00:00,2024-08-02 07:52:48+00:00,https://github.com/metabase/metabase/issues/46332,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]","[{'comment_id': 2260618514, 'issue_id': 2440053651, 'author': 'ranquild', 'body': '@harshith-bolar-rapido you can get your values cached if you go to Admin -> Table Metadata -> Select your database, schema, table, field -> And set `Filtering on this field` to `A list of all values`. This will only work if there are less than about a thousand unique values for this field.', 'created_at': datetime.datetime(2024, 7, 31, 14, 9, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260671361, 'issue_id': 2440053651, 'author': 'harshith-bolar-rapido', 'body': '@ranquild I tried this, set the field to `A list of all values`, hit re-scan this field, it triggered a query which finished successfully. Then I reloaded the question and clicked on the drop down filter, and it fired the same query again to fetch filter values. And the field has only about 100 unique values.\r\n\r\nIs there any way I can validate that it is actually caching something?', 'created_at': datetime.datetime(2024, 7, 31, 14, 34, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2260803856, 'issue_id': 2440053651, 'author': 'Tony-metabase', 'body': 'Go to the Application Database and find the `metabase_fieldvalues` table and you should find the filter values there if they are getting cached:\r\n\r\n<img width=""1506"" alt=""image"" src=""https://github.com/user-attachments/assets/d54abcbb-a75f-4716-889f-16643e7145c1"">', 'created_at': datetime.datetime(2024, 7, 31, 15, 32, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2262023693, 'issue_id': 2440053651, 'author': 'harshith-bolar-rapido', 'body': 'Verified that the field values are stored in `metabase_fieldvalues` table. But in the question it still triggers another query to the DB to fetch these values. Added screenshots for reference.\r\n\r\n<img width=""479"" alt=""image"" src=""https://github.com/user-attachments/assets/17e12f5c-35d1-4034-8da2-ee13d1856416"">\r\n<img width=""338"" alt=""image"" src=""https://github.com/user-attachments/assets/ba5277de-2c93-4341-8b1f-c5c790af800f"">\r\n<img width=""1258"" alt=""image"" src=""https://github.com/user-attachments/assets/0a55fa6e-285a-4110-adf9-4e5bcca5e4c5"">', 'created_at': datetime.datetime(2024, 8, 1, 4, 47, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263755047, 'issue_id': 2440053651, 'author': 'Tony-metabase', 'body': 'Can you go to Admin -> Table Metadata -> Order Logs Snapshot -> city_name and share a screenshot of the settings there as well please', 'created_at': datetime.datetime(2024, 8, 1, 18, 55, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264761754, 'issue_id': 2440053651, 'author': 'harshith-bolar-rapido', 'body': '@Tony-metabase \r\n\r\n<img width=""901"" alt=""image"" src=""https://github.com/user-attachments/assets/8689624d-1c2f-41e1-86e7-eb50c1c8ceec"">', 'created_at': datetime.datetime(2024, 8, 2, 7, 36, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264789480, 'issue_id': 2440053651, 'author': 'Tony-metabase', 'body': ""It's possible you are hitting this issue then https://github.com/starburstdata/metabase-driver/issues/44 which seems to be driver related"", 'created_at': datetime.datetime(2024, 8, 2, 7, 52, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265236106, 'issue_id': 2440053651, 'author': 'harshith-bolar-rapido', 'body': ""I see the same behaviour using the default presto driver shipped with Metabase, don't think this is a Starburst driver issue.\r\n\r\nAnother observation - Caching of field filters works in saved dashboards but not in saved questions."", 'created_at': datetime.datetime(2024, 8, 2, 12, 20, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309543681, 'issue_id': 2440053651, 'author': 'sabyasachinandy', 'body': '@Tony-metabase Can you please help us as with what to check in the driver?', 'created_at': datetime.datetime(2024, 8, 26, 7, 36, 7, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-31 14:09:30 UTC): @harshith-bolar-rapido you can get your values cached if you go to Admin -> Table Metadata -> Select your database, schema, table, field -> And set `Filtering on this field` to `A list of all values`. This will only work if there are less than about a thousand unique values for this field.

harshith-bolar-rapido (Issue Creator) on (2024-07-31 14:34:19 UTC): @ranquild I tried this, set the field to `A list of all values`, hit re-scan this field, it triggered a query which finished successfully. Then I reloaded the question and clicked on the drop down filter, and it fired the same query again to fetch filter values. And the field has only about 100 unique values.

Is there any way I can validate that it is actually caching something?

Tony-metabase on (2024-07-31 15:32:28 UTC): Go to the Application Database and find the `metabase_fieldvalues` table and you should find the filter values there if they are getting cached:

<img width=""1506"" alt=""image"" src=""https://github.com/user-attachments/assets/d54abcbb-a75f-4716-889f-16643e7145c1"">

harshith-bolar-rapido (Issue Creator) on (2024-08-01 04:47:02 UTC): Verified that the field values are stored in `metabase_fieldvalues` table. But in the question it still triggers another query to the DB to fetch these values. Added screenshots for reference.

<img width=""479"" alt=""image"" src=""https://github.com/user-attachments/assets/17e12f5c-35d1-4034-8da2-ee13d1856416"">
<img width=""338"" alt=""image"" src=""https://github.com/user-attachments/assets/ba5277de-2c93-4341-8b1f-c5c790af800f"">
<img width=""1258"" alt=""image"" src=""https://github.com/user-attachments/assets/0a55fa6e-285a-4110-adf9-4e5bcca5e4c5"">

Tony-metabase on (2024-08-01 18:55:56 UTC): Can you go to Admin -> Table Metadata -> Order Logs Snapshot -> city_name and share a screenshot of the settings there as well please

harshith-bolar-rapido (Issue Creator) on (2024-08-02 07:36:05 UTC): @Tony-metabase 

<img width=""901"" alt=""image"" src=""https://github.com/user-attachments/assets/8689624d-1c2f-41e1-86e7-eb50c1c8ceec"">

Tony-metabase on (2024-08-02 07:52:48 UTC): It's possible you are hitting this issue then https://github.com/starburstdata/metabase-driver/issues/44 which seems to be driver related

harshith-bolar-rapido (Issue Creator) on (2024-08-02 12:20:40 UTC): I see the same behaviour using the default presto driver shipped with Metabase, don't think this is a Starburst driver issue.

Another observation - Caching of field filters works in saved dashboards but not in saved questions.

sabyasachinandy on (2024-08-26 07:36:07 UTC): @Tony-metabase Can you please help us as with what to check in the driver?

"
2439554098,issue,open,,"""Refused to apply inline style"" in detectElementResize.js:140 on cloud-hosted metabase","### Describe the bug

We are embedding a cloud-hosted metabase dashboard via the URL
 `XXX.metabaseapp.com/embed/dashboard/eXXXXXX?bordered=false&titled=false`
inside an iframe and am getting the following Browser-Console error:
```
detectElementResize.js:140 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-nrkotVoP7Q'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-deDIoPlRijnpfbTDYsK+8JmDfUBmpwpnb0L/SUV8NeU='), or a nonce ('nonce-...') is required to enable inline execution.
```

The culprit seems to be the attempt by `detectElementResize.js` to inject a style element into the page which is not allowed by the CSP Settings on `XXX.metabaseapp.com`.

The Error also exists, when not embedding the URL inside an iframe, but just open it in a new tab, so we can rule out our own CSP Settings.

I think the settings on `XXX.metabaseapp.com` are wrong or the `detectElementResize.js` script is missing a nonce that would allow it to inject style tags into the page.

Visually, it does not impact us, all the data we need is displayed, but we do get error reports for the CSP violation and we do not know what the injected style would change.
Maybe we are missing out on something, maybe not.

### To Reproduce

Not sure how to reproduce because I don't know what causes `detectElementResize.js` to be called. But if it gets calles on a cloud-hosted dashboard, the CSP Violation should be reproducible.

### Expected behavior

There would be no CSP Violations on a cloud-hosted dashboard.

### Logs

Full Browser console log:
```
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
Third-party cookie will be blocked in future Chrome versions as part of Privacy Sandbox.
metadata.js:16 DEPRECATED: metabase/redux/metadata addParamValues
g @ metadata.js:16
I @ metadata.js:107
(anonymous) @ data-fetching.js:258
await in (anonymous)
(anonymous) @ redux-toolkit.esm.js:1237
(anonymous) @ redux-toolkit.esm.js:38
(anonymous) @ redux-toolkit.esm.js:41
(anonymous) @ redux-toolkit.esm.js:87
(anonymous) @ redux-toolkit.esm.js:69
(anonymous) @ redux-toolkit.esm.js:1276
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
_initialize @ PublicDashboard.jsx:78
componentDidMount @ PublicDashboard.jsx:99
(anonymous) @ react-dom.production.min.js:212
a$ @ react-dom.production.min.js:213
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
aX @ react-dom.production.min.js:248
aW @ react-dom.production.min.js:239
aq @ react-dom.production.min.js:230
si @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
aD @ react-dom.production.min.js:240
sp @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
x2 @ app.js:75
x3 @ app.js:106
57505 @ app-embed.js:12
a @ bootstrap:19
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
a.O @ chunk loaded:25
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
i @ jsonp chunk loading:73
(anonymous) @ app-embed.d783b56e027c066dec63.js:7
metadata.js:16 DEPRECATED: metabase/redux/metadata addParamValues
g @ metadata.js:16
I @ metadata.js:107
(anonymous) @ data-fetching.js:258
await in (anonymous)
(anonymous) @ redux-toolkit.esm.js:1237
(anonymous) @ redux-toolkit.esm.js:38
(anonymous) @ redux-toolkit.esm.js:41
(anonymous) @ redux-toolkit.esm.js:87
(anonymous) @ redux-toolkit.esm.js:69
(anonymous) @ redux-toolkit.esm.js:1276
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
_initialize @ PublicDashboard.jsx:78
componentDidMount @ PublicDashboard.jsx:99
(anonymous) @ react-dom.production.min.js:212
a$ @ react-dom.production.min.js:213
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
aX @ react-dom.production.min.js:248
aW @ react-dom.production.min.js:239
aq @ react-dom.production.min.js:230
si @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
aD @ react-dom.production.min.js:240
sp @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
x2 @ app.js:75
x3 @ app.js:106
57505 @ app-embed.js:12
a @ bootstrap:19
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
a.O @ chunk loaded:25
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
i @ jsonp chunk loading:73
(anonymous) @ app-embed.d783b56e027c066dec63.js:7
metadata.js:16 DEPRECATED: metabase/redux/metadata addFields
g @ metadata.js:16
D @ metadata.js:113
(anonymous) @ data-fetching.js:261
await in (anonymous)
(anonymous) @ redux-toolkit.esm.js:1237
(anonymous) @ redux-toolkit.esm.js:38
(anonymous) @ redux-toolkit.esm.js:41
(anonymous) @ redux-toolkit.esm.js:87
(anonymous) @ redux-toolkit.esm.js:69
(anonymous) @ redux-toolkit.esm.js:1276
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
_initialize @ PublicDashboard.jsx:78
componentDidMount @ PublicDashboard.jsx:99
(anonymous) @ react-dom.production.min.js:212
a$ @ react-dom.production.min.js:213
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
aX @ react-dom.production.min.js:248
aW @ react-dom.production.min.js:239
aq @ react-dom.production.min.js:230
si @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
aD @ react-dom.production.min.js:240
sp @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
x2 @ app.js:75
x3 @ app.js:106
57505 @ app-embed.js:12
a @ bootstrap:19
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
a.O @ chunk loaded:25
(anonymous) @ app-embed.d783b56e027c066dec63.js:168
i @ jsonp chunk loading:73
(anonymous) @ app-embed.d783b56e027c066dec63.js:7
detectElementResize.js:140 Refused to apply inline style because it violates the following Content Security Policy directive: ""style-src 'self' 'nonce-nrkotVoP7Q'   https://accounts.google.com"". Either the 'unsafe-inline' keyword, a hash ('sha256-deDIoPlRijnpfbTDYsK+8JmDfUBmpwpnb0L/SUV8NeU='), or a nonce ('nonce-...') is required to enable inline execution.

v @ detectElementResize.js:140
addResizeListener @ detectElementResize.js:157
value @ AutoSizer.js:105
(anonymous) @ react-dom.production.min.js:212
a$ @ react-dom.production.min.js:213
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
aX @ react-dom.production.min.js:248
aW @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
on @ react-dom.production.min.js:122
oi @ react-dom.production.min.js:123
oo @ react-dom.production.min.js:122
aT @ react-dom.production.min.js:240
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
o @ Subscription.js:93
b @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
t.type @ utils.js:204
```

### Information about your Metabase installation

```JSON
- cloud hosted
- chrome browser (`Version 127.0.6533.72 (Official Build) (64-bit)`)
```


### Severity

low

### Additional context

_No response_",felix-wtfoxtrot,2024-07-31 09:18:04+00:00,[],2025-02-04 20:25:53+00:00,,https://github.com/metabase/metabase/issues/46319,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]",[],
2439506402,issue,closed,completed,Click behavior | Custom destination | URL interpolation - Values from the returned rows not present in the visualization are interpolable in the URL but don't have values,"### Describe the bug

When creating a custom click behaviour to open a link from a visualization, we are prompted to use any of the query columns in the URL interpolation.

However, using a value not used in the visualization itself ends up with an empty value, meaning that we cannot really use it in the URL.

### To Reproduce

1. Create a new Dashboard
2. Add a new SQL question to that dashboard. To use an an example you can use this query:

<details>

<summary>SQL Query</summary>

```sql
WITH data AS (
    SELECT 
        ('group_1') AS main_group,
        ('sub_group_1') AS sub_group,
        (1) AS value,
    
    UNION ALL
    SELECT 
        ('group_1') AS main_group,
        ('sub_group_1') AS sub_group,
        (77) AS value,
        
    UNION ALL
    SELECT 
        ('group_1') AS main_group,
        ('sub_group_1') AS sub_group,
        (33) AS value,
        
    UNION ALL
    SELECT 
        ('group_1') AS main_group,
        ('sub_group_2') AS sub_group,
        (2) AS value,
    
    UNION ALL
    SELECT 
        ('group_1') AS main_group,
        ('sub_group_2') AS sub_group,
        (66) AS value,
        
    UNION ALL
    SELECT 
        ('group_2') AS main_group,
        ('sub_group_1') AS sub_group,
        (67) AS value,
        
    UNION ALL
    SELECT 
        ('group_2') AS main_group,
        ('sub_group_1') AS sub_group,
        (12) AS value,
    
    UNION ALL
    SELECT 
        ('group_2') AS main_group,
        ('sub_group_2') AS sub_group,
        (44) AS value
    
    UNION ALL
    SELECT 
        ('group_2') AS main_group,
        ('sub_group_2') AS sub_group,
        (8) AS value
)

SELECT
    main_group,
    sub_group,
    SUM(value) AS value_sum,
    CONCAT(main_group, '__', sub_group) AS group_name
FROM DATA
GROUP BY main_group, sub_group;
```

Expected result:

|main_group|sub_group  |value_sum|group_name          |
|----------|-----------|---------|--------------------|
|group_1   |sub_group_1|111      |group_1__sub_group_1|
|group_1   |sub_group_2|68       |group_1__sub_group_2|
|group_2   |sub_group_1|79       |group_2__sub_group_1|
|group_2   |sub_group_2|52       |group_2__sub_group_2|


</details>

3. Set the visualization type to `Row`
4. Configure the visualization like in the following image:
<details>

<summary>Row Visualization Configuration</summary>

![Screenshot 2024-07-31 at 10 51 34](https://github.com/user-attachments/assets/d83de23f-cd56-4283-899a-11d90e3394c9)

Expected result:
![Screenshot 2024-07-31 at 10 51 41](https://github.com/user-attachments/assets/da1c5815-1e1d-4a76-86d5-363f649f3b8b)


</details>

5. Add a custom click behaviour on that dashboard -> question
6. Set it to a Custom desintation and interpolate the value `{{group_name}}`, you can use this as an example: `https://google.com/search?q=data:{{group_name}}`
7. Save the dashboard
8. Click on any of the 4 rows in the dashboard

### Expected behavior

* The expected behaviour would be to arrive at `https://google.com/search?q=data:something`
* The actual behaviour is that we arrive at `https://google.com/search?q=data:` (no value after `data:`)

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Browser: Chrome 127.0.6533.73
- OS: MacOS 14.6 (23G80)
- Databases: BigQuery
- Metabase: SAAS version
```


### Severity

annoying

### Additional context

_No response_",jsmrcaga,2024-07-31 08:56:38+00:00,['kamilmielnik'],2024-11-07 09:38:17+00:00,2024-11-07 08:54:51+00:00,https://github.com/metabase/metabase/issues/46318,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2439015110,issue,closed,completed,Sync indexes will mark all fields of the same name as indexed if one of them is,"### Describe the bug

For Mongo DB you can have nested fields with the same name.
If one of the field with the same name is indexded, we'll mark all of them as indexed. This is wrong.

### To Reproduce

1. Create a Mongo DB
```
db.duplicate_indexed.insertOne({""name"": ""Ngoc"", ""class"": {""name"": ""Physics""}});
db.duplicate_indexed.createIndex({""name"": 1})
```

2. sync this DB and check that both `name` and `class.name` are indexed.

### Expected behavior

only one of them is indexed

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

P2 since this info is not really used anywhere. Though it creates OOM for one of our customer because they have million of column with the same name.

### Additional context

_No response_",qnkhuat,2024-07-31 03:10:31+00:00,['qnkhuat'],2024-08-02 08:52:24+00:00,2024-07-31 07:27:36+00:00,https://github.com/metabase/metabase/issues/46312,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2264893465, 'issue_id': 2439015110, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)', 'created_at': datetime.datetime(2024, 8, 2, 8, 52, 23, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-08-02 08:52:23 UTC): 🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)

"
2438943859,issue,open,,Aggregation by Timestamp (Day) Results in Multiple Values Per Day,"### Describe the bug

![image](https://github.com/user-attachments/assets/df17d81b-4364-4aca-9a97-b9e80103b7f1)

I'm encountering an issue when trying to aggregate data in Metabase by a timestamp field (timestamp) grouped by day. Despite grouping by day, I'm seeing multiple values being returned for each day, which is unexpected and making it difficult to interpret the data correctly.

### To Reproduce

Navigate to the dataset or question in Metabase that contains the timestamp field you're working with.
Attempt to create a visualization or query that aggregates the data by the timestamp field, specifically grouping by day.
Observe that for each day, multiple values are being returned instead of a single aggregated value (e.g., sum, average, etc.).

### Expected behavior

When grouping by day, I expect to see a single aggregated value per day for the selected aggregation method (e.g., sum of a numeric column).

### Logs

_No response_

### Information about your Metabase installation

```JSON
metabase version 50.7
```


### Severity

use other version

### Additional context

[query_result_2024-07-31T01_35_06.428037Z.csv](https://github.com/user-attachments/files/16435153/query_result_2024-07-31T01_35_06.428037Z.csv)
",cverdela,2024-07-31 01:44:27+00:00,[],2025-02-04 20:27:51+00:00,,https://github.com/metabase/metabase/issues/46310,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2259477287, 'issue_id': 2438943859, 'author': 'perivamsi', 'body': 'Can you show the query builder please?', 'created_at': datetime.datetime(2024, 7, 31, 1, 47, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259510879, 'issue_id': 2438943859, 'author': 'cverdela', 'body': ""```\r\nSELECT \r\n    s.id,\r\n    case when s.timestamp !='0' then floor(s.timestamp/1000)  else '0' end as timestamp,\r\n    s.host,\r\n    s.size,\r\n    s.query_string,\r\n    s.uri,\r\n    s.group_id,\r\n    s.client_ip,\r\n    to_timestamp(TO_char(s.timestamp_str, 'YYYYMMDDHH24mmss'), 'YYYYMMDDHH24mmss') dtime,\r\n    s.cost,\r\n    s.user_id,\r\n    s.status,\r\n    s.route_id,\r\n    s.upstream,\r\n    s.service_name,\r\n    s.service_id\r\nFROM mscm_gg_info.ODS_APISIX_INFO_FWRZFA AS s;\r\n```\r\nCould you please tell me what kind of data format in a database would be suitable for aggregation by month, day, and hour in Metabase?"", 'created_at': datetime.datetime(2024, 7, 31, 2, 17, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627711107, 'issue_id': 2438943859, 'author': 'lbrdnk', 'body': '@cverdela, are you able to reproduce the issue on current Metabase version (52)?', 'created_at': datetime.datetime(2025, 1, 31, 16, 11, 9, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-31 01:47:25 UTC): Can you show the query builder please?

cverdela (Issue Creator) on (2024-07-31 02:17:05 UTC): ```
SELECT 
    s.id,
    case when s.timestamp !='0' then floor(s.timestamp/1000)  else '0' end as timestamp,
    s.host,
    s.size,
    s.query_string,
    s.uri,
    s.group_id,
    s.client_ip,
    to_timestamp(TO_char(s.timestamp_str, 'YYYYMMDDHH24mmss'), 'YYYYMMDDHH24mmss') dtime,
    s.cost,
    s.user_id,
    s.status,
    s.route_id,
    s.upstream,
    s.service_name,
    s.service_id
FROM mscm_gg_info.ODS_APISIX_INFO_FWRZFA AS s;
```
Could you please tell me what kind of data format in a database would be suitable for aggregation by month, day, and hour in Metabase?

lbrdnk on (2025-01-31 16:11:09 UTC): @cverdela, are you able to reproduce the issue on current Metabase version (52)?

"
2438845533,issue,closed,completed,geojson content type validation missing at least one content type,"https://github.com/metabase/metabase/blame/e2086b2f735a4ac556cdaa66e65e4c8a0a3a9c0f/src/metabase/api/geojson.clj#L139

Should allow content-type `application/vnd.geo+json` ",darrengoldner,2024-07-30 23:43:45+00:00,[],2024-08-02 14:27:41+00:00,2024-08-02 13:37:24+00:00,https://github.com/metabase/metabase/issues/46307,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Maps', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2438627243,issue,closed,completed,Embedded dashboards filters converting varchar to int,"**Describe the bug**
Since updating from version 0.50.13 (currently 0.50.17) all of the static embedded dashboards I have an issue with their filters.

Specifically there is a filter called CompanyNumber coming from SQL Server as a varchar(8) and set as a entity key in metabase metadata (changing this to a few diffrent options had no effect), many of the records are numerical strings e.g. '12345678' but some have letters e.g. 'SC123456'.

On the embedded dashboard there is a filter for CompanyNumber that is linked to several cards, when a value is selected that is purely numerical e.g. '12345678' every card that is linked to that filter show the error ""There was a problem displaying this chart.""

The logs indicate that the embedded version of the dashboard is converting the string value of '12345678' in the filter to an int and then passing it to the cards that throw an error as the date type of int is incompatible with the underlying query.

The issue does not occur if the filter is set to a value that has letters e.g. 'SC123456', nor does it occur in public links or when browsing the dashboard directly.

**Logs**
[cb63b40f-e723-4668-8cf6-5b4d95ab26ca] 2024-07-30T21:16:43+01:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: An error occurred during the current command (Done status 0). Conversion failed when converting the varchar value 'CE029299' to data type int.

```json
{:database_id 13,
 :started_at #t ""2024-07-30T20:16:43.437515Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error reducing result rows: An error occurred during the current command (Done status 0). Conversion failed when converting the varchar value 'CE029299' to data type int."",
   :stacktrace
   [""--> query_processor.pipeline$_STAR_reduce_STAR_$fn__56905.invoke(pipeline.clj:74)""
    ""query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:62)""
    ""query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49)""
    ""query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___70094$fn__70095.invoke(cache.clj:214)""
    ""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""
    ""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
    ""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""
    ""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
    ""query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___70094.invoke(cache.clj:210)""
    ""query_processor.pipeline$_STAR_run_STAR_$respond__56917.invoke(pipeline.clj:95)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__81863.invoke(execute.clj:724)""
    ""driver.sql_jdbc.execute$fn__81656$fn__81657.invoke(execute.clj:397)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
    ""driver.sql_jdbc.execute$fn__81656.invokeStatic(execute.clj:391)""
    ""driver.sql_jdbc.execute$fn__81656.invoke(execute.clj:389)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc$fn__109630.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__109630.invoke(sql_jdbc.clj:76)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:61)""
    ""query_processor.execute$run.invoke(execute.clj:55)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__70117.invoke(execute.clj:24)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__70122.invoke(execute.clj:35)""
    ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:215)""
    ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:188)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70108.invoke(cache.clj:241)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__64090.invoke(permissions.clj:118)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64700.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64710.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__70149.invoke(execute.clj:93)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
    ""query_processor.execute$execute.invoke(execute.clj:88)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""query_processor.middleware.enterprise$fn__64727$handle_audit_app_internal_queries__64728$fn__64730.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64738.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75925.invoke(process_userland_query.clj:186)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75994.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__76031.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__65142.invoke(setup.clj:189)""
    ""query_processor.setup$do_with_database_local_settings$fn__65137.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__65132$fn__65133.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:105)""
    ""driver$do_with_driver.invoke(driver.clj:100)""
    ""query_processor.setup$do_with_driver$fn__65132.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__65125$fn__65128.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.setup$do_with_metadata_provider$fn__65125.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__65119.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
    ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
    ""api.public$process_query_for_card_with_id_run_fn$run__98466$fn__98467$fn__98468.invoke(public.clj:140)""
    ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
    ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
    ""api.public$process_query_for_card_with_id_run_fn$run__98466$fn__98467.invoke(public.clj:139)""
    ""query_processor.streaming$_streaming_response$fn__68592$fn__68593$fn__68594.invoke(streaming.clj:175)""
    ""query_processor.streaming$_streaming_response$fn__68592$fn__68593.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__68592.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
    ""async.streaming_response$do_f_async$task__52331.invoke(streaming_response.clj:87)""],
   :error_type :qp,
   :ex-data {:type :qp}}],
 :action_id nil,
 :state ""S0001"",
 :error_type :qp,
 :json_query
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :cache-strategy {:multiplier 10, :min_duration_ms 3000, :type :ttl, :avg-execution-ms 0},
  :viz-settings
  {:gauge.segments [{:color ""#EDF2F5"", :label """", :max 50000, :min 0}],
   :table.cell_column ""AVG Turnover"",
   :table.columns [{:name ""avg"", :enabled true}],
   :table.pivot_column ""Accounts Count"",
   :column_settings
   {""[\""name\"",\""sum\""]"" {:prefix ""£""},
    ""[\""ref\"",[\""field\"",14781,null]]""
    {:link_url ""https://find-and-update.company-information.service.gov.uk/company/{{Company Number}}"", :view_as nil}}},
  :database 13,
  :query {:limit 1, :source-table 845, :aggregation [[:avg [:field 14904 {:base-type :type/BigInteger}]]]},
  :parameters
  [{:type :string/=,
    :value [1234567],
    :slug ""company_number"",
    :id ""3d8d1af0"",
    :target [:dimension [:field 14907 {:base-type :type/Text}]]}]},
 :native
 {:query
  ""SELECT TOP(1) AVG(\""dbo\"".\""TargetAccounts\"".\""AVG Turnover\"") AS \""avg\"" FROM \""dbo\"".\""TargetAccounts\"" WHERE \""dbo\"".\""TargetAccounts\"".\""Company Number\"" = 1234567"",
  :params nil},
 :status :failed,
 :class com.microsoft.sqlserver.jdbc.SQLServerException,
 :stacktrace
 [""com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDatabaseError(SQLServerException.java:261)""
  ""com.microsoft.sqlserver.jdbc.SQLServerResultSet$FetchBuffer$FetchBufferTokenHandler.onDone(SQLServerResultSet.java:5455)""
  ""com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:103)""
  ""com.microsoft.sqlserver.jdbc.TDSParser.parse(tdsparser.java:42)""
  ""com.microsoft.sqlserver.jdbc.SQLServerResultSet$FetchBuffer.nextRow(SQLServerResultSet.java:5558)""
  ""com.microsoft.sqlserver.jdbc.SQLServerResultSet.fetchBufferNext(SQLServerResultSet.java:1821)""
  ""com.microsoft.sqlserver.jdbc.SQLServerResultSet.next(SQLServerResultSet.java:1079)""
  ""com.mchange.v2.c3p0.impl.NewProxyResultSet.next(NewProxyResultSet.java:685)""
  ""--> driver.sql_jdbc.execute$row_thunk$row_thunk_STAR___81842.invoke(execute.clj:644)""
  ""query_processor.reducible$reducible_rows$reify__56930.reduce(reducible.clj:55)""
  ""query_processor.pipeline$_STAR_reduce_STAR_$fn__56905.invoke(pipeline.clj:63)""
  ""query_processor.pipeline$_STAR_reduce_STAR_.invokeStatic(pipeline.clj:62)""
  ""query_processor.pipeline$_STAR_reduce_STAR_.invoke(pipeline.clj:49)""
  ""query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___70094$fn__70095.invoke(cache.clj:214)""
  ""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""
  ""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
  ""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""
  ""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
  ""query_processor.middleware.cache$run_query_with_cache$reduce_SINGLEQUOTE___70094.invoke(cache.clj:210)""
  ""query_processor.pipeline$_STAR_run_STAR_$respond__56917.invoke(pipeline.clj:95)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81863.invoke(execute.clj:724)""
  ""driver.sql_jdbc.execute$fn__81656$fn__81657.invoke(execute.clj:397)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
  ""driver.sql_jdbc.execute$fn__81656.invokeStatic(execute.clj:391)""
  ""driver.sql_jdbc.execute$fn__81656.invoke(execute.clj:389)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc$fn__109630.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__109630.invoke(sql_jdbc.clj:76)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:61)""
  ""query_processor.execute$run.invoke(execute.clj:55)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__70117.invoke(execute.clj:24)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__70122.invoke(execute.clj:35)""
  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:215)""
  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:188)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70108.invoke(cache.clj:241)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__64090.invoke(permissions.clj:118)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64700.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64710.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__70149.invoke(execute.clj:93)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
  ""query_processor.execute$execute.invoke(execute.clj:88)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""query_processor.middleware.enterprise$fn__64727$handle_audit_app_internal_queries__64728$fn__64730.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64738.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75925.invoke(process_userland_query.clj:186)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75994.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__76031.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__65142.invoke(setup.clj:189)""
  ""query_processor.setup$do_with_database_local_settings$fn__65137.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__65132$fn__65133.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:105)""
  ""driver$do_with_driver.invoke(driver.clj:100)""
  ""query_processor.setup$do_with_driver$fn__65132.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__65125$fn__65128.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.setup$do_with_metadata_provider$fn__65125.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__65119.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
  ""api.public$process_query_for_card_with_id_run_fn$run__98466$fn__98467$fn__98468.invoke(public.clj:140)""
  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
  ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
  ""api.public$process_query_for_card_with_id_run_fn$run__98466$fn__98467.invoke(public.clj:139)""
  ""query_processor.streaming$_streaming_response$fn__68592$fn__68593$fn__68594.invoke(streaming.clj:175)""
  ""query_processor.streaming$_streaming_response$fn__68592$fn__68593.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__68592.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
  ""async.streaming_response$do_f_async$task__52331.invoke(streaming_response.clj:87)""],
 :card_id 1229,
 :context :embedded-dashboard,
 :error
 ""An error occurred during the current command (Done status 0). Conversion failed when converting the varchar value 'CE029299' to data type int."",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 2000},
  :type :query,
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :cache-strategy {:multiplier 10, :min-duration-ms 3000, :type :ttl, :avg-execution-ms 0},
  :user-parameters
  [{:value [1234567],
    :type :string/=,
    :slug ""company_number"",
    :id ""3d8d1af0"",
    :target [:dimension [:field 14907 {:base-type :type/Text}]]}],
  :viz-settings
  {:gauge.segments [{:color ""#EDF2F5"", :label """", :max 50000, :min 0}],
   :table.cell_column ""AVG Turnover"",
   :table.columns [{:name ""avg"", :enabled true}],
   :table.pivot_column ""Accounts Count"",
   :column_settings
   {""[\""name\"",\""sum\""]"" {:prefix ""£""},
    ""[\""ref\"",[\""field\"",14781,null]]""
    {:link_url ""https://find-and-update.company-information.service.gov.uk/company/{{Company Number}}"", :view_as nil}}},
  :info
  {:context :embedded-dashboard,
   :card-id 1229,
   :card-name ""Average Turnover 2"",
   :dashboard-id 232,
   :visualization-settings
   {:gauge.segments [{:color ""#EDF2F5"", :label """", :max 50000, :min 0}],
    :table.cell_column ""AVG Turnover"",
    :table.columns [{:name ""avg"", :enabled true}],
    :table.pivot_column ""Accounts Count"",
    :column_settings
    {""[\""name\"",\""sum\""]"" {:prefix ""£""},
     ""[\""ref\"",[\""field\"",14781,null]]""
     {:link_url ""https://find-and-update.company-information.service.gov.uk/company/{{Company Number}}""}}}},
  :database 13,
  :query
  {:limit 1,
   :source-table 845,
   :aggregation [[:aggregation-options [:avg [:field 14904 {:base-type :type/BigInteger}]] {:name ""avg""}]],
   :filter
   [:=
    [:field 14907 {:base-type :type/Text}]
    [:value
     1234567
     {:base_type :type/Text,
      :effective_type :type/Text,
      :coercion_strategy nil,
      :semantic_type :type/PK,
      :database_type ""varchar"",
      :name ""Company Number""}]]}},
 :data {:rows [], :cols []}}
```

**To Reproduce**
Steps to reproduce the behavior:
1. Create dataset that has some purely numerical values (mine is 95% numerical)
2. Create a dashboard that has a filter on that column
3. Create a card that is linked to that filter
4. Staticly embed the dashboard
5. load the embeded dashboard and insert a numerical value into the filter
6. Get error

**Expected behavior**
Cards would apply the filter to their underlying data the same as direct view & publick links

**Screenshots**
![image](https://github.com/user-attachments/assets/6b6cfc07-5c1f-4fbd-b8a2-6dda8af30f93)

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Data source is a MS SQL Server view and the issue has afffected the last few versions after 0.50.13 (tested on 0.50.16, 0.50.17)

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-117-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.37-0ubuntu0.22.04.3""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-26"",
      ""tag"": ""v0.50.17"",
      ""hash"": ""afd6b17""
    },
    ""settings"": {
      ""report-timezone"": ""GMT""
    }
  }
}
```",cedmo8,2024-07-30 20:30:18+00:00,[],2024-08-02 12:41:49+00:00,2024-08-02 12:41:48+00:00,https://github.com/metabase/metabase/issues/46300,[],"[{'comment_id': 2260000628, 'issue_id': 2438627243, 'author': 'cedmo8', 'body': '0.50.18 (patch release) looks like it has a fix for this ""Text Filters turn number like entries into numeric when filtering on static embedding"", I will test tonight.', 'created_at': datetime.datetime(2024, 7, 31, 8, 55, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265293492, 'issue_id': 2438627243, 'author': 'noahmoss', 'body': 'Closing as dupe of https://github.com/metabase/metabase/issues/46240. @cedmo8 Please open a new issue if you continue to see problems', 'created_at': datetime.datetime(2024, 8, 2, 12, 41, 49, tzinfo=datetime.timezone.utc)}]","cedmo8 (Issue Creator) on (2024-07-31 08:55:20 UTC): 0.50.18 (patch release) looks like it has a fix for this ""Text Filters turn number like entries into numeric when filtering on static embedding"", I will test tonight.

noahmoss on (2024-08-02 12:41:49 UTC): Closing as dupe of https://github.com/metabase/metabase/issues/46240. @cedmo8 Please open a new issue if you continue to see problems

"
2438571028,issue,open,,"When window width is small, sql is shown and occupies whole screen","### Describe the bug

We save the user's last setting for showing/not showing the SQL in the GUI editor. If the user has the SQL on by default (I spun up a new instance and had it on, i think), and change the window size to be mobile (i usually work with slip windows in a 14'' mac, and that's enough to reduce it), then the SQL occupies the whole screen and can be confusing for some non-technial users that use the GUI editor.

https://github.com/user-attachments/assets/a6b9a0f2-e78b-47b3-858e-cdbcce2beb79

Small detail but still something to check out

### To Reproduce

Video self-explanatory

### Expected behavior

When I open the GUI editor I expect to see the GUI editor?

### Logs

_No response_

### Information about your Metabase installation

```JSON
-50.x
```


### Severity

p3

### Additional context

_No response_",ignacio-mb,2024-07-30 19:53:59+00:00,[],2025-02-04 20:27:33+00:00,,https://github.com/metabase/metabase/issues/46297,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2438469924,issue,closed,completed,Milestone 2 - Manual auto-archive,"```[tasklist]
### Tasks
- [ ] POST endpoint to archive all stale items in a collection
- [ ] FE add button to archive all items in a collection
- [ ] https://github.com/metabase/metabase/issues/48348
```
",johnswanson,2024-07-30 18:50:21+00:00,['johnswanson'],2025-01-16 14:02:41+00:00,2025-01-16 14:02:41+00:00,https://github.com/metabase/metabase/issues/46292,[],[],
2438110937,issue,closed,completed,OOM error syncing MongoDB collection with large documents,"Other OOM errors in this series: https://github.com/metabase/metabase/issues/46209

Metabase can use so much memory when syncing fields for a MongoDB collection with large documents it can lead to an OOM error.

Here's [a core dump](https://metaboat.slack.com/archives/C010ZSXQY87/p1721939246377189?thread_ts=1721939174.598129&cid=C010ZSXQY87) of an instance where this happened.

### How to reproduce:

1. Start Metabase with 1 GB of maximum heap space by setting -Xmx2g option
2. Execute this script in `mongosh`, assuming there is a database called `test`:
```
use test;

function generateLargeArrayDocument(arraySize) {
  const largeArray = Array.from({ length: arraySize }, (_, index) => ({
    id: index,
    value: Math.random()
  }));
  return {
    _id: new ObjectId(),
    largeArray: largeArray
  };
}

db.createCollection(""oom_test"")

const numDocuments = 500;
const arraySize = 100000;

for (let i = 0; i < numDocuments; i++) {
  db.oom_test.insertOne(generateLargeArrayDocument(arraySize));
}
```

3. Add the database to Metabase, and wait for the sync-fields step to fail. The logs should include a stack trace:
```
2024-07-30 15:05:29,875 ERROR driver.mongo :: Error introspecting collection: oom_test #error {
 :cause Java heap space
 :via
 [{:type java.lang.OutOfMemoryError
   :message Java heap space
   :at [java.util.Arrays copyOfRange Arrays.java 4030]}]
 :trace
 [[java.util.Arrays copyOfRange Arrays.java 4030]
  [java.lang.StringCoding decodeUTF8 StringCoding.java 732]
  [java.lang.StringCoding decode StringCoding.java 257]
  [java.lang.String <init> String.java 507]
  [java.lang.String <init> String.java 561]
  [org.bson.io.ByteBufferBsonInput readString ByteBufferBsonInput.java 155]
  [org.bson.io.ByteBufferBsonInput readCString ByteBufferBsonInput.java 134]
  [org.bson.BsonBinaryReader readBsonType BsonBinaryReader.java 122]
  [org.bson.codecs.DocumentCodec decode DocumentCodec.java 174]
  [org.bson.codecs.DocumentCodec decode DocumentCodec.java 44]
  [org.bson.internal.LazyCodec decode LazyCodec.java 53]
  [org.bson.codecs.ContainerCodecHelper readValue ContainerCodecHelper.java 65]
  [org.bson.codecs.CollectionCodec readValue CollectionCodec.java 86]
  [org.bson.codecs.AbstractCollectionCodec decode AbstractCollectionCodec.java 95]
  [org.bson.codecs.AbstractCollectionCodec decode AbstractCollectionCodec.java 42]
  [org.bson.codecs.ContainerCodecHelper readValue ContainerCodecHelper.java 65]
  [org.bson.codecs.DocumentCodec decode DocumentCodec.java 176]
  [org.bson.codecs.DocumentCodec decode DocumentCodec.java 44]
  [com.mongodb.internal.operation.CommandResultArrayCodec decode CommandResultArrayCodec.java 52]
  [com.mongodb.internal.operation.CommandResultDocumentCodec readValue CommandResultDocumentCodec.java 60]
  [org.bson.codecs.BsonDocumentCodec decode BsonDocumentCodec.java 87]
  [org.bson.codecs.BsonDocumentCodec decode BsonDocumentCodec.java 42]
  [org.bson.internal.LazyCodec decode LazyCodec.java 53]
  [org.bson.codecs.BsonDocumentCodec readValue BsonDocumentCodec.java 104]
  [com.mongodb.internal.operation.CommandResultDocumentCodec readValue CommandResultDocumentCodec.java 63]
  [org.bson.codecs.BsonDocumentCodec decode BsonDocumentCodec.java 87]
  [org.bson.codecs.BsonDocumentCodec decode BsonDocumentCodec.java 42]
  [com.mongodb.internal.connection.ReplyMessage <init> ReplyMessage.java 45]
  [com.mongodb.internal.connection.InternalStreamConnection getCommandResult InternalStreamConnection.java 544]
  [com.mongodb.internal.connection.InternalStreamConnection receiveCommandMessageResponse InternalStreamConnection.java 438]
  [com.mongodb.internal.connection.InternalStreamConnection sendAndReceive InternalStreamConnection.java 354]
  [com.mongodb.internal.connection.UsageTrackingInternalConnection sendAndReceive UsageTrackingInternalConnection.java 114]]}
```
",calherries,2024-07-30 15:25:21+00:00,[],2024-10-15 17:20:56+00:00,2024-10-09 22:07:41+00:00,https://github.com/metabase/metabase/issues/46277,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2297182797, 'issue_id': 2438110937, 'author': 'calherries', 'body': ""This is technically now a P2 because the customer that was hitting it churned, so it's not blocking anyone from using metabase."", 'created_at': datetime.datetime(2024, 8, 19, 18, 28, 58, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-08-19 18:28:58 UTC): This is technically now a P2 because the customer that was hitting it churned, so it's not blocking anyone from using metabase.

"
2438086925,issue,open,,filter on model inserted into middle of regular expression,"### Describe the bug

Adding a filter on a model based on the below athena query inserts the filter value randomly into a regular expression in the middle of the model, e.g. the model:

```
SELECT MIN(appversionname) as min_version,
MAX(appversionname) as max_version,
MIN(message) as example_error,
COUNT(*) as num,
COUNT(distinct hw_serial) as unique,
SUBSTR(regexp_replace(regexp_replace(regexp_replace(regexp_replace(regexp_replace(message, 'https?...(www.)?[-a-zA-Z0-9@:%._\+~#=]{1,256}.[a-zA-Z0-9()]{1,6}\b([-a-zA-Z0-9()@:%_\+.~#?&//=]*)', '<url>'), '(\[|\(|: |= ?-?|port |after )[0-9]+', '<num>'), '''.+''', '<str>'), '[a-fA-F0-9]{8}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{4}-[a-fA-F0-9]{12}', '<uuid>'), '((25[0-5]|(2[0-4]|1\d|[1-9]|)\d)\.?\b){4}', '<ip>'), 1, 1000) as pattern
FROM centraframelog.curated
WHERE received_at > format_datetime((now() - interval '28' hour), 'yyyy-MM-dd-hh') 
AND level = 'error'
GROUP BY 6 
HAVING COUNT(distinct hw_serial) > 1
ORDER BY COUNT(distinct hw_serial) desc
```

turns into this:

<img width=""1932"" alt=""Screenshot 2024-07-30 at 11 07 01 AM"" src=""https://github.com/user-attachments/assets/8f61a14f-5f92-4414-9860-aceb4ff16734"">

Could be related to the parameter substitution issue reported last year https://github.com/metabase/metabase/issues/33878

### To Reproduce

Not sure what the minimal repro case is here i modified that regular expression in the area it's replacing a few times and it still does this i can't tell what it's keying off of.  

### Expected behavior

_No response_

### Logs

nothing interesting in the log about why metabase generates the query this way, just the inevitable athena error trying to execute it:

[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. line 7:103: mismatched input '.817'. Expecting: '%', ')', '*', '+', ',', '-', '/', 'AT', 'ORDER', '||' [Execution ID not available]

### Information about your Metabase installation

```JSON
- Metabase version: 0.50.17
- Database:  Athena
```


### Severity

blocking some users

### Additional context

_No response_",ericcj,2024-07-30 15:13:49+00:00,[],2025-02-04 20:27:56+00:00,,https://github.com/metabase/metabase/issues/46275,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('Database/Athena', ''), ('.Team/Querying', '')]","[{'comment_id': 2302599263, 'issue_id': 2438086925, 'author': 'ericcj', 'body': 'this bug still exists in 0.50.21 FYI so was unrelated to #46547 but looks like you already knew that based on the tagging', 'created_at': datetime.datetime(2024, 8, 21, 17, 22, 53, tzinfo=datetime.timezone.utc)}]","ericcj (Issue Creator) on (2024-08-21 17:22:53 UTC): this bug still exists in 0.50.21 FYI so was unrelated to #46547 but looks like you already knew that based on the tagging

"
2438043078,issue,open,,"Pivot table row grand total and sub totals have the same color, and that can confuse users","**Is your feature request related to a problem? Please describe.**
Having the same color can confuse users and it can be difficult to identify each row

![Screenshot 2024-07-30 at 11 52 04 AM](https://github.com/user-attachments/assets/842cb041-9351-4d30-9d98-a99100c19b4b)

**Describe the solution you'd like**
Would be good for some users to have the ability to change the color of row totals and grand totals

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket [27705](https://metabase.zendesk.com/agent/tickets/27705)

**Additional context**
n.a
",ignacio-mb,2024-07-30 14:53:26+00:00,[],2024-07-30 14:53:27+00:00,,https://github.com/metabase/metabase/issues/46273,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]",[],
2437825163,issue,open,,Visually notify that a report has drill-down capabilities,"**Is your feature request related to a problem? Please describe.**
Users might not be taking advantage of drill-down capabilities, and as some of them don't (SQL cards), they don't know when they can do drill-down and when they can't in a dashboard.

**Describe the solution you'd like**
Somehow visually tell that a card can be drilled down

**Describe alternatives you've considered**
Adding a text card to the dashboard, but not ideal

**How important is this feature to you?**
Requested by a customer, internal ticket [27705](https://metabase.zendesk.com/agent/tickets/27705)

**Additional context**
N/A
",ignacio-mb,2024-07-30 13:18:58+00:00,[],2024-07-30 13:18:59+00:00,,https://github.com/metabase/metabase/issues/46267,"[('Visualization/', ''), ('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('.Frontend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus')]",[],
2437756902,issue,closed,completed,"Having a "" as part of a table name will break the sync","### Describe the bug

If you have a table name with as `test_""` it will break the sync altogether. 

The problem is that in Metabase you can setup model caching and tables will get created like `model_xxx_mymodel` .. If you create a name with "" like `model_1268_""test` ... It will completely break your syncing

### To Reproduce

1) Create a table with a `""` inside the name
2) Try to sync

More context here https://metaboat.slack.com/archives/C010L1Z4F9S/p1722338194656089

### Expected behavior

Tables will sync

### Logs
```
metabase  | 2024-07-30 05:48:00,679 INFO sync.util :: STARTING: Sync metadata for postgres Database 2 ''postgres_db''
metabase  | 2024-07-30 05:48:01,717 ERROR sync.fetch-metadata :: Error while fetching metdata with 'db-metadata'
metabase  | org.postgresql.util.PSQLException: ERROR: invalid name syntax
```
### Information about your Metabase installation

```JSON
Tested on 49 and 50 but also happens on master
```


### Severity

Silently stops the sync and scans 

### Additional context

_No response_",Tony-metabase,2024-07-30 12:46:24+00:00,['calherries'],2024-12-24 11:37:26+00:00,2024-07-30 15:10:58+00:00,https://github.com/metabase/metabase/issues/46265,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2258308016, 'issue_id': 2437756902, 'author': 'shivam-alraedah', 'body': 'Team, if we can also do a bit more context based logging about the reason of failure that would make the debugging easier.\r\nThanks', 'created_at': datetime.datetime(2024, 7, 30, 13, 6, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259228372, 'issue_id': 2437756902, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.18](https://github.com/metabase/metabase/milestone/259)', 'created_at': datetime.datetime(2024, 7, 30, 21, 18, 43, tzinfo=datetime.timezone.utc)}]","shivam-alraedah on (2024-07-30 13:06:29 UTC): Team, if we can also do a bit more context based logging about the reason of failure that would make the debugging easier.
Thanks

github-actions[bot] on (2024-07-30 21:18:43 UTC): 🚀 This should also be released by [v0.50.18](https://github.com/metabase/metabase/milestone/259)

"
2437500415,issue,closed,completed,upgrade jest related packages,,uladzimirdev,2024-07-30 10:36:12+00:00,[],2024-10-08 16:19:17+00:00,2024-07-30 12:56:00+00:00,https://github.com/metabase/metabase/issues/46264,[],[],
2437333875,issue,open,,Type parameter values,"- [We shouldn't use `any` for `Parameter[""value""]` or `Parameter[""default""]`](https://github.com/metabase/metabase/blob/0d5bc020d780d4ca86474c992f4fd4a49ee4a45b/frontend/src/metabase-types/api/parameters.ts#L47-L52)
- [`TemplateTag[""default""]` is incorrect (see below)](https://github.com/metabase/metabase/blob/bab6387cdff29b616c77eeff11ac39b6d212f1d5/frontend/src/metabase-types/api/dataset.ts#L144)


Value can be:
- a string (e.g. text filter)
- an array of strings (e.g. string contains filter)
- an array of numbers (e.g. number between filter)
- possibly `null` or `undefined`

TODO: verify the above list (it may not be exhaustive)

----

If we can't type this we should at least use `unknown` instead of `any`.",kamilmielnik,2024-07-30 09:16:06+00:00,[],2024-07-30 09:46:27+00:00,,https://github.com/metabase/metabase/issues/46263,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2257936183, 'issue_id': 2437333875, 'author': 'kamilmielnik', 'body': 'Search the codebase for `https://github.com/metabase/metabase/issues/46263` to see TODOs related to this.', 'created_at': datetime.datetime(2024, 7, 30, 9, 46, 26, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-07-30 09:46:26 UTC): Search the codebase for `https://github.com/metabase/metabase/issues/46263` to see TODOs related to this.

"
2436839172,issue,closed,completed,"[Mongo] Failed to fingerprint table with PK of type ""ObjectID""","### Describe the bug

It fails to fingerprint mongo tables with PK of type ObjectID, which is very common.
Mongo

### To Reproduce

1. Create a mongo DB with this collection
```
db.myCollection.insertMany([
  { name: ""Eminem"" }
]);
```
2. Sync it, observe log

### Expected behavior

Fingerprint succeed without errors

### Logs

```
2024-07-30 04:04:00,167 WARN sync.util :: Error fingerprinting Table 29 ''myCollection''
clojure.lang.ExceptionInfo: Error preprocessing query in #'metabase.query-processor.middleware.normalize-query/normalize-preprocessing-middleware: Error normalizing query: Error creating query from legacy query: Invalid output: {:stages [{:order-by [[nil nil [""an expression that can b
e compared with :> or :<, got: [:field {:lib/uuid \""88af652b-b169-4930-a34a-1c4dd9de5a22\"", :metabase.lib.query/transformation-added-base-type true, :base-type :type/MongoBSONID, :effective-type :type/MongoBSONID} 355]""]]]}]} {:fn #'metabase.query-processor.middleware.normalize-query/
normalize-preprocessing-middleware, :query {:database 4, :type :query, :query {:source-table 29, :expressions {""substring199343"" [:substring [:field 356 nil] 1 1234]}, :fields [[:expression ""substring199343""]], :limit 500, :order-by [[:desc [:field 355 nil]]]}, :middleware {:format-ro
ws? false, :skip-results-metadata? true}}, :type :qp}
        at metabase.query_processor.preprocess$fn__109470$_AMPERSAND_f__109471$fn__109472$fn__109473.invoke(preprocess.clj:150)
        at clojure.lang.PersistentVector.reduce(PersistentVector.java:343)
        at clojure.core$transduce.invokeStatic(core.clj:6947)
        at clojure.core$transduce.invoke(core.clj:6934)
        at metabase.query_processor.preprocess$fn__109470$_AMPERSAND_f__109471$fn__109472.invoke(preprocess.clj:124)
        at metabase.query_processor.setup$fn__109435$_AMPERSAND_f__109436.invoke(setup.clj:225)
        at metabase.query_processor.setup$fn__109435$fn__109440.invoke(setup.clj:216)
        at metabase.query_processor.preprocess$fn__109470$_AMPERSAND_f__109471.invoke(preprocess.clj:122)
        at metabase.query_processor.preprocess$fn__109470$fn__109485.invoke(preprocess.clj:118)
        at metabase.query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:46)
        at metabase.query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)
        at metabase.query_processor.middleware.enterprise$eval104531$handle_audit_app_internal_queries__104532$fn__104534.invoke(enterprise.clj:96)
        at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__104542.invoke(enterprise.clj:103)
        at metabase.query_processor.middleware.process_userland_query$fn__110355$_AMPERSAND_f__110356$_AMPERSAND_f__110357.invoke(process_userland_query.clj:182)
        at metabase.query_processor.middleware.process_userland_query$fn__110355$_AMPERSAND_f__110356$fn__110363.invoke(process_userland_query.clj:179)
        at metabase.query_processor.middleware.catch_exceptions$fn__110182$_AMPERSAND_f__110183$_AMPERSAND_f__110184.invoke(catch_exceptions.clj:121)
        at metabase.query_processor.middleware.catch_exceptions$fn__110182$_AMPERSAND_f__110183$fn__110196.invoke(catch_exceptions.clj:118)
        at metabase.query_processor$fn__110685$_AMPERSAND_f__110686$fn__110687.invoke(query_processor.clj:80)
        at metabase.query_processor.setup$fn__109427$_AMPERSAND_f__109428$fn__109429.invoke(setup.clj:189)
        at metabase.query_processor.setup$fn__109417$_AMPERSAND_f__109418$fn__109419.invoke(setup.clj:181)
        at metabase.query_processor.setup$fn__109407$_AMPERSAND_f__109408$fn__109409$fn__109410.invoke(setup.clj:166)
        at metabase.driver$do_with_driver.invokeStatic(driver.clj:106)
        at metabase.driver$do_with_driver.invoke(driver.clj:101)
        at metabase.query_processor.setup$fn__109407$_AMPERSAND_f__109408$fn__109409.invoke(setup.clj:165)
        at metabase.query_processor.setup$fn__109395$_AMPERSAND_f__109396$fn__109397.invoke(setup.clj:140)
        at metabase.query_processor.setup$fn__109377$_AMPERSAND_f__109378$_AMPERSAND_f__109379.invoke(setup.clj:128)
        at metabase.query_processor.setup$fn__109377$_AMPERSAND_f__109378$fn__109382.invoke(setup.clj:122)
        at metabase.query_processor.setup$fn__109435$_AMPERSAND_f__109436.invoke(setup.clj:232)
        at metabase.query_processor.setup$fn__109435$fn__109440.invoke(setup.clj:216)
        at metabase.query_processor$fn__110685$_AMPERSAND_f__110686.invoke(query_processor.clj:78)
        at metabase.query_processor$fn__110685$fn__110691.invoke(query_processor.clj:71)
        at metabase.db.metadata_queries$fn__196222$_AMPERSAND_f__196223.invoke(NO_SOURCE_FILE:219)
        at metabase.db.metadata_queries$fn__196222$fn__196225.invoke(NO_SOURCE_FILE:201)
        at metabase.driver.mongo$eval198870$fn__198871$fn__198872.invoke(NO_SOURCE_FILE:344)
        at metabase.query_processor.store$fn__96270$_AMPERSAND_f__96271.invoke(store.clj:166)
        at metabase.query_processor.store$fn__96270$fn__96274.invoke(store.clj:151)
        at metabase.driver.mongo$eval198870$fn__198871.invoke(NO_SOURCE_FILE:341)
        at clojure.lang.MultiFn.invoke(MultiFn.java:252)
        at metabase.sync.analyze.fingerprint$fn__198245$_AMPERSAND_f__198246.invoke(NO_SOURCE_FILE:88)
        at metabase.sync.analyze.fingerprint$fn__198245$fn__198259.invoke(NO_SOURCE_FILE:65)
        at metabase.sync.analyze.fingerprint$fn__139433$_AMPERSAND_f__139434$fn__139435.invoke(fingerprint.clj:206)
        at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189)
        at metabase.sync.util$do_with_error_handling.invoke(util.clj:182)
        at metabase.sync.analyze.fingerprint$fn__139433$_AMPERSAND_f__139434.invoke(fingerprint.clj:204)
        at metabase.sync.analyze.fingerprint$fn__139433$fn__139441.invoke(fingerprint.clj:198)
        at metabase.sync.analyze.fingerprint$fn__139444$_AMPERSAND_f__139445$fn__139446$fn__139447.invoke(fingerprint.clj:230)
        at clojure.core$completing$fn__8528.invoke(core.clj:6932)
        at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)
        at toucan2.pipeline$with_init$fn__58064.invoke(pipeline.clj:327)
        at clojure.core$completing$fn__8528.invoke(core.clj:6932)
        at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)
        at toucan2.jdbc.result_set$reduce_result_set.invokeStatic(result_set.clj:158)
        at toucan2.jdbc.result_set$reduce_result_set.invoke(result_set.clj:125)
        at toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:51)
        at toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$eval14962$fn__14963$fn__14964$fn__14971.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__14930$fn__14934.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__14930.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__14940.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_execute$with_connection_STAR___57962.invoke(pipeline.clj:78)
        at toucan2.connection$bind_current_connectable_fn$fn__57543.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__57543.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__57543.invoke(connection.clj:104)
        at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invokeStatic(connection.clj:18)
        at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invoke(connection.clj:15)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$eval14962$fn__14963$fn__14964$fn__14965.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__14930$fn__14934.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
               at metabase.sync.analyze.fingerprint$fn__139444$_AMPERSAND_f__139445$fn__139446.invoke(fingerprint.clj:228)
        at metabase.query_processor.store$fn__96270$_AMPERSAND_f__96271.invoke(store.clj:171)
        at metabase.query_processor.store$fn__96270$fn__96274.invoke(store.clj:151)
        at metabase.query_processor.store$fn__96270$_AMPERSAND_f__96271.invoke(store.clj:160)
        at metabase.query_processor.store$fn__96270$fn__96274.invoke(store.clj:151)
        at metabase.sync.analyze.fingerprint$fn__139444$_AMPERSAND_f__139445.invoke(fingerprint.clj:224)
        at metabase.sync.analyze.fingerprint$fn__139444$fn__139451.invoke(fingerprint.clj:215)
        at metabase.sync.analyze.fingerprint$fn__139444$_AMPERSAND_f__139445.invoke(fingerprint.clj:219)
        at metabase.sync.analyze.fingerprint$fn__139444$fn__139451.invoke(fingerprint.clj:215)
        at metabase.sync.analyze.fingerprint$fn__139454$_AMPERSAND_f__139455.invoke(fingerprint.clj:242)
        at metabase.sync.analyze.fingerprint$fn__139454$fn__139457.invoke(fingerprint.clj:237)
        at metabase.sync.analyze$make_analyze_steps$fn__139583.invoke(analyze.clj:100)
        at clojure.lang.AFn.applyToHelper(AFn.java:154)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.sync.util$fn__98447$_AMPERSAND_f__98449$fn__98451$fn__98454.invoke(util.clj:490)
        at metabase.models.task_history$fn__98197$_AMPERSAND_f__98198.invoke(task_history.clj:116)
        at metabase.models.task_history$fn__98197$fn__98201.invoke(task_history.clj:105)
        at metabase.sync.util$fn__98447$_AMPERSAND_f__98449$fn__98451.doInvoke(util.clj:483)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:124)
        at metabase.sync.util$do_with_start_and_finish_debug_logging.invokeStatic(util.clj:148)
        at metabase.sync.util$do_with_start_and_finish_debug_logging.invoke(util.clj:144)
        at metabase.sync.util$fn__98447$_AMPERSAND_f__98449.invoke(util.clj:477)
        at metabase.sync.util$fn__98447$fn__98460.invoke(util.clj:472)
        at metabase.sync.util$fn__98506$_AMPERSAND_f__98507$fn__98508$fn__98516.invoke(util.clj:563)
        at metabase.sync.util$fn__98506$_AMPERSAND_f__98507$fn__98508.invoke(util.clj:561)
        at metabase.models.task_history$fn__98197$_AMPERSAND_f__98198.invoke(task_history.clj:116)
        at metabase.models.task_history$fn__98197$fn__98201.invoke(task_history.clj:105)
        at metabase.sync.util$fn__98506$_AMPERSAND_f__98507.invoke(util.clj:558)
        at metabase.sync.util$fn__98506$fn__98526.invoke(util.clj:553)
        at metabase.sync.analyze$fn__139590$_AMPERSAND_f__139591$fn__139592.invoke(analyze.clj:116)
        at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:189)
        at metabase.sync.util$do_with_error_handling.invoke(util.clj:182)
        at clojure.core$partial$fn__5910.invoke(core.clj:2647)
        at metabase.driver.mongo$eval198412$fn__198413$f__126226__auto____198414.invoke(NO_SOURCE_FILE:104)
        at metabase.driver.mongo.connection$do_with_mongo_client$fn__126217.invoke(connection.clj:94)
        at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
        at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
        at metabase.driver.mongo.connection$do_with_mongo_client.invokeStatic(connection.clj:89)
        at metabase.driver.mongo.connection$do_with_mongo_client.invoke(connection.clj:85)
        at metabase.driver.mongo$eval198412$fn__198413.invoke(NO_SOURCE_FILE:103)
        at clojure.lang.MultiFn.invoke(MultiFn.java:239)
        at metabase.sync.util$sync_in_context$fn__98326.invoke(util.clj:165)
        at metabase.sync.util$with_db_logging_disabled$fn__98323.invoke(util.clj:157)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:130)
```

### Information about your Metabase installation

```JSON
master
```


### Severity

Regressions that exist in 50

### Additional context

_No response_",qnkhuat,2024-07-30 04:07:21+00:00,['snoe'],2024-08-28 02:09:01+00:00,2024-08-05 19:15:18+00:00,https://github.com/metabase/metabase/issues/46259,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Mongo', None), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2257417958, 'issue_id': 2436839172, 'author': 'qnkhuat', 'body': 'It fails to get the table sample rows in https://github.com/metabase/metabase/blob/84651267d4e11606601e54c2facdccf2d34f1a1f/modules/drivers/mongo/src/metabase/driver/mongo.clj#L344', 'created_at': datetime.datetime(2024, 7, 30, 4, 8, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2257424822, 'issue_id': 2436839172, 'author': 'qnkhuat', 'body': ""I think it's a MLv2 issue because if I add `:type/MongoBSONID` to this [orderable-types](https://github.com/metabase/metabase/blob/d364df916e50153ebba64c477cfd161e7b4984a8/src/metabase/lib/schema/expression.cljc#L139) list then fingerprint works."", 'created_at': datetime.datetime(2024, 7, 30, 4, 16, 11, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-07-30 04:08:24 UTC): It fails to get the table sample rows in https://github.com/metabase/metabase/blob/84651267d4e11606601e54c2facdccf2d34f1a1f/modules/drivers/mongo/src/metabase/driver/mongo.clj#L344

qnkhuat (Issue Creator) on (2024-07-30 04:16:11 UTC): I think it's a MLv2 issue because if I add `:type/MongoBSONID` to this [orderable-types](https://github.com/metabase/metabase/blob/d364df916e50153ebba64c477cfd161e7b4984a8/src/metabase/lib/schema/expression.cljc#L139) list then fingerprint works.

"
2436792865,issue,closed,duplicate,table image url picture is too small ,"

**Describe the solution you'd like**
data table about image url picture is too small ,i want 30px to 120px 


",niunan2019,2024-07-30 03:14:01+00:00,[],2025-01-02 17:00:16+00:00,2025-01-02 17:00:16+00:00,https://github.com/metabase/metabase/issues/46258,"[('Type:New Feature', ''), ('.Needs Triage', '')]",[],
2436611724,issue,closed,completed,"Links to table/database are broken in ""Most viewed tables"" Metabase analytics question","### Describe the bug

For the Metabase analytics question ""Most viewed tables"", the links for the table/database columns are broken: 

E.g. For table, it is using this link: https://.../question#?db=1&table=1
For database, it is using this link: https://.../browse/1

<img width=""772"" alt=""Screenshot 2024-07-29 at 4 51 34 PM"" src=""https://github.com/user-attachments/assets/3d622a3f-5dbb-4d48-821b-39e58a4cdf7a"">


### To Reproduce

1. Go to Metabase analytics -> Most Viewed Content dashboard
2. Scroll down to Most Viewed Tables card
3. Click on any table / database to open them
4. Bad links


### Expected behavior

Working links to tables and databases

### Logs

_No response_

### Information about your Metabase installation

```JSON
master @ Postgres
```


### Severity

Good to fix, but not sure how many people look at it and click-thru

### Additional context

_No response_",maxzheng,2024-07-29 23:54:11+00:00,[],2024-10-08 16:14:11+00:00,2024-09-30 14:25:25+00:00,https://github.com/metabase/metabase/issues/46256,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2276431696, 'issue_id': 2436611724, 'author': 'ranquild', 'body': '1. Database link should be `/browse/databases/:id` and not `/browse/:id`\r\n2. Table link seems to be correct, but there are some non-existing/non-accessible databases/tables here for which the BE throws 404.\r\n\r\nPlease add e2e tests for the links to continue working after routing changes.', 'created_at': datetime.datetime(2024, 8, 8, 18, 36, 25, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-08-08 18:36:25 UTC): 1. Database link should be `/browse/databases/:id` and not `/browse/:id`
2. Table link seems to be correct, but there are some non-existing/non-accessible databases/tables here for which the BE throws 404.

Please add e2e tests for the links to continue working after routing changes.

"
2436440650,issue,closed,completed,"Do not show ""hide notebook"" button when viewing a new question from the notebook and the question has not yet been run",blocks #46096,iethree,2024-07-29 21:49:00+00:00,[],2024-10-08 16:18:53+00:00,2024-08-02 19:08:00+00:00,https://github.com/metabase/metabase/issues/46252,[],[],
2436209176,issue,closed,completed,Some X-rays can't be saved (single value in a date column),"### Describe the bug

Some x-rays can't be saved

### To Reproduce

1. Create PG database `dvdrental` and import sample dataset from https://www.postgresqltutorial.com/postgresql-getting-started/postgresql-sample-database/
2. Add it as new data source in Metabase 
3. X-ray some tables like City
5. Errors are thrown in the backend but the X-ray is still saved
6. Then x-ray the Customer table and try to save it. This throws a 500 error


### Expected behavior

X-rays should be saved

### Logs

```
[backend] 2024-07-29 20:37:18,538 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 182.8 ms (20 DB calls) App DB connections: 8/13 Jetty threads: 8/50 (8 idle, 0 queued) (126 total active threads) Queries in flight: 1 (0 queued); postgres DB 2 connections: 4/6 (0 threads blocked) {:metabase-user-id 1}
[backend] 2024-07-29 20:37:18,539 WARN api.common :: Unexpected parameters at [:post ""/api/dataset""]: [:type :query :parameters]
[backend] Please add them to the schema or remove them from the API client
[backend] 2024-07-29 20:37:18,539 WARN api.common :: Unexpected parameters at [:post ""/api/dataset""]: [:type :query :parameters]
[backend] Please add them to the schema or remove them from the API client
[backend] 2024-07-29 20:37:18,540 WARN api.common :: Unexpected parameters at [:post ""/api/dataset""]: [:type :query :parameters]
[backend] Please add them to the schema or remove them from the API client
[backend] 2024-07-29 20:37:18,559 ERROR middleware.catch-exceptions :: Error processing query: Invalid output: {:query {:breakout [[nil nil [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]], :order-by [[nil [nil nil [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]]]}}
[backend] {:database_id 2,
[backend]  :started_at #t ""2024-07-29T20:37:18.477399+01:00[Atlantic/Canary]"",
[backend]  :via
[backend]  [{:status :failed,
[backend]    :class clojure.lang.ExceptionInfo,
[backend]    :error
[backend]    ""Error preprocessing query in clojure.lang.AFunction$1@3d0ea128: Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]    :stacktrace
[backend]    [""--> query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626$fn__95627.invoke(preprocess.clj:150)""
[backend]     ""query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626.invoke(preprocess.clj:124)""
[backend]     ""query_processor.setup$fn__95589$_AMPERSAND_f__95590.invoke(setup.clj:225)""
[backend]     ""query_processor.setup$fn__95589$fn__95594.invoke(setup.clj:216)""
[backend]     ""query_processor.preprocess$fn__95624$_AMPERSAND_f__95625.invoke(preprocess.clj:122)""
[backend]     ""query_processor.preprocess$fn__95624$fn__95639.invoke(preprocess.clj:118)""
[backend]     ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:46)""
[backend]     ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
[backend]     ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval146220$handle_audit_app_internal_queries__146221$fn__146222.invoke(handle_audit_queries.clj:145)""
[backend]     ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__90731.invoke(enterprise.clj:103)""
[backend]     ""query_processor.middleware.process_userland_query$fn__96509$_AMPERSAND_f__96510$_AMPERSAND_f__96511.invoke(process_userland_query.clj:196)""
[backend]     ""query_processor.middleware.process_userland_query$fn__96509$_AMPERSAND_f__96510$fn__96517.invoke(process_userland_query.clj:179)""
[backend]     ""query_processor.middleware.catch_exceptions$fn__96336$_AMPERSAND_f__96337$_AMPERSAND_f__96338.invoke(catch_exceptions.clj:128)""
[backend]     ""query_processor.middleware.catch_exceptions$fn__96336$_AMPERSAND_f__96337$fn__96350.invoke(catch_exceptions.clj:118)""
[backend]     ""query_processor$fn__96839$_AMPERSAND_f__96840$fn__96841.invoke(query_processor.clj:80)""
[backend]     ""query_processor.setup$fn__95581$_AMPERSAND_f__95582$fn__95583.invoke(setup.clj:189)""
[backend]     ""query_processor.setup$fn__95571$_AMPERSAND_f__95572$fn__95573.invoke(setup.clj:181)""
[backend]     ""query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563$fn__95564.invoke(setup.clj:166)""
[backend]     ""driver$do_with_driver.invokeStatic(driver.clj:106)""
[backend]     ""driver$do_with_driver.invoke(driver.clj:101)""
[backend]     ""query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563.invoke(setup.clj:165)""
[backend]     ""query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551$fn__95554.invoke(setup.clj:151)""
[backend]     ""query_processor.store$fn__76049$_AMPERSAND_f__76050.invoke(store.clj:171)""
[backend]     ""query_processor.store$fn__76049$fn__76053.invoke(store.clj:151)""
[backend]     ""query_processor.store$fn__76049$_AMPERSAND_f__76050.invoke(store.clj:160)""
[backend]     ""query_processor.store$fn__76049$fn__76053.invoke(store.clj:151)""
[backend]     ""query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551.invoke(setup.clj:150)""
[backend]     ""query_processor.setup$fn__95531$_AMPERSAND_f__95532$_AMPERSAND_f__95533.invoke(setup.clj:128)""
[backend]     ""query_processor.setup$fn__95531$_AMPERSAND_f__95532$fn__95536.invoke(setup.clj:122)""
[backend]     ""query_processor.setup$fn__95589$_AMPERSAND_f__95590.invoke(setup.clj:232)""
[backend]     ""query_processor.setup$fn__95589$fn__95594.invoke(setup.clj:216)""
[backend]     ""query_processor$fn__96839$_AMPERSAND_f__96840.invoke(query_processor.clj:78)""
[backend]     ""query_processor$fn__96839$fn__96845.invoke(query_processor.clj:71)""
[backend]     ""api.dataset$fn__121816$_AMPERSAND_f__121819$fn__121823.invoke(dataset.clj:84)""
[backend]     ""query_processor.streaming$_streaming_response$fn__83953$fn__83954$fn__83955.invoke(streaming.clj:175)""
[backend]     ""query_processor.streaming$_streaming_response$fn__83953$fn__83954.invoke(streaming.clj:174)""
[backend]     ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
[backend]     ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
[backend]     ""query_processor.streaming$_streaming_response$fn__83953.invoke(streaming.clj:171)""
[backend]     ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
[backend]     ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
[backend]     ""async.streaming_response$do_f_async$task__46251.invoke(streaming_response.clj:87)""],
[backend]    :error_type :qp,
[backend]    :ex-data
[backend]    {:fn #object[clojure.lang.AFunction$1 0x3d0ea128 ""clojure.lang.AFunction$1@3d0ea128""],
[backend]     :query
[backend]     {:constraints {:max-results 10000, :max-results-bare-rows 2000},
[backend]      :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
[backend]      :user-parameters
[backend]      [{:type :category, :id ""978782895"", :target [:dimension [:field 352 nil]]}
[backend]       {:type :category, :id ""-1186615977"", :target [:dimension [:field 252 {:source-field 358}]]}],
[backend]      :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x6e56b4a6 ""[B@6e56b4a6""]},
[backend]      :database 2,
[backend]      :type :query,
[backend]      :query
[backend]      {:aggregation [[:count]],
[backend]       :breakout [[:field 350 {:temporal-unit :minute}]],
[backend]       :source-table 41,
[backend]       :order-by [[:asc [:field 350 {:temporal-unit :minute}]]]}},
[backend]     :type :qp}}],
[backend]  :action_id nil,
[backend]  :error_type :qp,
[backend]  :json_query
[backend]  {:database 2,
[backend]   :type ""query"",
[backend]   :query {:aggregation [[""count""]], :breakout [[""field"" 350 {:temporal-unit ""minute""}]], :source-table 41},
[backend]   :parameters
[backend]   [{:type ""category"", :value nil, :id ""978782895"", :target [""dimension"" [""field"" 352 nil]]}
[backend]    {:type ""category"", :value nil, :id ""-1186615977"", :target [""dimension"" [""field"" 252 {:source-field 358}]]}],
[backend]   :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true}},
[backend]  :native nil,
[backend]  :status :failed,
[backend]  :class clojure.lang.ExceptionInfo,
[backend]  :stacktrace
[backend]  [""--> query_processor.middleware.desugar$fn__90654$fn__90657.invoke(desugar.clj:50)""
[backend]   ""query_processor.preprocess$ensure_legacy$fn__95616.invoke(preprocess.clj:64)""
[backend]   ""query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626$fn__95627.invoke(preprocess.clj:134)""
[backend]   ""query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626.invoke(preprocess.clj:124)""
[backend]   ""query_processor.setup$fn__95589$_AMPERSAND_f__95590.invoke(setup.clj:225)""
[backend]   ""query_processor.setup$fn__95589$fn__95594.invoke(setup.clj:216)""
[backend]   ""query_processor.preprocess$fn__95624$_AMPERSAND_f__95625.invoke(preprocess.clj:122)""
[backend]   ""query_processor.preprocess$fn__95624$fn__95639.invoke(preprocess.clj:118)""
[backend]   ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:46)""
[backend]   ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:44)""
[backend]   ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval146220$handle_audit_app_internal_queries__146221$fn__146222.invoke(handle_audit_queries.clj:145)""
[backend]   ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__90731.invoke(enterprise.clj:103)""
[backend]   ""query_processor.middleware.process_userland_query$fn__96509$_AMPERSAND_f__96510$_AMPERSAND_f__96511.invoke(process_userland_query.clj:196)""
[backend]   ""query_processor.middleware.process_userland_query$fn__96509$_AMPERSAND_f__96510$fn__96517.invoke(process_userland_query.clj:179)""
[backend]   ""query_processor.middleware.catch_exceptions$fn__96336$_AMPERSAND_f__96337$_AMPERSAND_f__96338.invoke(catch_exceptions.clj:128)""
  ""query_processor.middleware.catch_exceptions$fn__96336$_AMPERSAND_f__96337$fn__96350.invoke(catch_exceptions.clj:118)""
[backend]   ""query_processor$fn__96839$_AMPERSAND_f__96840$fn__96841.invoke(query_processor.clj:80)""
[backend]   ""query_processor.setup$fn__95581$_AMPERSAND_f__95582$fn__95583.invoke(setup.clj:189)""
[backend]   ""query_processor.setup$fn__95571$_AMPERSAND_f__95572$fn__95573.invoke(setup.clj:181)""
[backend]   ""query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563$fn__95564.invoke(setup.clj:166)""
[backend]   ""driver$do_with_driver.invokeStatic(driver.clj:106)""
[backend]   ""driver$do_with_driver.invoke(driver.clj:101)""
[backend]   ""query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563.invoke(setup.clj:165)""
[backend]   ""query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551$fn__95554.invoke(setup.clj:151)""
[backend]   ""query_processor.store$fn__76049$_AMPERSAND_f__76050.invoke(store.clj:171)""
[backend]   ""query_processor.store$fn__76049$fn__76053.invoke(store.clj:151)""
[backend]   ""query_processor.store$fn__76049$_AMPERSAND_f__76050.invoke(store.clj:160)""
[backend]   ""query_processor.store$fn__76049$fn__76053.invoke(store.clj:151)""
[backend]   ""query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551.invoke(setup.clj:150)""
[backend]   ""query_processor.setup$fn__95531$_AMPERSAND_f__95532$_AMPERSAND_f__95533.invoke(setup.clj:128)""
[backend]   ""query_processor.setup$fn__95531$_AMPERSAND_f__95532$fn__95536.invoke(setup.clj:122)""
[backend]   ""query_processor.setup$fn__95589$_AMPERSAND_f__95590.invoke(setup.clj:232)""
[backend]   ""query_processor.setup$fn__95589$fn__95594.invoke(setup.clj:216)""
[backend]   ""query_processor$fn__96839$_AMPERSAND_f__96840.invoke(query_processor.clj:78)""
[backend]   ""query_processor$fn__96839$fn__96845.invoke(query_processor.clj:71)""
[backend]   ""api.dataset$fn__121816$_AMPERSAND_f__121819$fn__121823.invoke(dataset.clj:84)""
[backend]   ""query_processor.streaming$_streaming_response$fn__83953$fn__83954$fn__83955.invoke(streaming.clj:175)""
[backend]   ""query_processor.streaming$_streaming_response$fn__83953$fn__83954.invoke(streaming.clj:174)""
[backend]   ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
[backend]   ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
[backend]   ""query_processor.streaming$_streaming_response$fn__83953.invoke(streaming.clj:171)""
[backend]   ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
[backend]   ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
[backend]   ""async.streaming_response$do_f_async$task__46251.invoke(streaming_response.clj:87)""],
[backend]  :card_id nil,
[backend]  :context :ad-hoc,
[backend]  :error
[backend]  ""Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]  :row_count 0,
[backend]  :running_time 0,
[backend]  :preprocessed nil,
[backend]  :ex-data
[backend]  {:type :metabase.util.malli.fn/invalid-output,
[backend]   :error
[backend]   {:schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]    :value
[backend]    {:constraints {:max-results 10000, :max-results-bare-rows 2000},
[backend]     :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
[backend]     :user-parameters
[backend]     [{:type :category, :id ""978782895"", :target [:dimension [:field 352 nil]]}
[backend]      {:type :category, :id ""-1186615977"", :target [:dimension [:field 252 {:source-field 358}]]}],
[backend]     :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x6e56b4a6 ""[B@6e56b4a6""]},
[backend]     :database 2,
[backend]     :type :query,
[backend]     :query
[backend]     {:aggregation [[:count]],
[backend]      :breakout
[backend]      [[:field
[backend]        350
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]      :source-table 41,
[backend]      :order-by
[backend]      [[:asc
[backend]        [:field
[backend]         350
[backend]         {:temporal-unit :minute,
[backend]          :base-type :type/Date,
[backend]          :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]    :errors
[backend]    ({:path [0 0 :query 0 0 :breakout 0 0 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]      :in [:query :breakout 0 2],
[backend]      :schema
[backend]      [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]      :value
[backend]      {:temporal-unit :minute,
[backend]       :base-type :type/Date,
[backend]       :metabase.query-processor.middleware.desugar/desugar-added-base-type true}}
[backend]     {:path [0 0 :query 0 0 :order-by 0 0 0 :asc 0 1 ""field"" 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]      :in [:query :order-by 0 1 2],
[backend]      :schema
[backend]      [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]      :value
[backend]      {:temporal-unit :minute,
[backend]       :base-type :type/Date,
[backend]       :metabase.query-processor.middleware.desugar/desugar-added-base-type true}})},
[backend]   :humanized
[backend]   {:query
[backend]    {:breakout
[backend]     [[nil
[backend]       nil
[backend]       [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]],
[backend]     :order-by
[backend]     [[nil
[backend]       [nil
[backend]        nil
[backend]        [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]]]}},
[backend]   :schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]   :value
[backend]   {:constraints {:max-results 10000, :max-results-bare-rows 2000},
[backend]    :middleware {:js-int-to-string? true, :userland-query? true, :add-default-userland-constraints? true},
[backend]    :user-parameters
[backend]    [{:type :category, :id ""978782895"", :target [:dimension [:field 352 nil]]}
[backend]     {:type :category, :id ""-1186615977"", :target [:dimension [:field 252 {:source-field 358}]]}],
[backend]    :info {:executed-by 1, :context :ad-hoc, :query-hash #object[""[B"" 0x6e56b4a6 ""[B@6e56b4a6""]},
[backend]    :database 2,
[backend]    :type :query,
[backend]    :query
[backend]    {:aggregation [[:count]],
[backend]     :breakout
[backend]     [[:field
[backend]       350
[backend]       {:temporal-unit :minute,
[backend]        :base-type :type/Date,
[backend]        :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]     :source-table 41,
[backend]     :order-by
[backend]     [[:asc
[backend]       [:field
[backend]        350
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]   :fn-name desugar},
[backend]  :data {:rows [], :cols []}}
[backend]
```

```
[backend] 2024-07-29 20:37:19,491 INFO metabase.query-analysis :: Performing query analysis for card 220
[backend] 2024-07-29 20:37:19,528 INFO metabase.query-analysis :: Performing query analysis for card 221
[backend] 2024-07-29 20:37:19,556 INFO metabase.query-analysis :: Performing query analysis for card 222
[backend] 2024-07-29 20:37:19,632 ERROR middleware.log :: POST /api/dashboard/save 500 224.3 ms (107 DB calls) {:metabase-user-id 1}
[backend] {:via
[backend]  [{:type clojure.lang.ExceptionInfo,
[backend]    :message
[backend]    ""Error preprocessing query in clojure.lang.AFunction$1@3d0ea128: Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]    :data
[backend]    {:fn #object[clojure.lang.AFunction$1 0x3d0ea128 ""clojure.lang.AFunction$1@3d0ea128""],
[backend]     :query
[backend]     {:database 2,
[backend]      :info {:executed-by 1},
[backend]      :type :query,
[backend]      :query
[backend]      {:aggregation [[:count]],
[backend]       :breakout [[:field 350 {:temporal-unit :minute}]],
[backend]       :source-table 41,
[backend]       :order-by [[:asc [:field 350 {:temporal-unit :minute}]]]}},
[backend]     :type :qp},
[backend]    :at
[backend]    [metabase.query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626$fn__95627 invoke ""preprocess.clj"" 150]}
[backend]   {:type clojure.lang.ExceptionInfo,
[backend]    :message
[backend]    ""Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]    :data
[backend]    {:type :metabase.util.malli.fn/invalid-output,
[backend]     :error
[backend]     {:schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]      :value
[backend]      {:database 2,
[backend]       :info {:executed-by 1},
[backend]       :type :query,
[backend]       :query
[backend]       {:aggregation [[:count]],
[backend]        :breakout
[backend]        [[:field
[backend]          350
[backend]          {:temporal-unit :minute,
[backend]           :base-type :type/Date,
[backend]           :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]        :source-table 41,
[backend]        :order-by
[backend]        [[:asc
[backend]          [:field
[backend]           350
[backend]           {:temporal-unit :minute,
[backend]            :base-type :type/Date,
[backend]            :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]      :errors
[backend]      ({:path [0 0 :query 0 0 :breakout 0 0 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]        :in [:query :breakout 0 2],
[backend]        :schema
[backend]        [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]        :value
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}}
[backend]       {:path [0 0 :query 0 0 :order-by 0 0 0 :asc 0 1 ""field"" 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]        :in [:query :order-by 0 1 2],
[backend]        :schema
[backend]        [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]        :value
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}})},
[backend]     :humanized
[backend]     {:query
[backend]      {:breakout
[backend]       [[nil
[backend]         nil
[backend]         [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]],
[backend]       :order-by
[backend]       [[nil
[backend]         [nil
[backend]          nil
[backend]          [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]]]}},
[backend]     :schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]     :value
[backend]     {:database 2,
[backend]      :info {:executed-by 1},
[backend]      :type :query,
[backend]      :query
[backend]      {:aggregation [[:count]],
[backend]       :breakout
[backend]       [[:field
[backend]         350
[backend]         {:temporal-unit :minute,
[backend]          :base-type :type/Date,
[backend]          :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]       :source-table 41,
[backend]       :order-by
[backend]       [[:asc
[backend]         [:field
[backend]          350
[backend]          {:temporal-unit :minute,
[backend]           :base-type :type/Date,
[backend]           :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]     :fn-name desugar},
[backend]    :at [metabase.query_processor.middleware.desugar$fn__90654$fn__90657 invoke ""desugar.clj"" 50]}],
[backend]  :trace
[backend]  [[metabase.query_processor.middleware.desugar$fn__90654$fn__90657 invoke ""desugar.clj"" 50]
[backend]   [clojure.lang.Var invoke ""Var.java"" 384]
[backend]   [metabase.query_processor.preprocess$ensure_legacy$fn__95616 invoke ""preprocess.clj"" 64]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 154]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 408]
[backend]   [metabase.query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626$fn__95627 invoke ""preprocess.clj"" 134]
[backend]   [clojure.lang.PersistentVector reduce ""PersistentVector.java"" 343]
[backend]   [clojure.core$transduce invokeStatic ""core.clj"" 6947]
[backend]   [clojure.core$transduce invoke ""core.clj"" 6934]
[backend]   [metabase.query_processor.preprocess$fn__95624$_AMPERSAND_f__95625$fn__95626 invoke ""preprocess.clj"" 124]
[backend]   [metabase.query_processor.setup$fn__95589$_AMPERSAND_f__95590 invoke ""setup.clj"" 225]
[backend]   [metabase.query_processor.setup$fn__95589$fn__95594 invoke ""setup.clj"" 216]
[backend]   [metabase.query_processor.preprocess$fn__95624$_AMPERSAND_f__95625 invoke ""preprocess.clj"" 122]
[backend]   [metabase.query_processor.preprocess$fn__95624$fn__95639 invoke ""preprocess.clj"" 118]
[backend]   [metabase.query_processor.compile$fn__95672$_AMPERSAND_f__95673$fn__95674 invoke ""compile.clj"" 43]
[backend]   [metabase.query_processor.setup$fn__95589$_AMPERSAND_f__95590 invoke ""setup.clj"" 225]
[backend]   [metabase.query_processor.setup$fn__95589$fn__95594 invoke ""setup.clj"" 216]
[backend]   [metabase.query_processor.compile$fn__95672$_AMPERSAND_f__95673 invoke ""compile.clj"" 42]
[backend]   [metabase.query_processor.compile$fn__95672$fn__95677 invoke ""compile.clj"" 39]
[backend]   [metabase.driver.sql_jdbc.metadata$fn__110844$_AMPERSAND_f__110845$fn__110846 invoke ""metadata.clj"" 22]
[backend]   [metabase.query_processor.setup$fn__95581$_AMPERSAND_f__95582$fn__95583 invoke ""setup.clj"" 189]
[backend]   [metabase.query_processor.setup$fn__95571$_AMPERSAND_f__95572$fn__95573 invoke ""setup.clj"" 181]
[backend]   [metabase.query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563$fn__95564 invoke ""setup.clj"" 166]
[backend]   [metabase.driver$do_with_driver invokeStatic ""driver.clj"" 106]
[backend]   [metabase.driver$do_with_driver invoke ""driver.clj"" 101]
[backend]   [metabase.query_processor.setup$fn__95561$_AMPERSAND_f__95562$fn__95563 invoke ""setup.clj"" 165]
[backend]   [metabase.query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551$fn__95554 invoke ""setup.clj"" 151]
[backend]   [metabase.query_processor.store$fn__76049$_AMPERSAND_f__76050 invoke ""store.clj"" 171]
[backend]   [metabase.query_processor.store$fn__76049$fn__76053 invoke ""store.clj"" 151]
[backend]   [metabase.query_processor.store$fn__76049$_AMPERSAND_f__76050 invoke ""store.clj"" 160]
[backend]   [metabase.query_processor.store$fn__76049$fn__76053 invoke ""store.clj"" 151]
[backend]   [metabase.query_processor.setup$fn__95549$_AMPERSAND_f__95550$fn__95551 invoke ""setup.clj"" 150]
[backend]   [metabase.query_processor.setup$fn__95531$_AMPERSAND_f__95532$_AMPERSAND_f__95533 invoke ""setup.clj"" 128]
[backend]   [metabase.query_processor.setup$fn__95531$_AMPERSAND_f__95532$fn__95536 invoke ""setup.clj"" 122]
[backend]   [metabase.query_processor.setup$fn__95589$_AMPERSAND_f__95590 invoke ""setup.clj"" 232]
[backend]   [metabase.query_processor.setup$fn__95589$fn__95594 invoke ""setup.clj"" 216]
[backend]   [metabase.driver.sql_jdbc.metadata$fn__110844$_AMPERSAND_f__110845 invoke ""metadata.clj"" 20]
[backend]   [metabase.driver.sql_jdbc.metadata$fn__110844$fn__110854 invoke ""metadata.clj"" 15]
  [metabase.driver.sql_jdbc$eval111020$fn__111021 invoke ""sql_jdbc.clj"" 228]
[backend]   [clojure.lang.MultiFn invoke ""MultiFn.java"" 234]
[backend]   [metabase.query_processor.metadata$fn__96897$_AMPERSAND_f__96898 invoke ""metadata.clj"" 73]
[backend]   [metabase.query_processor.metadata$fn__96897$fn__96901 invoke ""metadata.clj"" 64]
[backend]   [metabase.query_processor.metadata$fn__96918$_AMPERSAND_f__96919 invoke ""metadata.clj"" 106]
[backend]   [metabase.query_processor.metadata$fn__96918$fn__96922 invoke ""metadata.clj"" 103]
[backend]   [metabase.query_processor.metadata$fn__96945$_AMPERSAND_f__96946 invoke ""metadata.clj"" 155]
[backend]   [metabase.query_processor.metadata$fn__96945$fn__96948 invoke ""metadata.clj"" 146]
[backend]   [metabase.models.dashboard$legacy_result_metadata_for_query invokeStatic ""dashboard.clj"" 472]
[backend]   [metabase.models.dashboard$legacy_result_metadata_for_query invoke ""dashboard.clj"" 468]
[backend]   [metabase.models.dashboard$save_card_BANG_$fn__106341 invoke ""dashboard.clj"" 486]
[backend]   [clojure.core$update invokeStatic ""core.clj"" 6232]
[backend]   [clojure.core$update invoke ""core.clj"" 6224]
[backend]   [metabase.models.dashboard$save_card_BANG_ invokeStatic ""dashboard.clj"" 486]
[backend]   [metabase.models.dashboard$save_card_BANG_ invoke ""dashboard.clj"" 474]
[backend]   [metabase.models.dashboard$save_transient_dashboard_BANG_$iter__106350__106354$fn__106355$fn__106356
[backend]    invoke
[backend]    ""dashboard.clj""
[backend]    526]
[backend]   [metabase.models.dashboard$save_transient_dashboard_BANG_$iter__106350__106354$fn__106355 invoke ""dashboard.clj"" 525]
[backend]   [clojure.lang.LazySeq sval ""LazySeq.java"" 42]
[backend]   [clojure.lang.LazySeq seq ""LazySeq.java"" 51]
[backend]   [clojure.lang.RT seq ""RT.java"" 535]
[backend]   [clojure.core$seq__5467 invokeStatic ""core.clj"" 139]
[backend]   [clojure.core$map$fn__5935 invoke ""core.clj"" 2763]
[backend]   [clojure.lang.LazySeq sval ""LazySeq.java"" 42]
[backend]   [clojure.lang.LazySeq seq ""LazySeq.java"" 51]
[backend]   [clojure.lang.RT seq ""RT.java"" 535]
[backend]   [clojure.core$seq__5467 invokeStatic ""core.clj"" 139]
[backend]   [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 24]
[backend]   [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
[backend]   [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
[backend]   [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
[backend]   [clojure.core$reduce invokeStatic ""core.clj"" 6887]
[backend]   [clojure.core$reduce invoke ""core.clj"" 6869]
[backend]   [malli.core$_collection_schema$reify$reify__9032$fn__9033 invoke ""core.cljc"" 1224]
[backend]   [metabase.util.malli.registry$explainer$make_explainer__27422$schema_explainer__27423 invoke ""registry.cljc"" 47]
[backend]   [metabase.util.malli.registry$explain invokeStatic ""registry.cljc"" 54]
[backend]   [metabase.util.malli.registry$explain invoke ""registry.cljc"" 51]
[backend]   [metabase.util.malli.fn$validate invokeStatic ""fn.clj"" 152]
[backend]   [metabase.util.malli.fn$validate invoke ""fn.clj"" 150]
[backend]   [metabase.util.malli.fn$validate_input invokeStatic ""fn.clj"" 183]
[backend]   [metabase.util.malli.fn$validate_input invoke ""fn.clj"" 179]
[backend]   [metabase.models.dashboard_card$fn__82077$fn__82100 invoke ""dashboard_card.clj"" 209]
[backend]   [metabase.models.dashboard$add_dashcards_BANG_ invokeStatic ""dashboard.clj"" 428]
[backend]   [metabase.models.dashboard$add_dashcards_BANG_ invoke ""dashboard.clj"" 417]
[backend]   [metabase.models.dashboard$save_transient_dashboard_BANG_ invokeStatic ""dashboard.clj"" 524]
[backend]   [metabase.models.dashboard$save_transient_dashboard_BANG_ invoke ""dashboard.clj"" 504]
[backend]   [metabase.api.dashboard$fn__125662 invokeStatic ""dashboard.clj"" 988]
[backend]   [metabase.api.dashboard$fn__125662 invoke ""dashboard.clj"" 981]
[backend]   [compojure.core$wrap_response$fn__12079 invoke ""core.clj"" 160]
[backend]   [compojure.core$wrap_route_middleware$fn__12063 invoke ""core.clj"" 132]
[backend]   [compojure.core$wrap_route_info$fn__12068 invoke ""core.clj"" 139]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 151]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 152]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 152]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 152]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 152]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 152]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__117154 invoke ""auth.clj"" 18]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$make_context$handler__12159 invoke ""core.clj"" 290]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 300]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [clojure.lang.Var invoke ""Var.java"" 393]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [metabase.api.routes$fn__141985$fn__141986 invoke ""routes.clj"" 69]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
[backend]   [clojure.lang.AFn applyTo ""AFn.java"" 144]
[backend]   [clojure.core$apply invokeStatic ""core.clj"" 667]
[backend]   [clojure.core$apply invoke ""core.clj"" 662]
[backend]   [metabase.server.routes$fn__142949$fn__142950 doInvoke ""routes.clj"" 73]
[backend]   [clojure.lang.RestFn invoke ""RestFn.java"" 436]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$make_context$handler__12159 invoke ""core.clj"" 290]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 300]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__12072 invoke ""core.clj"" 153]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 199]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$make_context$handler__12159 invoke ""core.clj"" 290]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 300]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091$f__12092$respond_SINGLEQUOTE___12093 invoke ""core.clj"" 197]
[backend]   [compojure.core$make_context$fn__12163 invoke ""core.clj"" 301]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [compojure.core$routes$fn__12091$f__12092 invoke ""core.clj"" 198]
[backend]   [compojure.core$routes$fn__12091 invoke ""core.clj"" 200]
[backend]   [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__117393 invoke ""exceptions.clj"" 107]
[backend]   [metabase.server.middleware.exceptions$catch_api_exceptions$fn__117390 invoke ""exceptions.clj"" 96]
[backend]   [metabase.server.middleware.log$log_api_call$fn__117625$fn__117626$fn__117627 invoke ""log.clj"" 236]
[backend]   [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
[backend]   [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
[backend]   [metabase.server.middleware.log$log_api_call$fn__117625$fn__117626 invoke ""log.clj"" 227]
[backend]   [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
[backend]   [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
[backend]   [metabase.server.middleware.log$log_api_call$fn__117625 invoke ""log.clj"" 226]
[backend]   [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__117199 invoke ""browser_cookie.clj"" 40]
[backend]   [metabase.server.middleware.security$add_security_headers$fn__117341 invoke ""security.clj"" 240]
[backend]   [ring.middleware.json$wrap_json_body$fn__143244 invoke ""json.clj"" 64]
[backend]   [metabase.server.middleware.offset_paging$handle_paging$fn__117660 invoke ""offset_paging.clj"" 49]
[backend]   [metabase.server.middleware.json$wrap_streamed_json_response$fn__71977 invoke ""json.clj"" 88]
[backend]   [ring.middleware.keyword_params$wrap_keyword_params$fn__143341 invoke ""keyword_params.clj"" 55]
[backend]   [ring.middleware.params$wrap_params$fn__143368 invoke ""params.clj"" 77]
[backend]   [metabase.server.middleware.misc$maybe_set_site_url$fn__80281 invoke ""misc.clj"" 60]
[backend]   [metabase.server.middleware.session$reset_session_timeout$fn__97321 invoke ""session.clj"" 568]
[backend]   [metabase.server.middleware.session$bind_current_user$fn__97279$fn__97280 invoke ""session.clj"" 462]
[backend]   [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 441]
[backend]   [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 424]
[backend]   [metabase.server.middleware.session$bind_current_user$fn__97279 invoke ""session.clj"" 461]
[backend]   [metabase.server.middleware.session$wrap_current_user_info$fn__97250 invoke ""session.clj"" 385]
[backend]   [metabase.analytics.sdk$bind_embedding_mw$bound_embedding__47970 invoke ""sdk.clj"" 31]
[backend]   [metabase.server.middleware.session$wrap_session_id$fn__97222 invoke ""session.clj"" 261]
[backend]   [metabase.server.middleware.auth$wrap_static_api_key$fn__117162 invoke ""auth.clj"" 32]
[backend]   [ring.middleware.cookies$wrap_cookies$fn__143156 invoke ""cookies.clj"" 200]
[backend]   [metabase.server.middleware.misc$add_content_type$fn__80263 invoke ""misc.clj"" 28]
[backend]   [metabase.server.middleware.misc$disable_streaming_buffering$fn__80289 invoke ""misc.clj"" 77]
[backend]   [ring.middleware.gzip$wrap_gzip$fn__143206 invoke ""gzip.clj"" 86]
[backend]   [metabase.server.middleware.request_id$wrap_request_id$fn__117675 invoke ""request_id.clj"" 9]
[backend]   [metabase.server.middleware.misc$bind_request$fn__80292 invoke ""misc.clj"" 94]
[backend]   [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__117698 invoke ""ssl.clj"" 41]
[backend]   [metabase.server$async_proxy_handler$fn__73033 invoke ""server.clj"" 77]
[backend]   [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
[backend]   [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
[backend]   [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
[backend]   [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
[backend]   [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
[backend]   [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
[backend]   [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
[backend]   [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
[backend]   [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
[backend]   [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
[backend]   [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
[backend]   [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
[backend]   [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
[backend]   [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
[backend]   [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
[backend]   [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
[backend]   [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
[backend]   [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
[backend]   [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
[backend]   [java.lang.Thread run ""Thread.java"" 1570]],
[backend]  :cause
[backend]  ""Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]  :data
[backend]  {:type :metabase.util.malli.fn/invalid-output,
[backend]   :error
[backend]   {:schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]    :value
[backend]    {:database 2,
[backend]     :info {:executed-by 1},
[backend]     :type :query,
[backend]     :query
[backend]     {:aggregation [[:count]],
[backend]      :breakout
[backend]      [[:field
[backend]        350
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]      :source-table 41,
[backend]      :order-by
[backend]      [[:asc
[backend]        [:field
[backend]         350
[backend]         {:temporal-unit :minute,
[backend]          :base-type :type/Date,
[backend]          :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]    :errors
[backend]    ({:path [0 0 :query 0 0 :breakout 0 0 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]      :in [:query :breakout 0 2],
[backend]      :schema
[backend]      [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]      :value
[backend]      {:temporal-unit :minute,
[backend]       :base-type :type/Date,
[backend]       :metabase.query-processor.middleware.desugar/desugar-added-base-type true}}
    {:path [0 0 :query 0 0 :order-by 0 0 0 :asc 0 1 ""field"" 0 :field 0 0 1 ""options"" 0 0 1 0],
[backend]      :in [:query :order-by 0 1 2],
[backend]      :schema
[backend]      [:fn {:error/message ""Invalid :temporal-unit for the specified :base-type.""} #object[metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_ 0x43fdf27a ""metabase.legacy_mbql.schema$valid_temporal_unit_for_base_type_QMARK_@43fdf27a""]],
[backend]      :value
[backend]      {:temporal-unit :minute,
[backend]       :base-type :type/Date,
[backend]       :metabase.query-processor.middleware.desugar/desugar-added-base-type true}})},
[backend]   :humanized
[backend]   {:query
[backend]    {:breakout
[backend]     [[nil
[backend]       nil
[backend]       [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]],
[backend]     :order-by
[backend]     [[nil
[backend]       [nil
[backend]        nil
[backend]        [""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}""]]]]}},
[backend]   :schema [:ref :metabase.legacy-mbql.schema/Query],
[backend]   :value
[backend]   {:database 2,
[backend]    :info {:executed-by 1},
[backend]    :type :query,
[backend]    :query
[backend]    {:aggregation [[:count]],
[backend]     :breakout
[backend]     [[:field
[backend]       350
[backend]       {:temporal-unit :minute,
[backend]        :base-type :type/Date,
[backend]        :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]],
[backend]     :source-table 41,
[backend]     :order-by
[backend]     [[:asc
[backend]       [:field
[backend]        350
[backend]        {:temporal-unit :minute,
[backend]         :base-type :type/Date,
[backend]         :metabase.query-processor.middleware.desugar/desugar-added-base-type true}]]]}},
[backend]   :fn-name desugar},
[backend]  :message
[backend]  ""Error preprocessing query in clojure.lang.AFunction$1@3d0ea128: Invalid output: {:query {:breakout [[nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]], :order-by [[nil [nil nil [\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date, :metabase.query-processor.middleware.desugar/desugar-added-base-type true}\""]]]]}}"",
[backend]  :fn #object[clojure.lang.AFunction$1 0x3d0ea128 ""clojure.lang.AFunction$1@3d0ea128""],
[backend]  :query
[backend]  {:database 2,
[backend]   :info {:executed-by 1},
[backend]   :type :query,
[backend]   :query
[backend]   {:aggregation [[:count]],
[backend]    :breakout [[:field 350 {:temporal-unit :minute}]],
[backend]    :source-table 41,
[backend]    :order-by [[:asc [:field 350 {:temporal-unit :minute}]]]}}}
[backend]
[backend] 2024-07-29 20:40:00,070 INFO task.refresh-slack-channel-user-cache :: Slack is not configured, not refreshing slack user/channel cache.
```

### Information about your Metabase installation

```JSON
- Metabase from master, commit hash 06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

p1 - onboarding path 

### Additional context

_No response_",albertoperdomo,2024-07-29 19:41:32+00:00,['qnkhuat'],2024-12-24 11:37:37+00:00,2024-08-01 06:34:53+00:00,https://github.com/metabase/metabase/issues/46249,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/X-rays', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2258750698, 'issue_id': 2436209176, 'author': 'ranquild', 'body': 'It seems that the root cause is `[\\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date`', 'created_at': datetime.datetime(2024, 7, 30, 16, 30, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2259973351, 'issue_id': 2436209176, 'author': 'qnkhuat', 'body': ""This fails in a very specific way, the `customer.create_date` column from the `dvdrental` only have one value, and thus the fingerprint of earliest and latest is the same. we used this information to determine the temporal unit for generating query. The bug here is that we shouldn't return :minute temporal unit for date column in any case."", 'created_at': datetime.datetime(2024, 7, 31, 8, 40, 2, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-30 16:30:20 UTC): It seems that the root cause is `[\""Invalid :temporal-unit for the specified :base-type., got: {:temporal-unit :minute, :base-type :type/Date`

qnkhuat (Assginee) on (2024-07-31 08:40:02 UTC): This fails in a very specific way, the `customer.create_date` column from the `dvdrental` only have one value, and thus the fingerprint of earliest and latest is the same. we used this information to determine the temporal unit for generating query. The bug here is that we shouldn't return :minute temporal unit for date column in any case.

"
2436053157,issue,closed,completed,Trend charts give an error if there are additional non-numeric columns,"## Context
Trend charts give a non-sensical error when there is an extra non-numeric column. We should simply ignore this column if there are others that are suited for trend charts.

[Ex 1](https://stats.metabase.com/question/18920-case-custom-column-text)
[Ex 2](https://stats.metabase.com/question/18921-created-at-as-custom-column/notebook)

[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1722014473479339)

## Technical details

In the examples above questions have a single valid time series dimension, however, the backend does not return `insights` object in the dataset.",cdeweyx,2024-07-29 18:17:25+00:00,[],2024-08-15 20:57:26+00:00,2024-08-12 17:00:35+00:00,https://github.com/metabase/metabase/issues/46244,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2435972156,issue,open,,Can't change name of summarize metrics and groups,"### Describe the bug

In an account model, I am grouping by Created At to get a Count of rows. There are a few related issues when changing the name of the group and metric:

1.  If I click into the column settings for Count, when I change the name from Count to Accounts, the column setting side bar and chart still shows Count instead of Accounts. 
2. In the column setting for Created At group, there is no option to change the name. Not sure if this is a regression or maybe it was always like that, but seems like a big miss to be not able to rename a grouped by field, so filing it as a bug instead. 
3. If you use this question in a downstream question, the Count column will be named Count instead of Accounts. 

<img width=""652"" alt=""Screenshot 2024-07-29 at 10 32 06 AM"" src=""https://github.com/user-attachments/assets/54cadae1-3a31-4032-9771-0a6612cf9324"">


### To Reproduce

1. Create a question that summarizes one field with count rows as metric. 
2. In column settings, try changing the names of the metric and group fields, it doesn't work for metric field / not available for group field. 
3. Create a new question that uses the previous and it also shows Count instead of the changed named. 


### Expected behavior

1. Changing metric/group names of summarize should work.
2. Changed names should be reflected when used in downstream questions 

### Logs

_No response_

### Information about your Metabase installation

```JSON
master @ Postgres
```


### Severity

While it is cosmetic, it degrades the usability of summarize if you can't name them appropriately, so definitely good to fix sooner rather than later 

### Additional context

_No response_",maxzheng,2024-07-29 17:33:17+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/46243,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2303323372, 'issue_id': 2435972156, 'author': 'ranquild', 'body': ""re: Changed names should be reflected when used in downstream questions - this is not how it's supposed to work. If you want to change result_metadata, then you need to use a model. This bug should about viz settings only for the current question."", 'created_at': datetime.datetime(2024, 8, 22, 0, 6, 20, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-08-22 00:06:20 UTC): re: Changed names should be reflected when used in downstream questions - this is not how it's supposed to work. If you want to change result_metadata, then you need to use a model. This bug should about viz settings only for the current question.

"
2435832062,issue,closed,completed,Text Filters turn number like entries into numeric when filtering on static embedding,"### Describe the bug

If you have a question inside a dashboard and you try to use a TEXT filter on TEXT field it will fail for values such as ""1234567"" when using static embedding

### To Reproduce

1. Go to New -> Question -> Sample Database -> Products -> Save
2. Add the Question to Dashboard -> Add a TEXT Filter (set it as an input/search box) and link it to Category
3. Setup Static Embedding and try to filter using 12345 as an entry

You can go to stats using this [dashboard](https://stats.metabase.com/dashboard/2552-test-text-filter-turns-numeric?text=)

Go to Static Embedding and simply add 1234 to the filter, it fails with the following error:

<img width=""1474"" alt=""image"" src=""https://github.com/user-attachments/assets/4ce68513-7821-4624-b0c5-220abb994497"">

Notice that on metabase it works without problem and outputs a no results found

<img width=""1083"" alt=""image"" src=""https://github.com/user-attachments/assets/510102a9-00cd-42d1-ab97-9701d6ee6b69"">

The issue is that on static embedding when you type a number the where clause is sending a `""CATEGORY"" = 1234` and if you type anything else which is not numeric you get `""CATEGORY"" = '1234x'`

### Expected behavior

Text filter works

### Logs

1618970a-de54-4df8-b1e0-45ba1c5a1d7f] 2024-07-29T18:07:23+02:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Data conversion error converting ""Gizmo""; SQL statement:
-- Metabase:: userID: 1 queryType: MBQL queryHash: 90c17f8cdbff4b671604d7ae59913a0a5a024d9477e6d75b5f3652471593844a
SELECT ""PUBLIC"".""PRODUCTS"".""ID"" AS ""ID"", ""PUBLIC"".""PRODUCTS"".""EAN"" AS ""EAN"", ""PUBLIC"".""PRODUCTS"".""TITLE"" AS ""TITLE"", ""PUBLIC"".""PRODUCTS"".""CATEGORY"" AS ""CATEGORY"", ""PUBLIC"".""PRODUCTS"".""VENDOR"" AS ""VENDOR"", ""PUBLIC"".""PRODUCTS"".""PRICE"" AS ""PRICE"", ""PUBLIC"".""PRODUCTS"".""RATING"" AS ""RATING"", ""PUBLIC"".""PRO [22018-214]
{:database_id 1,
 :started_at #t ""2024-07-29T16:07:22.359501Z[GMT]"",
 :via
 [{:status :failed,
   :class org.h2.jdbc.JdbcSQLDataException,
   :error
   ""Data conversion error converting \""Gizmo\""; SQL statement:\n-- Metabase:: userID: 1 queryType: MBQL queryHash: 90c17f8cdbff4b671604d7ae59913a0a5a024d9477e6d75b5f3652471593844a\nSELECT \""PUBLIC\"".\""PRODUCTS\"".\""ID\"" AS \""ID\"", \""PUBLIC\"".\""PRODUCTS\"".\""EAN\"" AS \""EAN\"", \""PUBLIC\"".\""PRODUCTS\"".\""TITLE\"" AS \""TITLE\"", \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" AS \""CATEGORY\"", \""PUBLIC\"".\""PRODUCTS\"".\""VENDOR\"" AS \""VENDOR\"", \""PUBLIC\"".\""PRODUCTS\"".\""PRICE\"" AS \""PRICE\"", \""PUBLIC\"".\""PRODUCTS\"".\""RATING\"" AS \""RATING\"", \""PUBLIC\"".\""PRO [22018-214]"",
   :stacktrace
   [""org.h2.message.DbException.getJdbcSQLException(DbException.java:506)""
    ""org.h2.message.DbException.getJdbcSQLException(DbException.java:477)""
    ""org.h2.message.DbException.get(DbException.java:212)""
    ""org.h2.value.ValueStringBase.getInt(ValueStringBase.java:133)""
    ""org.h2.value.Value.convertToInt(Value.java:1575)""
    ""org.h2.value.Value.convertTo(Value.java:1135)""
    ""org.h2.value.Value.convertTo(Value.java:1003)""
    ""org.h2.value.Value.compareToNotNullable(Value.java:2630)""
    ""org.h2.value.Value.compareWithNull(Value.java:2654)""
    ""org.h2.engine.SessionLocal.compareWithNull(SessionLocal.java:1966)""
    ""org.h2.expression.condition.Comparison.compare(Comparison.java:250)""
    ""org.h2.expression.condition.Comparison.getValue(Comparison.java:222)""
    ""org.h2.expression.Expression.getBooleanValue(Expression.java:332)""
    ""org.h2.command.query.Select.isConditionMet(Select.java:449)""
    ""org.h2.command.query.Select$LazyResultQueryFlat.fetchNextRow(Select.java:1835)""
    ""org.h2.result.LazyResult.hasNext(LazyResult.java:78)""
    ""org.h2.result.FetchedResult.next(FetchedResult.java:34)""
    ""org.h2.command.query.Select.queryFlat(Select.java:728)""
    ""org.h2.command.query.Select.queryWithoutCache(Select.java:833)""
    ""org.h2.command.query.Query.queryWithoutCacheLazyCheck(Query.java:197)""
    ""org.h2.command.query.Query.query(Query.java:512)""
    ""org.h2.command.query.Query.query(Query.java:475)""
    ""org.h2.command.CommandContainer.query(CommandContainer.java:251)""
    ""org.h2.command.Command.executeQuery(Command.java:190)""
    ""org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:247)""
    ""org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)""
    ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
    ""--> driver.sql_jdbc.execute$fn__81456.invokeStatic(execute.clj:569)""
    ""driver.sql_jdbc.execute$fn__81456.invoke(execute.clj:567)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:577)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:574)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__81537$fn__81538.invoke(execute.clj:714)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__81537.invoke(execute.clj:713)""
    ""driver.h2$fn__84725$fn__84727.invoke(h2.clj:546)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
    ""driver.h2$fn__84725.invokeStatic(h2.clj:537)""
    ""driver.h2$fn__84725.invoke(h2.clj:533)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc$fn__115437.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__115437.invoke(sql_jdbc.clj:76)""
    ""driver.h2$fn__84564.invokeStatic(h2.clj:272)""
    ""driver.h2$fn__84564.invoke(h2.clj:268)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:61)""
    ""query_processor.execute$run.invoke(execute.clj:55)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__70034.invoke(execute.clj:24)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__70039.invoke(execute.clj:35)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70025.invoke(cache.clj:242)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__64004.invoke(permissions.clj:118)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__110068$check_download_permissions__110069$fn__110070.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64614.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111901$maybe_apply_column_level_perms_check__111902$fn__111903.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64624.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__70066.invoke(execute.clj:93)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
    ""query_processor.execute$execute.invoke(execute.clj:88)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81906$handle_audit_app_internal_queries__81907$fn__81908.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64652.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75840.invoke(process_userland_query.clj:186)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75909.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__75946.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__65056.invoke(setup.clj:189)""
    ""query_processor.setup$do_with_database_local_settings$fn__65051.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__65046$fn__65047.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__65046.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__65039$fn__65042.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.setup$do_with_metadata_provider$fn__65039.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__65033.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
    ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
    ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075$fn__99076.invoke(public.clj:140)""
    ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
    ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
    ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075.invoke(public.clj:139)""
    ""query_processor.streaming$_streaming_response$fn__68509$fn__68510$fn__68511.invoke(streaming.clj:175)""
    ""query_processor.streaming$_streaming_response$fn__68509$fn__68510.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__68509.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
    ""async.streaming_response$do_f_async$task__52275.invoke(streaming_response.clj:87)""],
   :state ""22018""}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: Data conversion error converting \""Gizmo\""; SQL statement:\n-- Metabase:: userID: 1 queryType: MBQL queryHash: 90c17f8cdbff4b671604d7ae59913a0a5a024d9477e6d75b5f3652471593844a\nSELECT \""PUBLIC\"".\""PRODUCTS\"".\""ID\"" AS \""ID\"", \""PUBLIC\"".\""PRODUCTS\"".\""EAN\"" AS \""EAN\"", \""PUBLIC\"".\""PRODUCTS\"".\""TITLE\"" AS \""TITLE\"", \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" AS \""CATEGORY\"", \""PUBLIC\"".\""PRODUCTS\"".\""VENDOR\"" AS \""VENDOR\"", \""PUBLIC\"".\""PRODUCTS\"".\""PRICE\"" AS \""PRICE\"", \""PUBLIC\"".\""PRODUCTS\"".\""RATING\"" AS \""RATING\"", \""PUBLIC\"".\""PRO [22018-214]"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__81537$fn__81538.invoke(execute.clj:716)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__81537.invoke(execute.clj:713)""
    ""driver.h2$fn__84725$fn__84727.invoke(h2.clj:546)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
    ""driver.h2$fn__84725.invokeStatic(h2.clj:537)""
    ""driver.h2$fn__84725.invoke(h2.clj:533)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
    ""driver.sql_jdbc$fn__115437.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__115437.invoke(sql_jdbc.clj:76)""
    ""driver.h2$fn__84564.invokeStatic(h2.clj:272)""
    ""driver.h2$fn__84564.invoke(h2.clj:268)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
    ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
    ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
    ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
    ""query_processor.execute$run.invokeStatic(execute.clj:61)""
    ""query_processor.execute$run.invoke(execute.clj:55)""
    ""query_processor.execute$add_native_form_to_result_metadata$fn__70034.invoke(execute.clj:24)""
    ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__70039.invoke(execute.clj:35)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70025.invoke(cache.clj:242)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__64004.invoke(permissions.clj:118)""
    ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__110068$check_download_permissions__110069$fn__110070.invoke(permissions.clj:90)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64614.invoke(enterprise.clj:51)""
    ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111901$maybe_apply_column_level_perms_check__111902$fn__111903.invoke(column_level_perms_check.clj:38)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64624.invoke(enterprise.clj:64)""
    ""query_processor.execute$execute$fn__70066.invoke(execute.clj:93)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
    ""query_processor.execute$execute.invoke(execute.clj:88)""
    ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
    ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
    ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81906$handle_audit_app_internal_queries__81907$fn__81908.invoke(handle_audit_queries.clj:145)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64652.invoke(enterprise.clj:103)""
    ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75840.invoke(process_userland_query.clj:186)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75909.invoke(catch_exceptions.clj:128)""
    ""query_processor$process_query$fn__75946.invoke(query_processor.clj:78)""
    ""query_processor.setup$do_with_canceled_chan$fn__65056.invoke(setup.clj:189)""
    ""query_processor.setup$do_with_database_local_settings$fn__65051.invoke(setup.clj:181)""
    ""query_processor.setup$do_with_driver$fn__65046$fn__65047.invoke(setup.clj:166)""
    ""driver$do_with_driver.invokeStatic(driver.clj:104)""
    ""driver$do_with_driver.invoke(driver.clj:99)""
    ""query_processor.setup$do_with_driver$fn__65046.invoke(setup.clj:165)""
    ""query_processor.setup$do_with_metadata_provider$fn__65039$fn__65042.invoke(setup.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
    ""query_processor.setup$do_with_metadata_provider$fn__65039.invoke(setup.clj:150)""
    ""query_processor.setup$do_with_resolved_database$fn__65033.invoke(setup.clj:128)""
    ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
    ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
    ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
    ""query_processor$process_query.invoke(query_processor.clj:69)""
    ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
    ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
    ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075$fn__99076.invoke(public.clj:140)""
    ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
    ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
    ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075.invoke(public.clj:139)""
    ""query_processor.streaming$_streaming_response$fn__68509$fn__68510$fn__68511.invoke(streaming.clj:175)""
    ""query_processor.streaming$_streaming_response$fn__68509$fn__68510.invoke(streaming.clj:174)""
    ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
    ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
    ""query_processor.streaming$_streaming_response$fn__68509.invoke(streaming.clj:171)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
    ""async.streaming_response$do_f_async$task__52275.invoke(streaming_response.clj:87)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :h2,
    :sql
    [""-- Metabase:: userID: 1 queryType: MBQL queryHash: 90c17f8cdbff4b671604d7ae59913a0a5a024d9477e6d75b5f3652471593844a""
     ""SELECT""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""ID\"" AS \""ID\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""EAN\"" AS \""EAN\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""TITLE\"" AS \""TITLE\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" AS \""CATEGORY\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""VENDOR\"" AS \""VENDOR\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""PRICE\"" AS \""PRICE\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""RATING\"" AS \""RATING\"",""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""CREATED_AT\"" AS \""CREATED_AT\""""
     ""FROM""
     ""  \""PUBLIC\"".\""PRODUCTS\""""
     ""WHERE""
     ""  \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" = 1234""
     ""LIMIT""
     ""  10000""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:constraints {:max-results 10000, :max-results-bare-rows 10000},
  :type :query,
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :cache-strategy nil,
  :viz-settings {:table.pivot_column ""CATEGORY"", :table.cell_column ""PRICE""},
  :database 1,
  :query {:source-table 8},
  :parameters
  [{:type :string/=,
    :value [1234],
    :slug ""text"",
    :id ""28b7ec17"",
    :target [:dimension [:field 58 {:base-type :type/Text}]]}]},
 :native
 {:query
  ""SELECT \""PUBLIC\"".\""PRODUCTS\"".\""ID\"" AS \""ID\"", \""PUBLIC\"".\""PRODUCTS\"".\""EAN\"" AS \""EAN\"", \""PUBLIC\"".\""PRODUCTS\"".\""TITLE\"" AS \""TITLE\"", \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" AS \""CATEGORY\"", \""PUBLIC\"".\""PRODUCTS\"".\""VENDOR\"" AS \""VENDOR\"", \""PUBLIC\"".\""PRODUCTS\"".\""PRICE\"" AS \""PRICE\"", \""PUBLIC\"".\""PRODUCTS\"".\""RATING\"" AS \""RATING\"", \""PUBLIC\"".\""PRODUCTS\"".\""CREATED_AT\"" AS \""CREATED_AT\"" FROM \""PUBLIC\"".\""PRODUCTS\"" WHERE \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" = 1234 LIMIT 10000"",
  :params nil},
 :status :failed,
 :class java.lang.NumberFormatException,
 :stacktrace
 [""java.base/java.lang.NumberFormatException.forInputString(Unknown Source)""
  ""java.base/java.lang.Integer.parseInt(Unknown Source)""
  ""java.base/java.lang.Integer.parseInt(Unknown Source)""
  ""org.h2.value.ValueStringBase.getInt(ValueStringBase.java:131)""
  ""org.h2.value.Value.convertToInt(Value.java:1575)""
  ""org.h2.value.Value.convertTo(Value.java:1135)""
  ""org.h2.value.Value.convertTo(Value.java:1003)""
  ""org.h2.value.Value.compareToNotNullable(Value.java:2630)""
  ""org.h2.value.Value.compareWithNull(Value.java:2654)""
  ""org.h2.engine.SessionLocal.compareWithNull(SessionLocal.java:1966)""
  ""org.h2.expression.condition.Comparison.compare(Comparison.java:250)""
  ""org.h2.expression.condition.Comparison.getValue(Comparison.java:222)""
  ""org.h2.expression.Expression.getBooleanValue(Expression.java:332)""
  ""org.h2.command.query.Select.isConditionMet(Select.java:449)""
  ""org.h2.command.query.Select$LazyResultQueryFlat.fetchNextRow(Select.java:1835)""
  ""org.h2.result.LazyResult.hasNext(LazyResult.java:78)""
  ""org.h2.result.FetchedResult.next(FetchedResult.java:34)""
  ""org.h2.command.query.Select.queryFlat(Select.java:728)""
  ""org.h2.command.query.Select.queryWithoutCache(Select.java:833)""
  ""org.h2.command.query.Query.queryWithoutCacheLazyCheck(Query.java:197)""
  ""org.h2.command.query.Query.query(Query.java:512)""
  ""org.h2.command.query.Query.query(Query.java:475)""
  ""org.h2.command.CommandContainer.query(CommandContainer.java:251)""
  ""org.h2.command.Command.executeQuery(Command.java:190)""
  ""org.h2.jdbc.JdbcStatement.executeInternal(JdbcStatement.java:247)""
  ""org.h2.jdbc.JdbcStatement.execute(JdbcStatement.java:223)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__81456.invokeStatic(execute.clj:569)""
  ""driver.sql_jdbc.execute$fn__81456.invoke(execute.clj:567)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:577)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:574)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81537$fn__81538.invoke(execute.clj:714)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__81537.invoke(execute.clj:713)""
  ""driver.h2$fn__84725$fn__84727.invoke(h2.clj:546)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320)""
  ""driver.h2$fn__84725.invokeStatic(h2.clj:537)""
  ""driver.h2$fn__84725.invoke(h2.clj:533)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:707)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:704)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:693)""
  ""driver.sql_jdbc$fn__115437.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__115437.invoke(sql_jdbc.clj:76)""
  ""driver.h2$fn__84564.invokeStatic(h2.clj:272)""
  ""driver.h2$fn__84564.invoke(h2.clj:268)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invokeStatic(pipeline.clj:47)""
  ""query_processor.pipeline$_STAR_execute_STAR_.invoke(pipeline.clj:34)""
  ""query_processor.pipeline$_STAR_run_STAR_.invokeStatic(pipeline.clj:97)""
  ""query_processor.pipeline$_STAR_run_STAR_.invoke(pipeline.clj:90)""
  ""query_processor.execute$run.invokeStatic(execute.clj:61)""
  ""query_processor.execute$run.invoke(execute.clj:55)""
  ""query_processor.execute$add_native_form_to_result_metadata$fn__70034.invoke(execute.clj:24)""
  ""query_processor.execute$add_preprocessed_query_to_result_metadata_for_userland_query$fn__70039.invoke(execute.clj:35)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70025.invoke(cache.clj:242)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__64004.invoke(permissions.clj:118)""
  ""metabase_enterprise.advanced_permissions.query_processor.middleware.permissions$fn__110068$check_download_permissions__110069$fn__110070.invoke(permissions.clj:90)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__64614.invoke(enterprise.clj:51)""
  ""metabase_enterprise.sandbox.query_processor.middleware.column_level_perms_check$fn__111901$maybe_apply_column_level_perms_check__111902$fn__111903.invoke(column_level_perms_check.clj:38)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__64624.invoke(enterprise.clj:64)""
  ""query_processor.execute$execute$fn__70066.invoke(execute.clj:93)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:225)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor.execute$execute.invokeStatic(execute.clj:92)""
  ""query_processor.execute$execute.invoke(execute.clj:88)""
  ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:47)""
  ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
  ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$fn__81906$handle_audit_app_internal_queries__81907$fn__81908.invoke(handle_audit_queries.clj:145)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__64652.invoke(enterprise.clj:103)""
  ""query_processor.middleware.process_userland_query$process_userland_query_middleware$fn__75840.invoke(process_userland_query.clj:186)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__75909.invoke(catch_exceptions.clj:128)""
  ""query_processor$process_query$fn__75946.invoke(query_processor.clj:78)""
  ""query_processor.setup$do_with_canceled_chan$fn__65056.invoke(setup.clj:189)""
  ""query_processor.setup$do_with_database_local_settings$fn__65051.invoke(setup.clj:181)""
  ""query_processor.setup$do_with_driver$fn__65046$fn__65047.invoke(setup.clj:166)""
  ""driver$do_with_driver.invokeStatic(driver.clj:104)""
  ""driver$do_with_driver.invoke(driver.clj:99)""
  ""query_processor.setup$do_with_driver$fn__65046.invoke(setup.clj:165)""
  ""query_processor.setup$do_with_metadata_provider$fn__65039$fn__65042.invoke(setup.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:171)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:160)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:151)""
  ""query_processor.setup$do_with_metadata_provider$fn__65039.invoke(setup.clj:150)""
  ""query_processor.setup$do_with_resolved_database$fn__65033.invoke(setup.clj:128)""
  ""query_processor.setup$do_with_qp_setup.invokeStatic(setup.clj:232)""
  ""query_processor.setup$do_with_qp_setup.invoke(setup.clj:216)""
  ""query_processor$process_query.invokeStatic(query_processor.clj:76)""
  ""query_processor$process_query.invoke(query_processor.clj:69)""
  ""query_processor.card$process_query_for_card_default_qp.invokeStatic(card.clj:170)""
  ""query_processor.card$process_query_for_card_default_qp.invoke(card.clj:166)""
  ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075$fn__99076.invoke(public.clj:140)""
  ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
  ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
  ""api.public$process_query_for_card_with_id_run_fn$run__99074$fn__99075.invoke(public.clj:139)""
  ""query_processor.streaming$_streaming_response$fn__68509$fn__68510$fn__68511.invoke(streaming.clj:175)""
  ""query_processor.streaming$_streaming_response$fn__68509$fn__68510.invoke(streaming.clj:174)""
  ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
  ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
  ""query_processor.streaming$_streaming_response$fn__68509.invoke(streaming.clj:171)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
  ""async.streaming_response$do_f_async$task__52275.invoke(streaming_response.clj:87)""],
 :card_id 135,
 :context :embedded-dashboard,
 :error
 ""Data conversion error converting \""Gizmo\""; SQL statement:\n-- Metabase:: userID: 1 queryType: MBQL queryHash: 90c17f8cdbff4b671604d7ae59913a0a5a024d9477e6d75b5f3652471593844a\nSELECT \""PUBLIC\"".\""PRODUCTS\"".\""ID\"" AS \""ID\"", \""PUBLIC\"".\""PRODUCTS\"".\""EAN\"" AS \""EAN\"", \""PUBLIC\"".\""PRODUCTS\"".\""TITLE\"" AS \""TITLE\"", \""PUBLIC\"".\""PRODUCTS\"".\""CATEGORY\"" AS \""CATEGORY\"", \""PUBLIC\"".\""PRODUCTS\"".\""VENDOR\"" AS \""VENDOR\"", \""PUBLIC\"".\""PRODUCTS\"".\""PRICE\"" AS \""PRICE\"", \""PUBLIC\"".\""PRODUCTS\"".\""RATING\"" AS \""RATING\"", \""PUBLIC\"".\""PRO [22018-214]"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:constraints {:max-results 10000, :max-results-bare-rows 10000},
  :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
  :user-parameters
  [{:value [1234],
    :type :string/=,
    :slug ""text"",
    :id ""28b7ec17"",
    :target [:dimension [:field 58 {:base-type :type/Text}]]}],
  :viz-settings {:table.pivot_column ""CATEGORY"", :table.cell_column ""PRICE""},
  :info
  {:executed-by 1,
   :context :embedded-dashboard,
   :card-id 135,
   :card-name ""Products"",
   :dashboard-id 11,
   :visualization-settings {:table.pivot_column ""CATEGORY"", :table.cell_column ""PRICE""}},
  :database 1,
  :type :query,
  :query
  {:source-table 8,
   :filter
   [:=
    [:field 58 {:base-type :type/Text}]
    [:value
     1234
     {:base_type :type/Text,
      :effective_type :type/Text,
      :coercion_strategy nil,
      :semantic_type :type/Category,
      :database_type ""CHARACTER VARYING"",
      :name ""CATEGORY""}]],
   :fields
   [[:field 62 nil]
    [:field 63 nil]
    [:field 65 nil]
    [:field 58 nil]
    [:field 60 nil]
    [:field 59 nil]
    [:field 61 nil]
    [:field 64 {:temporal-unit :default}]],
   :limit 10000,
   :metabase.query-processor.middleware.limit/original-limit nil}},
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
Tested this on 1.50.17 and also stats. 

Doesn't happen on 49
```


### Severity

Major issue cause it's breaking dashboards. To give a perspective a customer hitting this has 50+ dashboards that they have built and are customer-facing, many of which have 10+ filters, so they would need to go and audit + update all of those to resolve the issue completely

### Additional context

_No response_",Tony-metabase,2024-07-29 16:16:49+00:00,['ranquild'],2024-07-30 17:42:46+00:00,2024-07-30 16:29:44+00:00,https://github.com/metabase/metabase/issues/46240,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/Querying', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2256576301, 'issue_id': 2435832062, 'author': 'ranquild', 'body': 'Caused by https://github.com/metabase/metabase/pull/45447\r\n\r\nSpecifically https://github.com/metabase/metabase/blob/d9961ef0bb775e6eab66c5fd7794c56eedb73f74/src/metabase/api/embed/common.clj#L146', 'created_at': datetime.datetime(2024, 7, 29, 17, 58, 46, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-07-29 17:58:46 UTC): Caused by https://github.com/metabase/metabase/pull/45447

Specifically https://github.com/metabase/metabase/blob/d9961ef0bb775e6eab66c5fd7794c56eedb73f74/src/metabase/api/embed/common.clj#L146

"
2435620415,issue,open,,Driver: DuckDB (to allow for connections to other data sources),"The people at MotherDuck (https://github.com/MotherDuck-Open-Source/metabase_duckdb_driver?tab=readme-ov-file) have done the work to connect metabase to duckdb, which is an extremely capable analytics database.  I think it would be relatively little work to leverage duckdb capabilities to allow metabase to not only directly connect to duckdb instances which are blazingly fast, but to also connect to collections of, say .parquet files stored on S3. 

This would enable writing postgres-compatible SQL in metabase to query collections of .parqet files stored on S3.  How cool would that be?",robdmc,2024-07-29 14:43:26+00:00,[],2025-02-04 20:30:47+00:00,,https://github.com/metabase/metabase/issues/46237,"[('Database/', ''), ('Type:New Feature', '')]",[],
2435481509,issue,open,,Investigate peformance with a known problematic dashboard setup,"- 1 db
- 100 tables, 100 fields in each table (1 PK per table)
- 100 models, with 1 model based on each raw table
- 100 **aggregated** questions based on each model. Just Count is enough
- 1 dashboard with 20+ filters with these 100 questions, 1 tab
- connect each dashboard filter to each card
- **enable sandboxing** for all the tables for the user",ranquild,2024-07-29 13:45:48+00:00,['bshepherdson'],2024-08-14 08:52:54+00:00,,https://github.com/metabase/metabase/issues/46234,[],"[{'comment_id': 2288212835, 'issue_id': 2435481509, 'author': 'jakobhanna', 'body': 'We can reproduce the issue. We noticed a lot of queries as described in https://github.com/metabase/metabase/issues/46183. We have the issue without sandboxing. We can provide more infos. Thanks!', 'created_at': datetime.datetime(2024, 8, 14, 8, 52, 53, tzinfo=datetime.timezone.utc)}]","jakobhanna on (2024-08-14 08:52:53 UTC): We can reproduce the issue. We noticed a lot of queries as described in https://github.com/metabase/metabase/issues/46183. We have the issue without sandboxing. We can provide more infos. Thanks!

"
2435477775,issue,open,,Bulk `cached-metadata-provider` updates,"`metabase.lib.metadata.cached-provider/cached-metadata-provider` is naive about bulk metadata requests. It forwards bulk requests like `metadatas-for-tables` to the inner provider, of course, but when it gets back a (possibly fairly large) set of results, it does a naive `(doseq ... (store-in-cache! ...))` over each row.

That carries a lot of overhead, both in terms of repeatedly mutating Clojure structures and Atom synchronization. We should be able to do these bulk cache updates
- in one `swap!` call (or one per type of metadata being updated, perhaps)
- in larger chunks like a few `merge`s, rather than hundreds of `assoc-in`s.",ranquild,2024-07-29 13:44:07+00:00,['bshepherdson'],2024-07-31 16:47:47+00:00,,https://github.com/metabase/metabase/issues/46233,[],"[{'comment_id': 2258392196, 'issue_id': 2435477775, 'author': 'bshepherdson', 'body': ""I also note in passing that we're not de-duplicating simultaneous requests for the same metadata. I'm not sure how often that happens, but it's certainly possible. (Eg. on a dashboard load with a shared `metadata-provider`, several queries are being executed at once and if they have tables/models in common then we might be fetching the same rows multiple times.)\r\n\r\n**We should measure this and find out, probably by seeing how often we *overwrite* something in the cache rather than adding new keys.**\r\n\r\nThe `clojure.core.memoize` logic we're reusing in `metabase.util.memoize` handles this by wrapping every cached value in ` delay`, which is a low overhead way of de-duplicating these calls and blocking later calls until earlier ones are done."", 'created_at': datetime.datetime(2024, 7, 30, 13, 45, 39, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-07-30 13:45:39 UTC): I also note in passing that we're not de-duplicating simultaneous requests for the same metadata. I'm not sure how often that happens, but it's certainly possible. (Eg. on a dashboard load with a shared `metadata-provider`, several queries are being executed at once and if they have tables/models in common then we might be fetching the same rows multiple times.)

**We should measure this and find out, probably by seeing how often we *overwrite* something in the cache rather than adding new keys.**

The `clojure.core.memoize` logic we're reusing in `metabase.util.memoize` handles this by wrapping every cached value in ` delay`, which is a low overhead way of de-duplicating these calls and blocking later calls until earlier ones are done.

"
2435466616,issue,open,,[Epic] Dashboard perf fixes,"```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/46234
- [ ] https://github.com/metabase/metabase/pull/46204
- [ ] https://github.com/metabase/metabase/pull/46199
- [ ] https://github.com/metabase/metabase/issues/46339
- [ ] https://github.com/metabase/metabase/issues/46233
- [ ] https://github.com/metabase/metabase/issues/46181
- [ ] https://github.com/metabase/metabase/issues/46179
- [ ] https://github.com/metabase/metabase/issues/46183
```
",ranquild,2024-07-29 13:39:11+00:00,['bshepherdson'],2024-10-03 01:27:56+00:00,,https://github.com/metabase/metabase/issues/46232,"[('.Epic', 'Feature Implementation or Project')]",[],
2435462537,issue,closed,completed,Nightly Patch Releases,"see [discussion](https://metaboat.slack.com/archives/C864UT5CZ/p1721764399777419)

- New githib action: Release-1b-auto-patch
    - [x] runs nightly on a cron
    - [x] optional input: major release (for on-demand patch)
    - [x] find last commit with green CI for last 2 releases (eg 49 and 50)
    - [x] find next patch version based on tags
    - [x] trigger tag-for-release job with a new flag: `auto`
    - [ ] make sure that commit hasn't been released
    - [ ] trigger complete message without release notes
- `auto` flag:
    - [x] gets passed from tag job to test job
    - [x] test job with `auto` flag triggers release job
        - [x] skips release notes
        - [x] skips version-info update
        - [x] skips milestone management
        - [x] skips docs updates
        - [x] s3 and docker do not tag patch releases as `latest`
        - [x] sends flag to ee-extra
            - [ ] ee-extra auto approves/merges `auto` flag PRs with green CI
",iethree,2024-07-29 13:37:21+00:00,['iethree'],2024-10-08 16:19:03+00:00,2024-08-01 16:35:36+00:00,https://github.com/metabase/metabase/issues/46231,"[('.Building & Releasing', '')]",[],
2435307383,issue,closed,completed,Slack subscriptions silently fail when output is too big,"### Describe the bug

Since upgrading to v0.50, we have lot of Slack alerts that **silently fail**. Investigations showed that it's related to the size of the queries' outputs.

It's been a huge problem as we have important alerts setup on Slack, and we can't reliably trust them anymore.

**This only happens on alerts with a ~medium to big output.**

✅  The image.png file is correctly uploaded in our #metabase_files channel
❌  But the corresponding alert is not sent on the channel.

The logs show it's related to a timeout:
```
Jul 23 20:33:21 ip-172-31-50-7 bash: clojure.lang.ExceptionInfo: Timed out waiting to confirm the file was uploaded to a Slack channel. {:channel-id ""<redacted>"", :filename ""image.png""}
```

-------

When digging in the [source code](https://github.com/metabase/metabase/blob/master/src/metabase/integrations/slack.clj#L362) of Slack alerts, I'm surprised to see this:
```clj
;; Cal 2024-04-30: this typically takes 1-2 seconds to succeed.
;; If it takes more than 10 seconds, something else is wrong and we should abort.
:timeout-ms  3000
:interval-ms 500}))
```

👉 It's pretty clear the comment is not in sync with the code. The actual timeout is 3s, not 10s.

### To Reproduce

1. Create a new query.

Example that fails on our side (Snowflake SQL):
```sql
SELECT 'https://www.fakeapi.com/this/is/an/example/3ad59270-dbfd-40a3-88e2-c2721b59f2ab?parameter=foo&other=bar&id=339091ed-29ee-4d44-a860-092831895c4b&name=JohnDoe' AS url
FROM TABLE (GENERATOR(ROWCOUNT => 25))
```

If it does not fail as expected, you can artificially increase the query size by using `REPEAT('https://...', 10)`.

2. Save this query, and include it in a dashboard
3. Configure a Slack subscription for this dashboard, and hit ""Send to Slack now"" - it will time out

### Expected behavior

The alert should be sent, no timeout should happen.

### Logs

```
Jul 23 20:33:21 ip-172-31-50-7 bash: clojure.lang.ExceptionInfo: Timed out waiting to confirm the file was uploaded to a Slack channel. {:channel-id ""<redacted>"", :filename ""image.png""}
```


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.348-265.565.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-12"",
      ""tag"": ""v0.50.2"",
      ""hash"": ""1a2c2da""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Medium to high

### Additional context

Image is correctly sent in our #metabase_files channel (where all Metabase files are uploaded):
<img width=""424"" alt=""image"" src=""https://github.com/user-attachments/assets/87834331-b772-4983-9ede-21a253dddac1"">",florian-ernst-alan,2024-07-29 12:38:09+00:00,['calherries'],2024-08-01 06:35:21+00:00,2024-07-29 18:42:20+00:00,https://github.com/metabase/metabase/issues/46227,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]",[],
2434739998,issue,closed,completed,Wrong collection shown in ad-hoc model-based questions,"### Describe the bug

See [Slack](https://metaboat.slack.com/archives/C01LQQ2UW03/p1718411427896839)

> Once you modify a model by moving/hiding a column or change visualization options, the breadcrumb is changed from “collection / model” to “Our analytics / model”. Can we keep the original “collection / model” instead? I generally want to go to the same collection as the model to use other models and would never go to “Our analytics” collection from there. Thx!


https://github.com/user-attachments/assets/354d678c-8929-4b99-9ac4-ef62c4fab030



### To Reproduce

1. Create and save a collection
2. Create and save a model in that collection
3. Make any change to the model so that it turns into a model-based ad-hoc question (e.g. hide a column)


### Expected behavior

Breadcrumbs show the collection created in step 1


### Information about your Metabase installation

master, 7770cc69f6


### Severity

P2

### Additional context

When working on this issue, make sure the breadcrumbs work correctly for questions, models & metrics.
It looks like we don't even show the first breadcrumb when editing a metric-based ad-hoc question.
We need to make this constent.",kamilmielnik,2024-07-29 08:05:38+00:00,['nemanjaglumac'],2024-08-20 20:18:10+00:00,2024-08-20 12:15:14+00:00,https://github.com/metabase/metabase/issues/46221,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]",[],
2434593448,issue,closed,not_planned,convertTimezone expression not working,"### Describe the bug

I followed the instruction below to use timezone conversiono. but it did not work

https://www.metabase.com/docs/latest/questions/query-builder/expressions/converttimezone

convertTimezone(""2022-12-28T12:00:00"", ""Canada/Pacific"", ""Canada/Eastern"")


### To Reproduce

I added the custom column ""Test"", then enter 
convertTimezone(""2022-12-28T12:00:00"", ""Canada/Pacific"", ""Canada/Eastern"")

But it remiains empty in ""Test""


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.50.16 version I am using.
```


### Severity

blocking my usage of Metabase entirely

### Additional context

_No response_",Jianbin719,2024-07-29 06:47:38+00:00,[],2024-07-29 07:38:04+00:00,2024-07-29 07:36:34+00:00,https://github.com/metabase/metabase/issues/46216,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2255145572, 'issue_id': 2434593448, 'author': 'qnkhuat', 'body': ""What is the DB you're querying against? is it in the supported dbs list? : https://www.metabase.com/docs/latest/questions/query-builder/expressions/converttimezone#limitations"", 'created_at': datetime.datetime(2024, 7, 29, 7, 22, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2255206253, 'issue_id': 2434593448, 'author': 'Jianbin719', 'body': 'I see, MySQL is not support. sorry', 'created_at': datetime.datetime(2024, 7, 29, 7, 36, 31, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-29 07:22:09 UTC): What is the DB you're querying against? is it in the supported dbs list? : https://www.metabase.com/docs/latest/questions/query-builder/expressions/converttimezone#limitations

Jianbin719 (Issue Creator) on (2024-07-29 07:36:31 UTC): I see, MySQL is not support. sorry

"
2433523843,issue,closed,completed,Add hungarian translation,"**Is your feature request related to a problem? Please describe.**
Hungarian translation is still missing. 

**Describe the solution you'd like**
I have completed the translation that can be found at 
https://poeditor.com/projects/po_edit?id_language=65&id=200535

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**How important is this feature to you?**
This is important as it will enable every user from Hungary to use the project.

**Additional context**
The translation is now complete and validated.
",istvano,2024-07-27 15:23:43+00:00,[],2024-11-13 11:51:01+00:00,2024-11-13 10:37:25+00:00,https://github.com/metabase/metabase/issues/46215,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2254320546, 'issue_id': 2433523843, 'author': 'paoliniluis', 'body': '@zbodi74', 'created_at': datetime.datetime(2024, 7, 28, 2, 41, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320557669, 'issue_id': 2433523843, 'author': 'istvano', 'body': 'Hi,\r\nI have managed to update the translations again. it is 100% again', 'created_at': datetime.datetime(2024, 8, 30, 8, 59, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472903542, 'issue_id': 2433523843, 'author': 'istvano', 'body': 'Hi @paoliniluis \n\nI check it again and it is still 100% complete. Do you think it would be possible to include it in the next release ?', 'created_at': datetime.datetime(2024, 11, 13, 9, 4, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473135592, 'issue_id': 2433523843, 'author': 'paoliniluis', 'body': '@istvano I’ll check with the team. Btw I’m closing this issue as it seems that’s duplicate', 'created_at': datetime.datetime(2024, 11, 13, 10, 37, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473390815, 'issue_id': 2433523843, 'author': 'istvano', 'body': 'Hi @paoliniluis \n\nthanks a lot. this one had the needs triaging flag and other one had no such a thing. I am happy either way. If someone has a quick look. thanks again for looking!', 'created_at': datetime.datetime(2024, 11, 13, 11, 51, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-28 02:41:51 UTC): @zbodi74

istvano (Issue Creator) on (2024-08-30 08:59:39 UTC): Hi,
I have managed to update the translations again. it is 100% again

istvano (Issue Creator) on (2024-11-13 09:04:55 UTC): Hi @paoliniluis 

I check it again and it is still 100% complete. Do you think it would be possible to include it in the next release ?

paoliniluis on (2024-11-13 10:37:25 UTC): @istvano I’ll check with the team. Btw I’m closing this issue as it seems that’s duplicate

istvano (Issue Creator) on (2024-11-13 11:51:00 UTC): Hi @paoliniluis 

thanks a lot. this one had the needs triaging flag and other one had no such a thing. I am happy either way. If someone has a quick look. thanks again for looking!

"
2432993778,issue,closed,completed,Legend labels on pie charts on dashboards where the legend is below the pie and the percentage is on the wedge have an extraneous dash ,"### Describe the bug

If you make a pie chart really long on a dashboard so the legend is below the pie, and you set the percentages to show on the pie chart, the legend will have an extraneous dash like, ""Pie - ""

<img width=""376"" alt=""image"" src=""https://github.com/user-attachments/assets/e62f60ec-f56c-4584-8ab5-d19dc72c81f6"">


### To Reproduce

1.  Create a pie chart
2. Put it on a dash
3. Make the pie chart card really long so the legend is below piet
4. Marvel at the legend being below the pie
5. Set the pie chart display settings to have the percentage on the chart


### Expected behavior

There should not be a dash

### Logs

_No response_

### Information about your Metabase installation

```JSON
Built on 2024-07-26

Hash: f27d115
```


### Severity

It doesn't look great, but it works

### Additional context

See example at https://stats.metabase.com/dashboard/2546",cbalusek,2024-07-26 21:20:32+00:00,['alxnddr'],2024-11-18 20:51:15+00:00,2024-11-18 20:04:35+00:00,https://github.com/metabase/metabase/issues/46213,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Maps', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2253565668, 'issue_id': 2432993778, 'author': 'EmmadUsmani', 'body': 'Related to / duplicate of https://github.com/metabase/metabase/issues/29597. This affects not just the pie chart but the region map as well since they share the same legend component.', 'created_at': datetime.datetime(2024, 7, 26, 22, 0, 47, tzinfo=datetime.timezone.utc)}]","EmmadUsmani on (2024-07-26 22:00:47 UTC): Related to / duplicate of https://github.com/metabase/metabase/issues/29597. This affects not just the pie chart but the region map as well since they share the same legend component.

"
2432912850,issue,closed,completed,OOM errors during sync,"This task tracks progress on fixing OOM errors during sync

```[tasklist]
### More drivers
- [ ] https://github.com/metabase/metabase/issues/45163
- [ ] https://github.com/metabase/metabase/issues/44983
- [ ] https://github.com/metabase/metabase/pull/46193
- [ ] https://github.com/metabase/metabase/issues/46277
- [ ] https://github.com/metabase/metabase/issues/46411
```


[Sheet](https://docs.google.com/spreadsheets/d/1vAL8HwgAmsAE-WhzdzTLsPDhsY6MvaixQiKPLE2YSf8/edit?gid=100008772#gid=100008772)",calherries,2024-07-26 20:11:56+00:00,[],2024-08-19 18:30:50+00:00,2024-08-19 18:30:50+00:00,https://github.com/metabase/metabase/issues/46209,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2297186493, 'issue_id': 2432912850, 'author': 'calherries', 'body': ""Closing, I don't need this epic to track it anymore. People can create another one if there are more"", 'created_at': datetime.datetime(2024, 8, 19, 18, 30, 50, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-08-19 18:30:50 UTC): Closing, I don't need this epic to track it anymore. People can create another one if there are more

"
2432858322,issue,open,,BigQuery: Allow Mapping Field Filters to Tables in all GCP Projects the Service Account can Access,"**Is your feature request related to a problem? Please describe.**
When mapping field filters to tables in BigQuery you can only choose tables that exists in the datasets within the main project the service account is associated with. If the service account has access to multiple GCP projects you can weary them in the native SQL editor and join tables across datasets. 

**Describe the solution you'd like**
It would be ideal if field filters could be mapped to any of the tables you can query.

**Describe alternatives you've considered**
Using non field filters

**Additional context**
Currently, field filters in BigQuery generates SQL without the GCP project name included. That would need to change in order to implement this. It could break existing implementations to do so because BQ will throw an exception if some of the fields in the query have the project prefix while others do not.",ixipixi,2024-07-26 19:36:43+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/46206,"[('Type:New Feature', ''), ('Database/BigQuery', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2432783362,issue,closed,completed,[Testing Plan] Open the data source (in a new tab) from the notebook editor,"# Testing plan for #46201

## Open the data source in the new tab
Two most important things here are (1) to check underlying permissions, and (2) to make sure we open the correct link/state.
> [!Important]
> Keep an eye on situations where the underlying data source lives in a different collection for which the user might not have the sufficient permissions.

## Tooltips
- Make sure a tooltip is shown on hover only for
    - Data step
    - Join step
- Make sure a tooltip is not shown when there is no table selected
- Make sure a tooltip does not linger in the UI when we visit the new tab and come back to our notebook page

### Dimensions
- Entity type
    - Raw table
    - Question
    - Model
    - Metric
- Source table
    - Raw table
    - Saved question
    - Saved model
- Permissions
    - query
    - collection
    - sandboxing
- Click type
    - Regular left button
    - Middle button
    - Right click (nothing happens)
    - Regular click + keyboard modified
        - CMD (meta)
        - CTRL
- Device (screen) type
    - click
    - tap
- Metabase environment
    - Full app embedding
    - Static embedding
    - [x] Metabase on a subpath!

### Actions
- Open any of the first class entities in a notebook view and make sure you can open their data source in the new tab
- Regular left click on the data source still opens the entity picker
- Regular left click on the ""pick columns"" picker trigger still opens the columns picker
    - Deselecting some columns should have no effect on the underlying data source in the new tab
- Create as many stages of joins and as many types of joins you like and you should be able to open the underlying data source for each stage
    - Clicking on ""Previous results"" should not do anything
- Click on the data step to open entity picker
    - One should be able to open the entity in a new tab
    - Make sure collections and dashboards do not open
",nemanjaglumac,2024-07-26 18:35:41+00:00,['nemanjaglumac'],2024-10-08 16:17:22+00:00,2024-08-16 11:55:50+00:00,https://github.com/metabase/metabase/issues/46203,"[('.Team/Querying', '')]",[],
2432730226,issue,closed,completed,[Epic] Open the data source (in a new tab) from the notebook editor,"**Links**
- product doc: [Link to open the data source from the notebook editor](https://www.notion.so/metabase/Link-to-open-the-data-source-from-the-notebook-editor-640e1723dddb4ddb978190cca6a72791)
- [figma](https://www.figma.com/design/06jovUhXOrsRO8FYZi7G1d/Data-picker-improvements?node-id=6126-9480&t=5KR7Jvs7Hz0AXEbe-0)
- eng doc: N/A
- feature branch: `notebook-open-data-source`
- issue links: N/A
- testing plan: #46203

**Implementation Plan**
Alter the click behavior for certain UI elements to open the underlying data source in a new tab/window. The click handler should react to CMD + click, CTRL + click or middle button/scroll click.

```[tasklist]
### Milestone 1 (notebook data picker) #46228
- [x] Questions (based on the raw table, on the saved question, on the model)
- [x] Models (based on the raw table, on the saved question, on the model)
- [x] Testing coverage
```

```[tasklist]
### Milestone 2 (notebook joins) #46582
- [x] Raw tables
- [x] Questions
- [x] Models
```

```[tasklist]
### Milestone 3 (tooltips) #46552
- [x] Notebook data picker
- [x] Notebook joins
```

```[tasklist]
### Milestone 4 (follow ups and edge cases)
- [x] Make sure opening links works when Metabase is deployed on a subpath (#46684)
- [x] Prevent opening data source in an embedding SDK scenario (#46743)
- [x] Add E2E sandboxing scenarios (#46903)
```",nemanjaglumac,2024-07-26 18:02:20+00:00,['nemanjaglumac'],2024-10-08 16:17:21+00:00,2024-08-16 11:55:49+00:00,https://github.com/metabase/metabase/issues/46201,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2432448773,issue,closed,completed,Combine Question Filter Buttons,"[figma designs](https://www.figma.com/design/NOCVfjRaqkVhNqNq8jL9mX/Rework-the-info-sidebar-and-entity-actions?node-id=5744-72042&t=qGFdOYbO0EagfdUS-4)

![Screen Shot 2024-08-16 at 2 26 42 PM](https://github.com/user-attachments/assets/440ef972-aaf9-4886-be03-aec8372fae4b)
",iethree,2024-07-26 15:13:02+00:00,['iethree'],2024-10-08 16:16:06+00:00,2024-08-29 15:45:23+00:00,https://github.com/metabase/metabase/issues/46192,[],[],
2432448583,issue,closed,completed,Create Sharing Menu,"Consolidate all the sharing buttons into a single menu in the header (not the footer)

Question
![Screen Shot 2024-07-26 at 9 16 57 AM](https://github.com/user-attachments/assets/af4ff48d-a3d8-4f08-8482-3710daa01b65)


Dashboard
![Screen Shot 2024-07-26 at 9 16 42 AM](https://github.com/user-attachments/assets/d499c843-36c2-44a6-a758-e2d8e7c10e32)
",iethree,2024-07-26 15:12:55+00:00,['iethree'],2024-10-08 16:16:47+00:00,2024-08-21 19:08:55+00:00,https://github.com/metabase/metabase/issues/46191,"[('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('Sharing/Public', '')]",[],
2432398169,issue,closed,completed,Dashboard filters with long values go off-screen,"### Describe the bug

Dashboard string filters with long enough values go off-screen

### To Reproduce

1. Open a dashboard with at least one question
2. Add a string filter (don't forget to link it to a column so the filter is visible after leaving editing mode)
3. When editing the string filter, set pick ""Input box"" in the ""How should people filter on this column?"" section of the filter sidebar
4. Save the dashboard
5. Add a long enough value (could be a few sentences)
6. Notice the filter goes off-screen


### Expected behavior

String filters should have a fixed length (~30 characters), ellipsify text, and display the full value in a tooltip on hover

### Logs

_No response_

### Information about your Metabase installation

```JSON
`master`, but it's been like that for at least a few versions
```


### Severity

P2

### Additional context

  
![before](https://github.com/user-attachments/assets/672d65e2-44e7-43ff-9b2c-a0955ba12ab2)
",kulyk,2024-07-26 14:44:31+00:00,['kulyk'],2024-08-14 11:28:53+00:00,2024-08-13 15:38:03+00:00,https://github.com/metabase/metabase/issues/46189,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2286922633, 'issue_id': 2432398169, 'author': 'nemanjaglumac', 'body': '@kulyk duplicate of https://github.com/metabase/metabase/issues/44435?', 'created_at': datetime.datetime(2024, 8, 13, 18, 56, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288486991, 'issue_id': 2432398169, 'author': 'kulyk', 'body': ""> @kulyk duplicate of #44435?\r\n\r\n@nemanjaglumac I don't think so, this issue is about dashboard filters and the issue you mentioned is about QB filters"", 'created_at': datetime.datetime(2024, 8, 14, 11, 22, 3, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-08-13 18:56:16 UTC): @kulyk duplicate of https://github.com/metabase/metabase/issues/44435?

kulyk (Issue Creator) on (2024-08-14 11:22:03 UTC): @nemanjaglumac I don't think so, this issue is about dashboard filters and the issue you mentioned is about QB filters

"
2432245331,issue,closed,completed,Items can be dragged from the Trash into the Trash,"

![Image](https://github.com/user-attachments/assets/74b1e84d-93ea-45f1-86f7-b2f2b54f9b33)

",rafpaf,2024-07-26 13:28:32+00:00,['johnswanson'],2024-10-08 16:18:45+00:00,2024-08-05 16:01:59+00:00,https://github.com/metabase/metabase/issues/46184,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2263694951, 'issue_id': 2432245331, 'author': 'sloansparger', 'body': ""I've been able to fix this main issue, but in doing so discovered another bug where you can't undo a moving an item out of the trash if you drag it to a collection in the sidebar. This is due to us faking the collection_id/parent_id of items in the trash as being the trash's id even though it's not (items aren't technically moved into the trash). This results in our FE's undo system auto-calculating a diff which tries to set the parent collection as the trash, which the API does not allow. BE should accept updates to item's collection_id or parent_id equal to the trash_id, but discard the update (while continuing to fake the location as the trash).\r\n\r\n(cc: @johnswanson)"", 'created_at': datetime.datetime(2024, 8, 1, 18, 24, 28, tzinfo=datetime.timezone.utc)}]","sloansparger on (2024-08-01 18:24:28 UTC): I've been able to fix this main issue, but in doing so discovered another bug where you can't undo a moving an item out of the trash if you drag it to a collection in the sidebar. This is due to us faking the collection_id/parent_id of items in the trash as being the trash's id even though it's not (items aren't technically moved into the trash). This results in our FE's undo system auto-calculating a diff which tries to set the parent collection as the trash, which the API does not allow. BE should accept updates to item's collection_id or parent_id equal to the trash_id, but discard the update (while continuing to fake the location as the trash).

(cc: @johnswanson)

"
2432227513,issue,open,,Investigate another N+1 issue with fields in `query_metadata`,"There is a query that is executed a lot of times based on the logs
```
SELECT field . base_type, field . coercion_strategy, field . database_type, field . description, field . display_name, field . effective_type, field . fingerprint, field . fk_target_field_id, field . id, field . name, field . nfc_path, field . parent_id, field . position, field . semantic_type, field . settings, field . table_id, field . visibility_type, dimension . human_readable_field_id, dimension . id, dimension . name, dimension . type, 
values . human_readable_values, 
values . 
values FROM metabase_field 
    LEFT JOIN metabase_table ON field . table_id = ? . id 
    LEFT JOIN dimension ON ( dimension . field_id = ? . id ) AND dimension . type IN ( ? ) 
    LEFT JOIN metabase_fieldvalues ON ( 
    values . field_id = ? . id 
) AND ( 
    values . type = ? 
) 
```

This might be the same as https://github.com/metabase/metabase/issues/46179 or https://github.com/metabase/metabase/issues/46181 but it would be great to double check",ranquild,2024-07-26 13:18:53+00:00,['bshepherdson'],2024-07-31 16:47:56+00:00,,https://github.com/metabase/metabase/issues/46183,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2432211231,issue,open,,Fix N+1 DB calls with field values & sandboxing,"Check this chain:
1. https://github.com/metabase/metabase/blob/0a15637f1398fb3e9f9f31e55fb027a21e2d2f88/enterprise/backend/src/metabase_enterprise/sandbox/models/params/field_values.clj#L82
2. https://github.com/metabase/metabase/blob/0a15637f1398fb3e9f9f31e55fb027a21e2d2f88/enterprise/backend/src/metabase_enterprise/sandbox/models/params/field_values.clj#L22
3. https://github.com/metabase/metabase/blob/446bb823c151fca8879160e4dd3d395488479955/src/metabase/models/field.clj#L348",ranquild,2024-07-26 13:10:23+00:00,['bshepherdson'],2024-07-31 16:47:50+00:00,,https://github.com/metabase/metabase/issues/46181,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2252950295, 'issue_id': 2432211231, 'author': 'bshepherdson', 'body': 'The OSS code for this is only partially written in a batched way. It looks straightforward to write it in a fully batched way.\r\n\r\nThe EE code, however, has much more complex logic around `FieldValues` for different permission contexts, which IIUC are reduced to `hash-key`s used to allow many field values entries to coexist for a single field. That logic is designed to `select` or `insert` each row individually, and it\'s out of scope for a quick fix by a non-expert to change that.\r\n\r\nThat means there is a potential for N+1 mutations and selections, where N is the number of sandboxed fields linked to dashboard filters. Hopefully in practice that N is limited to a handful per dashboard.\r\n\r\nI think the approach here is to treat the OSS ""all fields"" N+1 as 50-blocking and I\'ll fix it now. The deeper sandboxing vs. parameters N+1 is a lower priority issue for the Admin/Webapp team to tackle later on.', 'created_at': datetime.datetime(2024, 7, 26, 15, 0, 5, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-07-26 15:00:05 UTC): The OSS code for this is only partially written in a batched way. It looks straightforward to write it in a fully batched way.

The EE code, however, has much more complex logic around `FieldValues` for different permission contexts, which IIUC are reduced to `hash-key`s used to allow many field values entries to coexist for a single field. That logic is designed to `select` or `insert` each row individually, and it's out of scope for a quick fix by a non-expert to change that.

That means there is a potential for N+1 mutations and selections, where N is the number of sandboxed fields linked to dashboard filters. Hopefully in practice that N is limited to a handful per dashboard.

I think the approach here is to treat the OSS ""all fields"" N+1 as 50-blocking and I'll fix it now. The deeper sandboxing vs. parameters N+1 is a lower priority issue for the Admin/Webapp team to tackle later on.

"
2432194630,issue,open,,fix(admin): Nav usability tweaks,"- [ ] Create new PR with Maz's icon
- [ ] Request color change to icon
- [ ] Small refactor described here: https://app.graphite.dev/github/pr/metabase/metabase/45882/fix-admin-nav-Ensure-that-the-Exit-admin-button-can-be-clicked-regardless-of-locale-or-viewport-size#comment-PRRC_kwDOAczgH85k2kIi
- [ ] Fix this little problem: the icon on the left moves a bit, at a certain breakpoint
",rafpaf,2024-07-26 13:01:13+00:00,[],2024-07-26 13:01:13+00:00,,https://github.com/metabase/metabase/issues/46180,[],[],
2432183139,issue,open,,Fix N+1 DB calls with fields values in `get-dashboard`,"https://github.com/metabase/metabase/blob/1e7823d1763abdaf82862972f4f01ce698426699/src/metabase/models/params/field_values.clj#L53

",ranquild,2024-07-26 12:54:55+00:00,['bshepherdson'],2024-07-31 16:47:53+00:00,,https://github.com/metabase/metabase/issues/46179,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2432029171,issue,open,,Stale filter input state shown when resetting or clearing the value,"### Describe the bug

https://github.com/user-attachments/assets/f966ea67-2b13-4b8d-995a-f94850a0e3cd



### To Reproduce

1. Create a question based on Orders table, add it to a new dashboard
2. Add required number dashboard filter with a default value and connect it to the question, save dashboard.
3. Change value of the filter, submit
4. Click the filter to show its input
5. Click ""reset"" button

Popover stays open and displays an old value.


### Expected behavior

The popover should be closed when resetting or clearing the field value.


### Information about your Metabase installation

master, d4cebf6043


### Severity

P3
",kamilmielnik,2024-07-26 11:25:45+00:00,[],2025-02-04 20:29:04+00:00,,https://github.com/metabase/metabase/issues/46177,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2432003475,issue,closed,not_planned,Convert a string to number,"### Describe the bug

With the last releases 0.50.15 and 0.50.16, creating a new numeric column from a string number is no longer possible.
Before that in the version v0.49.14 it was working fine.
![string_to_number](https://github.com/user-attachments/assets/1fcc3e16-df17-4444-b534-85db3f05a111)

![Capture](https://github.com/user-attachments/assets/e78c6992-7509-4287-9ebc-f844b4d3bb60)


### To Reproduce

1. Go to Metabase and create a question
2. Add a table that contains a string number
3. Try to create a new column from the string number.
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome: Version 127.0.6533.72 (Official Build) (64-bit)
- Database: Postgres
- Metabase versions: 0.50.15 and 0.50.16
```


### Severity

high

### Additional context

_No response_",idirall22,2024-07-26 11:09:07+00:00,[],2025-02-05 14:52:06+00:00,2025-02-05 14:52:06+00:00,https://github.com/metabase/metabase/issues/46176,"[('Querying/MBQL', ''), ('Type:New Feature', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2252670793, 'issue_id': 2432003475, 'author': 'paoliniluis', 'body': 'This was never possible and it was just a corner case in previous versions jfyi, we never supported casting', 'created_at': datetime.datetime(2024, 7, 26, 12, 34, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285571955, 'issue_id': 2432003475, 'author': 'fengqing11', 'body': 'The previous version did work, but it did not work after the upgrade', 'created_at': datetime.datetime(2024, 8, 13, 7, 43, 18, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-26 12:34:15 UTC): This was never possible and it was just a corner case in previous versions jfyi, we never supported casting

fengqing11 on (2024-08-13 07:43:18 UTC): The previous version did work, but it did not work after the upgrade

"
2431623908,issue,closed,not_planned,Inconsistency of columns on a dashboard card and the exported csv file,"### Describe the bug

Removal of columns from a question may cause missing columns or incorrect order of columns in the data downloaded from the card on the dashboard.

### To Reproduce

1. Create a question: 
  * Sample db / People - select the following columns: ID, Address, Email, Name, City, State, Birth Date, Zip
  * Table visualization
2. Save it and add to a dashboard
3. Edit the dashboard, on the cards visualization settings: hide Email and Address. Save the dashboard.
4. Now edit the question, and on the visualization settings: remove Email, Address (they were already hidden on the dashboard).
5. On the dashboard visualization settings: hide Zip, and move the ID column to the last position. Save it.
6. Now edit the question again, and add back the Email column. Save the question.
7. Email will be displayed as the last column on the dashboard:
<img width=""851"" alt=""image"" src=""https://github.com/user-attachments/assets/4bef7108-639f-4e1e-ac1d-f3f188ebc6a0"">
8. (!) Download CSV results from the card, and see the error: the Email column is missing.
<img width=""332"" alt=""image"" src=""https://github.com/user-attachments/assets/d1b3b594-b204-4efb-8a85-5bf337bc835a"">



### Expected behavior

The downloaded files should have the same columns in the same order as they are displayed on the dashboard.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.49.21
```


### Severity

P2 - reported by a customer

### Additional context

Clicking on 'Reset to defaults' on the card visualization settings seems to be a workaround. It resets the columns of the displayed card to the ones of the underlying question and after that rearranging columns or hiding individual ones works for both the dashboard and the downloaded data.",zbodi74,2024-07-26 07:37:45+00:00,[],2024-08-29 10:00:42+00:00,2024-08-29 10:00:41+00:00,https://github.com/metabase/metabase/issues/46175,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Unable to Reproduce', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2291684925, 'issue_id': 2431623908, 'author': 'kulyk', 'body': ""@zbodi74 i can't seem to reproduce this neither on v49 or v50. Could you please double-check if it's still an issue? If so, I'd appreciate if you could record a video repro, maybe I misunderstood some of the steps"", 'created_at': datetime.datetime(2024, 8, 15, 16, 36, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299569515, 'issue_id': 2431623908, 'author': 'cdeweyx', 'body': 'Also unable to repro this on master, going to close this until further notice', 'created_at': datetime.datetime(2024, 8, 20, 19, 7, 48, tzinfo=datetime.timezone.utc)}]","kulyk on (2024-08-15 16:36:34 UTC): @zbodi74 i can't seem to reproduce this neither on v49 or v50. Could you please double-check if it's still an issue? If so, I'd appreciate if you could record a video repro, maybe I misunderstood some of the steps

cdeweyx on (2024-08-20 19:07:48 UTC): Also unable to repro this on master, going to close this until further notice

"
2431313845,issue,closed,completed,"We keep the ""you've made changes to permissions"" bar on top after we pressed ""save""","### Describe the bug

FE state bug in 50.16. change the permissions and the bar will still be there
![image](https://github.com/user-attachments/assets/55d5e9a6-fbba-4fae-b8da-db242b9223d6)


### To Reproduce

1) add a database, probably with many schemas. 
2 Do a lot of changes at the same time (e.g. block all users, then jump into a schema and do granular stuff)
3) press save, see the bar still there

### Expected behavior

The bar should dissapear after the api call and a 200 status code

### Logs

NA, as everything ends fine, but the bar stays there

### Information about your Metabase installation

```JSON
v50.16
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-07-26 02:58:36+00:00,['sloansparger'],2024-08-23 19:47:27+00:00,2024-08-23 19:36:38+00:00,https://github.com/metabase/metabase/issues/46170,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Frontend', ''), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2258856417, 'issue_id': 2431313845, 'author': 'iethree', 'body': 'Unable to reproduce on 50.16 or on 17f64439966227756b4080934a6bb70a8f917307.\r\n\r\nTried a pretty full db with lots of groups and connection throttling on.', 'created_at': datetime.datetime(2024, 7, 30, 17, 28, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307702421, 'issue_id': 2431313845, 'author': 'sloansparger', 'body': ""Can confirm that I fixed this in v50.20 as part of #46509.\r\n\r\nReproduction steps:\r\n- remove all permissions from all columns permissions columns for all databases for a group\r\n- hit save\r\n\r\nv50.16 will maintain the save button at the top, v50.20 (with the fix) will remove it\r\n\r\nBackground context:\r\nThe BE was sending no info back for this group since all values were set to the default. The FE merges in updates for the modified groups into it's state, but was doing updates for each group present in the response. The fix just makes sure that we use the groups that were modified in the request instead."", 'created_at': datetime.datetime(2024, 8, 23, 19, 36, 38, tzinfo=datetime.timezone.utc)}]","iethree on (2024-07-30 17:28:53 UTC): Unable to reproduce on 50.16 or on 17f64439966227756b4080934a6bb70a8f917307.

Tried a pretty full db with lots of groups and connection throttling on.

sloansparger (Assginee) on (2024-08-23 19:36:38 UTC): Can confirm that I fixed this in v50.20 as part of #46509.

Reproduction steps:
- remove all permissions from all columns permissions columns for all databases for a group
- hit save

v50.16 will maintain the save button at the top, v50.20 (with the fix) will remove it

Background context:
The BE was sending no info back for this group since all values were set to the default. The FE merges in updates for the modified groups into it's state, but was doing updates for each group present in the response. The fix just makes sure that we use the groups that were modified in the request instead.

"
2431055167,issue,closed,completed,"""Filter by this date"" drill-through on Trend charts causes an error","### Describe the bug

Using ""Filter by this date"" drill through option on any trend chart will cause an error:
![image](https://github.com/user-attachments/assets/0c7a2c1d-8877-42e8-ac90-546327033564)


Seems like it's filtering on the date column but passing the _value_ from trend chart (instead of passing the date).

_Happens since v49.0_.

### To Reproduce

1. Create a GUI question ""Count of Orders by `Created At`""
2. Switch to Trend chart
3. Click on the big number
4. Select ""Filter by this date"" -> ""On""


### Expected behavior

Not an error

(But to be honest I'm not sure what the actual end result is supposed to be)

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.12-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.1 (Debian 16.1-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-25"",
      ""tag"": ""v1.50.16"",
      ""hash"": ""28de9df""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

https://github.com/user-attachments/assets/3eea1b5f-26a1-46b3-b2c1-3171cdc44558",alexyarosh,2024-07-25 22:09:23+00:00,['appleby'],2025-02-05 23:20:04+00:00,2025-02-05 17:11:41+00:00,https://github.com/metabase/metabase/issues/46168,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]","[{'comment_id': 2628364554, 'issue_id': 2431055167, 'author': 'appleby', 'body': ""Looks like maybe a dashviz (?) bug. Not sure so cc @ranquild for input.\n\nThe issue is, as alexyarosh mentions above, that the trend viz is passing the `column` from the date dimension, but the `value` from the aggregation.\n\nFrom the perspective of the drill thru, the following diff in `visualizations/SmartScalar/compute.js` fixes the bug, but I'm not familiar enough with the FE to know whether other things might be consuming this `clicked` object and expect to find the date column in `column`.\n\n```diff\ndiff --git a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\nindex 9fa95b5c45..c8401abe32 100644\n--- a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\n+++ b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\n@@ -204,7 +204,7 @@ function getCurrentMetricData({ series, insights, settings }) {\n \n   const clicked = {\n     value,\n-    column: cols[dimensionColIndex],\n+    column: cols[metricColIndex],\n     dimensions: [\n       {\n         value: rows[latestRowIndex][dimensionColIndex],\n```\n\nThere is also a minor product question here about what we want to drill through for this viz. Since the aggregation is the largest element and changes color on hover, drilling thru the aggregation value makes most sense to me, but you could also modify it to drill thru the date dimension like so:\n\n```diff\ndiff --git a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\nindex 9fa95b5c45..ed67dd67f6 100644\n--- a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\n+++ b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js\n@@ -203,7 +203,7 @@ function getCurrentMetricData({ series, insights, settings }) {\n   };\n \n   const clicked = {\n-    value,\n+    value: date,\n     column: cols[dimensionColIndex],\n     dimensions: [\n       {\n```\n\n**drill thru on aggregate column/value**\n![Image](https://github.com/user-attachments/assets/6d400c58-6952-4828-8784-1fa5bd78f9d0)\n\n**drill thru on date column/value**\n![Image](https://github.com/user-attachments/assets/db0ed2f0-b928-4e90-b5fb-0ece99ee5e86)"", 'created_at': datetime.datetime(2025, 1, 31, 20, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2638255045, 'issue_id': 2431055167, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)', 'created_at': datetime.datetime(2025, 2, 5, 23, 20, 3, tzinfo=datetime.timezone.utc)}]","appleby (Assginee) on (2025-01-31 20:41:55 UTC): Looks like maybe a dashviz (?) bug. Not sure so cc @ranquild for input.

The issue is, as alexyarosh mentions above, that the trend viz is passing the `column` from the date dimension, but the `value` from the aggregation.

From the perspective of the drill thru, the following diff in `visualizations/SmartScalar/compute.js` fixes the bug, but I'm not familiar enough with the FE to know whether other things might be consuming this `clicked` object and expect to find the date column in `column`.

```diff
diff --git a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
index 9fa95b5c45..c8401abe32 100644
--- a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
+++ b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
@@ -204,7 +204,7 @@ function getCurrentMetricData({ series, insights, settings }) {
 
   const clicked = {
     value,
-    column: cols[dimensionColIndex],
+    column: cols[metricColIndex],
     dimensions: [
       {
         value: rows[latestRowIndex][dimensionColIndex],
```

There is also a minor product question here about what we want to drill through for this viz. Since the aggregation is the largest element and changes color on hover, drilling thru the aggregation value makes most sense to me, but you could also modify it to drill thru the date dimension like so:

```diff
diff --git a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
index 9fa95b5c45..ed67dd67f6 100644
--- a/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
+++ b/frontend/src/metabase/visualizations/visualizations/SmartScalar/compute.js
@@ -203,7 +203,7 @@ function getCurrentMetricData({ series, insights, settings }) {
   };
 
   const clicked = {
-    value,
+    value: date,
     column: cols[dimensionColIndex],
     dimensions: [
       {
```

**drill thru on aggregate column/value**
![Image](https://github.com/user-attachments/assets/6d400c58-6952-4828-8784-1fa5bd78f9d0)

**drill thru on date column/value**
![Image](https://github.com/user-attachments/assets/db0ed2f0-b928-4e90-b5fb-0ece99ee5e86)

github-actions[bot] on (2025-02-05 23:20:03 UTC): 🚀 This should also be released by [v0.53](https://github.com/metabase/metabase/milestone/287)

"
2430987359,issue,closed,completed,Broken navigation when using Click Behavior and Tabs,"### Describe the bug

You won't be able to go back to the original dashboard if you do this set up. A video and steps below:
https://www.loom.com/share/d002458364d8449d974444958766ea9d?sid=bd706dc1-f1ed-45b1-b20d-6dd9341198ef

### To Reproduce

1. Set up two dashboards. Dashboard 2 should have 2 tabs.
2. Put a random table/card in Dashboard 1, and set click behavior of table/card to the Dashboard 2, Tab 2. 
3. Save
4. Click on the field of the table you set up Click Behavior on. It should correctly take you to Dashboard 2, Tab 2.
5. Now try to go back, using browser back button. See that you can't do it.




### Expected behavior

Should take to the original Dashboard 1

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 50.14
```


### Severity

P2

### Additional context

_No response_",ignacio-mb,2024-07-25 21:14:40+00:00,[],2024-08-05 21:39:35+00:00,2024-08-05 21:39:34+00:00,https://github.com/metabase/metabase/issues/46163,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Reporting/Dashboards/Click Behavior', ''), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2254497003, 'issue_id': 2430987359, 'author': 'perivamsi', 'body': 'Fixed with https://github.com/metabase/metabase/pull/44639\r\n\r\nWill be released in v51\r\n\r\nmore context in [Slack](https://metaboat.slack.com/archives/C052ZBWRG3W/p1721942106499729)', 'created_at': datetime.datetime(2024, 7, 28, 12, 12, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269856865, 'issue_id': 2430987359, 'author': 'cdeweyx', 'body': '@perivamsi Can we close this issue?', 'created_at': datetime.datetime(2024, 8, 5, 20, 26, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269966131, 'issue_id': 2430987359, 'author': 'perivamsi', 'body': 'yes please', 'created_at': datetime.datetime(2024, 8, 5, 21, 39, 34, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-28 12:12:25 UTC): Fixed with https://github.com/metabase/metabase/pull/44639

Will be released in v51

more context in [Slack](https://metaboat.slack.com/archives/C052ZBWRG3W/p1721942106499729)

cdeweyx on (2024-08-05 20:26:02 UTC): @perivamsi Can we close this issue?

perivamsi on (2024-08-05 21:39:34 UTC): yes please

"
2430949440,issue,closed,completed,[Epic] Add dashboard editing functionality to InteractiveDashboard SDK component,"We want to modify dashboard using Embedding SDK: edit mode, rearrange layout, save

**Links**
- product doc: https://www.notion.so/metabase/Embedding-SDK-Roadmap-02d1fba72171455bb3496d7d996cd302?pvs=4#6c735b525ce0466a9b4781f36e91028e
- feature branch: `branch-name` _this should be the feature branch where this work will be done in. PRs will be delivered against this branch_

**Implementation Plan**


",deniskaber,2024-07-25 20:44:56+00:00,['deniskaber'],2024-10-08 16:18:01+00:00,2024-08-12 13:33:36+00:00,https://github.com/metabase/metabase/issues/46160,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2430646549,issue,open,,Explain how to do cross database joins in MySQL,Explain how to do cross database joins in MySQL. E.g. ticket 29065,paoliniluis,2024-07-25 17:44:36+00:00,[],2024-07-25 17:44:36+00:00,,https://github.com/metabase/metabase/issues/46154,"[('Type:Documentation', ''), ('Database/MySQL', None)]",[],
2430343154,issue,closed,completed,Exiting a question picker modal launched by a Selectable values modal closes both modals,"Screencast showing the bug: https://www.loom.com/share/d0841e86f37440d38361a212c86660b1?sid=bdbf6102-dc36-400d-9272-4767ceb95284

To reproduce:
1. Create a dashboard
2. Add a text filter
3. Under ""How should people filter on this column?"", click Edit
4. Click ""Pick a modal or question""
5. Close that modal

Expected behavior: The ""Selectable values"" modal should remain open
Actual behavior: Both modals close",rafpaf,2024-07-25 15:39:33+00:00,[],2024-08-26 20:25:35+00:00,2024-08-26 19:33:34+00:00,https://github.com/metabase/metabase/issues/46149,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2289833789, 'issue_id': 2430343154, 'author': 'rafpaf', 'body': 'probably a `stopPropagation` thing', 'created_at': datetime.datetime(2024, 8, 14, 20, 38, 21, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-08-14 20:38:21 UTC): probably a `stopPropagation` thing

"
2430338811,issue,closed,completed,Comparing uuids when joining tables with MS SQL database causes sql error when casting GUID to varchar,"### Describe the bug

When using the drag and drop query builder joining tables with uuids as Keys, metabase generates sql that casts uuid to varchar with no length specified. This causes an error because MS SQL server's default varchar length is 30 and length must be 36 for uuids. See https://stackoverflow.com/questions/5628968/sql-server-insufficient-result-space-to-convert-uniqueidentifier-value-to-char.

This seems to have started following this fix - https://github.com/metabase/metabase/pull/45575) - worked as expected in version 50.11

### To Reproduce

1. Create a MS SQL database with one table as a uuid as primary key and another table with a foreign key of uuid to the first table 
2.  in metabase create a new question and join the two tables
3.  run the visualization
4. sql error occurs: An error occurred during the current command (Done status 0). Insufficient result space to convert uniqueidentifier value to char.

### Expected behavior

Expected SQL (v0.50.11)
SELECT
  TOP(1048575) ""dbo"".""TableA"".""TableAId"" AS ""TableAId"",
  ...
FROM
  ""dbo"".""TableA""
LEFT JOIN ""dbo"".""TableB"" AS ""TableB - TableAId"" ON ""dbo"".""TableA"".""TableAId"" = ""TableB - TableAId"".""TableAId""

Generated SQL (v0.50.15)
SELECT
  TOP(1048575) ""dbo"".""TableA"".""TableAId"" AS ""TableAId"",
  ...
FROM
  ""dbo"".""TableA""
LEFT JOIN ""dbo"".""TableB"" AS ""TableB - TableAId"" ON CAST(""dbo"".""TableA"".""TableAId"" AS varchar) = ""TableB - TableAId"".""TableAId""

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 Edg/126.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.4+7-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.4"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.4+7-LTS"",
    ""os.name"": ""Windows Server 2022"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/New_York""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-23"",
      ""tag"": ""v0.50.15"",
      ""hash"": ""c6697cf""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",37gears,2024-07-25 15:38:00+00:00,['snoe'],2024-10-01 22:20:39+00:00,2024-09-04 22:31:27+00:00,https://github.com/metabase/metabase/issues/46148,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/SQLServer', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Escalation', ''), ('.Team/Drivers', '')]","[{'comment_id': 2321850095, 'issue_id': 2430338811, 'author': 'snoe', 'body': ""I believe there's two issues here.\n\nThe one @37gears is showing should be fixed by https://github.com/metabase/metabase/issues/46558 in `50.20` as we should not be doing a cast at all in this situation. (I need to verify this still.)\n\nThe second issue, as they point out, is that sql server will need special handling to cast guids in the face of string operations (`contains`/`starts-with`/`ends-with`) which are relatively more rare."", 'created_at': datetime.datetime(2024, 8, 30, 16, 22, 37, tzinfo=datetime.timezone.utc)}]","snoe (Assginee) on (2024-08-30 16:22:37 UTC): I believe there's two issues here.

The one @37gears is showing should be fixed by https://github.com/metabase/metabase/issues/46558 in `50.20` as we should not be doing a cast at all in this situation. (I need to verify this still.)

The second issue, as they point out, is that sql server will need special handling to cast guids in the face of string operations (`contains`/`starts-with`/`ends-with`) which are relatively more rare.

"
2430119146,issue,closed,completed,"When creating a collection, the official collection tooltip appears behind the modal","### Describe the bug

![image](https://github.com/user-attachments/assets/bb3fbe22-fb0f-49dd-911f-bda8ae651c00)


### To Reproduce

1. New collection
2. Hoven the `i` on ""Collection type""

### Expected behavior

Tooltip should appear in front

### Logs

_No response_

### Information about your Metabase installation

```JSON
master Built on 2024-07-25 Hash: 575fa4e
```


### Severity

P3

### Additional context

_No response_",luizarakaki,2024-07-25 14:28:19+00:00,[],2024-10-22 19:05:28+00:00,2024-10-22 19:05:26+00:00,https://github.com/metabase/metabase/issues/46140,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2430036693, 'issue_id': 2430119146, 'author': 'rafpaf', 'body': '![Image](https://github.com/user-attachments/assets/96f16a85-6276-4894-ba69-35cd848cac2e)', 'created_at': datetime.datetime(2024, 10, 22, 19, 5, 26, tzinfo=datetime.timezone.utc)}]","rafpaf on (2024-10-22 19:05:26 UTC): ![Image](https://github.com/user-attachments/assets/96f16a85-6276-4894-ba69-35cd848cac2e)

"
2430097806,issue,open,,Druid JDBC: Skip long values in JSON unfolding query,"Implement the fix in https://github.com/metabase/metabase/pull/46089 for the Druid JDBC driver.

https://github.com/metabase/metabase/pull/46089 introduces a new optional multimethod for drivers that support `nested-field-columns`: `driver.sql/json-field-length`.

The task is to implement this method to avoid an OutOfMemoryError for the Druid JDBC driver.

I've set this to P2 because it could potentially block a user of the Druid JDBC driver from using Metabase if they have a lot of really large JSON values and a low enough memory to run into it, but we haven't seen any of these in the wild yet to know how common it might be.",calherries,2024-07-25 14:19:35+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/46137,"[('Type:New Feature', ''), ('Database/Druid', None), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2429681958,issue,closed,not_planned,Problem updating container from v0.50.10 onwards,"### Describe the bug

I have a dockerized metabase running since long ago. Last working version was 0.50.10. Since 0.50.11 I cannot update (I have it automated with watchtower), it seems to be related to the migration changeset.

Once it starts running, I get this error: 

`ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.
liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
        ...`

It happens with 0.50.11, and I've also tried waiting for 0.50.16, with the same result.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

2024-07-25 10:55:23,282 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
2024-07-25 10:55:23,338 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-25 10:55:23,340 INFO db.setup :: Verifying postgres Database Connection ...
2024-07-25 10:55:23,611 INFO db.setup :: Successfully verified PostgreSQL 10.21 (Debian 10.21-1.pgdg90+1) application database connection. ✅
2024-07-25 10:55:23,613 INFO db.setup :: Checking if a database downgrade is required...
2024-07-25 10:55:25,258 INFO db.setup :: Running Database Migrations...
2024-07-25 10:55:25,259 INFO db.setup :: Setting up Liquibase...
2024-07-25 10:55:25,944 INFO db.setup :: Liquibase is ready.
2024-07-25 10:55:25,945 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-25 10:55:27,303 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-07-25 10:55:27,406 INFO db.liquibase :: No migration lock found.
2024-07-25 10:55:27,407 INFO db.liquibase :: Migration lock acquired.
2024-07-25 10:55:28,109 INFO db.liquibase :: Running 5 migrations ...
2024-07-25 10:55:28,678 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.
liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44541.invoke(liquibase.clj:360)
	at metabase.db.liquibase$run_in_scope_locked$reify__44537.run(liquibase.clj:325)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
	at metabase.db.setup$migrate_BANG_$fn__53477.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44478.invoke(liquibase.clj:140)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53505$fn__53506.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53505.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53530.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""(""
  Position: 87
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more

UPDATE SUMMARY
Run:                          5
Previously run:             347
Filtered out:                50
-------------------------------
Total change sets:          402


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               50

2024-07-25 10:55:28,881 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
     Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.command.CommandScope.execute(CommandScope.java:253)
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
	at liquibase.Liquibase.update(Liquibase.java:234)
	at liquibase.Liquibase.update(Liquibase.java:212)
	at liquibase.Liquibase.update(Liquibase.java:194)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44541.invoke(liquibase.clj:360)
	at metabase.db.liquibase$run_in_scope_locked$reify__44537.run(liquibase.clj:325)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
	at metabase.db.setup$migrate_BANG_$fn__53477.invoke(setup.clj:84)
	at metabase.db.liquibase$do_with_liquibase$f_STAR___44478.invoke(liquibase.clj:140)
	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
	at clojure.lang.RestFn.invoke(RestFn.java:425)
	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
	at metabase.db.setup$setup_db_BANG_$fn__53505$fn__53506.invoke(setup.clj:167)
	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
	at metabase.db.setup$setup_db_BANG_$fn__53505.invoke(setup.clj:161)
	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
	at metabase.db$setup_db_BANG_$fn__53530.invoke(db.clj:86)
	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
	at metabase.core$init_BANG_.invoke(core.clj:165)
	at metabase.core$start_normally.invokeStatic(core.clj:182)
	at metabase.core$start_normally.invoke(core.clj:176)
	at metabase.core$entrypoint.invokeStatic(core.clj:215)
	at metabase.core$entrypoint.doInvoke(core.clj:209)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.Var.applyTo(Var.java:705)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
	at clojure.lang.RestFn.invoke(RestFn.java:397)
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
     Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 58 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
     Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 66 more
Caused by: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
  Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
  CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
) STORED]
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 81 more
Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""(""
  Position: 87
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
	... 86 more
2024-07-25 10:55:28,950 INFO metabase.core :: Metabase Shutting Down ...
2024-07-25 10:55:28,951 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-07-25 10:55:28,964 WARN db.liquibase :: ()
2024-07-25 10:55:28,965 INFO metabase.core :: Metabase Shutdown COMPLETE


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-116-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""10.21 (Debian 10.21-1.pgdg90+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying

### Additional context

_No response_",FerLSanchez,2024-07-25 11:05:48+00:00,[],2024-07-31 14:04:46+00:00,2024-07-25 11:18:09+00:00,https://github.com/metabase/metabase/issues/46127,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2250084286, 'issue_id': 2429681958, 'author': 'paoliniluis', 'body': 'Upgrade your db engine', 'created_at': datetime.datetime(2024, 7, 25, 11, 18, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-25 11:18:09 UTC): Upgrade your db engine

"
2429546492,issue,closed,completed,"""Settings"" isn't localized in command palette",![Image](https://github.com/user-attachments/assets/2f1d933e-8a0b-4da8-b81a-94ed9bdda943),rafpaf,2024-07-25 09:58:17+00:00,[],2024-07-25 17:04:30+00:00,2024-07-25 16:36:20+00:00,https://github.com/metabase/metabase/issues/46123,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2429454818,issue,closed,not_planned,OOM errors during Mongo DB sync-fields,"### Describe the bug

Some customers have OOM errors while inferring the schema of a MongoDB table during the sync-fields step. This issue is just to track its investigation and the fix.

### To Reproduce

NA

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

high, blocking

### Additional context

_No response_",calherries,2024-07-25 09:14:33+00:00,[],2024-08-02 02:57:58+00:00,2024-08-02 02:57:04+00:00,https://github.com/metabase/metabase/issues/46119,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2264416525, 'issue_id': 2429454818, 'author': 'qnkhuat', 'body': ""it's OOM during fetching sample documents for mongo, so this is a duplicate of https://github.com/metabase/metabase/issues/46277. See this [thread](https://metaboat.slack.com/archives/C010ZSXQY87/p1722567462371829?thread_ts=1721244154.390759&cid=C010ZSXQY87) for more details"", 'created_at': datetime.datetime(2024, 8, 2, 2, 57, 5, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-08-02 02:57:05 UTC): it's OOM during fetching sample documents for mongo, so this is a duplicate of https://github.com/metabase/metabase/issues/46277. See this [thread](https://metaboat.slack.com/archives/C010ZSXQY87/p1722567462371829?thread_ts=1721244154.390759&cid=C010ZSXQY87) for more details

"
2428716006,issue,closed,completed,SAVEPOINT ... does not exist,"### Describe the bug

There's something weird with v50.x and MySQL as the app DB, after we do a DELETE the DB sends that message and stops the questions from running (returning an error in the query run endpoint)

### To Reproduce

I can't reproduce

### Expected behavior

This should not happen

### Logs

```
[c28010c7-1210-4dbe-8bab-ddf6b73af980] 2024-07-24T15:07:31-04:00 ERROR metabase.server.middleware.log POST /api/dashboard/28/dashcard/346/card/384/query 500 918.3 ms (10 DB calls) {:metabase-user-id 1} 
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message ""(conn=4548157) SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist"",
   :data
   {:toucan2/context-trace
    [[""resolve connection"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}]
     [""resolve connection"" {:toucan2.connection/connectable :default}]
     [""resolve connection"" {:toucan2.connection/connectable nil}]
     {:toucan2.pipeline/rf
      #object[clojure.core$completing$fn__8528 0x73604ed9 ""clojure.core$completing$fn__8528@73604ed9""]}
     [""with compiled query""
      {:toucan2.pipeline/compiled-query
       [""DELETE FROM `user_parameter_value` WHERE (`user_id` = ?) AND (`dashboard_id` = ?) AND (`parameter_id` = ?)""
        1
        28
        ""50f949f9""]}]
     [""with built query""
      {:toucan2.pipeline/built-query
       {:delete-from [:user_parameter_value],
        :where [:and [:= :user_id 1] [:= :dashboard_id 28] [:= :parameter_id ""50f949f9""]]}}]
     [""with resolved query"" {:toucan2.pipeline/resolved-query {}}]
     [""with parsed args""
      {:toucan2.pipeline/query-type :toucan.query-type/delete.update-count,
       :toucan2.pipeline/parsed-args
       {:kv-args {:user_id 1, :dashboard_id 28, :parameter_id ""50f949f9""}, :queryable {}}}]
     [""with model"" {:toucan2.pipeline/model :model/UserParameterValue}]
     [""with unparsed args""
      {:toucan2.pipeline/query-type :toucan.query-type/delete.update-count,
       :toucan2.pipeline/unparsed-args
       (:model/UserParameterValue :user_id 1 :dashboard_id 28 :parameter_id ""50f949f9"")}]]},
   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}
  {:type java.sql.SQLSyntaxErrorException,
   :message ""(conn=4548157) SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist"",
   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}
  {:type org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException,
   :message ""SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist"",
   :at [org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException of ""MariaDbSqlException.java"" 34]}
  {:type java.sql.SQLException,
   :message ""SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist"",
   :at [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]}],
 :trace
 [[org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readPacket ""AbstractQueryProtocol.java"" 1555]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol getResult ""AbstractQueryProtocol.java"" 1518]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol executeQuery ""AbstractQueryProtocol.java"" 257]
  [org.mariadb.jdbc.MariaDbStatement executeInternal ""MariaDbStatement.java"" 356]
  [org.mariadb.jdbc.MariaDbStatement execute ""MariaDbStatement.java"" 500]
  [org.mariadb.jdbc.MariaDbConnection rollback ""MariaDbConnection.java"" 784]
  [com.mchange.v2.c3p0.impl.NewProxyConnection rollback ""NewProxyConnection.java"" 1007]
  [metabase.db.connection$do_transaction$thunk__42679 invoke ""connection.clj"" 146]
  [metabase.db.connection$do_transaction invokeStatic ""connection.clj"" 152]
  [metabase.db.connection$do_transaction invoke ""connection.clj"" 136]
  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invokeStatic ""connection.clj"" 189]
  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invoke ""connection.clj"" 162]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 165]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 457]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2643]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [methodical.impl.combo.threaded$fn__18174$fn__18175$fn__18178 invoke ""threaded.clj"" 71]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144$fn__18148 invoke ""threaded.clj"" 23]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144 invoke ""threaded.clj"" 21]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2588]
  [methodical.impl.combo.threaded$combine_with_threader$fn__18154 invoke ""threaded.clj"" 44]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 249]
  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invoke ""connection.clj"" 245]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 165]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 457]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2643]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 58]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 195]
  [toucan2.pipeline$transduce_execute$with_connection_STAR___21403 invoke ""pipeline.clj"" 74]
  [toucan2.connection$bind_current_connectable_fn$fn__21084 invoke ""connection.clj"" 104]
  [toucan2.connection$bind_current_connectable_fn$fn__21084 invoke ""connection.clj"" 104]
  [toucan2.connection$bind_current_connectable_fn$fn__21084 invoke ""connection.clj"" 104]
  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invokeStatic ""connection.clj"" 18]
  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invoke ""connection.clj"" 15]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.combo.threaded$fn__18174$fn__18175$fn__18176 invoke ""threaded.clj"" 70]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144$fn__18148 invoke ""threaded.clj"" 23]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144 invoke ""threaded.clj"" 21]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2587]
  [methodical.impl.combo.threaded$combine_with_threader$fn__18154 invoke ""threaded.clj"" 43]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 193]
  [metabase.db.connection$do_with_connection_primary_method_default invokeStatic ""connection.clj"" 132]
  [metabase.db.connection$do_with_connection_primary_method_default invoke ""connection.clj"" 130]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.combo.threaded$fn__18174$fn__18175$fn__18176 invoke ""threaded.clj"" 70]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144$fn__18148 invoke ""threaded.clj"" 23]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144 invoke ""threaded.clj"" 21]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2587]
  [methodical.impl.combo.threaded$combine_with_threader$fn__18154 invoke ""threaded.clj"" 43]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 193]
  [toucan2.connection$do_with_connection_primary_method_ invokeStatic ""connection.clj"" 204]
  [toucan2.connection$do_with_connection_primary_method_ invoke ""connection.clj"" 194]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.combo.threaded$fn__18174$fn__18175$fn__18176 invoke ""threaded.clj"" 70]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144$fn__18148 invoke ""threaded.clj"" 23]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144 invoke ""threaded.clj"" 21]
  [clojure.core$comp$fn__5876 invoke ""core.clj"" 2587]
  [methodical.impl.combo.threaded$combine_with_threader$fn__18154 invoke ""threaded.clj"" 43]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [clojure.core$partial$fn__5908 invoke ""core.clj"" 2642]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 156]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 132]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 421]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 193]
  [toucan2.pipeline$transduce_execute invokeStatic ""pipeline.clj"" 74]
  [toucan2.pipeline$transduce_execute invoke ""pipeline.clj"" 64]
  [clojure.lang.Var invoke ""Var.java"" 399]
  [toucan2.pipeline$transduce_compiled_query invokeStatic ""pipeline.clj"" 244]
  [toucan2.pipeline$transduce_compiled_query invoke ""pipeline.clj"" 240]
  [toucan2.pipeline$transduce_built_query invokeStatic ""pipeline.clj"" 252]
  [toucan2.pipeline$transduce_built_query invoke ""pipeline.clj"" 246]
  [toucan2.pipeline$transduce_query_primary_method_default invokeStatic ""pipeline.clj"" 272]
  [toucan2.pipeline$transduce_query_primary_method_default invoke ""pipeline.clj"" 269]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 178]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 675]
  [clojure.core$partial$fn__5908 doInvoke ""core.clj"" 2639]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 146]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [methodical.impl.combo.threaded$fn__18174$fn__18175$fn__18182 invoke ""threaded.clj"" 79]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144$fn__18148 invoke ""threaded.clj"" 23]
  [clojure.lang.ArrayChunk reduce ""ArrayChunk.java"" 58]
  [clojure.core.protocols$fn__8244 invokeStatic ""protocols.clj"" 136]
  [clojure.core.protocols$fn__8244 invoke ""protocols.clj"" 124]
  [clojure.core.protocols$fn__8204$G__8199__8213 invoke ""protocols.clj"" 19]
  [clojure.core.protocols$seq_reduce invokeStatic ""protocols.clj"" 31]
  [clojure.core.protocols$fn__8236 invokeStatic ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8236 invoke ""protocols.clj"" 75]
  [clojure.core.protocols$fn__8178$G__8173__8191 invoke ""protocols.clj"" 13]
  [clojure.core$reduce invokeStatic ""core.clj"" 6887]
  [clojure.core$reduce invoke ""core.clj"" 6869]
  [methodical.impl.combo.threaded$reducer_fn$fn__18144 invoke ""threaded.clj"" 21]
  [clojure.core$comp$fn__5876 doInvoke ""core.clj"" 2589]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 146]
  [clojure.core$apply invokeStatic ""core.clj"" 675]
  [clojure.core$apply doInvoke ""core.clj"" 662]
  [clojure.lang.RestFn invoke ""RestFn.java"" 533]
  [methodical.impl.combo.threaded$combine_with_threader$fn__18154 doInvoke ""threaded.clj"" 46]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 151]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 675]
  [clojure.core$apply doInvoke ""core.clj"" 662]
  [clojure.lang.RestFn invoke ""RestFn.java"" 533]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 65]
  [methodical.impl.standard$invoke_multifn doInvoke ""standard.clj"" 47]
  [clojure.lang.RestFn invoke ""RestFn.java"" 594]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 199]
  [toucan2.pipeline$transduce_query_STAR_ invokeStatic ""pipeline.clj"" 278]
  [toucan2.pipeline$transduce_query_STAR_ invoke ""pipeline.clj"" 274]
  [toucan2.pipeline$transduce_with_model invokeStatic ""pipeline.clj"" 293]
  [toucan2.pipeline$transduce_with_model invoke ""pipeline.clj"" 280]
  [toucan2.pipeline$transduce_parsed invokeStatic ""pipeline.clj"" 309]
  [toucan2.pipeline$transduce_parsed invoke ""pipeline.clj"" 295]
  [toucan2.pipeline$transduce_unparsed invokeStatic ""pipeline.clj"" 317]
  [toucan2.pipeline$transduce_unparsed invoke ""pipeline.clj"" 311]
  [toucan2.pipeline$transduce_unparsed_with_default_rf invokeStatic ""pipeline.clj"" 374]
  [toucan2.pipeline$transduce_unparsed_with_default_rf invoke ""pipeline.clj"" 368]
  [toucan2.delete$delete_BANG_ invokeStatic ""delete.clj"" 24]
  [toucan2.delete$delete_BANG_ doInvoke ""delete.clj"" 8]
  [clojure.lang.RestFn invoke ""RestFn.java"" 551]
  [metabase.models.user_parameter_value$upsert_BANG_ invokeStatic ""user_parameter_value.clj"" 49]
  [metabase.models.user_parameter_value$upsert_BANG_ invoke ""user_parameter_value.clj"" 33]
  [metabase.query_processor.dashboard$resolve_params_for_query invokeStatic ""dashboard.clj"" 149]
  [metabase.query_processor.dashboard$resolve_params_for_query invoke ""dashboard.clj"" 118]
  [metabase.query_processor.dashboard$process_query_for_dashcard invokeStatic ""dashboard.clj"" 182]
  [metabase.query_processor.dashboard$process_query_for_dashcard doInvoke ""dashboard.clj"" 163]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [medley.core$mapply invokeStatic ""core.cljc"" 243]
  [medley.core$mapply invoke ""core.cljc"" 237]
  [metabase.api.dashboard$fn__99414$fn__99418 invoke ""dashboard.clj"" 1231]
  [metabase.api.dashboard$do_with_dashboard_load_id invokeStatic ""dashboard.clj"" 308]
  [metabase.api.dashboard$do_with_dashboard_load_id invoke ""dashboard.clj"" 303]
  [metabase.api.dashboard$fn__99414 invokeStatic ""dashboard.clj"" 1230]
  [metabase.api.dashboard$fn__99414 invoke ""dashboard.clj"" 1222]
  [compojure.core$wrap_response$fn__53013 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__52997 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__53002 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__98468 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__53053 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [metabase.api.routes$fn__105149$fn__105150 invoke ""routes.clj"" 70]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__105429$fn__105430 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__53053 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__53006 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__53053 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025$f__53026$respond_SINGLEQUOTE___53027 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__53057 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__53025$f__53026 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__53025 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__101566 invoke ""exceptions.clj"" 107]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__101563 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__107772$fn__107773$fn__107774 invoke ""log.clj"" 236]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__107772$fn__107773 invoke ""log.clj"" 227]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__107772 invoke ""log.clj"" 226]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__113898 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__101522 invoke ""security.clj"" 240]
  [ring.middleware.json$wrap_json_body$fn__114157 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__87757 invoke ""offset_paging.clj"" 43]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54545 invoke ""json.clj"" 83]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__114246 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__114265 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__70247 invoke ""misc.clj"" 60]
  [metabase.server.middleware.session$reset_session_timeout$fn__77370 invoke ""session.clj"" 552]
  [metabase.server.middleware.session$bind_current_user$fn__77336$fn__77337 invoke ""session.clj"" 446]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 425]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 408]
  [metabase.server.middleware.session$bind_current_user$fn__77336 invoke ""session.clj"" 445]
  [metabase.server.middleware.session$wrap_current_user_info$fn__77317 invoke ""session.clj"" 383]
  [metabase.server.middleware.session$wrap_session_id$fn__77289 invoke ""session.clj"" 259]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__98476 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__114085 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__70229 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__70255 invoke ""misc.clj"" 77]
  [ring.middleware.gzip$wrap_gzip$fn__114127 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__70258 invoke ""misc.clj"" 94]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__113914 invoke ""ssl.clj"" 51]
  [metabase.server$async_proxy_handler$fn__70593 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause ""SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist"",
 :message ""(conn=4548157) SAVEPOINT 58dded4e-eb80-432d-99cb-6adbf96a1fe4 does not exist""}
```

### Information about your Metabase installation

```JSON
v50.x
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-07-25 00:52:15+00:00,[],2025-01-09 22:14:59+00:00,2025-01-09 22:14:59+00:00,https://github.com/metabase/metabase/issues/46111,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2252767662, 'issue_id': 2428716006, 'author': 'bshepherdson', 'body': 'https://stackoverflow.com/a/53285013 This answer seems like the first place to look - what did we run in this transaction that auto-closed it?', 'created_at': datetime.datetime(2024, 7, 26, 13, 28, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2252929089, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': '@bshepherdson might be related to https://github.com/metabase/metabase/pull/44509', 'created_at': datetime.datetime(2024, 7, 26, 14, 48, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2343296214, 'issue_id': 2428716006, 'author': 'simepy', 'body': '@ranquild, I also have this issue on production environment, I have a dashboard of 5 questions, loading it trigger the issue at least on one of them\r\n@paoliniluis did you find a workaround ?\r\n\r\nI run on Metabase v0.50.25\r\nMy error message :\r\n<details>\r\n\r\n```\r\n2024-09-11 10:19:17,178 ERROR middleware.log :: POST /api/dashboard/48/dashcard/493/card/547/query 500 281.5 ms (9 DB calls) {:metabase-user-id 2}\r\n{:via\r\n [{:type clojure.lang.ExceptionInfo,\r\n   :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",\r\n   :data\r\n   {:toucan2/context-trace\r\n    [[""resolve connection"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}]\r\n     [""resolve connection"" {:toucan2.connection/connectable :default}]\r\n     [""resolve connection"" {:toucan2.connection/connectable nil}]]},\r\n   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}\r\n  {:type java.sql.SQLSyntaxErrorException,\r\n   :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",\r\n   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}\r\n  {:type org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException,\r\n   :message ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",\r\n   :at [org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException of ""MariaDbSqlException.java"" 34]}\r\n  {:type java.sql.SQLException,\r\n   :message ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",\r\n   :at [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]}],\r\n :trace\r\n [[org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]\r\n  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readPacket ""AbstractQueryProtocol.java"" 1555]\r\n  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol getResult ""AbstractQueryProtocol.java"" 1518]\r\n  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol executeQuery ""AbstractQueryProtocol.java"" 257]\r\n  [org.mariadb.jdbc.MariaDbStatement executeInternal ""MariaDbStatement.java"" 356]\r\n  [org.mariadb.jdbc.MariaDbStatement execute ""MariaDbStatement.java"" 500]\r\n  [org.mariadb.jdbc.MariaDbConnection rollback ""MariaDbConnection.java"" 784]\r\n  [com.mchange.v2.c3p0.impl.NewProxyConnection rollback ""NewProxyConnection.java"" 1007]\r\n  [metabase.db.connection$do_transaction$thunk__42408 invoke ""connection.clj"" 146]\r\n  [metabase.db.connection$do_transaction invokeStatic ""connection.clj"" 152]\r\n  [metabase.db.connection$do_transaction invoke ""connection.clj"" 136]\r\n  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invokeStatic ""connection.clj"" 189]\r\n  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invoke ""connection.clj"" 162]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 13]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 249]\r\n  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invoke ""connection.clj"" 245]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 13]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 58]\r\n  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]\r\n  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 212]\r\n  [metabase.models.user_parameter_value$batched_upsert_BANG_$with_connection_STAR___94806\r\n   invoke\r\n   ""user_parameter_value.clj""\r\n   43]\r\n  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]\r\n  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]\r\n  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]\r\n  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invokeStatic ""connection.clj"" 18]\r\n  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invoke ""connection.clj"" 15]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]\r\n  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]\r\n  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]\r\n  [metabase.db.connection$do_with_connection_primary_method_default invokeStatic ""connection.clj"" 132]\r\n  [metabase.db.connection$do_with_connection_primary_method_default invoke ""connection.clj"" 130]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]\r\n  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]\r\n  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]\r\n  [toucan2.connection$do_with_connection_primary_method_ invokeStatic ""connection.clj"" 204]\r\n  [toucan2.connection$do_with_connection_primary_method_ invoke ""connection.clj"" 194]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]\r\n  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]\r\n  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]\r\n  [methodical.util.FnWithMeta invoke ""util.clj"" 46]\r\n  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]\r\n  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]\r\n  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]\r\n  [metabase.models.user_parameter_value$batched_upsert_BANG_ invokeStatic ""user_parameter_value.clj"" 43]\r\n  [metabase.models.user_parameter_value$batched_upsert_BANG_ invoke ""user_parameter_value.clj"" 33]\r\n  [metabase.query_processor.dashboard$resolve_params_for_query invokeStatic ""dashboard.clj"" 147]\r\n  [metabase.query_processor.dashboard$resolve_params_for_query invoke ""dashboard.clj"" 118]\r\n  [metabase.query_processor.dashboard$process_query_for_dashcard invokeStatic ""dashboard.clj"" 182]\r\n  [metabase.query_processor.dashboard$process_query_for_dashcard doInvoke ""dashboard.clj"" 163]\r\n  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]\r\n  [clojure.core$apply invokeStatic ""core.clj"" 667]\r\n  [clojure.core$apply invoke ""core.clj"" 662]\r\n  [medley.core$mapply invokeStatic ""core.cljc"" 243]\r\n  [medley.core$mapply invoke ""core.cljc"" 237]\r\n  [metabase.api.dashboard$fn__95727$fn__95730 invoke ""dashboard.clj"" 1245]\r\n  [metabase.api.dashboard$do_with_dashboard_load_id invokeStatic ""dashboard.clj"" 309]\r\n  [metabase.api.dashboard$do_with_dashboard_load_id invoke ""dashboard.clj"" 304]\r\n  [metabase.api.dashboard$fn__95727 invokeStatic ""dashboard.clj"" 1244]\r\n  [metabase.api.dashboard$fn__95727 invoke ""dashboard.clj"" 1236]\r\n  [compojure.core$wrap_response$fn__52754 invoke ""core.clj"" 160]\r\n  [compojure.core$wrap_route_middleware$fn__52738 invoke ""core.clj"" 132]\r\n  [compojure.core$wrap_route_info$fn__52743 invoke ""core.clj"" 139]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 151]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [metabase.server.middleware.auth$enforce_authentication$fn__97278 invoke ""auth.clj"" 18]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]\r\n  [compojure.core$make_context$handler__52794 invoke ""core.clj"" 290]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 300]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [clojure.lang.Var invoke ""Var.java"" 393]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [metabase.api.routes$fn__102954$fn__102957 invoke ""routes.clj"" 73]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]\r\n  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]\r\n  [clojure.lang.AFn applyTo ""AFn.java"" 144]\r\n  [clojure.core$apply invokeStatic ""core.clj"" 667]\r\n  [clojure.core$apply invoke ""core.clj"" 662]\r\n  [metabase.server.routes$fn__103234$fn__103235 doInvoke ""routes.clj"" 73]\r\n  [clojure.lang.RestFn invoke ""RestFn.java"" 436]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]\r\n  [compojure.core$make_context$handler__52794 invoke ""core.clj"" 290]\r\n  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 300]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]\r\n  [metabase.server.routes$fn__103217$fn__103219 invoke ""routes.clj"" 47]\r\n  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]\r\n  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]\r\n  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99312 invoke ""exceptions.clj"" 107]\r\n  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__99309 invoke ""exceptions.clj"" 96]\r\n  [metabase.server.middleware.log$log_api_call$fn__103521$fn__103522$fn__103523 invoke ""log.clj"" 233]\r\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]\r\n  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]\r\n  [metabase.server.middleware.log$log_api_call$fn__103521$fn__103522 invoke ""log.clj"" 224]\r\n  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]\r\n  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]\r\n  [metabase.server.middleware.log$log_api_call$fn__103521 invoke ""log.clj"" 223]\r\n  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__106811 invoke ""browser_cookie.clj"" 40]\r\n  [metabase.server.middleware.security$add_security_headers$fn__99268 invoke ""security.clj"" 246]\r\n  [ring.middleware.json$wrap_json_body$fn__107070 invoke ""json.clj"" 64]\r\n  [metabase.server.middleware.offset_paging$handle_paging$fn__87699 invoke ""offset_paging.clj"" 43]\r\n  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54361 invoke ""json.clj"" 83]\r\n  [ring.middleware.keyword_params$wrap_keyword_params$fn__107159 invoke ""keyword_params.clj"" 55]\r\n  [ring.middleware.params$wrap_params$fn__107178 invoke ""params.clj"" 77]\r\n  [metabase.server.middleware.misc$maybe_set_site_url$fn__64160 invoke ""misc.clj"" 59]\r\n  [metabase.server.middleware.session$reset_session_timeout$fn__65711 invoke ""session.clj"" 548]\r\n  [metabase.server.middleware.session$bind_current_user$fn__65677$fn__65678 invoke ""session.clj"" 443]\r\n  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 422]\r\n  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 405]\r\n  [metabase.server.middleware.session$bind_current_user$fn__65677 invoke ""session.clj"" 442]\r\n  [metabase.server.middleware.session$wrap_current_user_info$fn__65658 invoke ""session.clj"" 381]\r\n  [metabase.server.middleware.session$wrap_session_id$fn__65630 invoke ""session.clj"" 259]\r\n  [metabase.server.middleware.auth$wrap_static_api_key$fn__97286 invoke ""auth.clj"" 32]\r\n  [ring.middleware.cookies$wrap_cookies$fn__106998 invoke ""cookies.clj"" 200]\r\n  [metabase.server.middleware.misc$add_content_type$fn__64142 invoke ""misc.clj"" 28]\r\n  [metabase.server.middleware.misc$disable_streaming_buffering$fn__64168 invoke ""misc.clj"" 75]\r\n  [ring.middleware.gzip$wrap_gzip$fn__107040 invoke ""gzip.clj"" 86]\r\n  [metabase.server.middleware.misc$bind_request$fn__64171 invoke ""misc.clj"" 91]\r\n  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__106827 invoke ""ssl.clj"" 51]\r\n  [metabase.server$async_proxy_handler$fn__71902 invoke ""server.clj"" 77]\r\n  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]\r\n  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]\r\n  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]\r\n  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]\r\n  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]\r\n  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]\r\n  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]\r\n  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]\r\n  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]\r\n  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]\r\n  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]\r\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]\r\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]\r\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]\r\n  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]\r\n  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]\r\n  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]\r\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]\r\n  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]\r\n  [java.lang.Thread run nil -1]],\r\n :cause ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",\r\n :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist""}\r\n```\r\n\r\n</details>', 'created_at': datetime.datetime(2024, 9, 11, 10, 47, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2343354889, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'The trace telling me there\'s something with:\r\n```\r\n  [metabase.models.user_parameter_value$batched_upsert_BANG_$with_connection_STAR___94806\r\n   invoke\r\n   ""user_parameter_value.clj""\r\n   43]\r\n```\r\n\r\nmight indicate that this is the same as https://github.com/metabase/metabase/issues/47660...', 'created_at': datetime.datetime(2024, 9, 11, 11, 19, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452550920, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'https://github.com/metabase/metabase/issues/42816', 'created_at': datetime.datetime(2024, 11, 1, 20, 34, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452551124, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'https://github.com/metabase/metabase/issues/47657', 'created_at': datetime.datetime(2024, 11, 1, 20, 34, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452551572, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'https://github.com/metabase/metabase/issues/40546', 'created_at': datetime.datetime(2024, 11, 1, 20, 34, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561283840, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'Reopening this', 'created_at': datetime.datetime(2024, 12, 24, 16, 45, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578003353, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': '@simepy can you move to 52.5 and send us the logs', 'created_at': datetime.datetime(2025, 1, 8, 15, 46, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580113052, 'issue_id': 2428716006, 'author': 'simepy', 'body': ""@paoliniluis I don't have the error anymore with this version on the same question, thanks to the fix of @nvoxland I guess !\nI will continue to monitor that and report it if any error is raised 👍"", 'created_at': datetime.datetime(2025, 1, 9, 13, 7, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580590180, 'issue_id': 2428716006, 'author': 'nvoxland', 'body': 'Good to hear, @simepy, thanks for letting us know.', 'created_at': datetime.datetime(2025, 1, 9, 15, 37, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581341413, 'issue_id': 2428716006, 'author': 'paoliniluis', 'body': 'Closing as I got a second confirmation that this has been fixed', 'created_at': datetime.datetime(2025, 1, 9, 22, 13, 46, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-26 13:28:09 UTC): https://stackoverflow.com/a/53285013 This answer seems like the first place to look - what did we run in this transaction that auto-closed it?

paoliniluis (Issue Creator) on (2024-07-26 14:48:08 UTC): @bshepherdson might be related to https://github.com/metabase/metabase/pull/44509

simepy on (2024-09-11 10:47:41 UTC): @ranquild, I also have this issue on production environment, I have a dashboard of 5 questions, loading it trigger the issue at least on one of them
@paoliniluis did you find a workaround ?

I run on Metabase v0.50.25
My error message :
<details>

```
2024-09-11 10:19:17,178 ERROR middleware.log :: POST /api/dashboard/48/dashcard/493/card/547/query 500 281.5 ms (9 DB calls) {:metabase-user-id 2}
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",
   :data
   {:toucan2/context-trace
    [[""resolve connection"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}]
     [""resolve connection"" {:toucan2.connection/connectable :default}]
     [""resolve connection"" {:toucan2.connection/connectable nil}]]},
   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}
  {:type java.sql.SQLSyntaxErrorException,
   :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",
   :at [org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory createException ""ExceptionFactory.java"" 62]}
  {:type org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException,
   :message ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",
   :at [org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException of ""MariaDbSqlException.java"" 34]}
  {:type java.sql.SQLException,
   :message ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",
   :at [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]}],
 :trace
 [[org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readErrorPacket ""AbstractQueryProtocol.java"" 1693]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol readPacket ""AbstractQueryProtocol.java"" 1555]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol getResult ""AbstractQueryProtocol.java"" 1518]
  [org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol executeQuery ""AbstractQueryProtocol.java"" 257]
  [org.mariadb.jdbc.MariaDbStatement executeInternal ""MariaDbStatement.java"" 356]
  [org.mariadb.jdbc.MariaDbStatement execute ""MariaDbStatement.java"" 500]
  [org.mariadb.jdbc.MariaDbConnection rollback ""MariaDbConnection.java"" 784]
  [com.mchange.v2.c3p0.impl.NewProxyConnection rollback ""NewProxyConnection.java"" 1007]
  [metabase.db.connection$do_transaction$thunk__42408 invoke ""connection.clj"" 146]
  [metabase.db.connection$do_transaction invokeStatic ""connection.clj"" 152]
  [metabase.db.connection$do_transaction invoke ""connection.clj"" 136]
  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invokeStatic ""connection.clj"" 189]
  [metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection invoke ""connection.clj"" 162]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 13]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 249]
  [toucan2.connection$do_with_transaction_around_method_toucan2_connection_default invoke ""connection.clj"" 245]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 13]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 58]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 212]
  [metabase.models.user_parameter_value$batched_upsert_BANG_$with_connection_STAR___94806
   invoke
   ""user_parameter_value.clj""
   43]
  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]
  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]
  [toucan2.connection$bind_current_connectable_fn$fn__21267 invoke ""connection.clj"" 104]
  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invokeStatic ""connection.clj"" 18]
  [toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource invoke ""connection.clj"" 15]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]
  [metabase.db.connection$do_with_connection_primary_method_default invokeStatic ""connection.clj"" 132]
  [metabase.db.connection$do_with_connection_primary_method_default invoke ""connection.clj"" 130]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]
  [toucan2.connection$do_with_connection_primary_method_ invokeStatic ""connection.clj"" 204]
  [toucan2.connection$do_with_connection_primary_method_ invoke ""connection.clj"" 194]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invokeStatic ""connection.clj"" 118]
  [toucan2.connection$do_with_connection_around_method_toucan2_connection_default invoke ""connection.clj"" 106]
  [methodical.impl.combo.common$partial_STAR_$fn__18172 invoke ""common.clj"" 12]
  [methodical.util.FnWithMeta invoke ""util.clj"" 46]
  [methodical.impl.standard$invoke_multifn invokeStatic ""standard.clj"" 55]
  [methodical.impl.standard$invoke_multifn invoke ""standard.clj"" 47]
  [methodical.impl.standard.StandardMultiFn invoke ""standard.clj"" 210]
  [metabase.models.user_parameter_value$batched_upsert_BANG_ invokeStatic ""user_parameter_value.clj"" 43]
  [metabase.models.user_parameter_value$batched_upsert_BANG_ invoke ""user_parameter_value.clj"" 33]
  [metabase.query_processor.dashboard$resolve_params_for_query invokeStatic ""dashboard.clj"" 147]
  [metabase.query_processor.dashboard$resolve_params_for_query invoke ""dashboard.clj"" 118]
  [metabase.query_processor.dashboard$process_query_for_dashcard invokeStatic ""dashboard.clj"" 182]
  [metabase.query_processor.dashboard$process_query_for_dashcard doInvoke ""dashboard.clj"" 163]
  [clojure.lang.RestFn applyTo ""RestFn.java"" 137]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [medley.core$mapply invokeStatic ""core.cljc"" 243]
  [medley.core$mapply invoke ""core.cljc"" 237]
  [metabase.api.dashboard$fn__95727$fn__95730 invoke ""dashboard.clj"" 1245]
  [metabase.api.dashboard$do_with_dashboard_load_id invokeStatic ""dashboard.clj"" 309]
  [metabase.api.dashboard$do_with_dashboard_load_id invoke ""dashboard.clj"" 304]
  [metabase.api.dashboard$fn__95727 invokeStatic ""dashboard.clj"" 1244]
  [metabase.api.dashboard$fn__95727 invoke ""dashboard.clj"" 1236]
  [compojure.core$wrap_response$fn__52754 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__52738 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__52743 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__97278 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52794 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [metabase.api.routes$fn__102954$fn__102957 invoke ""routes.clj"" 73]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__103234$fn__103235 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52794 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52798 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52747 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766$f__52767$respond_SINGLEQUOTE___52768 invoke ""core.clj"" 197]
  [metabase.server.routes$fn__103217$fn__103219 invoke ""routes.clj"" 47]
  [compojure.core$routes$fn__52766$f__52767 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52766 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99312 invoke ""exceptions.clj"" 107]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__99309 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__103521$fn__103522$fn__103523 invoke ""log.clj"" 233]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__103521$fn__103522 invoke ""log.clj"" 224]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__103521 invoke ""log.clj"" 223]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__106811 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__99268 invoke ""security.clj"" 246]
  [ring.middleware.json$wrap_json_body$fn__107070 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__87699 invoke ""offset_paging.clj"" 43]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54361 invoke ""json.clj"" 83]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__107159 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__107178 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__64160 invoke ""misc.clj"" 59]
  [metabase.server.middleware.session$reset_session_timeout$fn__65711 invoke ""session.clj"" 548]
  [metabase.server.middleware.session$bind_current_user$fn__65677$fn__65678 invoke ""session.clj"" 443]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 422]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 405]
  [metabase.server.middleware.session$bind_current_user$fn__65677 invoke ""session.clj"" 442]
  [metabase.server.middleware.session$wrap_current_user_info$fn__65658 invoke ""session.clj"" 381]
  [metabase.server.middleware.session$wrap_session_id$fn__65630 invoke ""session.clj"" 259]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__97286 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__106998 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__64142 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__64168 invoke ""misc.clj"" 75]
  [ring.middleware.gzip$wrap_gzip$fn__107040 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__64171 invoke ""misc.clj"" 91]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__106827 invoke ""ssl.clj"" 51]
  [metabase.server$async_proxy_handler$fn__71902 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run nil -1]],
 :cause ""SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist"",
 :message ""(conn=39) SAVEPOINT fb1e0290-9f90-4f87-92fa-5a542546af00 does not exist""}
```

</details>

paoliniluis (Issue Creator) on (2024-09-11 11:19:03 UTC): The trace telling me there's something with:
```
  [metabase.models.user_parameter_value$batched_upsert_BANG_$with_connection_STAR___94806
   invoke
   ""user_parameter_value.clj""
   43]
```

might indicate that this is the same as https://github.com/metabase/metabase/issues/47660...

paoliniluis (Issue Creator) on (2024-11-01 20:34:05 UTC): https://github.com/metabase/metabase/issues/42816

paoliniluis (Issue Creator) on (2024-11-01 20:34:14 UTC): https://github.com/metabase/metabase/issues/47657

paoliniluis (Issue Creator) on (2024-11-01 20:34:36 UTC): https://github.com/metabase/metabase/issues/40546

paoliniluis (Issue Creator) on (2024-12-24 16:45:33 UTC): Reopening this

paoliniluis (Issue Creator) on (2025-01-08 15:46:32 UTC): @simepy can you move to 52.5 and send us the logs

simepy on (2025-01-09 13:07:18 UTC): @paoliniluis I don't have the error anymore with this version on the same question, thanks to the fix of @nvoxland I guess !
I will continue to monitor that and report it if any error is raised 👍

nvoxland on (2025-01-09 15:37:26 UTC): Good to hear, @simepy, thanks for letting us know.

paoliniluis (Issue Creator) on (2025-01-09 22:13:46 UTC): Closing as I got a second confirmation that this has been fixed

"
2428681184,issue,closed,completed,"We try to import the analytic views on load-from-h2, causing a ""ERROR: duplicate key value violates unique constraint ""idx_xxx""","### Describe the bug

If you connect Metabase to an app db and then try to import an h2 dump, then the views we create for analytics will already be there, but the process will try to also load the analytics tables that are in the dump, causing an error

### To Reproduce

1) initialize metabase
2) dump it to h2
3) then initialize another metabase
4) try to load-from-h2 the previous dump

### Expected behavior

We should not dump the analytics tables in the process, as those tables should always be in the destination

### Logs

NA

### Information about your Metabase installation

```JSON
v49+
```


### Severity

P2

### Additional context

workaround: initialize the new MB environment with MB_LOAD_ANALYTICS_CONTENT=false",paoliniluis,2024-07-25 00:09:14+00:00,[],2024-10-18 12:01:41+00:00,2024-10-18 12:01:41+00:00,https://github.com/metabase/metabase/issues/46110,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2249097006, 'issue_id': 2428681184, 'author': 'perivamsi', 'body': 'This should be a P1 since importing from h2 is completely broken.', 'created_at': datetime.datetime(2024, 7, 25, 0, 11, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249100727, 'issue_id': 2428681184, 'author': 'paoliniluis', 'body': ""@perivamsi ~agree~, the workaround that I posted ~doesn't work~ worked. So P2 I guess"", 'created_at': datetime.datetime(2024, 7, 25, 0, 16, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400553445, 'issue_id': 2428681184, 'author': 'johnswanson', 'body': ""I was able to reproduce on v49 was unable to repro on v50 or `master`. I _think_ [this](https://github.com/metabase/metabase/pull/40907/files#diff-65fdb622c6760fde1867daf5516614006d0c0fb106cf63f5718cd31bde2ebbefR202) may have fixed the issue, although I'm a little confused that @paoliniluis was able to repro on July 24 (this PR was merged Apr 3). @paoliniluis were you using a specific version or v50+/`master`?\n\nIf it's fixed as of v50 I think we could probably close this since it has a workaround and is only an issue on v49 or below."", 'created_at': datetime.datetime(2024, 10, 8, 18, 32, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401687867, 'issue_id': 2428681184, 'author': 'paoliniluis', 'body': ""I'm cool with that @johnswanson"", 'created_at': datetime.datetime(2024, 10, 9, 8, 32, 49, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-25 00:11:45 UTC): This should be a P1 since importing from h2 is completely broken.

paoliniluis (Issue Creator) on (2024-07-25 00:16:01 UTC): @perivamsi ~agree~, the workaround that I posted ~doesn't work~ worked. So P2 I guess

johnswanson on (2024-10-08 18:32:52 UTC): I was able to reproduce on v49 was unable to repro on v50 or `master`. I _think_ [this](https://github.com/metabase/metabase/pull/40907/files#diff-65fdb622c6760fde1867daf5516614006d0c0fb106cf63f5718cd31bde2ebbefR202) may have fixed the issue, although I'm a little confused that @paoliniluis was able to repro on July 24 (this PR was merged Apr 3). @paoliniluis were you using a specific version or v50+/`master`?

If it's fixed as of v50 I think we could probably close this since it has a workaround and is only an issue on v49 or below.

paoliniluis (Issue Creator) on (2024-10-09 08:32:49 UTC): I'm cool with that @johnswanson

"
2428587356,issue,closed,not_planned,"The little ""i"" icon that signals that there's a description only shows by default on scalars","**Is your feature request related to a problem? Please describe.**
We only show by default the little ""i"" icon on the scalars, which indicate that there's a description. For all other cards, you need to hover over it

**Describe the solution you'd like**
We should show the little ""i"" icon on all the cards by default

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-24 22:45:21+00:00,[],2024-07-25 17:51:42+00:00,2024-07-25 17:51:42+00:00,https://github.com/metabase/metabase/issues/46105,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2251079273, 'issue_id': 2428587356, 'author': 'ignacio-mb', 'body': 'Closing as dupe of https://github.com/metabase/metabase/issues/44984', 'created_at': datetime.datetime(2024, 7, 25, 17, 51, 42, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-07-25 17:51:42 UTC): Closing as dupe of https://github.com/metabase/metabase/issues/44984

"
2428486685,issue,closed,not_planned,Non-administrators attempting to create an alert encounter an error,"### Describe the bug

Alerts are created successfully by administrators. However, non-administrators attempting to create an alert encounter a message that says, ""To send alerts, an admin needs to set up email integration.""

### To Reproduce

1. Log in as a non-administrator
2. Go to an existing question
3. Click on the bell icon to ""Get alerts""
4. See a message saying that the administrator must setup the email integration.

<img width=""1175"" alt=""image"" src=""https://github.com/user-attachments/assets/e39fa701-a43a-452f-b393-6031a385964a"">


### Expected behavior

Assuming alerts are configured to allow administrators to create them, I expect non-administrators to have the same ability. The following link specifies that all users can create alerts and dashboard subscriptions.

https://www.metabase.com/docs/latest/permissions/notifications

### Logs

_No response_

### Information about your Metabase installation

- Your browser and the version: Chrome 126.0
- Your operating system: macOS 14.5
- Your database: Snowflake
- Metabase version: v0.50.13
- Metabase hosting environment: Docker
- Metabase internal database: Postgres



### Severity

Blocking some users

### Additional context

_No response_",matthelm,2024-07-24 21:13:20+00:00,[],2024-11-06 00:21:51+00:00,2024-11-06 00:21:51+00:00,https://github.com/metabase/metabase/issues/46100,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Alerts', ''), ('.Frontend', ''), ('Notifications/Slack', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2251797711, 'issue_id': 2428486685, 'author': 'qnkhuat', 'body': ""I can't reproduce it with an email setup.\r\n\r\nA couple of questions for you:\r\n1. Do you use slack or email, or both?\r\n2. Is your non-admin user sandboxed or impersonated?"", 'created_at': datetime.datetime(2024, 7, 26, 1, 43, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2256000502, 'issue_id': 2428486685, 'author': 'matthelm', 'body': ""@qnkhuat thanks for taking a look! \r\n1. We've only configured Slack.\r\n2. I’m unclear on your question. We experienced the issue with two separate logins. First, a non-admin colleague brought it to my attention. I then created a test user, logged in with that user, and confirmed the issue myself."", 'created_at': datetime.datetime(2024, 7, 29, 13, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2262171453, 'issue_id': 2428486685, 'author': 'qnkhuat', 'body': 'Thanks, I can reproduce with Slack now.\r\n\r\n@metabase/core-frontend-admin-webapp I believe this is a FE bug, the API `GET /api/pulse/input_form` does return slack as configured so we should show it.', 'created_at': datetime.datetime(2024, 8, 1, 6, 41, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271747353, 'issue_id': 2428486685, 'author': 'iethree', 'body': 'So this is the intended behavior, non-admins can only send email alerts. This message, however, is confusing, we will improve it. 👍 \r\n\r\nsee https://github.com/metabase/metabase/issues/17526', 'created_at': datetime.datetime(2024, 8, 6, 17, 3, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276618636, 'issue_id': 2428486685, 'author': 'matthelm', 'body': 'Thank you for the clarification and for improving the message.', 'created_at': datetime.datetime(2024, 8, 8, 20, 42, 15, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-26 01:43:51 UTC): I can't reproduce it with an email setup.

A couple of questions for you:
1. Do you use slack or email, or both?
2. Is your non-admin user sandboxed or impersonated?

matthelm (Issue Creator) on (2024-07-29 13:48:50 UTC): @qnkhuat thanks for taking a look! 
1. We've only configured Slack.
2. I’m unclear on your question. We experienced the issue with two separate logins. First, a non-admin colleague brought it to my attention. I then created a test user, logged in with that user, and confirmed the issue myself.

qnkhuat on (2024-08-01 06:41:43 UTC): Thanks, I can reproduce with Slack now.

@metabase/core-frontend-admin-webapp I believe this is a FE bug, the API `GET /api/pulse/input_form` does return slack as configured so we should show it.

iethree on (2024-08-06 17:03:58 UTC): So this is the intended behavior, non-admins can only send email alerts. This message, however, is confusing, we will improve it. 👍 

see https://github.com/metabase/metabase/issues/17526

matthelm (Issue Creator) on (2024-08-08 20:42:15 UTC): Thank you for the clarification and for improving the message.

"
2428413617,issue,closed,completed,Make Query Editor Button Bigger,"This is the most important button on the screen, it shouldn't be the smallest

![Screen Shot 2024-07-24 at 2 26 55 PM](https://github.com/user-attachments/assets/e2d4c421-a5b2-4938-bbf9-c8d71718e9f0)

this is gonna break a lot of tests",iethree,2024-07-24 20:26:24+00:00,['iethree'],2024-10-08 16:18:51+00:00,2024-08-02 22:18:49+00:00,https://github.com/metabase/metabase/issues/46096,[],[],
2428399448,issue,closed,completed,Cannot Access Table from our Database - Stuck Rendering,"One of our tables from a DB is stuck rendering and I cannot click into it in Admin control. 

**To Reproduce**
Steps to reproduce the behavior:
1. Go to browse data
2. Click on Safelease Production
3. Scroll down to ReportStatuses
4. See error

**Expected behavior**
Access the data in this table

**Screenshots**
<img width=""1147"" alt=""Screenshot 2024-07-24 at 3 17 12 PM"" src=""https://github.com/user-attachments/assets/1769c94a-7373-41e6-b10e-69d2148820f0"">
<img width=""417"" alt=""Screenshot 2024-07-24 at 3 17 35 PM"" src=""https://github.com/user-attachments/assets/803ff1fd-a178-4c4c-81e9-9ff9a42f15b3"">


**Severity**
Blocking use of this specific dataset. 

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v1.49.21"",
      ""hash"": ""a8b4d96""
    },
    ""settings"": {
      ""report-timezone"": ""US/Central""
    }
  }
}
```",jdavissafelease,2024-07-24 20:18:26+00:00,['calherries'],2024-12-24 11:37:44+00:00,2024-08-13 08:13:45+00:00,https://github.com/metabase/metabase/issues/46094,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2249018535, 'issue_id': 2428399448, 'author': 'paoliniluis', 'body': ""it's syncing and it might be because of an error, please send us the logs"", 'created_at': datetime.datetime(2024, 7, 24, 22, 46, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250843415, 'issue_id': 2428399448, 'author': 'jdavissafelease', 'body': 'Metabase Admin\r\n<https://safelease.metabaseapp.com/admin>\r\n\r\n   - Settings <https://safelease.metabaseapp.com/admin/settings>\r\n   - Databases <https://safelease.metabaseapp.com/admin/databases>\r\n   - Table Metadata <https://safelease.metabaseapp.com/admin/datamodel>\r\n   - People <https://safelease.metabaseapp.com/admin/people>\r\n   - Permissions <https://safelease.metabaseapp.com/admin/permissions>\r\n   - Tools <https://safelease.metabaseapp.com/admin/tools>\r\n   - Troubleshooting\r\n   <https://safelease.metabaseapp.com/admin/troubleshooting>\r\n\r\nExit admin <https://safelease.metabaseapp.com/>\r\n\r\n   - Help <https://safelease.metabaseapp.com/admin/troubleshooting/help>\r\n   - Tasks <https://safelease.metabaseapp.com/admin/troubleshooting/tasks>\r\n   - Jobs <https://safelease.metabaseapp.com/admin/troubleshooting/jobs>\r\n   - Logs <https://safelease.metabaseapp.com/admin/troubleshooting/logs>\r\n\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1934/card/1676/query 202 [ASYNC:\r\nunexpected-error] 1.5 s (18 DB calls) App DB connections: 1/15 Jetty\r\nthreads: 3/50 (16 idle, 0 queued) (156 total active threads) Queries in\r\nflight: 1 (0 queued); postgres DB 133 connections: 6/6 (3 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR\r\nmetabase.query-processor.middleware.catch-exceptions Error processing\r\nquery: Broken pipe {:database_id 133, :started_at #t\r\n""2024-07-25T14:13:34.033529Z[GMT]"", :via [{:status :failed, :class\r\norg.eclipse.jetty.io.EofException, :error nil, :stacktrace\r\n[""org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:116)""\r\n""org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:422)""\r\n""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:275)""\r\n""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:254)""\r\n""org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:386)""\r\n""org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:832)""\r\n""org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:243)""\r\n""org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:224)""\r\n""org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:589)""\r\n""org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:1051)""\r\n""org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:1123)""\r\n""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:270)""\r\n""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:254)""\r\n""org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:736)""\r\n""java.base/java.util.zip.DeflaterOutputStream.flush(Unknown Source)"" ""-->\r\nasync.streaming_response$delay_output_stream$fn__44112.invoke(streaming_response.clj:123)""\r\n""async.streaming_response.proxy$java.io.OutputStream$ff19274a.flush(Unknown\r\nSource)""\r\n""query_processor.streaming.json$fn$reify__53036.finish_BANG_(json.clj:115)""\r\n""query_processor.streaming$streaming_reducedf$fn__53812.invoke(streaming.clj:132)""\r\n""query_processor.context$reducedf.invokeStatic(context.clj:78)""\r\n""query_processor.context$reducedf.invoke(context.clj:73)""\r\n""query_processor.context.default$default_reducef.invokeStatic(default.clj:40)""\r\n""query_processor.context.default$default_reducef.invoke(default.clj:25)""\r\n""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671$fn__72672.invoke(cache.clj:201)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""\r\n""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671.invoke(cache.clj:197)""\r\n""query_processor.context$reducef.invokeStatic(context.clj:70)""\r\n""query_processor.context$reducef.invoke(context.clj:63)""\r\n""query_processor.context.default$default_runf$respond_STAR___50910.invoke(default.clj:45)""\r\n""driver.sql_jdbc.execute$execute_reducible_query$fn__79873.invoke(execute.clj:710)""\r\n""driver.sql_jdbc.execute$fn__79666$fn__79667.invoke(execute.clj:389)""\r\n""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""\r\n""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""\r\n""driver.sql_jdbc.execute$fn__79666.invokeStatic(execute.clj:383)""\r\n""driver.sql_jdbc.execute$fn__79666.invoke(execute.clj:381)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""\r\n""driver.sql_jdbc$fn__113278.invokeStatic(sql_jdbc.clj:78)""\r\n""driver.sql_jdbc$fn__113278.invoke(sql_jdbc.clj:76)""\r\n""query_processor.context$executef.invokeStatic(context.clj:60)""\r\n""query_processor.context$executef.invoke(context.clj:49)""\r\n""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""\r\n""query_processor.context.default$default_runf.invoke(default.clj:42)""\r\n""query_processor.context$runf.invokeStatic(context.clj:46)""\r\n""query_processor.context$runf.invoke(context.clj:40)""\r\n""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""\r\n""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""\r\n""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""\r\n""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""\r\n""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72684.invoke(cache.clj:228)""\r\n""query_processor.middleware.permissions$check_query_permissions$fn__67031.invoke(permissions.clj:140)""\r\n""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72505.invoke(enterprise.clj:51)""\r\n""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72515.invoke(enterprise.clj:64)""\r\n""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:24)""\r\n""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""\r\n""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""\r\n""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""\r\n""driver$do_with_driver.invokeStatic(driver.clj:97)""\r\n""driver$do_with_driver.invoke(driver.clj:92)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""\r\n""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""\r\n""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""\r\n""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""\r\n""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""\r\n""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""\r\n""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""\r\n""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""\r\n""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""\r\n""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""\r\n""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""\r\n""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""\r\n""query_processor.reducible$async_qp$qp_STAR___63247$fn__63251.invoke(reducible.clj:131)""]}],\r\n:action_id nil, :json_query {:constraints {:max-results 10000,\r\n:max-results-bare-rows 2000}, :type :query, :middleware {:js-int-to-string?\r\ntrue, :ignore-cached-results? false}, :viz-settings {}, :database 133,\r\n:query {:source-table 489, :aggregation [[:count]], :joins [{:fields :all,\r\n:alias ""Campaigns - CampaignId"", :condition [:= [:field 3713 {:base-type\r\n:type/UUID}] [:field 3733 {:base-type :type/UUID, :join-alias ""Campaigns -\r\nCampaignId""}]], :source-table 490} {:fields :all, :alias ""Facilities -\r\nFacilityId"", :condition [:= [:field 3729 {:base-type :type/UUID,\r\n:join-alias ""Campaigns - CampaignId""}] [:field 3790 {:base-type :type/UUID,\r\n:join-alias ""Facilities - FacilityId""}]], :source-table 484}], :filter\r\n[:and [:time-interval [:field 3723 {:base-type :type/DateTimeWithLocalTZ}]\r\n-1 :day] [:!= [:field 3797 {:base-type :type/UUID, :join-alias ""Facilities\r\n- FacilityId""}] ""d40eba2e-5f98-46d0-b03d-a6b77afd82b3""]]}, :parameters\r\n[{:type :string/=, :id ""6f1338c"", :target [:dimension [:field 3793\r\n{:base-type :type/Text, :join-alias ""Facilities - FacilityId""}]]} {:type\r\n:date/relative, :id ""ab826ff0"", :target [:dimension [:field 3718\r\n{:base-type :type/DateTimeWithLocalTZ}]]}], :async? true, :cache-ttl 5},\r\n:native {:query ""SELECT COUNT(*) AS \\""count\\"" FROM \\""public\\"".\\""messages\\""\r\nLEFT JOIN \\""public\\"".\\""campaigns\\"" AS \\""Campaigns - CampaignId\\"" ON\r\n\\""public\\"".\\""messages\\"".\\""campaignId\\"" = \\""Campaigns - CampaignId\\"".\\""id\\""\r\nLEFT JOIN \\""public\\"".\\""facilities\\"" AS \\""Facilities - FacilityId\\"" ON\r\n\\""Campaigns - CampaignId\\"".\\""facilityId\\"" = \\""Facilities -\r\nFacilityId\\"".\\""id\\"" WHERE (\\""public\\"".\\""messages\\"".\\""createdAt\\"" >=\r\nCAST((NOW() + INTERVAL \'-1 day\') AS date)) AND\r\n(\\""public\\"".\\""messages\\"".\\""createdAt\\"" < CAST(NOW() AS date)) AND\r\n((\\""Facilities - FacilityId\\"".\\""portfolioId\\"" <> ?) OR (\\""Facilities -\r\nFacilityId\\"".\\""portfolioId\\"" IS NULL))"", :params (#uuid\r\n""d40eba2e-5f98-46d0-b03d-a6b77afd82b3"")}, :status :failed, :class\r\njava.io.IOException, :stacktrace\r\n[""java.base/sun.nio.ch.FileDispatcherImpl.writev0(Native Method)""\r\n""java.base/sun.nio.ch.SocketDispatcher.writev(Unknown Source)""\r\n""java.base/sun.nio.ch.IOUtil.write(Unknown Source)""\r\n""java.base/sun.nio.ch.IOUtil.write(Unknown Source)""\r\n""java.base/sun.nio.ch.SocketChannelImpl.write(Unknown Source)""\r\n""java.base/java.nio.channels.SocketChannel.write(Unknown Source)""\r\n""org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:110)""\r\n""org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:422)""\r\n""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:275)""\r\n""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:254)""\r\n""org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:386)""\r\n""org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:832)""\r\n""org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:243)""\r\n""org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:224)""\r\n""org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:589)""\r\n""org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:1051)""\r\n""org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:1123)""\r\n""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:270)""\r\n""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:254)""\r\n""org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:736)""\r\n""java.base/java.util.zip.DeflaterOutputStream.flush(Unknown Source)"" ""-->\r\nasync.streaming_response$delay_output_stream$fn__44112.invoke(streaming_response.clj:123)""\r\n""async.streaming_response.proxy$java.io.OutputStream$ff19274a.flush(Unknown\r\nSource)""\r\n""query_processor.streaming.json$fn$reify__53036.finish_BANG_(json.clj:115)""\r\n""query_processor.streaming$streaming_reducedf$fn__53812.invoke(streaming.clj:132)""\r\n""query_processor.context$reducedf.invokeStatic(context.clj:78)""\r\n""query_processor.context$reducedf.invoke(context.clj:73)""\r\n""query_processor.context.default$default_reducef.invokeStatic(default.clj:40)""\r\n""query_processor.context.default$default_reducef.invoke(default.clj:25)""\r\n""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671$fn__72672.invoke(cache.clj:201)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""\r\n""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""\r\n""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671.invoke(cache.clj:197)""\r\n""query_processor.context$reducef.invokeStatic(context.clj:70)""\r\n""query_processor.context$reducef.invoke(context.clj:63)""\r\n""query_processor.context.default$default_runf$respond_STAR___50910.invoke(default.clj:45)""\r\n""driver.sql_jdbc.execute$execute_reducible_query$fn__79873.invoke(execute.clj:710)""\r\n""driver.sql_jdbc.execute$fn__79666$fn__79667.invoke(execute.clj:389)""\r\n""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""\r\n""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""\r\n""driver.sql_jdbc.execute$fn__79666.invokeStatic(execute.clj:383)""\r\n""driver.sql_jdbc.execute$fn__79666.invoke(execute.clj:381)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""\r\n""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""\r\n""driver.sql_jdbc$fn__113278.invokeStatic(sql_jdbc.clj:78)""\r\n""driver.sql_jdbc$fn__113278.invoke(sql_jdbc.clj:76)""\r\n""query_processor.context$executef.invokeStatic(context.clj:60)""\r\n""query_processor.context$executef.invoke(context.clj:49)""\r\n""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""\r\n""query_processor.context.default$default_runf.invoke(default.clj:42)""\r\n""query_processor.context$runf.invokeStatic(context.clj:46)""\r\n""query_processor.context$runf.invoke(context.clj:40)""\r\n""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""\r\n""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""\r\n""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""\r\n""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""\r\n""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72684.invoke(cache.clj:228)""\r\n""query_processor.middleware.permissions$check_query_permissions$fn__67031.invoke(permissions.clj:140)""\r\n""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72505.invoke(enterprise.clj:51)""\r\n""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72515.invoke(enterprise.clj:64)""\r\n""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:24)""\r\n""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""\r\n""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""\r\n""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""\r\n""driver$do_with_driver.invokeStatic(driver.clj:97)""\r\n""driver$do_with_driver.invoke(driver.clj:92)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""\r\n""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""\r\n""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""\r\n""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""\r\n""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""\r\n""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""\r\n""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""\r\n""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""\r\n""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""\r\n""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""\r\n""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""\r\n""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""\r\n""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""\r\n""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""\r\n""query_processor.reducible$async_qp$qp_STAR___63247$fn__63251.invoke(reducible.clj:131)""],\r\n:card_id 1668, :context :dashboard, :error ""Broken pipe"", :row_count 0,\r\n:running_time 0, :preprocessed {:constraints {:max-results 10000,\r\n:max-results-bare-rows 2000}, :type :query, :middleware {:js-int-to-string?\r\ntrue, :ignore-cached-results? false}, :user-parameters [{:type :string/=,\r\n:id ""6f1338c"", :target [:dimension [:field 3793 {:base-type :type/Text,\r\n:join-alias ""Facilities - FacilityId""}]]} {:type :date/relative, :id\r\n""ab826ff0"", :target [:dimension [:field 3718 {:base-type\r\n:type/DateTimeWithLocalTZ}]]}], :viz-settings {}, :info {:executed-by 71,\r\n:context :dashboard, :card-id 1668, :card-name ""Number of Messages Sent\r\nYesterday"", :dashboard-id 397}, :database 133, :query {:source-table 489,\r\n:aggregation [[:aggregation-options [:count] {:name ""count""}]], :filter\r\n[:and [:>= [:field 3723 {:base-type :type/DateTimeWithLocalTZ,\r\n:temporal-unit :default}] [:relative-datetime -1 :day]] [:< [:field 3723\r\n{:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}]\r\n[:relative-datetime 0 :day]] [:!= [:field 3797 {:base-type :type/UUID,\r\n:join-alias ""Facilities - FacilityId""}] [:value\r\n""d40eba2e-5f98-46d0-b03d-a6b77afd82b3"" {:base_type :type/UUID,\r\n:effective_type :type/UUID, :coercion_strategy nil, :semantic_type\r\n:type/Category, :database_type ""uuid"", :name ""portfolioId""}]]], :joins\r\n[{:alias ""Campaigns - CampaignId"", :strategy :left-join, :fields [[:field\r\n3733 {:join-alias ""Campaigns - CampaignId""}] [:field 3734 {:join-alias\r\n""Campaigns - CampaignId""}] [:field 3731 {:join-alias ""Campaigns -\r\nCampaignId""}] [:field 3730 {:join-alias ""Campaigns - CampaignId""}] [:field\r\n3736 {:join-alias ""Campaigns - CampaignId""}] [:field 3727 {:temporal-unit\r\n:default, :join-alias ""Campaigns - CampaignId""}] [:field 3738 {:join-alias\r\n""Campaigns - CampaignId""}] [:field 3740 {:join-alias ""Campaigns -\r\nCampaignId""}] [:field 3728 {:temporal-unit :default, :join-alias ""Campaigns\r\n- CampaignId""}] [:field 3739 {:temporal-unit :default, :join-alias\r\n""Campaigns - CampaignId""}] [:field 3737 {:temporal-unit :default,\r\n:join-alias ""Campaigns - CampaignId""}] [:field 3729 {:join-alias ""Campaigns\r\n- CampaignId""}] [:field 3735 {:join-alias ""Campaigns - CampaignId""}]\r\n[:field 3732 {:join-alias ""Campaigns - CampaignId""}] [:field 3829\r\n{:join-alias ""Campaigns - CampaignId""}]], :condition [:= [:field 3713\r\n{:base-type :type/UUID}] [:field 3733 {:base-type :type/UUID, :join-alias\r\n""Campaigns - CampaignId""}]], :source-table 490} {:alias ""Facilities -\r\nFacilityId"", :strategy :left-join, :fields [[:field 3790 {:join-alias\r\n""Facilities - FacilityId""}] [:field 3796 {:join-alias ""Facilities -\r\nFacilityId""}] [:field 3797 {:join-alias ""Facilities - FacilityId""}] [:field\r\n3798 {:join-alias ""Facilities - FacilityId""}] [:field 3786 {:join-alias\r\n""Facilities - FacilityId""}] [:field 3799 {:join-alias ""Facilities -\r\nFacilityId""}] [:field 3794 {:join-alias ""Facilities - FacilityId""}] [:field\r\n3784 {:join-alias ""Facilities - FacilityId""}] [:field 3788 {:join-alias\r\n""Facilities - FacilityId""}] [:field 3791 {:join-alias ""Facilities -\r\nFacilityId""}] [:field 3795 {:join-alias ""Facilities - FacilityId""}] [:field\r\n3787 {:join-alias ""Facilities - FacilityId""}] [:field 3782 {:join-alias\r\n""Facilities - FacilityId""}] [:field 3783 {:join-alias ""Facilities -\r\nFacilityId""}] [:field 5950 {:join-alias ""Facilities - FacilityId""}] [:field\r\n3792 {:temporal-unit :default, :join-alias ""Facilities - FacilityId""}]\r\n[:field 3781 {:temporal-unit :default, :join-alias ""Facilities -\r\nFacilityId""}] [:field 3789 {:temporal-unit :default, :join-alias\r\n""Facilities - FacilityId""}] [:field 3793 {:join-alias ""Facilities -\r\nFacilityId""}] [:field 3800 {:join-alias ""Facilities - FacilityId""}] [:field\r\n3801 {:join-alias ""Facilities - FacilityId""}] [:field 3866 {:temporal-unit\r\n:default, :join-alias ""Facilities - FacilityId""}] [:field 3865\r\n{:temporal-unit :default, :join-alias ""Facilities - FacilityId""}] [:field\r\n3884 {:join-alias ""Facilities - FacilityId""}]], :condition [:= [:field 3729\r\n{:base-type :type/UUID, :join-alias ""Campaigns - CampaignId""}] [:field 3790\r\n{:base-type :type/UUID, :join-alias ""Facilities - FacilityId""}]],\r\n:source-table 484}]}, :async? true, :cache-ttl 5}, :data {:rows [], :cols\r\n[]}} [15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR\r\nmetabase.async.streaming-response Caught unexpected Exception in streaming\r\nresponse body,java.lang.NullPointerException: Deflater has been closed, at\r\njava.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at\r\njava.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at\r\nmetabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),\r\nat\r\nmetabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown\r\nSource), at\r\nmetabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:58),\r\nat\r\nmetabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),\r\nat\r\nmetabase.query_processor.streaming$streaming_response_STAR_$fn__53862.invoke(streaming.clj:176),\r\nat clojure.lang.AFn.applyToHelper(AFn.java:156), at\r\nclojure.lang.AFn.applyTo(AFn.java:144), at\r\nclojure.core$apply.invokeStatic(core.clj:667), at\r\nclojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990), at\r\nclojure.core$with_bindings_STAR_.doInvoke(core.clj:1990), at\r\nclojure.lang.RestFn.applyTo(RestFn.java:142), at\r\nclojure.core$apply.invokeStatic(core.clj:671), at\r\nclojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020), at\r\nclojure.lang.RestFn.invoke(RestFn.java:421), at\r\nmetabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69),\r\nat\r\nmetabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),\r\nat\r\nmetabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),\r\nat clojure.lang.AFn.run(AFn.java:22), at\r\njava.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown\r\nSource), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),\r\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown\r\nSource), at\r\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource), at java.base/java.lang.Thread.run(Unknown Source)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR\r\nmetabase.async.streaming-response Error writing error to output stream\r\n{:via [{:type java.lang.NullPointerException, :message Deflater has been\r\nclosed, :at [java.util.zip.Deflater ensureOpen nil -1]}], :trace\r\n[[java.util.zip.Deflater ensureOpen nil -1] [java.util.zip.Deflater deflate\r\nnil -1] [java.util.zip.Deflater deflate nil -1]\r\n[java.util.zip.GZIPOutputStream finish nil -1]\r\n[java.util.zip.DeflaterOutputStream close nil -1]\r\n[metabase.async.streaming_response$delay_output_stream$fn__44110 invoke\r\nstreaming_response.clj 121]\r\n[metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a\r\nclose nil -1] [metabase.async.streaming_response$write_error_BANG_\r\ninvokeStatic streaming_response.clj 58]\r\n[metabase.async.streaming_response$write_error_BANG_ invoke\r\nstreaming_response.clj 46]\r\n[metabase.query_processor.streaming$streaming_response_STAR_$fn__53862\r\ninvoke streaming.clj 176] [clojure.lang.AFn applyToHelper AFn.java 156]\r\n[clojure.lang.AFn applyTo AFn.java 144] [clojure.core$apply invokeStatic\r\ncore.clj 667] [clojure.core$with_bindings_STAR_ invokeStatic core.clj 1990]\r\n[clojure.core$with_bindings_STAR_ doInvoke core.clj 1990]\r\n[clojure.lang.RestFn applyTo RestFn.java 142] [clojure.core$apply\r\ninvokeStatic core.clj 671] [clojure.core$bound_fn_STAR_$fn__5818 doInvoke\r\ncore.clj 2020] [clojure.lang.RestFn invoke RestFn.java 421]\r\n[metabase.async.streaming_response$do_f_STAR_ invokeStatic\r\nstreaming_response.clj 69] [metabase.async.streaming_response$do_f_STAR_\r\ninvoke streaming_response.clj 67]\r\n[metabase.async.streaming_response$do_f_async$task__44095 invoke\r\nstreaming_response.clj 88] [clojure.lang.AFn run AFn.java 22]\r\n[java.util.concurrent.Executors$RunnableAdapter call nil -1]\r\n[java.util.concurrent.FutureTask run nil -1]\r\n[java.util.concurrent.ThreadPoolExecutor runWorker nil -1]\r\n[java.util.concurrent.ThreadPoolExecutor$Worker run nil -1]\r\n[java.lang.Thread run nil -1]], :cause Deflater has been closed, :_status\r\n500},java.lang.NullPointerException: Deflater has been closed, at\r\njava.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at\r\njava.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at\r\nmetabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),\r\nat\r\nmetabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown\r\nSource), at java.base/sun.nio.cs.StreamEncoder.implClose(Unknown Source),\r\nat java.base/sun.nio.cs.StreamEncoder.close(Unknown Source), at\r\njava.base/java.io.OutputStreamWriter.close(Unknown Source), at\r\njava.base/java.io.BufferedWriter.close(Unknown Source), at\r\nmetabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:61),\r\nat\r\nmetabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),\r\nat\r\nmetabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78),\r\nat\r\nmetabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),\r\nat\r\nmetabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),\r\nat clojure.lang.AFn.run(AFn.java:22), at\r\njava.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown\r\nSource), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),\r\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown\r\nSource), at\r\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource), at java.base/java.lang.Thread.run(Unknown Source)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR\r\nmetabase.async.streaming-response bound-fn caught unexpected\r\nException,java.lang.NullPointerException: Deflater has been closed, at\r\njava.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.Deflater.deflate(Unknown Source), at\r\njava.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at\r\njava.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at\r\nmetabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),\r\nat\r\nmetabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown\r\nSource), at\r\nmetabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:58),\r\nat\r\nmetabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),\r\nat\r\nmetabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78),\r\nat\r\nmetabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),\r\nat\r\nmetabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),\r\nat clojure.lang.AFn.run(AFn.java:22), at\r\njava.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown\r\nSource), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),\r\nat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown\r\nSource), at\r\njava.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource), at java.base/java.lang.Thread.run(Unknown Source)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1915/card/1668/query 202 [ASYNC:\r\nunexpected-error] 1.5 s (22 DB calls) App DB connections: 1/15 Jetty\r\nthreads: 3/50 (16 idle, 0 queued) (156 total active threads) Queries in\r\nflight: 0 (0 queued); postgres DB 133 connections: 6/6 (5 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/session/properties 200 11.7 ms (4\r\nDB calls) App DB connections: 2/15 Jetty threads: 5/50 (17 idle, 0 queued)\r\n(139 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/user/current 200 24.6 ms (11 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 5/50 (17 idle, 0 queued)\r\n(139 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/root 200 5.5 ms (2 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (17 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database 200 8.7 ms (3 DB calls)\r\nApp DB connections: 1/15 Jetty threads: 4/50 (17 idle, 0 queued) (141 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/bookmark 200 4.1 ms (1 DB calls)\r\nApp DB connections: 2/15 Jetty threads: 7/50 (15 idle, 0 queued) (141 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/tree 200 20.7 ms (6 DB\r\ncalls) App DB connections: 3/15 Jetty threads: 6/50 (15 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/search 200 74.0 ms (5 DB calls) App\r\nDB connections: 2/15 Jetty threads: 5/50 (15 idle, 0 queued) (141 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/dashboard/397 200 164.3 ms (41 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database/133/schemas 200 7.4 ms (4\r\nDB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/464/query_metadata 200 24.9\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (16 idle, 0\r\nqueued) (141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/490/query_metadata 200 16.4\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (16 idle, 0\r\nqueued) (141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/484/query_metadata 200 30.7\r\nms (9 DB calls) App DB connections: 3/15 Jetty threads: 6/50 (16 idle, 0\r\nqueued) (141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/489/query_metadata 200 26.1\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0\r\nqueued) (141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/998/query_metadata 200 17.5\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0\r\nqueued) (141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/532 200 6.4 ms (4 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/pulse/form_input 200 834.5 µs (1 DB\r\ncalls) App DB connections: 2/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(141 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n417.0 ms; using \'magic\' TTL of 4.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n642.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n779.0 ms; using \'magic\' TTL of 8.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n571.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 84.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 63.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1912/card/1665/query 202 [ASYNC: completed]\r\n226.4 ms (21 DB calls) App DB connections: 14/15 Jetty threads: 15/50 (6\r\nidle, 0 queued) (141 total active threads) Queries in flight: 2 (0 queued);\r\npostgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1939/card/1679/query 202 [ASYNC: completed]\r\n214.5 ms (21 DB calls) App DB connections: 14/15 Jetty threads: 15/50 (6\r\nidle, 0 queued) (141 total active threads) Queries in flight: 2 (0 queued);\r\npostgres DB 133 connections: 1/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 89.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 154.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1919/card/1669/query 202 [ASYNC: completed]\r\n316.8 ms (20 DB calls) App DB connections: 15/15 Jetty threads: 17/50 (5\r\nidle, 0 queued) (141 total active threads) Queries in flight: 1 (0 queued);\r\npostgres DB 133 connections: 2/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1726/card/1494/query 202 [ASYNC: completed]\r\n407.4 ms (22 DB calls) App DB connections: 15/15 Jetty threads: 17/50 (5\r\nidle, 0 queued) (141 total active threads) Queries in flight: 0 (0 queued);\r\npostgres DB 133 connections: 3/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n585.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n660.0 ms; using \'magic\' TTL of 7.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n567.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n526.0 ms; using \'magic\' TTL of 5.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n550.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n385.0 ms; using \'magic\' TTL of 4.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n564.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n511.0 ms; using \'magic\' TTL of 5.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n608.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n613.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n456.0 ms; using \'magic\' TTL of 5.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n293.0 ms; using \'magic\' TTL of 3.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n357.0 ms; using \'magic\' TTL of 4.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 99.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n308.0 ms; using \'magic\' TTL of 3.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1940/card/1680/query 202 [ASYNC: completed]\r\n560.7 ms (20 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 13 (0\r\nqueued); postgres DB 133 connections: 1/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 114.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 137.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1934/card/1676/query 202 [ASYNC: completed]\r\n566.8 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 12 (0\r\nqueued); postgres DB 133 connections: 2/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/2114/card/1882/query 202 [ASYNC: completed]\r\n584.0 ms (20 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 11 (0\r\nqueued); postgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 86.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 90.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 76.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 87.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1933/card/1677/query 202 [ASYNC: completed]\r\n604.1 ms (18 DB calls) App DB connections: 5/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 10 (0\r\nqueued); postgres DB 133 connections: 5/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1922/card/1672/query 202 [ASYNC: completed]\r\n642.1 ms (20 DB calls) App DB connections: 5/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 8 (0 queued);\r\npostgres DB 133 connections: 4/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1923/card/1671/query 202 [ASYNC: completed]\r\n641.5 ms (20 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 9 (0 queued);\r\npostgres DB 133 connections: 8/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1917/card/1667/query 202 [ASYNC: completed]\r\n643.0 ms (20 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 7 (0 queued);\r\npostgres DB 133 connections: 6/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 77.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1921/card/1670/query 202 [ASYNC: completed]\r\n660.1 ms (22 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 6 (0 queued);\r\npostgres DB 133 connections: 11/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 127.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1727/card/1493/query 202 [ASYNC: completed]\r\n672.1 ms (20 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 5 (0 queued);\r\npostgres DB 133 connections: 3/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 132.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 123.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 122.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1935/card/1675/query 202 [ASYNC: completed]\r\n645.0 ms (18 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);\r\npostgres DB 133 connections: 9/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1936/card/1678/query 202 [ASYNC: completed]\r\n640.6 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);\r\npostgres DB 133 connections: 7/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1924/card/1673/query 202 [ASYNC: completed]\r\n695.9 ms (22 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 2 (0 queued);\r\npostgres DB 133 connections: 11/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 169.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 162.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1915/card/1668/query 202 [ASYNC: completed]\r\n742.0 ms (22 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);\r\npostgres DB 133 connections: 10/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1925/card/1674/query 202 [ASYNC: completed]\r\n747.8 ms (22 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);\r\npostgres DB 133 connections: 12/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n218.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n153.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n184.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n200.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n214.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n255.0 ms; using \'magic\' TTL of 3.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 51.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1984/card/1654/query 202 [ASYNC: completed]\r\n162.4 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 5 (0 queued);\r\npostgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 56.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 50.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1987/card/1624/query 202 [ASYNC: completed]\r\n164.0 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 4 (0 queued);\r\npostgres DB 133 connections: 3/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1988/card/1623/query 202 [ASYNC: completed]\r\n157.0 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);\r\npostgres DB 133 connections: 4/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 84.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 60.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1986/card/1618/query 202 [ASYNC: completed]\r\n199.2 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);\r\npostgres DB 133 connections: 2/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/2065/card/1850/query 202 [ASYNC: completed]\r\n173.1 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);\r\npostgres DB 133 connections: 5/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 107.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]\r\n228.0 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);\r\npostgres DB 133 connections: 1/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/timeline 200 14.0 ms (5 DB calls)\r\nApp DB connections: 2/15 Jetty threads: 5/50 (16 idle, 0 queued) (151 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/card/1891 200 19.3 ms (13 DB calls)\r\nApp DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued) (151 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/alert/question/1891 200 7.0 ms (1\r\nDB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(151 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection 200 8.1 ms (3 DB calls)\r\nApp DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0 queued) (151 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/native-query-snippet 200 16.5 ms (4\r\nDB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(151 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database 200 50.6 ms (15 DB calls)\r\nApp DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued) (151 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n150.0 ms; using \'magic\' TTL of 2.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 89.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG\r\nmetabase.server.middleware.log POST /api/card/1891/query 202 [ASYNC:\r\ncompleted] 118.7 ms (15 DB calls) App DB connections: 2/15 Jetty threads:\r\n3/50 (16 idle, 0 queued) (151 total active threads) Queries in flight: 0 (0\r\nqueued); postgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:26-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database/133 200 4.6 ms (3 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)\r\n(151 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:37-05:00 DEBUG\r\nmetabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed]\r\n108.8 ms (4 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16\r\nidle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);\r\npostgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:51-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection 200 41.5 ms (4 DB calls)\r\nApp DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued) (142 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG\r\nmetabase.server.middleware.log PUT /api/card/1891 200 129.6 ms (35 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued)\r\n(142 total active threads) Queries in flight: 0 (0 queued); postgres DB 133\r\nconnections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/alert/question/1891 200 1.8 ms (1\r\nDB calls) App DB connections: 1/15 Jetty threads: 5/50 (15 idle, 0 queued)\r\n(142 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/search 200 64.7 ms (5 DB calls) App\r\nDB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued) (142 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/pulse/form_input 200 859.3 µs (1 DB\r\ncalls) App DB connections: 2/15 Jetty threads: 4/50 (15 idle, 0 queued)\r\n(142 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]\r\n180.1 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (15\r\nidle, 0 queued) (142 total active threads) Queries in flight: 1 (0 queued);\r\npostgres DB 133 connections: 0/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]\r\n183.2 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (15\r\nidle, 0 queued) (142 total active threads) Queries in flight: 0 (0 queued);\r\npostgres DB 133 connections: 1/15 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/user/current 200 14.0 ms (10 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (8 idle, 0 queued) (130\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 INFO\r\nmetabase.public-settings.premium-features Checking with the MetaStore to\r\nsee whether token \'269a...482a\' is valid...\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/session/properties 200 66.7 ms (7\r\nDB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued)\r\n(131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/root 200 4.9 ms (2 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued) (131\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/bookmark 200 3.4 ms (1 DB calls)\r\nApp DB connections: 3/15 Jetty threads: 6/50 (7 idle, 0 queued) (131 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database 200 8.3 ms (3 DB calls)\r\nApp DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (131 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/search 200 69.3 ms (5 DB calls) App\r\nDB connections: 3/15 Jetty threads: 6/50 (7 idle, 0 queued) (131 total\r\nactive threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/tree 200 16.2 ms (6 DB\r\ncalls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (131\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/dashboard/397 200 145.6 ms (41 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued) (131\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/util/bug_report_details 200 7.8 ms\r\n(1 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/database/133/schemas 200 6.5 ms (4\r\nDB calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued)\r\n(131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/464/query_metadata 200 17.7\r\nms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/490/query_metadata 200 15.3\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/484/query_metadata 200 21.6\r\nms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/489/query_metadata 200 19.8\r\nms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/table/998/query_metadata 200 19.8\r\nms (9 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0\r\nqueued) (131 total active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/collection/532 200 6.1 ms (4 DB\r\ncalls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued) (131\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG\r\nmetabase.server.middleware.log GET /api/pulse/form_input 200 1.1 ms (1 DB\r\ncalls) App DB connections: 2/15 Jetty threads: 4/50 (7 idle, 0 queued) (131\r\ntotal active threads) Queries in flight: 0 (0 queued)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.integrations.slack Refreshing slack channels and usernames.\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n390.0 ms; using \'magic\' TTL of 4.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n534.0 ms; using \'magic\' TTL of 5.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n591.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n731.0 ms; using \'magic\' TTL of 7.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n551.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n625.0 ms; using \'magic\' TTL of 6.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 107.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.card Question\'s average execution duration is\r\n360.0 ms; using \'magic\' TTL of 4.0 s 💾\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1912/card/1665/query 202 [ASYNC: completed]\r\n306.0 ms (21 DB calls) App DB connections: 12/15 Jetty threads: 13/50 (0\r\nidle, 0 queued) (138 total active threads) Queries in flight: 6 (0 queued);\r\npostgres DB 133 connections: 0/1 (0 threads blocked)\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO\r\nmetabase.query-processor.middleware.cache Query took 412.0 ms to run;\r\nminimum for cache eligibility is 60.0 s; not eligible\r\n[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:12-05:00 DEBUG\r\nmetabase.server.middleware.log POST\r\n/api/dashboard/397/dashcard/1919/card/1669/query 202 [ASYNC: completed]\r\n724.3 ms (20 DB calls)', 'created_at': datetime.datetime(2024, 7, 25, 16, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2257035091, 'issue_id': 2428399448, 'author': 'jdavissafelease', 'body': 'https://safelease.metabaseapp.com/admin/troubleshooting/logs\r\n\r\nFollowing up here - please let me know what else you need for this', 'created_at': datetime.datetime(2024, 7, 29, 21, 24, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265288006, 'issue_id': 2428399448, 'author': 'noahmoss', 'body': '@jdavissafelease Sorry for the delay. Can you try re-syncing the database schema from the `/admin/databases` page?', 'created_at': datetime.datetime(2024, 8, 2, 12, 40, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265473028, 'issue_id': 2428399448, 'author': 'jdavissafelease', 'body': 'Noah, \r\n\r\nI re-synced the database and the problem still persists. \r\n\r\nJulia\r\n\r\n> On Aug 2, 2024, at 7:40\u202fAM, Noah Moss ***@***.***> wrote:\r\n> \r\n> \r\n> @jdavissafelease <https://github.com/jdavissafelease> Sorry for the delay. Can you try re-syncing the database schema from the /admin/databases page?\r\n> \r\n> —\r\n> Reply to this email directly, view it on GitHub <https://github.com/metabase/metabase/issues/46094#issuecomment-2265288006>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BDIHLZ64OLYI7P5VVWP6APLZPN44RAVCNFSM6AAAAABLNGCPUCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENRVGI4DQMBQGY>.\r\n> You are receiving this because you were mentioned.\r\n>', 'created_at': datetime.datetime(2024, 8, 2, 14, 4, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270403056, 'issue_id': 2428399448, 'author': 'qnkhuat', 'body': 'Looks like the sync process is not completed. Debugging [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1722607969980679)', 'created_at': datetime.datetime(2024, 8, 6, 5, 17, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284075076, 'issue_id': 2428399448, 'author': 'jdavissafelease', 'body': 'I do not have access to that thread link. Please advise. \r\n\r\n> On Aug 6, 2024, at 12:17\u202fAM, Ngoc Khuat ***@***.***> wrote:\r\n> \r\n> \r\n> Looks like the sync process is not completed. Debugging thread <https://metaboat.slack.com/archives/C0641E4PB9B/p1722607969980679>\r\n> —\r\n> Reply to this email directly, view it on GitHub <https://github.com/metabase/metabase/issues/46094#issuecomment-2270403056>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/BDIHLZ453DE5F57NGJVGUQTZQBL77AVCNFSM6AAAAABLNGCPUCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENZQGQYDGMBVGY>.\r\n> You are receiving this because you were mentioned.\r\n>', 'created_at': datetime.datetime(2024, 8, 12, 14, 1, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284305382, 'issue_id': 2428399448, 'author': 'paoliniluis', 'body': '@jdavissafelease we need to see the logs for that specific table, please force a sync and check the logs for that one', 'created_at': datetime.datetime(2024, 8, 12, 15, 36, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285635420, 'issue_id': 2428399448, 'author': 'calherries', 'body': 'Closing as I believe the root cause has been fixed in 49.22 with https://github.com/metabase/metabase/pull/46089. Feel free to reopen if not', 'created_at': datetime.datetime(2024, 8, 13, 8, 13, 45, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-24 22:46:43 UTC): it's syncing and it might be because of an error, please send us the logs

jdavissafelease (Issue Creator) on (2024-07-25 16:11:46 UTC): Metabase Admin
<https://safelease.metabaseapp.com/admin>

   - Settings <https://safelease.metabaseapp.com/admin/settings>
   - Databases <https://safelease.metabaseapp.com/admin/databases>
   - Table Metadata <https://safelease.metabaseapp.com/admin/datamodel>
   - People <https://safelease.metabaseapp.com/admin/people>
   - Permissions <https://safelease.metabaseapp.com/admin/permissions>
   - Tools <https://safelease.metabaseapp.com/admin/tools>
   - Troubleshooting
   <https://safelease.metabaseapp.com/admin/troubleshooting>

Exit admin <https://safelease.metabaseapp.com/>

   - Help <https://safelease.metabaseapp.com/admin/troubleshooting/help>
   - Tasks <https://safelease.metabaseapp.com/admin/troubleshooting/tasks>
   - Jobs <https://safelease.metabaseapp.com/admin/troubleshooting/jobs>
   - Logs <https://safelease.metabaseapp.com/admin/troubleshooting/logs>

[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1934/card/1676/query 202 [ASYNC:
unexpected-error] 1.5 s (18 DB calls) App DB connections: 1/15 Jetty
threads: 3/50 (16 idle, 0 queued) (156 total active threads) Queries in
flight: 1 (0 queued); postgres DB 133 connections: 6/6 (3 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR
metabase.query-processor.middleware.catch-exceptions Error processing
query: Broken pipe {:database_id 133, :started_at #t
""2024-07-25T14:13:34.033529Z[GMT]"", :via [{:status :failed, :class
org.eclipse.jetty.io.EofException, :error nil, :stacktrace
[""org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:116)""
""org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:422)""
""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:275)""
""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:254)""
""org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:386)""
""org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:832)""
""org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:243)""
""org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:224)""
""org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:589)""
""org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:1051)""
""org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:1123)""
""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:270)""
""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:254)""
""org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:736)""
""java.base/java.util.zip.DeflaterOutputStream.flush(Unknown Source)"" ""-->
async.streaming_response$delay_output_stream$fn__44112.invoke(streaming_response.clj:123)""
""async.streaming_response.proxy$java.io.OutputStream$ff19274a.flush(Unknown
Source)""
""query_processor.streaming.json$fn$reify__53036.finish_BANG_(json.clj:115)""
""query_processor.streaming$streaming_reducedf$fn__53812.invoke(streaming.clj:132)""
""query_processor.context$reducedf.invokeStatic(context.clj:78)""
""query_processor.context$reducedf.invoke(context.clj:73)""
""query_processor.context.default$default_reducef.invokeStatic(default.clj:40)""
""query_processor.context.default$default_reducef.invoke(default.clj:25)""
""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671$fn__72672.invoke(cache.clj:201)""
""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""
""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""
""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671.invoke(cache.clj:197)""
""query_processor.context$reducef.invokeStatic(context.clj:70)""
""query_processor.context$reducef.invoke(context.clj:63)""
""query_processor.context.default$default_runf$respond_STAR___50910.invoke(default.clj:45)""
""driver.sql_jdbc.execute$execute_reducible_query$fn__79873.invoke(execute.clj:710)""
""driver.sql_jdbc.execute$fn__79666$fn__79667.invoke(execute.clj:389)""
""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
""driver.sql_jdbc.execute$fn__79666.invokeStatic(execute.clj:383)""
""driver.sql_jdbc.execute$fn__79666.invoke(execute.clj:381)""
""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
""driver.sql_jdbc$fn__113278.invokeStatic(sql_jdbc.clj:78)""
""driver.sql_jdbc$fn__113278.invoke(sql_jdbc.clj:76)""
""query_processor.context$executef.invokeStatic(context.clj:60)""
""query_processor.context$executef.invoke(context.clj:49)""
""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
""query_processor.context.default$default_runf.invoke(default.clj:42)""
""query_processor.context$runf.invokeStatic(context.clj:46)""
""query_processor.context$runf.invoke(context.clj:40)""
""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""
""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""
""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72684.invoke(cache.clj:228)""
""query_processor.middleware.permissions$check_query_permissions$fn__67031.invoke(permissions.clj:140)""
""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72505.invoke(enterprise.clj:51)""
""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72515.invoke(enterprise.clj:64)""
""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:24)""
""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""
""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""
""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""
""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""
""driver$do_with_driver.invokeStatic(driver.clj:97)""
""driver$do_with_driver.invoke(driver.clj:92)""
""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""
""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""
""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""
""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""
""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""
""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""
""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""
""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""
""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""
""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""
""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""
""query_processor.reducible$async_qp$qp_STAR___63247$fn__63251.invoke(reducible.clj:131)""]}],
:action_id nil, :json_query {:constraints {:max-results 10000,
:max-results-bare-rows 2000}, :type :query, :middleware {:js-int-to-string?
true, :ignore-cached-results? false}, :viz-settings {}, :database 133,
:query {:source-table 489, :aggregation [[:count]], :joins [{:fields :all,
:alias ""Campaigns - CampaignId"", :condition [:= [:field 3713 {:base-type
:type/UUID}] [:field 3733 {:base-type :type/UUID, :join-alias ""Campaigns -
CampaignId""}]], :source-table 490} {:fields :all, :alias ""Facilities -
FacilityId"", :condition [:= [:field 3729 {:base-type :type/UUID,
:join-alias ""Campaigns - CampaignId""}] [:field 3790 {:base-type :type/UUID,
:join-alias ""Facilities - FacilityId""}]], :source-table 484}], :filter
[:and [:time-interval [:field 3723 {:base-type :type/DateTimeWithLocalTZ}]
-1 :day] [:!= [:field 3797 {:base-type :type/UUID, :join-alias ""Facilities
- FacilityId""}] ""d40eba2e-5f98-46d0-b03d-a6b77afd82b3""]]}, :parameters
[{:type :string/=, :id ""6f1338c"", :target [:dimension [:field 3793
{:base-type :type/Text, :join-alias ""Facilities - FacilityId""}]]} {:type
:date/relative, :id ""ab826ff0"", :target [:dimension [:field 3718
{:base-type :type/DateTimeWithLocalTZ}]]}], :async? true, :cache-ttl 5},
:native {:query ""SELECT COUNT(*) AS \""count\"" FROM \""public\"".\""messages\""
LEFT JOIN \""public\"".\""campaigns\"" AS \""Campaigns - CampaignId\"" ON
\""public\"".\""messages\"".\""campaignId\"" = \""Campaigns - CampaignId\"".\""id\""
LEFT JOIN \""public\"".\""facilities\"" AS \""Facilities - FacilityId\"" ON
\""Campaigns - CampaignId\"".\""facilityId\"" = \""Facilities -
FacilityId\"".\""id\"" WHERE (\""public\"".\""messages\"".\""createdAt\"" >=
CAST((NOW() + INTERVAL '-1 day') AS date)) AND
(\""public\"".\""messages\"".\""createdAt\"" < CAST(NOW() AS date)) AND
((\""Facilities - FacilityId\"".\""portfolioId\"" <> ?) OR (\""Facilities -
FacilityId\"".\""portfolioId\"" IS NULL))"", :params (#uuid
""d40eba2e-5f98-46d0-b03d-a6b77afd82b3"")}, :status :failed, :class
java.io.IOException, :stacktrace
[""java.base/sun.nio.ch.FileDispatcherImpl.writev0(Native Method)""
""java.base/sun.nio.ch.SocketDispatcher.writev(Unknown Source)""
""java.base/sun.nio.ch.IOUtil.write(Unknown Source)""
""java.base/sun.nio.ch.IOUtil.write(Unknown Source)""
""java.base/sun.nio.ch.SocketChannelImpl.write(Unknown Source)""
""java.base/java.nio.channels.SocketChannel.write(Unknown Source)""
""org.eclipse.jetty.io.SocketChannelEndPoint.flush(SocketChannelEndPoint.java:110)""
""org.eclipse.jetty.io.WriteFlusher.flush(WriteFlusher.java:422)""
""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:275)""
""org.eclipse.jetty.io.WriteFlusher.write(WriteFlusher.java:254)""
""org.eclipse.jetty.io.AbstractEndPoint.write(AbstractEndPoint.java:386)""
""org.eclipse.jetty.server.HttpConnection$SendCallback.process(HttpConnection.java:832)""
""org.eclipse.jetty.util.IteratingCallback.processing(IteratingCallback.java:243)""
""org.eclipse.jetty.util.IteratingCallback.iterate(IteratingCallback.java:224)""
""org.eclipse.jetty.server.HttpConnection.send(HttpConnection.java:589)""
""org.eclipse.jetty.server.HttpChannel.sendResponse(HttpChannel.java:1051)""
""org.eclipse.jetty.server.HttpChannel.write(HttpChannel.java:1123)""
""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:270)""
""org.eclipse.jetty.server.HttpOutput.channelWrite(HttpOutput.java:254)""
""org.eclipse.jetty.server.HttpOutput.flush(HttpOutput.java:736)""
""java.base/java.util.zip.DeflaterOutputStream.flush(Unknown Source)"" ""-->
async.streaming_response$delay_output_stream$fn__44112.invoke(streaming_response.clj:123)""
""async.streaming_response.proxy$java.io.OutputStream$ff19274a.flush(Unknown
Source)""
""query_processor.streaming.json$fn$reify__53036.finish_BANG_(json.clj:115)""
""query_processor.streaming$streaming_reducedf$fn__53812.invoke(streaming.clj:132)""
""query_processor.context$reducedf.invokeStatic(context.clj:78)""
""query_processor.context$reducedf.invoke(context.clj:73)""
""query_processor.context.default$default_reducef.invokeStatic(default.clj:40)""
""query_processor.context.default$default_reducef.invoke(default.clj:25)""
""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671$fn__72672.invoke(cache.clj:201)""
""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:83)""
""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
""query_processor.middleware.cache.impl$do_with_serialization.invokeStatic(impl.clj:73)""
""query_processor.middleware.cache.impl$do_with_serialization.invoke(impl.clj:54)""
""query_processor.middleware.cache$run_query_with_cache$reducef_SINGLEQUOTE___72671.invoke(cache.clj:197)""
""query_processor.context$reducef.invokeStatic(context.clj:70)""
""query_processor.context$reducef.invoke(context.clj:63)""
""query_processor.context.default$default_runf$respond_STAR___50910.invoke(default.clj:45)""
""driver.sql_jdbc.execute$execute_reducible_query$fn__79873.invoke(execute.clj:710)""
""driver.sql_jdbc.execute$fn__79666$fn__79667.invoke(execute.clj:389)""
""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:335)""
""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:318)""
""driver.sql_jdbc.execute$fn__79666.invokeStatic(execute.clj:383)""
""driver.sql_jdbc.execute$fn__79666.invoke(execute.clj:381)""
""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:693)""
""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:690)""
""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:679)""
""driver.sql_jdbc$fn__113278.invokeStatic(sql_jdbc.clj:78)""
""driver.sql_jdbc$fn__113278.invoke(sql_jdbc.clj:76)""
""query_processor.context$executef.invokeStatic(context.clj:60)""
""query_processor.context$executef.invoke(context.clj:49)""
""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
""query_processor.context.default$default_runf.invoke(default.clj:42)""
""query_processor.context$runf.invokeStatic(context.clj:46)""
""query_processor.context$runf.invoke(context.clj:40)""
""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""
""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""
""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72684.invoke(cache.clj:228)""
""query_processor.middleware.permissions$check_query_permissions$fn__67031.invoke(permissions.clj:140)""
""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72505.invoke(enterprise.clj:51)""
""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72515.invoke(enterprise.clj:64)""
""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71947.invoke(mbql_to_native.clj:24)""
""query_processor$fn__73852$combined_post_process__73857$combined_post_process_STAR___73858.invoke(query_processor.clj:262)""
""query_processor$fn__73852$combined_pre_process__73853$combined_pre_process_STAR___73854.invoke(query_processor.clj:259)""
""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67128.invoke(fetch_source_query.clj:303)""
""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595$fn__72599.invoke(resolve_database_and_driver.clj:77)""
""driver$do_with_driver.invokeStatic(driver.clj:97)""
""driver$do_with_driver.invoke(driver.clj:92)""
""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72595.invoke(resolve_database_and_driver.clj:76)""
""query_processor.middleware.store$initialize_store$fn__67755$fn__67756.invoke(store.clj:14)""
""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
""query_processor.middleware.store$initialize_store$fn__67755.invoke(store.clj:13)""
""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72592.invoke(resolve_database_and_driver.clj:60)""
""query_processor.middleware.normalize_query$normalize$fn__72897.invoke(normalize_query.clj:38)""
""query_processor.middleware.enterprise$fn__72532$handle_audit_app_internal_queries__72533$fn__72535.invoke(enterprise.clj:96)""
""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72543.invoke(enterprise.clj:103)""
""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71658.invoke(constraints.clj:104)""
""query_processor.middleware.process_userland_query$process_userland_query$fn__72828.invoke(process_userland_query.clj:156)""
""query_processor.middleware.catch_exceptions$catch_exceptions$fn__73429.invoke(catch_exceptions.clj:171)""
""query_processor.reducible$async_qp$qp_STAR___63247$thunk__63249.invoke(reducible.clj:126)""
""query_processor.reducible$async_qp$qp_STAR___63247$fn__63251.invoke(reducible.clj:131)""],
:card_id 1668, :context :dashboard, :error ""Broken pipe"", :row_count 0,
:running_time 0, :preprocessed {:constraints {:max-results 10000,
:max-results-bare-rows 2000}, :type :query, :middleware {:js-int-to-string?
true, :ignore-cached-results? false}, :user-parameters [{:type :string/=,
:id ""6f1338c"", :target [:dimension [:field 3793 {:base-type :type/Text,
:join-alias ""Facilities - FacilityId""}]]} {:type :date/relative, :id
""ab826ff0"", :target [:dimension [:field 3718 {:base-type
:type/DateTimeWithLocalTZ}]]}], :viz-settings {}, :info {:executed-by 71,
:context :dashboard, :card-id 1668, :card-name ""Number of Messages Sent
Yesterday"", :dashboard-id 397}, :database 133, :query {:source-table 489,
:aggregation [[:aggregation-options [:count] {:name ""count""}]], :filter
[:and [:>= [:field 3723 {:base-type :type/DateTimeWithLocalTZ,
:temporal-unit :default}] [:relative-datetime -1 :day]] [:< [:field 3723
{:base-type :type/DateTimeWithLocalTZ, :temporal-unit :default}]
[:relative-datetime 0 :day]] [:!= [:field 3797 {:base-type :type/UUID,
:join-alias ""Facilities - FacilityId""}] [:value
""d40eba2e-5f98-46d0-b03d-a6b77afd82b3"" {:base_type :type/UUID,
:effective_type :type/UUID, :coercion_strategy nil, :semantic_type
:type/Category, :database_type ""uuid"", :name ""portfolioId""}]]], :joins
[{:alias ""Campaigns - CampaignId"", :strategy :left-join, :fields [[:field
3733 {:join-alias ""Campaigns - CampaignId""}] [:field 3734 {:join-alias
""Campaigns - CampaignId""}] [:field 3731 {:join-alias ""Campaigns -
CampaignId""}] [:field 3730 {:join-alias ""Campaigns - CampaignId""}] [:field
3736 {:join-alias ""Campaigns - CampaignId""}] [:field 3727 {:temporal-unit
:default, :join-alias ""Campaigns - CampaignId""}] [:field 3738 {:join-alias
""Campaigns - CampaignId""}] [:field 3740 {:join-alias ""Campaigns -
CampaignId""}] [:field 3728 {:temporal-unit :default, :join-alias ""Campaigns
- CampaignId""}] [:field 3739 {:temporal-unit :default, :join-alias
""Campaigns - CampaignId""}] [:field 3737 {:temporal-unit :default,
:join-alias ""Campaigns - CampaignId""}] [:field 3729 {:join-alias ""Campaigns
- CampaignId""}] [:field 3735 {:join-alias ""Campaigns - CampaignId""}]
[:field 3732 {:join-alias ""Campaigns - CampaignId""}] [:field 3829
{:join-alias ""Campaigns - CampaignId""}]], :condition [:= [:field 3713
{:base-type :type/UUID}] [:field 3733 {:base-type :type/UUID, :join-alias
""Campaigns - CampaignId""}]], :source-table 490} {:alias ""Facilities -
FacilityId"", :strategy :left-join, :fields [[:field 3790 {:join-alias
""Facilities - FacilityId""}] [:field 3796 {:join-alias ""Facilities -
FacilityId""}] [:field 3797 {:join-alias ""Facilities - FacilityId""}] [:field
3798 {:join-alias ""Facilities - FacilityId""}] [:field 3786 {:join-alias
""Facilities - FacilityId""}] [:field 3799 {:join-alias ""Facilities -
FacilityId""}] [:field 3794 {:join-alias ""Facilities - FacilityId""}] [:field
3784 {:join-alias ""Facilities - FacilityId""}] [:field 3788 {:join-alias
""Facilities - FacilityId""}] [:field 3791 {:join-alias ""Facilities -
FacilityId""}] [:field 3795 {:join-alias ""Facilities - FacilityId""}] [:field
3787 {:join-alias ""Facilities - FacilityId""}] [:field 3782 {:join-alias
""Facilities - FacilityId""}] [:field 3783 {:join-alias ""Facilities -
FacilityId""}] [:field 5950 {:join-alias ""Facilities - FacilityId""}] [:field
3792 {:temporal-unit :default, :join-alias ""Facilities - FacilityId""}]
[:field 3781 {:temporal-unit :default, :join-alias ""Facilities -
FacilityId""}] [:field 3789 {:temporal-unit :default, :join-alias
""Facilities - FacilityId""}] [:field 3793 {:join-alias ""Facilities -
FacilityId""}] [:field 3800 {:join-alias ""Facilities - FacilityId""}] [:field
3801 {:join-alias ""Facilities - FacilityId""}] [:field 3866 {:temporal-unit
:default, :join-alias ""Facilities - FacilityId""}] [:field 3865
{:temporal-unit :default, :join-alias ""Facilities - FacilityId""}] [:field
3884 {:join-alias ""Facilities - FacilityId""}]], :condition [:= [:field 3729
{:base-type :type/UUID, :join-alias ""Campaigns - CampaignId""}] [:field 3790
{:base-type :type/UUID, :join-alias ""Facilities - FacilityId""}]],
:source-table 484}]}, :async? true, :cache-ttl 5}, :data {:rows [], :cols
[]}} [15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR
metabase.async.streaming-response Caught unexpected Exception in streaming
response body,java.lang.NullPointerException: Deflater has been closed, at
java.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at
java.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at
metabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),
at
metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown
Source), at
metabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:58),
at
metabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),
at
metabase.query_processor.streaming$streaming_response_STAR_$fn__53862.invoke(streaming.clj:176),
at clojure.lang.AFn.applyToHelper(AFn.java:156), at
clojure.lang.AFn.applyTo(AFn.java:144), at
clojure.core$apply.invokeStatic(core.clj:667), at
clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990), at
clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990), at
clojure.lang.RestFn.applyTo(RestFn.java:142), at
clojure.core$apply.invokeStatic(core.clj:671), at
clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020), at
clojure.lang.RestFn.invoke(RestFn.java:421), at
metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69),
at
metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),
at
metabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),
at clojure.lang.AFn.run(AFn.java:22), at
java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown
Source), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown
Source), at
java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown
Source), at java.base/java.lang.Thread.run(Unknown Source)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR
metabase.async.streaming-response Error writing error to output stream
{:via [{:type java.lang.NullPointerException, :message Deflater has been
closed, :at [java.util.zip.Deflater ensureOpen nil -1]}], :trace
[[java.util.zip.Deflater ensureOpen nil -1] [java.util.zip.Deflater deflate
nil -1] [java.util.zip.Deflater deflate nil -1]
[java.util.zip.GZIPOutputStream finish nil -1]
[java.util.zip.DeflaterOutputStream close nil -1]
[metabase.async.streaming_response$delay_output_stream$fn__44110 invoke
streaming_response.clj 121]
[metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a
close nil -1] [metabase.async.streaming_response$write_error_BANG_
invokeStatic streaming_response.clj 58]
[metabase.async.streaming_response$write_error_BANG_ invoke
streaming_response.clj 46]
[metabase.query_processor.streaming$streaming_response_STAR_$fn__53862
invoke streaming.clj 176] [clojure.lang.AFn applyToHelper AFn.java 156]
[clojure.lang.AFn applyTo AFn.java 144] [clojure.core$apply invokeStatic
core.clj 667] [clojure.core$with_bindings_STAR_ invokeStatic core.clj 1990]
[clojure.core$with_bindings_STAR_ doInvoke core.clj 1990]
[clojure.lang.RestFn applyTo RestFn.java 142] [clojure.core$apply
invokeStatic core.clj 671] [clojure.core$bound_fn_STAR_$fn__5818 doInvoke
core.clj 2020] [clojure.lang.RestFn invoke RestFn.java 421]
[metabase.async.streaming_response$do_f_STAR_ invokeStatic
streaming_response.clj 69] [metabase.async.streaming_response$do_f_STAR_
invoke streaming_response.clj 67]
[metabase.async.streaming_response$do_f_async$task__44095 invoke
streaming_response.clj 88] [clojure.lang.AFn run AFn.java 22]
[java.util.concurrent.Executors$RunnableAdapter call nil -1]
[java.util.concurrent.FutureTask run nil -1]
[java.util.concurrent.ThreadPoolExecutor runWorker nil -1]
[java.util.concurrent.ThreadPoolExecutor$Worker run nil -1]
[java.lang.Thread run nil -1]], :cause Deflater has been closed, :_status
500},java.lang.NullPointerException: Deflater has been closed, at
java.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at
java.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at
metabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),
at
metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown
Source), at java.base/sun.nio.cs.StreamEncoder.implClose(Unknown Source),
at java.base/sun.nio.cs.StreamEncoder.close(Unknown Source), at
java.base/java.io.OutputStreamWriter.close(Unknown Source), at
java.base/java.io.BufferedWriter.close(Unknown Source), at
metabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:61),
at
metabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),
at
metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78),
at
metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),
at
metabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),
at clojure.lang.AFn.run(AFn.java:22), at
java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown
Source), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown
Source), at
java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown
Source), at java.base/java.lang.Thread.run(Unknown Source)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 ERROR
metabase.async.streaming-response bound-fn caught unexpected
Exception,java.lang.NullPointerException: Deflater has been closed, at
java.base/java.util.zip.Deflater.ensureOpen(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.Deflater.deflate(Unknown Source), at
java.base/java.util.zip.GZIPOutputStream.finish(Unknown Source), at
java.base/java.util.zip.DeflaterOutputStream.close(Unknown Source), at
metabase.async.streaming_response$delay_output_stream$fn__44110.invoke(streaming_response.clj:121),
at
metabase.async.streaming_response.proxy$java.io.OutputStream$ff19274a.close(Unknown
Source), at
metabase.async.streaming_response$write_error_BANG_.invokeStatic(streaming_response.clj:58),
at
metabase.async.streaming_response$write_error_BANG_.invoke(streaming_response.clj:46),
at
metabase.async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:78),
at
metabase.async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67),
at
metabase.async.streaming_response$do_f_async$task__44095.invoke(streaming_response.clj:88),
at clojure.lang.AFn.run(AFn.java:22), at
java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown
Source), at java.base/java.util.concurrent.FutureTask.run(Unknown Source),
at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown
Source), at
java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown
Source), at java.base/java.lang.Thread.run(Unknown Source)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:13:35-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1915/card/1668/query 202 [ASYNC:
unexpected-error] 1.5 s (22 DB calls) App DB connections: 1/15 Jetty
threads: 3/50 (16 idle, 0 queued) (156 total active threads) Queries in
flight: 0 (0 queued); postgres DB 133 connections: 6/6 (5 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/session/properties 200 11.7 ms (4
DB calls) App DB connections: 2/15 Jetty threads: 5/50 (17 idle, 0 queued)
(139 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/user/current 200 24.6 ms (11 DB
calls) App DB connections: 1/15 Jetty threads: 5/50 (17 idle, 0 queued)
(139 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/root 200 5.5 ms (2 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (17 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/database 200 8.7 ms (3 DB calls)
App DB connections: 1/15 Jetty threads: 4/50 (17 idle, 0 queued) (141 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/bookmark 200 4.1 ms (1 DB calls)
App DB connections: 2/15 Jetty threads: 7/50 (15 idle, 0 queued) (141 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/tree 200 20.7 ms (6 DB
calls) App DB connections: 3/15 Jetty threads: 6/50 (15 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/search 200 74.0 ms (5 DB calls) App
DB connections: 2/15 Jetty threads: 5/50 (15 idle, 0 queued) (141 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/dashboard/397 200 164.3 ms (41 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/database/133/schemas 200 7.4 ms (4
DB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/table/464/query_metadata 200 24.9
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (16 idle, 0
queued) (141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/table/490/query_metadata 200 16.4
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (16 idle, 0
queued) (141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/table/484/query_metadata 200 30.7
ms (9 DB calls) App DB connections: 3/15 Jetty threads: 6/50 (16 idle, 0
queued) (141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/table/489/query_metadata 200 26.1
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0
queued) (141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/table/998/query_metadata 200 17.5
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0
queued) (141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/532 200 6.4 ms (4 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:44-05:00 DEBUG
metabase.server.middleware.log GET /api/pulse/form_input 200 834.5 µs (1 DB
calls) App DB connections: 2/15 Jetty threads: 4/50 (16 idle, 0 queued)
(141 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
417.0 ms; using 'magic' TTL of 4.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
642.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
779.0 ms; using 'magic' TTL of 8.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
571.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 84.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 63.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1912/card/1665/query 202 [ASYNC: completed]
226.4 ms (21 DB calls) App DB connections: 14/15 Jetty threads: 15/50 (6
idle, 0 queued) (141 total active threads) Queries in flight: 2 (0 queued);
postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1939/card/1679/query 202 [ASYNC: completed]
214.5 ms (21 DB calls) App DB connections: 14/15 Jetty threads: 15/50 (6
idle, 0 queued) (141 total active threads) Queries in flight: 2 (0 queued);
postgres DB 133 connections: 1/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 89.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 154.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1919/card/1669/query 202 [ASYNC: completed]
316.8 ms (20 DB calls) App DB connections: 15/15 Jetty threads: 17/50 (5
idle, 0 queued) (141 total active threads) Queries in flight: 1 (0 queued);
postgres DB 133 connections: 2/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1726/card/1494/query 202 [ASYNC: completed]
407.4 ms (22 DB calls) App DB connections: 15/15 Jetty threads: 17/50 (5
idle, 0 queued) (141 total active threads) Queries in flight: 0 (0 queued);
postgres DB 133 connections: 3/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
585.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
660.0 ms; using 'magic' TTL of 7.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
567.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
526.0 ms; using 'magic' TTL of 5.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
550.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
385.0 ms; using 'magic' TTL of 4.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
564.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
511.0 ms; using 'magic' TTL of 5.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
608.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
613.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
456.0 ms; using 'magic' TTL of 5.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
293.0 ms; using 'magic' TTL of 3.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
357.0 ms; using 'magic' TTL of 4.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 99.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.card Question's average execution duration is
308.0 ms; using 'magic' TTL of 3.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1940/card/1680/query 202 [ASYNC: completed]
560.7 ms (20 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 13 (0
queued); postgres DB 133 connections: 1/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 114.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 137.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1934/card/1676/query 202 [ASYNC: completed]
566.8 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 12 (0
queued); postgres DB 133 connections: 2/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/2114/card/1882/query 202 [ASYNC: completed]
584.0 ms (20 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 11 (0
queued); postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 86.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 90.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 76.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 87.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1933/card/1677/query 202 [ASYNC: completed]
604.1 ms (18 DB calls) App DB connections: 5/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 10 (0
queued); postgres DB 133 connections: 5/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1922/card/1672/query 202 [ASYNC: completed]
642.1 ms (20 DB calls) App DB connections: 5/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 8 (0 queued);
postgres DB 133 connections: 4/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1923/card/1671/query 202 [ASYNC: completed]
641.5 ms (20 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 9 (0 queued);
postgres DB 133 connections: 8/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1917/card/1667/query 202 [ASYNC: completed]
643.0 ms (20 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 7 (0 queued);
postgres DB 133 connections: 6/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 77.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1921/card/1670/query 202 [ASYNC: completed]
660.1 ms (22 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 6 (0 queued);
postgres DB 133 connections: 11/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 127.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1727/card/1493/query 202 [ASYNC: completed]
672.1 ms (20 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 5 (0 queued);
postgres DB 133 connections: 3/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 132.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 123.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 122.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1935/card/1675/query 202 [ASYNC: completed]
645.0 ms (18 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);
postgres DB 133 connections: 9/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1936/card/1678/query 202 [ASYNC: completed]
640.6 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);
postgres DB 133 connections: 7/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1924/card/1673/query 202 [ASYNC: completed]
695.9 ms (22 DB calls) App DB connections: 4/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 2 (0 queued);
postgres DB 133 connections: 11/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 169.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 INFO
metabase.query-processor.middleware.cache Query took 162.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1915/card/1668/query 202 [ASYNC: completed]
742.0 ms (22 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);
postgres DB 133 connections: 10/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:14:45-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1925/card/1674/query 202 [ASYNC: completed]
747.8 ms (22 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);
postgres DB 133 connections: 12/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
218.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
153.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
184.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
200.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
214.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.card Question's average execution duration is
255.0 ms; using 'magic' TTL of 3.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 51.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1984/card/1654/query 202 [ASYNC: completed]
162.4 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 5 (0 queued);
postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 56.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 50.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1987/card/1624/query 202 [ASYNC: completed]
164.0 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 4 (0 queued);
postgres DB 133 connections: 3/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1988/card/1623/query 202 [ASYNC: completed]
157.0 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 3 (0 queued);
postgres DB 133 connections: 4/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 84.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 60.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1986/card/1618/query 202 [ASYNC: completed]
199.2 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);
postgres DB 133 connections: 2/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/2065/card/1850/query 202 [ASYNC: completed]
173.1 ms (18 DB calls) App DB connections: 3/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 1 (0 queued);
postgres DB 133 connections: 5/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 INFO
metabase.query-processor.middleware.cache Query took 107.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:10-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]
228.0 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);
postgres DB 133 connections: 1/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/timeline 200 14.0 ms (5 DB calls)
App DB connections: 2/15 Jetty threads: 5/50 (16 idle, 0 queued) (151 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/card/1891 200 19.3 ms (13 DB calls)
App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued) (151 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/alert/question/1891 200 7.0 ms (1
DB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)
(151 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/collection 200 8.1 ms (3 DB calls)
App DB connections: 1/15 Jetty threads: 5/50 (16 idle, 0 queued) (151 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/native-query-snippet 200 16.5 ms (4
DB calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)
(151 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log GET /api/database 200 50.6 ms (15 DB calls)
App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued) (151 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 INFO
metabase.query-processor.card Question's average execution duration is
150.0 ms; using 'magic' TTL of 2.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 INFO
metabase.query-processor.middleware.cache Query took 89.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:25-05:00 DEBUG
metabase.server.middleware.log POST /api/card/1891/query 202 [ASYNC:
completed] 118.7 ms (15 DB calls) App DB connections: 2/15 Jetty threads:
3/50 (16 idle, 0 queued) (151 total active threads) Queries in flight: 0 (0
queued); postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:26-05:00 DEBUG
metabase.server.middleware.log GET /api/database/133 200 4.6 ms (3 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (16 idle, 0 queued)
(151 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:37-05:00 DEBUG
metabase.server.middleware.log POST /api/dataset 202 [ASYNC: completed]
108.8 ms (4 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (16
idle, 0 queued) (151 total active threads) Queries in flight: 0 (0 queued);
postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:51-05:00 DEBUG
metabase.server.middleware.log GET /api/collection 200 41.5 ms (4 DB calls)
App DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued) (142 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG
metabase.server.middleware.log PUT /api/card/1891 200 129.6 ms (35 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued)
(142 total active threads) Queries in flight: 0 (0 queued); postgres DB 133
connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG
metabase.server.middleware.log GET /api/alert/question/1891 200 1.8 ms (1
DB calls) App DB connections: 1/15 Jetty threads: 5/50 (15 idle, 0 queued)
(142 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:53-05:00 DEBUG
metabase.server.middleware.log GET /api/search 200 64.7 ms (5 DB calls) App
DB connections: 1/15 Jetty threads: 4/50 (15 idle, 0 queued) (142 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG
metabase.server.middleware.log GET /api/pulse/form_input 200 859.3 µs (1 DB
calls) App DB connections: 2/15 Jetty threads: 4/50 (15 idle, 0 queued)
(142 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]
180.1 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (15
idle, 0 queued) (142 total active threads) Queries in flight: 1 (0 queued);
postgres DB 133 connections: 0/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:15:58-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/2119/card/1891/query 202 [ASYNC: completed]
183.2 ms (18 DB calls) App DB connections: 2/15 Jetty threads: 3/50 (15
idle, 0 queued) (142 total active threads) Queries in flight: 0 (0 queued);
postgres DB 133 connections: 1/15 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG
metabase.server.middleware.log GET /api/user/current 200 14.0 ms (10 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (8 idle, 0 queued) (130
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 INFO
metabase.public-settings.premium-features Checking with the MetaStore to
see whether token '269a...482a' is valid...
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG
metabase.server.middleware.log GET /api/session/properties 200 66.7 ms (7
DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued)
(131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:09-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/root 200 4.9 ms (2 DB
calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0 queued) (131
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/bookmark 200 3.4 ms (1 DB calls)
App DB connections: 3/15 Jetty threads: 6/50 (7 idle, 0 queued) (131 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/database 200 8.3 ms (3 DB calls)
App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (131 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/search 200 69.3 ms (5 DB calls) App
DB connections: 3/15 Jetty threads: 6/50 (7 idle, 0 queued) (131 total
active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/tree 200 16.2 ms (6 DB
calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0 queued) (131
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/dashboard/397 200 145.6 ms (41 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued) (131
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/util/bug_report_details 200 7.8 ms
(1 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/database/133/schemas 200 6.5 ms (4
DB calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued)
(131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/table/464/query_metadata 200 17.7
ms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/table/490/query_metadata 200 15.3
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 5/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/table/484/query_metadata 200 21.6
ms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/table/489/query_metadata 200 19.8
ms (9 DB calls) App DB connections: 2/15 Jetty threads: 5/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:10-05:00 DEBUG
metabase.server.middleware.log GET /api/table/998/query_metadata 200 19.8
ms (9 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0
queued) (131 total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG
metabase.server.middleware.log GET /api/collection/532 200 6.1 ms (4 DB
calls) App DB connections: 1/15 Jetty threads: 4/50 (7 idle, 0 queued) (131
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG
metabase.server.middleware.log GET /api/pulse/form_input 200 1.1 ms (1 DB
calls) App DB connections: 2/15 Jetty threads: 4/50 (7 idle, 0 queued) (131
total active threads) Queries in flight: 0 (0 queued)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.integrations.slack Refreshing slack channels and usernames.
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
390.0 ms; using 'magic' TTL of 4.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
534.0 ms; using 'magic' TTL of 5.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
591.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
731.0 ms; using 'magic' TTL of 7.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
551.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
625.0 ms; using 'magic' TTL of 6.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.middleware.cache Query took 107.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.card Question's average execution duration is
360.0 ms; using 'magic' TTL of 4.0 s 💾
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1912/card/1665/query 202 [ASYNC: completed]
306.0 ms (21 DB calls) App DB connections: 12/15 Jetty threads: 13/50 (0
idle, 0 queued) (138 total active threads) Queries in flight: 6 (0 queued);
postgres DB 133 connections: 0/1 (0 threads blocked)
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:11-05:00 INFO
metabase.query-processor.middleware.cache Query took 412.0 ms to run;
minimum for cache eligibility is 60.0 s; not eligible
[15f64f5f-bb2e-4f0d-8fe9-91787adc93f7] 2024-07-25T09:24:12-05:00 DEBUG
metabase.server.middleware.log POST
/api/dashboard/397/dashcard/1919/card/1669/query 202 [ASYNC: completed]
724.3 ms (20 DB calls)

jdavissafelease (Issue Creator) on (2024-07-29 21:24:18 UTC): https://safelease.metabaseapp.com/admin/troubleshooting/logs

Following up here - please let me know what else you need for this

noahmoss on (2024-08-02 12:40:18 UTC): @jdavissafelease Sorry for the delay. Can you try re-syncing the database schema from the `/admin/databases` page?

jdavissafelease (Issue Creator) on (2024-08-02 14:04:17 UTC): Noah, 

I re-synced the database and the problem still persists. 

Julia

qnkhuat on (2024-08-06 05:17:31 UTC): Looks like the sync process is not completed. Debugging [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1722607969980679)

jdavissafelease (Issue Creator) on (2024-08-12 14:01:59 UTC): I do not have access to that thread link. Please advise.

paoliniluis on (2024-08-12 15:36:26 UTC): @jdavissafelease we need to see the logs for that specific table, please force a sync and check the logs for that one

calherries (Assginee) on (2024-08-13 08:13:45 UTC): Closing as I believe the root cause has been fixed in 49.22 with https://github.com/metabase/metabase/pull/46089. Feel free to reopen if not

"
2428396535,issue,open,,Increase the character limit in tooltips,"**Is your feature request related to a problem? Please describe.**
We're cropping the tooltip text to ~300 chars and there's a lot of info in there that some customers want to show. If you add more than that we add ""..."". We could increase that to a few chars more

**Describe the solution you'd like**
Increase the limit of the tooltip

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-24 20:17:03+00:00,[],2025-02-04 20:31:49+00:00,,https://github.com/metabase/metabase/issues/46092,"[('Visualization/', ''), ('Type:New Feature', ''), ('Visualization/Tooltips', '')]",[],
2428385849,issue,open,,Collapsible (and expandable) text cards in dashboards,"**Is your feature request related to a problem? Please describe.**
A customer mentioned that they have long text cards and they might want to expand and collapse and expand text cards which shouldn't show by default, this is an example
![image](https://github.com/user-attachments/assets/62364440-f1ef-440f-b975-5ce4758c972e)

**Describe the solution you'd like**
A possibility for the text card to collapse (by default) and expand

**Describe alternatives you've considered**
none

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-24 20:09:47+00:00,[],2025-02-04 20:30:14+00:00,,https://github.com/metabase/metabase/issues/46090,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2428339434,issue,closed,completed,Database Connection form input icons and tooltips are broken,"Why do some fields in database connection dialogues have the ""i"" icon and some have circles?  What does a circle signify?
Also, the fields that have circles have the ""i"" icon next to field title, but the tooltip seems to be the same when hovering over the circle or the ""i""?

[Slack Message](https://metaboat.slack.com/archives/C01LQQ2UW03/p1721848987640029?thread_ts=1721848987.640029&cid=C01LQQ2UW03)

Broken tooltips
![Screen Shot 2024-07-24 at 1 40 07 PM](https://github.com/user-attachments/assets/661211f9-9ee6-4cbd-9509-e13c0be9f0d9)

Broken Icons
![Screen Shot 2024-07-24 at 1 40 05 PM](https://github.com/user-attachments/assets/5f554abe-663f-4b24-a987-85a782730576)

871955e8ebc8a36eb245a8f3e030dd1a942c94bc
",iethree,2024-07-24 19:39:58+00:00,['iethree'],2024-08-02 18:31:24+00:00,2024-08-01 18:22:18+00:00,https://github.com/metabase/metabase/issues/46088,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2258885906, 'issue_id': 2428339434, 'author': 'iethree', 'body': 'introduced as part of the icon rework\r\n\r\n\r\n![Screen Shot 2024-07-30 at 11 46 28 AM](https://github.com/user-attachments/assets/79f8269c-e75d-4df0-bb39-70033c26b24e)', 'created_at': datetime.datetime(2024, 7, 30, 17, 46, 37, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-07-30 17:46:37 UTC): introduced as part of the icon rework


![Screen Shot 2024-07-30 at 11 46 28 AM](https://github.com/user-attachments/assets/79f8269c-e75d-4df0-bb39-70033c26b24e)

"
2428338821,issue,open,,Subscriptions can include unwired filters which is confusing,"### Context
If a dashboard filter is created but isn't wired to any card, it will not show up when viewing the dashboard. But then, the non-wired invisible filters does appear in other places like setting up subscriptions, which causes another layer of confusion - ""why is there a random filter in my subscription that I don't see on the dashboard?"" (especially confusing if a filter has a default value because then you just have this random value in the subscription setup screen? what does it do? Is it important? What does it control? 
[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1721839965541749)

### Expected Behavior
Filters that aren't wired to anything shouldn't appear in the subscription pane or subscriptions.

",cdeweyx,2024-07-24 19:39:43+00:00,[],2025-02-04 20:29:32+00:00,,https://github.com/metabase/metabase/issues/46087,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2428330702,issue,open,,"""Info"" icon is showing in dashboard edit mode when it shouldn't","### Context
""Info"" icon should only show when consuming the dashboard, not in edit mode as it gets in the way of the hover toolbar. Can repro on any dashcard of a question with a description. 
[Slack context](https://metaboat.slack.com/archives/C01LQQ2UW03/p1721823611757049).

![Image](https://github.com/user-attachments/assets/b52c37b1-9ffb-4ee4-a1ae-ea30bdcd3503)

",cdeweyx,2024-07-24 19:34:32+00:00,[],2024-07-24 19:37:10+00:00,,https://github.com/metabase/metabase/issues/46085,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2428322705,issue,open,,Column order on Viz Settings is not Respected on Serialization Import (if DB doesn't Exist in Target Instance),"### Describe the bug

When you export questions with custom column order on a table viz, then import them into a target instance - the column order does not display correctly on the target instance. This happens when the database connection isn't already set up on the target instance. If the database is already there this is non issue.

### To Reproduce

1. Set up a new Metabase instance 
2. Add a connection to a DB that is not the default sample DB
3. On this Db create a Question and change the column order before saving it
4. Export it
5. Import into a clean instance 
6. Add the DB connection details to the database
7. View the imported question
8. Note the column order is not displayed correctly


**Helpful Links:**

- [Loom recording](https://www.loom.com/share/1f2cfc66cfb1405e85dd93414e4b1922) 
- [API Response for Card from Source](https://github.com/user-attachments/files/16366688/source_14921.json)
- [API Response for Imported Card](https://github.com/user-attachments/files/16366689/target_24921.json)

**Note:** It looks like the ""key"" values in the column viz settings aren't generated correctly on import in this case. They still refer to the IDs from the source instance. Updating these manually corrects the card.


### Expected behavior

The column order should display correctly

### Logs

_No response_

### Information about your Metabase installation

```JSON
Tested in version 49.21
```


### Severity

Annoying

### Additional context

_No response_",ixipixi,2024-07-24 19:29:26+00:00,[],2025-02-04 20:26:37+00:00,,https://github.com/metabase/metabase/issues/46084,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Operation/Serialization', 'Enterprise contents migration'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2250275043, 'issue_id': 2428322705, 'author': 'luizarakaki', 'body': '@ixipixi What are your `export` params? There is a yaml for the database, right?', 'created_at': datetime.datetime(2024, 7, 25, 13, 5, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250534018, 'issue_id': 2428322705, 'author': 'ixipixi', 'body': ""@luizarakaki no export params. I don't have the export file or the Metabase environment anymore - but I still have the export endpoint and the env set up in Postman. I can spin up an instance real quick and run an export to confirm the DB YAML makes it to the export."", 'created_at': datetime.datetime(2024, 7, 25, 14, 48, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2250972756, 'issue_id': 2428322705, 'author': 'luizarakaki', 'body': ""If you didn't add any params, then there was a db yaml. This is a very weird bug...\r\nI was thinking this could happen because the db yaml doesn't contain the secrets (you'd need to add a param to add secrets), but I think it isn't related because the data model is loaded too"", 'created_at': datetime.datetime(2024, 7, 25, 16, 52, 5, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-07-25 13:05:28 UTC): @ixipixi What are your `export` params? There is a yaml for the database, right?

ixipixi (Issue Creator) on (2024-07-25 14:48:12 UTC): @luizarakaki no export params. I don't have the export file or the Metabase environment anymore - but I still have the export endpoint and the env set up in Postman. I can spin up an instance real quick and run an export to confirm the DB YAML makes it to the export.

luizarakaki on (2024-07-25 16:52:05 UTC): If you didn't add any params, then there was a db yaml. This is a very weird bug...
I was thinking this could happen because the db yaml doesn't contain the secrets (you'd need to add a param to add secrets), but I think it isn't related because the data model is loaded too

"
2428182212,issue,closed,completed,Horizontal Right Alignment in Text Card,"### Describe the bug

Horizontal right alignment does not work in text cards. It aligns text to the left instead. 

### To Reproduce

1. Go to create a new dashboard
2. Click on add a heading or text
3. Select text
4. Type in text
5. Click visualization options
6. Click 'Right' under horizontal alignment
8. See error


### Expected behavior

Text aligns to the right when horizontal right alignment is selected in the text card

### Logs

_No response_

### Information about your Metabase installation

```JSON
Browser: Google Chrome
Metabase version: 50.13
Database: Redshift
```


### Severity

annoying

### Additional context

_No response_",cbinczyk,2024-07-24 18:06:24+00:00,[],2024-09-17 19:20:47+00:00,2024-09-17 18:31:03+00:00,https://github.com/metabase/metabase/issues/46078,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2317756274, 'issue_id': 2428182212, 'author': 'amardatar', 'body': ""Just ran into this as well - had a look through and I think it might just be because of an accidental change from align-start to align-end [here](https://github.com/metabase/metabase/pull/40457/files#diff-a2ba33a5dd0199912039c945da46e149555b84243e5653ee32d017f04643d684R23). I can put in a PR for this, but given it's minor and might be quicker for someone from the team to fix than for me to get an approval, just thought I'd leave a comment here first."", 'created_at': datetime.datetime(2024, 8, 29, 14, 1, 41, tzinfo=datetime.timezone.utc)}]","amardatar on (2024-08-29 14:01:41 UTC): Just ran into this as well - had a look through and I think it might just be because of an accidental change from align-start to align-end [here](https://github.com/metabase/metabase/pull/40457/files#diff-a2ba33a5dd0199912039c945da46e149555b84243e5653ee32d017f04643d684R23). I can put in a PR for this, but given it's minor and might be quicker for someone from the team to fix than for me to get an approval, just thought I'd leave a comment here first.

"
2428018862,issue,closed,completed,"Intermittent (but frequent) ""There was a problem displaying this chart.""","**Describe the bug**
I am intermittently getting the message ""There was a problem displaying this chart "" across charts randomly. Its happens randomly on different charts. If I refresh, they might work, they might not. It might happen to a different chart. Who knows, it's completely random!

**Logs**
[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 DEBUG metabase.server.middleware.log POST /api/dashboard/1486/dashcard/4762/card/5228/query 202 [ASYNC: completed] 4.2 s (25 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (6 idle, 0 queued) (120 total active threads) Queries in flight: 5 (0 queued); redshift DB 3 connections: 3/8 (0 threads blocked) {:metabase-user-id 1}
[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 WARN metabase.server.middleware.log OST /api/dashboard/1486/dashcard/4760/card/5226/query 404 145.8 µs (0 DB calls) {:metabase-user-id 1} 
#metabase.util.i18n.UserLocalizedString{:format-string ""API endpoint does not exist."", :args [], :pluralization-opts {}}

[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 DEBUG metabase.server.middleware.log POST /api/dashboard/1486/dashcard/4761/card/5227/query 202 [ASYNC: completed] 2.9 s (25 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (6 idle, 0 queued) (120 total active threads) Queries in flight: 3 (0 queued); redshift DB 3 connections: 5/8 (0 threads blocked) {:metabase-user-id 1}
[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 DEBUG metabase.server.middleware.log POST /api/dashboard/1486/dashcard/4764/card/5230/query 202 [ASYNC: completed] 4.2 s (24 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (6 idle, 0 queued) (120 total active threads) Queries in flight: 4 (0 queued); redshift DB 3 connections: 1/8 (0 threads blocked) {:metabase-user-id 1}
[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 WARN metabase.server.middleware.log OST /api/dashboard/pivot/1486/dashcard/4274/card/4966/query 404 123.1 µs (0 DB calls) {:metabase-user-id 1} 
#metabase.util.i18n.UserLocalizedString{:format-string ""API endpoint does not exist."", :args [], :pluralization-opts {}}

[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 DEBUG metabase.server.middleware.log POST /api/dashboard/1486/dashcard/4763/card/5229/query 202 [ASYNC: completed] 4.2 s (25 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (6 idle, 0 queued) (120 total active threads) Queries in flight: 2 (0 queued); redshift DB 3 connections: 0/8 (0 threads blocked) {:metabase-user-id 1}
[f61dbcf7-3732-44cf-a710-0176a8d2d8a2] 2024-07-24T18:26:10+02:00 WARN metabase.server.middleware.log OST /api/dashboard/1486/dashcard/4768/card/5225/query 404 118.9 µs (0 DB calls) {:metabase-user-id 1} 
#metabase.util.i18n.UserLocalizedString{:format-string ""API endpoint does not exist."", :args [], :pluralization-opts {}}

**Severity**
HIGH


**Metabase Diagnostic Info**

{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v0.50.13"",
      ""hash"": ""2086968""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}",hss-iullah,2024-07-24 16:30:36+00:00,[],2024-11-05 17:32:33+00:00,2024-11-05 09:50:17+00:00,https://github.com/metabase/metabase/issues/46071,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Redshift', None), ('Difficulty:Hard', ''), ('.Backend', ''), ('.Team/Querying', ''), ('.LongTerm', 'Issues we will fix in the long term, not a near term priority')]","[{'comment_id': 2248467974, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""seems like it's not the backend, can you check if there's something on the browser console when this happens?"", 'created_at': datetime.datetime(2024, 7, 24, 16, 42, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248630565, 'issue_id': 2428018862, 'author': 'hss-iullah', 'body': ""It's weird cos it's intermittent. If I refresh the page again, the chart might work and then might not on the next reload or when applying a filter. It's totally sporadic.\r\n\r\nBut this is what appears in the logs for every chart which fails to load:\r\n![image](https://github.com/user-attachments/assets/52b08446-759b-4562-8f81-2d5b8a65f239)\r\n\r\nFor each chart that fails to load I get this in the browser:\r\n![image](https://github.com/user-attachments/assets/12711f25-5526-4f50-ab8c-768b3d9803b3)\r\n\r\n\r\nIn the browser I get loads of errors in general for metabase\r\n![image](https://github.com/user-attachments/assets/ed673070-0d21-412d-8e22-9470fd658903)"", 'created_at': datetime.datetime(2024, 7, 24, 18, 12, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249020100, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': 'do you know if you have dns problems in your infrastructure?', 'created_at': datetime.datetime(2024, 7, 24, 22, 48, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2249615579, 'issue_id': 2428018862, 'author': 'hss-iullah', 'body': ""No, all is good and it's just one specific dashboard (the questions themselves load fine, it's just in the dashboard mode) which is using Redshift **plus some Redshift external schema tables** which pull from a postgres database.\r\nThe SQL fires totally fine, no performance issues or delays, it's just this one specific dashboard which uses a combination of Redshift tables and Redshift external schema tables."", 'created_at': datetime.datetime(2024, 7, 25, 7, 10, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265426564, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': '@hss-iullah do you have a CDN in place that might be caching stuff? Have you cleared the cache in your browser?', 'created_at': datetime.datetime(2024, 8, 2, 13, 38, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265443943, 'issue_id': 2428018862, 'author': 'alxnddr', 'body': '@paoliniluis I think it may not be related to CDN because the request hits Metabase BE and the BE middleware logs 404', 'created_at': datetime.datetime(2024, 8, 2, 13, 48, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265448143, 'issue_id': 2428018862, 'author': 'alxnddr', 'body': '@hss-iullah do you use in-app caching?', 'created_at': datetime.datetime(2024, 8, 2, 13, 50, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266154569, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': '@alxnddr my theory here was that they were using a cached FE bundle (many people end up with old FE assets after upgrading due to CDN stuff) and this ends in very weird behaviors like this one', 'created_at': datetime.datetime(2024, 8, 2, 21, 16, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2267427706, 'issue_id': 2428018862, 'author': 'hss-iullah', 'body': 'Hi. No cdn. The issue persists and only affects redshift federated tables.  Have you tested metabase with redshift federated tables?\r\n\r\nSent from Outlook for iOS<https://aka.ms/o0ukef>\r\n________________________________\r\nFrom: Luis Paolini ***@***.***>\r\nSent: Friday, August 2, 2024 11:16:42 PM\r\nTo: metabase/metabase ***@***.***>\r\nCc: Imtiaz Ullah ***@***.***>; Mention ***@***.***>\r\nSubject: Re: [metabase/metabase] Intermittent (but frequent) ""There was a problem displaying this chart."" (Issue #46071)\r\n\r\n\r\n\r\nCAUTION: This email originates from outside of the organisation. Do not click links or open attachments unless you recognise the sender, have verified their email address, and know the content is safe. Please report suspicious emails using the Microsoft Report button.\r\n\r\n\r\n@alxnddr<https://github.com/alxnddr> my theory here was that they were using a cached FE bundle (many people end up with old FE assets after upgrading due to CDN stuff) and this ends in very weird behaviors like this one\r\n\r\n—\r\nReply to this email directly, view it on GitHub<https://github.com/metabase/metabase/issues/46071#issuecomment-2266154569>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BDTWM7XFEGI66N6QYF4HU6LZPPZLVAVCNFSM6AAAAABLM3AVRKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENRWGE2TINJWHE>.\r\nYou are receiving this because you were mentioned.Message ID: ***@***.***>\r\n\r\n\r\nThis message, and any associated files, are intended only for the use of the message recipient and may contain information that is confidential, subject to copyright or constitute a trade secret. If you are not the message recipient you are hereby notified that any dissemination, copying or distribution of this message, or files associated with this message, is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the message and then deleting it from your computer. HSS Hire Service Group Limited may monitor email traffic data and also the content of email for the purposes of security and staff training. Any views or opinions presented are solely those of the sender and do not necessarily represent those of the company.\r\n\r\nHSS Hire Service Group is a limited company registered in England and Wales. Registered number: 644490.\r\nRegistered office: Building 2, Think Park, Mosley Road, Trafford Park, Manchester, M17 1FQ, United Kingdom.', 'created_at': datetime.datetime(2024, 8, 4, 8, 28, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273879598, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""Just reproduced this with a customer, we'll address it ASAP"", 'created_at': datetime.datetime(2024, 8, 7, 16, 38, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273999179, 'issue_id': 2428018862, 'author': 'snoe', 'body': 'Related issue that are showing the `OST` logs.\r\nhttps://github.com/metabase/metabase/issues/36774', 'created_at': datetime.datetime(2024, 8, 7, 17, 43, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278349310, 'issue_id': 2428018862, 'author': 'snoe', 'body': 'Reproduction steps:\r\n- On a metabase instance running outside AWS\r\n- Make a native query against a redshift test data orders table (this schema is in our dev redshift instance)\r\n`select * from ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".test_data_orders`\r\n- Open dev tools\r\n- Run it, after the query finishes you should see a request for `GET /api/database/:id` in network requests, it may or may not fail. (usually does for me)\r\n- You can refresh the page and re-run it to test or you can ""copy as curl"" the `POST /api/dataset` and `GET /api/database/:id` requests from the network tab and combine them using `--next`\r\n\r\n```\r\ncurl \'https://stats.metabase.com/api/dataset\' \\\r\n  -H \'accept: application/json\' \\\r\n  -H \'content-type: application/json\' \\\r\n  -H \'cookie: metabase.TIMEOUT=alive; metabase.SESSION=$SESSION\' \\\r\n  --data-raw \'{""type"":""native"",""database"":168,""native"":{""query"":""select * from \\""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema\\"".test_data_orders"",""template-tags"":{}},""parameters"":[]}\' \\\r\n--next \'https://stats.metabase.com/api/database/168\' \\\r\n  -H \'accept: application/json\' \\\r\n  -H \'content-type: application/json\' \\\r\n  -H \'cookie: metabase.SESSION=$SESSION\'\r\n```\r\n\r\nIt is inconsistent if the app receives a `GET /api/database/168` `ET/api/database/168` `T /api/database/168` or ` /api/database/168` Usually at least one byte is dropped with this method from my local machine.', 'created_at': datetime.datetime(2024, 8, 9, 16, 47, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329887548, 'issue_id': 2428018862, 'author': 'bshepherdson', 'body': 'I can reproduce this on localhost, a bit less consistently than I would like.\r\n\r\nI captured the packets with Wireshark and the `GET` definitely went over the wire. The server only caught `ET /api/database/487`, though.', 'created_at': datetime.datetime(2024, 9, 4, 20, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329905904, 'issue_id': 2428018862, 'author': 'bshepherdson', 'body': 'The method is `ET` by the time it reaches the Jetty server: both the [Jetty `Request` and Jakarta `HttpServletRequest`](https://github.com/metabase/metabase/blob/master/src/metabase/server.clj#L66) have method `""ET""`.\r\n\r\nSo there\'s something happening deeper in the network or server infra, before we reach the request handlers in Clojure land.', 'created_at': datetime.datetime(2024, 9, 4, 20, 24, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329906379, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': '@bshepherdson redshift as well?', 'created_at': datetime.datetime(2024, 9, 4, 20, 25, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329908065, 'issue_id': 2428018862, 'author': 'bshepherdson', 'body': ""Yeah, I'm using the Redshift query that Case mentioned above. It reproduces more often if I keep refreshing the page, rather than using `curl`."", 'created_at': datetime.datetime(2024, 9, 4, 20, 26, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2338470348, 'issue_id': 2428018862, 'author': 'bshepherdson', 'body': ""With `DEBUG` logging turned on in Jetty, the repro gets a bit less frequent but it does still happen. The logs show that when it repros most of the Jetty internals (`HttpInput`, `AsyncContentProcessor` and more) are the same instances, recycled. That is, the async streaming `/query` request/response used the same Jetty machinery as the new `/database` request that loses a byte.\r\n\r\nThat's telling, but it's still not clear how that byte actually gets skipped or consumed wrongly. Since this is Redshift-specific I suspect it's related to the Redshift JDBC driver's `RingBufferThread`, which is still receiving data rows from the server.\r\n\r\nThe Redshift servers don't respect `.setMaxRows`, and are either slow to react to a cancellation message, or don't respect those either. Therefore when max rows is reached, the Redshift JDBC driver closes the result set, and spawns a separate thread (`RingBufferThread`) to drain the data rows which the server is still sending to it. That leads to Metabase thinking that (1) the query is finished; (2) the Redshift connection can be reused; and (3) the Jetty HTTP connection parts can be `.recycle()`ed and `.reopen()`ed.\r\n\r\nIn fact none of those three conditions are quite true, but I wasn't able to find where it actually goes wrong. The connection can be reused, but it [starts by waiting for the old one to finish](https://github.com/aws/amazon-redshift-jdbc-driver/blob/master/src/main/java/com/amazon/redshift/core/v3/QueryExecutorImpl.java#L331) which might take a long time. Since the Redshift socket is separate from the Metabase HTTP sockets, I'm not sure what happens to that lost byte. Maybe it tries to write something via the `ResultSet` when the query really ends, and that advances the `ByteBuffer.pos()` by 1?"", 'created_at': datetime.datetime(2024, 9, 9, 15, 45, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341316273, 'issue_id': 2428018862, 'author': 'nathanjones4323', 'body': 'Does anyone know which version introduced this bug? I am looking to rollback to an old version until there is a release for a fix on this', 'created_at': datetime.datetime(2024, 9, 10, 15, 47, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341353068, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""@nathanjones4323 we don't know, we have a strong belief this is redshift, so if I were you I would be downgrading the redshift JDBC driver rather than the Metabase version"", 'created_at': datetime.datetime(2024, 9, 10, 16, 0, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341379200, 'issue_id': 2428018862, 'author': 'nathanjones4323', 'body': 'Thanks for the quick response!\r\n\r\nMy team is experiencing the same issue as the OP, but we are using Amazon RDS for PostgreSQL.', 'created_at': datetime.datetime(2024, 9, 10, 16, 9, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341418172, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': '@nathanjones4323 is PostgreSQL the app db or the DW?', 'created_at': datetime.datetime(2024, 9, 10, 16, 23, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341428475, 'issue_id': 2428018862, 'author': 'evan-dixon', 'body': '@paoliniluis I am on the same team as @nathanjones4323 . PostgreSQL is our data warehouse, we do not have redshift/snowflake/etc', 'created_at': datetime.datetime(2024, 9, 10, 16, 28, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341430389, 'issue_id': 2428018862, 'author': 'nathanjones4323', 'body': '@paoliniluis We use separate instances but both RDS for our warehouse and Metabase backend.', 'created_at': datetime.datetime(2024, 9, 10, 16, 29, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2341976216, 'issue_id': 2428018862, 'author': 'sifxtreme', 'body': 'Running into an issue that manifests itself similarly. With the ""There was a problem displaying this chart."". Digging deeper, we are getting intermittent 500s from the Metabase backend. The error message is ""ERROR: cannot execute UPDATE in a read-only transaction"".\r\n\r\nNot sure what changed and where that would be coming from. Any ideas?', 'created_at': datetime.datetime(2024, 9, 10, 20, 43, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2342047991, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""@sifxtreme this is not the issue you're seeing, please post version and reproduction steps or conditions in another issue so we can investigate and fix"", 'created_at': datetime.datetime(2024, 9, 10, 21, 33, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2342049258, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""@evan-dixon can you confirm that you're seing the HTTP verbs getting chopped on the logs? first time we hear this happens on pure postgres so that will discard that this is an issue with Redshift"", 'created_at': datetime.datetime(2024, 9, 10, 21, 34, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2342201878, 'issue_id': 2428018862, 'author': 'evan-dixon', 'body': ""@paoliniluis I think we have the same outward symptoms with different inward issues. The POST requests don't seem to be getting chopped, but instead are experiencing internal server errors. This particular thread still may just be related to redshift, sorry for any mis-direction. @sifxtreme is logging a separate issue."", 'created_at': datetime.datetime(2024, 9, 10, 22, 24, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2357216378, 'issue_id': 2428018862, 'author': 'hudovisk', 'body': 'Hey @paoliniluis we are using two postgres instances, one for Metabase backend and one for the warehouse. I was running locally using a localhost postgres for metabase backend and I observed the same behavior on `OST` requests:\r\n```\r\nmetabase-1  | {""@timestamp"":""2024-09-17T23:43:19.721Z"",""ecs.version"":""1.2.0"",""log.level"":""WARN"",""message"":""OST /api/dashboard/17/dashcard/200/card/288/query 404 11.8 ms (0 chamadas ao banco de dados) {:metabase-user-id 1} \\n#metabase.util.i18n.UserLocalizedString{:format-string \\""API endpoint does not exist.\\"", :args [], :pluralization-opts {}}\\n"",""process.thread.name"":""qtp1460527055-220"",""log.logger"":""metabase.server.middleware.log""}\r\n```\r\n\r\nThis is an intermittent issue that displays the ""There was a problem displaying this chart."" in the dashboard\r\n\r\nDiagnosis info:\r\n```\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""pt-BR"",\r\n    ""platform"": ""MacIntel"",\r\n    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""postgres""\r\n    ],\r\n    ""run-mode"": ""prod"",\r\n    ""plan-alias"": """",\r\n    ""version"": {\r\n      ""date"": ""2024-08-29"",\r\n      ""tag"": ""v0.50.23.1"",\r\n      ""hash"": ""f7c10c3""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": null\r\n    },\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.3""\r\n      }\r\n    }\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.24+8"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.24"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.24+8"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""6.10.4-linuxkit"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""GMT""\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 9, 17, 23, 50, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416168581, 'issue_id': 2428018862, 'author': 'nsaje', 'body': 'Facing this locally as well with Redshift (edit: and postgres! doesn\'t appear to be driver related). The browser is not to blame (confirmed with tcpdump, see screenshots). It appears like some middleware does a substring on the HTTP method and cuts off the `P`. The resulting HTTP method starting with `OST ...` obviously doesn\'t match any known path so a 404 is returned.\n\n<details><summary>Diagnostic Info</summary>\n<p>\n\n{\n  ""url"": ""http://localhost:3000/dashboard/35-leadership-dashboard?tab=13-customers-by-tier"",\n  ""entityName"": ""dashboard"",\n  ""bugReportDetails"": {\n    ""metabase-info"": {\n      ""databases"": [\n        ""redshift""\n      ],\n      ""run-mode"": ""prod"",\n      ""plan-alias"": """",\n      ""version"": {\n        ""date"": ""2024-10-02"",\n        ""tag"": ""v0.50.28"",\n        ""hash"": ""3179ef2""\n      },\n      ""settings"": {\n        ""report-timezone"": ""UTC""\n      },\n      ""hosting-env"": ""unknown"",\n      ""application-database"": ""postgres"",\n      ""application-database-details"": {\n        ""database"": {\n          ""name"": ""PostgreSQL"",\n          ""version"": ""16.2 (Debian 16.2-1.pgdg120+2)""\n        },\n        ""jdbc-driver"": {\n          ""name"": ""PostgreSQL JDBC Driver"",\n          ""version"": ""42.7.3""\n        }\n      }\n    },\n    ""system-info"": {\n      ""file.encoding"": ""UTF-8"",\n      ""java.runtime.name"": ""OpenJDK Runtime Environment"",\n      ""java.runtime.version"": ""11.0.24+8"",\n      ""java.vendor"": ""Eclipse Adoptium"",\n      ""java.vendor.url"": ""https://adoptium.net/"",\n      ""java.version"": ""11.0.24"",\n      ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\n      ""java.vm.version"": ""11.0.24+8"",\n      ""os.name"": ""Linux"",\n      ""os.version"": ""6.10.12-orbstack-00282-gd1783374c25e"",\n      ""user.language"": ""en"",\n      ""user.timezone"": ""GMT""\n    }\n  }\n}\n\n</p>\n</details> \n\n### browser network tab\n\n![Image](https://github.com/user-attachments/assets/f21ba580-cfc7-4836-bdb7-0112ca7a760b)\n\n### server logs error\n![Image](https://github.com/user-attachments/assets/12fd7be2-db6d-42a6-890d-72beb5c1b39b)\n\n### wireshark request\n![Image](https://github.com/user-attachments/assets/6a8f7901-a751-48ec-b4b4-e9377b02ed5d)\n\n### wireshark response\n![Image](https://github.com/user-attachments/assets/96681841-3a5b-44b0-8f44-5e78d91054ea)', 'created_at': datetime.datetime(2024, 10, 16, 9, 3, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416351906, 'issue_id': 2428018862, 'author': 'paoliniluis', 'body': ""@nsaje nice debugging skills. Just want to mention that the issue seems to be the HTTP method here which the Jetty web server does not seem to understand (because it simply doesn't exist). So everything is fine on the browser end and at some point in the middle, something strips the P from the HTTP method and the backend receives an unknown method and replies with a 404"", 'created_at': datetime.datetime(2024, 10, 16, 10, 11, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416365819, 'issue_id': 2428018862, 'author': 'nsaje', 'body': ""> backend receives an unknown method\n\nThe backend receives the method correctly as evidenced by tcpdump. My theory is that there is some middleware _within_ the Metabase backend that malforms the HTTP method before it's matched against known endpoints."", 'created_at': datetime.datetime(2024, 10, 16, 10, 17, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422021316, 'issue_id': 2428018862, 'author': 'nsaje', 'body': ""Curiously I'm unable to reproduce this when running Clojure in development mode via `clojure -M:run` - it only happens via Docker (running the same version in both).\n\nEdit: jumped the gun, I can reproduce it locally with `clojure -M:run`."", 'created_at': datetime.datetime(2024, 10, 18, 9, 55, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428013271, 'issue_id': 2428018862, 'author': 'perivamsi', 'body': 'Got excited about the docker repro for a second but looks like this is happening directly as well.', 'created_at': datetime.datetime(2024, 10, 22, 1, 10, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429302287, 'issue_id': 2428018862, 'author': 'bshepherdson', 'body': 'I agree with [nsaje above](https://github.com/metabase/metabase/issues/46071#issuecomment-2416365819) that the issue lies in the depths of the Metabase server somewhere.\n\nI think my earlier [comment](https://github.com/metabase/metabase/issues/46071#issuecomment-2338470348) is still on the right track, except for the Redshift-specific part. Jetty has a `recycle()` flow that wipes and reuses various internal objects. I think somewhere a `Socket` (or `HttpConnection` etc.) is getting recycled and used for the ""chopped"" request, even though some async process still has references to it.\n\nI suspect the lost byte is getting read[1] by that async process and the new request never sees it. Perhaps with a heap snapshot tool like VisualVM we could capture that moment of recycling eg. Jetty\'s `HttpInput`, and find who still has references to that or the `ByteBuffer`/`InputStream`/`Socket` it previously owned.\n\n\n[1] I can easily imagine a process that\'s either pre-fetching a byte optimistically, or `.get()`ing the byte, realizing it\'s the wrong thing, and rewinding the stream (`PushBackReader`, adjusting `ByteBuffer.pos()`, etc.) but either too ""locally"" or too late for the other consumer to get the byte back.', 'created_at': datetime.datetime(2024, 10, 22, 13, 32, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439939878, 'issue_id': 2428018862, 'author': 'alexander-yakushev', 'body': 'I tried reproducing this with:\n- local Postgres and remote Redshift \n- JDK 11 and 23\n- browser, curl, and HTTP client from a Clojure process.\n- MacOS\n\nNothing worked, unfortunately; I haven\'t seen a single 404 or 400. Here\'s the code I used for stress test, in case somebody wants to check if they can reproduce with it:\n```clj\n(import \'[java.net.http HttpClient HttpRequest HttpResponse$BodyHandlers\n          HttpRequest$BodyPublishers]\n        \'[java.net URI]\n        \'[java.time Duration])\n\n(defn client []\n  (-> (HttpClient/newBuilder)\n      (.connectTimeout (Duration/ofSeconds 20))\n      (.version java.net.http.HttpClient$Version/HTTP_1_1) ;; keep-alive\n      (.executor (java.util.concurrent.Executors/newFixedThreadPool 2))\n      (.build)))\n\n(def request\n  (-> (HttpRequest/newBuilder)\n      (.uri (URI/create ""http://localhost:3000/api/card/110/query"")) ;; Replace this and line below with URL you want to test against.\n      (.POST (HttpRequest$BodyPublishers/ofString ""{\\""ignore_cache\\"":false,\\""collection_preview\\"":false,\\""parameters\\"":[]}""))\n      (.timeout (Duration/ofSeconds 5))\n      (.header ""Content-Type"" ""application/json"")\n      (.header ""Accept"" ""application/json"")\n      ;; Other headers here including cookies.\n      (.build)))\n\n(defn query [client]\n  (try\n    (let [response (.send client request (HttpResponse$BodyHandlers/ofString))]\n      (.statusCode response))\n    (catch Exception _ 999)))\n\n;; Single request\n(query (client))\n\n;; Multiple clients querying many times.\n(def results (atom []))\n\n(let [clis (vec (repeatedly 20 client))]\n  (run! (fn [cli]\n          (Thread/startVirtualThread #(dotimes [_ 1000]\n                                        (swap! results conj (query cli)))))\n        clis))\n\n(frequencies @results) ;; Analyze results\n```', 'created_at': datetime.datetime(2024, 10, 27, 10, 14, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2440641136, 'issue_id': 2428018862, 'author': 'nsaje', 'body': ""@alexander-yakushev Results (I accidentally aborted it a bit early)\n\n```\nuser=> (frequencies @results) ;; Analyze results\n{202 13530, 999 13, 404 4036}\n```\n\nThis is on macOS 15.0.1, commit 405ed53baa5a3346e7ac253fc8cd8e7bf9a72dff , metabase running via `clojure -M:run`, metabase's postgres instance running locally in docker, remote Redshift, Clojure 1.12.0.1479 and\n\n```\n$ java --version\nopenjdk 22 2024-03-19\nOpenJDK Runtime Environment (build 22+36-2370)\nOpenJDK 64-Bit Server VM (build 22+36-2370, mixed mode, sharing)\n```"", 'created_at': datetime.datetime(2024, 10, 28, 6, 14, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2453113581, 'issue_id': 2428018862, 'author': 'alexander-yakushev', 'body': '@nsaje Thank you very much for repeating my experiment! With you confirming once again that it reproduces, I managed to reproduce it myself and [hopefully] fix this issue in the PR linked above.', 'created_at': datetime.datetime(2024, 11, 2, 20, 6, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457783136, 'issue_id': 2428018862, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.51.3](https://github.com/metabase/metabase/milestone/279)', 'created_at': datetime.datetime(2024, 11, 5, 17, 32, 31, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-24 16:42:26 UTC): seems like it's not the backend, can you check if there's something on the browser console when this happens?

hss-iullah (Issue Creator) on (2024-07-24 18:12:48 UTC): It's weird cos it's intermittent. If I refresh the page again, the chart might work and then might not on the next reload or when applying a filter. It's totally sporadic.

But this is what appears in the logs for every chart which fails to load:
![image](https://github.com/user-attachments/assets/52b08446-759b-4562-8f81-2d5b8a65f239)

For each chart that fails to load I get this in the browser:
![image](https://github.com/user-attachments/assets/12711f25-5526-4f50-ab8c-768b3d9803b3)


In the browser I get loads of errors in general for metabase
![image](https://github.com/user-attachments/assets/ed673070-0d21-412d-8e22-9470fd658903)

paoliniluis on (2024-07-24 22:48:22 UTC): do you know if you have dns problems in your infrastructure?

hss-iullah (Issue Creator) on (2024-07-25 07:10:41 UTC): No, all is good and it's just one specific dashboard (the questions themselves load fine, it's just in the dashboard mode) which is using Redshift **plus some Redshift external schema tables** which pull from a postgres database.
The SQL fires totally fine, no performance issues or delays, it's just this one specific dashboard which uses a combination of Redshift tables and Redshift external schema tables.

paoliniluis on (2024-08-02 13:38:41 UTC): @hss-iullah do you have a CDN in place that might be caching stuff? Have you cleared the cache in your browser?

alxnddr on (2024-08-02 13:48:30 UTC): @paoliniluis I think it may not be related to CDN because the request hits Metabase BE and the BE middleware logs 404

alxnddr on (2024-08-02 13:50:47 UTC): @hss-iullah do you use in-app caching?

paoliniluis on (2024-08-02 21:16:21 UTC): @alxnddr my theory here was that they were using a cached FE bundle (many people end up with old FE assets after upgrading due to CDN stuff) and this ends in very weird behaviors like this one

hss-iullah (Issue Creator) on (2024-08-04 08:28:10 UTC): Hi. No cdn. The issue persists and only affects redshift federated tables.  Have you tested metabase with redshift federated tables?

Sent from Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Luis Paolini ***@***.***>
Sent: Friday, August 2, 2024 11:16:42 PM
To: metabase/metabase ***@***.***>
Cc: Imtiaz Ullah ***@***.***>; Mention ***@***.***>
Subject: Re: [metabase/metabase] Intermittent (but frequent) ""There was a problem displaying this chart."" (Issue #46071)



CAUTION: This email originates from outside of the organisation. Do not click links or open attachments unless you recognise the sender, have verified their email address, and know the content is safe. Please report suspicious emails using the Microsoft Report button.


@alxnddr<https://github.com/alxnddr> my theory here was that they were using a cached FE bundle (many people end up with old FE assets after upgrading due to CDN stuff) and this ends in very weird behaviors like this one

—
Reply to this email directly, view it on GitHub<https://github.com/metabase/metabase/issues/46071#issuecomment-2266154569>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/BDTWM7XFEGI66N6QYF4HU6LZPPZLVAVCNFSM6AAAAABLM3AVRKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDENRWGE2TINJWHE>.
You are receiving this because you were mentioned.Message ID: ***@***.***>


This message, and any associated files, are intended only for the use of the message recipient and may contain information that is confidential, subject to copyright or constitute a trade secret. If you are not the message recipient you are hereby notified that any dissemination, copying or distribution of this message, or files associated with this message, is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the message and then deleting it from your computer. HSS Hire Service Group Limited may monitor email traffic data and also the content of email for the purposes of security and staff training. Any views or opinions presented are solely those of the sender and do not necessarily represent those of the company.

HSS Hire Service Group is a limited company registered in England and Wales. Registered number: 644490.
Registered office: Building 2, Think Park, Mosley Road, Trafford Park, Manchester, M17 1FQ, United Kingdom.

paoliniluis on (2024-08-07 16:38:38 UTC): Just reproduced this with a customer, we'll address it ASAP

snoe on (2024-08-07 17:43:49 UTC): Related issue that are showing the `OST` logs.
https://github.com/metabase/metabase/issues/36774

snoe on (2024-08-09 16:47:24 UTC): Reproduction steps:
- On a metabase instance running outside AWS
- Make a native query against a redshift test data orders table (this schema is in our dev redshift instance)
`select * from ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".test_data_orders`
- Open dev tools
- Run it, after the query finishes you should see a request for `GET /api/database/:id` in network requests, it may or may not fail. (usually does for me)
- You can refresh the page and re-run it to test or you can ""copy as curl"" the `POST /api/dataset` and `GET /api/database/:id` requests from the network tab and combine them using `--next`

```
curl 'https://stats.metabase.com/api/dataset' \
  -H 'accept: application/json' \
  -H 'content-type: application/json' \
  -H 'cookie: metabase.TIMEOUT=alive; metabase.SESSION=$SESSION' \
  --data-raw '{""type"":""native"",""database"":168,""native"":{""query"":""select * from \""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema\"".test_data_orders"",""template-tags"":{}},""parameters"":[]}' \
--next 'https://stats.metabase.com/api/database/168' \
  -H 'accept: application/json' \
  -H 'content-type: application/json' \
  -H 'cookie: metabase.SESSION=$SESSION'
```

It is inconsistent if the app receives a `GET /api/database/168` `ET/api/database/168` `T /api/database/168` or ` /api/database/168` Usually at least one byte is dropped with this method from my local machine.

bshepherdson on (2024-09-04 20:13:05 UTC): I can reproduce this on localhost, a bit less consistently than I would like.

I captured the packets with Wireshark and the `GET` definitely went over the wire. The server only caught `ET /api/database/487`, though.

bshepherdson on (2024-09-04 20:24:46 UTC): The method is `ET` by the time it reaches the Jetty server: both the [Jetty `Request` and Jakarta `HttpServletRequest`](https://github.com/metabase/metabase/blob/master/src/metabase/server.clj#L66) have method `""ET""`.

So there's something happening deeper in the network or server infra, before we reach the request handlers in Clojure land.

paoliniluis on (2024-09-04 20:25:02 UTC): @bshepherdson redshift as well?

bshepherdson on (2024-09-04 20:26:10 UTC): Yeah, I'm using the Redshift query that Case mentioned above. It reproduces more often if I keep refreshing the page, rather than using `curl`.

bshepherdson on (2024-09-09 15:45:41 UTC): With `DEBUG` logging turned on in Jetty, the repro gets a bit less frequent but it does still happen. The logs show that when it repros most of the Jetty internals (`HttpInput`, `AsyncContentProcessor` and more) are the same instances, recycled. That is, the async streaming `/query` request/response used the same Jetty machinery as the new `/database` request that loses a byte.

That's telling, but it's still not clear how that byte actually gets skipped or consumed wrongly. Since this is Redshift-specific I suspect it's related to the Redshift JDBC driver's `RingBufferThread`, which is still receiving data rows from the server.

The Redshift servers don't respect `.setMaxRows`, and are either slow to react to a cancellation message, or don't respect those either. Therefore when max rows is reached, the Redshift JDBC driver closes the result set, and spawns a separate thread (`RingBufferThread`) to drain the data rows which the server is still sending to it. That leads to Metabase thinking that (1) the query is finished; (2) the Redshift connection can be reused; and (3) the Jetty HTTP connection parts can be `.recycle()`ed and `.reopen()`ed.

In fact none of those three conditions are quite true, but I wasn't able to find where it actually goes wrong. The connection can be reused, but it [starts by waiting for the old one to finish](https://github.com/aws/amazon-redshift-jdbc-driver/blob/master/src/main/java/com/amazon/redshift/core/v3/QueryExecutorImpl.java#L331) which might take a long time. Since the Redshift socket is separate from the Metabase HTTP sockets, I'm not sure what happens to that lost byte. Maybe it tries to write something via the `ResultSet` when the query really ends, and that advances the `ByteBuffer.pos()` by 1?

nathanjones4323 on (2024-09-10 15:47:03 UTC): Does anyone know which version introduced this bug? I am looking to rollback to an old version until there is a release for a fix on this

paoliniluis on (2024-09-10 16:00:28 UTC): @nathanjones4323 we don't know, we have a strong belief this is redshift, so if I were you I would be downgrading the redshift JDBC driver rather than the Metabase version

nathanjones4323 on (2024-09-10 16:09:15 UTC): Thanks for the quick response!

My team is experiencing the same issue as the OP, but we are using Amazon RDS for PostgreSQL.

paoliniluis on (2024-09-10 16:23:09 UTC): @nathanjones4323 is PostgreSQL the app db or the DW?

evan-dixon on (2024-09-10 16:28:15 UTC): @paoliniluis I am on the same team as @nathanjones4323 . PostgreSQL is our data warehouse, we do not have redshift/snowflake/etc

nathanjones4323 on (2024-09-10 16:29:18 UTC): @paoliniluis We use separate instances but both RDS for our warehouse and Metabase backend.

sifxtreme on (2024-09-10 20:43:33 UTC): Running into an issue that manifests itself similarly. With the ""There was a problem displaying this chart."". Digging deeper, we are getting intermittent 500s from the Metabase backend. The error message is ""ERROR: cannot execute UPDATE in a read-only transaction"".

Not sure what changed and where that would be coming from. Any ideas?

paoliniluis on (2024-09-10 21:33:08 UTC): @sifxtreme this is not the issue you're seeing, please post version and reproduction steps or conditions in another issue so we can investigate and fix

paoliniluis on (2024-09-10 21:34:06 UTC): @evan-dixon can you confirm that you're seing the HTTP verbs getting chopped on the logs? first time we hear this happens on pure postgres so that will discard that this is an issue with Redshift

evan-dixon on (2024-09-10 22:24:08 UTC): @paoliniluis I think we have the same outward symptoms with different inward issues. The POST requests don't seem to be getting chopped, but instead are experiencing internal server errors. This particular thread still may just be related to redshift, sorry for any mis-direction. @sifxtreme is logging a separate issue.

hudovisk on (2024-09-17 23:50:58 UTC): Hey @paoliniluis we are using two postgres instances, one for Metabase backend and one for the warehouse. I was running locally using a localhost postgres for metabase backend and I observed the same behavior on `OST` requests:
```
metabase-1  | {""@timestamp"":""2024-09-17T23:43:19.721Z"",""ecs.version"":""1.2.0"",""log.level"":""WARN"",""message"":""OST /api/dashboard/17/dashcard/200/card/288/query 404 11.8 ms (0 chamadas ao banco de dados) {:metabase-user-id 1} \n#metabase.util.i18n.UserLocalizedString{:format-string \""API endpoint does not exist.\"", :args [], :pluralization-opts {}}\n"",""process.thread.name"":""qtp1460527055-220"",""log.logger"":""metabase.server.middleware.log""}
```

This is an intermittent issue that displays the ""There was a problem displaying this chart."" in the dashboard

Diagnosis info:
```
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-08-29"",
      ""tag"": ""v0.50.23.1"",
      ""hash"": ""f7c10c3""
    },
    ""settings"": {
      ""report-timezone"": null
    },
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    }
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.24+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.24"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.24+8"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.10.4-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  }
}
```

nsaje on (2024-10-16 09:03:16 UTC): Facing this locally as well with Redshift (edit: and postgres! doesn't appear to be driver related). The browser is not to blame (confirmed with tcpdump, see screenshots). It appears like some middleware does a substring on the HTTP method and cuts off the `P`. The resulting HTTP method starting with `OST ...` obviously doesn't match any known path so a 404 is returned.

<details><summary>Diagnostic Info</summary>
<p>

{
  ""url"": ""http://localhost:3000/dashboard/35-leadership-dashboard?tab=13-customers-by-tier"",
  ""entityName"": ""dashboard"",
  ""bugReportDetails"": {
    ""metabase-info"": {
      ""databases"": [
        ""redshift""
      ],
      ""run-mode"": ""prod"",
      ""plan-alias"": """",
      ""version"": {
        ""date"": ""2024-10-02"",
        ""tag"": ""v0.50.28"",
        ""hash"": ""3179ef2""
      },
      ""settings"": {
        ""report-timezone"": ""UTC""
      },
      ""hosting-env"": ""unknown"",
      ""application-database"": ""postgres"",
      ""application-database-details"": {
        ""database"": {
          ""name"": ""PostgreSQL"",
          ""version"": ""16.2 (Debian 16.2-1.pgdg120+2)""
        },
        ""jdbc-driver"": {
          ""name"": ""PostgreSQL JDBC Driver"",
          ""version"": ""42.7.3""
        }
      }
    },
    ""system-info"": {
      ""file.encoding"": ""UTF-8"",
      ""java.runtime.name"": ""OpenJDK Runtime Environment"",
      ""java.runtime.version"": ""11.0.24+8"",
      ""java.vendor"": ""Eclipse Adoptium"",
      ""java.vendor.url"": ""https://adoptium.net/"",
      ""java.version"": ""11.0.24"",
      ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
      ""java.vm.version"": ""11.0.24+8"",
      ""os.name"": ""Linux"",
      ""os.version"": ""6.10.12-orbstack-00282-gd1783374c25e"",
      ""user.language"": ""en"",
      ""user.timezone"": ""GMT""
    }
  }
}

</p>
</details> 

### browser network tab

![Image](https://github.com/user-attachments/assets/f21ba580-cfc7-4836-bdb7-0112ca7a760b)

### server logs error
![Image](https://github.com/user-attachments/assets/12fd7be2-db6d-42a6-890d-72beb5c1b39b)

### wireshark request
![Image](https://github.com/user-attachments/assets/6a8f7901-a751-48ec-b4b4-e9377b02ed5d)

### wireshark response
![Image](https://github.com/user-attachments/assets/96681841-3a5b-44b0-8f44-5e78d91054ea)

paoliniluis on (2024-10-16 10:11:30 UTC): @nsaje nice debugging skills. Just want to mention that the issue seems to be the HTTP method here which the Jetty web server does not seem to understand (because it simply doesn't exist). So everything is fine on the browser end and at some point in the middle, something strips the P from the HTTP method and the backend receives an unknown method and replies with a 404

nsaje on (2024-10-16 10:17:54 UTC): The backend receives the method correctly as evidenced by tcpdump. My theory is that there is some middleware _within_ the Metabase backend that malforms the HTTP method before it's matched against known endpoints.

nsaje on (2024-10-18 09:55:35 UTC): Curiously I'm unable to reproduce this when running Clojure in development mode via `clojure -M:run` - it only happens via Docker (running the same version in both).

Edit: jumped the gun, I can reproduce it locally with `clojure -M:run`.

perivamsi on (2024-10-22 01:10:44 UTC): Got excited about the docker repro for a second but looks like this is happening directly as well.

bshepherdson on (2024-10-22 13:32:54 UTC): I agree with [nsaje above](https://github.com/metabase/metabase/issues/46071#issuecomment-2416365819) that the issue lies in the depths of the Metabase server somewhere.

I think my earlier [comment](https://github.com/metabase/metabase/issues/46071#issuecomment-2338470348) is still on the right track, except for the Redshift-specific part. Jetty has a `recycle()` flow that wipes and reuses various internal objects. I think somewhere a `Socket` (or `HttpConnection` etc.) is getting recycled and used for the ""chopped"" request, even though some async process still has references to it.

I suspect the lost byte is getting read[1] by that async process and the new request never sees it. Perhaps with a heap snapshot tool like VisualVM we could capture that moment of recycling eg. Jetty's `HttpInput`, and find who still has references to that or the `ByteBuffer`/`InputStream`/`Socket` it previously owned.


[1] I can easily imagine a process that's either pre-fetching a byte optimistically, or `.get()`ing the byte, realizing it's the wrong thing, and rewinding the stream (`PushBackReader`, adjusting `ByteBuffer.pos()`, etc.) but either too ""locally"" or too late for the other consumer to get the byte back.

alexander-yakushev on (2024-10-27 10:14:33 UTC): I tried reproducing this with:
- local Postgres and remote Redshift 
- JDK 11 and 23
- browser, curl, and HTTP client from a Clojure process.
- MacOS

Nothing worked, unfortunately; I haven't seen a single 404 or 400. Here's the code I used for stress test, in case somebody wants to check if they can reproduce with it:
```clj
(import '[java.net.http HttpClient HttpRequest HttpResponse$BodyHandlers
          HttpRequest$BodyPublishers]
        '[java.net URI]
        '[java.time Duration])

(defn client []
  (-> (HttpClient/newBuilder)
      (.connectTimeout (Duration/ofSeconds 20))
      (.version java.net.http.HttpClient$Version/HTTP_1_1) ;; keep-alive
      (.executor (java.util.concurrent.Executors/newFixedThreadPool 2))
      (.build)))

(def request
  (-> (HttpRequest/newBuilder)
      (.uri (URI/create ""http://localhost:3000/api/card/110/query"")) ;; Replace this and line below with URL you want to test against.
      (.POST (HttpRequest$BodyPublishers/ofString ""{\""ignore_cache\"":false,\""collection_preview\"":false,\""parameters\"":[]}""))
      (.timeout (Duration/ofSeconds 5))
      (.header ""Content-Type"" ""application/json"")
      (.header ""Accept"" ""application/json"")
      ;; Other headers here including cookies.
      (.build)))

(defn query [client]
  (try
    (let [response (.send client request (HttpResponse$BodyHandlers/ofString))]
      (.statusCode response))
    (catch Exception _ 999)))

;; Single request
(query (client))

;; Multiple clients querying many times.
(def results (atom []))

(let [clis (vec (repeatedly 20 client))]
  (run! (fn [cli]
          (Thread/startVirtualThread #(dotimes [_ 1000]
                                        (swap! results conj (query cli)))))
        clis))

(frequencies @results) ;; Analyze results
```

nsaje on (2024-10-28 06:14:05 UTC): @alexander-yakushev Results (I accidentally aborted it a bit early)

```
user=> (frequencies @results) ;; Analyze results
{202 13530, 999 13, 404 4036}
```

This is on macOS 15.0.1, commit 405ed53baa5a3346e7ac253fc8cd8e7bf9a72dff , metabase running via `clojure -M:run`, metabase's postgres instance running locally in docker, remote Redshift, Clojure 1.12.0.1479 and

```
$ java --version
openjdk 22 2024-03-19
OpenJDK Runtime Environment (build 22+36-2370)
OpenJDK 64-Bit Server VM (build 22+36-2370, mixed mode, sharing)
```

alexander-yakushev on (2024-11-02 20:06:48 UTC): @nsaje Thank you very much for repeating my experiment! With you confirming once again that it reproduces, I managed to reproduce it myself and [hopefully] fix this issue in the PR linked above.

github-actions[bot] on (2024-11-05 17:32:31 UTC): 🚀 This should also be released by [v0.51.3](https://github.com/metabase/metabase/milestone/279)

"
2427998110,issue,closed,completed,[FE] Filter available columns in click behaviors when updating a dashboard filter,,ranquild,2024-07-24 16:18:48+00:00,['ranquild'],2024-10-08 16:19:32+00:00,2024-07-26 12:40:02+00:00,https://github.com/metabase/metabase/issues/46069,[],[],
2427996968,issue,closed,completed,"[BE] When the temporal-unit cannot be applied to a column, return an error message explaining that and not a generic error",,ranquild,2024-07-24 16:18:09+00:00,['lbrdnk'],2024-10-08 16:17:12+00:00,2024-08-19 15:28:41+00:00,https://github.com/metabase/metabase/issues/46068,"[('.Backend', ''), ('.Team/Querying', '')]",[],
2427949608,issue,closed,not_planned,Migrate from 0.50.10 to 0.50.11,"### Describe the bug

Hello,
When I try to update the version of metabase from 0.50.10 to 0.50.11, I got this error : 
```
Caused by: liquibase.exception.DatabaseException: ERREUR: erreur de syntaxe sur ou près de « ( »                                                                                                              Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
	CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (
		CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END
	) END
) STORED]
```



### To Reproduce

```
helm repo add pmint93 https://pmint93.github.io/helm-charts
helm repo update
helm install metabase pmint93/metabase -f values.yaml
```
Using a values.yaml similar to this

```
image:
    tag: v0.50.10
database:
    type: postgres
    host: postgre.********
    port: ""5432""
    dbname: metabase
    username: *********
    password: *********
```

Upgrade the version to v0.50.11 by updating your values.yaml
```
image:
    tag: v0.50.11
...
```

Execute the following command
```
helm upgrade metabase pmint93/metabase -f values.yaml
```

The update will fail on migration

### Expected behavior

_No response_

### Logs

Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:   │
│      Reason: liquibase.exception.DatabaseException: ERREUR: erreur de syntaxe sur ou près de « ( »                                                                                                            │
│   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (                                                                                       │
│   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END                                                                                          │
│ ) STORED]

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-113-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.12 (Debian 11.12-0+deb10u1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking upgrade

### Additional context

_No response_",ArthurJam,2024-07-24 15:55:34+00:00,[],2024-07-24 15:57:06+00:00,2024-07-24 15:57:06+00:00,https://github.com/metabase/metabase/issues/46063,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2248372480, 'issue_id': 2427949608, 'author': 'paoliniluis', 'body': 'please upgrade your postgres db and then also upgrade to metabase 50.15', 'created_at': datetime.datetime(2024, 7, 24, 15, 56, 59, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-24 15:56:59 UTC): please upgrade your postgres db and then also upgrade to metabase 50.15

"
2427799202,issue,closed,completed,Filtering by a Postgres Enum Column Leads to a `NullPointerException` When Based on a Model,"### Describe the bug

I have a table called `calendar_entries` which is in a PostgresDB. In it, I have column ""status"" which is a postgres enum with string values. Whenever I create a question based on that table directly, I can add a filter for ""status"" which works just fine.

But, as soon as I create a custom model based on `calendar_entries` and I then try to add the filter, I get a `NullPointerException`.

This is the SQL Metabase created for my model:
(Simplified my test case for the sake of this issue)

```sql
SELECT
  ""source"".""id"" AS ""id"",
  ""source"".""status"" AS ""status""
FROM
  (
    SELECT
      ""public"".""calendar_entries"".""id"" AS ""id"",
      ""public"".""calendar_entries"".""status"" AS ""status""
    FROM
      ""public"".""calendar_entries""
  ) AS ""source""
LIMIT
  1048575
```

In Metabase it shows:
```
There was a problem with your question
Most of the time this is caused by an invalid selection or bad input value. Double check your inputs and retry your query.

Hide error details
Here's the full error message
Error running query
```

Or when looking at the generated SQL: `Error generating the query.`


### To Reproduce

1. Create a Postgres table with a column of type postgres enum with string values
2. Create a model in Metabase that is based on that table
3. Add a new metabase ""Question"" based on the model from step 2
4. Use the purple ""Filter"" button and try to filter by the enum column type
5. Error

### Expected behavior

_No response_

### Logs

```
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message ""Error compiling query: null"",
   :data
   {:query
    {:database 2,
     :qp/source-card-id 55,
     :info {:card-id 55},
     :type :query,
     :query
     {:qp/stage-had-source-card 55,
      :source-query/model? true,
      :filter
      [:= [:field ""status"" {:base-type :type/PostgresEnum}] [:value ""scheduled"" {:base_type :type/PostgresEnum}]],
      :source-metadata
      [{:database_type ""bigserial"",
        :semantic_type :type/PK,
        :table_id 9,
        :name ""id"",
        :field_ref [:field 100 {:base-type :type/BigInteger}],
        :effective_type :type/BigInteger,
        :id 100,
        :position 0,
        :visibility_type :normal,
        :display_name ""ID"",
        :base_type :type/BigInteger}
       {:database_type ""calendar_entry_status"",
        :semantic_type :type/Category,
        :table_id 9,
        :name ""status"",
        :field_ref [:field 98 {:base-type :type/PostgresEnum}],
        :effective_type :type/*,
        :id 98,
        :position 2,
        :visibility_type :normal,
        :display_name ""Status"",
        :fingerprint
        {:global {:distinct-count 4, :nil% 0.0},
         :type
         {:type/Text
          {:percent-json 0.0, :percent-url 0.0, :percent-email 0.0, :percent-state 0.0, :average-length 8.1374}}},
        :base_type :type/PostgresEnum}],
      :fields [[:field 100 {:base-type :type/BigInteger}] [:field 98 {:base-type :type/PostgresEnum}]],
      :source-query
      {:source-table 9,
       :fields [[:field 100 {:base-type :type/BigInteger}] [:field 98 {:base-type :type/PostgresEnum}]],
       :qp/stage-is-from-source-card 55},
      :limit 1048575,
      :metabase.query-processor.middleware.limit/original-limit nil}},
    :type :driver},
   :at [metabase.query_processor.compile$compile_preprocessed$fn__66228 invoke ""compile.clj"" 25]}
  {:type java.lang.NullPointerException}],
 :trace [],
 :message ""Error compiling query: null"",
 :query
 {:database 2,
  :qp/source-card-id 55,
  :info {:card-id 55},
  :type :query,
  :query
  {:qp/stage-had-source-card 55,
   :source-query/model? true,
   :filter [:= [:field ""status"" {:base-type :type/PostgresEnum}] [:value ""scheduled"" {:base_type :type/PostgresEnum}]],
   :source-metadata
   [{:database_type ""bigserial"",
     :semantic_type :type/PK,
     :table_id 9,
     :name ""id"",
     :field_ref [:field 100 {:base-type :type/BigInteger}],
     :effective_type :type/BigInteger,
     :id 100,
     :position 0,
     :visibility_type :normal,
     :display_name ""ID"",
     :base_type :type/BigInteger}
    {:database_type ""calendar_entry_status"",
     :semantic_type :type/Category,
     :table_id 9,
     :name ""status"",
     :field_ref [:field 98 {:base-type :type/PostgresEnum}],
     :effective_type :type/*,
     :id 98,
     :position 2,
     :visibility_type :normal,
     :display_name ""Status"",
     :fingerprint
     {:global {:distinct-count 4, :nil% 0.0},
      :type
      {:type/Text
       {:percent-json 0.0, :percent-url 0.0, :percent-email 0.0, :percent-state 0.0, :average-length 8.1374}}},
     :base_type :type/PostgresEnum}],
   :fields [[:field 100 {:base-type :type/BigInteger}] [:field 98 {:base-type :type/PostgresEnum}]],
   :source-query
   {:source-table 9,
    :fields [[:field 100 {:base-type :type/BigInteger}] [:field 98 {:base-type :type/PostgresEnum}]],
    :qp/stage-is-from-source-card 55},
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil}}}
```

### Information about your Metabase installation

```
Database: Postgres
Metabase: v0.50.15
Hosting Env: Docker
```


### Severity

Currently prevents us from using Metabase as the column(s) at hand are very important

### Additional context

https://github.com/user-attachments/assets/532d937b-c91e-4fc2-9ee8-3e7bddbaab0c

![Screenshot_2024-07-24_19-19-21@2x](https://github.com/user-attachments/assets/dd262bd5-1009-4ee5-a851-19753b07e8d9)
",ptts,2024-07-24 14:51:01+00:00,['lbrdnk'],2024-08-28 02:09:01+00:00,2024-08-14 08:34:31+00:00,https://github.com/metabase/metabase/issues/46059,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Postgres', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2427733366,issue,closed,completed,[Epic] Use the metric's data source when creating a new query based on a metric,"Product doc https://www.notion.so/metabase/Querying-and-combining-metrics-defined-on-the-same-data-source-1229f547df8140ce9c6f96cd707d28a5
Depends on https://github.com/metabase/metabase/issues/45824

We currently allow only single-stage metrics. When creating a query based on a metric, we should use the metric's data source for the new query data source and append an aggregation clause based on the metric. E.g.

```
// metric with id 2
{
  ""source-table"": ""card__1"",
  ""aggregation"": [[""count""]],
}

// new query should be like this
{
  ""source-table"": ""card__1"",
  ""aggregation"": [[""metric"", 2]]
}
```

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/46687
- [ ] https://github.com/metabase/metabase/issues/46781
- [ ] https://github.com/metabase/metabase/issues/46782
```",ranquild,2024-07-24 14:22:45+00:00,['metamben'],2024-08-15 14:08:45+00:00,2024-08-15 14:08:45+00:00,https://github.com/metabase/metabase/issues/46055,"[('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2289176160, 'issue_id': 2427733366, 'author': 'metamben', 'body': '@ranquild, is there more to this epic (e.g., the recent items issue) or can it be closed?', 'created_at': datetime.datetime(2024, 8, 14, 15, 54, 16, tzinfo=datetime.timezone.utc)}]","metamben (Assginee) on (2024-08-14 15:54:16 UTC): @ranquild, is there more to this epic (e.g., the recent items issue) or can it be closed?

"
2427492007,issue,open,,Improved Query Analysis Workflow and Persistence,"This continues on from https://github.com/metabase/metabase/issues/45460.

These tasks are non-functional, serving only to make our implementation more efficient by avoiding needless analysis and database churn.

```[tasklist]
- [x] Introduce QueryAnalysis model to act as root node for an analysis snapshot
- [x] Update SQL Analyzer to perform atomic swaps
- [ ] Use hash of analysis results to skip re-creating children
- [ ] Use version of analyser + hash of query to skip re-analysing all cards on load
- [ ] Use hash of query to continuously detect stale analysis due to races
- [ ] Replace in-memory failure map with error tracking on the root node
```",crisptrutski,2024-07-24 12:43:35+00:00,[],2024-10-03 01:27:55+00:00,,https://github.com/metabase/metabase/issues/46051,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]",[],
2427316806,issue,open,,Visualization: Venn Diagram,"**Is your feature request related to a problem? Please describe.**
There is no option to create a Venn diagram which uses overlapping circles or other shapes to illustrate the logical relationships between two or more sets of items.

![image](https://github.com/user-attachments/assets/433c2d90-14ba-4e54-84cb-d8e4ed3a6fc7)

**Describe the solution you'd like**
Option to create Venn diagram",Tony-metabase,2024-07-24 11:17:19+00:00,[],2024-07-24 11:17:19+00:00,,https://github.com/metabase/metabase/issues/46040,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]",[],
2427072087,issue,closed,completed,Developer doc for serdes,"Write a doc for developers how to deal with serdes: what to do if you add a new model, what if you add a column, how to deal with a bit more complex cases (FKs, nested data).",piranha,2024-07-24 09:36:10+00:00,['piranha'],2024-09-02 12:01:18+00:00,2024-09-02 08:09:24+00:00,https://github.com/metabase/metabase/issues/46039,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2247383209, 'issue_id': 2427072087, 'author': 'qnkhuat', 'body': 'an example of what to tests would be great too.', 'created_at': datetime.datetime(2024, 7, 24, 9, 37, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285707634, 'issue_id': 2427072087, 'author': 'devurandom', 'body': 'How to conditionally exclude something from serialization, if a feature flag is set, or if a property of the object is set to a certain value.', 'created_at': datetime.datetime(2024, 8, 13, 8, 48, 31, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-24 09:37:34 UTC): an example of what to tests would be great too.

devurandom on (2024-08-13 08:48:31 UTC): How to conditionally exclude something from serialization, if a feature flag is set, or if a property of the object is set to a certain value.

"
2426618370,issue,closed,not_planned,"What driver is ""sql server""?","https://www.metabase.com/docs/latest/databases/connecting#connecting-to-supported-databases

There's some ""SQL Server"", but if I open the details, it doesn't describe what it is, is that microsoft mssql? please clarify in documentation!

- https://www.metabase.com/docs/latest/databases/connections/sql-server
- https://github.com/metabase/metabase/blob/65bb3bb3a9fc978afcf3f3e67cb20a3596a7fc2c/docs/databases/connections/sql-server.md",glensc,2024-07-24 05:18:42+00:00,[],2024-07-25 18:51:50+00:00,2024-07-24 10:34:41+00:00,https://github.com/metabase/metabase/issues/46033,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2247554068, 'issue_id': 2426618370, 'author': 'paoliniluis', 'body': 'Microsoft sql server', 'created_at': datetime.datetime(2024, 7, 24, 10, 34, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2251189585, 'issue_id': 2426618370, 'author': 'glensc', 'body': 'issue idea was to indicate documentation needs updating', 'created_at': datetime.datetime(2024, 7, 25, 18, 51, 49, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-24 10:34:41 UTC): Microsoft sql server

glensc (Issue Creator) on (2024-07-25 18:51:49 UTC): issue idea was to indicate documentation needs updating

"
2426586127,issue,closed,completed,Serdes tests are broken,"This test is failing, the second select returns Card even though it was bound on the `dest-db`.


```clojure
(deftest with-dbs-works-as-expected-test
  (ts/with-dbs [source-db dest-db]
    (ts/with-db source-db
      (mt/with-temp
        [:model/Card {card-id :id} {:name ""MY CARD""}]
        (testing ""card is available in the source db""
          (is (some? (t2/select-one :model/Card :name ""MY CARD""))))
        (ts/with-db dest-db
          (testing ""card should not be available in the dest db""
           ;; FAIL, select is returning a Card
           (is (nil? (t2/select-one :model/Card :name ""MY CARD"")))))))))
```

This makes some e2e tests like `metabase-enterprise.serialization.v2.e2e-test/dashboard-with-tabs-test`  passes even if you comment out the `(serdes.load/load-metabase! (ingest/ingest-yaml dump-dir))` call",qnkhuat,2024-07-24 04:47:32+00:00,[],2024-08-05 15:10:43+00:00,2024-08-05 14:21:55+00:00,https://github.com/metabase/metabase/issues/46032,"[('Priority:P2', 'Average run of the mill bug'), ('.CI & Tests', ''), ('Operation/Serialization', 'Enterprise contents migration'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2246862028, 'issue_id': 2426586127, 'author': 'qnkhuat', 'body': ""Could be fixed if I wrap the test with `mt/test-helpers-set-global-values!`, but we need to figure out what's the root cause here."", 'created_at': datetime.datetime(2024, 7, 24, 4, 49, 3, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-07-24 04:49:03 UTC): Could be fixed if I wrap the test with `mt/test-helpers-set-global-values!`, but we need to figure out what's the root cause here.

"
2426251913,issue,open,,Query with custom column with name that exactly matches unused column name in source table breaks,"If you add a custom column called `CATEGORY` to the `PRODUCTS` table and exclude `PRODUCTS.CATEGORY` from the list of fields to return, the query will fail because it will incorrectly think the custom column expression is returned as `CATEGORY_2` from the source query.

Failing query:

```clj
{:lib/type     :mbql/query
               :lib/metadata meta/metadata-provider
               :database     (meta/id)
               :stages       [{:lib/type     :mbql.stage/mbql
                               :source-table (meta/id :products)}
                              {:lib/type    :mbql.stage/mbql
                               :expressions [[:value
                                              {:lib/uuid            ""e3b6ee32-fdc6-4115-bafa-b6cc0460d06e""
                                               :base-type           :type/Text
                                               :effective-type      :type/Text
                                               :lib/expression-name ""CATEGORY""}
                                              nil]
                                             [:abs {:lib/uuid            ""92f28262-35ef-4bb0-9a8d-49feb1046d25""
                                                    :lib/expression-name ""pivot-grouping""}
                                              1]]
                               :aggregation [[:count {:lib/uuid ""01c5c2ee-1cc7-48ba-b993-11fdceac2fd2""}]]
                               :breakout    [[:expression
                                              {:lib/uuid       ""c0d8fe94-f429-4839-8cad-b69e77e832b1""
                                               :base-type      :type/Text
                                               :effective-type :type/Text}
                                              ""CATEGORY""]
                                             [:field
                                              {:temporal-unit                                     :month
                                               :lib/uuid                                          ""694b7bb2-5bd9-4694-ad24-8c988a1179f5""
                                               :metabase.lib.query/transformation-added-base-type true
                                               :base-type                                         :type/DateTimeWithLocalTZ
                                               :effective-type                                    :type/DateTimeWithLocalTZ}
                                              (meta/id :products :created-at)]
                                             [:expression
                                              {:lib/uuid       ""de5492f3-58a8-4650-8665-5c8d7907d99a""
                                               :base-type      :type/Integer
                                               :effective-type :type/Integer}
                                              ""pivot-grouping""]]}]}
```

Compiles to this SQL:

```sql
SELECT
  ""source"".""CATEGORY_2"" AS ""CATEGORY"",
  DATE_TRUNC('month', ""source"".""CREATED_AT"") AS ""CREATED_AT"",
  ""source"".""pivot-grouping"" AS ""pivot-grouping"",
  COUNT(*) AS ""count""
FROM
  (
    SELECT
      ""source"".""CREATED_AT"" AS ""CREATED_AT"",
      NULL AS ""CATEGORY"",
      ABS(1) AS ""pivot-grouping""
    FROM
      (
        SELECT
          ""PUBLIC"".""PRODUCTS"".""ID"" AS ""ID"",
          ""PUBLIC"".""PRODUCTS"".""EAN"" AS ""EAN"",
          ""PUBLIC"".""PRODUCTS"".""TITLE"" AS ""TITLE"",
          ""PUBLIC"".""PRODUCTS"".""CATEGORY"" AS ""CATEGORY"",
          ""PUBLIC"".""PRODUCTS"".""VENDOR"" AS ""VENDOR"",
          ""PUBLIC"".""PRODUCTS"".""PRICE"" AS ""PRICE"",
          ""PUBLIC"".""PRODUCTS"".""RATING"" AS ""RATING"",
          ""PUBLIC"".""PRODUCTS"".""CREATED_AT"" AS ""CREATED_AT""
        FROM
          ""PUBLIC"".""PRODUCTS""
      ) AS ""source""
  ) AS ""source""
GROUP BY
  ""source"".""CATEGORY_2"",
  DATE_TRUNC('month', ""source"".""CREATED_AT""),
  ""source"".""pivot-grouping""
ORDER BY
  ""source"".""CATEGORY_2"" ASC,
  DATE_TRUNC('month', ""source"".""CREATED_AT"") ASC,
  ""source"".""pivot-grouping"" ASC
```

note that the SQL is wrong because there is no `CATEGORY_2` in the source query.
",camsaul,2024-07-23 22:59:07+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/46029,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2426244174,issue,open,,Allow timestamp casting in numeric fields,"**Is your feature request related to a problem? Please describe.**
Yes, this might lead to some issue, but if you save timestamps in ""numeric"" fields (allows floats) rather than pure integers, you can't do any sort of timestamp casting which is sad

**Describe the solution you'd like**
Allow timestamp casting to all numeric fields

**Describe alternatives you've considered**
A DB view

**How important is this feature to you?**
It might help people that used numeric datatypes for unix timestamps rather than integers

**Additional context**
NA
",paoliniluis,2024-07-23 22:49:52+00:00,[],2025-02-04 20:30:46+00:00,,https://github.com/metabase/metabase/issues/46028,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook/Custom Expression', '')]",[],
2425858723,issue,closed,completed,"Download results shows while dashboard cards are loading, and then disappears unexpectedly","### Context
[See this thread](https://metaboat.slack.com/archives/C64DB8QH2/p1721751841460789)

### Expected Behavior
Hide the ""..."" on dashboard cards when they are loading.",cdeweyx,2024-07-23 18:35:33+00:00,['kulyk'],2024-07-26 14:50:01+00:00,2024-07-25 12:56:55+00:00,https://github.com/metabase/metabase/issues/46019,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('Visualization/Download', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2425680485,issue,closed,completed,BE flake: metabase.util.queue-test/deduplicating-bounded-blocking-queue-test,"BE test flake: `metabase.util.queue-test/deduplicating-bounded-blocking-queue-test`

[example run](https://github.com/metabase/metabase/actions/runs/10061433681/job/27811546028?pr=44654#step:4:1241):
```
FAIL in metabase.util.queue-test/deduplicating-bounded-blocking-queue-test (queue_test.clj:69)
We processed all the events that were enqueued
expected: 1403
  actual: 223

FAIL in metabase.util.queue-test/deduplicating-bounded-blocking-queue-test (queue_test.clj:82)
Every item is processed
expected: #{0
            893
            920
...
<very long list of IDs>
...
```


failed 12 times in the past week ([source](https://stats.metabase.com/question#eyJuYW1lIjoiVGVzdCBmbGFrZXMgYnkgc3VpdGUgbmFtZSBhbmQgdGVzdCBuYW1lIChub3QgUVApIiwiZGVzY3JpcHRpb24iOiJodHRwczovL3N0YXRzLm1ldGFiYXNlLmNvbS9tb2RlbC8xNDgyOC10ZXN0LWZsYWtpbmVzcyIsImRhdGFzZXRfcXVlcnkiOnsiZGF0YWJhc2UiOjI2LCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJhZ2dyZWdhdGlvbiI6W1siY291bnQiXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl91cmwiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl9zdGFydGVkX2F0Iix7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiIsInRlbXBvcmFsLXVuaXQiOiJtaW51dGUifV1dLFsiYWdncmVnYXRpb24tb3B0aW9ucyIsWyJjb3VudC13aGVyZSIsWyI-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))",calherries,2024-07-23 16:58:37+00:00,[],2024-10-08 16:19:55+00:00,2024-07-24 09:09:55+00:00,https://github.com/metabase/metabase/issues/46010,"[('flaky-test-fix', ''), ('.Team/Workflows', 'aka BEC')]",[],
2425677788,issue,closed,completed,Make two messages in the question footer more useful,"As discussed here: https://metaboat.slack.com/archives/C06KX7QECN4/p1721743559366729


![Image](https://github.com/user-attachments/assets/fd86000e-6189-459b-99cd-eb52b3eaf4c5)

",rafpaf,2024-07-23 16:56:59+00:00,[],2024-10-08 16:19:38+00:00,2024-07-25 19:09:03+00:00,https://github.com/metabase/metabase/issues/46009,[],[],
2425598711,issue,closed,completed,"update `dashboard_pdf_exported` to make the dashboard_id optional (we won't send it from public/embed) + add the context (internal, public, static-embed)",[Slack convo](https://metaboat.slack.com/archives/C010L1Z4F9S/p1721745811912789),npretto,2024-07-23 16:16:50+00:00,['npretto'],2024-08-01 17:06:34+00:00,2024-08-01 17:06:34+00:00,https://github.com/metabase/metabase/issues/46007,"[('.Team/Embedding', '')]",[],
2425596889,issue,closed,not_planned,Migrations fails during upgrade to 0.50.14,"### Describe the bug

Upgrade Meatabse from 0.50.14 got the following error.

`2024-07-23T16:11:11.153Z INFO  - v0.50.14 Pulling from metabase/metabase
2024-07-23T16:11:11.154Z INFO  -  Digest: sha256:2cb63f8b3145516c0b245b9c6647bbce689436233a690a3803c86666b9b18fe7
2024-07-23T16:11:11.155Z INFO  -  Status: Image is up to date for metabase/metabase:v0.50.14
2024-07-23T16:11:11.166Z INFO  - Pull Image successful, Time taken: 1 Seconds
2024-07-23T16:11:11.172Z INFO  - Starting container for site
2024-07-23T16:11:11.173Z INFO  - docker run -d --expose=3000 --name app-metabase-size_0_85dcc28c -e WEBSITE_USE_DIAGNOSTIC_SERVER=false -e WEBSITES_ENABLE_APP_SERVICE_STORAGE=false -e WEBSITE_SITE_NAME=app-metabase-size -e WEBSITE_AUTH_ENABLED=False -e PORT=3000 -e WEBSITE_ROLE_INSTANCE_ID=0 -e WEBSITE_HOSTNAME=app-metabase-size.azurewebsites.net -e WEBSITE_INSTANCE_ID=8846bb390c5bca9e48006c82c6fd32a455abf47d795f7fc5cd48aeb21a10394c metabase/metabase:v0.50.14
2024-07-23T16:11:11.173Z INFO  - Logging is not enabled for this container.Please use https://aka.ms/linux-diagnostics to enable logging to see container logs here.
2024-07-23T16:11:11.378Z INFO  - Initiating warmup request to container app-metabase-size_0_85dcc28c for site app-metabase-size
2024-07-23T16:11:13.203193451Z Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-07-23T16:11:16.078157261Z 2024-07-23 16:11:16,076 INFO metabase.util :: Maximum memory available to JVM: 6.6 GB
2024-07-23T16:11:18.613248037Z 2024-07-23 16:11:18,612 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. 🔓
2024-07-23T16:11:18.613302838Z  For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-23T16:11:24.255690113Z 2024-07-23 16:11:24,255 INFO driver.impl :: [34mRegistered abstract driver :sql[0m  🚚
2024-07-23T16:11:24.263507313Z 2024-07-23 16:11:24,263 INFO driver.impl :: [34mRegistered abstract driver :sql-jdbc[0m (parents: [:sql]) 🚚
2024-07-23T16:11:24.270394000Z 2024-07-23 16:11:24,270 INFO metabase.util :: [32mLoad driver :sql-jdbc took 44.8 ms[0m
2024-07-23T16:11:24.270640204Z 2024-07-23 16:11:24,270 INFO driver.impl :: [34mRegistered driver :h2[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:24.458933702Z 2024-07-23 16:11:24,458 INFO driver.impl :: [34mRegistered driver :mysql[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:24.498277104Z 2024-07-23 16:11:24,498 INFO driver.impl :: [34mRegistered driver :postgres[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:26.500291701Z 2024-07-23 16:11:26,493 INFO metabase.core ::
2024-07-23T16:11:26.500331401Z Metabase v0.50.14 (26d21b1)
2024-07-23T16:11:26.500337301Z
2024-07-23T16:11:26.500340601Z Copyright © 2024 Metabase, Inc.
2024-07-23T16:11:26.500344502Z
2024-07-23T16:11:26.500347702Z Metabase Enterprise Edition extensions are NOT PRESENT.
2024-07-23T16:11:26.505267164Z 2024-07-23 16:11:26,504 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-07-23T16:11:26.555913108Z 2024-07-23 16:11:26,555 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
2024-07-23T16:11:26.555961508Z  {:port 3000, :host ""0.0.0.0""}
2024-07-23T16:11:26.555969708Z
2024-07-23T16:11:26.605729741Z 2024-07-23 16:11:26,605 INFO metabase.core :: Starting Metabase version v0.50.14 (26d21b1) ...
2024-07-23T16:11:26.610102196Z 2024-07-23 16:11:26,609 INFO metabase.core :: System info:
2024-07-23T16:11:26.610131097Z  {""file.encoding"" ""UTF-8"",
2024-07-23T16:11:26.610136897Z  ""java.runtime.name"" ""OpenJDK Runtime Environment"",
2024-07-23T16:11:26.610140997Z  ""java.runtime.version"" ""11.0.23+9"",
2024-07-23T16:11:26.610148397Z  ""java.vendor"" ""Eclipse Adoptium"",
2024-07-23T16:11:26.610152197Z  ""java.vendor.url"" ""https://adoptium.net/"",
2024-07-23T16:11:26.610156497Z  ""java.version"" ""11.0.23"",
2024-07-23T16:11:26.610160097Z  ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
2024-07-23T16:11:26.610164397Z  ""java.vm.version"" ""11.0.23+9"",
2024-07-23T16:11:26.610167997Z  ""os.name"" ""Linux"",
2024-07-23T16:11:26.610185798Z  ""os.version"" ""5.15.153.1-2.cm2"",
2024-07-23T16:11:26.610190298Z  ""user.language"" ""en"",
2024-07-23T16:11:26.610194798Z  ""user.timezone"" ""GMT""}
2024-07-23T16:11:26.610198298Z
2024-07-23T16:11:26.611846919Z 2024-07-23 16:11:26,611 INFO metabase.plugins :: Loading plugins in /plugins...
2024-07-23T16:11:26.768494910Z 2024-07-23 16:11:26,768 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-07-23T16:11:27.122705412Z 2024-07-23 16:11:27,121 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-07-23T16:11:27.151506278Z 2024-07-23 16:11:27,151 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-07-23T16:11:27.372824891Z 2024-07-23 16:11:27,372 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-07-23T16:11:27.381652903Z 2024-07-23 16:11:27,381 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-07-23T16:11:27.433818866Z 2024-07-23 16:11:27,433 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-07-23T16:11:27.437402411Z 2024-07-23 16:11:27,437 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-07-23T16:11:27.494422436Z 2024-07-23 16:11:27,494 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-07-23T16:11:27.495848954Z 2024-07-23 16:11:27,495 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-07-23T16:11:27.512883871Z 2024-07-23 16:11:27,512 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-07-23T16:11:27.519396754Z 2024-07-23 16:11:27,519 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-07-23T16:11:27.520560068Z 2024-07-23 16:11:27,520 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-07-23T16:11:27.599366270Z 2024-07-23 16:11:27,598 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-07-23T16:11:27.842154556Z 2024-07-23 16:11:27,841 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :presto-jdbc...[0m
2024-07-23T16:11:27.842775764Z 2024-07-23 16:11:27,842 INFO driver.impl :: [34mRegistered driver :presto-jdbc[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:27.849061744Z 2024-07-23 16:11:27,848 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :redshift...[0m
2024-07-23T16:11:27.849586350Z 2024-07-23 16:11:27,849 INFO driver.impl :: [34mRegistered driver :redshift[0m (parents: [:postgres]) 🚚
2024-07-23T16:11:28.019086405Z 2024-07-23 16:11:28,018 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :snowflake...[0m
2024-07-23T16:11:28.019568411Z 2024-07-23 16:11:28,019 INFO driver.impl :: [34mRegistered driver :snowflake[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.025286283Z 2024-07-23 16:11:28,025 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid-jdbc...[0m
2024-07-23T16:11:28.025706889Z 2024-07-23 16:11:28,025 INFO driver.impl :: [34mRegistered driver :druid-jdbc[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.031875067Z 2024-07-23 16:11:28,031 INFO plugins.dependencies :: [31mMetabase cannot initialize plugin Metabase Oracle Driver due to required dependencies.[0m Metabase requires the Oracle JDBC driver in order to connect to Oracle databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/oracle.html for more details.
2024-07-23T16:11:28.031902568Z
2024-07-23T16:11:28.033320186Z 2024-07-23 16:11:28,033 INFO plugins.dependencies :: Metabase Oracle Driver dependency {:class oracle.jdbc.OracleDriver} satisfied? false
2024-07-23T16:11:28.033944294Z 2024-07-23 16:11:28,033 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Oracle Driver""][0m
2024-07-23T16:11:28.036727229Z 2024-07-23 16:11:28,036 INFO plugins.dependencies :: [31mMetabase cannot initialize plugin Metabase Vertica Driver due to required dependencies.[0m Metabase requires the Vertica JDBC driver in order to connect to Vertica databases, but we can't ship it as part of Metabase due to licensing restrictions. See https://metabase.com/docs/latest/administration-guide/databases/vertica.html for more details.
2024-07-23T16:11:28.036755529Z
2024-07-23T16:11:28.037109634Z 2024-07-23 16:11:28,036 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false
2024-07-23T16:11:28.037580140Z 2024-07-23 16:11:28,037 INFO plugins.dependencies :: [33mPlugins with unsatisfied deps: [""Metabase Vertica Driver"" ""Metabase Oracle Driver""][0m
2024-07-23T16:11:28.041246186Z 2024-07-23 16:11:28,040 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlserver...[0m
2024-07-23T16:11:28.041794193Z 2024-07-23 16:11:28,041 INFO driver.impl :: [34mRegistered driver :sqlserver[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.059887023Z 2024-07-23 16:11:28,059 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :bigquery-cloud-sdk...[0m
2024-07-23T16:11:28.060170827Z 2024-07-23 16:11:28,059 INFO driver.impl :: [34mRegistered driver :bigquery-cloud-sdk[0m (parents: [:sql]) 🚚
2024-07-23T16:11:28.063422968Z 2024-07-23 16:11:28,063 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sqlite...[0m
2024-07-23T16:11:28.063794973Z 2024-07-23 16:11:28,063 INFO driver.impl :: [34mRegistered driver :sqlite[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.073428995Z 2024-07-23 16:11:28,073 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :athena...[0m
2024-07-23T16:11:28.073877201Z 2024-07-23 16:11:28,073 INFO driver.impl :: [34mRegistered driver :athena[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.077397746Z 2024-07-23 16:11:28,077 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :druid...[0m
2024-07-23T16:11:28.077747350Z 2024-07-23 16:11:28,077 INFO driver.impl :: [34mRegistered driver :druid[0m  🚚
2024-07-23T16:11:28.084787440Z 2024-07-23 16:11:28,084 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :hive-like...[0m
2024-07-23T16:11:28.085111344Z 2024-07-23 16:11:28,084 INFO driver.impl :: [34mRegistered abstract driver :hive-like[0m (parents: [:sql-jdbc]) 🚚
2024-07-23T16:11:28.085530049Z 2024-07-23 16:11:28,085 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :sparksql...[0m
2024-07-23T16:11:28.085849753Z 2024-07-23 16:11:28,085 INFO driver.impl :: [34mRegistered driver :sparksql[0m (parents: [:hive-like]) 🚚
2024-07-23T16:11:28.090885917Z 2024-07-23 16:11:28,090 DEBUG plugins.lazy-loaded-driver :: [35mRegistering lazy loading driver :mongo...[0m
2024-07-23T16:11:28.091158121Z 2024-07-23 16:11:28,090 INFO driver.impl :: [34mRegistered driver :mongo[0m  🚚
2024-07-23T16:11:28.097390300Z 2024-07-23 16:11:28,096 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-23T16:11:28.099289824Z 2024-07-23 16:11:28,099 INFO db.setup :: [36mVerifying mysql Database Connection ...[0m
2024-07-23T16:11:28.228225663Z 2024-07-23 16:11:28,227 INFO db.setup :: Successfully verified MySQL 8.0.32 application database connection. ✅
2024-07-23T16:11:28.228653968Z 2024-07-23 16:11:28,228 INFO db.setup :: [36mChecking if a database downgrade is required...[0m
2024-07-23T16:11:28.944560068Z 2024-07-23 16:11:28,944 INFO db.setup :: Running Database Migrations...
2024-07-23T16:11:28.946093587Z 2024-07-23 16:11:28,945 INFO db.setup :: Setting up Liquibase...
2024-07-23T16:11:29.153820728Z 2024-07-23 16:11:29,153 INFO db.setup :: Liquibase is ready.
2024-07-23T16:11:29.154096131Z 2024-07-23 16:11:29,153 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-23T16:11:29.691853467Z 2024-07-23 16:11:29,684 ERROR metabase.core :: Metabase Initialization FAILED
2024-07-23T16:11:29.691900667Z liquibase.exception.ValidationFailedException: Validation Failed:
2024-07-23T16:11:29.691906767Z      1 changesets check sum
2024-07-23T16:11:29.691910967Z           migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss was: 9:838ed8f582c11e79f574db21b2dcb999 but is now: 9:29e840f2e163f8795c220faee8201c81
2024-07-23T16:11:29.691915868Z
2024-07-23T16:11:29.691920468Z 	at liquibase.changelog.DatabaseChangeLog.validate(DatabaseChangeLog.java:358)
2024-07-23T16:11:29.691925468Z 	at liquibase.Liquibase.lambda$listUnrunChangeSets$20(Liquibase.java:1149)
2024-07-23T16:11:29.691929268Z 	at liquibase.Scope.lambda$child$0(Scope.java:186)
2024-07-23T16:11:29.691933068Z 	at liquibase.Scope.child(Scope.java:195)
2024-07-23T16:11:29.691950468Z 	at liquibase.Scope.child(Scope.java:185)
2024-07-23T16:11:29.691953568Z 	at liquibase.Scope.child(Scope.java:164)
2024-07-23T16:11:29.691956268Z 	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
2024-07-23T16:11:29.691959068Z 	at liquibase.Liquibase.listUnrunChangeSets(Liquibase.java:1141)
2024-07-23T16:11:29.691961968Z 	at liquibase.Liquibase.listUnrunChangeSets(Liquibase.java:1131)
2024-07-23T16:11:29.691964468Z 	at metabase.db.liquibase$unrun_migrations$fn__44491.invoke(liquibase.clj:186)
2024-07-23T16:11:29.691968268Z 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44476.invoke(liquibase.clj:140)
2024-07-23T16:11:29.691972168Z 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:150)
2024-07-23T16:11:29.691976468Z 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
2024-07-23T16:11:29.691982668Z 	at metabase.db.liquibase$unrun_migrations.invokeStatic(liquibase.clj:185)
2024-07-23T16:11:29.691986868Z 	at metabase.db.liquibase$unrun_migrations.invoke(liquibase.clj:176)
2024-07-23T16:11:29.691990869Z 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:346)
2024-07-23T16:11:29.691995069Z 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
2024-07-23T16:11:29.691998969Z 	at metabase.db.setup$migrate_BANG_$fn__53475.invoke(setup.clj:84)
2024-07-23T16:11:29.692002769Z 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44476.invoke(liquibase.clj:140)
2024-07-23T16:11:29.692007169Z 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
2024-07-23T16:11:29.692011169Z 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
2024-07-23T16:11:29.692015669Z 	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
2024-07-23T16:11:29.692019869Z 	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
2024-07-23T16:11:29.692024069Z 	at clojure.lang.RestFn.invoke(RestFn.java:425)
2024-07-23T16:11:29.692028169Z 	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
2024-07-23T16:11:29.692033669Z 	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
2024-07-23T16:11:29.692037769Z 	at metabase.db.setup$setup_db_BANG_$fn__53503$fn__53504.invoke(setup.clj:167)
2024-07-23T16:11:29.692041469Z 	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
2024-07-23T16:11:29.692045369Z 	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
2024-07-23T16:11:29.692049969Z 	at metabase.db.setup$setup_db_BANG_$fn__53503.invoke(setup.clj:161)
2024-07-23T16:11:29.692054369Z 	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
2024-07-23T16:11:29.692058269Z 	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
2024-07-23T16:11:29.692061969Z 	at metabase.db$setup_db_BANG_$fn__53528.invoke(db.clj:86)
2024-07-23T16:11:29.692070570Z 	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
2024-07-23T16:11:29.692075070Z 	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
2024-07-23T16:11:29.692078970Z 	at clojure.lang.RestFn.invoke(RestFn.java:421)
2024-07-23T16:11:29.692082970Z 	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
2024-07-23T16:11:29.692087470Z 	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
2024-07-23T16:11:29.692091670Z 	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
2024-07-23T16:11:29.692096070Z 	at metabase.core$init_BANG_.invoke(core.clj:165)
2024-07-23T16:11:29.692100370Z 	at metabase.core$start_normally.invokeStatic(core.clj:182)
2024-07-23T16:11:29.692104570Z 	at metabase.core$start_normally.invoke(core.clj:176)
2024-07-23T16:11:29.692108670Z 	at metabase.core$entrypoint.invokeStatic(core.clj:215)
2024-07-23T16:11:29.692112670Z 	at metabase.core$entrypoint.doInvoke(core.clj:209)
2024-07-23T16:11:29.692116770Z 	at clojure.lang.RestFn.invoke(RestFn.java:397)
2024-07-23T16:11:29.692120870Z 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
2024-07-23T16:11:29.692125070Z 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
2024-07-23T16:11:29.692129270Z 	at clojure.lang.Var.applyTo(Var.java:705)
2024-07-23T16:11:29.692133270Z 	at clojure.core$apply.invokeStatic(core.clj:667)
2024-07-23T16:11:29.692137470Z 	at clojure.core$apply.invoke(core.clj:662)
2024-07-23T16:11:29.692141470Z 	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
2024-07-23T16:11:29.692145670Z 	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
2024-07-23T16:11:29.692149371Z 	at clojure.lang.RestFn.invoke(RestFn.java:397)
2024-07-23T16:11:29.692153071Z 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
2024-07-23T16:11:29.692156671Z 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
2024-07-23T16:11:29.692160571Z 	at metabase.bootstrap.main(Unknown Source)
2024-07-23T16:11:29.693979694Z 2024-07-23 16:11:29,693 INFO metabase.core :: Metabase Shutting Down ...
2024-07-23T16:11:29.694571901Z 2024-07-23 16:11:29,694 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-07-23T16:11:29.702846606Z 2024-07-23 16:11:29,702 WARN db.liquibase :: ()
2024-07-23T16:11:29.703195711Z 2024-07-23 16:11:29,703 INFO metabase.core :: Metabase Shutdown COMPLETE
2024-07-23T16:11:41.396Z ERROR - Container app-metabase-size_0_85dcc28c for site app-metabase-size has exited, failing site start
2024-07-23T16:11:41.403Z ERROR - Container app-metabase-size_0_85dcc28c didn't respond to HTTP pings on port: 3000, failing site start. See container logs for debugging.`

### To Reproduce

Change image in docker run command.


### Expected behavior

Migrations successfully finished

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase in webapp azure
- Database MySQL 8.0.32
```


### Severity

metabase down

### Additional context

_No response_",pratesy,2024-07-23 16:15:48+00:00,[],2024-07-23 16:53:00+00:00,2024-07-23 16:25:26+00:00,https://github.com/metabase/metabase/issues/46005,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', '')]","[{'comment_id': 2245690291, 'issue_id': 2425596889, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/45967', 'created_at': datetime.datetime(2024, 7, 23, 16, 25, 26, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-23 16:25:26 UTC): Duplicate of https://github.com/metabase/metabase/issues/45967

"
2425438355,issue,closed,not_planned,"Dashboard parameter preview doesn't work in static embed modal when publishing a parameter as ""locked"" and change to ""editable""","### Describe the bug

This only happens to dashboard parameters, I've tested that native question parameter values work as expected.

Given a dashboard filter with dropdown values, if you statically embed this dashboard by setting the parameter as `locked` and publishing the dashboard, then change the parameter type to `editable`, when clicking on the filter, there won't be a dropdown value with this error from BE.
<details>

<summary>Expand the error details</summary>


```text
{
  ""allowed-param-slugs"": {
    ""bool"": ""disabled""
  },
  ""param-id"": ""22b759cb"",
  ""id->slug"": {
    ""22b759cb"": ""bool""
  },
  ""cause"": ""Cannot search for values: \""bool\"" is not an enabled parameter."",
  ""via"": [
    {
      ""type"": ""clojure.lang.ExceptionInfo"",
      ""message"": ""Cannot search for values: \""bool\"" is not an enabled parameter."",
      ""data"": {
        ""dashboard-id"": 667,
        ""dashboard-params"": [
          {
            ""name"": ""Bool"",
            ""slug"": ""bool"",
            ""id"": ""22b759cb"",
            ""type"": ""string/="",
            ""sectionId"": ""string""
          }
        ],
        ""allowed-param-slugs"": {
          ""bool"": ""disabled""
        },
        ""slug->id"": {
          ""bool"": ""22b759cb""
        },
        ""id->slug"": {
          ""22b759cb"": ""bool""
        },
        ""param-id"": ""22b759cb"",
        ""param-slug"": ""bool"",
        ""token-params"": {}
      },
      ""at"": [
        ""metabase.api.embed.common$dashboard_param_values"",
        ""invokeStatic"",
        ""common.clj"",
        481
      ]
    },
    {
      ""type"": ""clojure.lang.ExceptionInfo"",
      ""message"": ""Cannot search for values: \""bool\"" is not an enabled parameter."",
      ""data"": {
        ""status-code"": 400
      },
      ""at"": [
        ""metabase.api.embed.common$dashboard_param_values"",
        ""invokeStatic"",
        ""common.clj"",
        465
      ]
    }
  ],
  ""trace"": [
    [
      ""metabase.api.embed.common$dashboard_param_values"",
      ""invokeStatic"",
      ""common.clj"",
      465
    ],
    [
      ""metabase.api.embed.common$dashboard_param_values"",
      ""doInvoke"",
      ""common.clj"",
      441
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      497
    ],
    [
      ""metabase.api.preview_embed$fn__136207"",
      ""invokeStatic"",
      ""preview_embed.clj"",
      62
    ],
    [
      ""metabase.api.preview_embed$fn__136207"",
      ""invoke"",
      ""preview_embed.clj"",
      59
    ],
    [
      ""compojure.core$wrap_response$fn__26509"",
      ""invoke"",
      ""core.clj"",
      160
    ],
    [
      ""compojure.core$wrap_route_middleware$fn__26493"",
      ""invoke"",
      ""core.clj"",
      132
    ],
    [
      ""compojure.core$wrap_route_info$fn__26498"",
      ""invoke"",
      ""core.clj"",
      139
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      151
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""metabase.server.middleware.auth$enforce_authentication$fn__120093"",
      ""invoke"",
      ""auth.clj"",
      18
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$make_context$handler__26589"",
      ""invoke"",
      ""core.clj"",
      290
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      300
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""clojure.lang.Var"",
      ""invoke"",
      ""Var.java"",
      393
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""metabase.api.routes$fn__143084$fn__143085"",
      ""invoke"",
      ""routes.clj"",
      69
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.lang.AFunction$1"",
      ""doInvoke"",
      ""AFunction.java"",
      31
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""clojure.lang.AFn"",
      ""applyToHelper"",
      ""AFn.java"",
      160
    ],
    [
      ""clojure.lang.AFn"",
      ""applyTo"",
      ""AFn.java"",
      144
    ],
    [
      ""clojure.core$apply"",
      ""invokeStatic"",
      ""core.clj"",
      667
    ],
    [
      ""clojure.core$apply"",
      ""invoke"",
      ""core.clj"",
      662
    ],
    [
      ""metabase.server.routes$fn__144048$fn__144049"",
      ""doInvoke"",
      ""routes.clj"",
      73
    ],
    [
      ""clojure.lang.RestFn"",
      ""invoke"",
      ""RestFn.java"",
      436
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$make_context$handler__26589"",
      ""invoke"",
      ""core.clj"",
      290
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      300
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      153
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$wrap_route_matches$fn__26502"",
      ""invoke"",
      ""core.clj"",
      152
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      199
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$make_context$handler__26589"",
      ""invoke"",
      ""core.clj"",
      290
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      300
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522$respond_SINGLEQUOTE___26523"",
      ""invoke"",
      ""core.clj"",
      197
    ],
    [
      ""compojure.core$make_context$fn__26593"",
      ""invoke"",
      ""core.clj"",
      301
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""compojure.core$routes$fn__26521$f__26522"",
      ""invoke"",
      ""core.clj"",
      198
    ],
    [
      ""compojure.core$routes$fn__26521"",
      ""invoke"",
      ""core.clj"",
      200
    ],
    [
      ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__120332"",
      ""invoke"",
      ""exceptions.clj"",
      107
    ],
    [
      ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__120329"",
      ""invoke"",
      ""exceptions.clj"",
      96
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__120564$fn__120565$fn__120566"",
      ""invoke"",
      ""log.clj"",
      236
    ],
    [
      ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
      ""invokeStatic"",
      ""diagnostic.clj"",
      18
    ],
    [
      ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
      ""invoke"",
      ""diagnostic.clj"",
      12
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__120564$fn__120565"",
      ""invoke"",
      ""log.clj"",
      227
    ],
    [
      ""toucan2.execute$do_with_call_counts"",
      ""invokeStatic"",
      ""execute.clj"",
      112
    ],
    [
      ""toucan2.execute$do_with_call_counts"",
      ""invoke"",
      ""execute.clj"",
      103
    ],
    [
      ""metabase.server.middleware.log$log_api_call$fn__120564"",
      ""invoke"",
      ""log.clj"",
      226
    ],
    [
      ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__120138"",
      ""invoke"",
      ""browser_cookie.clj"",
      40
    ],
    [
      ""metabase.server.middleware.security$add_security_headers$fn__120280"",
      ""invoke"",
      ""security.clj"",
      240
    ],
    [
      ""ring.middleware.json$wrap_json_body$fn__144343"",
      ""invoke"",
      ""json.clj"",
      64
    ],
    [
      ""metabase.server.middleware.offset_paging$handle_paging$fn__120599"",
      ""invoke"",
      ""offset_paging.clj"",
      49
    ],
    [
      ""metabase.server.middleware.json$wrap_streamed_json_response$fn__74974"",
      ""invoke"",
      ""json.clj"",
      88
    ],
    [
      ""ring.middleware.keyword_params$wrap_keyword_params$fn__144440"",
      ""invoke"",
      ""keyword_params.clj"",
      55
    ],
    [
      ""ring.middleware.params$wrap_params$fn__144467"",
      ""invoke"",
      ""params.clj"",
      77
    ],
    [
      ""metabase.server.middleware.misc$maybe_set_site_url$fn__83239"",
      ""invoke"",
      ""misc.clj"",
      60
    ],
    [
      ""metabase.server.middleware.session$reset_session_timeout$fn__100349"",
      ""invoke"",
      ""session.clj"",
      568
    ],
    [
      ""metabase.server.middleware.session$bind_current_user$fn__100307$fn__100308"",
      ""invoke"",
      ""session.clj"",
      462
    ],
    [
      ""metabase.server.middleware.session$do_with_current_user"",
      ""invokeStatic"",
      ""session.clj"",
      441
    ],
    [
      ""metabase.server.middleware.session$do_with_current_user"",
      ""invoke"",
      ""session.clj"",
      424
    ],
    [
      ""metabase.server.middleware.session$bind_current_user$fn__100307"",
      ""invoke"",
      ""session.clj"",
      461
    ],
    [
      ""metabase.server.middleware.session$wrap_current_user_info$fn__100280"",
      ""invoke"",
      ""session.clj"",
      385
    ],
    [
      ""metabase.server.middleware.session$wrap_session_id$fn__100252"",
      ""invoke"",
      ""session.clj"",
      261
    ],
    [
      ""metabase.server.middleware.auth$wrap_static_api_key$fn__120101"",
      ""invoke"",
      ""auth.clj"",
      32
    ],
    [
      ""ring.middleware.cookies$wrap_cookies$fn__144255"",
      ""invoke"",
      ""cookies.clj"",
      200
    ],
    [
      ""metabase.server.middleware.misc$add_content_type$fn__83221"",
      ""invoke"",
      ""misc.clj"",
      28
    ],
    [
      ""metabase.server.middleware.misc$disable_streaming_buffering$fn__83247"",
      ""invoke"",
      ""misc.clj"",
      77
    ],
    [
      ""ring.middleware.gzip$wrap_gzip$fn__144305"",
      ""invoke"",
      ""gzip.clj"",
      86
    ],
    [
      ""metabase.server.middleware.request_id$wrap_request_id$fn__120614"",
      ""invoke"",
      ""request_id.clj"",
      9
    ],
    [
      ""metabase.server.middleware.misc$bind_request$fn__83250"",
      ""invoke"",
      ""misc.clj"",
      94
    ],
    [
      ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__120637"",
      ""invoke"",
      ""ssl.clj"",
      41
    ],
    [
      ""metabase.server$async_proxy_handler$fn__76030"",
      ""invoke"",
      ""server.clj"",
      77
    ],
    [
      ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
      ""handle"",
      null,
      -1
    ],
    [
      ""org.eclipse.jetty.server.handler.StatisticsHandler"",
      ""handle"",
      ""StatisticsHandler.java"",
      173
    ],
    [
      ""org.eclipse.jetty.server.handler.HandlerWrapper"",
      ""handle"",
      ""HandlerWrapper.java"",
      122
    ],
    [
      ""org.eclipse.jetty.server.Server"",
      ""handle"",
      ""Server.java"",
      563
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
      ""dispatch"",
      ""HttpChannel.java"",
      1598
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel"",
      ""dispatch"",
      ""HttpChannel.java"",
      753
    ],
    [
      ""org.eclipse.jetty.server.HttpChannel"",
      ""handle"",
      ""HttpChannel.java"",
      501
    ],
    [
      ""org.eclipse.jetty.server.HttpConnection"",
      ""onFillable"",
      ""HttpConnection.java"",
      287
    ],
    [
      ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
      ""succeeded"",
      ""AbstractConnection.java"",
      314
    ],
    [
      ""org.eclipse.jetty.io.FillInterest"",
      ""fillable"",
      ""FillInterest.java"",
      100
    ],
    [
      ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
      ""run"",
      ""SelectableChannelEndPoint.java"",
      53
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""runTask"",
      ""AdaptiveExecutionStrategy.java"",
      421
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""consumeTask"",
      ""AdaptiveExecutionStrategy.java"",
      390
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""tryProduce"",
      ""AdaptiveExecutionStrategy.java"",
      277
    ],
    [
      ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
      ""run"",
      ""AdaptiveExecutionStrategy.java"",
      199
    ],
    [
      ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
      ""run"",
      ""ReservedThreadExecutor.java"",
      411
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
      ""runJob"",
      ""QueuedThreadPool.java"",
      969
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
      ""doRunJob"",
      ""QueuedThreadPool.java"",
      1194
    ],
    [
      ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
      ""run"",
      ""QueuedThreadPool.java"",
      1149
    ],
    [
      ""java.lang.Thread"",
      ""run"",
      ""Thread.java"",
      1583
    ]
  ],
  ""dashboard-params"": [
    {
      ""name"": ""Bool"",
      ""slug"": ""bool"",
      ""id"": ""22b759cb"",
      ""type"": ""string/="",
      ""sectionId"": ""string""
    }
  ],
  ""slug->id"": {
    ""bool"": ""22b759cb""
  },
  ""dashboard-id"": 667,
  ""token-params"": {},
  ""param-slug"": ""bool"",
  ""message"": ""Cannot search for values: \""bool\"" is not an enabled parameter."",
  ""data"": {
    ""status-code"": 400
  }
}
```
</details>

### To Reproduce

1. Create a dashboard with a question e.g. Orders
2. Add a filter and connect to a field that would result in a dropdown value e.g. Category
3. Open static embed sharing modal > Go to the Parameters tab
4. Change the filter type to `Editable` and click Preview > Then click the filter in the preview, the preview should show the dropdown values.
5. Change the filter type to `Locked` and publish the embed
6. Change the filter type back to `Editable` > Then click the filter in the preview, the preview will _not_ show any dropdown values, it will only show a text box. If you observe the network request at this step you should see the error in the description above.

### Expected behavior

The parameter values endpoint should work regardless of the published status of the parameter.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master @ 3bf053c4912eb08e0cdbcdb7947566c276af22ec

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-20"",
      ""src_hash"": ""2d1f1a7b6d411a36ba96c0c09499b81fcc479372"",
      ""tag"": ""v1.1.23-SNAPSHOT"",
      ""hash"": ""4486d36""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Non blocking, since the actual embed is working

### Additional context

_No response_",WiNloSt,2024-07-23 14:59:41+00:00,[],2024-08-14 13:01:37+00:00,2024-08-14 13:01:12+00:00,https://github.com/metabase/metabase/issues/45997,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2288678995, 'issue_id': 2425438355, 'author': 'kulyk', 'body': 'Can no longer reproduce, should have been fixed at some point\r\n\r\nhttps://github.com/user-attachments/assets/78d99054-7341-4ceb-b98e-2094e78a701b', 'created_at': datetime.datetime(2024, 8, 14, 13, 1, 12, tzinfo=datetime.timezone.utc)}]","kulyk on (2024-08-14 13:01:12 UTC): Can no longer reproduce, should have been fixed at some point

https://github.com/user-attachments/assets/78d99054-7341-4ceb-b98e-2094e78a701b

"
2425112281,issue,closed,completed,"""Reset all filters"" button",,kamilmielnik,2024-07-23 12:37:38+00:00,['kamilmielnik'],2024-08-05 14:29:42+00:00,2024-08-05 09:18:50+00:00,https://github.com/metabase/metabase/issues/45984,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2425112213,issue,closed,completed,"Update ""Clear"" and ""Reset"" buttons","- update UI (~background~, tooltip, icon)
- update when buttons are displayed

product doc: https://www.notion.so/metabase/Reset-dashboard-filters-eeb554324b00457bb1daa250b41bf0e5
testing plan: #45977",kamilmielnik,2024-07-23 12:37:36+00:00,['kamilmielnik'],2024-08-05 12:29:31+00:00,2024-08-05 08:48:06+00:00,https://github.com/metabase/metabase/issues/45983,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2424872153,issue,closed,completed,[Testing plan] Reset dashboard filters ,"Testing plan for #45935

## ""Clear"" & ""Reset"" buttons

Testing plan for #45983

### Dimensions

- Type of filter
    - dashboard
        - unit of time
        - time
        - location (single-value & multi-value)
        - id (single-value & multi-value)
        - number (single-value & multi-value)
        - text (single-value & multi-value)
    - sql editor
        - text
        - number
        - date
        - field filter
- Presence of default value (with / without)
- Current value (empty, same as default, different than default)
- Is filter required (yes / no)

### Unit tests

- [x] clear & reset buttons have tooltips

### e2e tests

For all filter types and for both single-value & multi-value inputs check if correct icon is shown and if it works as expected:
  - [x] Dashboard - default value input parameter sidebar (required / non-required)
    - [x] no current value -> chevron icon
    - [x] has current value -> clear icon
  - [x] Dashboard filters
    - [x] no current value / no default value / non-required -> no icon
    - [x] has current value / no default value / non-required -> clear icon
    - [x] no current value / has default value / non-required -> reset icon
    - [x] current value different than default / has default value / non-required -> reset icon
    - [x] current value same as default / has default value / non-required -> clear icon
    - [x] current value different than default / has default value / required -> reset icon
    - [x] current value same as default / has default value / required -> no icon
  - [x] can reset to default ""1,2,3"" number parameters and has correct URL (see #25374 and [Slack](https://metaboat.slack.com/archives/C0645JP1W81/p1721745604147769?thread_ts=1721745372.566439&cid=C0645JP1W81)):
      - https://github.com/metabase/metabase/blob/437684cd3d871e7f94a77004d62bd104d72dd69c/frontend/src/metabase-lib/v1/parameters/utils/parameter-parsing.ts#L38
      - https://github.com/metabase/metabase/blob/437684cd3d871e7f94a77004d62bd104d72dd69c/frontend/src/metabase-lib/v1/parameters/utils/parameter-parsing.ts#L76
  - [x] SQL Editor - default value input parameter sidebar (required / non-required)
    - [x] no current value -> chevron or no icon
    - [x] has current value -> clear icon
  - [x] SQL Editor filters
    - [x] all icon-related ""Dashboard filters"" cases listed above :point_up: 
    - [x] no current value / no default value / required -> no icon
    - [x] has current value / no default value / required -> clear icon
    - [x] no current value / has default value / required -> reset icon

## ""Reset all filters"" button

Testing plan for #45984

### Dimensions

- Auto-apply filters (on / off)
- Tabs (multiple)
- Presence of default value (with / without)
- Current value (empty, same as default, different than default)

### Unit tests

- [x] there will be a new function that will determine whether the button is shown, it needs to be unit-tested

### e2e tests

For all filter types and for both single-value & multi-value inputs check if correct icon is shown and if it works as expected:
  - [x] is shown only when at least one filter has a value different from its default (if it has a default) or just any value if it doesn’t have a default (use cases from the first list in this file)
      - [x] no current value / no default value -> not shown
      - [x] has current value / no default value -> shown
      - [x] no current value / has default value -> shown
      - [x] current value different than default / has default value -> shown
      - [x] current value same as default / has default value -> not shown
  - [x] works correctly on all tabs with Auto-apply filters on
  - [x] works correctly on all tabs with Auto-apply filters off
- [x] can reset to default ""1,2,3"" number parameters and has correct URL (see #25374 and [Slack](https://metaboat.slack.com/archives/C0645JP1W81/p1721745604147769?thread_ts=1721745372.566439&cid=C0645JP1W81)):
    - https://github.com/metabase/metabase/blob/437684cd3d871e7f94a77004d62bd104d72dd69c/frontend/src/metabase-lib/v1/parameters/utils/parameter-parsing.ts#L38
    - https://github.com/metabase/metabase/blob/437684cd3d871e7f94a77004d62bd104d72dd69c/frontend/src/metabase-lib/v1/parameters/utils/parameter-parsing.ts#L76
",kamilmielnik,2024-07-23 10:44:55+00:00,['kamilmielnik'],2024-10-31 10:45:38+00:00,2024-10-31 10:45:37+00:00,https://github.com/metabase/metabase/issues/45977,"[('.TestingStrategy/FE', '')]","[{'comment_id': 2449555310, 'issue_id': 2424872153, 'author': 'kamilmielnik', 'body': 'Implemented, closing', 'created_at': datetime.datetime(2024, 10, 31, 10, 45, 37, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-10-31 10:45:37 UTC): Implemented, closing

"
2424539121,issue,closed,completed,Cant start service after upgrade to 0.50.14,"### Describe the bug

Upgrade jar from 0.50.13 to 0.50.14

```
Jul 23 07:53:53 metabase metabase[26508]: 2024-07-23 07:53:53,254 ERROR metabase.core :: Metabase Initialization FAILED
Jul 23 07:53:53 metabase metabase[26508]: liquibase.exception.ValidationFailedException: Validation Failed:
Jul 23 07:53:53 metabase metabase[26508]:      1 changesets check sum
Jul 23 07:53:53 metabase metabase[26508]:           migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss was: 9:838ed8f582c11e79f574db21b2dcb999 but is now: 9:29e840f2e163f8795c220faee8201c81
```

### To Reproduce

1. Stop metabse service
2. replace metabase.jar to new version
3. restart service
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Ubuntu 22.04.4 LTS (GNU/Linux 5.15.0-116-generic x86_64)
- mysql  Ver 8.0.37-0ubuntu0.22.04.3
- metabase version 0.50.14
```


### Severity

blocking usage

### Additional context

_No response_",Gemorroj,2024-07-23 08:03:03+00:00,[],2024-07-24 09:52:39+00:00,2024-07-23 13:38:55+00:00,https://github.com/metabase/metabase/issues/45967,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2244621561, 'issue_id': 2424539121, 'author': 'lomby', 'body': 'I have the same thing running from the latest docker image\r\n```\r\n2024-07-23 08:45:55,290 INFO db.liquibase :: Checking if Database has unrun migrations...\r\n2024-07-23 08:45:56,455 ERROR metabase.core :: Metabase Initialization FAILED\r\nliquibase.exception.ValidationFailedException: Validation Failed:\r\n     1 changesets check sum\r\n          migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss was: 9:838ed8f582c11e79f574db21b2dcb999 but is now: 9:29e840f2e163f8795c220faee8201c81\r\n          ```', 'created_at': datetime.datetime(2024, 7, 23, 8, 48, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244624621, 'issue_id': 2424539121, 'author': 'thomaskglas', 'body': 'Same here', 'created_at': datetime.datetime(2024, 7, 23, 8, 49, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244850087, 'issue_id': 2424539121, 'author': 'jcaloudgroover', 'body': 'Same here', 'created_at': datetime.datetime(2024, 7, 23, 10, 33, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245252431, 'issue_id': 2424539121, 'author': 'willnaoosmith', 'body': 'Same here', 'created_at': datetime.datetime(2024, 7, 23, 13, 25, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245360391, 'issue_id': 2424539121, 'author': 'kmogilevskii', 'body': 'I dropped everything from DATABASECHANGELOG and DATABASECHANGELOGLOCK and it startedd to work.\r\n\r\nOtherwise returning to v1.50.13 works as well.', 'created_at': datetime.datetime(2024, 7, 23, 14, 7, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245517894, 'issue_id': 2424539121, 'author': 'michael-murtagh', 'body': 'Same!', 'created_at': datetime.datetime(2024, 7, 23, 15, 10, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247427071, 'issue_id': 2424539121, 'author': 'qnkhuat', 'body': '> I dropped everything from DATABASECHANGELOG and DATABASECHANGELOGLOCK and it startedd to work.\r\n\r\n@kmogilevskii \r\nwhat do you mean by this?\r\n\r\nIn general you should never touch `databasechangelog` manually. If you drop all rows, then upgrade will try to re-run all the migrations again and can destroy your application DB.', 'created_at': datetime.datetime(2024, 7, 24, 9, 48, 55, tzinfo=datetime.timezone.utc)}]","lomby on (2024-07-23 08:48:29 UTC): I have the same thing running from the latest docker image
```
2024-07-23 08:45:55,290 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-23 08:45:56,455 ERROR metabase.core :: Metabase Initialization FAILED
liquibase.exception.ValidationFailedException: Validation Failed:
     1 changesets check sum
          migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss was: 9:838ed8f582c11e79f574db21b2dcb999 but is now: 9:29e840f2e163f8795c220faee8201c81
          ```

thomaskglas on (2024-07-23 08:49:52 UTC): Same here

jcaloudgroover on (2024-07-23 10:33:45 UTC): Same here

willnaoosmith on (2024-07-23 13:25:56 UTC): Same here

kmogilevskii on (2024-07-23 14:07:39 UTC): I dropped everything from DATABASECHANGELOG and DATABASECHANGELOGLOCK and it startedd to work.

Otherwise returning to v1.50.13 works as well.

michael-murtagh on (2024-07-23 15:10:03 UTC): Same!

qnkhuat on (2024-07-24 09:48:55 UTC): @kmogilevskii 
what do you mean by this?

In general you should never touch `databasechangelog` manually. If you drop all rows, then upgrade will try to re-run all the migrations again and can destroy your application DB.

"
2423697120,issue,closed,completed,Download full results for Bigquery tables is giving duplicated data in file,"### Describe the bug

We majorly use bigquery and it was working fine until 0.50.13 version
After upgrading to 0.50.13, when we are writing questions with filter conditions and downloading data > 1 lakh records, then in result csv file some rows are getting repeated and some are missing.

### To Reproduce

1. Go to 'any large bigquery table and apply filter conditions'
2. Click on 'Download full results'
3. summerise and see count in metabase
4. see records count in file
5. records in file are more and repeating


### Expected behavior

after downloading, count of records in file should match actual records in bigquery table

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.177+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo"",
      ""postgres"",
      ""bigquery-cloud-sdk"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.19""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v0.50.13"",
      ""hash"": ""2086968""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Kolkata""
    }
  }
}
```


### Severity

blocking my usage of Metabase entirely

### Additional context

_No response_",shubz-zoop,2024-07-22 20:17:10+00:00,['adam-james-v'],2024-07-25 16:03:58+00:00,2024-07-25 15:10:35+00:00,https://github.com/metabase/metabase/issues/45953,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Export', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2243829302, 'issue_id': 2423697120, 'author': 'perivamsi', 'body': '@shubz-zoop which version of Metabase were you using before where this worked?', 'created_at': datetime.datetime(2024, 7, 22, 21, 16, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244354855, 'issue_id': 2423697120, 'author': 'shubz-zoop', 'body': '@perivamsi  i have not taken a note of metabase pervious version but here is docker image metabase/metabase@sha256:28e8a33cfa70e8126d96727b201e6f1888938376e376063a066225469171eb17\r\n\r\nedit: previous metabase version v0.47.5', 'created_at': datetime.datetime(2024, 7, 23, 6, 30, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2246733931, 'issue_id': 2423697120, 'author': 'kasinathreddy', 'body': 'Metabase version : 0.50.14\r\nQuery used : `SELECT id from UNNEST(GENERATE_ARRAY(1,516667)) id;`\r\nFor above query I have exported results as a csv ended up with 7lakh records where id is available from 1 to 350000 and it is exactly duplicated twice\r\nYou can test this query without any dependency of the table or filters', 'created_at': datetime.datetime(2024, 7, 24, 2, 18, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2246774862, 'issue_id': 2423697120, 'author': 'perivamsi', 'body': 'Thanks @kasinathreddy \r\n\r\nThis also repros the issue very clearly\r\n\r\n`SELECT id from UNNEST(GENERATE_ARRAY(1,350001)) id;`\r\n\r\nBut this works fine\r\n\r\n`SELECT id from UNNEST(GENERATE_ARRAY(1,350000)) id;`', 'created_at': datetime.datetime(2024, 7, 24, 3, 6, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2246804284, 'issue_id': 2423697120, 'author': 'kasinathreddy', 'body': '@adam-james-v \r\nKindly let us know when a patch fix can be expected for the above', 'created_at': datetime.datetime(2024, 7, 24, 3, 43, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247276199, 'issue_id': 2423697120, 'author': 'perivamsi', 'body': ""@kasinathreddy we are working on it, don't have an ETA yet unfortunately"", 'created_at': datetime.datetime(2024, 7, 24, 8, 54, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247330548, 'issue_id': 2423697120, 'author': 'kasinathreddy', 'body': ""@perivamsi \r\nIt is currently blocking lot of our work, we have decided to roll the version back to 0.49 and while setting it up we are getting issue as **Unknown column report_card.dataset in field list**\r\nSo currently we are fully blocked because there is no patch fix and reverting back isn't helping either"", 'created_at': datetime.datetime(2024, 7, 24, 9, 15, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247334620, 'issue_id': 2423697120, 'author': 'perivamsi', 'body': 'Can you send me the full logs for rollback?', 'created_at': datetime.datetime(2024, 7, 24, 9, 17, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247438840, 'issue_id': 2423697120, 'author': 'shubz-zoop', 'body': 'rollback will create problem with database. it will ask for database downgrade before metabase downgrade..\r\n\r\nour work is also affected allot because of this issue.. we need it before month end', 'created_at': datetime.datetime(2024, 7, 24, 9, 53, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247451532, 'issue_id': 2423697120, 'author': 'shubz-zoop', 'body': '@perivamsi  is it possible to downgrade to previous version 0.47.5 from current updated version 0.50.13 without previous postgres database backup?', 'created_at': datetime.datetime(2024, 7, 24, 9, 59, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247767946, 'issue_id': 2423697120, 'author': 'perivamsi', 'body': ""Can you downgrade to [0.49.21](https://github.com/metabase/metabase/releases/tag/v0.49.21)? You don't need to restore postgres db backup for that. Just follow the [instructions here](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade). Please don't downgrade to 47 though, these instructions wont work for downgrading multiple versions."", 'created_at': datetime.datetime(2024, 7, 24, 12, 18, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247905676, 'issue_id': 2423697120, 'author': 'kasinathreddy', 'body': 'I downgraded it to 0.49.21 and it fixed the issue for me', 'created_at': datetime.datetime(2024, 7, 24, 13, 15, 55, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-22 21:16:47 UTC): @shubz-zoop which version of Metabase were you using before where this worked?

shubz-zoop (Issue Creator) on (2024-07-23 06:30:02 UTC): @perivamsi  i have not taken a note of metabase pervious version but here is docker image metabase/metabase@sha256:28e8a33cfa70e8126d96727b201e6f1888938376e376063a066225469171eb17

edit: previous metabase version v0.47.5

kasinathreddy on (2024-07-24 02:18:58 UTC): Metabase version : 0.50.14
Query used : `SELECT id from UNNEST(GENERATE_ARRAY(1,516667)) id;`
For above query I have exported results as a csv ended up with 7lakh records where id is available from 1 to 350000 and it is exactly duplicated twice
You can test this query without any dependency of the table or filters

perivamsi on (2024-07-24 03:06:58 UTC): Thanks @kasinathreddy 

This also repros the issue very clearly

`SELECT id from UNNEST(GENERATE_ARRAY(1,350001)) id;`

But this works fine

`SELECT id from UNNEST(GENERATE_ARRAY(1,350000)) id;`

kasinathreddy on (2024-07-24 03:43:19 UTC): @adam-james-v 
Kindly let us know when a patch fix can be expected for the above

perivamsi on (2024-07-24 08:54:50 UTC): @kasinathreddy we are working on it, don't have an ETA yet unfortunately

kasinathreddy on (2024-07-24 09:15:44 UTC): @perivamsi 
It is currently blocking lot of our work, we have decided to roll the version back to 0.49 and while setting it up we are getting issue as **Unknown column report_card.dataset in field list**
So currently we are fully blocked because there is no patch fix and reverting back isn't helping either

perivamsi on (2024-07-24 09:17:49 UTC): Can you send me the full logs for rollback?

shubz-zoop (Issue Creator) on (2024-07-24 09:53:39 UTC): rollback will create problem with database. it will ask for database downgrade before metabase downgrade..

our work is also affected allot because of this issue.. we need it before month end

shubz-zoop (Issue Creator) on (2024-07-24 09:59:52 UTC): @perivamsi  is it possible to downgrade to previous version 0.47.5 from current updated version 0.50.13 without previous postgres database backup?

perivamsi on (2024-07-24 12:18:49 UTC): Can you downgrade to [0.49.21](https://github.com/metabase/metabase/releases/tag/v0.49.21)? You don't need to restore postgres db backup for that. Just follow the [instructions here](https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase#rolling-back-an-upgrade). Please don't downgrade to 47 though, these instructions wont work for downgrading multiple versions.

kasinathreddy on (2024-07-24 13:15:55 UTC): I downgraded it to 0.49.21 and it fixed the issue for me

"
2423685208,issue,closed,completed,Embedding SDK Analytics: BE Plan,"**Context**

We want to save some more information about how users are utilizing our embedding SDK. We will save the version and client info, and expose it when summarizing executions.


## Plan

1. [x] Add a middleware and dynamic vars
In our api middleware stack we will put another async middleware that reads from `X-Metabase-Client` and `X-Metabase-Client-Version` headers, and uses information there to set the `*sdk-metabase-client*` and `*sdk-metabase-client-version*` dynamic vars respectively.
2. [x] Add a migration
add `client` and `client_version` varchar 64 columns to `query_execution` and `view_log`

3. [x] Fill the columns
We will add a middleware to the query processor that reads from the dynamic vars mentioned above and writes the required information.
    3.1 [x]  Write the info for the embedding `client` and `client_version` to `query_execution` and `view_log` tables when they are set.

4. ~Include the data for this in [`summarize-executions`](https://github.com/metabase/metabase/blob/master/src/metabase/analytics/stats.clj#L365)~.

I've decided this should be sequenced in the Migrate-Anonymous-Stats-ping-to-Snowplow project, because there isn't a clear place to put this info, and the way it is currently computed gets reused on a per-user basis too.

",escherize,2024-07-22 20:09:17+00:00,['escherize'],2024-10-08 16:19:29+00:00,2024-07-26 16:48:08+00:00,https://github.com/metabase/metabase/issues/45952,"[('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2253026154, 'issue_id': 2423685208, 'author': 'escherize', 'body': 'This needs to work across a thread boundry, being adressed in #46173.', 'created_at': datetime.datetime(2024, 7, 26, 15, 41, 55, tzinfo=datetime.timezone.utc)}]","escherize (Issue Creator) on (2024-07-26 15:41:55 UTC): This needs to work across a thread boundry, being adressed in #46173.

"
2423595048,issue,open,,No button to create new dashboard or collection on Recents tab,"### Describe the bug

In contexts like ""Add this question to a dashboard"" or ""Move this [item] to a collection"", the picker opens on the ""Recents"" tab, which does not have the button to create a new dashboard/collection etc. Unless you already know that the other tabs do have that button, you get kind of blocked if what you want is to create a new dashboard.

### To Reproduce

1. Open question
2. Click on '...'
3. Click on Add this question to a dashboard
4. See data picker opened on the Recents tab
5. There is no Create a new dashboard button there, only on the Dashboards tab

1. Open question
2. Click on '...'
3. Click on Move
4. See data picker opened on the Recents tab
5. There is no Create a new collection button there, only on the Collections tab


### Expected behavior

In these contexts, there should be Create a new dashboard button or Create a new collection button respectively

### Logs

_No response_

### Information about your Metabase installation

```JSON
e02589a
```


### Severity

Blocks some use cases

### Additional context

_No response_",mngr,2024-07-22 19:13:20+00:00,[],2024-07-24 16:15:02+00:00,,https://github.com/metabase/metabase/issues/45949,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2423587920,issue,closed,completed,"If `driver/describe-database` throws an error, `sync/sync-database!` does not handle it correctly","So it looks like `metabase.sync.sync-metadata/sync-db-metadata!` can return either an instance of a `Throwable` or a map (this seems to be on purpose since `metabase.sync.util/do-with-error-handling` has that logic, however calling code assumes it always returns a map and triggers a different error that makes logs confusing

https://github.com/metabase/metabase/blob/89dc03f2c747f579dceda8e4624509b697d0339a/src/metabase/sync.clj#L52

you can see that happening in this test run https://github.com/metabase/metabase/actions/runs/10038716376/job/27748689824#step:3:1397

```
[main] ERROR metabase.test.data.impl.get-or-create - Failed to sync test database ""diff-time-zones-cases"": Invalid output: [""invalid type, got: #error {\n :cause \""class com.amazon.redshift.util.RedshiftException cannot be cast to class clojure.lang.Associative (com.amazon.redshift.util.RedshiftException and clojure.lang.Associative are in unnamed module of loader 'app')\""\n :via\n [{:type java.lang.ClassCastException\n   :message \""class com.amazon.redshift.util.RedshiftException cannot be cast to class clojure.lang.Associative (com.amazon.redshift.util.RedshiftException and clojure.lang.Associative are in unnamed module of loader 'app')\""\n   :at [clojure.lang.RT assoc \""RT.java\"" 827]}]\n :trace\n [[clojure.lang.RT assoc \""RT.java\"" 827]\n  [clojure.core$assoc__5481 invokeStatic \""core.clj\"" 193]\n  [clojure.core$assoc__5481 invoke \""core.clj\"" 192]\n  [metabase.sync$fn__117877$_AMPERSAND_f__117879$fn__117881 invoke \""sync.clj\"" 52]\n  [metabase.sync.util$do_with_error_handling invokeStatic \""util.clj\"" 188]\n  [metabase.sync.util$do_with_error_handling invoke \""util.clj\"" 181]\n  [clojure.core$partial$fn__5910 invoke \""core.clj\"" 2647]\n  [metabase.driver$eval76273$fn__76274 invoke \""driver.clj\"" 884]\n  [clojure.lang.MultiFn invoke \""MultiFn.java\"" 239]\n  [metabase.sync.util$sync_in_context$fn__82219 invoke \""util.clj\"" 164]\n  [metabase.sync.util$with_db_logging_disabled$fn__82216 invoke \""util.clj\"" 156]\n  [metabase.sync.util$with_start_and_finish_logging_STAR_ invokeStatic \""util.clj\"" 129]\n  [metabase.sync.util$with_start_and_finish_logging_STAR_ invoke \""util.clj\"" 123]\n  [metabase.sync.util$with_start_and_finish_logging$fn__82203 invoke \""util.clj\"" 141]\n  [metabase.sync.util$fn__82190$_AMPERSAND_f__82191$fn__82195 invoke \""util.clj\"" 115]\n  [metabase.sync.util$with_duplicate_ops_prevented$fn__82180 invoke \""util.clj\"" 87]\n  [metabase.sync.util$fn__82238$_AMPERSAND_f__82239 invoke \""util.clj\"" 213]\n  [metabase.sync.util$fn__82238$fn__82241 invoke \""util.clj\"" 207]\n  [metabase.sync$fn__117877$_AMPERSAND_f__117879 invoke \""sync.clj\"" 51]\n  [metabase.sync$fn__117877$fn__117885 invoke \""sync.clj\"" 37]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190$fn__147194$fn__147195 invoke \""get_or_create.clj\"" 137]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190$fn__147194 invoke \""get_or_create.clj\"" 136]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190 invoke \""get_or_create.clj\"" 128]\n  [clojure.core$binding_conveyor_fn$fn__5823 invoke \""core.clj\"" 2047]\n  [clojure.lang.AFn call \""AFn.java\"" 18]\n  [java.util.concurrent.FutureTask run \""FutureTask.java\"" 264]\n  [java.util.concurrent.ThreadPoolExecutor runWorker \""ThreadPoolExecutor.java\"" 1128]\n  [java.util.concurrent.ThreadPoolExecutor$Worker run \""ThreadPoolExecutor.java\"" 628]\n  [java.lang.Thread run \""Thread.java\"" 829]]}""]
clojure.lang.ExceptionInfo: Failed to sync test database ""diff-time-zones-cases"": Invalid output: [""invalid type, got: #error {\n :cause \""class com.amazon.redshift.util.RedshiftException cannot be cast to class clojure.lang.Associative (com.amazon.redshift.util.RedshiftException and clojure.lang.Associative are in unnamed module of loader 'app')\""\n :via\n [{:type java.lang.ClassCastException\n   :message \""class com.amazon.redshift.util.RedshiftException cannot be cast to class clojure.lang.Associative (com.amazon.redshift.util.RedshiftException and clojure.lang.Associative are in unnamed module of loader 'app')\""\n   :at [clojure.lang.RT assoc \""RT.java\"" 827]}]\n :trace\n [[clojure.lang.RT assoc \""RT.java\"" 827]\n  [clojure.core$assoc__5481 invokeStatic \""core.clj\"" 193]\n  [clojure.core$assoc__5481 invoke \""core.clj\"" 192]\n  [metabase.sync$fn__117877$_AMPERSAND_f__117879$fn__117881 invoke \""sync.clj\"" 52]\n  [metabase.sync.util$do_with_error_handling invokeStatic \""util.clj\"" 188]\n  [metabase.sync.util$do_with_error_handling invoke \""util.clj\"" 181]\n  [clojure.core$partial$fn__5910 invoke \""core.clj\"" 2647]\n  [metabase.driver$eval76273$fn__76274 invoke \""driver.clj\"" 884]\n  [clojure.lang.MultiFn invoke \""MultiFn.java\"" 239]\n  [metabase.sync.util$sync_in_context$fn__82219 invoke \""util.clj\"" 164]\n  [metabase.sync.util$with_db_logging_disabled$fn__82216 invoke \""util.clj\"" 156]\n  [metabase.sync.util$with_start_and_finish_logging_STAR_ invokeStatic \""util.clj\"" 129]\n  [metabase.sync.util$with_start_and_finish_logging_STAR_ invoke \""util.clj\"" 123]\n  [metabase.sync.util$with_start_and_finish_logging$fn__82203 invoke \""util.clj\"" 141]\n  [metabase.sync.util$fn__82190$_AMPERSAND_f__82191$fn__82195 invoke \""util.clj\"" 115]\n  [metabase.sync.util$with_duplicate_ops_prevented$fn__82180 invoke \""util.clj\"" 87]\n  [metabase.sync.util$fn__82238$_AMPERSAND_f__82239 invoke \""util.clj\"" 213]\n  [metabase.sync.util$fn__82238$fn__82241 invoke \""util.clj\"" 207]\n  [metabase.sync$fn__117877$_AMPERSAND_f__117879 invoke \""sync.clj\"" 51]\n  [metabase.sync$fn__117877$fn__117885 invoke \""sync.clj\"" 37]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190$fn__147194$fn__147195 invoke \""get_or_create.clj\"" 137]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190$fn__147194 invoke \""get_or_create.clj\"" 136]\n  [metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_$fn__147190 invoke \""get_or_create.clj\"" 128]\n  [clojure.core$binding_conveyor_fn$fn__5823 invoke \""core.clj\"" 2047]\n  [clojure.lang.AFn call \""AFn.java\"" 18]\n  [java.util.concurrent.FutureTask run \""FutureTask.java\"" 264]\n  [java.util.concurrent.ThreadPoolExecutor runWorker \""ThreadPoolExecutor.java\"" 1128]\n  [java.util.concurrent.ThreadPoolExecutor$Worker run \""ThreadPoolExecutor.java\"" 628]\n  [java.lang.Thread run \""Thread.java\"" 829]]}""]
	at metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_.invokeStatic(get_or_create.clj:145) [?:?]
	at metabase.test.data.impl.get_or_create$sync_newly_created_database_BANG_.invoke(get_or_create.clj:120) [?:?]
	at metabase.test.data.impl.get_or_create$fn__147267$_AMPERSAND_f__147269.invoke(get_or_create.clj:265) [?:?]
	at metabase.test.data.impl.get_or_create$fn__147267$fn__147272.invoke(get_or_create.clj:253) [?:?]
	at metabase.test.data.impl.get_or_create$create_database_BANG_.invokeStatic(get_or_create.clj:276) [?:?]
	at metabase.test.data.impl.get_or_create$create_database_BANG_.invoke(get_or_create.clj:272) [?:?]
	at metabase.test.data.impl.get_or_create$create_database_with_bound_settings_BANG_$thunk__147280.invoke(get_or_create.clj:286) [?:?]
	at metabase.test.util$do_with_temporary_setting_value.invokeStatic(util.clj:450) [?:?]
	at metabase.test.util$do_with_temporary_setting_value.doInvoke(util.clj:406) [?:?]
	at clojure.lang.RestFn.invoke(RestFn.java:445) [clojure-1.11.2.jar:?]
	at clojure.lang.Var.invoke(Var.java:393) [clojure-1.11.2.jar:?]
	at metabase.test.data.impl.get_or_create$create_database_with_bound_settings_BANG_.invokeStatic(get_or_create.clj:292) [?:?]
	at metabase.test.data.impl.get_or_create$create_database_with_bound_settings_BANG_.invoke(get_or_create.clj:282) [?:?]
	at metabase.test.data.impl.get_or_create$create_and_sync_database_with_write_lock_BANG_.invokeStatic(get_or_create.clj:303) [?:?]
	at metabase.test.data.impl.get_or_create$create_and_sync_database_with_write_lock_BANG_.invoke(get_or_create.clj:297) [?:?]
	at metabase.test.data.impl.get_or_create$default_get_or_create_database_BANG_.invokeStatic(get_or_create.clj:343) [?:?]
	at metabase.test.data.impl.get_or_create$default_get_or_create_database_BANG_.invoke(get_or_create.clj:334) [?:?]
	at metabase.test.data.impl$eval147408$fn__147409.invoke(impl.clj:41) [?:?]
	at clojure.lang.MultiFn.invoke(MultiFn.java:234) [clojure-1.11.2.jar:?]
	at metabase.test.data.impl$do_with_dataset$fn__147594.invoke(impl.clj:377) [?:?]
	at clojure.lang.AFn.applyToHelper(AFn.java:154) [clojure-1.11.2.jar:?]
	at clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:667) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invoke(core.clj:662) [clojure-1.11.2.jar:?]
	at metabase.db$memoize_for_application_db$fn__74145.doInvoke(db.clj:104) [?:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:139) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:667) [clojure-1.11.2.jar:?]
	at clojure.core$memoize$fn__6946.doInvoke(core.clj:6389) [clojure-1.11.2.jar:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:137) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:669) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invoke(core.clj:662) [clojure-1.11.2.jar:?]
	at metabase.db$memoize_for_application_db$fn__74147.doInvoke(db.clj:106) [?:?]
	at clojure.lang.RestFn.invoke(RestFn.java:408) [clojure-1.11.2.jar:?]
	at metabase.test.data.impl$do_with_dataset$db_fn__147596.invoke(impl.clj:381) [?:?]
	at metabase.test.data.impl$do_with_dataset$fn__147598.invoke(impl.clj:383) [?:?]
	at metabase.test.data.impl$fn__147426$_AMPERSAND_f__147427.invoke(impl.clj:89) [?:?]
	at metabase.test.data.impl$fn__147426$fn__147429.invoke(impl.clj:87) [?:?]
	at metabase.test.data$id.invokeStatic(data.clj:219) [?:?]
	at metabase.test.data$id.invoke(data.clj:214) [?:?]
	at clojure.lang.AFn.applyToHelper(AFn.java:152) [clojure-1.11.2.jar:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:132) [clojure-1.11.2.jar:?]
	at clojure.lang.Var.applyTo(Var.java:705) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:667) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invoke(core.clj:662) [clojure-1.11.2.jar:?]
	at metabase.test.data.mbql_query_impl$druid_id_fn.invokeStatic(mbql_query_impl.clj:19) [?:?]
	at metabase.test.data.mbql_query_impl$druid_id_fn.doInvoke(mbql_query_impl.clj:12) [?:?]
	at clojure.lang.RestFn.invoke(RestFn.java:397) [clojure-1.11.2.jar:?]
	at metabase.query_processor_test.date_time_zone_functions_test$fn__276350$fn__276389$fn__276390$diffs__276391.invoke(date_time_zone_functions_test.clj:1066) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$run_datetime_diff_time_zone_tests_BANG_$fn__276291$fn__276292.invoke(date_time_zone_functions_test.clj:963) [?:?]
	at metabase.test.util$do_with_temporary_setting_value.invokeStatic(util.clj:450) [?:?]
	at metabase.test.util$do_with_temporary_setting_value.doInvoke(util.clj:406) [?:?]
	at clojure.lang.RestFn.invoke(RestFn.java:445) [clojure-1.11.2.jar:?]
	at metabase.query_processor_test.date_time_zone_functions_test$run_datetime_diff_time_zone_tests_BANG_$fn__276291.invoke(date_time_zone_functions_test.clj:961) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$run_datetime_diff_time_zone_tests_BANG_.invokeStatic(date_time_zone_functions_test.clj:960) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$run_datetime_diff_time_zone_tests_BANG_.invoke(date_time_zone_functions_test.clj:949) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$fn__276350$fn__276389$fn__276390.invoke(date_time_zone_functions_test.clj:[1075](https://github.com/metabase/metabase/actions/runs/10038716376/job/27748689824#step:3:1089)) [?:?]
	at metabase.test.data.impl$do_with_dataset.invokeStatic(impl.clj:385) [?:?]
	at metabase.test.data.impl$do_with_dataset.invoke(impl.clj:371) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$fn__276350$fn__276389.invoke(date_time_zone_functions_test.clj:1063) [?:?]
	at metabase.test.data.datasets$_test_driver$fn__146757.invoke(datasets.clj:29) [?:?]
	at metabase.driver$do_with_driver.invokeStatic(driver.clj:105) [?:?]
	at metabase.driver$do_with_driver.invoke(driver.clj:100) [?:?]
	at metabase.test.data.datasets$_test_driver.invokeStatic(datasets.clj:28) [?:?]
	at metabase.test.data.datasets$_test_driver.invoke(datasets.clj:23) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$fn__276350.invokeStatic(date_time_zone_functions_test.clj:1062) [?:?]
	at metabase.query_processor_test.date_time_zone_functions_test$fn__276350.invoke(date_time_zone_functions_test.clj:1061) [?:?]
	at clojure.test$test_var$fn__9856.invoke(test.clj:717) [clojure-1.11.2.jar:?]
	at clojure.test$test_var.invokeStatic(test.clj:717) [clojure-1.11.2.jar:?]
	at clojure.test$test_var.invoke(test.clj:708) [clojure-1.11.2.jar:?]
	at mb.hawk.core$run_test.invokeStatic(core.clj:151) [?:?]
	at mb.hawk.core$run_test.invoke(core.clj:142) [?:?]
	at eftest.runner$test_vars$fn__21553$fn__21557.invoke(runner.clj:106) [?:?]
	at clojure.test$default_fixture.invokeStatic(test.clj:687) [clojure-1.11.2.jar:?]
	at clojure.test$default_fixture.invoke(test.clj:683) [clojure-1.11.2.jar:?]
	at eftest.runner$test_vars$fn__21553.invoke(runner.clj:98) [?:?]
	at eftest.runner$wrap_test_with_timer$fn__21514.invoke(runner.clj:38) [?:?]
	at clojure.core$map$fn__5935.invoke(core.clj:2770) [clojure-1.11.2.jar:?]
	at clojure.lang.LazySeq.sval(LazySeq.java:42) [clojure-1.11.2.jar:?]
	at clojure.lang.LazySeq.seq(LazySeq.java:51) [clojure-1.11.2.jar:?]
	at clojure.lang.RT.seq(RT.java:535) [clojure-1.11.2.jar:?]
	at clojure.core$seq__5467.invokeStatic(core.clj:139) [clojure-1.11.2.jar:?]
	at clojure.core$dorun.invokeStatic(core.clj:3135) [clojure-1.11.2.jar:?]
	at clojure.core$dorun.invoke(core.clj:3135) [clojure-1.11.2.jar:?]
	at eftest.runner$test_vars$fn__21561.invoke(runner.clj:115) [?:?]
	at clojure.test$default_fixture.invokeStatic(test.clj:687) [clojure-1.11.2.jar:?]
	at clojure.test$default_fixture.invoke(test.clj:683) [clojure-1.11.2.jar:?]
	at eftest.runner$test_vars.invokeStatic(runner.clj:112) [?:?]
	at eftest.runner$test_vars.invoke(runner.clj:88) [?:?]
	at eftest.runner$test_ns.invokeStatic(runner.clj:125) [?:?]
	at eftest.runner$test_ns.invoke(runner.clj:121) [?:?]
	at eftest.runner$test_all$f__21575$fn__21577.invoke(runner.clj:140) [?:?]
	at clojure.core$map$fn__5935.invoke(core.clj:2772) [clojure-1.11.2.jar:?]
	at clojure.lang.LazySeq.sval(LazySeq.java:42) [clojure-1.11.2.jar:?]
	at clojure.lang.LazySeq.seq(LazySeq.java:51) [clojure-1.11.2.jar:?]
	at clojure.lang.Cons.next(Cons.java:39) [clojure-1.11.2.jar:?]
	at clojure.lang.RT.next(RT.java:713) [clojure-1.11.2.jar:?]
	at clojure.core$next__5451.invokeStatic(core.clj:64) [clojure-1.11.2.jar:?]
	at clojure.core$reduce1.invokeStatic(core.clj:946) [clojure-1.11.2.jar:?]
	at clojure.core$reduce1.invokeStatic(core.clj:936) [clojure-1.11.2.jar:?]
	at clojure.core$merge_with.invokeStatic(core.clj:3077) [clojure-1.11.2.jar:?]
	at clojure.core$merge_with.doInvoke(core.clj:3069) [clojure-1.11.2.jar:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:139) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:669) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invoke(core.clj:662) [clojure-1.11.2.jar:?]
	at eftest.runner$test_all$f__21575.invoke(runner.clj:141) [?:?]
	at eftest.runner$test_all.invokeStatic(runner.clj:144) [?:?]
	at eftest.runner$test_all.invoke(runner.clj:129) [?:?]
	at eftest.runner$run_tests$fn__21621.invoke(runner.clj:215) [?:?]
	at eftest.runner$run_tests.invokeStatic(runner.clj:215) [?:?]
	at eftest.runner$run_tests.invoke(runner.clj:181) [?:?]
	at mb.hawk.core$run_tests$fn__22066.invoke(core.clj:197) [?:?]
	at clojure.core$with_redefs_fn.invokeStatic(core.clj:7583) [clojure-1.11.2.jar:?]
	at clojure.core$with_redefs_fn.invoke(core.clj:7567) [clojure-1.11.2.jar:?]
	at clojure.lang.AFn.applyToHelper(AFn.java:156) [clojure-1.11.2.jar:?]
	at clojure.lang.AFn.applyTo(AFn.java:144) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:667) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invoke(core.clj:662) [clojure-1.11.2.jar:?]
	at metabase.test.redefs$new_with_redefs_fn.invokeStatic(redefs.clj:38) [?:?]
	at metabase.test.redefs$new_with_redefs_fn.doInvoke(redefs.clj:36) [?:?]
	at clojure.lang.RestFn.invoke(RestFn.java:421) [clojure-1.11.2.jar:?]
	at mb.hawk.core$run_tests.invokeStatic(core.clj:194) [?:?]
	at mb.hawk.core$run_tests.invoke(core.clj:175) [?:?]
	at mb.hawk.core$find_and_run_tests_with_options$fn__22093.invoke(core.clj:233) [?:?]
	at mb.hawk.core$find_and_run_tests_with_options.invokeStatic(core.clj:230) [?:?]
	at mb.hawk.core$find_and_run_tests_with_options.invoke(core.clj:223) [?:?]
	at mb.hawk.core$find_and_run_tests_cli.invokeStatic(core.clj:266) [?:?]
	at mb.hawk.core$find_and_run_tests_cli.invoke(core.clj:258) [?:?]
	at metabase.test_runner$find_and_run_tests_cli.invokeStatic(test_runner.clj:104) [?:?]
	at metabase.test_runner$find_and_run_tests_cli.invoke(test_runner.clj:101) [?:?]
	at clojure.lang.Var.invoke(Var.java:384) [clojure-1.11.2.jar:?]
	at clojure.run.exec$exec.invokeStatic(exec.clj:89) [?:?]
	at clojure.run.exec$exec.invoke(exec.clj:78) [?:?]
	at clojure.run.exec$_main$fn__20820.invoke(exec.clj:216) [?:?]
	at clojure.run.exec$_main.invokeStatic(exec.clj:212) [?:?]
	at clojure.run.exec$_main.doInvoke(exec.clj:180) [?:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:137) [clojure-1.11.2.jar:?]
	at clojure.lang.Var.applyTo(Var.java:705) [clojure-1.11.2.jar:?]
	at clojure.core$apply.invokeStatic(core.clj:667) [clojure-1.11.2.jar:?]
	at clojure.main$main_opt.invokeStatic(main.clj:514) [clojure-1.11.2.jar:?]
	at clojure.main$main_opt.invoke(main.clj:510) [clojure-1.11.2.jar:?]
	at clojure.main$main.invokeStatic(main.clj:664) [clojure-1.11.2.jar:?]
	at clojure.main$main.doInvoke(main.clj:616) [clojure-1.11.2.jar:?]
	at clojure.lang.RestFn.applyTo(RestFn.java:137) [clojure-1.11.2.jar:?]
	at clojure.lang.Var.applyTo(Var.java:705) [clojure-1.11.2.jar:?]
	at clojure.main.main(main.java:40) [clojure-1.11.2.jar:?]
```",camsaul,2024-07-22 19:08:36+00:00,[],2024-08-06 16:13:45+00:00,2024-08-06 15:24:06+00:00,https://github.com/metabase/metabase/issues/45948,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Redshift', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2243784774, 'issue_id': 2423587920, 'author': 'camsaul', 'body': 'Test to reproduce failure\r\n\r\n```clj\r\n(ns metabase.sync-test ...)\r\n\r\n...\r\n\r\n(driver/register! ::sync-database-error-test)\r\n\r\n(defmethod driver/describe-database ::sync-database-error-test\r\n  [_driver _database]\r\n  (throw (Exception. ""OOPS!"")))\r\n\r\n(deftest sync-database!-error-test\r\n  (testing ""Errors in sync-database! should be caught and handled correctly (#45848)""\r\n    (mt/with-temp [Database db {:engine ::sync-database-error-test}]\r\n      (binding [sync-util/*log-exceptions-and-continue?* true]\r\n        (is (= :error-placeholder\r\n               (sync/sync-database! db)))))))\r\n```\r\n\r\nThis test fails because it unexpectedly throws an uncaught class cast exception because it\'s trying to `assoc` with a Throwable. Not clear what we want the behavior to be here but it\'s probably not throwing un unexpected exception because we\'re not handling an expected one', 'created_at': datetime.datetime(2024, 7, 22, 20, 45, 50, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-07-22 20:45:50 UTC): Test to reproduce failure

```clj
(ns metabase.sync-test ...)

...

(driver/register! ::sync-database-error-test)

(defmethod driver/describe-database ::sync-database-error-test
  [_driver _database]
  (throw (Exception. ""OOPS!"")))

(deftest sync-database!-error-test
  (testing ""Errors in sync-database! should be caught and handled correctly (#45848)""
    (mt/with-temp [Database db {:engine ::sync-database-error-test}]
      (binding [sync-util/*log-exceptions-and-continue?* true]
        (is (= :error-placeholder
               (sync/sync-database! db)))))))
```

This test fails because it unexpectedly throws an uncaught class cast exception because it's trying to `assoc` with a Throwable. Not clear what we want the behavior to be here but it's probably not throwing un unexpected exception because we're not handling an expected one

"
2423391341,issue,closed,completed,Filtering on date columns by relative dates using weeks results in wrong time range,"### Describe the bug

This is a follow-up bug for https://github.com/metabase/metabase/issues/42291. I decided to create a new GH issue as opposed to re-opening since it's a slightly different issue this time.

We are still seeing duplicate results in our question, week over week, around the beginning and end of the time range.
Context: we have an alert setup every week for a question that uses a filter on created_at in the previous week, 16 weeks ago. 

This seems to because the time range that is generated is 8 days instead of 7, apparently.

### To Reproduce

1. Go to https://stats.metabase.com/question/4859
2. Click on Show filters
3. Click on Created At is in the previous week, 16 weeks ago
4. There is a preview in the UI for the time range: March 24-30 (see screenshot)
<img width=""452"" alt=""image"" src=""https://github.com/user-attachments/assets/689d62ce-6a60-4202-9ed5-750c1a96e79c"">

5. Notice there is one result with Created At on March 24
6. Now change the filter to 17 weeks ago, the preview in the UI states shows March 17 and 23
<img width=""442"" alt=""image"" src=""https://github.com/user-attachments/assets/a9494e05-a3cf-4cd5-9ae6-0a53fc3716aa"">

7. Notice the same record in the result set with Created on March 24, which should not be included

### Expected behavior

- The time range applied in the where clause matches the time range I see in the UI when I select a value
- The time range is 7 days, e.g. from March 17 00:00 to March 23 23:59, no results from March 24
- There is no overlap as you increment or decrement the offset in weeks, otherwise you end up with duplicates

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Reproduced on stats, Built on 2024-07-22, Hash: e02589a
```


### Severity

P1

### Additional context

_No response_",albertoperdomo,2024-07-22 17:29:24+00:00,['lbrdnk'],2024-08-28 02:09:00+00:00,2024-08-07 09:36:42+00:00,https://github.com/metabase/metabase/issues/45942,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Team/Querying', '')]",[],
2423347059,issue,open,,Mantine v7,"Now that we're on React 18, we should upgrade to mantine v7 sooner rather than later to take advantage of new components, better component APIs, more performant styling, and better accessiblity.

see:
- https://github.com/metabase/metabase/pull/33368


```[tasklist]
### Tasks
- [x] Update Branch to Mantine v7
- [x] Setup Base Theme
- [ ] Convert each set of overrides to CSS
- [ ] Design review + figma comparison
- [ ] setup Loki tests against UI components storybook
```

```[tasklist]
### Follow-ups
- [ ] remove `theme.fn.themeColor` usage?
- [ ] audit all `styles` props: https://mantine.dev/guides/6x-to-7x/#styles-prop
- [ ] change spacing to gap props on stack components
- [ ] overrides truncation
```
",luizarakaki,2024-07-22 17:04:53+00:00,"['npfitz', 'iethree']",2025-01-20 18:19:06+00:00,,https://github.com/metabase/metabase/issues/45941,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2423262076,issue,closed,completed,Upgrade Mantine to v7,"Now that we're on React 18, we should upgrade to mantine v7 sooner rather than later to take advantage of new components, better component APIs, more performant styling, and better accessiblity.

see:
- https://github.com/metabase/metabase/pull/33368
",iethree,2024-07-22 16:17:51+00:00,[],2024-07-22 17:06:29+00:00,2024-07-22 17:06:29+00:00,https://github.com/metabase/metabase/issues/45940,"[('Type:Tech Debt', 'or Refactoring'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2243425389, 'issue_id': 2423262076, 'author': 'iethree', 'body': 'closing in favor of #45941', 'created_at': datetime.datetime(2024, 7, 22, 17, 5, 45, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-07-22 17:05:45 UTC): closing in favor of #45941

"
2423152314,issue,closed,completed,"Model breaks with ""column source.ID does not exist""","### Describe the bug

Older models in 50.x (at least 50.6 models in 50.8; probably earlier ones really) can result in this error.

It seems to be a change somewhere in how columns and refs are handled with models, causing us to generate a SQL that `SELECT`s a column that the inner query doesn't provide.

More context in [this slack thread](https://metaboat.slack.com/archives/C01LQQ2UW03/p1721654026800009).

### To Reproduce

See the [broken original model](https://metabase-public.metabaseapp.com/model/1382-euro-2024-player-stats) or the (nearly) working [duplicate](https://metabase-public.metabaseapp.com/model/1519-euro-2024-player-stats-duplicate).

### Expected behavior

The original model should still be working fine.

### Information about your Metabase installation

```JSON
* Version v1.50.8 (after upgrading from v1.50.6)
```",Somtom,2024-07-22 15:23:15+00:00,['bshepherdson'],2024-10-01 22:14:21+00:00,2024-09-09 19:48:47+00:00,https://github.com/metabase/metabase/issues/45938,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]",[],
2423086607,issue,closed,completed,[Epic] Reset dashboard filters,"**Links**
- product doc: https://www.notion.so/metabase/Reset-dashboard-filters-eeb554324b00457bb1daa250b41bf0e5
- testing plan: #45977
- feature branch: PRs will come with tests and go straight to `master`
- issue links:
  - previous related epic: #39809

**Implementation Plan**

```[tasklist]
### Milestone 1
- [ ] https://github.com/metabase/metabase/issues/45983
- [ ] https://github.com/metabase/metabase/issues/45984
```

",NevRA,2024-07-22 14:53:37+00:00,['kamilmielnik'],2024-08-05 14:31:14+00:00,2024-08-05 14:31:14+00:00,https://github.com/metabase/metabase/issues/45935,"[('.Epic', 'Feature Implementation or Project')]",[],
2423035292,issue,closed,completed,update `static_embed_code_copied` to use `downloads`,,npretto,2024-07-22 14:33:01+00:00,['npretto'],2024-07-26 10:02:08+00:00,2024-07-26 10:02:08+00:00,https://github.com/metabase/metabase/issues/45932,[],[],
2422972121,issue,closed,not_planned,Model metadata changes are not reflected in the notebook preview,"### Describe the bug

Model metadata changes are not reflected in the notebook preview for any of the stages, including the initial change without any query modifications.

### To Reproduce

1. Create a new GUI model
2. Edit metadata and rename any column to ""Foo""
3. Save the model (but this is possible to reproduce without saving  as well)
4. Edit query definition
5. Do not actually change the query (it will wipe out the metadata, which is #45924), but instead just click on the preview
6. Notice that the column name in the preview is not ""Foo""

<img width=""2054"" alt=""Screenshot 2024-07-22 at 16 01 30"" src=""https://github.com/user-attachments/assets/c97da256-a312-4961-9dd0-e7fba8d2b05e"">


### Expected behavior

Query previews should ideally reflect the actual query (including metadata changes)

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, fcf8c51, H2, Sample Database
```


### Severity

P3

### Additional context

_No response_",nemanjaglumac,2024-07-22 14:05:53+00:00,[],2024-07-22 15:04:17+00:00,2024-07-22 14:57:19+00:00,https://github.com/metabase/metabase/issues/45928,"[('Type:New Feature', ''), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2243169908, 'issue_id': 2422972121, 'author': 'ranquild', 'body': 'This is no way how we can map metadata from query results to arbitrary query stages. By design - for now.', 'created_at': datetime.datetime(2024, 7, 22, 14, 57, 19, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-22 14:57:19 UTC): This is no way how we can map metadata from query results to arbitrary query stages. By design - for now.

"
2422952246,issue,closed,completed,GUI does not show restored model metadata initially (refresh required),"### Describe the bug

Revert history should have the info about the metadata changes, but reverting to a specific point in history does *not* restore previously configured model metadata.

### To Reproduce

1. Create a GUI model and save
2. Edit metadata and rename a column > Save again
3. Notice the percentage indicator went up a bit (in my case it went from the initial 59% to 61% for the complete metadata)
4. Notice that there is an entry in the model history panel that says ""edited metadata""
5. Edit the query which will get rid of metadata (#45924) or mess with the metadata in any other way - a new entry in the history will appear
6. Revert to the older point in history (from the step 4)
7. The metadata for the renamed column doesn't appear restored, but the percentage pointer shows presumably the correct 61%

### Expected behavior

We should show the restored metadata changes without a refresh.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, fcf8c51, H2, Sample Database
```


### Severity

P2

### Additional context

Backend responses contain the correct information. It's the FE that doesn't display them initially, without the refresh.",nemanjaglumac,2024-07-22 13:57:20+00:00,['uladzimirdev'],2025-01-30 06:40:43+00:00,2025-01-30 06:04:06+00:00,https://github.com/metabase/metabase/issues/45926,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]",[],
2422909546,issue,closed,completed,Changing a query definition on an existing GUI Model will drop all configured metadata,"### Describe the bug

Changing a query definition on a GUI model that has some custom metadata will drop that metadata.

### To Reproduce

For all scenarios:
1. Create a new model > notebook > Orders
2. Edit model metadata > Rename ""ID"" column to ""Foo"" and ""Save"" the model
3. Edit query definition
4. Do literally anything in the notebook that would result in a dirty state (and the need to re-run the query) - this can be adding a custom column, sorting, applying limit, filter, summarize, join, add/remove columns in the data picker...
5. Notice that the column ""Foo"" is now ""ID"" again


### Expected behavior

Metadata should be preserved.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, fcf8c51, H2, Sample Database
```


### Severity

P1

### Additional context

This is the same issue as #22517, but this time for GUI models specifically.",nemanjaglumac,2024-07-22 13:38:53+00:00,['ranquild'],2024-09-12 18:38:14+00:00,2024-07-23 13:34:28+00:00,https://github.com/metabase/metabase/issues/45924,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]",[],
2422870747,issue,open,,Data models do not update to reflect fields that have been removed from the parent table,"**Describe the bug**

I’m trying to clean up some of the data models we use to remove fields no longer uses. However, I still see some fields that have been removed (hidden) from the main parent table.

These do not show in the dropdown list for setting up the data model definition, but they do persist in the data model table and I so I can’t think of a way to get rid of them.

Go to data model
See ""field X"" in the table
Look at data model definition from ""main table""
Field X is not in the dropdown list of options for ""main table""
Look at the ""main table"" metadata set up from admin view and see ""field X"" is listed as ""Do not include"" 

--> Unsure how to remove ""field X"" from the data model 

![Screenshot 2024-07-22 at 14 03 11](https://github.com/user-attachments/assets/f803a320-6cf0-469d-8c8d-a8a5752f0c57)
![Screenshot 2024-07-22 at 14 03 51](https://github.com/user-attachments/assets/ea700a93-3911-4051-bf7a-d47af0cb9088)
![Screenshot 2024-07-22 at 14 07 31](https://github.com/user-attachments/assets/9158788f-0c31-4f71-a78c-f5fd451b6682)

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/London""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-16"",
      ""tag"": ""v1.49.6"",
      ""hash"": ""5abf130""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/London""
    }
  }
}
```",cswaq,2024-07-22 13:21:47+00:00,[],2025-02-04 20:27:20+00:00,,https://github.com/metabase/metabase/issues/45919,"[('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Frontend', ''), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2265261403, 'issue_id': 2422870747, 'author': 'noahmoss', 'body': ""Hi @cswaq —\xa0I don't fully understand the issue. Could you provide steps to reproduce this with the sample dataset included in Metabase?"", 'created_at': datetime.datetime(2024, 8, 2, 12, 33, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283753577, 'issue_id': 2422870747, 'author': 'darksciencebase', 'body': '@cswaq have you had a chance to try and reproduce this with the sample dataset?', 'created_at': datetime.datetime(2024, 8, 12, 11, 46, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288788466, 'issue_id': 2422870747, 'author': 'cswaq', 'body': 'Hello,\r\n\r\nThis has been picked up with our support engineer Zoltan, he was able to\r\nreproduce and confirm the bug but also provided us with a workaround which\r\nhas resolved the issue for now.\r\n\r\nThanks!\r\nCaroline\r\n\r\nOn Mon, 12 Aug 2024 at 12:47, Lena ***@***.***> wrote:\r\n\r\n> @cswaq <https://github.com/cswaq> have you had a chance to try and\r\n> reproduce this with the sample dataset?\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/45919#issuecomment-2283753577>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/BIKSPUXF6BCRE26R3Q3HOODZRCOEFAVCNFSM6AAAAABLIKED56VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEOBTG42TGNJXG4>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 8, 14, 13, 40, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296641076, 'issue_id': 2422870747, 'author': 'noahmoss', 'body': '@zbodi74 could you please triage this if you have more context?', 'created_at': datetime.datetime(2024, 8, 19, 13, 54, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396564466, 'issue_id': 2422870747, 'author': 'zbodi74', 'body': 'The error was that columns hidden in table metadata were still referred by GUI models which caused incorrect query errors while querying the model or questions based on the model. In my case, the issue resolved automatically after some time, so this seems to be related to caching or to an async process that updates dependent models after changes.\n\nTo reproduce:\n1. Create a model, Sample Database / People, select all columns\n2. Hide the Password column in Admin Settings / Table Metadata / sample database / People .\n3. Try to use the model created in step 1. and see the invalid query error (`Column ""source.PASSWORD"" not found`).\n4. Edit the model, and see the field is no longer in the column selector, but it is still referring to the hidden field when being queried.\n\nThe workaround was to force the update of the model\'s query definition by updating and saving the model, which also refreshed the column metadata:\n- Edited the query definition of the model.\n- Added a row limit.\n- Updated the record preview and saved the model.\n- At this point the column changes were properly reflected in the model\'s output\n- Updated the query definition again, and removed the row limit.', 'created_at': datetime.datetime(2024, 10, 7, 10, 42, 55, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-08-02 12:33:02 UTC): Hi @cswaq — I don't fully understand the issue. Could you provide steps to reproduce this with the sample dataset included in Metabase?

darksciencebase on (2024-08-12 11:46:54 UTC): @cswaq have you had a chance to try and reproduce this with the sample dataset?

cswaq (Issue Creator) on (2024-08-14 13:40:22 UTC): Hello,

This has been picked up with our support engineer Zoltan, he was able to
reproduce and confirm the bug but also provided us with a workaround which
has resolved the issue for now.

Thanks!
Caroline

On Mon, 12 Aug 2024 at 12:47, Lena ***@***.***> wrote:

noahmoss on (2024-08-19 13:54:45 UTC): @zbodi74 could you please triage this if you have more context?

zbodi74 on (2024-10-07 10:42:55 UTC): The error was that columns hidden in table metadata were still referred by GUI models which caused incorrect query errors while querying the model or questions based on the model. In my case, the issue resolved automatically after some time, so this seems to be related to caching or to an async process that updates dependent models after changes.

To reproduce:
1. Create a model, Sample Database / People, select all columns
2. Hide the Password column in Admin Settings / Table Metadata / sample database / People .
3. Try to use the model created in step 1. and see the invalid query error (`Column ""source.PASSWORD"" not found`).
4. Edit the model, and see the field is no longer in the column selector, but it is still referring to the hidden field when being queried.

The workaround was to force the update of the model's query definition by updating and saving the model, which also refreshed the column metadata:
- Edited the query definition of the model.
- Added a row limit.
- Updated the record preview and saved the model.
- At this point the column changes were properly reflected in the model's output
- Updated the query definition again, and removed the row limit.

"
2422846766,issue,closed,completed,"In Admin / Performance, in the Schedule policy, if the default time (8am) is used, an incorrect schedule will get saved","### Describe the bug

https://www.loom.com/share/7065bd50b8a14f9ea4071af7fe327631?sid=e82d2ab7-993b-4f41-99c1-4bc4ef1e434f

### To Reproduce

1. Admin / Performance
2. Take a database that does not use the schedule strategy and change it to the schedule strategy. Choose weekly. Don't change the time.
3. You'll see in DevTools / Network that there is no integer 8 in the cron expression sent to the BE. Instead, the wildcard is used, resulting in a cache invalidation strategy that runs once per hour on the selected day.

### Expected behavior

The expected cron expression includes an 8.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.12 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-16"",
      ""src_hash"": ""4eb9e3ac0c4bf649e0a92401806fc7eec9228175"",
      ""tag"": ""v1.1.23-SNAPSHOT"",
      ""hash"": ""f96ba69""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2

### Additional context

_No response_",rafpaf,2024-07-22 13:11:14+00:00,['rafpaf'],2024-07-26 14:17:58+00:00,2024-07-25 20:37:16+00:00,https://github.com/metabase/metabase/issues/45916,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2422606683,issue,open,,Some queries do not complete on Redshift,"As per discussion with customer, some queries do not complete on Redshift. Originally it it seemed window function is common denominator of these queries, but it turned out it is happening also with queries with no window functions.

Info from the customer:
```
- Metabase version is `50.13`.
- There are no exceptions in logs.
- ""queries used the 'first_value' function with the window frame 'unbounded preceding and unbounded following'"" seem not to complete.
- If queries previously described are modified ""to use 'row_number'"" instead, queries complete.
- If joins are added to the ""row_number"" queries, those, again, do not complete.
- Queries do timeout on Metabase side after 10 minutes. Queries do not terminate on Redshift side.
```
Original issue (reproduction of which is resolved):
#39018",lbrdnk,2024-07-22 11:13:32+00:00,[],2025-02-04 20:25:41+00:00,,https://github.com/metabase/metabase/issues/45910,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Redshift', None), ('Difficulty:Hard', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2283538552, 'issue_id': 2422606683, 'author': 'lbrdnk', 'body': 'I was able to come up with a query that in *some* circumstances does not finish in Metabase. Even though the not-finishing behavior is slightly different to what has been reported, it enables to analyze what happens inside a Metabase instance when this situation arise.\n\n### The query\n\n`test-data` dataset is used. The query could be probably simplified for the same effect.\n\n<details>\n<summary>The query</summary>\n<pre><code>\nSELECT\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" AS ""id"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""user_id"" AS ""user_id"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""product_id"" AS ""product_id"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""subtotal"" AS ""subtotal"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""tax"" AS ""tax"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""total"" AS ""total"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""discount"" AS ""discount"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""created_at"" AS ""created_at"",\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""quantity"" AS ""quantity"",\n  GETDATE() AS ""now"",\n  ""Test Data Orders"".""id"" AS ""Test Data Orders__id"",\n  ""Test Data Orders"".""user_id"" AS ""Test Data Orders__user_id"",\n  ""Test Data Orders"".""product_id"" AS ""Test Data Orders__product_id"",\n  ""Test Data Orders"".""subtotal"" AS ""Test Data Orders__subtotal"",\n  ""Test Data Orders"".""tax"" AS ""Test Data Orders__tax"",\n  ""Test Data Orders"".""total"" AS ""Test Data Orders__total"",\n  ""Test Data Orders"".""discount"" AS ""Test Data Orders__discount"",\n  ""Test Data Orders"".""created_at"" AS ""Test Data Orders__created_at"",\n  ""Test Data Orders"".""quantity"" AS ""Test Data Orders__quantity"",\n  ""Test Data Orders_2"".""id"" AS ""Test Data Orders_2__id"",\n  ""Test Data Orders_2"".""user_id"" AS ""Test Data Orders_2__user_id"",\n  ""Test Data Orders_2"".""product_id"" AS ""Test Data Orders_2__product_id"",\n  ""Test Data Orders_2"".""subtotal"" AS ""Test Data Orders_2__subtotal"",\n  ""Test Data Orders_2"".""tax"" AS ""Test Data Orders_2__tax"",\n  ""Test Data Orders_2"".""total"" AS ""Test Data Orders_2__total"",\n  ""Test Data Orders_2"".""discount"" AS ""Test Data Orders_2__discount"",\n  ""Test Data Orders_2"".""created_at"" AS ""Test Data Orders_2__created_at"",\n  ""Test Data Orders_2"".""quantity"" AS ""Test Data Orders_2__quantity"",\n  ""Test Data Orders_2_2"".""id"" AS ""Test Data Orders_2_2__id"",\n  ""Test Data Orders_2_2"".""user_id"" AS ""Test Data Orders_2_2__user_id"",\n  ""Test Data Orders_2_2"".""product_id"" AS ""Test Data Orders_2_2__product_id"",\n  ""Test Data Orders_2_2"".""subtotal"" AS ""Test Data Orders_2_2__subtotal"",\n  ""Test Data Orders_2_2"".""tax"" AS ""Test Data Orders_2_2__tax"",\n  ""Test Data Orders_2_2"".""total"" AS ""Test Data Orders_2_2__total"",\n  ""Test Data Orders_2_2"".""discount"" AS ""Test Data Orders_2_2__discount"",\n  ""Test Data Orders_2_2"".""created_at"" AS ""Test Data Orders_2_2__created_at"",\n  ""Test Data Orders_2_2"".""quantity"" AS ""Test Data Orders_2_2__quantity"",\n  ""Test Data Products - Product"".""id"" AS ""Test Data Products - Product__id"",\n  ""Test Data Products - Product"".""ean"" AS ""Test Data Products - Product__ean"",\n  ""Test Data Products - Product"".""title"" AS ""Test Data Products - Product__title"",\n  ""Test Data Products - Product"".""category"" AS ""Test Data Products - Product__category"",\n  ""Test Data Products - Product"".""vendor"" AS ""Test Data Products - Product__vendor"",\n  ""Test Data Products - Product"".""price"" AS ""Test Data Products - Product__price"",\n  ""Test Data Products - Product"".""rating"" AS ""Test Data Products - Product__rating"",\n  ""Test Data Products - Product"".""created_at"" AS ""Test Data Products - Product__created_at""\nFROM\n  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders""\n \nLEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders"" ON (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders"".""id""\n  )\n \n    OR (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL\n  )\n  LEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders_2"" ON (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders_2"".""id""\n  )\n  OR (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL\n  )\n  LEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders_2_2"" ON (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders_2_2"".""id""\n  )\n  OR (\n    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL\n  )\n  FULL JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_products"" AS ""Test Data Products - Product"" ON ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""product_id"" = ""Test Data Products - Product"".""id""\nLIMIT 2000\n</code>\n</pre>\n</details>\n\n\n### Findings\n\nBE returned to FE *almost all* rows with regards to limit for the non-finishing query. BE starts returning rows relatively quickly after the execution is initiated (Dev tools > Network > Timing). After returning first ~1997 rows, the process halts.\n\n2000 rows are expected, in this specific case by actual `LIMIT 2000` clause, but in general because of limit middleware which just takes first 2K rows from a `ResultSet`.\n\nIn the situation where the query is killed on the Redshift side before `jdbc-data-warehouse-unreturned-connection-timeout-seconds` was reached, then _the remaining rows are returned_!  And the query completes successfully.\n\nUsing `jconsole` it could be seen that thread is left waiting for more results after calling `.next` method.\n```\njava.base@11.0.21/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)\napp//com.amazon.redshift.core.v3.RedshiftRowsBlockingQueue.take(RedshiftRowsBlockingQueue.java:132)\napp//com.amazon.redshift.jdbc.RedshiftResultSet.next(RedshiftResultSet.java:2066)\napp//com.mchange.v2.c3p0.impl.NewProxyResultSet.next(NewProxyResultSet.java:685)\nmetabase.driver.sql_jdbc.execute$row_thunk$row_thunk_STAR___133067.invoke(execute.clj:647)\nmetabase.query_processor.reducible$reducible_rows$reify__90714.reduce(reducible.clj:56)\n```\n\nOn the other hand, the same query with `LIMIT` set to a greater value (eg. 5000) or with no `LIMIT` completes. _Fact, that just lowering the limit clause in Redshift\'s SQL makes the thread wait for more input indefinitely leaves an impression the problem may be external to Metabase._\n\n\n### Miscellaneous\n\nThere are 2 Metabase variables significant to the problem:\n- `jdbc-data-warehouse-unreturned-connection-timeout-seconds`,\n- `mb-jetty-async-response-timeout`.\n\nThe first one ensures that connections are returned. Beware, that does not mean the queries that run under the connection are canceled. The query is left running after the timeout is reached (connection is returned correctly), and even after the Metabase instance is terminated.\n\n\n### Solution\n\nTo address the problem, imho further debugging efforts should focus on Redshift JDBC java code (OSS), to figure out why take from queue blocks. Is it empty? Why?\n\n\n### Mitigation\n\nRedshift\'s Work Load Management, specifically [the query monitoring rules](https://docs.aws.amazon.com/redshift/latest/dg/cm-c-wlm-query-monitoring-rules.html#cm-c-wlm-defining-query-monitoring-rules) could be used to ensure there are no orphaned queries running in the cluster.', 'created_at': datetime.datetime(2024, 8, 12, 9, 51, 33, tzinfo=datetime.timezone.utc)}]","lbrdnk (Issue Creator) on (2024-08-12 09:51:33 UTC): I was able to come up with a query that in *some* circumstances does not finish in Metabase. Even though the not-finishing behavior is slightly different to what has been reported, it enables to analyze what happens inside a Metabase instance when this situation arise.

### The query

`test-data` dataset is used. The query could be probably simplified for the same effect.

<details>
<summary>The query</summary>
<pre><code>
SELECT
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" AS ""id"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""user_id"" AS ""user_id"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""product_id"" AS ""product_id"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""subtotal"" AS ""subtotal"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""tax"" AS ""tax"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""total"" AS ""total"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""discount"" AS ""discount"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""created_at"" AS ""created_at"",
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""quantity"" AS ""quantity"",
  GETDATE() AS ""now"",
  ""Test Data Orders"".""id"" AS ""Test Data Orders__id"",
  ""Test Data Orders"".""user_id"" AS ""Test Data Orders__user_id"",
  ""Test Data Orders"".""product_id"" AS ""Test Data Orders__product_id"",
  ""Test Data Orders"".""subtotal"" AS ""Test Data Orders__subtotal"",
  ""Test Data Orders"".""tax"" AS ""Test Data Orders__tax"",
  ""Test Data Orders"".""total"" AS ""Test Data Orders__total"",
  ""Test Data Orders"".""discount"" AS ""Test Data Orders__discount"",
  ""Test Data Orders"".""created_at"" AS ""Test Data Orders__created_at"",
  ""Test Data Orders"".""quantity"" AS ""Test Data Orders__quantity"",
  ""Test Data Orders_2"".""id"" AS ""Test Data Orders_2__id"",
  ""Test Data Orders_2"".""user_id"" AS ""Test Data Orders_2__user_id"",
  ""Test Data Orders_2"".""product_id"" AS ""Test Data Orders_2__product_id"",
  ""Test Data Orders_2"".""subtotal"" AS ""Test Data Orders_2__subtotal"",
  ""Test Data Orders_2"".""tax"" AS ""Test Data Orders_2__tax"",
  ""Test Data Orders_2"".""total"" AS ""Test Data Orders_2__total"",
  ""Test Data Orders_2"".""discount"" AS ""Test Data Orders_2__discount"",
  ""Test Data Orders_2"".""created_at"" AS ""Test Data Orders_2__created_at"",
  ""Test Data Orders_2"".""quantity"" AS ""Test Data Orders_2__quantity"",
  ""Test Data Orders_2_2"".""id"" AS ""Test Data Orders_2_2__id"",
  ""Test Data Orders_2_2"".""user_id"" AS ""Test Data Orders_2_2__user_id"",
  ""Test Data Orders_2_2"".""product_id"" AS ""Test Data Orders_2_2__product_id"",
  ""Test Data Orders_2_2"".""subtotal"" AS ""Test Data Orders_2_2__subtotal"",
  ""Test Data Orders_2_2"".""tax"" AS ""Test Data Orders_2_2__tax"",
  ""Test Data Orders_2_2"".""total"" AS ""Test Data Orders_2_2__total"",
  ""Test Data Orders_2_2"".""discount"" AS ""Test Data Orders_2_2__discount"",
  ""Test Data Orders_2_2"".""created_at"" AS ""Test Data Orders_2_2__created_at"",
  ""Test Data Orders_2_2"".""quantity"" AS ""Test Data Orders_2_2__quantity"",
  ""Test Data Products - Product"".""id"" AS ""Test Data Products - Product__id"",
  ""Test Data Products - Product"".""ean"" AS ""Test Data Products - Product__ean"",
  ""Test Data Products - Product"".""title"" AS ""Test Data Products - Product__title"",
  ""Test Data Products - Product"".""category"" AS ""Test Data Products - Product__category"",
  ""Test Data Products - Product"".""vendor"" AS ""Test Data Products - Product__vendor"",
  ""Test Data Products - Product"".""price"" AS ""Test Data Products - Product__price"",
  ""Test Data Products - Product"".""rating"" AS ""Test Data Products - Product__rating"",
  ""Test Data Products - Product"".""created_at"" AS ""Test Data Products - Product__created_at""
FROM
  ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders""
 
LEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders"" ON (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders"".""id""
  )
 
    OR (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL
  )
  LEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders_2"" ON (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders_2"".""id""
  )
  OR (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL
  )
  LEFT JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"" AS ""Test Data Orders_2_2"" ON (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" <> ""Test Data Orders_2_2"".""id""
  )
  OR (
    ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""id"" IS NULL
  )
  FULL JOIN ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_products"" AS ""Test Data Products - Product"" ON ""2024_08_07_c997e9dd_9140_4b37_b9d4_ffff99b57876_schema"".""test_data_orders"".""product_id"" = ""Test Data Products - Product"".""id""
LIMIT 2000
</code>
</pre>
</details>


### Findings

BE returned to FE *almost all* rows with regards to limit for the non-finishing query. BE starts returning rows relatively quickly after the execution is initiated (Dev tools > Network > Timing). After returning first ~1997 rows, the process halts.

2000 rows are expected, in this specific case by actual `LIMIT 2000` clause, but in general because of limit middleware which just takes first 2K rows from a `ResultSet`.

In the situation where the query is killed on the Redshift side before `jdbc-data-warehouse-unreturned-connection-timeout-seconds` was reached, then _the remaining rows are returned_!  And the query completes successfully.

Using `jconsole` it could be seen that thread is left waiting for more results after calling `.next` method.
```
java.base@11.0.21/java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:433)
app//com.amazon.redshift.core.v3.RedshiftRowsBlockingQueue.take(RedshiftRowsBlockingQueue.java:132)
app//com.amazon.redshift.jdbc.RedshiftResultSet.next(RedshiftResultSet.java:2066)
app//com.mchange.v2.c3p0.impl.NewProxyResultSet.next(NewProxyResultSet.java:685)
metabase.driver.sql_jdbc.execute$row_thunk$row_thunk_STAR___133067.invoke(execute.clj:647)
metabase.query_processor.reducible$reducible_rows$reify__90714.reduce(reducible.clj:56)
```

On the other hand, the same query with `LIMIT` set to a greater value (eg. 5000) or with no `LIMIT` completes. _Fact, that just lowering the limit clause in Redshift's SQL makes the thread wait for more input indefinitely leaves an impression the problem may be external to Metabase._


### Miscellaneous

There are 2 Metabase variables significant to the problem:
- `jdbc-data-warehouse-unreturned-connection-timeout-seconds`,
- `mb-jetty-async-response-timeout`.

The first one ensures that connections are returned. Beware, that does not mean the queries that run under the connection are canceled. The query is left running after the timeout is reached (connection is returned correctly), and even after the Metabase instance is terminated.


### Solution

To address the problem, imho further debugging efforts should focus on Redshift JDBC java code (OSS), to figure out why take from queue blocks. Is it empty? Why?


### Mitigation

Redshift's Work Load Management, specifically [the query monitoring rules](https://docs.aws.amazon.com/redshift/latest/dg/cm-c-wlm-query-monitoring-rules.html#cm-c-wlm-defining-query-monitoring-rules) could be used to ensure there are no orphaned queries running in the cluster.

"
2422381831,issue,closed,completed,Investigate the ability to build the main in parallel,run main and static-viz in parallel,uladzimirdev,2024-07-22 09:22:28+00:00,['uladzimirdev'],2025-02-03 08:51:33+00:00,2025-02-03 08:51:33+00:00,https://github.com/metabase/metabase/issues/45907,[],[],
2422358748,issue,closed,completed,Check that emotion still works,,uladzimirdev,2024-07-22 09:11:32+00:00,['uladzimirdev'],2024-07-29 11:46:11+00:00,2024-07-29 11:45:49+00:00,https://github.com/metabase/metabase/issues/45906,[],[],
2422358453,issue,closed,completed,Migrate to the SWC,,uladzimirdev,2024-07-22 09:11:24+00:00,['uladzimirdev'],2024-07-29 11:46:07+00:00,2024-07-29 11:45:52+00:00,https://github.com/metabase/metabase/issues/45905,[],[],
2422225930,issue,closed,completed,"""Is"" Filter on Notebook editor does not show list of values for fields with `has_field_values=:list`","### Describe the bug

If a field is manually set ""Filtering on this field"" to ""A list of values"", filtering on this field in the Notebook Editor still shows a search box.

### To Reproduce

1. Go to Admin => Table Metadata => Sample Dataset => Reviews => Body
2. Change ""Filtering on this field"" to ""A list of values""
3. New => Question => Reviews
4. Try filter with the ""Is"" operator on ""Body"" column, the UI shows a search box

### Expected behavior

The UI should show a list of values, and when the user types in, the UI makes API calls to search.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

P2?

### Additional context

Worked on 49.9, I didn't check later versions.",qnkhuat,2024-07-22 08:06:54+00:00,['ranquild'],2024-07-22 14:59:22+00:00,2024-07-22 14:30:51+00:00,https://github.com/metabase/metabase/issues/45904,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2242342780, 'issue_id': 2422225930, 'author': 'qnkhuat', 'body': ""Giving this a p1 because it's a regression"", 'created_at': datetime.datetime(2024, 7, 22, 8, 7, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242352551, 'issue_id': 2422225930, 'author': 'qnkhuat', 'body': 'On 49.9 when I open the filter on ""Body"" column, the default filter operator is ""Is"" and it shows a list of values.\r\n\r\nBut on master(8d22b08feeac5127b08851a02c544ee326645628), the default filter operator is ""Contains"", when I switch to ""Is"", I see FE make an API call to get a list of values but still not display the values list.\r\n![Screenshot 2024-07-22 at 15 11 58](https://github.com/user-attachments/assets/ef8a98d8-6712-4a17-9406-5e7ac1794f07)', 'created_at': datetime.datetime(2024, 7, 22, 8, 12, 14, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-07-22 08:07:15 UTC): Giving this a p1 because it's a regression

qnkhuat (Issue Creator) on (2024-07-22 08:12:14 UTC): On 49.9 when I open the filter on ""Body"" column, the default filter operator is ""Is"" and it shows a list of values.

But on master(8d22b08feeac5127b08851a02c544ee326645628), the default filter operator is ""Contains"", when I switch to ""Is"", I see FE make an API call to get a list of values but still not display the values list.
![Screenshot 2024-07-22 at 15 11 58](https://github.com/user-attachments/assets/ef8a98d8-6712-4a17-9406-5e7ac1794f07)

"
2421252983,issue,closed,not_planned,"Feature Request: When doing ""IS"" queries while browsing tables, don't use separate different OR comparisons, use a single ""IN"" instead","**Is your feature request related to a problem? Please describe.**
I'm evaluating this product for potential deployment for my company and love it so far......

....but my server CPU is being blown out by inefficient queries when filtering on columns using ""IS"" filters on a MSSQL database. It will literally use 96 cores and take a whole minute or more to return a search on 1000 entries when doing an ""IS"" query. When running an ""IN"" query doing the exact same thing it returns instantaneously and uses little CPU.

End-Users are faced with super-slow filters when filtering on even moderate numbers of filter criteria.

**Describe the solution you'd like**
Use IN when doing ""IS"" queries (or change the word ""IS"" to ""IN"" since that's technically what you're doing). Something along the lines of ""WHERE lower([value]) IN ( {{ comma-delimited-list }} )""

**Describe alternatives you've considered**
I am forced to make a parameterized question which removes the drill-through or filter capabilities. I just basically implement the above ""IN"" functionality and it returns instantaneously with little CPU utilization when filtering on 1,000 criteria.

**How important is this feature to you?**
This is (or should be) important to everyone, not just me. I believe that this is bordering on a bug.

**Additional context**
This is using Microsoft SQL Server (I imagine this is true on other DBMS and equally slow) and I looked at the query monitor when filtering a column on 1,000 different strings using an ""IS"" filter. I then found a mountain of this in the resultant query text:

OR (LOWER(""dbo"".""exampletable"".""FieldToISQuery"") =  '123456788' ) OR (LOWER(""dbo"".""exampletable"".""FieldToISQuery"") =  '123456789' )

^ this is massively inefficient and blows out CPU utilization. The correct way to do this would be WHERE lower(""dbo"".""exampletable"".""FieldToISQuery"") IN ('123456788','123456789')

I'm assuming the string text that users input is LOWER() prior to search. This should work on all DBMS.

Thank You.",nutsnox,2024-07-21 06:37:30+00:00,[],2024-07-24 12:55:57+00:00,2024-07-24 12:55:57+00:00,https://github.com/metabase/metabase/issues/45900,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2247843269, 'issue_id': 2421252983, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/23101', 'created_at': datetime.datetime(2024, 7, 24, 12, 55, 57, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-24 12:55:57 UTC): duplicate of https://github.com/metabase/metabase/issues/23101

"
2421249030,issue,open,,incoherent data do not display values when the mouse moves over,"### Describe the bug

![bug1](https://github.com/user-attachments/assets/36cd1965-dbd5-4dde-b75a-932d45837a75)
![bug2](https://github.com/user-attachments/assets/fba6a8b7-0919-4c0a-a9be-715016a8d382)

This is right: When using a time series (the first picture), the corresponding values can be displayed on the right side, and detailed information can also be displayed on the legend with the mouse;

This is wrong: When using the sequence (the second picture), the values are not displayed, and no detailed information is displayed when the mouse is moved over;

### To Reproduce

Use a incoherent data, such as Figure 1. A piece of data is missing in the middle of the rendering mode.

### Expected behavior

Wrong mode repair, values can be displayed in the picture

### Logs

_No response_

### Information about your Metabase installation

```JSON
-Metabase version: v0.50.13
```


### Severity

important,  impact efficiency and experience

### Additional context

![bug1](https://github.com/user-attachments/assets/90f50fb4-e83f-45b0-999f-ec55eb901aa1)
![bug2](https://github.com/user-attachments/assets/30f66d11-a213-43d3-9b4b-8ece591fabd5)",nkjshlsqja7331,2024-07-21 06:23:40+00:00,[],2024-07-22 14:10:41+00:00,,https://github.com/metabase/metabase/issues/45899,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2420743981,issue,closed,completed,Upgrade from 0.50.10 to 0.50.13 failed with failing migration,"### Describe the bug

After downloading the latest 0.50.13 version and tried to upgrade our 0.50.10 version, it failed with failing migration. 

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

1. Have 0.50.10 running
2. Download and install 0.50.13
3. Start it, it will fail with provided logs.

### Logs

```
 Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""(""
   Position: 87
         at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
         at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
         at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
         at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
         at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
         at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
         at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
         at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
         at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
         at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
         at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
         ... 86 more
 UPDATE SUMMARY
 Run:                          3
 Previously run:             347
 Filtered out:                50
 -------------------------------
 Total change sets:          400
 FILTERED CHANGE SETS SUMMARY
 DBMS mismatch:               50
 2024-07-20 08:48:43,688 ERROR metabase.core :: Metabase Initialization FAILED
 liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
      Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
 ) STORED]
         at liquibase.command.CommandScope.execute(CommandScope.java:253)
         at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
         at liquibase.Scope.lambda$child$0(Scope.java:186)
...

 Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
      Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
 ) STORED]
         at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
         at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
         at liquibase.Scope.lambda$child$0(Scope.java:186)
         at liquibase.Scope.child(Scope.java:195)
         at liquibase.Scope.child(Scope.java:185)
         at liquibase.Scope.child(Scope.java:164)
         at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
         at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
         at liquibase.command.CommandScope.execute(CommandScope.java:217)
         ... 58 more
 Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries:
      Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
 ) STORED]
...
 Caused by: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""(""
   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (
   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END
 ) STORED]
         at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
         at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
         at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
         at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
         at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
         at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
         ... 81 more
 Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near ""(""
   Position: 87
         at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)
         at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)
         at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
         at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
         at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
         at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
         at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
         at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
         at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
         at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
         at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
         ... 86 more
 2024-07-20 08:48:43,692 INFO metabase.core :: Metabase Shutting Down ...
 2024-07-20 08:48:43,693 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
 2024-07-20 08:48:43,701 WARN db.liquibase :: ()
 2024-07-20 08:48:43,702 INFO metabase.core :: Metabase Shutdown COMPLETE
 metabase.service: Main process exited, code=exited, status=1/FAILURE
 metabase.service: Unit entered failed state.
 metabase.service: Failed with result 'exit-code'.
```

### Information about your Metabase installation

```JSON
- Tested on 126.0.6478.182 (Official Build, ungoogled-chromium) (64-bit)
- JDK: 126.0.6478.182 (Official Build, ungoogled-chromium) (64-bit)
- Postgres 10.17-1.pgdg16.04+1
- Ubuntu 16.04.7 LTS
```


### Severity

Unable to migrate to the latest version

### Additional context

Downgrade to 0.50.10 for now. Maybe a dumb question, is minimal required Postgres version changed? I saw psql errors like this when newer psql syntax was used on older Postgres version, but I might be wrong.",sanel,2024-07-20 09:01:17+00:00,[],2024-07-20 15:15:19+00:00,2024-07-20 15:15:19+00:00,https://github.com/metabase/metabase/issues/45894,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2241076654, 'issue_id': 2420743981, 'author': 'perivamsi', 'body': 'We support postgres 12 and above\r\n\r\nhttps://endoflife.date/postgresql', 'created_at': datetime.datetime(2024, 7, 20, 10, 22, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241179461, 'issue_id': 2420743981, 'author': 'paoliniluis', 'body': '@sanel please move to postgres v12 at least or better, to v16', 'created_at': datetime.datetime(2024, 7, 20, 15, 6, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241181465, 'issue_id': 2420743981, 'author': 'sanel', 'body': ""@perivamsi @paoliniluis thank you guys for your fast reply. I'll plan for migration and re-open this ticket if I get the same issue. Cheers!"", 'created_at': datetime.datetime(2024, 7, 20, 15, 15, 19, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-20 10:22:42 UTC): We support postgres 12 and above

https://endoflife.date/postgresql

paoliniluis on (2024-07-20 15:06:45 UTC): @sanel please move to postgres v12 at least or better, to v16

sanel (Issue Creator) on (2024-07-20 15:15:19 UTC): @perivamsi @paoliniluis thank you guys for your fast reply. I'll plan for migration and re-open this ticket if I get the same issue. Cheers!

"
2420657256,issue,closed,completed,collection order ignore non-alphabet char in 0.50 version,"### Describe the bug

We used ""_"" to pin important collection in top of the collection, but after update Metabase 0.48 to 0.50 the ordering ignore _ from leading of collection name.

### To Reproduce

1. rename last sub_collection of a collection from XXX to _XXX.
2. no change in order appeared.


### Expected behavior

the collection bring to the first order.

### Logs

_No response_

### Information about your Metabase installation

```JSON
-Metabase version: v0.50.13
```


### Severity

annoying

### Additional context

![image](https://github.com/user-attachments/assets/dc847ac1-870d-4c97-b56e-df9a3107a798)
",mohsendata,2024-07-20 07:28:00+00:00,[],2024-10-22 13:57:53+00:00,2024-10-22 13:57:52+00:00,https://github.com/metabase/metabase/issues/45893,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Collections', ''), ('.Backend', ''), ('.Product Input Needed', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2244266641, 'issue_id': 2420657256, 'author': 'mohsendata', 'body': ""We're also encountering this problem with database names; we're unable to pin a gold database at the header or trailer of databases with special characters (such as _ or ~) and necessitating the addition of a 'A' or 'Z' prefix to it."", 'created_at': datetime.datetime(2024, 7, 23, 5, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429367259, 'issue_id': 2420657256, 'author': 'rafpaf', 'body': 'Thank you, @mohsendata! This has now been fixed.\n\n![Image](https://github.com/user-attachments/assets/459a1b1e-64f7-4ab5-9806-21108c841f7d)', 'created_at': datetime.datetime(2024, 10, 22, 13, 57, 52, tzinfo=datetime.timezone.utc)}]","mohsendata (Issue Creator) on (2024-07-23 05:12:06 UTC): We're also encountering this problem with database names; we're unable to pin a gold database at the header or trailer of databases with special characters (such as _ or ~) and necessitating the addition of a 'A' or 'Z' prefix to it.

rafpaf on (2024-10-22 13:57:52 UTC): Thank you, @mohsendata! This has now been fixed.

![Image](https://github.com/user-attachments/assets/459a1b1e-64f7-4ab5-9806-21108c841f7d)

"
2420486187,issue,open,,fix(admin/performance): Discarding changes after Schedule was edited does not reset the form,"![Kapture 2024-07-19 at 22 11 43](https://github.com/user-attachments/assets/0e8459c0-9dc0-4c9c-9f75-f1fd874839e1)

To reproduce:
1. In Admin/Performance, select a database (or the default policy), then Schedule, and fill out the form (or leave it as ""hourly"").
2. Click ""Save changes"".
3. Change the Schedule to something different, like ""Monthly"".
4. Click ""Discard changes"".

The form should now revert to its earlier state, but it doesn't.",rafpaf,2024-07-20 02:11:00+00:00,[],2025-02-05 19:22:09+00:00,,https://github.com/metabase/metabase/issues/45890,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/Cache', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2420181603,issue,closed,not_planned,Query Cache Environment Variables Ignored in v50,"### Describe the bug

In version 50, using environment variables to set default query cache values doesn't work.

### To Reproduce

1. Set up Metabase v50+ with the following environment variables:

MB_ENABLE_QUERY_CACHING=TRUE
MB_QUERY_CACHING_MIN_TTL=5

2. Navigate to the performance tab in Admin Settings and note that there are no references made to the environment variables having been set
3. Connect to a Postgres sample DB
4. Create a question with the query ""SELECT pg_sleep(10);""
5. Note that no cache is created for the question in the ""query_cache"" table

You can manually enable cache from the performance tab and rerun the pg_sleep query to see that it will generate a cache if the cache is configured manually. If you already have a Snowflake connection set up you can also test this with ""SELECT SYSTEM$WAIT(5);"" .

### Expected behavior

The environment variables should be respected

### Logs

_No response_

### Information about your Metabase installation

```JSON
v50.13
```


### Severity

Not fun for self hosted folks managing these settings programmatically.

### Additional context

_No response_",ixipixi,2024-07-19 22:54:09+00:00,[],2024-07-22 13:11:31+00:00,2024-07-22 13:11:31+00:00,https://github.com/metabase/metabase/issues/45886,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Needs Triage', '')]","[{'comment_id': 2242926774, 'issue_id': 2420181603, 'author': 'luizarakaki', 'body': 'This is a breaking change from v49, because the caching system evolved significantly on v50.\r\n\r\nNow, there are 3 available policies: `ttl`, `schedule`, and `duration`.\r\nThere is a new API endpoint to configure cache: https://www.metabase.com/docs/latest/api/cache\r\n\r\n`MB_QUERY_CACHING_MIN_TTL` was removed on v50. We are verifying why they are still in docs.', 'created_at': datetime.datetime(2024, 7, 22, 13, 11, 31, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-07-22 13:11:31 UTC): This is a breaking change from v49, because the caching system evolved significantly on v50.

Now, there are 3 available policies: `ttl`, `schedule`, and `duration`.
There is a new API endpoint to configure cache: https://www.metabase.com/docs/latest/api/cache

`MB_QUERY_CACHING_MIN_TTL` was removed on v50. We are verifying why they are still in docs.

"
2420168929,issue,closed,not_planned," org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint ""idx_uniq_field_table_id_parent_id_name_2col""","### Describe the bug

Error getting the fields of a table

### To Reproduce

Not sure. But one important thing is that there is another table in another schema with same name and fields and it works.

### Expected behavior

Correctly mapping of the table

### Logs

[log.log](https://github.com/user-attachments/files/16317564/log.log)


### Information about your Metabase installation

```JSON
- Metabase v0.50.6
- AWS Aurora Postgres
```


### Severity

Blocks the usage of a table

### Additional context

_No response_",douglaz,2024-07-19 22:48:13+00:00,[],2024-07-23 01:13:01+00:00,2024-07-22 22:28:00+00:00,https://github.com/metabase/metabase/issues/45885,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2243075940, 'issue_id': 2420168929, 'author': 'qnkhuat', 'body': 'Could you upgrade to the latest version and try again? \r\n\r\nWe have a fix related to this index in https://github.com/metabase/metabase/issues/44659#issuecomment-2192932023', 'created_at': datetime.datetime(2024, 7, 22, 14, 16, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243085200, 'issue_id': 2420168929, 'author': 'qnkhuat', 'body': 'probably a dup of https://github.com/metabase/metabase/issues/44459', 'created_at': datetime.datetime(2024, 7, 22, 14, 20, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243916700, 'issue_id': 2420168929, 'author': 'douglaz', 'body': 'Yes, it works, thanks!', 'created_at': datetime.datetime(2024, 7, 22, 22, 28, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-22 14:16:19 UTC): Could you upgrade to the latest version and try again? 

We have a fix related to this index in https://github.com/metabase/metabase/issues/44659#issuecomment-2192932023

qnkhuat on (2024-07-22 14:20:35 UTC): probably a dup of https://github.com/metabase/metabase/issues/44459

douglaz (Issue Creator) on (2024-07-22 22:28:00 UTC): Yes, it works, thanks!

"
2419839486,issue,open,,"Optionally remove ""add filter"" in the filters","**Is your feature request related to a problem? Please describe.**
A customer needs to remove the ""add filter"" in the filters as it confuses the users (they're using sandboxing so the filter options are limited)

**Describe the solution you'd like**
Remove the button ""add filter"" in the filter

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-19 20:54:44+00:00,[],2025-02-04 20:30:50+00:00,,https://github.com/metabase/metabase/issues/45879,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2419704614,issue,closed,completed,Selected boolean filter value will render twice in the dropdown menu,"### Describe the bug

When we're filtering on the boolean column, and the filter options are set to show in the dropdown menu, choosing either false or true will result in the duplicated list of options.

https://github.com/user-attachments/assets/cb682ed0-18a8-4471-9c9e-5a7c20bd6e77



### To Reproduce

The simplest repro would be to add Invoices to the dashboard and to add a text/category filter and connect it to expected invoice. But that tests it only in dashboards. The following repro will make it possible to check both questions and dashboards filters.

1. create a native query `SELECT * FROM INVOICES [[ where {{ boolean_param }} ]]` and map to field filter - Invoices.Expected_invoice.
2. Please note that we have either multiple options or a single option available here and they should both be tested
3. Save the question
4. Click on the filter and it should display a dropdown with two checkboxes (""true"" and ""false"")
5. Select either one of them (let's say we select ""true"").
6. Refresh the query and make sure the filter was applied correctly
7. Click on the filter again and you will see selected ""true"" checkbox rendered twice

https://github.com/user-attachments/assets/7f6c45a0-870c-4eb4-883c-886d7f5c85db

This same mechanism is present in a question, in a dashboard and in embedding AND in public dashboards.


### Expected behavior

Selecting a boolean column should result always in only two filter options (true and false) shown in the dropdown menu.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, b69d4d5, H2, Sample Database
```


### Severity

P2

### Additional context

Regression after #43293",nemanjaglumac,2024-07-19 19:34:26+00:00,['nemanjaglumac'],2024-10-08 16:20:11+00:00,2024-07-19 22:30:38+00:00,https://github.com/metabase/metabase/issues/45877,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Querying', '')]",[],
2419695387,issue,closed,completed,"""Exit admin"" button is sometimes offscreen","For example, here's French with a viewport width of 973px

![Image](https://github.com/user-attachments/assets/5006b5fc-386f-43ce-a266-b31eccba44c3)

German with a viewport width of 980px

![Image](https://github.com/user-attachments/assets/27761da6-dcd2-4013-ac72-566682a19600)

Russian with viewport of 1100px

![Image](https://github.com/user-attachments/assets/e4c961e9-b2b0-441a-b8b3-121e307cfc51)

Suggested workaround: set the hamburger-menu breakpoint based on a runtime calculation of the width of all the strings. We have a `measureTextWidth` function",rafpaf,2024-07-19 19:26:26+00:00,['rafpaf'],2024-07-31 02:06:49+00:00,2024-07-26 03:22:47+00:00,https://github.com/metabase/metabase/issues/45876,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2419650798,issue,open,,"Redshift sync can return stale metadata for a short amount of time after tables are deleted, or can fail completely","See this Slack thread https://metaboat.slack.com/archives/C5XHN8GLW/p1721339724075889

Redshift `describe-database` seems to sometimes return tables that were recently deleted. This has been causing test flakes for a while, since we then attempt to sync that table that no longer exists and `describe-table` on it fails.

We had an old hack in the code prior to my test data loading PR #45268 that disabled table deletion in tests for Redshift. I took that out because it broke a lot of stuff now that we don't destroy and recreate the test data a dozen times in test runs. In #45873 I introduced a new hack to enable normal robust sync behavior so sync should still complete normally even if a specific `describe-table` call fails.

Neither the old hack nor the new hack really address the fundamental root issue tho which is that Redshift sync is returning stale metadata for some unknown reason. We should try to figure out why this is the case and see if we can prevent it from happening. Is the query getting cached upstream? 

This is a pretty low-priority issue since it's probably not a problem in real life since we use the robust sync behavior in prod and timing seems to have to be pretty tight between dropping a table and running sync, but we should still look into this issue and make sure we're not inadvertently enabling query caching for sync metadata queries or anything like that. And removing the hack from #45873 will be nice.",camsaul,2024-07-19 19:03:28+00:00,[],2025-02-04 20:25:29+00:00,,https://github.com/metabase/metabase/issues/45874,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/Redshift', None), ('Administration/Metadata & Sync', ''), ('.CI & Tests', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2243819738, 'issue_id': 2419650798, 'author': 'camsaul', 'body': 'It seems like Redshift sync can actually fail entirely sometimes -- `driver/describe-database` can fail if there are recently deleted tables, for some reason. For example\r\n\r\nhttps://github.com/metabase/metabase/actions/runs/10038716376/job/27748689824#step:3:1431\r\n\r\n```\r\n[CLI-agent-send-off-pool-22] ERROR metabase.sync.fetch-metadata - Error while fetching metdata with \'db-metadata\'\r\ncom.amazon.redshift.util.RedshiftException: ERROR: relation ""2024_07_22_13d160b0_08a1_4a12_b85d_2c7348823961_schema.mwnpmfiotgmmwsjmldze"" does not exist\r\n\tat com.amazon.redshift.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2648) ~[redshift-jdbc42-2.1.0.28.jar:?]\r\n\tat com.amazon.redshift.core.v3.QueryExecutorImpl.processResultsOnThread(QueryExecutorImpl.java:2295) ~[redshift-jdbc42-2.1.0.28.jar:?]\r\n\tat com.amazon.redshift.core.v3.QueryExecutorImpl.access$000(QueryExecutorImpl.java:82) ~[redshift-jdbc42-2.1.0.28.jar:?]\r\n\tat com.amazon.redshift.core.v3.QueryExecutorImpl$RingBufferThread.run(QueryExecutorImpl.java:3128) ~[redshift-jdbc42-2.1.0.28.jar:?]\r\n```\r\n\r\nnot clear where the rest of the stacktrace is, but it\'s definitely triggered by this code in `metabase.sync.fetch-metadata`\r\n\r\n```clj\r\n(mu/defn db-metadata :- i/DatabaseMetadata\r\n  ""Get basic Metadata about a `database` and its Tables. Doesn\'t include information about the Fields.""\r\n  [database :- i/DatabaseInstance]\r\n  (log-if-error ""db-metadata""\r\n    (driver/describe-database (driver.u/database->driver database) database)))\r\n```', 'created_at': datetime.datetime(2024, 7, 22, 21, 9, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243859398, 'issue_id': 2419650798, 'author': 'camsaul', 'body': 'Here\'s a way to reliably reproduce Redshift sync failures\r\n\r\n```clj\r\n(ns metabase.driver.redshift-test ...)\r\n\r\n...\r\n\r\n;;; NOCOMMIT do not merge\r\n(defn reproduce-redshift-sync-failures []\r\n  (mt/test-driver :redshift\r\n    ;; make sure test data is loaded\r\n    (mt/db)\r\n    ;; create a DIFFERENT schema than our unique-session-schema to fill with trash asynchronously\r\n    (let [do-with-connection (fn [f]\r\n                               (sql-jdbc.execute/do-with-connection-with-options\r\n                                :redshift\r\n                                (sql-jdbc.conn/connection-details->spec :redshift @redshift.test/db-connection-details)\r\n                                {:write? true}\r\n                                f))\r\n          schema             (str (redshift.test/unique-session-schema) ""_2"")]\r\n      (locking println (println ""UNIQUE SESSION SCHEMA ="" (redshift.test/unique-session-schema)))\r\n      (try\r\n        (do-with-connection\r\n         (fn [^java.sql.Connection conn]\r\n           (with-open [stmt (.createStatement conn)]\r\n             (.execute stmt (format ""CREATE SCHEMA IF NOT EXISTS \\""%s\\"";"" schema)))))\r\n        ;; now asynchronously load a bunch of trash into the schema\r\n        (let [fut (future\r\n                    (do-with-connection\r\n                     (fn [^java.sql.Connection conn]\r\n                       (with-open [stmt (.createStatement conn)]\r\n                         (dotimes [_ 100]\r\n                           (let [table (u/lower-case-en (mt/random-name))]\r\n                             (locking println (println ""CREATING AND DROPPING"" schema table))\r\n                             (.execute stmt (format ""CREATE TABLE \\""%s\\"".\\""%s\\"" (id INTEGER);"" schema table))\r\n                             (.execute stmt (format ""DROP TABLE \\""%s\\"".\\""%s\\"";"" schema table))))))))]\r\n          (try\r\n            ;; now run sync a bunch of times and make sure it completes ok.\r\n            (dotimes [i 100]\r\n              (locking println (println ""Sync #"" i))\r\n              (let [sync-tables (:tables (driver/describe-database :redshift (mt/db)))]\r\n                (doseq [{sync-table-name :name, :as synced-table} sync-tables]\r\n                  (testing (format ""\\nsynced table: %s"" (u/pprint-to-str synced-table))\r\n                    (is (or (str/starts-with? sync-table-name ""test_data_"")\r\n                            (= sync-table-name ""extsales"")\r\n                            (#{""ioczvlzuryxmervumwrn"" ""umcwdqwjjaagvmrgrdhi""} sync-table-name)))))))\r\n            (finally\r\n              ;; cancel the async trash-loading future if it\'s still running.\r\n              (future-cancel fut))))\r\n        (finally\r\n          ;; clean up after ourselves and drop the test schema.\r\n          (do-with-connection\r\n           (fn [^java.sql.Connection conn]\r\n             (with-open [stmt (.createStatement conn)]\r\n               (.execute stmt (format ""DROP SCHEMA \\""%s\\"";"" schema))))))))))\r\n```', 'created_at': datetime.datetime(2024, 7, 22, 21, 38, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243867668, 'issue_id': 2419650798, 'author': 'camsaul', 'body': ""I don't know if there's a problem with the query used to power Redshift sync we added in https://github.com/metabase/metabase/pull/41068 or Redshift is just being terrible again.\r\n\r\nMaybe we can update the Redshift sync code to use the schema inclusion and exclusion patterns in the query itself instead of fetching every single table in the DB and then filtering them out client-side and maybe that would improve things"", 'created_at': datetime.datetime(2024, 7, 22, 21, 45, 13, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-07-22 21:09:33 UTC): It seems like Redshift sync can actually fail entirely sometimes -- `driver/describe-database` can fail if there are recently deleted tables, for some reason. For example

https://github.com/metabase/metabase/actions/runs/10038716376/job/27748689824#step:3:1431

```
[CLI-agent-send-off-pool-22] ERROR metabase.sync.fetch-metadata - Error while fetching metdata with 'db-metadata'
com.amazon.redshift.util.RedshiftException: ERROR: relation ""2024_07_22_13d160b0_08a1_4a12_b85d_2c7348823961_schema.mwnpmfiotgmmwsjmldze"" does not exist
	at com.amazon.redshift.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2648) ~[redshift-jdbc42-2.1.0.28.jar:?]
	at com.amazon.redshift.core.v3.QueryExecutorImpl.processResultsOnThread(QueryExecutorImpl.java:2295) ~[redshift-jdbc42-2.1.0.28.jar:?]
	at com.amazon.redshift.core.v3.QueryExecutorImpl.access$000(QueryExecutorImpl.java:82) ~[redshift-jdbc42-2.1.0.28.jar:?]
	at com.amazon.redshift.core.v3.QueryExecutorImpl$RingBufferThread.run(QueryExecutorImpl.java:3128) ~[redshift-jdbc42-2.1.0.28.jar:?]
```

not clear where the rest of the stacktrace is, but it's definitely triggered by this code in `metabase.sync.fetch-metadata`

```clj
(mu/defn db-metadata :- i/DatabaseMetadata
  ""Get basic Metadata about a `database` and its Tables. Doesn't include information about the Fields.""
  [database :- i/DatabaseInstance]
  (log-if-error ""db-metadata""
    (driver/describe-database (driver.u/database->driver database) database)))
```

camsaul (Issue Creator) on (2024-07-22 21:38:37 UTC): Here's a way to reliably reproduce Redshift sync failures

```clj
(ns metabase.driver.redshift-test ...)

...

;;; NOCOMMIT do not merge
(defn reproduce-redshift-sync-failures []
  (mt/test-driver :redshift
    ;; make sure test data is loaded
    (mt/db)
    ;; create a DIFFERENT schema than our unique-session-schema to fill with trash asynchronously
    (let [do-with-connection (fn [f]
                               (sql-jdbc.execute/do-with-connection-with-options
                                :redshift
                                (sql-jdbc.conn/connection-details->spec :redshift @redshift.test/db-connection-details)
                                {:write? true}
                                f))
          schema             (str (redshift.test/unique-session-schema) ""_2"")]
      (locking println (println ""UNIQUE SESSION SCHEMA ="" (redshift.test/unique-session-schema)))
      (try
        (do-with-connection
         (fn [^java.sql.Connection conn]
           (with-open [stmt (.createStatement conn)]
             (.execute stmt (format ""CREATE SCHEMA IF NOT EXISTS \""%s\"";"" schema)))))
        ;; now asynchronously load a bunch of trash into the schema
        (let [fut (future
                    (do-with-connection
                     (fn [^java.sql.Connection conn]
                       (with-open [stmt (.createStatement conn)]
                         (dotimes [_ 100]
                           (let [table (u/lower-case-en (mt/random-name))]
                             (locking println (println ""CREATING AND DROPPING"" schema table))
                             (.execute stmt (format ""CREATE TABLE \""%s\"".\""%s\"" (id INTEGER);"" schema table))
                             (.execute stmt (format ""DROP TABLE \""%s\"".\""%s\"";"" schema table))))))))]
          (try
            ;; now run sync a bunch of times and make sure it completes ok.
            (dotimes [i 100]
              (locking println (println ""Sync #"" i))
              (let [sync-tables (:tables (driver/describe-database :redshift (mt/db)))]
                (doseq [{sync-table-name :name, :as synced-table} sync-tables]
                  (testing (format ""\nsynced table: %s"" (u/pprint-to-str synced-table))
                    (is (or (str/starts-with? sync-table-name ""test_data_"")
                            (= sync-table-name ""extsales"")
                            (#{""ioczvlzuryxmervumwrn"" ""umcwdqwjjaagvmrgrdhi""} sync-table-name)))))))
            (finally
              ;; cancel the async trash-loading future if it's still running.
              (future-cancel fut))))
        (finally
          ;; clean up after ourselves and drop the test schema.
          (do-with-connection
           (fn [^java.sql.Connection conn]
             (with-open [stmt (.createStatement conn)]
               (.execute stmt (format ""DROP SCHEMA \""%s\"";"" schema))))))))))
```

camsaul (Issue Creator) on (2024-07-22 21:45:13 UTC): I don't know if there's a problem with the query used to power Redshift sync we added in https://github.com/metabase/metabase/pull/41068 or Redshift is just being terrible again.

Maybe we can update the Redshift sync code to use the schema inclusion and exclusion patterns in the query itself instead of fetching every single table in the DB and then filtering them out client-side and maybe that would improve things

"
2419466587,issue,open,,Metabase should not run if it can't decrypt the encrypted values,"**Is your feature request related to a problem? Please describe.**
If you run Metabase without an encryption key but the values are encrypted, you will get stuff like
![image](https://github.com/user-attachments/assets/3565836d-4460-478c-8f6e-3cc9a3bcb702)

**Describe the solution you'd like**
Metabase should not start if it can't decrypt the values

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
For our own mental sanity

**Additional context**
NA
",paoliniluis,2024-07-19 17:23:56+00:00,[],2025-02-04 20:30:45+00:00,,https://github.com/metabase/metabase/issues/45869,"[('Type:New Feature', ''), ('Operation/', ''), ('Operation/Environment variables', '')]",[],
2419159413,issue,open,,"Incorrect cumulative sum is with grouping (v49, H2)","### Describe the bug

Cumulative sum when used with a grouped dataset produces incorrect results in v49.21 while using the H2 database .
Note that this appears to be working in v50.13.

### To Reproduce

1. Create a native model (use H2 / Sample Database as source):
```
SELECT '2024-01-01' AS ""Date"",'A' AS ""Category"", 1 as ""Value""
UNION SELECT '2024-01-02','A',1
UNION SELECT '2024-01-03','A',1
UNION SELECT '2024-01-04','A',0
UNION SELECT '2024-01-05','A',1
UNION SELECT '2024-01-01','B',0
UNION SELECT '2024-01-02','B',0 
UNION SELECT '2024-01-03','B',1
UNION SELECT '2024-01-04','B',1
UNION SELECT '2024-01-04','B',0
UNION SELECT '2024-01-05','B',0
```
2. Build a question:
* cumulative sum of value
* group by date, category

3. See the error: 
<img width=""417"" alt=""image"" src=""https://github.com/user-attachments/assets/d25c33f9-e427-49aa-94da-0a733414198c"">


### Expected behavior

It should work.

### Logs

_No response_

### Information about your Metabase installation

```JSON
1.49.21
```


### Severity

Reported by a customer who is still on v49

### Additional context

_No response_",zbodi74,2024-07-19 15:01:27+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/45857,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/H2', None), ('Querying/Processor', ''), ('.Correctness', ''), ('Database/Snowflake', ''), ('.Backend', ''), ('.Team/Querying', ''), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2239435553, 'issue_id': 2419159413, 'author': 'perivamsi', 'body': 'This is fairly hard to backport to 49. My suggestion is to wait until the customer upgrades to 50 (whenever 50 is ready) instead of trying to backport the change to 49.', 'created_at': datetime.datetime(2024, 7, 19, 15, 14, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241172539, 'issue_id': 2419159413, 'author': 'zbodi74', 'body': ""@perivamsi - It's fine not to backport it, considering v50 will be cloud-ready soon. \r\nNote that the same issue occurs with Snowflake, though I haven't had a chance to confirm it works on v50 yet."", 'created_at': datetime.datetime(2024, 7, 20, 14, 45, 8, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-19 15:14:51 UTC): This is fairly hard to backport to 49. My suggestion is to wait until the customer upgrades to 50 (whenever 50 is ready) instead of trying to backport the change to 49.

zbodi74 (Issue Creator) on (2024-07-20 14:45:08 UTC): @perivamsi - It's fine not to backport it, considering v50 will be cloud-ready soon. 
Note that the same issue occurs with Snowflake, though I haven't had a chance to confirm it works on v50 yet.

"
2419095670,issue,open,,[wip] Some strings are not translated because ttag functions must be run after locale is set,,rafpaf,2024-07-19 14:39:06+00:00,[],2024-07-19 14:39:14+00:00,,https://github.com/metabase/metabase/issues/45856,[],[],
2419038462,issue,open,,Cannot fetch (dropdown) values in a static embedding preview after the disabled or locked param has been published,"### Describe the bug

The dropdown values fetch is failing in a static embedding preview after the disabled or locked param has been published. That is - after we first publish disabled or locked and then change back to editable, the dropdown will not be shown in the preview.
GET request fails with:
`Cannot search for values: ""text"" is not an enabled parameter.`

You need to re-publish to be able to see a dropdown in the embed preview again.

### To Reproduce

1. Save ""People"" table as a question, and add it to a dashboard ""People in a dashboard""
2. Add a text/category filter to the dashboard and connect it to people.source (multiple values, dropdown)
3. Go to static embedding set up for the dashboard
4. The parameter will be ""Disabled by default""
5. Change it to editable and make sure that clicking on the filter in the preview gives you a dropdown will all options
6. Now set it to either locked or disabled and Publish
7. Change it back to editable, but do not re-publish
8. The preview now shows only a plain text input

The dropdown will be shows only after you publish again.


### Expected behavior

I would expect the preview to work even without re-publishing since that matches the initial behavior. In other words, if it's possible to fetch all values before we publish this embed in the first place, it should be possible to have a preview that corresponds to changes in the preview panel even after we publish.

These two worlds should not depend on each other.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, master, ec4d441, H2, Sample Database
```


### Severity

P3, since the actual embed is working

### Additional context

_No response_",nemanjaglumac,2024-07-19 14:18:49+00:00,[],2025-02-04 20:25:48+00:00,,https://github.com/metabase/metabase/issues/45853,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2239432450, 'issue_id': 2419038462, 'author': 'nemanjaglumac', 'body': ""I've been going through the Metabase history and this might be an important context:\r\nThe dropdown with all values in the preview was never there in previous versions. I've just checked 0.50.13.\r\n\r\nTo be clear, I'm talking about the step 5 from the reproduction steps."", 'created_at': datetime.datetime(2024, 7, 19, 15, 12, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298737839, 'issue_id': 2419038462, 'author': 'albertoperdomo', 'body': 'When a change is made to the parameters, the following notice is displayed at the top, to prompt the user to publish.\r\nWe could expand it and add a note about filters not updated in preview until published, perhaps?\r\n\r\n<img width=""1149"" alt=""image"" src=""https://github.com/user-attachments/assets/6ff785d8-363c-49a0-81a6-c2cba2ef0f17"">', 'created_at': datetime.datetime(2024, 8, 20, 12, 27, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298796041, 'issue_id': 2419038462, 'author': 'ixipixi', 'body': '@albertoperdomo is the purpose of the preview to let users see how their changes will impact the embedded application before they publish it?', 'created_at': datetime.datetime(2024, 8, 20, 12, 56, 35, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Issue Creator) on (2024-07-19 15:12:54 UTC): I've been going through the Metabase history and this might be an important context:
The dropdown with all values in the preview was never there in previous versions. I've just checked 0.50.13.

To be clear, I'm talking about the step 5 from the reproduction steps.

albertoperdomo on (2024-08-20 12:27:54 UTC): When a change is made to the parameters, the following notice is displayed at the top, to prompt the user to publish.
We could expand it and add a note about filters not updated in preview until published, perhaps?

<img width=""1149"" alt=""image"" src=""https://github.com/user-attachments/assets/6ff785d8-363c-49a0-81a6-c2cba2ef0f17"">

ixipixi on (2024-08-20 12:56:35 UTC): @albertoperdomo is the purpose of the preview to let users see how their changes will impact the embedded application before they publish it?

"
2418994919,issue,open,,Export custom column names as key=val instead of just the name being the key,"**Is your feature request related to a problem? Please describe.**
We have a customer that translates all the UI including the custom columns, but as they translate things via key=val, and custom column names are just the key name, the tool can't get it

**Describe the solution you'd like**
Transform the custom column names as key=val
![image](https://github.com/user-attachments/assets/ee552d35-bd14-4256-9220-dbc685cf7689)

**Describe alternatives you've considered**
Some custom logic should be implemented

**How important is this feature to you?**
Requested by a customer

**Additional context**
NA
",paoliniluis,2024-07-19 13:59:26+00:00,[],2025-02-04 20:30:58+00:00,,https://github.com/metabase/metabase/issues/45852,"[('Type:New Feature', ''), ('Operation/Serialization', 'Enterprise contents migration')]",[],
2418716266,issue,open,,Issue with Incorrect Value Presentation in Chart after multiplying,"### Describe the bug

Since Stripe reports revenue in cents, I need to multiply the dataset values by 0.01 to convert them to dollars. However, when I do this and try to add another series to the chart, the values of the second dataset are displayed incorrectly.

Could you please assist with this issue?

<img width=""960"" alt=""Screenshot 2024-07-19 at 13 46 56"" src=""https://github.com/user-attachments/assets/b49968d9-944e-4b66-9e7d-b3c187503e13"">


### To Reproduce

1. Try to visualize two different data sets
2. Multiply one dataset by 0.01
3. Check values


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version v0.49.14, self-hosted as docker container on AWS
```


### Severity

URGENT

### Additional context

_No response_",tilensavnik,2024-07-19 11:57:23+00:00,[],2025-02-04 20:31:26+00:00,,https://github.com/metabase/metabase/issues/45846,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Correctness', ''), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2246676964, 'issue_id': 2418716266, 'author': 'perivamsi', 'body': '@tilensavnik can you please go to the ""axes"" tab and see if ""split y-axis when necessary"" is checked or unchecked? can you toggle it and see if that helps?', 'created_at': datetime.datetime(2024, 7, 24, 1, 21, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247055224, 'issue_id': 2418716266, 'author': 'tilensavnik', 'body': ""Hey @perivamsi, thanks for the tip. I tried it, it doesn't work"", 'created_at': datetime.datetime(2024, 7, 24, 7, 0, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247273464, 'issue_id': 2418716266, 'author': 'perivamsi', 'body': 'Can you send me screenshots with ""Split y-axis when necessary"" turned off and also turned on?', 'created_at': datetime.datetime(2024, 7, 24, 8, 54, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247283480, 'issue_id': 2418716266, 'author': 'tilensavnik', 'body': 'Issue persists...\r\n<img width=""1274"" alt=""Screenshot 2024-07-24 at 10 55 38"" src=""https://github.com/user-attachments/assets/be7454b2-0816-43ab-a58c-236de1d0dbfc"">\r\n<img width=""1269"" alt=""Screenshot 2024-07-24 at 10 55 45"" src=""https://github.com/user-attachments/assets/f5e6084a-892b-409b-a0fc-dba2f0ca203d"">', 'created_at': datetime.datetime(2024, 7, 24, 8, 57, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2247300621, 'issue_id': 2418716266, 'author': 'perivamsi', 'body': 'Can you press [`Ctrl + F1` or `Cmd + F1`](https://www.metabase.com/docs/latest/troubleshooting-guide/diagnostic-info) and send me the question definition?\r\n\r\n<img width=""602"" alt=""Screenshot 2024-07-24 at 5 02 42\u202fAM"" src=""https://github.com/user-attachments/assets/5331a067-9571-4889-9a29-199a2b1ae703"">', 'created_at': datetime.datetime(2024, 7, 24, 9, 4, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274008648, 'issue_id': 2418716266, 'author': 'cdeweyx', 'body': 'Having trouble reproducing this [here](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiYWdncmVnYXRpb24iOltbImFnZ3JlZ2F0aW9uLW9wdGlvbnMiLFsic3VtIixbImZpZWxkIiw1NzAyOTgseyJiYXNlLXR5cGUiOiJ0eXBlL0Zsb2F0In1dXSx7Im5hbWUiOiJBUlIiLCJkaXNwbGF5LW5hbWUiOiJBUlIifV0sWyJhZ2dyZWdhdGlvbi1vcHRpb25zIixbImNvdW50Il0seyJuYW1lIjoic2Rmc2QiLCJkaXNwbGF5LW5hbWUiOiJzZGZzZCJ9XV0sImJyZWFrb3V0IjpbWyJmaWVsZCIsInJlY29nbml6ZWRfYXQiLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlIiwidGVtcG9yYWwtdW5pdCI6Im1vbnRoIn1dLFsiZmllbGQiLDU1Mjc3NCx7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XV0sInNvdXJjZS10YWJsZSI6ImNhcmRfXzcyOTEiLCJmaWx0ZXIiOlsidGltZS1pbnRlcnZhbCIsWyJmaWVsZCIsNTUyNzkxLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlIn1dLC0xMiwibW9udGgiLHsiaW5jbHVkZS1jdXJyZW50Ijp0cnVlfV19fSwiZGlzcGxheSI6ImJhciIsImRpc3BsYXlJc0xvY2tlZCI6dHJ1ZSwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnsiZ3JhcGgueV9heGlzLnRpdGxlX3RleHQiOiJSZXZlbnVlICgkKSIsImdyYXBoLnNob3dfdmFsdWVzIjp0cnVlLCJ0YWJsZS5jZWxsX2NvbHVtbiI6IkFSUiIsImdyYXBoLnNlcmllc19vcmRlcl9kaW1lbnNpb24iOm51bGwsImdyYXBoLnhfYXhpcy50aXRsZV90ZXh0IjoiTW9udGgiLCJncmFwaC5tZXRyaWNzIjpbInNkZnNkIiwiQVJSIl0sImdyYXBoLmxhYmVsX3ZhbHVlX2Zvcm1hdHRpbmciOiJhdXRvIiwiZ3JhcGguc2VyaWVzX29yZGVyIjpudWxsLCJ0YWJsZS5waXZvdF9jb2x1bW4iOiJkYXRlIiwiY29sdW1uX3NldHRpbmdzIjp7IltcIm5hbWVcIixcIkFSUlwiXSI6eyJwcmVmaXgiOiIiLCJudW1iZXJfc3R5bGUiOiJjdXJyZW5jeSIsImRlY2ltYWxzIjowfSwiW1wibmFtZVwiLFwic2Rmc2RcIl0iOnsic2NhbGUiOjAuMDF9fSwiZ3JhcGguZGltZW5zaW9ucyI6WyJyZWNvZ25pemVkX2F0Il0sInN0YWNrYWJsZS5zdGFja190eXBlIjpudWxsLCJncmFwaC55X2F4aXMuYXV0b19zcGxpdCI6dHJ1ZSwic2VyaWVzX3NldHRpbmdzIjp7InBybyI6eyJjb2xvciI6IiNGMkE4NkYifSwicHJlbWl1bS1lbWJlZGRpbmctZGVwcmVjYXRlZCI6eyJjb2xvciI6IiNGN0M0QzQifSwic3RhcnRlciI6eyJjb2xvciI6IiM4OEJGNEQifSwiZ3Jvd3RoIjp7ImNvbG9yIjoiIzg4QkY0RCJ9fX0sIm9yaWdpbmFsX2NhcmRfaWQiOjExNjkxLCJ0eXBlIjoicXVlc3Rpb24ifQ==).', 'created_at': datetime.datetime(2024, 8, 7, 17, 49, 44, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-07-24 01:21:54 UTC): @tilensavnik can you please go to the ""axes"" tab and see if ""split y-axis when necessary"" is checked or unchecked? can you toggle it and see if that helps?

tilensavnik (Issue Creator) on (2024-07-24 07:00:26 UTC): Hey @perivamsi, thanks for the tip. I tried it, it doesn't work

perivamsi on (2024-07-24 08:54:08 UTC): Can you send me screenshots with ""Split y-axis when necessary"" turned off and also turned on?

tilensavnik (Issue Creator) on (2024-07-24 08:57:45 UTC): Issue persists...
<img width=""1274"" alt=""Screenshot 2024-07-24 at 10 55 38"" src=""https://github.com/user-attachments/assets/be7454b2-0816-43ab-a58c-236de1d0dbfc"">
<img width=""1269"" alt=""Screenshot 2024-07-24 at 10 55 45"" src=""https://github.com/user-attachments/assets/f5e6084a-892b-409b-a0fc-dba2f0ca203d"">

perivamsi on (2024-07-24 09:04:29 UTC): Can you press [`Ctrl + F1` or `Cmd + F1`](https://www.metabase.com/docs/latest/troubleshooting-guide/diagnostic-info) and send me the question definition?

<img width=""602"" alt=""Screenshot 2024-07-24 at 5 02 42 AM"" src=""https://github.com/user-attachments/assets/5331a067-9571-4889-9a29-199a2b1ae703"">

cdeweyx on (2024-08-07 17:49:44 UTC): Having trouble reproducing this [here](https://stats.metabase.com/question#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiYWdncmVnYXRpb24iOltbImFnZ3JlZ2F0aW9uLW9wdGlvbnMiLFsic3VtIixbImZpZWxkIiw1NzAyOTgseyJiYXNlLXR5cGUiOiJ0eXBlL0Zsb2F0In1dXSx7Im5hbWUiOiJBUlIiLCJkaXNwbGF5LW5hbWUiOiJBUlIifV0sWyJhZ2dyZWdhdGlvbi1vcHRpb25zIixbImNvdW50Il0seyJuYW1lIjoic2Rmc2QiLCJkaXNwbGF5LW5hbWUiOiJzZGZzZCJ9XV0sImJyZWFrb3V0IjpbWyJmaWVsZCIsInJlY29nbml6ZWRfYXQiLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlIiwidGVtcG9yYWwtdW5pdCI6Im1vbnRoIn1dLFsiZmllbGQiLDU1Mjc3NCx7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XV0sInNvdXJjZS10YWJsZSI6ImNhcmRfXzcyOTEiLCJmaWx0ZXIiOlsidGltZS1pbnRlcnZhbCIsWyJmaWVsZCIsNTUyNzkxLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlIn1dLC0xMiwibW9udGgiLHsiaW5jbHVkZS1jdXJyZW50Ijp0cnVlfV19fSwiZGlzcGxheSI6ImJhciIsImRpc3BsYXlJc0xvY2tlZCI6dHJ1ZSwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnsiZ3JhcGgueV9heGlzLnRpdGxlX3RleHQiOiJSZXZlbnVlICgkKSIsImdyYXBoLnNob3dfdmFsdWVzIjp0cnVlLCJ0YWJsZS5jZWxsX2NvbHVtbiI6IkFSUiIsImdyYXBoLnNlcmllc19vcmRlcl9kaW1lbnNpb24iOm51bGwsImdyYXBoLnhfYXhpcy50aXRsZV90ZXh0IjoiTW9udGgiLCJncmFwaC5tZXRyaWNzIjpbInNkZnNkIiwiQVJSIl0sImdyYXBoLmxhYmVsX3ZhbHVlX2Zvcm1hdHRpbmciOiJhdXRvIiwiZ3JhcGguc2VyaWVzX29yZGVyIjpudWxsLCJ0YWJsZS5waXZvdF9jb2x1bW4iOiJkYXRlIiwiY29sdW1uX3NldHRpbmdzIjp7IltcIm5hbWVcIixcIkFSUlwiXSI6eyJwcmVmaXgiOiIiLCJudW1iZXJfc3R5bGUiOiJjdXJyZW5jeSIsImRlY2ltYWxzIjowfSwiW1wibmFtZVwiLFwic2Rmc2RcIl0iOnsic2NhbGUiOjAuMDF9fSwiZ3JhcGguZGltZW5zaW9ucyI6WyJyZWNvZ25pemVkX2F0Il0sInN0YWNrYWJsZS5zdGFja190eXBlIjpudWxsLCJncmFwaC55X2F4aXMuYXV0b19zcGxpdCI6dHJ1ZSwic2VyaWVzX3NldHRpbmdzIjp7InBybyI6eyJjb2xvciI6IiNGMkE4NkYifSwicHJlbWl1bS1lbWJlZGRpbmctZGVwcmVjYXRlZCI6eyJjb2xvciI6IiNGN0M0QzQifSwic3RhcnRlciI6eyJjb2xvciI6IiM4OEJGNEQifSwiZ3Jvd3RoIjp7ImNvbG9yIjoiIzg4QkY0RCJ9fX0sIm9yaWdpbmFsX2NhcmRfaWQiOjExNjkxLCJ0eXBlIjoicXVlc3Rpb24ifQ==).

"
2417401792,issue,closed,completed,Metric saved in the personal collection is visible to other people in the summarize block,"### Describe the bug

Anything stored in the personal collection must be hidden from other people, including metrics

### To Reproduce

1. Click on + New metric
2. Choose any date source and aggregation
3. Save a metric to your personal collection
4. Login from another account
5. Click on + New question
6. Choose the same data source
7. See the saved metric in the Common metrics list in the Summarize block


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Breaks major use cases

### Additional context

_No response_",mngr,2024-07-18 21:03:55+00:00,['metamben'],2024-10-08 16:16:48+00:00,2024-08-21 18:45:54+00:00,https://github.com/metabase/metabase/issues/45832,"[('Type:New Feature', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', ''), ('Querying/Metrics', 'v2'), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2417192910,issue,closed,completed,[Epic] Metrics defined on a question/model should be shown in the summarize block,"Product doc https://www.notion.so/metabase/Querying-and-combining-metrics-defined-on-the-same-data-source-1229f547df8140ce9c6f96cd707d28a5
Depends on https://github.com/metabase/metabase/pull/46054

### Describe the bug

If you create a metric that is defined on top of a model, and then start new question based on that model, you won't see this metric in the Common Metrics list in the Summarize block

### To Reproduce

1. Go to + New metric
2. Choose any model as a data source
3. Choose any aggregation
4. Save this metric
5. Go to + New question
6. Choose the same model as a data source
7. Click on Summarize
8. There is no Common metrics with your newly created metric there


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Breaks major use cases

### Implementation details

We currently allow single stage metrics only. Please note that there is a follow-up epic https://github.com/metabase/metabase/issues/46055

```[tasklist]
- [x] Allow card-based metrics in aggregation clauses in the QP
- [x] Return compatible card-based `:metrics` in query metadata
```

",mngr,2024-07-18 19:13:32+00:00,[],2024-10-08 16:18:38+00:00,2024-08-06 21:42:16+00:00,https://github.com/metabase/metabase/issues/45824,"[('Type:New Feature', ''), ('Cloud-Blocker:51', 'Issues blocking the cloud customers to be upgraded to v51')]",[],
2417159417,issue,open,,"Real-time, card-based reload in dashboard","**Is your feature request related to a problem? Please describe.**
right now, you set up a dashboard refresh but the timeframe is too long for some use cases, and there is no option to set it up for specific cards. 

**Describe the solution you'd like**
An option to set cards in dashboard to reload in real time (1-10 seconds). Grafana is a very good example of this. 

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Very relevant for real-time use cases.

**Additional context**
We have the following related feature requests: https://github.com/metabase/metabase/issues/7133 https://github.com/metabase/metabase/issues/31924
",ignacio-mb,2024-07-18 18:51:55+00:00,[],2025-02-04 20:30:32+00:00,,https://github.com/metabase/metabase/issues/45821,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Querying/', '')]",[],
2417117462,issue,open,,"Trend visualization should support binning by ""Last 30 days"" and not just by Month","**Is your feature request related to a problem? Please describe.**
The binning options for using the ""Trend"" visualization are limited and not useful.  For example, comparing a Month-over-Month trend is a little pointless when the current Month is still in progress?  

**Describe the solution you'd like**
Comparing Trailing 30d with a previous 30d period is an example of a useful comparable trend.  

",ronrlin,2024-07-18 18:43:09+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/45820,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/Querying', '')]","[{'comment_id': 2569215861, 'issue_id': 2417117462, 'author': 'brunobergher', 'body': 'Related to #33126 as it deals with incomplete periods.', 'created_at': datetime.datetime(2025, 1, 3, 13, 22, 48, tzinfo=datetime.timezone.utc)}]","brunobergher on (2025-01-03 13:22:48 UTC): Related to #33126 as it deals with incomplete periods.

"
2417054291,issue,open,,Snowflake Native SQL Pivot Fails if it calls a CTE that contains a Text Variable,"### Describe the bug

SQL compilation error is returned if a TEXT variable is used in a CTE that is later called within a PIVOT function

### To Reproduce

1. Set up Metabase (texted in 48, 49 and 50)
2. Connect to Sample DB in Snowflake
3. Create native SQL question with this query:

```
with select_stuff

as

(SELECT
  ""PUBLIC"".""people"".""id"" AS ""id"",
  ""PUBLIC"".""people"".""address"" AS ""address"",
  ""PUBLIC"".""people"".""email"" AS ""email"",
  ""PUBLIC"".""people"".""password"" AS ""password"",
  ""PUBLIC"".""people"".""name"" AS ""name"",
  ""PUBLIC"".""people"".""city"" AS ""city"",
  ""PUBLIC"".""people"".""state"" AS ""state"",
  ""PUBLIC"".""people"".""source"" AS ""source""
FROM
  ""v3_sample-dataset"".""PUBLIC"".""people""
    where 1=1 [[and ""email""={{var}}]]
LIMIT 5)

select * from select_stuff
PIVOT(count(""state"") for ""state"" in 
    (SELECT DISTINCT ""state"" FROM select_stuff)
)
```

4. Execute without a value assigned to a variable and note that it works
5. Assign a value to the TEXT variable and observe error:

`SQL compilation error: error line 12 at position 26 Bind variable ? not set.`

6. Change variable type to INT or DATE and observe that query compiles as expected


### Expected behavior

The query should compile correctly for all variable types.

### Logs

[e3f27a21-a62e-4f34-b2b6-beffa2b7293a] 2024-07-18T13:09:10-05:00 DEBUG metabase.server.middleware.log GET /api/health 200 154.1 µs (0 DB calls) App DB connections: 2/7 Jetty threads: 7/50 (1 idle, 0 queued) (136 total active threads) Queries in flight: 0 (0 queued)
[e3f27a21-a62e-4f34-b2b6-beffa2b7293a] 2024-07-18T13:09:20-05:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: SQL compilation error: error line 12 at position 26
Bind variable ? not set.
{:database_id 2,
 :started_at #t ""2024-07-18T18:09:19.320318Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: SQL compilation error: error line 12 at position 26\nBind variable ? not set."",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__78370$fn__78371.invoke(execute.clj:698)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__78370.invoke(execute.clj:695)""
    ""driver.sql_jdbc.execute$fn__78163$fn__78164.invoke(execute.clj:388)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
    ""driver.sql_jdbc.execute$fn__78163.invokeStatic(execute.clj:382)""
    ""driver.sql_jdbc.execute$fn__78163.invoke(execute.clj:380)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:686)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc$fn__111692.invokeStatic(sql_jdbc.clj:82)""
    ""driver.sql_jdbc$fn__111692.invoke(sql_jdbc.clj:80)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71351.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65323.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71172.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71182.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70419.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__72485$combined_post_process__72490$combined_post_process_STAR___72491.invoke(query_processor.clj:262)""
    ""query_processor$fn__72485$combined_pre_process__72486$combined_pre_process_STAR___72487.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65420.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71262$fn__71266.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71262.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__65812$fn__65813.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__65812.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71259.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71564.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71199$handle_audit_app_internal_queries__71200$fn__71202.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71210.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70134.invoke(constraints.clj:102)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71495.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72085.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___60983$thunk__60985.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___60983.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___60995.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__94611.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51829$fn__51831.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51829.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43153.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :snowflake,
    :sql
    [""with select_stuff as (""
     ""  SELECT""
     ""    \""PUBLIC\"".\""people\"".\""id\"" AS \""id\"",""
     ""    \""PUBLIC\"".\""people\"".\""address\"" AS \""address\"",""
     ""    \""PUBLIC\"".\""people\"".\""email\"" AS \""email\"",""
     ""    \""PUBLIC\"".\""people\"".\""password\"" AS \""password\"",""
     ""    \""PUBLIC\"".\""people\"".\""name\"" AS \""name\"",""
     ""    \""PUBLIC\"".\""people\"".\""city\"" AS \""city\"",""
     ""    \""PUBLIC\"".\""people\"".\""state\"" AS \""state\"",""
     ""    \""PUBLIC\"".\""people\"".\""source\"" AS \""source\""""
     ""  FROM""
     ""    \""v3_sample-dataset\"".\""PUBLIC\"".\""people\""""
     ""  where""
     ""    1 = 1""
     ""    and \""email\"" = ?""
     ""  LIMIT""
     ""    5""
     "")""
     ""select""
     ""  *""
     ""from""
     ""  select_stuff PIVOT(""
     ""    count(\""state\"") for \""state\"" in (""
     ""      SELECT""
     ""        DISTINCT \""state\""""
     ""      FROM""
     ""        select_stuff""
     ""    )""
     ""  ) -- {\""pulseId\"":null,\""serverId\"":\""f145d8aa-f996-40f4-899b-8d154e1cd187\"",\""client\"":\""Metabase\"",\""queryHash\"":\""8572e1f3c8eb47a5b9f932f7ea0b7b71dcf3abac096e7ff467c0c6b764462b2e\"",\""queryType\"":\""native\"",\""cardId\"":null,\""dashboardId\"":null,\""context\"":\""ad-hoc\"",\""userId\"":1,\""databaseId\"":2}""],
    :params [""a""],
    :type :invalid-query}}],
 :action_id nil,
 :state ""42601"",
 :error_type :invalid-query,
 :json_query
 {:native
  {:collection ""people"",
   :template-tags {:var {:type ""text"", :name ""var"", :id ""90aa7355-2d79-4353-93a0-0d9dcee5f824"", :display-name ""Var""}},
   :query
   ""with select_stuff\n\nas\n\n(SELECT\n  \""PUBLIC\"".\""people\"".\""id\"" AS \""id\"",\n  \""PUBLIC\"".\""people\"".\""address\"" AS \""address\"",\n  \""PUBLIC\"".\""people\"".\""email\"" AS \""email\"",\n  \""PUBLIC\"".\""people\"".\""password\"" AS \""password\"",\n  \""PUBLIC\"".\""people\"".\""name\"" AS \""name\"",\n  \""PUBLIC\"".\""people\"".\""city\"" AS \""city\"",\n  \""PUBLIC\"".\""people\"".\""state\"" AS \""state\"",\n  \""PUBLIC\"".\""people\"".\""source\"" AS \""source\""\nFROM\n  \""v3_sample-dataset\"".\""PUBLIC\"".\""people\""\n    where 1=1 [[and \""email\""={{var}}]]\nLIMIT 5)\n\nselect * from select_stuff\nPIVOT(count(\""state\"") for \""state\"" in \n    (SELECT DISTINCT \""state\"" FROM select_stuff)\n)\n""},
  :database 2,
  :type ""native"",
  :parameters
  [{:id ""90aa7355-2d79-4353-93a0-0d9dcee5f824"",
    :type ""category"",
    :value ""a"",
    :target [""variable"" [""template-tag"" ""var""]]}],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class net.snowflake.client.jdbc.SnowflakeSQLException,
 :stacktrace
 [""net.snowflake.client.jdbc.SnowflakeUtil.checkErrorAndThrowExceptionSub(SnowflakeUtil.java:144)""
  ""net.snowflake.client.jdbc.SnowflakeUtil.checkErrorAndThrowException(SnowflakeUtil.java:77)""
  ""net.snowflake.client.core.StmtUtil.pollForOutput(StmtUtil.java:501)""
  ""net.snowflake.client.core.StmtUtil.execute(StmtUtil.java:407)""
  ""net.snowflake.client.core.SFStatement.executeHelper(SFStatement.java:482)""
  ""net.snowflake.client.core.SFStatement.executeQueryInternal(SFStatement.java:199)""
  ""net.snowflake.client.core.SFStatement.executeQuery(SFStatement.java:133)""
  ""net.snowflake.client.core.SFStatement.execute(SFStatement.java:769)""
  ""net.snowflake.client.core.SFStatement.execute(SFStatement.java:677)""
  ""net.snowflake.client.jdbc.SnowflakeStatementV1.executeQueryInternal(SnowflakeStatementV1.java:267)""
  ""net.snowflake.client.jdbc.SnowflakePreparedStatementV1.executeQuery(SnowflakePreparedStatementV1.java:122)""
  ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)""
  ""--> driver.sql_jdbc.execute$fn__78287.invokeStatic(execute.clj:556)""
  ""driver.sql_jdbc.execute$fn__78287.invoke(execute.clj:554)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:569)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:565)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__78370$fn__78371.invoke(execute.clj:696)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__78370.invoke(execute.clj:695)""
  ""driver.sql_jdbc.execute$fn__78163$fn__78164.invoke(execute.clj:388)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
  ""driver.sql_jdbc.execute$fn__78163.invokeStatic(execute.clj:382)""
  ""driver.sql_jdbc.execute$fn__78163.invoke(execute.clj:380)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:686)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc$fn__111692.invokeStatic(sql_jdbc.clj:82)""
  ""driver.sql_jdbc$fn__111692.invoke(sql_jdbc.clj:80)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71351.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__65323.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71172.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71182.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__70419.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__72485$combined_post_process__72490$combined_post_process_STAR___72491.invoke(query_processor.clj:262)""
  ""query_processor$fn__72485$combined_pre_process__72486$combined_pre_process_STAR___72487.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65420.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71262$fn__71266.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:94)""
  ""driver$do_with_driver.invoke(driver.clj:89)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71262.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__65812$fn__65813.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__65812.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71259.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__71564.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__71199$handle_audit_app_internal_queries__71200$fn__71202.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71210.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70134.invoke(constraints.clj:102)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__71495.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72085.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___60983$thunk__60985.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___60983.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___60995.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__94611.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__51829$fn__51831.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__51829.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43153.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""SQL compilation error: error line 12 at position 26\nBind variable ? not set."",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}


### Information about your Metabase installation

```JSON
Pulled the logs from 48.10 but also tested in v49 and v50
```


### Severity

annoying

### Additional context

Works for INT and DATE variables but not TEXT (whether field filters or standard SQL variables).",ixipixi,2024-07-18 18:13:24+00:00,[],2025-02-04 20:29:06+00:00,,https://github.com/metabase/metabase/issues/45817,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('Database/Snowflake', ''), ('.Backend', ''), ('.Escalation', ''), ('.Team/Drivers', '')]","[{'comment_id': 2239041656, 'issue_id': 2417054291, 'author': 'bshepherdson', 'body': 'The generated SQL looks fine, but apparently the `?` parameter is not getting a value. Possibly a difference in how the different parameter types are handled, possibly a Snowflake driver bug.', 'created_at': datetime.datetime(2024, 7, 19, 12, 34, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243630998, 'issue_id': 2417054291, 'author': 'tjfaust', 'body': ""For whatever it's worth, I'm having this issue too."", 'created_at': datetime.datetime(2024, 7, 22, 19, 6, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248602401, 'issue_id': 2417054291, 'author': 'alec-aumni', 'body': 'I am also having this issue', 'created_at': datetime.datetime(2024, 7, 24, 17, 56, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2253280959, 'issue_id': 2417054291, 'author': 'ksbystrom', 'body': 'I am also having this issue.', 'created_at': datetime.datetime(2024, 7, 26, 18, 38, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2253629893, 'issue_id': 2417054291, 'author': 'haleybryan1', 'body': 'Also experiencing this', 'created_at': datetime.datetime(2024, 7, 26, 23, 5, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269480911, 'issue_id': 2417054291, 'author': 'l-tuttle', 'body': 'Also experiencing this issue', 'created_at': datetime.datetime(2024, 8, 5, 16, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364668960, 'issue_id': 2417054291, 'author': 'snoe', 'body': 'This looks very much like a snowflake driver bug.\r\nOpened https://github.com/snowflakedb/snowflake-jdbc/issues/1899\r\n\r\nThe reason why other param types work is because we inline those values rather than pass them as jdbc parameters.', 'created_at': datetime.datetime(2024, 9, 20, 21, 55, 18, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-19 12:34:09 UTC): The generated SQL looks fine, but apparently the `?` parameter is not getting a value. Possibly a difference in how the different parameter types are handled, possibly a Snowflake driver bug.

tjfaust on (2024-07-22 19:06:36 UTC): For whatever it's worth, I'm having this issue too.

alec-aumni on (2024-07-24 17:56:49 UTC): I am also having this issue

ksbystrom on (2024-07-26 18:38:44 UTC): I am also having this issue.

haleybryan1 on (2024-07-26 23:05:21 UTC): Also experiencing this

l-tuttle on (2024-08-05 16:39:12 UTC): Also experiencing this issue

snoe on (2024-09-20 21:55:18 UTC): This looks very much like a snowflake driver bug.
Opened https://github.com/snowflakedb/snowflake-jdbc/issues/1899

The reason why other param types work is because we inline those values rather than pass them as jdbc parameters.

"
2416521538,issue,closed,not_planned,Upgrading Metabase to to the v1.50.9 stuck on DB migration step,"### Describe the bug

Hi Team,

We are having an issue with an upgrade to the `v1.50.9` on self hosted metabase that running on k8s (EKS) with 2 replicas.
The full upgrade path is ` 1.47.9 -> 1.48.13 -> 1.49.19 -> 1.50.9`

The DB migration is stuck on one of the steps that updating data in `data_permissions` table.
See the problematic query below:

```
-- Insert table-level view-data permissions when necessary: when a group has
-- table-level data-access permissions, and some of the `no-self-service` rows
-- cannot be automatically migrated to `unrestricted` due to conflicts with
-- other groups

INSERT INTO
  data_permissions (
    group_id,
    perm_type,
    db_id,
    schema_name,
    table_id,
    perm_value
  )
SELECT
  dp.group_id,
  'perms/view-data' AS perm_type,
  dp.db_id,
  dp.schema_name,
  dp.table_id,
  CASE
    WHEN dp.perm_value = 'no-self-service'
         AND EXISTS (
           SELECT
             1
           FROM
             permissions_group_membership pgm
             JOIN (
               SELECT
                 group_id,
                 db_id,
                 CAST(NULL AS INTEGER) AS table_id
               FROM
                 connection_impersonations
               UNION
               SELECT
                 group_id,
                 db_id,
                 CAST(NULL AS INTEGER) AS table_id
               FROM
                 data_permissions
               WHERE
                 perm_value = 'block'
                 AND table_id IS NULL
               UNION
               SELECT
                 group_id,
                 CAST(NULL AS INTEGER) AS db_id,
                 table_id
               FROM
                 sandboxes
             ) AS sp ON pgm.group_id = sp.group_id
           WHERE
             pgm.group_id <> dp.group_id
             AND (
               sp.db_id IS NULL
               OR sp.db_id = dp.db_id
             )
             AND (
               sp.table_id IS NULL
               OR sp.table_id = dp.table_id
             )
         ) THEN 'legacy-no-self-service'
    ELSE 'unrestricted'
  END AS perm_value
FROM
  data_permissions dp
WHERE
  dp.perm_type = 'perms/data-access'
  AND dp.table_id IS NOT NULL;
```

The mentioned migration query is running for a while causing the pods stopping after some time, however the process is not killed in data base. The duration of the migration varied; sometimes it took 40 minutes before pod stopped, while other times it only took 2 minutes.

We have Metabase running on three different environments, and the upgrade to the same version went smoothly on two of them. We also spotted the huge difference in number of rows stored in `data_permissions` table. In 'failing' env the count of rows is `1 678 810`, which is `~278 MB` in size. For example on 'successful' env the same table contains only the `4150` rows (1.2MB). Also worth to mention that 'failing' environment have 45 group permissions groups.

As an experiment we deleted all records from the `data_permissions` table . After restarting the pod, the migration completed successfully, but it reset all group permissions to their default values (like shown in the table below) so we rolled back to the old version.
<img width=""1058"" alt=""image"" src=""https://github.com/user-attachments/assets/e85e0572-874e-4c00-aea1-a6a7b0287f87"">

Could you please check if there is something that should be fixed ?



### To Reproduce

Upgrade metabase version from 1.49.19 to 1.50.9

### Expected behavior

DB migration steps successfully completed and metabase is up and running

### Logs

Warning: environ value jdk-11.0.23+9 for key :java-version has been overwritten with 11.0.23
2024-07-17 19:54:36,912 INFO metabase.util :: Maximum memory available to JVM: 3.0 GB
2024-07-17 19:54:41,051 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. 🔓 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-07-17 19:54:48,814 INFO driver.impl :: Registered abstract driver :sql  🚚
2024-07-17 19:54:48,823 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) 🚚
2024-07-17 19:54:48,831 INFO metabase.util :: Load driver :sql-jdbc took 65.6 ms
2024-07-17 19:54:48,831 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:49,060 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:49,132 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:53,454 INFO metabase.core :: 
Metabase v1.50.12 (86d4671) 
Copyright © 2024 Metabase, Inc. 
Metabase Enterprise Edition extensions are PRESENT.
Usage of Metabase Enterprise Edition features are subject to the Metabase Commercial License.See https://www.metabase.com/license/commercial/ for details.
2024-07-17 19:54:53,466 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-07-17 19:54:53,532 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}
2024-07-17 19:54:53,630 INFO metabase.core :: Starting Metabase version v1.50.12 (86d4671) ...
2024-07-17 19:54:53,650 INFO metabase.core :: System info:
 {""file.encoding"" ""UTF-8"",
 ""java.runtime.name"" ""OpenJDK Runtime Environment"",
 ""java.runtime.version"" ""11.0.23+9"",
 ""java.vendor"" ""Eclipse Adoptium"",
 ""java.vendor.url"" ""https://adoptium.net/"",
 ""java.version"" ""11.0.23"",
 ""java.vm.name"" ""OpenJDK 64-Bit Server VM"",
 ""java.vm.version"" ""11.0.23+9"",
 ""os.name"" ""Linux"",
 ""os.version"" ""5.10.219-208.866.amzn2.x86_64"",
 ""user.language"" ""en"",
 ""user.timezone"" ""GMT""}
2024-07-17 19:54:53,652 INFO metabase.plugins :: Loading plugins in /plugins...
2024-07-17 19:54:53,985 INFO util.files :: Extract file /modules/snowflake.metabase-driver.jar -> /plugins/snowflake.metabase-driver.jar
2024-07-17 19:54:54,418 INFO util.files :: Extract file /modules/sqlite.metabase-driver.jar -> /plugins/sqlite.metabase-driver.jar
2024-07-17 19:54:54,457 INFO util.files :: Extract file /modules/bigquery-cloud-sdk.metabase-driver.jar -> /plugins/bigquery-cloud-sdk.metabase-driver.jar
2024-07-17 19:54:54,700 INFO util.files :: Extract file /modules/sqlserver.metabase-driver.jar -> /plugins/sqlserver.metabase-driver.jar
2024-07-17 19:54:54,709 INFO util.files :: Extract file /modules/presto-jdbc.metabase-driver.jar -> /plugins/presto-jdbc.metabase-driver.jar
2024-07-17 19:54:54,761 INFO util.files :: Extract file /modules/druid.metabase-driver.jar -> /plugins/druid.metabase-driver.jar
2024-07-17 19:54:54,764 INFO util.files :: Extract file /modules/sparksql.metabase-driver.jar -> /plugins/sparksql.metabase-driver.jar
2024-07-17 19:54:54,819 INFO util.files :: Extract file /modules/oracle.metabase-driver.jar -> /plugins/oracle.metabase-driver.jar
2024-07-17 19:54:54,856 INFO util.files :: Extract file /modules/mongo.metabase-driver.jar -> /plugins/mongo.metabase-driver.jar
2024-07-17 19:54:54,872 INFO util.files :: Extract file /modules/redshift.metabase-driver.jar -> /plugins/redshift.metabase-driver.jar
2024-07-17 19:54:54,879 INFO util.files :: Extract file /modules/vertica.metabase-driver.jar -> /plugins/vertica.metabase-driver.jar
2024-07-17 19:54:54,887 INFO util.files :: Extract file /modules/athena.metabase-driver.jar -> /plugins/athena.metabase-driver.jar
2024-07-17 19:54:54,964 INFO util.files :: Extract file /modules/druid-jdbc.metabase-driver.jar -> /plugins/druid-jdbc.metabase-driver.jar
2024-07-17 19:54:55,223 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-07-17 19:54:55,233 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,237 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-07-17 19:54:55,238 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,253 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-07-17 19:54:55,254 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) 🚚
2024-07-17 19:54:55,259 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-07-17 19:54:55,259 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,282 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-07-17 19:54:55,283 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,287 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-07-17 19:54:55,287 INFO driver.impl :: Registered driver :druid  🚚
2024-07-17 19:54:55,293 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-07-17 19:54:55,294 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,294 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-07-17 19:54:55,294 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) 🚚
2024-07-17 19:54:55,300 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
2024-07-17 19:54:55,301 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,307 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-07-17 19:54:55,307 INFO driver.impl :: Registered driver :mongo  🚚
2024-07-17 19:54:55,309 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-07-17 19:54:55,310 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) 🚚
2024-07-17 19:54:55,312 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...
2024-07-17 19:54:55,312 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,329 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-07-17 19:54:55,329 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,335 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid-jdbc...
2024-07-17 19:54:55,338 INFO driver.impl :: Registered driver :druid-jdbc (parents: [:sql-jdbc]) 🚚
2024-07-17 19:54:55,352 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...
2024-07-17 19:54:55,354 INFO db.setup :: Verifying postgres Database Connection ...
2024-07-17 19:54:55,982 INFO db.setup :: Successfully verified PostgreSQL 13.13 application database connection. ✅
2024-07-17 19:54:55,982 INFO db.setup :: Checking if a database downgrade is required...
2024-07-17 19:54:57,021 INFO db.setup :: Running Database Migrations...
2024-07-17 19:54:57,022 INFO db.setup :: Setting up Liquibase...
2024-07-17 19:54:57,319 INFO db.setup :: Liquibase is ready.
2024-07-17 19:54:57,321 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-07-17 19:54:58,039 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...
2024-07-17 19:54:58,073 INFO db.liquibase :: No migration lock found.
2024-07-17 19:54:58,074 INFO db.liquibase :: Migration lock acquired.
2024-07-17 19:54:58,506 INFO db.liquibase :: Running 55 migrations ...
2024-07-17 20:23:37,800 INFO metabase.core :: Metabase Shutting Down ...
2024-07-17 20:23:37,803 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-07-17 20:23:37,818 WARN db.liquibase :: (#object[liquibase.Liquibase 0x6f005f3a liquibase.Liquibase@6f005f3a])
2024-07-17 20:23:37,819 INFO db.liquibase :: Waiting for migration lock(s) to be released (max 20.0 secs)


### Information about your Metabase installation

```JSON
- Metabase Internal DB: Postgress 13.13 that running on RDS instance
- Metabase hosting Environment: EKS v1.30.0
```


### Severity

P3

### Additional context

_No response_",vdubovets,2024-07-18 14:16:33+00:00,[],2024-07-19 07:01:57+00:00,2024-07-18 15:01:26+00:00,https://github.com/metabase/metabase/issues/45801,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2236803267, 'issue_id': 2416521538, 'author': 'noahmoss', 'body': '@vdubovets Thanks for your report. Closing in favor of https://github.com/metabase/metabase/issues/45701', 'created_at': datetime.datetime(2024, 7, 18, 15, 1, 26, tzinfo=datetime.timezone.utc)}]","noahmoss on (2024-07-18 15:01:26 UTC): @vdubovets Thanks for your report. Closing in favor of https://github.com/metabase/metabase/issues/45701

"
2416513231,issue,closed,not_planned,Spanish translation mostly fails to load,"### Describe the bug

After setting the locale to Spanish, very little of the Spanish translation appears. Most strings are still in English.

### To Reproduce

1. Go to Admin / Settings / Localizations
2. Select Spanish as the Instance language
3. The page will automatically reload
4. Note that much of the UI is still in English

![image](https://github.com/user-attachments/assets/b873f2db-0a08-4882-9893-b3f2ed30b562)

To take one example, there is a translation for ""Table Metadata"" in `locales/es.po`:

```
#: frontend/src/metabase/admin/app/reducers.ts:30
#: frontend/src/metabase/admin/routes.jsx:91
msgid ""Table Metadata""
msgstr ""Metadatos de la Tabla""
```

But as the screenshot above shows, the admin nav still says ""Table Metadata"", not ""Metadatos de la Tabla"".

### Expected behavior

We expect to see much of the UI in Spanish

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.11 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-10"",
      ""src_hash"": ""a94a90c2294b956183475275a9611b44023318d6"",
      ""tag"": ""v1.1.17-SNAPSHOT"",
      ""hash"": ""0b46f7c""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P1

### Additional context

_No response_",rafpaf,2024-07-18 14:13:20+00:00,[],2024-07-18 14:18:07+00:00,2024-07-18 14:17:42+00:00,https://github.com/metabase/metabase/issues/45800,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Customization/i18n', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2236655676, 'issue_id': 2416513231, 'author': 'rafpaf', 'body': 'This was just a problem for me locally', 'created_at': datetime.datetime(2024, 7, 18, 14, 17, 42, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-07-18 14:17:42 UTC): This was just a problem for me locally

"
2416113390,issue,closed,not_planned,Migrations to v0.50.13 fail ,"### Describe the bug

When upgrading from  v0.50.7 to v0.50.13, metabase startup fails while applying Liquibase migration and continues in a loop.


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs


```
"" 2024-07-18 08:23:29,272 INFO db.setup :: Running Database Migrations...

""
"" 2024-07-18 08:23:29,272 INFO db.setup :: Setting up Liquibase...

""
"" 2024-07-18 08:23:30,237 INFO db.setup :: Liquibase is ready.

""
"" 2024-07-18 08:23:30,238 INFO db.liquibase :: Checking if Database has unrun migrations...

""
"" 2024-07-18 08:23:32,580 INFO db.liquibase :: Database has unrun migrations. Checking if migration lock is taken...

""
"" 2024-07-18 08:23:32,715 INFO db.liquibase :: No migration lock found.

""
"" 2024-07-18 08:23:32,716 INFO db.liquibase :: Migration lock acquired.

""
"" 2024-07-18 08:23:33,762 INFO db.liquibase :: Running 15 migrations ...

""
"" 2024-07-18 08:23:35,283 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-06-27T00:00:07::calherries encountered an exception.

""
"" liquibase.exception.DatabaseException: ERROR: syntax error at or near """"(""""

""
""   Position: 87 [Failed SQL: (0) ALTER TABLE metabase_field ADD COLUMN unique_field_helper INTEGER GENERATED ALWAYS AS (

""
""   CASE WHEN is_defective_duplicate = TRUE THEN NULL ELSE (CASE WHEN parent_id IS NULL THEN 0 ELSE parent_id END) END

""
"" ) STORED]

""
"" 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)

""
"" 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)

""
"" 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)

""
"" 	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)

""
"" 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)

""
"" 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)

""
"" 	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)

""
"" 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)

""
"" 	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)

""
"" 	at liquibase.Scope.lambda$child$0(Scope.java:186)

""
"" 	at liquibase.Scope.child(Scope.java:195)

""
"" 	at liquibase.Scope.child(Scope.java:185)

""
"" 	at liquibase.Scope.child(Scope.java:164)

""
"" 	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)

""
"" 	at liquibase.Scope.lambda$child$0(Scope.java:186)

""
"" 	at liquibase.Scope.child(Scope.java:195)

""
"" 	at liquibase.Scope.child(Scope.java:185)

""
"" 	at liquibase.Scope.child(Scope.java:164)

""
"" 	at liquibase.Scope.child(Scope.java:252)

""
"" 	at liquibase.Scope.child(Scope.java:256)

""
"" 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)

""
"" 	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)

""
"" 	at liquibase.Scope.lambda$child$0(Scope.java:186)

""
"" 	at liquibase.Scope.child(Scope.java:195)

""
"" 	at liquibase.Scope.child(Scope.java:185)

""
"" 	at liquibase.Scope.child(Scope.java:164)

""
"" 	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)

""
"" 	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)

""
"" 	at liquibase.command.CommandScope.execute(CommandScope.java:217)

""
"" 	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)

""
"" 	at liquibase.Scope.lambda$child$0(Scope.java:186)

""
"" 	at liquibase.Scope.child(Scope.java:195)

""
"" 	at liquibase.Scope.child(Scope.java:185)

""
"" 	at liquibase.Scope.child(Scope.java:164)

""
"" 	at liquibase.Liquibase.runInScope(Liquibase.java:1419)

""
"" 	at liquibase.Liquibase.update(Liquibase.java:234)

""
"" 	at liquibase.Liquibase.update(Liquibase.java:212)

""
"" 	at liquibase.Liquibase.update(Liquibase.java:194)

""
"" 	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44519.invoke(liquibase.clj:360)

""
"" 	at metabase.db.liquibase$run_in_scope_locked$reify__44515.run(liquibase.clj:325)

""
"" 	at liquibase.Scope.lambda$child$0(Scope.java:186)

""
"" 	at liquibase.Scope.child(Scope.java:195)

""
"" 	at liquibase.Scope.child(Scope.java:185)

""
"" 	at liquibase.Scope.child(Scope.java:164)

""
"" 	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)

""
"" 	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)

""
"" 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)

""
"" 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)

""
"" 	at metabase.db.setup$migrate_BANG_$fn__53455.invoke(setup.clj:84)

""
"" 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44456.invoke(liquibase.clj:140)

""
"" 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)

""
"" 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)

""
"" 	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)

""
"" 	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)

""
"" 	at clojure.lang.RestFn.invoke(RestFn.java:425)

""
"" 	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)

""
"" 	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)

""
"" 	at metabase.db.setup$setup_db_BANG_$fn__53483$fn__53484.invoke(setup.clj:167)

""
"" 	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)

""
"" 	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)

""
"" 	at metabase.db.setup$setup_db_BANG_$fn__53483.invoke(setup.clj:161)

""
"" 	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)

""
"" 	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)

""
"" 	at metabase.db$setup_db_BANG_$fn__53508.invoke(db.clj:86)

""
"" 	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)

""
"" 	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)

""
"" 	at clojure.lang.RestFn.invoke(RestFn.java:421)

""
"" 	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)

""
"" 	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)

""
"" 	at metabase.core$init_BANG_.invokeStatic(core.clj:170)

""
"" 	at metabase.core$init_BANG_.invoke(core.clj:165)

""
"" 	at metabase.core$start_normally.invokeStatic(core.clj:182)

""
"" 	at metabase.core$start_normally.invoke(core.clj:176)

""
"" 	at metabase.core$entrypoint.invokeStatic(core.clj:215)

""
"" 	at metabase.core$entrypoint.doInvoke(core.clj:209)

""
"" 	at clojure.lang.RestFn.invoke(RestFn.java:397)

""
"" 	at clojure.lang.AFn.applyToHelper(AFn.java:152)

""
"" 	at clojure.lang.RestFn.applyTo(RestFn.java:132)

""
"" 	at clojure.lang.Var.applyTo(Var.java:705)

""
"" 	at clojure.core$apply.invokeStatic(core.clj:667)

""
"" 	at clojure.core$apply.invoke(core.clj:662)

""
"" 	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)

""
"" 	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)

""
"" 	at clojure.lang.RestFn.invoke(RestFn.java:397)

""
"" 	at clojure.lang.AFn.applyToHelper(AFn.java:152)

""
"" 	at clojure.lang.RestFn.applyTo(RestFn.java:132)

""
"" 	at metabase.bootstrap.main(Unknown Source)

""
"" Caused by: org.postgresql.util.PSQLException: ERROR: syntax error at or near """"(""""

""
""   Position: 87

""
"" 	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725)

""
"" 	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412)

""
"" 	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)

""
"" 	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)

""
"" 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)

""
"" 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)

""
"" 	at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)

""
"" 	at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)

""
"" 	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)

""
"" 	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)

""
"" 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)

""
"" 	... 86 more

""
"" 

""
"" UPDATE SUMMARY

""
"" Run:                         15

""
"" Previously run:             335

""
"" Filtered out:                50

""
"" -------------------------------

""
"" Total change sets:          400

""
```

### Information about your Metabase installation

```JSON
PostgreSQL 11.22
Metabase: v0.50.13
Docker image: metabase/metabase:latest
```


### Severity

blocking your usage of Metabase entirely

### Additional context

_No response_",leopasta-enable,2024-07-18 11:26:27+00:00,[],2024-07-19 06:59:55+00:00,2024-07-18 12:08:24+00:00,https://github.com/metabase/metabase/issues/45795,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2236317652, 'issue_id': 2416113390, 'author': 'ilmarivikstrom', 'body': 'Suffering from the same exact problem.', 'created_at': datetime.datetime(2024, 7, 18, 11, 58, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236335874, 'issue_id': 2416113390, 'author': 'qnkhuat', 'body': ""Please upgrade to postgres 12 or above. We no longer support version 11 as it's already end of life"", 'created_at': datetime.datetime(2024, 7, 18, 12, 8, 24, tzinfo=datetime.timezone.utc)}]","ilmarivikstrom on (2024-07-18 11:58:13 UTC): Suffering from the same exact problem.

qnkhuat on (2024-07-18 12:08:24 UTC): Please upgrade to postgres 12 or above. We no longer support version 11 as it's already end of life

"
2415901616,issue,open,,Load datetime values to sqlite datasets with millisecond precision,Load datetime values to sqlite test datasets with millisecond precision. That way the `temporal-str->iso8601-str` (added in https://github.com/metabase/metabase/pull/44894) should become obsolete and we could use same test expectations as for other drivers.,lbrdnk,2024-07-18 09:52:01+00:00,[],2025-02-04 20:23:54+00:00,,https://github.com/metabase/metabase/issues/45790,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2415877285,issue,open,,Foreign key relationships sync does not work on sqlite,"Historically `:foreign-keys` was disabled during tests in sqlite. While working on https://github.com/metabase/metabase/pull/44894, converting the `:foreign-keys` to `:metadata/key-constraints`, I've found out that fks sync does not work. Hence I've temporarily disabled `:metadata/key-constraints` for tests (the original state).

We should make the fks sync work correctly and remove the code that disables the feature during tests.
",lbrdnk,2024-07-18 09:42:27+00:00,[],2025-02-04 20:25:22+00:00,,https://github.com/metabase/metabase/issues/45788,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/SQLite', None), ('Administration/Metadata & Sync', ''), ('.Team/Drivers', '')]",[],
2415839531,issue,open,,Redundant POST /api/dataset request fired when navigating back,"### Describe the bug

https://github.com/user-attachments/assets/e1165270-0f88-41f0-a883-2cdae3b950d2


### To Reproduce

1. New > Model > Use the notebook editor > Orders
2. Run the question
3. Go to ""Metadata"" tab
4. Open network tab in browser developer tools
5. Click the back button in your browser

There are 2 requests redundantly fired: POST `/api/dataset` & GET `/api/database/1`

If instead (of step 5) you go to ""Query"" tab by clicking it, these requests won't be fired

### Information about your Metabase installation

master, 24caede62a


### Severity

P3
",kamilmielnik,2024-07-18 09:25:02+00:00,[],2024-07-18 09:26:10+00:00,,https://github.com/metabase/metabase/issues/45787,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2415457898,issue,closed,completed,Create CLI to download and start Metabase locally for embedding sdk onboarding,"Create a CLI to download and start Metabase instances locally, and prints useful information about the embedding sdk. See more information on the [product docs](https://www.notion.so/metabase/CLI-to-download-and-start-MB-locally-8ad752a7f73b4ed3b38f6bd0971a2fd4?pvs=4).",heypoom,2024-07-18 06:07:41+00:00,['heypoom'],2024-10-08 16:19:48+00:00,2024-07-24 17:35:13+00:00,https://github.com/metabase/metabase/issues/45781,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2415199674,issue,open,,Dashboard 500 calls,"This is an analysis of looking at all the queries we made to the appDB to view the example dashboard : E-commerce insights. 
The dashboard has 
- 4 tabs
- 31 dashcards in total
- 8 cards on the first tab
- 4 parameters

Currently at 8aeebaa2ea47efd0013027beaa3ccf68bdc0f1e8 and opening this dashboard on UI shows:
- 504 queries made in total
- 21 API calls
![Screenshot 2024-07-18 at 11 35 59](https://github.com/user-attachments/assets/efbecb28-a52f-46dc-89ac-8770e8311293)

This csv contains all the queries
[full-reload-dashboard.csv](https://github.com/user-attachments/files/16277609/full-reload-dashboard.csv)

Here are some breakdowns and my findings of places we can optimize

### 1. GET /api/dashboard/:id
[get dashboard.csv](https://github.com/user-attachments/files/16277617/get.dashboard.csv)

54 queries in total

a. (16 queries) N+1 where n is the number of dashcards in checking query permissions. Triggered by the hydrating the key [:can_run_adhoc_query](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/card.clj#L184). there are repeated calls of [(lib.metadata/bulk-metadata metadata-provider :metadata/column field-ids).](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/lib/query.cljc#L120) I think if we pre-warm the metadata-provider before checking perm for all cards, we can remove the n+1 here.
b. (5 queries) N+1 in hydrating [field_values](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/params/field_values.clj#L53) where N is the number of parameters. It's so silly that we're getting field values twice, one batched and one for each param. Should be an easy fix.
c. (8 queries) just to [update recent_view](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/recent_views.clj#L131), 5 of which are used to find [ids to prune](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/recent_views.clj#L122). This is the same for when we view card/table/collection so it's a good investment to optimize this. Consider doing the pruning async and periodically

### 2. GET /api/dashboard/:id/query_metadata

78 queries in total
[dashboard metadata.csv](https://github.com/user-attachments/files/16277664/dashboard.metadata.csv)

Like `GET /api/dashboard/:id` this has issues with N+1 in checking query permissions as well

### 3. POST /api/dashboard/:id/dashcard/:id/card/:id/query
[execute a dashcard.csv](https://github.com/user-attachments/files/16277613/execute.a.dashcard.csv)

38 queries for a simple card

a. (4 queries) there is an n+1 to update user_parameter_value where n is the number of parameters a dashboard has; it looks like we can use 2 queries to batch this: delete all, then insert new values. Also, consider adding an index on (dashboard_id, user_id) ([src](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/query_processor/dashboard.clj#L148))
b. (4 queries) we're upserting ParameterCard everytime we update a card or a dashboard, even when updating name!!!. [dashboard](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/dashboard.clj#L102)  and [card](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/models/card.clj#L509)
  - do we even need this table? What is it used for? it was added in https://github.com/metabase/metabase/pull/27008 but afaik we don't use it for anything
  - either way, a quick fix is to only call `parameter-card/upsert-or-delete-from-parameters!` when parameters change.

### 4. GET /api/search
[search .csv](https://github.com/user-attachments/files/16277620/search.csv)

16 queries in total 

a.  (7 queries) repeated `SELECT * FROM ""collection"" WHERE ""personal_owner_id"" IS NOT NULL` in [code](https://github.com/metabase/metabase/blob/44da4d0f435d10813ef3cffd611878f6645a793f/src/metabase/search/impl.clj#L142). This can be cached.


```[tasklist]
### Tasks (ordered from higher impact to lower, but everything can be done in parallel)
- [x] 3a. [N+1 updating user_parameter_value [AW → done by BEC]](https://github.com/metabase/metabase/pull/46615)
- [x] 3b. [Upserting ParameterCard when not needed [BEC]](https://github.com/metabase/metabase/pull/45901)
- [ ] 1b. N+1 hydrating field_values in GET /api/dashboard/:id [BEC or AW, whoever's done with 3a/3b first]
- [x] 1a. N+1 hydrating :can_run_adhoc_query in GET /api/dashboard/:id [QPD]
- [ ] 1c. finding id:s to prune [AW]
- [ ] 4a. Repeated non-null select in /api/search [AW]
```

### Links
* [thread with impact, effort, and team breakdown](https://metaboat.slack.com/archives/C0765BXUYS0/p1721357301326859)
",qnkhuat,2024-07-18 04:33:16+00:00,[],2025-02-04 20:23:47+00:00,,https://github.com/metabase/metabase/issues/45780,"[('.Performance', ''), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2235320920, 'issue_id': 2415199674, 'author': 'qnkhuat', 'body': 'Feel free to dig and find more places we can optimize :)', 'created_at': datetime.datetime(2024, 7, 18, 4, 43, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293165032, 'issue_id': 2415199674, 'author': 'darksciencebase', 'body': ""moved 4a from BEC to AW as we've moved Search into their scope. QPD might or might not already be working on 1b."", 'created_at': datetime.datetime(2024, 8, 16, 9, 29, 1, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-07-18 04:43:42 UTC): Feel free to dig and find more places we can optimize :)

darksciencebase on (2024-08-16 09:29:01 UTC): moved 4a from BEC to AW as we've moved Search into their scope. QPD might or might not already be working on 1b.

"
2415138621,issue,closed,completed,[Cache] Some strings are not translated in strategy form,"Descriptions of OSS-only strategies are not translated

![Image](https://github.com/user-attachments/assets/2e585bb2-3761-4934-a345-e0bc5ed1a532)

",rafpaf,2024-07-18 03:32:13+00:00,['rafpaf'],2024-07-24 03:04:54+00:00,2024-07-23 18:43:26+00:00,https://github.com/metabase/metabase/issues/45779,"[('Priority:P2', 'Average run of the mill bug'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2414512201,issue,closed,completed,Update aggregation picker to support interactive questions in embedding sdk,"We should replace the use of `const question = useSelector(getQuestion)` in the aggregation picker component with one that considers the SDK context. The aggregation picker does not work in the SDK right now. We should re-add the `checkNotNull` method to `useQuestion` as well - we've temporarily removed the runtime null assertion because the SDK did not has the question in the query builder reducer, and it would crash the SDK.",heypoom,2024-07-17 20:24:43+00:00,['heypoom'],2024-11-12 17:21:18+00:00,2024-11-12 17:21:08+00:00,https://github.com/metabase/metabase/issues/45766,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2459692357, 'issue_id': 2414512201, 'author': 'albertoperdomo', 'body': '@heypoom Is this still relevant?', 'created_at': datetime.datetime(2024, 11, 6, 13, 0, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471137276, 'issue_id': 2414512201, 'author': 'heypoom', 'body': 'Tested that aggregation picker is actually working now. The question object in the selector was only used for tracking the column_compare_via_shortcut event. It used to throw errors in the older versions of the SDK, but works without issues/errors now.\n\n![Image](https://github.com/user-attachments/assets/fedbe540-8360-48f8-86c2-3f372c13a40a)', 'created_at': datetime.datetime(2024, 11, 12, 17, 21, 8, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-11-06 13:00:01 UTC): @heypoom Is this still relevant?

heypoom (Issue Creator) on (2024-11-12 17:21:08 UTC): Tested that aggregation picker is actually working now. The question object in the selector was only used for tracking the column_compare_via_shortcut event. It used to throw errors in the older versions of the SDK, but works without issues/errors now.

![Image](https://github.com/user-attachments/assets/fedbe540-8360-48f8-86c2-3f372c13a40a)

"
2414461683,issue,closed,completed,Expose getDefaultCardHeight function to allow custom interactive question layouts to have correct height in embedding sdk,"The getDefaultCardHeight method is not exposed, so we cannot determine the `QuestionVisualization`'s default height at runtime. Otherwise, the card will have a bad height if it is rendered with a dynamic question id.

![Image](https://github.com/user-attachments/assets/6a739aab-355b-407d-82d1-f1377259caa7)

# Code sample

In our default InteractiveQuestionResult, notice that we use `getDefaultVizHeight` to get the content's default height.

```tsx
export const InteractiveQuestionResult = ({
  height,
  withTitle,
  customTitle,
  withResetButton,
}: InteractiveQuestionResultProps): ReactElement => {
  const [questionView, setQuestionView] =
    useState<QuestionView>(""visualization"");

  const { question, queryResults, isQuestionLoading } =
    useInteractiveQuestionContext();

  const card = question?.card();
  const defaultHeight = card ? getDefaultVizHeight(card.display) : undefined;

  let content;

  if (isQuestionLoading) {
    content = <SdkLoader />;
  } else if (!question || !queryResults) {
    content = <SdkError message={t`Question not found`} />;
  } else {
    content = (
      <Stack h=""100%"">
        <Flex direction=""row"" gap=""md"" px=""md"" align=""center"">
          <BackButton />
          {withTitle && (customTitle ?? <Title />)}
          {withResetButton && <QuestionResetButton />}
          <FilterButton
            onClick={() =>
              setQuestionView(
                questionView === ""filter"" ? ""visualization"" : ""filter"",
              )
            }
          />
          <SummarizeButton
            isOpen={questionView === ""summarize""}
            onOpen={() => setQuestionView(""summarize"")}
            onClose={() => setQuestionView(""visualization"")}
          />
          <NotebookButton
            isOpen={questionView === ""notebook""}
            onClick={() =>
              setQuestionView(
                questionView === ""notebook"" ? ""visualization"" : ""notebook"",
              )
            }
          />
        </Flex>

        <FilterBar />

        <Group h=""100%"" pos=""relative"" align=""flex-start"">
          <ResultView
            questionView={questionView}
            setQuestionView={setQuestionView}
          />
        </Group>
      </Stack>
    );
  }

  return (
    <Box
      className={cx(CS.flexFull, CS.fullWidth)}
      h={height ?? defaultHeight}
      bg=""var(--mb-color-bg-question)""
    >
      {content}
    </Box>
  );
};
```",heypoom,2024-07-17 20:04:23+00:00,[],2024-09-05 07:36:36+00:00,2024-09-05 07:36:16+00:00,https://github.com/metabase/metabase/issues/45765,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2330819396, 'issue_id': 2414461683, 'author': 'heypoom', 'body': 'This is solved by https://github.com/metabase/metabase/pull/47169 by default without the need to expose `getDefaultCardHeight`, closing.', 'created_at': datetime.datetime(2024, 9, 5, 7, 36, 16, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-09-05 07:36:16 UTC): This is solved by https://github.com/metabase/metabase/pull/47169 by default without the need to expose `getDefaultCardHeight`, closing.

"
2414451308,issue,closed,completed,Theme options for tooltip text colors and background colors for sdk,"Tooltip looks broken in light-themed apps, because `text-*` could be set to dark colors. We need to expose a separate semantic color variable for tooltip foreground and background colors.

![Image](https://github.com/user-attachments/assets/e3a38926-05dc-4fa4-a39d-f6bb3d666a3c)

",heypoom,2024-07-17 19:58:47+00:00,['heypoom'],2024-11-28 10:18:20+00:00,2024-11-27 18:38:31+00:00,https://github.com/metabase/metabase/issues/45764,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2459692892, 'issue_id': 2414451308, 'author': 'albertoperdomo', 'body': '@heypoom Is this still relevant?', 'created_at': datetime.datetime(2024, 11, 6, 13, 0, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459698336, 'issue_id': 2414451308, 'author': 'albertoperdomo', 'body': ""I can't repro [here](https://embedded-analytics-sdk-demo.metabase.com/admin/products/42), because I don't get any tool top when hovering over the interactive question component."", 'created_at': datetime.datetime(2024, 11, 6, 13, 2, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493361367, 'issue_id': 2414451308, 'author': 'heypoom', 'body': '@albertoperdomo this is still relevant, I visited https://embedded-analytics-sdk-demo.metabase.com/admin/products/40 and then hovered on the bar in the bar chart \n\n![Image](https://github.com/user-attachments/assets/18cdcbe8-8382-428f-b79e-5f034c450248)', 'created_at': datetime.datetime(2024, 11, 22, 9, 53, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505755189, 'issue_id': 2414451308, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)', 'created_at': datetime.datetime(2024, 11, 28, 10, 18, 19, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-11-06 13:00:17 UTC): @heypoom Is this still relevant?

albertoperdomo on (2024-11-06 13:02:44 UTC): I can't repro [here](https://embedded-analytics-sdk-demo.metabase.com/admin/products/42), because I don't get any tool top when hovering over the interactive question component.

heypoom (Issue Creator) on (2024-11-22 09:53:35 UTC): @albertoperdomo this is still relevant, I visited https://embedded-analytics-sdk-demo.metabase.com/admin/products/40 and then hovered on the bar in the bar chart 

![Image](https://github.com/user-attachments/assets/18cdcbe8-8382-428f-b79e-5f034c450248)

github-actions[bot] on (2024-11-28 10:18:19 UTC): 🚀 This should also be released by [v0.52](https://github.com/metabase/metabase/milestone/283)

"
2414373986,issue,open,,relativeDateTime seems to think it only returns dates not datetimes,"### Describe the bug

when i use relativeDateTime in a custom expression it adds DATE_TRUNC('day', in front of my source column to compare to it whereas if i use dateTimeAdd/Subtract on now it does not

### To Reproduce

see above

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version 0.50.10
```


### Severity

annoying

### Additional context

_No response_",ericcj,2024-07-17 19:18:26+00:00,[],2025-02-04 20:28:53+00:00,,https://github.com/metabase/metabase/issues/45761,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]",[],
2414308141,issue,closed,completed,MySQL `describe-nested-field-columns` type detection doesn't work correctly unless Database human-friendly name matches physical name,"Seems to only affect MySQL AFAIK. MariaDB seems to work ok still, or maybe we're not testing JSON support for it?

There's a bug in the default implementation of `sql-jdbc.sync.interface/describe-nested-field-columns` here

https://github.com/metabase/metabase/blob/d60facf3fc669c0560338d4516ee4a79fbe32b15/src/metabase/driver/sql_jdbc/sync/describe_table.clj#L614

where we're using `(:name database)` (the human-friendly display name) for fetching PKs (`metabase.driver.sql-jdbc.sync.describe-table/get-table-pks`). This does not return any matching PKs if the human-friendly display name (e.g. `Test Data`) does not match the actual physical database name e.g. `test-data`.

If there are no matching PKs then our type JSON type detection logic only checks the most recent values instead of a sampling of oldest and newest values, since it doesn't have a good column to order by. This means our advanced detection logic is basically broken for MySQL unless database display name matches the physical database name,

Tests were previously passing because we used `test-data` for both, but in #45268 I changed this to use `test-data (h2)` for the display name while keeping `test-data` for the physical database name, and it resulted in a test failure.",camsaul,2024-07-17 18:36:19+00:00,['camsaul'],2024-08-28 02:09:00+00:00,2024-07-18 04:06:13+00:00,https://github.com/metabase/metabase/issues/45760,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/MySQL', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2414304050,issue,open,,Specify custom dashboard title in embedding sdk,"Exposes a `customTitle` hook to support customized dashboard titles for embedding sdk.

![Image](https://github.com/user-attachments/assets/76ce88db-e740-43a4-8651-e587983e8268)

",heypoom,2024-07-17 18:33:38+00:00,[],2025-02-04 20:31:00+00:00,,https://github.com/metabase/metabase/issues/45759,"[('Type:New Feature', ''), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2414172419,issue,closed,completed,Bug: Cards in root collection don't appear,,tsmacdonald,2024-07-17 17:37:38+00:00,['tsmacdonald'],2024-08-07 15:12:14+00:00,2024-07-18 17:59:22+00:00,https://github.com/metabase/metabase/issues/45756,"[('.Team/Workflows', 'aka BEC')]",[],
2413971769,issue,closed,completed,[Flaky Test]: e2e-storage-ingestion-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9943505153
Last Flake Time: 2024-07-15T10:29:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-17 15:50:12+00:00,['crisptrutski'],2024-08-17 09:23:24+00:00,2024-08-17 09:23:24+00:00,https://github.com/metabase/metabase/issues/45747,"[('flaky-test-fix', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2252461697, 'issue_id': 2413971769, 'author': 'calherries', 'body': ""This flake has been around since at [least May](https://metaboat.slack.com/archives/C5XHN8GLW/p1714642505921739?thread_ts=1714641978.456929&cid=C5XHN8GLW). It just flaked for me so that's 3 times this week according to [the query](https://stats.metabase.com/question#eyJuYW1lIjoiVGVzdCBmbGFrZXMgYnkgc3VpdGUgbmFtZSBhbmQgdGVzdCBuYW1lIChub3QgUVApIiwiZGVzY3JpcHRpb24iOiJodHRwczovL3N0YXRzLm1ldGFiYXNlLmNvbS9tb2RlbC8xNDgyOC10ZXN0LWZsYWtpbmVzcyIsImRhdGFzZXRfcXVlcnkiOnsiZGF0YWJhc2UiOjI2LCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJhZ2dyZWdhdGlvbiI6W1siY291bnQiXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl91cmwiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl9zdGFydGVkX2F0Iix7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiIsInRlbXBvcmFsLXVuaXQiOiJtaW51dGUifV1dLFsiYWdncmVnYXRpb24tb3B0aW9ucyIsWyJjb3VudC13aGVyZSIsWyI-IixbImZpZWxkIiwid29ya2Zsb3dfcnVuX3N0YXJ0ZWRfYXQiLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlVGltZVdpdGhMb2NhbFRaIn1dLFsiZGF0ZXRpbWUtc3VidHJhY3QiLFsibm93Il0sMywiZGF5Il1dXSx7Im5hbWUiOiJDb3VudCAobGFzdCAzZCkiLCJkaXNwbGF5LW5hbWUiOiJDb3VudCAobGFzdCAzZCkifV1dLCJicmVha291dCI6W1siZmllbGQiLCJzdWl0ZV9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSxbImZpZWxkIiwidGVzdF9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSxbImZpZWxkIiwid29ya2Zsb3dfcnVuX25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dLFsiZmllbGQiLCJ3b3JrZmxvd19qb2JfbmFtZSIseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV1dLCJvcmRlci1ieSI6W1siZGVzYyIsWyJhZ2dyZWdhdGlvbiIsM11dLFsiZGVzYyIsWyJhZ2dyZWdhdGlvbiIsMF1dXSwic291cmNlLXRhYmxlIjoiY2FyZF9fMTQ4MjgiLCJmaWx0ZXIiOlsiYW5kIixbInRpbWUtaW50ZXJ2YWwiLFsiZmllbGQiLCJ3b3JrZmxvd19ydW5fc3RhcnRlZF9hdCIseyJiYXNlLXR5cGUiOiJ0eXBlL0RhdGVUaW1lV2l0aExvY2FsVFoifV0sLTcsImRheSJdLFsiZG9lcy1ub3QtY29udGFpbiIsWyJmaWVsZCIsInN1aXRlX25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dLCJxdWVyeS1wcm9jZXNzb3IiLHsiY2FzZS1zZW5zaXRpdmUiOmZhbHNlfV0sWyJjb250YWlucyIsWyJmaWVsZCIsIndvcmtmbG93X2pvYl9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSwiYmUtdGVzdHMtIix7ImNhc2Utc2Vuc2l0aXZlIjpmYWxzZX1dLFsiPSIsWyJmaWVsZCIsInRlc3RfbmFtZSIseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV0sImUyZS1zdG9yYWdlLWluZ2VzdGlvbi10ZXN0Il1dfX0sImRpc3BsYXkiOiJ0YWJsZSIsImRpc3BsYXlJc0xvY2tlZCI6dHJ1ZSwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnsidGFibGUucGl2b3RfY29sdW1uIjoic3VpdGVfbmFtZSIsInRhYmxlLmNlbGxfY29sdW1uIjoiY291bnQiLCJ0YWJsZS5waXZvdCI6ZmFsc2UsInRhYmxlLmNvbHVtbnMiOlt7Im5hbWUiOiJzdWl0ZV9uYW1lIiwia2V5IjoiW1wibmFtZVwiLFwic3VpdGVfbmFtZVwiXSIsImVuYWJsZWQiOnRydWUsImZpZWxkUmVmIjpbImZpZWxkIiwic3VpdGVfbmFtZSIseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV19LHsibmFtZSI6InRlc3RfbmFtZSIsImtleSI6IltcIm5hbWVcIixcInRlc3RfbmFtZVwiXSIsImVuYWJsZWQiOnRydWUsImZpZWxkUmVmIjpbImZpZWxkIiwidGVzdF9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XX0seyJuYW1lIjoid29ya2Zsb3dfcnVuX25hbWUiLCJrZXkiOiJbXCJuYW1lXCIsXCJ3b3JrZmxvd19ydW5fbmFtZVwiXSIsImVuYWJsZWQiOnRydWUsImZpZWxkUmVmIjpbImZpZWxkIiwid29ya2Zsb3dfcnVuX25hbWUiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dfSx7Im5hbWUiOiJ3b3JrZmxvd19qb2JfbmFtZSIsImtleSI6IltcIm5hbWVcIixcIndvcmtmbG93X2pvYl9uYW1lXCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiZmllbGQiLCJ3b3JrZmxvd19qb2JfbmFtZSIseyJiYXNlLXR5cGUiOiJ0eXBlL1RleHQifV19LHsibmFtZSI6IkNvdW50IChsYXN0IDNkKSIsImtleSI6IltcIm5hbWVcIixcIkNvdW50IChsYXN0IDNkKVwiXSIsImVuYWJsZWQiOnRydWUsImZpZWxkUmVmIjpbImFnZ3JlZ2F0aW9uIiwzXX0seyJuYW1lIjoiY291bnQiLCJrZXkiOiJbXCJuYW1lXCIsXCJjb3VudFwiXSIsImVuYWJsZWQiOnRydWUsImZpZWxkUmVmIjpbImFnZ3JlZ2F0aW9uIiwwXX0seyJuYW1lIjoibWF4Iiwia2V5IjoiW1wibmFtZVwiLFwibWF4XCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiYWdncmVnYXRpb24iLDFdfSx7Im5hbWUiOiJtYXhfMiIsImtleSI6IltcIm5hbWVcIixcIm1heF8yXCJdIiwiZW5hYmxlZCI6dHJ1ZSwiZmllbGRSZWYiOlsiYWdncmVnYXRpb24iLDJdfV0sImNvbHVtbl9zZXR0aW5ncyI6eyJbXCJuYW1lXCIsXCJjb3VudFwiXSI6eyJjb2x1bW5fdGl0bGUiOiJDb3VudCAobGFzdCA3ZCkifSwiW1wibmFtZVwiLFwibWF4XCJdIjp7ImNvbHVtbl90aXRsZSI6Ikxhc3QgZmFpbGVkIHJ1biJ9LCJbXCJuYW1lXCIsXCJtYXhfMlwiXSI6eyJjb2x1bW5fdGl0bGUiOiJMYXN0IGZhaWxlZCBkYXRlIiwiZGF0ZV9zdHlsZSI6Ik1NTU0gRCwgWVlZWSIsInRpbWVfZW5hYmxlZCI6bnVsbH19fSwib3JpZ2luYWxfY2FyZF9pZCI6MTUyMTIsInR5cGUiOiJxdWVzdGlvbiJ9)"", 'created_at': datetime.datetime(2024, 7, 26, 10, 28, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285684041, 'issue_id': 2413971769, 'author': 'crisptrutski', 'body': ""This hasn't flaked again in almost 3 weeks, so I'm not sure how much time it's worth putting into it, given the complexity of this helper. For now I'm just going to mitigate it further by increasing the number of attempts that we make."", 'created_at': datetime.datetime(2024, 8, 13, 8, 37, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291493759, 'issue_id': 2413971769, 'author': 'crisptrutski', 'body': 'Jinxed it, just flaked twice this week.', 'created_at': datetime.datetime(2024, 8, 15, 15, 11, 9, tzinfo=datetime.timezone.utc)}]","calherries on (2024-07-26 10:28:08 UTC): This flake has been around since at [least May](https://metaboat.slack.com/archives/C5XHN8GLW/p1714642505921739?thread_ts=1714641978.456929&cid=C5XHN8GLW). It just flaked for me so that's 3 times this week according to [the query](https://stats.metabase.com/question#eyJuYW1lIjoiVGVzdCBmbGFrZXMgYnkgc3VpdGUgbmFtZSBhbmQgdGVzdCBuYW1lIChub3QgUVApIiwiZGVzY3JpcHRpb24iOiJodHRwczovL3N0YXRzLm1ldGFiYXNlLmNvbS9tb2RlbC8xNDgyOC10ZXN0LWZsYWtpbmVzcyIsImRhdGFzZXRfcXVlcnkiOnsiZGF0YWJhc2UiOjI2LCJ0eXBlIjoicXVlcnkiLCJxdWVyeSI6eyJhZ2dyZWdhdGlvbiI6W1siY291bnQiXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl91cmwiLHsiYmFzZS10eXBlIjoidHlwZS9UZXh0In1dXSxbIm1heCIsWyJmaWVsZCIsIndvcmtmbG93X3J1bl9zdGFydGVkX2F0Iix7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiIsInRlbXBvcmFsLXVuaXQiOiJtaW51dGUifV1dLFsiYWdncmVnYXRpb24tb3B0aW9ucyIsWyJjb3VudC13aGVyZSIsWyI-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)

crisptrutski (Assginee) on (2024-08-13 08:37:22 UTC): This hasn't flaked again in almost 3 weeks, so I'm not sure how much time it's worth putting into it, given the complexity of this helper. For now I'm just going to mitigate it further by increasing the number of attempts that we make.

crisptrutski (Assginee) on (2024-08-15 15:11:09 UTC): Jinxed it, just flaked twice this week.

"
2413971689,issue,closed,not_planned,[Flaky Test]: connection-pool-invalidated-on-details-change,"Last Flake: https://github.com/metabase/metabase/actions/runs/9943505158
Last Flake Time: 2024-07-15T10:50:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-17 15:50:10+00:00,[],2024-12-13 16:43:44+00:00,2024-12-13 16:43:44+00:00,https://github.com/metabase/metabase/issues/45746,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2413971657,issue,closed,not_planned,[Flaky Test]: should be able to edit a custom column with the same name as one of the columns used in the expression (metabase#40064),"Last Flake: https://github.com/metabase/metabase/actions/runs/9947519673
Last Flake Time: 2024-07-15T15:57:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-17 15:50:09+00:00,[],2024-12-13 16:45:44+00:00,2024-12-13 16:45:44+00:00,https://github.com/metabase/metabase/issues/45745,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2413971609,issue,closed,not_planned,[Flaky Test]: scenarios > admin > datamodel > editor field settings should allow changing the field semantic type and currency,"Last Flake: https://github.com/metabase/metabase/actions/runs/9956316207
Last Flake Time: 2024-07-16T05:50:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 1
Flakes in the last 7d: 1",github-automation-metabase,2024-07-17 15:50:08+00:00,[],2024-12-13 16:45:44+00:00,2024-12-13 16:45:44+00:00,https://github.com/metabase/metabase/issues/45744,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2413971569,issue,closed,not_planned,[Flaky Test]: public question sharing snowplow events when embedding question when interacting with static embedding should send `static_embed_published` when publishing changes in the static embed modal,"Last Flake: https://github.com/metabase/metabase/actions/runs/9965076628
Last Flake Time: 2024-07-16T16:10:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 2
Flakes in the last 7d: 2",github-automation-metabase,2024-07-17 15:50:07+00:00,[],2024-12-13 16:45:43+00:00,2024-12-13 16:45:43+00:00,https://github.com/metabase/metabase/issues/45743,"[('flaky-test-fix', ''), ('.Team/Embedding', '')]",[],
2413971541,issue,closed,not_planned,[Flaky Test]: should be able to hide the visualization for a pinned question,"Last Flake: https://github.com/metabase/metabase/actions/runs/9961409771
Last Flake Time: 2024-07-16T11:00:00-07:00
Flakes in the last day: 2
Flakes in the last 3d: 2
Flakes in the last 7d: 2",github-automation-metabase,2024-07-17 15:50:06+00:00,[],2024-12-13 16:45:43+00:00,2024-12-13 16:45:43+00:00,https://github.com/metabase/metabase/issues/45742,"[('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2233646767, 'issue_id': 2413971541, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9961409771\nLast Flake Time: 2024-07-16T11:00:00-07:00\nFlakes in the last day: 2\nFlakes in the last 3d: 2\nFlakes in the last 7d: 2', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 3, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:03 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9961409771
Last Flake Time: 2024-07-16T11:00:00-07:00
Flakes in the last day: 2
Flakes in the last 3d: 2
Flakes in the last 7d: 2

"
2413971514,issue,closed,not_planned,[Flaky Test]: breadcrumbs should allow to navigate to and from field settings for a single-schema database,"Last Flake: https://github.com/metabase/metabase/actions/runs/9962498767
Last Flake Time: 2024-07-16T12:29:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 2",github-automation-metabase,2024-07-17 15:50:05+00:00,[],2024-12-13 16:44:02+00:00,2024-12-13 16:44:02+00:00,https://github.com/metabase/metabase/issues/45741,"[('flaky-test-fix', ''), ('.Team/Querying', '')]","[{'comment_id': 2233646738, 'issue_id': 2413971514, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9962498767\nLast Flake Time: 2024-07-16T12:29:00-07:00\nFlakes in the last day: 1\nFlakes in the last 3d: 1\nFlakes in the last 7d: 2', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 2, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:02 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9962498767
Last Flake Time: 2024-07-16T12:29:00-07:00
Flakes in the last day: 1
Flakes in the last 3d: 1
Flakes in the last 7d: 2

"
2413971478,issue,closed,not_planned,[Flaky Test]: should be possible to add and remove a metric from bookmarks,"Last Flake: https://github.com/metabase/metabase/actions/runs/9967438512
Last Flake Time: 2024-07-16T20:34:00-07:00
Flakes in the last day: 3
Flakes in the last 3d: 3
Flakes in the last 7d: 3",github-automation-metabase,2024-07-17 15:50:04+00:00,[],2024-12-13 16:45:43+00:00,2024-12-13 16:45:43+00:00,https://github.com/metabase/metabase/issues/45740,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2233646719, 'issue_id': 2413971478, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9967438512\nLast Flake Time: 2024-07-16T20:34:00-07:00\nFlakes in the last day: 3\nFlakes in the last 3d: 3\nFlakes in the last 7d: 3', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2523025702, 'issue_id': 2413971478, 'author': 'rafpaf', 'body': ""Stress tested this test: https://github.com/metabase/metabase/actions/runs/12198047313/job/34028958272#step:9:237. It's still flaky.\n\n![Image](https://github.com/user-attachments/assets/37e9f0cd-715c-49a3-b323-b81ac6711f52)"", 'created_at': datetime.datetime(2024, 12, 6, 11, 50, 29, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:02 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9967438512
Last Flake Time: 2024-07-16T20:34:00-07:00
Flakes in the last day: 3
Flakes in the last 3d: 3
Flakes in the last 7d: 3

rafpaf on (2024-12-06 11:50:29 UTC): Stress tested this test: https://github.com/metabase/metabase/actions/runs/12198047313/job/34028958272#step:9:237. It's still flaky.

![Image](https://github.com/user-attachments/assets/37e9f0cd-715c-49a3-b323-b81ac6711f52)

"
2413971442,issue,closed,not_planned,"[Flaky Test]: should be possible to archive, unarchive, and delete a metric","Last Flake: https://github.com/metabase/metabase/actions/runs/9967438512
Last Flake Time: 2024-07-16T20:34:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6",github-automation-metabase,2024-07-17 15:50:04+00:00,[],2024-12-13 16:45:42+00:00,2024-12-13 16:45:42+00:00,https://github.com/metabase/metabase/issues/45739,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2233646708, 'issue_id': 2413971442, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9967438512\nLast Flake Time: 2024-07-16T20:34:00-07:00\nFlakes in the last day: 6\nFlakes in the last 3d: 6\nFlakes in the last 7d: 6', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 2, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:02 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9967438512
Last Flake Time: 2024-07-16T20:34:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6

"
2413971419,issue,closed,not_planned,[Flaky Test]: Public dashboards/questions downloads (results and export as pdf) Public questions should be able to download the question as PNG,"Last Flake: https://github.com/metabase/metabase/actions/runs/9964396314
Last Flake Time: 2024-07-16T19:24:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6",github-automation-metabase,2024-07-17 15:50:03+00:00,[],2024-12-13 16:45:42+00:00,2024-12-13 16:45:42+00:00,https://github.com/metabase/metabase/issues/45738,"[('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2233646694, 'issue_id': 2413971419, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9964396314\nLast Flake Time: 2024-07-16T19:24:00-07:00\nFlakes in the last day: 6\nFlakes in the last 3d: 6\nFlakes in the last 7d: 6', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 1, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:01 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9964396314
Last Flake Time: 2024-07-16T19:24:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6

"
2413971390,issue,closed,not_planned,[Flaky Test]: Public dashboards/questions downloads (results and export as pdf) Public questions should be able to download a public card as CSV,"Last Flake: https://github.com/metabase/metabase/actions/runs/9964396314
Last Flake Time: 2024-07-16T19:24:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6",github-automation-metabase,2024-07-17 15:50:02+00:00,[],2024-12-13 16:45:42+00:00,2024-12-13 16:45:41+00:00,https://github.com/metabase/metabase/issues/45737,"[('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2233646680, 'issue_id': 2413971390, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9964396314\nLast Flake Time: 2024-07-16T19:24:00-07:00\nFlakes in the last day: 6\nFlakes in the last 3d: 6\nFlakes in the last 7d: 6', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, 1, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:01 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9964396314
Last Flake Time: 2024-07-16T19:24:00-07:00
Flakes in the last day: 6
Flakes in the last 3d: 6
Flakes in the last 7d: 6

"
2413971345,issue,closed,not_planned,[Flaky Test]: should be able to open x-ray on a dashcard from a dashboard with multiple tabs,"Last Flake: https://github.com/metabase/metabase/actions/runs/9967292089
Last Flake Time: 2024-07-16T19:41:00-07:00
Flakes in the last day: 5
Flakes in the last 3d: 9
Flakes in the last 7d: 9",github-automation-metabase,2024-07-17 15:50:01+00:00,[],2024-12-13 16:45:41+00:00,2024-12-13 16:45:41+00:00,https://github.com/metabase/metabase/issues/45736,"[('flaky-test-fix', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2233646650, 'issue_id': 2413971345, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9967292089\nLast Flake Time: 2024-07-16T19:41:00-07:00\nFlakes in the last day: 5\nFlakes in the last 3d: 9\nFlakes in the last 7d: 9', 'created_at': datetime.datetime(2024, 7, 17, 15, 51, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:51:00 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9967292089
Last Flake Time: 2024-07-16T19:41:00-07:00
Flakes in the last day: 5
Flakes in the last 3d: 9
Flakes in the last 7d: 9

"
2413971319,issue,closed,not_planned,[Flaky Test]: should allow setting column relations (metabase#29318),"Last Flake: https://github.com/metabase/metabase/actions/runs/9963279920
Last Flake Time: 2024-07-16T13:54:00-07:00
Flakes in the last day: 2
Flakes in the last 3d: 9
Flakes in the last 7d: 11",github-automation-metabase,2024-07-17 15:50:00+00:00,[],2024-12-13 16:44:02+00:00,2024-12-13 16:44:02+00:00,https://github.com/metabase/metabase/issues/45735,"[('flaky-test-fix', ''), ('.Team/Querying', '')]","[{'comment_id': 2233646635, 'issue_id': 2413971319, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9963279920\nLast Flake Time: 2024-07-16T13:54:00-07:00\nFlakes in the last day: 2\nFlakes in the last 3d: 9\nFlakes in the last 7d: 11', 'created_at': datetime.datetime(2024, 7, 17, 15, 50, 59, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:50:59 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9963279920
Last Flake Time: 2024-07-16T13:54:00-07:00
Flakes in the last day: 2
Flakes in the last 3d: 9
Flakes in the last 7d: 11

"
2413971294,issue,closed,not_planned,[Flaky Test]: later-page-fetch-throws-test,"Last Flake: https://github.com/metabase/metabase/actions/runs/9956415536
Last Flake Time: 2024-07-16T06:35:00-07:00
Flakes in the last day: 0
Flakes in the last 3d: 10
Flakes in the last 7d: 11",github-automation-metabase,2024-07-17 15:49:59+00:00,[],2024-12-13 16:43:44+00:00,2024-12-13 16:43:44+00:00,https://github.com/metabase/metabase/issues/45734,"[('.Backend', ''), ('flaky-test-fix', ''), ('.Team/Querying', '')]",[],
2413971238,issue,closed,not_planned,[Flaky Test]: model query & metadata should allow to edit the model with write data & collection permissions,"Last Flake: https://github.com/metabase/metabase/actions/runs/9963563901
Last Flake Time: 2024-07-16T13:38:00-07:00
Flakes in the last day: 5
Flakes in the last 3d: 12
Flakes in the last 7d: 33",github-automation-metabase,2024-07-17 15:49:57+00:00,[],2024-12-13 16:45:41+00:00,2024-12-13 16:45:41+00:00,https://github.com/metabase/metabase/issues/45733,"[('flaky-test-fix', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2233646586, 'issue_id': 2413971238, 'author': 'github-automation-metabase', 'body': 'This test is still flaky\n\nLast Flake: https://github.com/metabase/metabase/actions/runs/9963563901\nLast Flake Time: 2024-07-16T13:38:00-07:00\nFlakes in the last day: 5\nFlakes in the last 3d: 12\nFlakes in the last 7d: 33', 'created_at': datetime.datetime(2024, 7, 17, 15, 50, 57, tzinfo=datetime.timezone.utc)}]","github-automation-metabase (Issue Creator) on (2024-07-17 15:50:57 UTC): This test is still flaky

Last Flake: https://github.com/metabase/metabase/actions/runs/9963563901
Last Flake Time: 2024-07-16T13:38:00-07:00
Flakes in the last day: 5
Flakes in the last 3d: 12
Flakes in the last 7d: 33

"
2413833394,issue,closed,completed,Downloads (png+pdf) not working on the sdk because of bundling issues,"https://metaboat.slack.com/archives/C063Q3F1HPF/p1721148433794729

The issue seems to be caused by dynamic imports and can be fixed by doing normal imports, that will increase the bundle size of both the core app and the sdk",npretto,2024-07-17 14:51:56+00:00,['npretto'],2024-10-08 16:20:15+00:00,2024-07-19 13:03:08+00:00,https://github.com/metabase/metabase/issues/45732,"[('.Team/Embedding', '')]",[],
2413787923,issue,closed,completed,NaN displayed in query execution time,"### Describe the bug

![image](https://github.com/user-attachments/assets/f5527ae1-3f03-4b39-bf85-3bfe3fb024f1)


### To Reproduce

1. New > Question > Orders > Visualize
2. Disable network
3. Summarize > Done

### Information about your Metabase installation

master, 24caede62a


### Severity

P3
",kamilmielnik,2024-07-17 14:35:43+00:00,['nemanjaglumac'],2024-07-18 10:16:26+00:00,2024-07-18 09:45:11+00:00,https://github.com/metabase/metabase/issues/45730,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2413757746,issue,closed,completed,Add basic auth capabilities to Druid JDBC,Add basic auth capabilities to Druid JDBC. It is supported by Avatica driver as per [docs](https://calcite.apache.org/avatica/docs/client_reference.html#authentication). Testing requires modification to Druid's configuration mounted to the test container.,lbrdnk,2024-07-17 14:22:25+00:00,['lbrdnk'],2024-12-17 14:07:22+00:00,2024-12-16 13:18:15+00:00,https://github.com/metabase/metabase/issues/45728,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2489097873, 'issue_id': 2413757746, 'author': 'davilavp', 'body': 'Hello! Do you have any estimate of when you could release this issue? Thank you!', 'created_at': datetime.datetime(2024, 11, 20, 16, 50, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489900544, 'issue_id': 2413757746, 'author': 'paoliniluis', 'body': ""@davilavp please let us know if you're a paid customer so we can reorganize the priorities of this"", 'created_at': datetime.datetime(2024, 11, 21, 1, 51, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490890232, 'issue_id': 2413757746, 'author': 'davilavp', 'body': 'Hola @paoliniluis! \nI work in a government entity in the province of Santa Fe, Argentina. We are currently using the free version of Metabase. Right now, we are in a project that involves Druid as a data source and we need this functionality. Regarding this, we made a custom adaptation that we could use, but the ideal would be to have the official release to avoid compatibility problems in the future.', 'created_at': datetime.datetime(2024, 11, 21, 11, 39, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518562292, 'issue_id': 2413757746, 'author': 'ddowbnac', 'body': '@lbrdnk please check the latest PR, it has the fixed commits for the workflow. Thank you for being patient.', 'created_at': datetime.datetime(2024, 12, 4, 21, 6, 37, tzinfo=datetime.timezone.utc)}]","davilavp on (2024-11-20 16:50:17 UTC): Hello! Do you have any estimate of when you could release this issue? Thank you!

paoliniluis on (2024-11-21 01:51:10 UTC): @davilavp please let us know if you're a paid customer so we can reorganize the priorities of this

davilavp on (2024-11-21 11:39:26 UTC): Hola @paoliniluis! 
I work in a government entity in the province of Santa Fe, Argentina. We are currently using the free version of Metabase. Right now, we are in a project that involves Druid as a data source and we need this functionality. Regarding this, we made a custom adaptation that we could use, but the ideal would be to have the official release to avoid compatibility problems in the future.

ddowbnac on (2024-12-04 21:06:37 UTC): @lbrdnk please check the latest PR, it has the fixed commits for the workflow. Thank you for being patient.

"
2413750461,issue,closed,completed,Fix flake test on `public-resource-downloads.cy.spec.ts`,Example failure: https://github.com/metabase/metabase/actions/runs/9963242462/job/27529262510?pr=45619,npretto,2024-07-17 14:19:03+00:00,['npretto'],2024-10-08 16:20:34+00:00,2024-07-17 15:10:19+00:00,https://github.com/metabase/metabase/issues/45727,"[('.Team/Embedding', '')]",[],
2413706845,issue,closed,completed,Match all filter popover styles with dark theme,,WiNloSt,2024-07-17 14:00:55+00:00,['WiNloSt'],2024-08-01 16:29:12+00:00,2024-08-01 16:29:11+00:00,https://github.com/metabase/metabase/issues/45723,[],[],
2413672146,issue,open,,java.lang.IllegalArgumentException: No implementation of method: :->temporal of protocol: #'metabase.sync.analyze.fingerprint.fingerprinters/ITemporalCoerceable found for class: java.lang.Boolean when fingerprinting mongodb,"### Describe the bug

A very interesting log line in a mongodb fingerprint on our cloud

### To Reproduce

Check the ticket associated with this issue, you'll be able to see the log line exactly at 2024-07-17 13:30:13.748

### Expected behavior

We should not have any errors on the fingerprints

### Logs

```
2024-07-17 13:30:13.749	
	at java.base/java.lang.Thread.run(Unknown Source)



2024-07-17 13:30:13.749	
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
2024-07-17 13:30:13.749	
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
2024-07-17 13:30:13.749	
	at java.base/java.util.concurrent.FutureTask.run(Unknown Source)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.call(AFn.java:18)
2024-07-17 13:30:13.749	
	at clojure.lang.RestFn.invoke(RestFn.java:397)
2024-07-17 13:30:13.749	
	at clojure.core$bound_fn_STAR_$fn__5818.doInvoke(core.clj:2020)
2024-07-17 13:30:13.749	
	at clojure.core$apply.invokeStatic(core.clj:671)
2024-07-17 13:30:13.749	
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
2024-07-17 13:30:13.749	
	at clojure.lang.RestFn.invoke(RestFn.java:425)
2024-07-17 13:30:13.749	
	at clojure.core$with_bindings_STAR_.doInvoke(core.clj:1990)
2024-07-17 13:30:13.749	
	at clojure.core$with_bindings_STAR_.invokeStatic(core.clj:1990)
2024-07-17 13:30:13.749	
	at clojure.core$apply.invokeStatic(core.clj:667)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.applyTo(AFn.java:144)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.applyToHelper(AFn.java:152)
2024-07-17 13:30:13.749	
	at metabase.sync.concurrent$submit_task$fn__94647.invoke(concurrent.clj:23)
2024-07-17 13:30:13.749	
	at metabase.api.table$sync_unhidden_tables$fn__98932.invoke(table.clj:90)
2024-07-17 13:30:13.749	
	at metabase.sync$sync_table_BANG_.invoke(sync.clj:57)
2024-07-17 13:30:13.749	
	at metabase.sync$sync_table_BANG_.invokeStatic(sync.clj:61)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze$analyze_table_BANG_.invoke(analyze.clj:76)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze$analyze_table_BANG_.invokeStatic(analyze.clj:79)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze.fingerprint$fingerprint_fields_BANG_.invoke(fingerprint.clj:194)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze.fingerprint$fingerprint_fields_BANG_.invokeStatic(fingerprint.clj:200)
2024-07-17 13:30:13.749	
	at metabase.sync.util$do_with_error_handling.invoke(util.clj:183)
2024-07-17 13:30:13.749	
	at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:190)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze.fingerprint$fingerprint_fields_BANG_$fn__83413.invoke(fingerprint.clj:202)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze.fingerprint$fingerprint_table_BANG_.invoke(fingerprint.clj:61)
2024-07-17 13:30:13.749	
	at metabase.sync.analyze.fingerprint$fingerprint_table_BANG_.invokeStatic(fingerprint.clj:84)
2024-07-17 13:30:13.749	
	at clojure.lang.MultiFn.invoke(MultiFn.java:252)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123884.invoke(mongo.clj:337)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123884.invokeStatic(mongo.clj:339)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123884$fn__123885.invoke(mongo.clj:342)
2024-07-17 13:30:13.749	
	at metabase.db.metadata_queries$table_rows_sample.invoke(metadata_queries.clj:200)
2024-07-17 13:30:13.749	
	at metabase.db.metadata_queries$table_rows_sample.invokeStatic(metadata_queries.clj:218)
2024-07-17 13:30:13.749	
	at metabase.query_processor$process_query.invoke(query_processor.clj:291)
2024-07-17 13:30:13.749	
	at metabase.query_processor$process_query.invokeStatic(query_processor.clj:311)
2024-07-17 13:30:13.749	
	at clojure.lang.RestFn.invoke(RestFn.java:436)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$sync_qp$qp_STAR___63256.doInvoke(reducible.clj:153)
2024-07-17 13:30:13.749	
	at clojure.core$apply.invoke(core.clj:662)
2024-07-17 13:30:13.749	
	at clojure.core$apply.invokeStatic(core.clj:667)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.applyTo(AFn.java:144)
2024-07-17 13:30:13.749	
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$async_qp$qp_STAR___63244.invoke(reducible.clj:132)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$async_qp$qp_STAR___63244$thunk__63246.invoke(reducible.clj:126)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72540.invoke(enterprise.clj:103)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.enterprise$fn__72529$handle_audit_app_internal_queries__72530$fn__72532.invoke(enterprise.clj:96)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.normalize_query$normalize$fn__72894.invoke(normalize_query.clj:38)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72589.invoke(resolve_database_and_driver.clj:60)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.store$initialize_store$fn__67752.invoke(store.clj:13)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
2024-07-17 13:30:13.749	
	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:164)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.store$initialize_store$fn__67752$fn__67753.invoke(store.clj:14)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72592.invoke(resolve_database_and_driver.clj:76)
2024-07-17 13:30:13.749	
	at metabase.driver$do_with_driver.invoke(driver.clj:92)
2024-07-17 13:30:13.749	
	at metabase.driver$do_with_driver.invokeStatic(driver.clj:97)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72592$fn__72596.invoke(resolve_database_and_driver.clj:77)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__67125.invoke(fetch_source_query.clj:303)
2024-07-17 13:30:13.749	
	at metabase.query_processor$fn__73849$combined_pre_process__73850$combined_pre_process_STAR___73851.invoke(query_processor.clj:259)
2024-07-17 13:30:13.749	
	at metabase.query_processor$fn__73849$combined_post_process__73854$combined_post_process_STAR___73855.invoke(query_processor.clj:262)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71944.invoke(mbql_to_native.clj:24)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__72512.invoke(enterprise.clj:64)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.enterprise$check_download_permissions_middleware$fn__72502.invoke(enterprise.clj:51)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.permissions$check_query_permissions$fn__67028.invoke(permissions.clj:140)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72681.invoke(cache.clj:229)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$identity_qp.invoke(reducible.clj:36)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$runf.invoke(context.clj:40)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$runf.invokeStatic(context.clj:46)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_runf.invoke(default.clj:42)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_runf.invokeStatic(default.clj:44)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$executef.invoke(context.clj:49)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$executef.invokeStatic(context.clj:60)
2024-07-17 13:30:13.749	
	at clojure.lang.MultiFn.invoke(MultiFn.java:244)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123872.invoke(mongo.clj:318)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123872.invokeStatic(mongo.clj:320)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.connection$do_with_mongo_client.invoke(connection.clj:85)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.connection$do_with_mongo_client.invokeStatic(connection.clj:89)
2024-07-17 13:30:13.749	
	at metabase.util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)
2024-07-17 13:30:13.749	
	at metabase.util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.connection$do_with_mongo_client$fn__120057.invoke(connection.clj:94)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo$fn__123872$f__120066__auto____123873.invoke(mongo.clj:321)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.execute$execute_reducible_query.invoke(execute.clj:182)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.execute$execute_reducible_query.invokeStatic(execute.clj:207)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.execute$reduce_results.invoke(execute.clj:171)
2024-07-17 13:30:13.749	
	at metabase.driver.mongo.execute$reduce_results.invokeStatic(execute.clj:177)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_runf$respond_STAR___50910.invoke(default.clj:45)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$reducef.invoke(context.clj:63)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context$reducef.invokeStatic(context.clj:70)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_reducef.invoke(default.clj:25)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_reducef.invokeStatic(default.clj:33)
2024-07-17 13:30:13.749	
	at metabase.query_processor.context.default$default_reducef$fn__50906.invoke(default.clj:34)
2024-07-17 13:30:13.749	
	at clojure.core$transduce.invoke(core.clj:6934)
2024-07-17 13:30:13.749	
	at clojure.core$transduce.invokeStatic(core.clj:6943)
2024-07-17 13:30:13.749	
	at clojure.core$transduce.invokeStatic(core.clj:6947)
2024-07-17 13:30:13.749	
	at metabase.query_processor.reducible$reducible_rows$reify__63259.reduce(reducible.clj:177)
2024-07-17 13:30:13.749	
	at metabase.query_processor.middleware.add_rows_truncated$add_rows_truncated_xform$fn__71615.invoke(add_rows_truncated.clj:34)
2024-07-17 13:30:13.749	
	at clojure.core$take$fn__5974$fn__5975.invoke(core.clj:2894)
2024-07-17 13:30:13.749	
	at redux.core$post_complete$fn__62630.invoke(core.cljc:15)
2024-07-17 13:30:13.748	
	at metabase.sync.analyze.fingerprint.fingerprinters$col_wise$fn__62990.invoke(fingerprinters.clj:31)
2024-07-17 13:30:13.748	
	at clojure.core$mapv.invoke(core.clj:6971)
2024-07-17 13:30:13.748	
	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-07-17 13:30:13.748	
	at clojure.core$into.invokeStatic(core.clj:6959)
2024-07-17 13:30:13.748	
	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8249.invoke(protocols.clj:124)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:169)
2024-07-17 13:30:13.748	
	at clojure.core$next__5451.invokeStatic(core.clj:64)
2024-07-17 13:30:13.748	
	at clojure.lang.RT.next(RT.java:713)
2024-07-17 13:30:13.748	
	at clojure.lang.Cons.next(Cons.java:39)
2024-07-17 13:30:13.748	
	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-07-17 13:30:13.748	
	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-07-17 13:30:13.748	
	at clojure.core$map$fn__5942.invoke(core.clj:2783)
2024-07-17 13:30:13.748	
	at metabase.sync.analyze.fingerprint.fingerprinters$col_wise$fn__62990$fn__62995.invoke(fingerprinters.clj:34)
2024-07-17 13:30:13.748	
	at metabase.sync.analyze.fingerprint.fingerprinters$with_error_handling$fn__63027.invoke(fingerprinters.clj:84)
2024-07-17 13:30:13.748	
	at metabase.sync.util$do_with_error_handling.invoke(util.clj:183)
2024-07-17 13:30:13.748	
	at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:190)
2024-07-17 13:30:13.748	
	at metabase.sync.analyze.fingerprint.fingerprinters$with_error_handling$fn__63027$fn__63032.invoke(fingerprinters.clj:84)
2024-07-17 13:30:13.748	
	at redux.core$post_complete$fn__62630.invoke(core.cljc:15)
2024-07-17 13:30:13.748	
	at redux.core$juxt$fn__62636.invoke(core.cljc:34)
2024-07-17 13:30:13.748	
	at clojure.core$mapv.invoke(core.clj:6971)
2024-07-17 13:30:13.748	
	at clojure.core$mapv.invokeStatic(core.clj:6971)
2024-07-17 13:30:13.748	
	at clojure.core$into.invokeStatic(core.clj:6959)
2024-07-17 13:30:13.748	
	at clojure.core$reduce.invokeStatic(core.clj:6887)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
2024-07-17 13:30:13.748	
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:24)
2024-07-17 13:30:13.748	
	at clojure.core$seq__5467.invokeStatic(core.clj:139)
2024-07-17 13:30:13.748	
	at clojure.lang.RT.seq(RT.java:535)
2024-07-17 13:30:13.748	
	at clojure.lang.LazySeq.seq(LazySeq.java:51)
2024-07-17 13:30:13.748	
	at clojure.lang.LazySeq.sval(LazySeq.java:42)
2024-07-17 13:30:13.748	
	at clojure.core$map$fn__5939.invoke(core.clj:2777)
2024-07-17 13:30:13.748	
	at redux.core$juxt$fn__62636$fn__62641.invoke(core.cljc:37)
2024-07-17 13:30:13.748	
	at redux.core$post_complete$fn__62630.invoke(core.cljc:15)
2024-07-17 13:30:13.748	
	at clojure.core$map$fn__5931$fn__5932.invoke(core.clj:2759)
2024-07-17 13:30:13.748	
	at metabase.sync.analyze.fingerprint.fingerprinters$fn__63085$G__63080__63090.invoke(fingerprinters.clj:189)
2024-07-17 13:30:13.748	
	at clojure.core$_cache_protocol_fn.invoke(core_deftype.clj:576)
2024-07-17 13:30:13.748	
	at clojure.core$_cache_protocol_fn.invokeStatic(core_deftype.clj:584)
2024-07-17 13:30:13.748	
java.lang.IllegalArgumentException: No implementation of method: :->temporal of protocol: #'metabase.sync.analyze.fingerprint.fingerprinters/ITemporalCoerceable found for class: java.lang.Boolean
2024-07-17 13:30:13.748	
2024-07-17 13:30:13,748 WARN sync.util :: Error generating fingerprint for Field 1062 ''lastSessionTime''
```

### Information about your Metabase installation

```JSON
v49
```


### Severity

P2

### Additional context

NA",paoliniluis,2024-07-17 13:46:43+00:00,[],2025-02-04 20:25:11+00:00,,https://github.com/metabase/metabase/issues/45722,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2413666165,issue,closed,completed,Document SQL Analysis workflows,Write namespace docstrings and spiff up the methods ones as well. ~~Sprinkle some types where applicable.~~,crisptrutski,2024-07-17 13:44:15+00:00,['crisptrutski'],2024-07-30 20:19:49+00:00,2024-07-24 10:56:22+00:00,https://github.com/metabase/metabase/issues/45720,"[('.Team/Workflows', 'aka BEC')]",[],
2413587963,issue,closed,completed,"Stacked bar chart ""Stack values to show"" setting produces ""Cannot read properties of undefined"" error","### Describe the bug

When selecting a value of ""Stack values to show"" choice to anything other than Total (e.g. Segment or Both), an error is produced by Metabase `Cannot read properties of undefined (reading 'null:value:d')`. This works on inputs with specific characteristics.

### To Reproduce

For any database engine, use the following SQL query:
```sql
    select '2024-06-23 00:00:00' as date,	'a' as value_type,	14080 as value
    UNION ALL
    select '2024-07-24 00:00:00' as date,	'd' as value_type,	0 as value
 ```
 Then build a bar chart
 X-axis: `date`, series breakout by `value_type`
 Y-axis: `value`
Set Display -> **Stacking**: Stack, **Values to show**: Some, **Stack values to show**: Segments.
Observe error `Cannot read properties of undefined (reading 'null:value:d')`

### Expected behavior

No error being produced

### Logs

This error does not occur when set **Stack values to show**: Total
This also does not happen on a different input:
```sql
    select '2024-06-23 00:00:00' as date,	'a' as value_type,	14080 as value
    UNION ALL
    select '2024-06-24 00:00:00' as date,	'd' as value_type,	0 as value
 ```
 Here the date is changed to 06-24 instead of 07-24 on a second row

### Information about your Metabase installation

```JSON
Metabase version: 0.50.13
Metabase database: postgres
```


### Severity

Annoying

### Additional context

_No response_",phantom943,2024-07-17 13:10:22+00:00,['alxnddr'],2024-09-04 19:16:46+00:00,2024-09-04 14:23:25+00:00,https://github.com/metabase/metabase/issues/45717,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2233381981, 'issue_id': 2413587963, 'author': 'bshepherdson', 'body': ""Something about the dates being in the future, perhaps.\r\n\r\n@phantom943 Can you include more details about that error? Either capture a bug report (Ctrl-F1 or Cmd+F1 on Mac) or include a copy-paste or screenshot of the error's stack trace. With a generic JS error like that it's hard to know where to look for the problem."", 'created_at': datetime.datetime(2024, 7, 17, 13, 51, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233396404, 'issue_id': 2413587963, 'author': 'phantom943', 'body': ""Hey @bshepherdson  thanks for replying!\r\n\r\n![image](https://github.com/user-attachments/assets/be52541e-ced8-4574-bce0-4416d5c90d0e)\r\n\r\nHere is the screenshot of the error, because cmd+f1 seems to do nothing.\r\nAlso, the dates in the future seem not to be the culprit, because the error is also observed for this query:\r\n```sql\r\nselect '2024-05-23 00:00:00' as date,\t'a' as value_type,\t14080 as value\r\n    UNION ALL\r\n    select '2024-06-24 00:00:00' as date,\t'd' as value_type,\t0 as value\r\n```"", 'created_at': datetime.datetime(2024, 7, 17, 13, 58, 11, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-17 13:51:57 UTC): Something about the dates being in the future, perhaps.

@phantom943 Can you include more details about that error? Either capture a bug report (Ctrl-F1 or Cmd+F1 on Mac) or include a copy-paste or screenshot of the error's stack trace. With a generic JS error like that it's hard to know where to look for the problem.

phantom943 (Issue Creator) on (2024-07-17 13:58:11 UTC): Hey @bshepherdson  thanks for replying!

![image](https://github.com/user-attachments/assets/be52541e-ced8-4574-bce0-4416d5c90d0e)

Here is the screenshot of the error, because cmd+f1 seems to do nothing.
Also, the dates in the future seem not to be the culprit, because the error is also observed for this query:
```sql
select '2024-05-23 00:00:00' as date,	'a' as value_type,	14080 as value
    UNION ALL
    select '2024-06-24 00:00:00' as date,	'd' as value_type,	0 as value
```

"
2413515511,issue,open,,Add sanity checks to test embedding sdk compatibility with React 17 and 18,"We should add basic tests to verify compatibility with the supported React versions, i.e. React 17 and React 18.",heypoom,2024-07-17 12:37:33+00:00,[],2025-02-04 20:25:56+00:00,,https://github.com/metabase/metabase/issues/45714,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2413510302,issue,closed,completed,Embedding sdk throws a runtime error when used with React 17,"The embedding sdk currently throws a runtime error when rendering the `MetabaseProvider` with React 17. We should troubleshoot and fix this, so they are compatible with both React 17 and 18.

```
o is not a function
TypeError: o is not a function
    at t.useSyncExternalStoreWithSelector (http://localhost:3004/static/js/vendors-node_modules_metabase_embedding-sdk-react_dist_main_bundle_js.chunk.js:202565:19)
    at n (http://localhost:3004/static/js/vendors-node_modules_metabase_embedding-sdk-react_dist_main_bundle_js.chunk.js:217237:23)
    at e73 (http://localhost:3004/static/js/vendors-node_modules_metabase_embedding-sdk-react_dist_main_bundle_js.chunk.js:348614:25)
    at renderWithHooks (http://localhost:3004/static/js/bundle.js:19125:22)
    at mountIndeterminateComponent (http://localhost:3004/static/js/bundle.js:21608:17)
    at beginWork (http://localhost:3004/static/js/bundle.js:22661:20)
    at HTMLUnknownElement.callCallback (http://localhost:3004/static/js/bundle.js:9702:18)
    at Object.invokeGuardedCallbackDev (http://localhost:3004/static/js/bundle.js:9746:20)
    at invokeGuardedCallback (http://localhost:3004/static/js/bundle.js:9801:35)
    at beginWork$1 (http://localhost:3004/static/js/bundle.js:26792:11)
    at performUnitOfWork (http://localhost:3004/static/js/bundle.js:25803:16)
    at workLoopSync (http://localhost:3004/static/js/bundle.js:25748:9)
    at renderRootSync (http://localhost:3004/static/js/bundle.js:25718:11)
    at performSyncWorkOnRoot (http://localhost:3004/static/js/bundle.js:25388:22)
    at http://localhost:3004/static/js/bundle.js:16082:30
    at unstable_runWithPriority (http://localhost:3004/static/js/bundle.js:33626:16)
    at runWithPriority$1 (http://localhost:3004/static/js/bundle.js:16036:14)
    at flushSyncCallbackQueueImpl (http://localhost:3004/static/js/bundle.js:16078:13)
    at flushSyncCallbackQueue (http://localhost:3004/static/js/bundle.js:16067:7)
    at scheduleUpdateOnFiber (http://localhost:3004/static/js/bundle.js:25039:13)
```",heypoom,2024-07-17 12:35:17+00:00,[],2024-10-08 16:19:54+00:00,2024-07-24 10:25:23+00:00,https://github.com/metabase/metabase/issues/45713,"[('Type:Bug', 'Product defects'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2413390351,issue,closed,not_planned,Pivot table is hiding information,"### Describe the bug

When I create a pivot table without filtering and summarized by value divided into 4 fields, the last level only shows 1 record. When filtering by customer, all the correct records appear
![print-pivot-table-with-filter](https://github.com/user-attachments/assets/26f5f2cf-345d-49e5-b09e-a9deea555f61)
![print-pivot-table-without-filter](https://github.com/user-attachments/assets/1ae124c5-1edc-4da7-bb57-5c4c8317569a)
![Print-editor](https://github.com/user-attachments/assets/28460d5b-32db-4e9b-b447-6a924bb8cf29)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

All records appear when I don't choose any filter.
![print-pivot-table-with-filter](https://github.com/user-attachments/assets/537ea80d-d20c-4838-9448-6f7b5e91660f)


### Logs

[9e860b23-866c-42a4-b8e8-97dc31f64e02] 2024-07-17T08:21:58-03:00 INFO metabase.core 
Metabase v0.50.13 (2086968) 

Copyright © 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
[9e860b23-866c-42a4-b8e8-97dc31f64e02] 2024-07-17T08:21:58-03:00 INFO metabase.core Starting Metabase in STANDALONE mode
[9e860b23-866c-42a4-b8e8-97dc31f64e02] 2024-07-17T08:21:58-03:00 INFO metabase.server Launching Embedded Jetty Webserver with config:
 {:port 3000}

[log.txt](https://github.com/user-attachments/files/16264907/log.txt)


### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9-post-Ubuntu-1ubuntu120.04.2"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9-post-Ubuntu-1ubuntu120.04.2"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-187-generic"",
    ""user.language"": ""pt"",
    ""user.timezone"": ""America/Sao_Paulo""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v0.50.13"",
      ""hash"": ""2086968""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

is hiding information

### Additional context

_No response_",kennyrogerson,2024-07-17 11:42:55+00:00,[],2024-08-30 20:38:51+00:00,2024-08-30 20:38:50+00:00,https://github.com/metabase/metabase/issues/45708,"[('Type:Bug', 'Product defects'), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/Querying', ''), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2233356138, 'issue_id': 2413390351, 'author': 'bshepherdson', 'body': ""I think the screenshots are in a different order than intended? It makes this report hard to follow.\r\n\r\nIt's not clear what you expected to see, and what you're seeing instead."", 'created_at': datetime.datetime(2024, 7, 17, 13, 40, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2322304103, 'issue_id': 2413390351, 'author': 'paoliniluis', 'body': 'closing due to non response', 'created_at': datetime.datetime(2024, 8, 30, 20, 38, 50, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-17 13:40:18 UTC): I think the screenshots are in a different order than intended? It makes this report hard to follow.

It's not clear what you expected to see, and what you're seeing instead.

paoliniluis on (2024-08-30 20:38:50 UTC): closing due to non response

"
2413284833,issue,open,,The discard-setting-changes test helper is broken for settings that use init,"### Description

Consider the following setting, where `sql-parsing-enabled` is some other, deprecated setting, which defaults to `true`.

```clojure
(defsetting query-analysis-native-disabled
  (deferred-tru ""Whether we should disable analysis of all native queries"")
  :visibility :internal
  :export?    false
  :init       (comp not sql-parsing-enabled)
  :type       :boolean)
```

Normally evaluating this setting for the first time will return `false`, but things go horribly wrong in tests:

```clojure
(mt/with-discard-setting-changes [sql-parsing-enabled query-analysis-native-disabled]
  (query-analysis-native-disabled)) ;; => nil
```

To make matters worse, this value will now be saved in the case for this setting, so even calling it outside of the macro will yield an incorrect answer.",crisptrutski,2024-07-17 10:51:43+00:00,[],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/45707,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.CI & Tests', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Team/Workflows', 'aka BEC'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]","[{'comment_id': 2311511586, 'issue_id': 2413284833, 'author': 'AnshMishra2001', 'body': 'Hey @crisptrutski can I work on this issue ?', 'created_at': datetime.datetime(2024, 8, 27, 3, 45, 33, tzinfo=datetime.timezone.utc)}]","AnshMishra2001 on (2024-08-27 03:45:33 UTC): Hey @crisptrutski can I work on this issue ?

"
2412904968,issue,closed,not_planned,Can not reset user's password,"**Describe the bug**
A clear and concise description of what the bug is.

Hello, I am Florian from Glinko. I apologize in advance I don't know how to send you the logs. I am a simple user administrator on Metabase. 
I have a user who has been unable to log in since last night. I tried to reset his password from the administration console. The button is present but there is no action when the button is clicked. My user can't reset it either. 

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.7+10"",
    ""java.vendor"": ""AdoptOpenJDK"",
    ""java.vendor.url"": ""https://adoptopenjdk.net/"",
    ""java.version"": ""11.0.7"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.7+10"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-20-cloud-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""1.4.197 (2018-03-18)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""1.4.197 (2018-03-18)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2020-12-03"",
      ""tag"": ""v0.37.3"",
      ""branch"": ""release-x.37.x"",
      ""hash"": ""2f1e783""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",FlorianGlinko,2024-07-17 07:43:53+00:00,[],2024-07-17 15:40:34+00:00,2024-07-17 15:01:56+00:00,https://github.com/metabase/metabase/issues/45704,"[('Type:Bug', 'Product defects'), ('Type:Question', 'Please use the forum: https://discourse.metabase.com/'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2233340445, 'issue_id': 2412904968, 'author': 'bshepherdson', 'body': ""@FlorianGlinko ~~You can hit Ctrl+F1 (Cmd+F1 on Mac) in Metabase to capture a bug report. That will include both server and client logs.~~\r\n\r\nI didn't see that you were running a very old version of Metabase (0.37.3, released 3.5 years ago). It doesn't have the bug report functionality I mentioned above. I don't know how much we can help with a version that old."", 'created_at': datetime.datetime(2024, 7, 17, 13, 33, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233521169, 'issue_id': 2412904968, 'author': 'FlorianGlinko', 'body': 'I took a screen video shot and I am limited less than 10MB. So I give a wetransfer link with it. \r\nAs you could see in this video, when I am clicking on the reset button nothing happen.', 'created_at': datetime.datetime(2024, 7, 17, 14, 52, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233541656, 'issue_id': 2412904968, 'author': 'luizarakaki', 'body': ""Please upgrade to v49. We don't support releases this old."", 'created_at': datetime.datetime(2024, 7, 17, 15, 1, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233549380, 'issue_id': 2412904968, 'author': 'FlorianGlinko', 'body': 'Ok, thank you for your time. Metabase is connected with our production tool, I am afraid to break some components.', 'created_at': datetime.datetime(2024, 7, 17, 15, 5, 23, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-17 13:33:43 UTC): @FlorianGlinko ~~You can hit Ctrl+F1 (Cmd+F1 on Mac) in Metabase to capture a bug report. That will include both server and client logs.~~

I didn't see that you were running a very old version of Metabase (0.37.3, released 3.5 years ago). It doesn't have the bug report functionality I mentioned above. I don't know how much we can help with a version that old.

FlorianGlinko (Issue Creator) on (2024-07-17 14:52:32 UTC): I took a screen video shot and I am limited less than 10MB. So I give a wetransfer link with it. 
As you could see in this video, when I am clicking on the reset button nothing happen.

luizarakaki on (2024-07-17 15:01:56 UTC): Please upgrade to v49. We don't support releases this old.

FlorianGlinko (Issue Creator) on (2024-07-17 15:05:23 UTC): Ok, thank you for your time. Metabase is connected with our production tool, I am afraid to break some components.

"
2412854186,issue,closed,completed,Search not working in aggregations picker,"### Describe the bug

![image](https://github.com/user-attachments/assets/dd573c63-0c8c-4bb4-a78c-58d8d6c97ce0)


### To Reproduce

1. Go to stats
2. New > Question
3. Search for a model called ""Pull Request Review"" and use it
4. Add a Count aggregation (notice that there is no search in the popover)
5. Try to add another aggregation

This time search is shown in the popover.
If you try to use it, all options disappear (except ""Custom Expression"")


### Expected behavior

Search should not be available


### Information about your Metabase installation

stats @ 8aeebaa


### Severity

P3/P2

### Additional context

I was not able to reproduce it locally",kamilmielnik,2024-07-17 07:17:27+00:00,['romeovs'],2024-08-23 14:20:48+00:00,2024-08-23 14:20:48+00:00,https://github.com/metabase/metabase/issues/45702,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2302522920, 'issue_id': 2412854186, 'author': 'romeovs', 'body': 'This will be fixed by https://github.com/metabase/metabase/pull/46887', 'created_at': datetime.datetime(2024, 8, 21, 16, 39, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307197818, 'issue_id': 2412854186, 'author': 'romeovs', 'body': ""We've fixed this in #46887 by making the Basic Metrics available to the search bar."", 'created_at': datetime.datetime(2024, 8, 23, 14, 20, 48, tzinfo=datetime.timezone.utc)}]","romeovs (Assginee) on (2024-08-21 16:39:06 UTC): This will be fixed by https://github.com/metabase/metabase/pull/46887

romeovs (Assginee) on (2024-08-23 14:20:48 UTC): We've fixed this in #46887 by making the Basic Metrics available to the search bar.

"
2412853561,issue,closed,completed,Migrations fails during upgrade from 049.8 to 0.50.13,"### Describe the bug

Upgrade Metabase from 049.8  to 0.50.13 got the following error.

```
2024-07-17 06:29:16,168 INFO db.liquibase :: Running 55 migrations ...
2024-07-17 06:39:18,093 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-02-26T22:15:54::noahmoss encountered an exception.
liquibase.exception.DatabaseException: An I/O error occurred while sending to the backend. [Failed SQL: (0) -- Insert table-level view-data permissions when necessary: when a group has
-- table-level data-access permissions, and some of the `no-self-service` rows
-- cannot be automatically migrated to `unrestricted` due to conflicts with
-- other groups
INSERT INTO
  data_permissions (
    group_id,
    perm_type,
    db_id,
    schema_name,
    table_id,
    perm_value
  )
SELECT
  dp.group_id,
  'perms/view-data' AS perm_type,
  dp.db_id,
  dp.schema_name,
  dp.table_id,
  CASE
    WHEN dp.perm_value = 'no-self-service'
    AND EXISTS (
      SELECT
        1
      FROM
        permissions_group_membership pgm
        JOIN (
          SELECT
            group_id,
            db_id,
            CAST(NULL AS INTEGER) AS table_id
          FROM
            connection_impersonations
          UNION
          SELECT
            group_id,
            db_id,
            CAST(NULL AS INTEGER) AS table_id
          FROM
            data_permissions
          WHERE
            perm_value = 'block'
            AND table_id IS NULL
          UNION
          SELECT
            group_id,
            CAST(NULL AS INTEGER) as db_id,
            table_id
          FROM
            sandboxes
        ) AS sp ON pgm.group_id = sp.group_id
      WHERE
        pgm.group_id <> dp.group_id
        AND (
          sp.db_id IS NULL
          OR sp.db_id = dp.db_id
        )
        AND (
          sp.table_id IS NULL
          OR sp.table_id = dp.table_id
        )
    ) THEN 'legacy-no-self-service'
    ELSE 'unrestricted'
  END AS perm_value
FROM
  data_permissions dp
WHERE
  dp.perm_type = 'perms/data-access'
  AND dp.table_id IS NOT NULL]
        at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
        at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
        at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
        at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
        at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
        at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
        at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
        at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
        at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.Scope.child(Scope.java:252)
        at liquibase.Scope.child(Scope.java:256)
        at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
        at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
        at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
        at liquibase.command.CommandScope.execute(CommandScope.java:217)
        at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.Liquibase.runInScope(Liquibase.java:1419)
        at liquibase.Liquibase.update(Liquibase.java:234)
        at liquibase.Liquibase.update(Liquibase.java:212)
        at liquibase.Liquibase.update(Liquibase.java:194)
        at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44519.invoke(liquibase.clj:360)
        at metabase.db.liquibase$run_in_scope_locked$reify__44515.run(liquibase.clj:325)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
        at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
        at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
        at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
        at metabase.db.setup$migrate_BANG_$fn__53455.invoke(setup.clj:84)
        at metabase.db.liquibase$do_with_liquibase$f_STAR___44456.invoke(liquibase.clj:140)
        at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
        at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
        at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
        at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
        at clojure.lang.RestFn.invoke(RestFn.java:425)
        at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
        at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
        at metabase.db.setup$setup_db_BANG_$fn__53483$fn__53484.invoke(setup.clj:167)
        at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
        at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
        at metabase.db.setup$setup_db_BANG_$fn__53483.invoke(setup.clj:161)
        at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
        at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
        at metabase.db$setup_db_BANG_$fn__53508.invoke(db.clj:86)
        at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
        at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
        at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
        at metabase.core$init_BANG_.invokeStatic(core.clj:170)
        at metabase.core$init_BANG_.invoke(core.clj:165)
        at metabase.core$start_normally.invokeStatic(core.clj:182)
        at metabase.core$start_normally.invoke(core.clj:176)
        at metabase.core$entrypoint.invokeStatic(core.clj:215)
        at metabase.core$entrypoint.doInvoke(core.clj:209)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at clojure.lang.AFn.applyToHelper(AFn.java:152)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at metabase.bootstrap.main(Unknown Source)
Caused by: org.postgresql.util.PSQLException: An I/O error occurred while sending to the backend.
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:398)
        at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419)
        at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:341)
        at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:326)
        at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:302)
        at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:297)
        at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
        at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
        ... 86 more
Caused by: java.io.EOFException
        at org.postgresql.core.PGStream.receiveChar(PGStream.java:469)
        at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2166)
        at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371)
        ... 94 more

UPDATE SUMMARY
Run:                         55
Previously run:             295
Filtered out:                50
-------------------------------
Total change sets:          400


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:               50

```

The `ERROR liquibase.changelog` error happened after 10 min migration stared. Probably timeout?

### To Reproduce

Change image in docker run command.

### Expected behavior

Migrations successfully finished

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase in docker on a VM
- Database Postgres 16.1 AWS RDS
```


### Severity

-

### Additional context

_No response_",vterdunov,2024-07-17 07:17:05+00:00,['noahmoss'],2024-07-19 19:43:49+00:00,2024-07-19 14:33:28+00:00,https://github.com/metabase/metabase/issues/45701,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2233336539, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': ""@vterdunov What's the size of your instance? Do you have a particularly large number of users, groups, DBs, or tables connected?"", 'created_at': datetime.datetime(2024, 7, 17, 13, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233372179, 'issue_id': 2412853561, 'author': 'vterdunov', 'body': '@noahmoss Hi I guess a small instance\r\nVM -  2cpu 4GB Ram\r\nAWS RDS Aurora Postgres 16.1 db.t4g.medium (4 vCPU 8GB RAM)\r\n~73 users and 24 groups\r\n35 Databases connected', 'created_at': datetime.datetime(2024, 7, 17, 13, 47, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233589207, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': ""@vterdunov Thanks. I'm trying to replicate...do you have an estimate of how many tables you have total in the DBs? You can run `select count(*) from metabase_database;` on your app DB to get an exact count, if you have access to it."", 'created_at': datetime.datetime(2024, 7, 17, 15, 23, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233620409, 'issue_id': 2412853561, 'author': 'vterdunov', 'body': '@noahmoss \r\n```\r\nselect count(*) from metabase_database;\r\n```\r\n35', 'created_at': datetime.datetime(2024, 7, 17, 15, 38, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233623526, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': '@vterdunov Sorry, I mistyped. `select count(*) from metabase_table;` will return the total table count.', 'created_at': datetime.datetime(2024, 7, 17, 15, 40, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233626944, 'issue_id': 2412853561, 'author': 'vterdunov', 'body': ""@noahmoss 17424\r\n\r\nI guess can try another migration attempt if it's possible to increase the timeout. Probably for some reason VM or Postgres was on some load."", 'created_at': datetime.datetime(2024, 7, 17, 15, 41, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233730754, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': ""@vterdunov Can you give me a sense of what your permissions configuration looks like? I'm trying to replicate with a similar number of DBs & tables but I'm not seeing it timeout."", 'created_at': datetime.datetime(2024, 7, 17, 16, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233777301, 'issue_id': 2412853561, 'author': 'vterdunov', 'body': '@noahmoss could you please clarify what kind of permissions do you mean? in terms of Postgres user?', 'created_at': datetime.datetime(2024, 7, 17, 17, 1, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233816513, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': '@vterdunov No, your permissions configuration in Metabase. Assuming you\'re logged in as an admin, it\'s at `<site-url>/admin/permissions/data`\r\n\r\nIs the ""Create queries"" permission set to the a single value for each DB in each group? Is it set to different values for different tables? Or a combination of both? Whatever details you could provide would be useful. It\'s possible that this migration has a hot spot that\'s triggered under specific circumstances but I haven\'t determined what those are yet.', 'created_at': datetime.datetime(2024, 7, 17, 17, 20, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233882156, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': 'Actually, think I might have just reproduced it.', 'created_at': datetime.datetime(2024, 7, 17, 17, 52, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236319132, 'issue_id': 2412853561, 'author': 'ilmarivikstrom', 'body': 'Suffering from the same exact problem.', 'created_at': datetime.datetime(2024, 7, 18, 11, 59, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236437490, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': ""I believe there's a hot spot in the migration under specific circumstances (many tables with permissions set granularly) which can be mitigated with specific indexes. I have a fix which will be out in Metabase 50.14. \r\n\r\nIf you want, you can apply these indexes manually and see if that fixes the timeouts:\r\n```\r\nCREATE INDEX idx_data_permissions_group_id_db_id_perm_value ON data_permissions(group_id, db_id, perm_value);\r\nCREATE INDEX idx_data_permissions_group_id_db_id_table_id_perm_value ON data_permissions(group_id, db_id, table_id, perm_value);\r\n```\r\n\r\nIf you try this, please let me know if you still see issues."", 'created_at': datetime.datetime(2024, 7, 18, 13, 0, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236771315, 'issue_id': 2412853561, 'author': 'vdubovets', 'body': 'We had the same issue -> https://github.com/metabase/metabase/issues/45801', 'created_at': datetime.datetime(2024, 7, 18, 14, 48, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236816561, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': '@vdubovets @ilmarivikstrom How many tables are on your instances? You can run `select count(*) from metabase_table;` to fetch the total count.', 'created_at': datetime.datetime(2024, 7, 18, 15, 7, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2236868850, 'issue_id': 2412853561, 'author': 'vdubovets', 'body': '@noahmoss The table count is `77 247`', 'created_at': datetime.datetime(2024, 7, 18, 15, 30, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2239897899, 'issue_id': 2412853561, 'author': 'GabrielBourget52', 'body': 'I got a similar problem with my local setop, form 0.49 to 0.50.\r\nI have 1 database\r\n\r\n2024-07-19 14:39:04 liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:29::noahmoss:\r\n2024-07-19 14:39:04      Reason: liquibase.exception.DatabaseException: ERROR: constraint ""fk_sandboxes_ref_permissions"" of relation ""sandboxes"" does not exist [Failed SQL: (0) ALTER TABLE ""public"".""sandboxes"" DROP CONSTRAINT ""fk_sandboxes_ref_permissions""]', 'created_at': datetime.datetime(2024, 7, 19, 18, 40, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2240010169, 'issue_id': 2412853561, 'author': 'noahmoss', 'body': ""@GabrielBourget52 That's a separate issue which has already been fixed. Please upgrade to 0.50.13 instead of 0.50.0"", 'created_at': datetime.datetime(2024, 7, 19, 19, 43, 48, tzinfo=datetime.timezone.utc)}]","noahmoss (Assginee) on (2024-07-17 13:32:00 UTC): @vterdunov What's the size of your instance? Do you have a particularly large number of users, groups, DBs, or tables connected?

vterdunov (Issue Creator) on (2024-07-17 13:47:25 UTC): @noahmoss Hi I guess a small instance
VM -  2cpu 4GB Ram
AWS RDS Aurora Postgres 16.1 db.t4g.medium (4 vCPU 8GB RAM)
~73 users and 24 groups
35 Databases connected

noahmoss (Assginee) on (2024-07-17 15:23:49 UTC): @vterdunov Thanks. I'm trying to replicate...do you have an estimate of how many tables you have total in the DBs? You can run `select count(*) from metabase_database;` on your app DB to get an exact count, if you have access to it.

vterdunov (Issue Creator) on (2024-07-17 15:38:45 UTC): @noahmoss 
```
select count(*) from metabase_database;
```
35

noahmoss (Assginee) on (2024-07-17 15:40:17 UTC): @vterdunov Sorry, I mistyped. `select count(*) from metabase_table;` will return the total table count.

vterdunov (Issue Creator) on (2024-07-17 15:41:59 UTC): @noahmoss 17424

I guess can try another migration attempt if it's possible to increase the timeout. Probably for some reason VM or Postgres was on some load.

noahmoss (Assginee) on (2024-07-17 16:34:35 UTC): @vterdunov Can you give me a sense of what your permissions configuration looks like? I'm trying to replicate with a similar number of DBs & tables but I'm not seeing it timeout.

vterdunov (Issue Creator) on (2024-07-17 17:01:28 UTC): @noahmoss could you please clarify what kind of permissions do you mean? in terms of Postgres user?

noahmoss (Assginee) on (2024-07-17 17:20:01 UTC): @vterdunov No, your permissions configuration in Metabase. Assuming you're logged in as an admin, it's at `<site-url>/admin/permissions/data`

Is the ""Create queries"" permission set to the a single value for each DB in each group? Is it set to different values for different tables? Or a combination of both? Whatever details you could provide would be useful. It's possible that this migration has a hot spot that's triggered under specific circumstances but I haven't determined what those are yet.

noahmoss (Assginee) on (2024-07-17 17:52:10 UTC): Actually, think I might have just reproduced it.

ilmarivikstrom on (2024-07-18 11:59:05 UTC): Suffering from the same exact problem.

noahmoss (Assginee) on (2024-07-18 13:00:59 UTC): I believe there's a hot spot in the migration under specific circumstances (many tables with permissions set granularly) which can be mitigated with specific indexes. I have a fix which will be out in Metabase 50.14. 

If you want, you can apply these indexes manually and see if that fixes the timeouts:
```
CREATE INDEX idx_data_permissions_group_id_db_id_perm_value ON data_permissions(group_id, db_id, perm_value);
CREATE INDEX idx_data_permissions_group_id_db_id_table_id_perm_value ON data_permissions(group_id, db_id, table_id, perm_value);
```

If you try this, please let me know if you still see issues.

vdubovets on (2024-07-18 14:48:10 UTC): We had the same issue -> https://github.com/metabase/metabase/issues/45801

noahmoss (Assginee) on (2024-07-18 15:07:17 UTC): @vdubovets @ilmarivikstrom How many tables are on your instances? You can run `select count(*) from metabase_table;` to fetch the total count.

vdubovets on (2024-07-18 15:30:42 UTC): @noahmoss The table count is `77 247`

GabrielBourget52 on (2024-07-19 18:40:20 UTC): I got a similar problem with my local setop, form 0.49 to 0.50.
I have 1 database

2024-07-19 14:39:04 liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-01-10T03:27:29::noahmoss:
2024-07-19 14:39:04      Reason: liquibase.exception.DatabaseException: ERROR: constraint ""fk_sandboxes_ref_permissions"" of relation ""sandboxes"" does not exist [Failed SQL: (0) ALTER TABLE ""public"".""sandboxes"" DROP CONSTRAINT ""fk_sandboxes_ref_permissions""]

noahmoss (Assginee) on (2024-07-19 19:43:48 UTC): @GabrielBourget52 That's a separate issue which has already been fixed. Please upgrade to 0.50.13 instead of 0.50.0

"
2412842874,issue,open,,deduplicate dependencies,use `yarn-deduplicate` to drop duplicated dependencies from lockfile,uladzimirdev,2024-07-17 07:11:27+00:00,[],2024-07-30 13:59:59+00:00,,https://github.com/metabase/metabase/issues/45700,[],"[{'comment_id': 2258425434, 'issue_id': 2412842874, 'author': 'uladzimirdev', 'body': 'partially addressed https://github.com/metabase/metabase/pull/45923', 'created_at': datetime.datetime(2024, 7, 30, 13, 59, 57, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Issue Creator) on (2024-07-30 13:59:57 UTC): partially addressed https://github.com/metabase/metabase/pull/45923

"
2412838958,issue,open,,move storybook to optional dependencies,and update all installation scripts to use `yarn --ignore-optional` except the storybook build itself,uladzimirdev,2024-07-17 07:09:31+00:00,[],2024-07-17 07:10:39+00:00,,https://github.com/metabase/metabase/issues/45699,[],[],
2412819339,issue,closed,completed,Get rid of style-src errors,"related discussions 

[slack](https://metaboat.slack.com/archives/C052LBPDAF3/p1723042282948509)
https://github.com/orgs/mantinedev/discussions/6546#discussioncomment-10264958

possibly related issues
https://github.com/emotion-js/emotion/issues/3169
https://github.com/mantinedev/mantine/issues/3705
https://github.com/igorovic/mantine-prepend-issue

TL;DR emotion uses correct cache, but mantine creates its own cache with a key ""mantine"" and doesn't apply `nonce` for those style tags

we have such logs locally
![Untitled](https://github.com/user-attachments/assets/b3f09a1f-766e-407a-a7d0-acbd73aaa77f)
",uladzimirdev,2024-07-17 06:59:05+00:00,['uladzimirdev'],2024-10-08 16:18:10+00:00,2024-08-09 13:14:50+00:00,https://github.com/metabase/metabase/issues/45698,[],[],
2412143514,issue,closed,completed,Column names with special characters are created with encoded characters,"### Describe the bug

I don't know why it happens with only this file and not if I generate a new one

### To Reproduce

1) just import this as a CSV
[colegios_alumnos_activos.csv](https://github.com/user-attachments/files/16257255/colegios_alumnos_activos.csv)


### Expected behavior

we should not create columns with special characters

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-07-16 22:27:31+00:00,['crisptrutski'],2024-12-24 11:37:52+00:00,2024-09-06 15:38:46+00:00,https://github.com/metabase/metabase/issues/45689,"[('Type:Bug', 'Product defects'), ('.Backend', ''), ('.Needs Triage', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2233309497, 'issue_id': 2412143514, 'author': 'bshepherdson', 'body': ""This file is not encoded in UTF-8, and I suspect that's why it's getting mangled.\r\n\r\n`Dirección` is encoded as (hex) `44 69 72 65 63 63 69 f3 6e`. The trouble is that the `ó` is encoded as `0xf3`, which is correct **extended ASCII** (ISO 8859-1, aka Latin-1). But I suspect we're trying to ingest it as UTF-8, which would fail to decode correctly.\r\n\r\n`f3` (`1111 0011`) looks like the start of a 4-byte character (U+010000 to U+10FFFF), beginning with `0 11__ ____ ____ ____`.\r\nThe three further bytes should all start with `10__ ____`, but they don't - the next byte is `n = 6e = 0110 1110`.\r\n\r\nThe correct UTF-8 encoding would use a 2-byte form (`110a aabb 10bb cccc`): `ó = U+00F3 = 1100 0011 1011 0011 = c3 b3`."", 'created_at': datetime.datetime(2024, 7, 17, 13, 20, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233325531, 'issue_id': 2412143514, 'author': 'bshepherdson', 'body': ""@paoliniluis I'm not sure what the Right Thing for Metabase to do here is. Do we document the input formats we expect? Should we be rejecting encodings we can't understand with an error message?"", 'created_at': datetime.datetime(2024, 7, 17, 13, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2334339084, 'issue_id': 2412143514, 'author': 'paoliniluis', 'body': 'the issue here is that we end up trying to insert encoded characters... there has to be a way in which we can enforce utf-8', 'created_at': datetime.datetime(2024, 9, 6, 15, 42, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339894753, 'issue_id': 2412143514, 'author': 'crisptrutski', 'body': ""We are inserting valid utf-8, the problem is on the read side. This file is in `ISO-8859-1`, which hopefully we can detect with the same library that we're using to detect the mime-type. Should be an easy enough fix, will look at this today."", 'created_at': datetime.datetime(2024, 9, 10, 7, 35, 42, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-17 13:20:13 UTC): This file is not encoded in UTF-8, and I suspect that's why it's getting mangled.

`Dirección` is encoded as (hex) `44 69 72 65 63 63 69 f3 6e`. The trouble is that the `ó` is encoded as `0xf3`, which is correct **extended ASCII** (ISO 8859-1, aka Latin-1). But I suspect we're trying to ingest it as UTF-8, which would fail to decode correctly.

`f3` (`1111 0011`) looks like the start of a 4-byte character (U+010000 to U+10FFFF), beginning with `0 11__ ____ ____ ____`.
The three further bytes should all start with `10__ ____`, but they don't - the next byte is `n = 6e = 0110 1110`.

The correct UTF-8 encoding would use a 2-byte form (`110a aabb 10bb cccc`): `ó = U+00F3 = 1100 0011 1011 0011 = c3 b3`.

bshepherdson on (2024-07-17 13:27:00 UTC): @paoliniluis I'm not sure what the Right Thing for Metabase to do here is. Do we document the input formats we expect? Should we be rejecting encodings we can't understand with an error message?

paoliniluis (Issue Creator) on (2024-09-06 15:42:34 UTC): the issue here is that we end up trying to insert encoded characters... there has to be a way in which we can enforce utf-8

crisptrutski (Assginee) on (2024-09-10 07:35:42 UTC): We are inserting valid utf-8, the problem is on the read side. This file is in `ISO-8859-1`, which hopefully we can detect with the same library that we're using to detect the mime-type. Should be an easy enough fix, will look at this today.

"
2412113767,issue,closed,completed,display warning when measure column has negative values,https://metaboat.slack.com/archives/C07CHBT2T16/p1720624615859139,EmmadUsmani,2024-07-16 22:01:16+00:00,['EmmadUsmani'],2024-07-17 22:05:26+00:00,2024-07-17 22:05:26+00:00,https://github.com/metabase/metabase/issues/45687,[],"[{'comment_id': 2234422822, 'issue_id': 2412113767, 'author': 'EmmadUsmani', 'body': 'Implemented in https://github.com/metabase/metabase/pull/43555/commits/cb9a793dff1828abbeddf81482160ad8fe4ad7fe', 'created_at': datetime.datetime(2024, 7, 17, 22, 5, 26, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-07-17 22:05:26 UTC): Implemented in https://github.com/metabase/metabase/pull/43555/commits/cb9a793dff1828abbeddf81482160ad8fe4ad7fe

"
2412110342,issue,closed,completed,hide total text when chart is small,https://metaboat.slack.com/archives/C07CHBT2T16/p1720622808992189,EmmadUsmani,2024-07-16 21:58:10+00:00,['EmmadUsmani'],2024-07-16 22:06:41+00:00,2024-07-16 22:06:40+00:00,https://github.com/metabase/metabase/issues/45686,[],"[{'comment_id': 2231902156, 'issue_id': 2412110342, 'author': 'EmmadUsmani', 'body': 'Fixed in https://github.com/metabase/metabase/pull/43555/commits/d75c8039696a7cdc9c7422eb7628d08abaed9c56', 'created_at': datetime.datetime(2024, 7, 16, 22, 6, 40, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-07-16 22:06:40 UTC): Fixed in https://github.com/metabase/metabase/pull/43555/commits/d75c8039696a7cdc9c7422eb7628d08abaed9c56

"
2412080667,issue,open,,X-rays containing duplicate columns don't work when added to dashboard,"### Describe the bug

new query: orders join with people join with orders (again)
save it as a model
do an x-ray of this

### To Reproduce

new query: orders join with people join with orders (again)
save it as a model
do an x-ray of this

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
stats
Built on 2024-07-16
Hash: dcfdbec
```


### Severity

P2

### Additional context

_No response_",perivamsi,2024-07-16 21:34:34+00:00,[],2025-02-04 20:28:41+00:00,,https://github.com/metabase/metabase/issues/45685,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/X-rays', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2231868174, 'issue_id': 2412080667, 'author': 'perivamsi', 'body': 'This seems to be working https://stats.metabase.com/dashboard/2525-a-look-at-repro-for-45685-orders-people-orders', 'created_at': datetime.datetime(2024, 7, 16, 21, 37, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231869111, 'issue_id': 2412080667, 'author': 'perivamsi', 'body': '@paoliniluis what do you think?', 'created_at': datetime.datetime(2024, 7, 16, 21, 38, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231914005, 'issue_id': 2412080667, 'author': 'paoliniluis', 'body': 'works for me, I tried both in v50 and in stats\r\n![image](https://github.com/user-attachments/assets/be54d825-a779-4a46-80c6-f89e7c513fe3)', 'created_at': datetime.datetime(2024, 7, 16, 22, 17, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231926825, 'issue_id': 2412080667, 'author': 'metamben', 'body': 'When I tried to reproduce the issue, I got some cards cards working (as in the picture you attached), but a bunch of others were displaying ""Which fields do you want to use for the X and Y axes?"".', 'created_at': datetime.datetime(2024, 7, 16, 22, 30, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233260845, 'issue_id': 2412080667, 'author': 'bshepherdson', 'body': 'I renamed this bug since the original name omitted a key factor that the base model includes a self join.\r\n\r\nI think the place to start here is in the X-ray logic. When we have a self join, are the X-ray tables generated properly? Perhaps they return ambiguous field refs, or key on `:id`, or a similar pitfall of duplicated columns.', 'created_at': datetime.datetime(2024, 7, 17, 12, 57, 15, tzinfo=datetime.timezone.utc)}]","perivamsi (Issue Creator) on (2024-07-16 21:37:17 UTC): This seems to be working https://stats.metabase.com/dashboard/2525-a-look-at-repro-for-45685-orders-people-orders

perivamsi (Issue Creator) on (2024-07-16 21:38:04 UTC): @paoliniluis what do you think?

paoliniluis on (2024-07-16 22:17:40 UTC): works for me, I tried both in v50 and in stats
![image](https://github.com/user-attachments/assets/be54d825-a779-4a46-80c6-f89e7c513fe3)

metamben on (2024-07-16 22:30:40 UTC): When I tried to reproduce the issue, I got some cards cards working (as in the picture you attached), but a bunch of others were displaying ""Which fields do you want to use for the X and Y axes?"".

bshepherdson on (2024-07-17 12:57:15 UTC): I renamed this bug since the original name omitted a key factor that the base model includes a self join.

I think the place to start here is in the X-ray logic. When we have a self join, are the X-ray tables generated properly? Perhaps they return ambiguous field refs, or key on `:id`, or a similar pitfall of duplicated columns.

"
2412030605,issue,open,,Incorrect suggestions in the SQL editor for multi-schema databases,"### Describe the bug

If you have a database with multiple schemas they are not suggested when you start typing their names in the SQL editor. At the same time table names are suggested from all the schemas even if you have chosen the specific schema already.

### To Reproduce

1. Connect a database with multiple schemas
2. Click on + New SQL
3. Write `select * from `
4. Start typing any schema name
5. There is no relevant suggestion in the list
6. Finish typing the schema name like `select * from public.`
7. Start typing and table name
8. You will get suggestions from all the schemas


### Expected behavior

Fetch schema names in the suggestions.
Fetch only relevant table names in the suggestions when the schema is chosen.

### Logs

_No response_

### Information about your Metabase installation

```JSON
06d1ba2ae111e66253209c01c244d6379acfc6dcb1911fa9ab6012cec9ce52e5
```


### Severity

Annoying

### Additional context

_No response_",mngr,2024-07-16 20:56:14+00:00,[],2024-07-16 21:14:57+00:00,,https://github.com/metabase/metabase/issues/45681,"[('Type:New Feature', ''), ('.Team/Querying', '')]",[],
2411967875,issue,closed,completed,"Since Metabase 0.50.13, colors on tables are no longer visible on dashboard subscriptions","### Describe the bug

Before Metabase 0.50.13, we were getting subscriptions like this with conditional formatting appearing in Slack:

![image](https://github.com/user-attachments/assets/bf45dc72-de52-4034-a191-9db9f696e45e)

We upgraded from 0.50.10 to 0.50.13 and now we get no highlighting:
![image](https://github.com/user-attachments/assets/e3eb24bd-d178-40da-bd29-1a8bbc855ddd)

Which is a shame because colors help visually scan tables pretty fast.

The report still has colors in Metabase, but being able to scan it on Slack is very useful.

I see the same behavior on some slack alerts we have set up, so this doesn't seem to be exclusive to dashboard subs.

### To Reproduce

1. Send a subscription with conditional formatting enabled
2. Check that it has no colors on Slack

### Expected behavior

We should be seeing the same colors as we see in Metabase

### Logs

```[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:37-03:00 DEBUG metabase.server.middleware.log GET /api/pulse/form_input 200 11.2 ms (1 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (3 idle, 0 queued) (127 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:37-03:00 DEBUG metabase.server.middleware.log GET /api/user/recipients 200 38.3 ms (2 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (3 idle, 0 queued) (127 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/user/current 200 57.1 ms (10 DB calls) App DB connections: 1/15 Jetty threads: 6/50 (1 idle, 0 queued) (127 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 59.5 ms (12 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (1 idle, 0 queued) (127 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/database 200 18.2 ms (1 DB calls) App DB connections: 1/15 Jetty threads: 9/50 (1 idle, 0 queued) (130 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 40.2 ms (12 DB calls) App DB connections: 1/15 Jetty threads: 8/50 (1 idle, 0 queued) (130 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/setting 200 59.2 ms (16 DB calls) App DB connections: 1/15 Jetty threads: 8/50 (1 idle, 0 queued) (130 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:52-03:00 DEBUG metabase.server.middleware.log GET /api/search 200 88.5 ms (5 DB calls) App DB connections: 0/15 Jetty threads: 7/50 (2 idle, 0 queued) (130 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 142}
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:53-03:00 INFO metabase.query-processor.middleware.cache Caching results for next time for query with hash ""bd1b1f4a"". 💾
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:53-03:00 INFO metabase.query-processor.middleware.cache Query bd1b1f4a took 9.8 s to run; minimum for cache eligibility is 3.0 s; eligible
[6df9c9db-3639-4f84-b447-0d7c5daeb174] 2024-07-16T17:10:55-03:00 DEBUG metabase.server.middleware.log POST /api/pulse/test 200 12.2 s (46 DB calls) App DB connections: 0/15 Jetty threads: 5/50 (5 idle, 0 queued) (130 total active threads) Queries in flight: 0 (0 queued); snowflake DB 4 connections: 0/1 (0 threads blocked) {:metabase-user-id 142}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.28""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""tag"": ""v0.50.13-logs"",
      ""hash"": ""8b72e50""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```


### Severity

It's an annoying regression of a feature we have been using

### Additional context

_No response_",sicarul,2024-07-16 20:14:06+00:00,['adam-james-v'],2024-07-26 11:09:42+00:00,2024-07-26 02:45:03+00:00,https://github.com/metabase/metabase/issues/45678,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Notifications/Slack', ''), ('.Escalation', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2411936313,issue,closed,completed,Bug: API returns duplicate cards if they have multiple errors,,tsmacdonald,2024-07-16 19:53:38+00:00,[],2024-10-08 16:20:31+00:00,2024-07-17 17:35:52+00:00,https://github.com/metabase/metabase/issues/45673,"[('.Team/Workflows', 'aka BEC')]",[],
2411924236,issue,closed,completed,`regexextract` is not an actual MBQL clause,"There's some super weirdness going on with the `regexextract` and `regex-match-first` MBQL clauses. I don't think `regexextract` is actually a real MBQL clause at all, it's just for whatever weird reason what the frontend expression editor calls `regex-match-first`

```js
  ""regex-match-first"": {
    displayName: `regexextract`,
    type: ""string"",
    args: [""string"", ""string""],
    requiresFeature: ""regex"",
  },
```

Anyways MLv2 defines both, but if you try to create a query with `regexextract` it fails since it's not part of the legacy MBQL schema nad the QP doesn't understand it.

We should remove the helper functions and schema for `regexextract` from MLv2 to avoid confusion.",camsaul,2024-07-16 19:45:29+00:00,['camsaul'],2024-08-28 02:08:59+00:00,2024-07-17 17:02:04+00:00,https://github.com/metabase/metabase/issues/45672,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2411869277,issue,closed,completed,"Dashboard Boolean Filter Values Sent as String On Page Load, Boolean on Filter Value Change","### Describe the bug

In a Dashboard, if you have a Filter connected to a Card with a Boolean Field Filter in its (native) query, when the dashboard first loads, the paramter value is sent as a string eg. ""true"", which causes the query to fail.

If you then change the filter, the value is sent as a boolean `true` or `false`, or `[true, false]` when selecting both. In this case, the query succeeds.

NOTE: this may only apply to Postgres dbs, I haven't double checked that.

Initial dashboard load:
![image](https://github.com/user-attachments/assets/858febcd-a9c7-4106-9f91-cc20e5e14b95)

And after changing the filter's value:
![image](https://github.com/user-attachments/assets/09d111f0-ab1d-4981-aba5-7aa72f503129)


### To Reproduce

1. Set up a field filter on a card, where the field in question is a boolean field.
2. Add this card to a dashboard
3. Create a drop down list filter, link it to the field filter on the card, set default value to true (or false, just set it)
4. Save dashboard, and refresh.

Here is a dashboard on stats with the setup:
https://stats.metabase.com/dashboard/2520-boolean-field-filter-test-dashboard?text=true

### Expected behavior

The query should succeed. As I see it, this means either the frontend should send booleans, not strings OR the backend should permit stringy booleans and work nicely, not sure if that's in endpoints, in QP, or in drivers.

I think that things are a little confusing here because to get the filters, we're using a 'Category' filter type, which is clearly meant to work on lists of string values, not really booleans.

### Logs

The relevant error message from `POST /api/dashboard/:dashboard-id/dashcard/:dashcard-id/card/:card-id/query`:
```
ERROR: operator does not exist: boolean = character varying
  Hint: No operator matches the given name and argument types. You might need to add explicit type casts.
  Position: 197
```

### Information about your Metabase installation

```JSON
- Firefox
- Postgres
- Master: f961d4f
```


### Severity

P2

### Additional context

_No response_",adam-james-v,2024-07-16 19:10:36+00:00,['ranquild'],2024-10-25 18:10:09+00:00,2024-10-24 15:37:18+00:00,https://github.com/metabase/metabase/issues/45670,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Hard', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2304025556, 'issue_id': 2411869277, 'author': 'nemanjaglumac', 'body': 'To be able to reproduce this, both the native question filter and the dashboard filter **must be** required.\r\nIt is also true that it is not reproducible on H2. Use Postgres (data warehouse, not app db) for that.\r\n\r\nRelated #45877\r\nFilter will render the option twice but this time because it stores one option as a string, and the other one as a boolean.\r\n![image](https://github.com/user-attachments/assets/cef372ca-fd45-4cc7-b398-e76b78f69d3a)', 'created_at': datetime.datetime(2024, 8, 22, 7, 58, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307659543, 'issue_id': 2411869277, 'author': 'nemanjaglumac', 'body': 'This is happening only on the first page load (including when we visit the dashboard and set the link directly through URL query params).\r\n\r\nThe problem is that the `dashboard` is still not in the `state` at that point so we have to rely on parsing the URL query parameters. This is why frontend sends the value as a string.\r\n```js\r\nconst parameterValuesById = preserveParameters\r\n  ? getParameterValues(getState())\r\n  : getParameterValuesByIdFromQueryParams(\r\n      result.parameters ?? [], // no fields\r\n      queryParams,\r\n      lastUsedParametersValues,\r\n    );\r\n```\r\nThe logic starts from this ""lovely"" thunk:\r\nhttps://github.com/metabase/metabase/blob/master/frontend/src/metabase/dashboard/actions/data-fetching-typed.ts#L32-L193\r\n\r\nIn order to ""build"" (set) fields, we need to use `getDashboardUiParameters`, and for that we need the dashboard in the state. And we need fields in order for this condition to be met:\r\n```js\r\nconst { fields } = parameter as FieldFilterUiParameter;\r\nif (Array.isArray(fields) && fields.length > 0) {\r\n  return parseParameterValueForFields(coercedValue, fields);\r\n}\r\n```\r\n\r\n`parseParameterValueForFields` is dealing with converting string values to booleans:\r\n```js\r\nif (fields.every(f => f.isBoolean())) {\r\n  return value === ""true"" ? true : value === ""false"" ? false : value;\r\n}\r\n```\r\n\r\nOne potential (hacky) solution that @ranquild proposed is to delay setting the parameters while we dispatch the action to set the dashboard in state.\r\n\r\nFor the posterity, the original Slack discussion is [here](https://metaboat.slack.com/archives/C0645JP1W81/p1724338292252369).', 'created_at': datetime.datetime(2024, 8, 23, 19, 6, 50, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-08-22 07:58:46 UTC): To be able to reproduce this, both the native question filter and the dashboard filter **must be** required.
It is also true that it is not reproducible on H2. Use Postgres (data warehouse, not app db) for that.

Related #45877
Filter will render the option twice but this time because it stores one option as a string, and the other one as a boolean.
![image](https://github.com/user-attachments/assets/cef372ca-fd45-4cc7-b398-e76b78f69d3a)

nemanjaglumac on (2024-08-23 19:06:50 UTC): This is happening only on the first page load (including when we visit the dashboard and set the link directly through URL query params).

The problem is that the `dashboard` is still not in the `state` at that point so we have to rely on parsing the URL query parameters. This is why frontend sends the value as a string.
```js
const parameterValuesById = preserveParameters
  ? getParameterValues(getState())
  : getParameterValuesByIdFromQueryParams(
      result.parameters ?? [], // no fields
      queryParams,
      lastUsedParametersValues,
    );
```
The logic starts from this ""lovely"" thunk:
https://github.com/metabase/metabase/blob/master/frontend/src/metabase/dashboard/actions/data-fetching-typed.ts#L32-L193

In order to ""build"" (set) fields, we need to use `getDashboardUiParameters`, and for that we need the dashboard in the state. And we need fields in order for this condition to be met:
```js
const { fields } = parameter as FieldFilterUiParameter;
if (Array.isArray(fields) && fields.length > 0) {
  return parseParameterValueForFields(coercedValue, fields);
}
```

`parseParameterValueForFields` is dealing with converting string values to booleans:
```js
if (fields.every(f => f.isBoolean())) {
  return value === ""true"" ? true : value === ""false"" ? false : value;
}
```

One potential (hacky) solution that @ranquild proposed is to delay setting the parameters while we dispatch the action to set the dashboard in state.

For the posterity, the original Slack discussion is [here](https://metaboat.slack.com/archives/C0645JP1W81/p1724338292252369).

"
2411578323,issue,open,,Funnel charts for Multi series charts on dashboards disappeared,"### Describe the bug

I upgraded our Metabase from v0.49.11 to v0.50.11, and after the update, some dashboards using the Funnel chart visualisation to display multiple series on the same card are not working anymore. The only possible display is bar chart.

### To Reproduce

1. Create a new dashboard
2. Add a question to the dashboard
3. Add multiple number series to the same question


### Expected behavior

In previous versions, there was an option to display those multiple series as a funnel chart. Simple bar charts are much less useful than funnel charts.
<img width=""1504"" alt=""Screenshot 2024-07-16 at 18 18 25"" src=""https://github.com/user-attachments/assets/5afa3e22-2328-4503-9752-6d89f531dca2"">


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.219-208.866.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""athena"",
      ""redshift"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.8""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-09"",
      ""tag"": ""v0.50.11"",
      ""hash"": ""e08c1fb""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High

### Additional context

_No response_",colax94,2024-07-16 16:21:31+00:00,['alxnddr'],2025-02-04 20:31:20+00:00,,https://github.com/metabase/metabase/issues/45656,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2231345656, 'issue_id': 2411578323, 'author': 'paoliniluis', 'body': ""unless I'm mistaken when you add 2 series to a funnel in a dashboard it will show a bar chart, this has always worked like that"", 'created_at': datetime.datetime(2024, 7, 16, 16, 24, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232441945, 'issue_id': 2411578323, 'author': 'colax94', 'body': 'Yes, but there used to be an option to display those series as a funnel instead of simple bars (in the ""visualization options"" menu of the dashboard card). That option disappeared, that""s why I\'m surprised', 'created_at': datetime.datetime(2024, 7, 17, 5, 22, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402211930, 'issue_id': 2411578323, 'author': 'colax94', 'body': 'Hello ! Any news on this one please ? Thank you !', 'created_at': datetime.datetime(2024, 10, 9, 12, 39, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402387483, 'issue_id': 2411578323, 'author': 'paoliniluis', 'body': ""@colax94, there's an open PR in flight, we're doing a lot of work for v51 and that's why we haven't been able to merge it yet, sorry"", 'created_at': datetime.datetime(2024, 10, 9, 13, 42, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571560896, 'issue_id': 2411578323, 'author': 'colax94', 'body': 'Hi there, is there any plan to merge this please ? Thank you !', 'created_at': datetime.datetime(2025, 1, 5, 9, 27, 45, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-16 16:24:34 UTC): unless I'm mistaken when you add 2 series to a funnel in a dashboard it will show a bar chart, this has always worked like that

colax94 (Issue Creator) on (2024-07-17 05:22:55 UTC): Yes, but there used to be an option to display those series as a funnel instead of simple bars (in the ""visualization options"" menu of the dashboard card). That option disappeared, that""s why I'm surprised

colax94 (Issue Creator) on (2024-10-09 12:39:58 UTC): Hello ! Any news on this one please ? Thank you !

paoliniluis on (2024-10-09 13:42:04 UTC): @colax94, there's an open PR in flight, we're doing a lot of work for v51 and that's why we haven't been able to merge it yet, sorry

colax94 (Issue Creator) on (2025-01-05 09:27:45 UTC): Hi there, is there any plan to merge this please ? Thank you !

"
2411515240,issue,closed,not_planned,Bug: Schedule not working in old Safaris due to usage of regex lookbehind,,rafpaf,2024-07-16 15:46:46+00:00,[],2024-07-16 18:21:15+00:00,2024-07-16 18:21:15+00:00,https://github.com/metabase/metabase/issues/45653,[],"[{'comment_id': 2231534907, 'issue_id': 2411515240, 'author': 'camsaul', 'body': 'duplicate of #45647', 'created_at': datetime.datetime(2024, 7, 16, 18, 21, 15, tzinfo=datetime.timezone.utc)}]","camsaul on (2024-07-16 18:21:15 UTC): duplicate of #45647

"
2411386602,issue,closed,completed,Metabase v0.50.1+ doesn't work on Safari 15.2,"### Describe the bug

Safari refuses to load the app because of an unsupported regex syntax. Works on chrome. No issues with 0.49.20.

### To Reproduce

1. Download `0.50.1` jar
2. Run it
3. Open the app in Safari
4. Open the browser console and see the error

<img width=""1727"" alt=""Screenshot 2024-07-16 at 10 39 34"" src=""https://github.com/user-attachments/assets/898db501-2ced-433b-a3d8-33410ad48386"">

This line causes issues https://github.com/metabase/metabase/blob/08613cb3b64f87eb1260c3a1eb5f918632dff156/frontend/src/metabase/admin/performance/utils.tsx#L128


### Expected behavior

It should work as before.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.50.1
- Safari 15.2
```


### Severity

P1

### Additional context

_No response_",ranquild,2024-07-16 14:59:23+00:00,['bshepherdson'],2024-07-24 17:24:00+00:00,2024-07-24 17:12:22+00:00,https://github.com/metabase/metabase/issues/45647,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Browser:Safari', ''), ('.Frontend', ''), ('Administration/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2234343350, 'issue_id': 2411386602, 'author': 'iethree', 'body': ""there's more than one offending regex here, found another one in our CLJS code\r\n\r\nhttps://github.com/metabase/metabase/blob/0293ce541f905996cbc56ccf1c97e1bed9a808fc/src/metabase/legacy_mbql/util.cljc#L346\r\n\r\n![Screen Shot 2024-07-17 at 3 16 08 PM](https://github.com/user-attachments/assets/22f05a57-b4ed-4338-8aa0-bde1c2c988b3)\r\n\r\n@bshepherdson do you think you can rewrite these regexes to not use lookbehind so that we can support safar < 16.3 ?\r\nhttps://caniuse.com/js-regexp-lookbehind"", 'created_at': datetime.datetime(2024, 7, 17, 21, 23, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248519982, 'issue_id': 2411386602, 'author': 'lbrdnk', 'body': 'Closing as completed; FE and also cljs PRs were merged and backported.', 'created_at': datetime.datetime(2024, 7, 24, 17, 12, 22, tzinfo=datetime.timezone.utc)}]","iethree on (2024-07-17 21:23:28 UTC): there's more than one offending regex here, found another one in our CLJS code

https://github.com/metabase/metabase/blob/0293ce541f905996cbc56ccf1c97e1bed9a808fc/src/metabase/legacy_mbql/util.cljc#L346

![Screen Shot 2024-07-17 at 3 16 08 PM](https://github.com/user-attachments/assets/22f05a57-b4ed-4338-8aa0-bde1c2c988b3)

@bshepherdson do you think you can rewrite these regexes to not use lookbehind so that we can support safar < 16.3 ?
https://caniuse.com/js-regexp-lookbehind

lbrdnk on (2024-07-24 17:12:22 UTC): Closing as completed; FE and also cljs PRs were merged and backported.

"
2411156695,issue,closed,completed,Flakey Question Picker unit test,"2 tests in `QuestionPicker.unit.spec.tsx` are a bit flakey as they perform searches in the Entity Picker and test for a loading state before examining search results. However, sometimes the runner misses the in between loading state, or React batches the state updates in a way that it's never displayed, causing the test to flake.

This PR removes checking the loading state, and adds a more generic ""loading search results"" state in `EntityPickerModal.unit.spec.tsx`.

[Link](https://stats.metabase.com/question#eyJuYW1lIjoiVGVzdCBGbGFraW5lc3MiLCJkZXNjcmlwdGlvbiI6IkZsYWtleSB0ZXN0cyBmb3IgTWV0YWJhc2UgZnJvbSB3b3JrZmxvdyBqb2JzIHBlciB0ZXN0L2pvYi9ydW4vYnJhbmNoL2NvbW1pdC4gVXBkYXRlZCBkYWlseS4iLCJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsib3JkZXItYnkiOltbImRlc2MiLFsiZmllbGQiLDU3ODkyOSx7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiIsInRlbXBvcmFsLXVuaXQiOiJkZWZhdWx0In1dXV0sInNvdXJjZS10YWJsZSI6ImNhcmRfXzE0ODI4IiwiZmlsdGVyIjpbIj0iLFsiZmllbGQiLCJzdWl0ZV9uYW1lIix7ImJhc2UtdHlwZSI6InR5cGUvVGV4dCJ9XSwiUXVlc3Rpb25QaWNrZXIiXX19LCJkaXNwbGF5IjoidGFibGUiLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6e30sIm9yaWdpbmFsX2NhcmRfaWQiOjE0ODI4LCJ0eXBlIjoicXVlc3Rpb24ifQ==) to stats with flakey occurances

",npfitz,2024-07-16 13:32:02+00:00,['npfitz'],2024-07-16 20:26:39+00:00,2024-07-16 20:06:50+00:00,https://github.com/metabase/metabase/issues/45642,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2411068396,issue,open,,Aurora MySQL AppDB can't create Metabase Analytics views without using `SQL SECURITY INVOKER`,"### Describe the bug

There is more context in this ticket: https://metabase.zendesk.com/agent/tickets/28784

It seems that mysql has two methods for executing views which are defined at creation in the [CREATE VIEW](https://dev.mysql.com/doc/refman/8.4/en/create-view.html) DDL: `SQL SECURITY DEFINER` and `SQL SECURITY INVOKER`. All the views begin with CREATE ALGORITHM=UNDEFINED DEFINER=`root`@`%` SQL SECURITY DEFINER VIEW when scripted out. With SQL SECURITY DEFINER, when metabase_admin selects from the view, it’s using the permissions assigned to the definer, the root user. Our mysql instance doesn’t have a user named “root” so no user selecting from the view has sufficient permissions.

The workaround is to create the views changing the DDL to set `SQL SECURITY INVOKER`

### To Reproduce

See above

### Expected behavior

User shouldn't need to tweak view DDL

### Logs

-

### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

_No response_",luizarakaki,2024-07-16 12:54:01+00:00,[],2025-02-05 19:16:39+00:00,,https://github.com/metabase/metabase/issues/45641,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2410961305,issue,closed,completed,Embed preview doesn't change the font when setting static question font to any font,"### Describe the bug

Embed preview doesn't change the font when setting static question font to any font.
![image](https://github.com/user-attachments/assets/1c15486a-c104-4e86-a716-47e12a80c148)

https://github.com/user-attachments/assets/1e72924d-0a5a-4773-9681-04f553adb0ef


### To Reproduce

Using EE/Pro license, with embedding enabled
1. Go to a question
2. Click sharing icon > Embed > Static Embed
3. Select Appearance tab and click the preview to see the question preview
4. Change the font to any font. The preview font stays the same regardless of any font selected.

### Expected behavior

The embed preview font should reflect the selected font option immediately.

### Logs

_No response_

### Information about your Metabase installation

```JSON
commit: `master` @ 97cfe29e894d63733ce29e391d5ff8d5e98fe4d2

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""src_hash"": ""80ae6221f268db83d6c316285073f7428bd3c659"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""efeab36""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",WiNloSt,2024-07-16 12:00:40+00:00,['sanex3339'],2025-01-23 08:50:59+00:00,2025-01-21 15:01:19+00:00,https://github.com/metabase/metabase/issues/45638,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Embedding', ''), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2410955585,issue,closed,completed,Embed preview doesn't change the font when setting static dashboard font to something else then back to instance font,"### Describe the bug

Embed preview doesn't change the font when setting static dashboard font to something else then back to _use instance font_
![image](https://github.com/user-attachments/assets/bca99324-7519-4218-9c8b-ef32b32dc2e8)


### To Reproduce

Using EE/Pro license, with embedding enabled
1. Go to a dashboard
2. Click sharing icon > Embed > Static Embed
3. Select Appearance tab and click the preview to see the dashboard preview
4. Change the font to another font. The preview should reflect the font immediately.
5. Change the font back to _Use instance font_. The preview font is stuck with the previous font.

This only affect the preview, as the actual embed would work fine.


### Expected behavior

The preview should reflect the selected options

### Logs

_No response_

### Information about your Metabase installation

```JSON
commit: `master` @ 97cfe29e894d63733ce29e391d5ff8d5e98fe4d2

{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""21.0.2+13-LTS"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""21.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.2+13-LTS"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.5"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""dev"",
    ""plan-alias"": ""enterprise-self-hosted"",
    ""version"": {
      ""date"": ""2024-07-15"",
      ""src_hash"": ""80ae6221f268db83d6c316285073f7428bd3c659"",
      ""tag"": ""v1.2.0-SNAPSHOT"",
      ""hash"": ""efeab36""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",WiNloSt,2024-07-16 11:57:33+00:00,['sanex3339'],2025-01-17 13:33:07+00:00,2025-01-17 12:45:54+00:00,https://github.com/metabase/metabase/issues/45637,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Embedding', ''), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2410949200,issue,closed,completed,"When bookmarks are reordered, the wrong ordering gets recorded","The order doesn't get preserved in the FE:

![Kapture 2024-07-16 at 07 55 51](https://github.com/user-attachments/assets/f1b3cdbd-c4d2-40bb-9299-fec24693db92)

Also, the FE is sending the wrong ordering to the API. Below, I drag items 1 and 2 to the bottom, but item 1 is still at the top after a refresh.

![Kapture 2024-07-16 at 07 57 56](https://github.com/user-attachments/assets/e5605e34-d9c3-48f1-9dce-30dc916d581e)
",rafpaf,2024-07-16 11:54:08+00:00,['rafpaf'],2024-07-30 14:55:02+00:00,2024-07-30 13:35:06+00:00,https://github.com/metabase/metabase/issues/45635,"[('Priority:P2', 'Average run of the mill bug'), ('backport', 'Automatically create PR on current release branch on merge'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2410918805,issue,open,,ClickHouse driver: an infinite loop of logs if database no longer exists,"### Describe the bug

With the ClickHouse driver, if a database does not exist, the sync will trigger an infinite loop of retries and logs. It is not clear whether it is currently coming from the driver code or Metabase.
See https://github.com/ClickHouse/metabase-clickhouse-driver/issues/258

### To Reproduce

See https://github.com/ClickHouse/metabase-clickhouse-driver/issues/258#issuecomment-2224601648

### Expected behavior

A single failure occurs when db does exist, and no infinite retries that could produce an enormous amount of logs.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- metabase-clickhouse-driver version: 1.50.1
- Metabase version: v0.50.6
```


### Severity

Blocking some users

### Additional context

_No response_",slvrtrn,2024-07-16 11:37:29+00:00,[],2025-02-04 20:24:38+00:00,,https://github.com/metabase/metabase/issues/45634,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2233476465, 'issue_id': 2410918805, 'author': 'paoliniluis', 'body': '@Tony-metabase you were investigating this', 'created_at': datetime.datetime(2024, 7, 17, 14, 32, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233490847, 'issue_id': 2410918805, 'author': 'Tony-metabase', 'body': 'Yeah this is very related to this https://github.com/ClickHouse/metabase-clickhouse-driver/issues/242 ... is it possible that the change here https://github.com/metabase/metabase/pull/43429 caused this? \r\n\r\nI already see @calherries on the clickhouse issue so I believe if that is the case he is already aware', 'created_at': datetime.datetime(2024, 7, 17, 14, 39, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244722931, 'issue_id': 2410918805, 'author': 'calherries', 'body': ""This is QPD, it happens on every attempt to query the DB. Here's [a slack thread](https://metaboat.slack.com/archives/C0439QDFHFZ/p1721129872287519?thread_ts=1720709864.736679&cid=C0439QDFHFZ) for more context"", 'created_at': datetime.datetime(2024, 7, 23, 9, 34, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245428541, 'issue_id': 2410918805, 'author': 'crisptrutski', 'body': 'I tried adding the following C3P0 options to see if it would end the retry loop, but didn\'t seem to make any difference:\r\n\r\n```\r\n   ""acquireRetryAttempts""         5\r\n   ""acquireRetryDelay""            1000\r\n   ""breakAfterAcquireFailure""     true\r\n```', 'created_at': datetime.datetime(2024, 7, 23, 14, 34, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-17 14:32:56 UTC): @Tony-metabase you were investigating this

Tony-metabase on (2024-07-17 14:39:28 UTC): Yeah this is very related to this https://github.com/ClickHouse/metabase-clickhouse-driver/issues/242 ... is it possible that the change here https://github.com/metabase/metabase/pull/43429 caused this? 

I already see @calherries on the clickhouse issue so I believe if that is the case he is already aware

calherries on (2024-07-23 09:34:24 UTC): This is QPD, it happens on every attempt to query the DB. Here's [a slack thread](https://metaboat.slack.com/archives/C0439QDFHFZ/p1721129872287519?thread_ts=1720709864.736679&cid=C0439QDFHFZ) for more context

crisptrutski on (2024-07-23 14:34:25 UTC): I tried adding the following C3P0 options to see if it would end the retry loop, but didn't seem to make any difference:

```
   ""acquireRetryAttempts""         5
   ""acquireRetryDelay""            1000
   ""breakAfterAcquireFailure""     true
```

"
2410661635,issue,open,,Mongo UUID not displayed correctly and filter not working,"### Describe the bug

I have verified that using an `ObjectId` (second row) is well represented, but it is not the case for `UUIDs` (first row). Here is an example of how they look like:

![image](https://github.com/user-attachments/assets/a85dfbdd-026d-4b2a-9289-f3399f267d8c)


### To Reproduce

Use a Mongo database and create a collection that uses [BSON UUID](https://www.mongodb.com/docs/manual/reference/bson-types/#binary-data).

Open the collection in Metabase and try to filter, it doesn't open the filter popup menu when the values are only `UUIDs`.

### Expected behavior

They should be represented as:
![image](https://github.com/user-attachments/assets/d4fefec5-2378-4513-b7f8-71d066d643ac)

And be able to filter by value.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:129.0) Gecko/20100101 Firefox/129.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.5.0-1021-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-07-04"",
      ""tag"": ""v0.50.10"",
      ""hash"": ""49d9e46""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

_No response_",aleixmorgadas,2024-07-16 09:26:32+00:00,[],2025-02-04 20:27:57+00:00,,https://github.com/metabase/metabase/issues/45626,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2230469725, 'issue_id': 2410661635, 'author': 'aleixmorgadas', 'body': 'If I use the native query like the next it works but the result still has the UUID formatting as before:\r\n\r\n```json\r\n[\r\n    {\r\n        ""$match"": {\r\n            ""_id"": UUID(\'ce607da3-4d76-469f-9e74-f378be0221c0\')\r\n        }  \r\n    },\r\n  {\r\n    ""$project"": {\r\n      ""_id"": ""$_id"",\r\n      ""name"": ""$name"",\r\n      ""createdAt"": ""$createdAt"",\r\n      ""updatedAt"": ""$updatedAt""\r\n    }\r\n  },\r\n  {\r\n    ""$limit"": 1048575\r\n  }\r\n]\r\n```', 'created_at': datetime.datetime(2024, 7, 16, 9, 44, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233244577, 'issue_id': 2410661635, 'author': 'bshepherdson', 'body': 'QP side: make sure the right Metabase types are returned for these columns, that they serialize correctly in the query results, and that a filter with a string literal works properly.\r\n\r\nThere may also be FE work here to render these correctly. But `org.bson.types.Binary@db466c45` looks like generic `Object.toString()` is being sent on the wire, which is a BE issue foremost.', 'created_at': datetime.datetime(2024, 7, 17, 12, 49, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233321439, 'issue_id': 2410661635, 'author': 'aleixmorgadas', 'body': '@bshepherdson, if you point me to some area of the code, I could try to fix the issue myself.\r\n\r\nI setup the environment with emacs and I have been able to run the project locally.\r\n\r\nI tried to extend the next code https://github.com/metabase/metabase/blob/master/modules/drivers/mongo/src/metabase/driver/mongo.clj#L38-L44\r\n\r\n```clojure\r\n(nippy/extend-freeze ObjectId :mongodb/ObjectId\r\n                     [^ObjectId oid data-output]\r\n                     (.writeUTF data-output (.toHexString oid)))\r\n\r\n(nippy/extend-thaw :mongodb/ObjectId\r\n  [data-input]\r\n  (ObjectId. (.readUTF data-input)))\r\n```\r\n\r\nBy adding something like the next thing without luck. I have limited Clojure knowledge but willing to learn.\r\n\r\n```clojure\r\n(nippy/extend-freeze UUID :mongodb/UUID\r\n                     [^UUID oid data-output]\r\n                     (.writeUTF data-output (.toHexString oid)))\r\n\r\n(nippy/extend-thaw :mongodb/UUID\r\n  [data-input]\r\n  (UUID. (.readUTF data-input)))\r\n```', 'created_at': datetime.datetime(2024, 7, 17, 13, 25, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2377905456, 'issue_id': 2410661635, 'author': 'aleixmorgadas', 'body': 'Any suggestions on how I can contribute?', 'created_at': datetime.datetime(2024, 9, 26, 20, 45, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549018750, 'issue_id': 2410661635, 'author': 'warren-leonardo-souza', 'body': 'Hello, this issue continues to affect my team. Any ideas for progress or alternatives?', 'created_at': datetime.datetime(2024, 12, 17, 16, 52, 32, tzinfo=datetime.timezone.utc)}]","aleixmorgadas (Issue Creator) on (2024-07-16 09:44:14 UTC): If I use the native query like the next it works but the result still has the UUID formatting as before:

```json
[
    {
        ""$match"": {
            ""_id"": UUID('ce607da3-4d76-469f-9e74-f378be0221c0')
        }  
    },
  {
    ""$project"": {
      ""_id"": ""$_id"",
      ""name"": ""$name"",
      ""createdAt"": ""$createdAt"",
      ""updatedAt"": ""$updatedAt""
    }
  },
  {
    ""$limit"": 1048575
  }
]
```

bshepherdson on (2024-07-17 12:49:06 UTC): QP side: make sure the right Metabase types are returned for these columns, that they serialize correctly in the query results, and that a filter with a string literal works properly.

There may also be FE work here to render these correctly. But `org.bson.types.Binary@db466c45` looks like generic `Object.toString()` is being sent on the wire, which is a BE issue foremost.

aleixmorgadas (Issue Creator) on (2024-07-17 13:25:07 UTC): @bshepherdson, if you point me to some area of the code, I could try to fix the issue myself.

I setup the environment with emacs and I have been able to run the project locally.

I tried to extend the next code https://github.com/metabase/metabase/blob/master/modules/drivers/mongo/src/metabase/driver/mongo.clj#L38-L44

```clojure
(nippy/extend-freeze ObjectId :mongodb/ObjectId
                     [^ObjectId oid data-output]
                     (.writeUTF data-output (.toHexString oid)))

(nippy/extend-thaw :mongodb/ObjectId
  [data-input]
  (ObjectId. (.readUTF data-input)))
```

By adding something like the next thing without luck. I have limited Clojure knowledge but willing to learn.

```clojure
(nippy/extend-freeze UUID :mongodb/UUID
                     [^UUID oid data-output]
                     (.writeUTF data-output (.toHexString oid)))

(nippy/extend-thaw :mongodb/UUID
  [data-input]
  (UUID. (.readUTF data-input)))
```

aleixmorgadas (Issue Creator) on (2024-09-26 20:45:54 UTC): Any suggestions on how I can contribute?

warren-leonardo-souza on (2024-12-17 16:52:32 UTC): Hello, this issue continues to affect my team. Any ideas for progress or alternatives?

"
2410294082,issue,closed,completed,Dashboard subscription mail sent multiple in v0.50.x,"### Describe the bug

After updating from version 0.49.4 to v0.50.6, one of the Dashboard subscriptions started sending 3 copies of the same email instead of one. A week later it started sending 4 copies. Then I updated to v0.50.11, issue remains. I also reacreated subscription of dashboard, issue still remains.

The other subscriptions seem to be fine, only one is facing this problem, its settings is unchanged (between 0.49 and 0.50).

Other users also face this [issue](https://discourse.metabase.com/t/dashboard-subscription-mail-sent-3x-in-v0-50/130080/4). 

### To Reproduce

Hard to reproduce, not all subscriptions face this issue:
-have dashboard with one question inside
-question use Table visualisation (no any setting inside)
-dashboard has one Date filter, set Today as default value
Subscription setting is:
Sent daily, Don't send if there aren't results, Attach results

### Expected behavior

Send single email same as previously...

### Logs

Troubleshooting logs (4th line is probably other subscription because have other pulse-id)
![image](https://github.com/user-attachments/assets/5a5ca1be-e4d0-4b99-971e-4b8efa926bba)


### Information about your Metabase installation

```JSON
v0.50.6 and v0.50.11
```


### Severity

low

### Additional context

_No response_",CZvacko,2024-07-16 06:09:30+00:00,['qnkhuat'],2024-09-17 13:15:41+00:00,2024-07-17 09:36:10+00:00,https://github.com/metabase/metabase/issues/45622,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2230114341, 'issue_id': 2410294082, 'author': 'qnkhuat', 'body': ""Hey, Thanks for reporting.\r\n\r\nIt'd help if you could give us the task history of send-pulse tasks by executing this query\r\n\r\n```sql\r\nselect * from task_history where task = 'send-pulse' order by started_at desc limit 100;\r\n```\r\n\r\nAnd the trigger info\r\n\r\n```sql\r\nselect * from qrtz_cron_triggers where trigger_name like 'metabase.task.send-pulse.trigger.[YOUR_REPEATED_PULSE_ID].%';\r\n```\r\n\r\nAlso, what does the query of the question look like?"", 'created_at': datetime.datetime(2024, 7, 16, 6, 23, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230154598, 'issue_id': 2410294082, 'author': 'CZvacko', 'body': 'Here is output for task_history\r\nNote: since dashboard have Date filter = Today, not every day have results, like once per week. \r\n2024-07-15 with results, 2024-07-16 without results.\r\n|    id   |    task    | db_id |         started_at         |          ended_at          | duration |            task_details            |  status |\r\n|:-------:|:----------:|:-----:|:--------------------------:|:--------------------------:|:--------:|:----------------------------------:|:-------:|\r\n| 4998826 | send-pulse | NULL  | 2024-07-16 08:00:00.006530 | 2024-07-16 08:00:00.022154 | 11       | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998683 | send-pulse | NULL  | 2024-07-16 07:00:00.015459 | 2024-07-16 07:00:00.023437 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998682 | send-pulse | NULL  | 2024-07-16 06:00:01.033857 | 2024-07-16 06:00:01.162477 | 128      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998681 | send-pulse | NULL  | 2024-07-16 06:00:00.860705 | 2024-07-16 06:00:00.988953 | 128      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998680 | send-pulse | NULL  | 2024-07-16 06:00:00.687150 | 2024-07-16 06:00:00.812807 | 126      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998679 | send-pulse | NULL  | 2024-07-16 06:00:00.499662 | 2024-07-16 06:00:00.638284 | 137      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998678 | send-pulse | NULL  | 2024-07-16 06:00:00.340931 | 2024-07-16 06:00:00.455642 | 115      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998677 | send-pulse | NULL  | 2024-07-16 06:00:00.198348 | 2024-07-16 06:00:00.302037 | 104      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998676 | send-pulse | NULL  | 2024-07-16 06:00:00.032137 | 2024-07-16 06:00:00.037123 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998675 | send-pulse | NULL  | 2024-07-16 06:00:00.013217 | 2024-07-16 06:00:00.158429 | 145      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4998622 | send-pulse | NULL  | 2024-07-16 05:00:00.956293 | 2024-07-16 05:00:01.222637 | 265      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4998621 | send-pulse | NULL  | 2024-07-16 05:00:00.859557 | 2024-07-16 05:00:01.082495 | 223      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4998620 | send-pulse | NULL  | 2024-07-16 05:00:00.646060 | 2024-07-16 05:00:00.908423 | 262      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4998619 | send-pulse | NULL  | 2024-07-16 05:00:00.588218 | 2024-07-16 05:00:00.816674 | 228      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4998618 | send-pulse | NULL  | 2024-07-16 05:00:00.338898 | 2024-07-16 05:00:00.590213 | 251      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4998617 | send-pulse | NULL  | 2024-07-16 05:00:00.314964 | 2024-07-16 05:00:00.533368 | 218      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4998616 | send-pulse | NULL  | 2024-07-16 05:00:00.054989 | 2024-07-16 05:00:00.060972 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998615 | send-pulse | NULL  | 2024-07-16 05:00:00.038035 | 2024-07-16 05:00:00.302997 | 264      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4998614 | send-pulse | NULL  | 2024-07-16 05:00:00.015097 | 2024-07-16 05:00:00.279061 | 263      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4998610 | send-pulse | NULL  | 2024-07-16 04:00:00.012128 | 2024-07-16 04:00:00.020107 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998470 | send-pulse | NULL  | 2024-07-16 03:00:00.014831 | 2024-07-16 03:00:00.031078 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998463 | send-pulse | NULL  | 2024-07-16 02:00:00.017905 | 2024-07-16 02:00:00.033528 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998320 | send-pulse | NULL  | 2024-07-16 01:00:00.014477 | 2024-07-16 01:00:00.022455 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998317 | send-pulse | NULL  | 2024-07-16 00:00:00.015001 | 2024-07-16 00:00:00.024973 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998129 | send-pulse | NULL  | 2024-07-15 23:00:00.016239 | 2024-07-15 23:00:00.025214 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4998128 | send-pulse | NULL  | 2024-07-15 22:00:00.013978 | 2024-07-15 22:00:00.021956 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997937 | send-pulse | NULL  | 2024-07-15 21:00:00.015767 | 2024-07-15 21:00:00.026765 | 10       | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997930 | send-pulse | NULL  | 2024-07-15 20:00:00.015819 | 2024-07-15 20:00:00.024794 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997787 | send-pulse | NULL  | 2024-07-15 19:00:00.019305 | 2024-07-15 19:00:00.027284 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997786 | send-pulse | NULL  | 2024-07-15 18:00:00.014263 | 2024-07-15 18:00:00.022241 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997643 | send-pulse | NULL  | 2024-07-15 17:00:00.065778 | 2024-07-15 17:00:00.070765 | 5        | {""pulse-id"":4,""channel-ids"":[4]}   | success |\r\n| 4997642 | send-pulse | NULL  | 2024-07-15 17:00:00.049822 | 2024-07-15 17:00:00.055806 | 6        | {""pulse-id"":3,""channel-ids"":[3]}   | success |\r\n| 4997641 | send-pulse | NULL  | 2024-07-15 17:00:00.032869 | 2024-07-15 17:00:00.042842 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997640 | send-pulse | NULL  | 2024-07-15 17:00:00.014216 | 2024-07-15 17:00:05.104086 | 5089     | {""pulse-id"":5,""channel-ids"":[5]}   | success |\r\n| 4997636 | send-pulse | NULL  | 2024-07-15 16:00:00.016321 | 2024-07-15 16:00:00.025297 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997496 | send-pulse | NULL  | 2024-07-15 15:00:00.016826 | 2024-07-15 15:00:00.025802 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997492 | send-pulse | NULL  | 2024-07-15 14:00:00.010987 | 2024-07-15 14:00:00.018965 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997343 | send-pulse | NULL  | 2024-07-15 13:00:00.012903 | 2024-07-15 13:00:00.020881 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997341 | send-pulse | NULL  | 2024-07-15 12:00:00.015462 | 2024-07-15 12:00:00.022444 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997198 | send-pulse | NULL  | 2024-07-15 11:00:00.018298 | 2024-07-15 11:00:00.026245 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997197 | send-pulse | NULL  | 2024-07-15 10:00:00.011858 | 2024-07-15 10:00:00.017842 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997050 | send-pulse | NULL  | 2024-07-15 09:00:00.978657 | 2024-07-15 09:00:01.433477 | 446      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4997049 | send-pulse | NULL  | 2024-07-15 09:00:00.916149 | 2024-07-15 09:00:01.292862 | 373      | {""pulse-id"":15,""channel-ids"":[15]} | success |\r\n| 4997048 | send-pulse | NULL  | 2024-07-15 09:00:00.806836 | 2024-07-15 09:00:01.511577 | 702      | {""pulse-id"":16,""channel-ids"":[16]} | success |\r\n| 4997045 | send-pulse | NULL  | 2024-07-15 09:00:00.509446 | 2024-07-15 09:00:00.947417 | 437      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4997044 | send-pulse | NULL  | 2024-07-15 09:00:00.493826 | 2024-07-15 09:00:00.869316 | 384      | {""pulse-id"":15,""channel-ids"":[15]} | success |\r\n| 4997040 | send-pulse | NULL  | 2024-07-15 09:00:00.061615 | 2024-07-15 09:00:00.077288 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997039 | send-pulse | NULL  | 2024-07-15 09:00:00.061615 | 2024-07-15 09:00:00.775604 | 713      | {""pulse-id"":16,""channel-ids"":[16]} | success |\r\n| 4997038 | send-pulse | NULL  | 2024-07-15 09:00:00.045995 | 2024-07-15 09:00:00.431372 | 393      | {""pulse-id"":15,""channel-ids"":[15]} | success |\r\n| 4997037 | send-pulse | NULL  | 2024-07-15 09:00:00.014751 | 2024-07-15 09:00:00.462613 | 446      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4997036 | send-pulse | NULL  | 2024-07-15 08:00:00.053785 | 2024-07-15 08:00:00.053785 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4997035 | send-pulse | NULL  | 2024-07-15 08:00:00.038166 | 2024-07-15 08:00:25.408963 | 25371    | {""pulse-id"":8,""channel-ids"":[8]}   | success |\r\n| 4997034 | send-pulse | NULL  | 2024-07-15 08:00:00.006891 | 2024-07-15 08:00:17.545975 | 17535    | {""pulse-id"":9,""channel-ids"":[9]}   | success |\r\n| 4996978 | send-pulse | NULL  | 2024-07-15 07:00:00.033598 | 2024-07-15 07:00:00.039554 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996977 | send-pulse | NULL  | 2024-07-15 07:00:00.014622 | 2024-07-15 07:00:27.330058 | 27316    | {""pulse-id"":2,""channel-ids"":[2]}   | success |\r\n| 4996976 | send-pulse | NULL  | 2024-07-15 06:00:00.966295 | 2024-07-15 06:00:01.224529 | 258      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4996975 | send-pulse | NULL  | 2024-07-15 06:00:00.674277 | 2024-07-15 06:00:00.921418 | 246      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4996974 | send-pulse | NULL  | 2024-07-15 06:00:00.379082 | 2024-07-15 06:00:00.630425 | 252      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4996973 | send-pulse | NULL  | 2024-07-15 06:00:00.035829 | 2024-07-15 06:00:00.042810 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996972 | send-pulse | NULL  | 2024-07-15 06:00:00.015883 | 2024-07-15 06:00:00.333238 | 317      | {""pulse-id"":21,""channel-ids"":[21]} | success |\r\n| 4996919 | send-pulse | NULL  | 2024-07-15 05:00:00.983342 | 2024-07-15 05:00:01.225686 | 241      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4996918 | send-pulse | NULL  | 2024-07-15 05:00:00.728963 | 2024-07-15 05:00:01.019244 | 290      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4996917 | send-pulse | NULL  | 2024-07-15 05:00:00.657157 | 2024-07-15 05:00:00.936928 | 279      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4996916 | send-pulse | NULL  | 2024-07-15 05:00:00.380906 | 2024-07-15 05:00:00.662144 | 281      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4996915 | send-pulse | NULL  | 2024-07-15 05:00:00.338422 | 2024-07-15 05:00:00.603303 | 264      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4996914 | send-pulse | NULL  | 2024-07-15 05:00:00.051197 | 2024-07-15 05:00:00.057181 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996913 | send-pulse | NULL  | 2024-07-15 05:00:00.032249 | 2024-07-15 05:00:00.343408 | 310      | {""pulse-id"":13,""channel-ids"":[13]} | success |\r\n| 4996912 | send-pulse | NULL  | 2024-07-15 05:00:00.013328 | 2024-07-15 05:00:00.299527 | 286      | {""pulse-id"":12,""channel-ids"":[12]} | success |\r\n| 4996908 | send-pulse | NULL  | 2024-07-15 04:00:00.018233 | 2024-07-15 04:00:00.027209 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996768 | send-pulse | NULL  | 2024-07-15 03:00:00.016852 | 2024-07-15 03:00:00.027928 | 11       | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996761 | send-pulse | NULL  | 2024-07-15 02:00:00.017766 | 2024-07-15 02:00:00.024740 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996618 | send-pulse | NULL  | 2024-07-15 01:00:00.016358 | 2024-07-15 01:00:00.025305 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996615 | send-pulse | NULL  | 2024-07-15 00:00:00.019257 | 2024-07-15 00:00:00.027235 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996427 | send-pulse | NULL  | 2024-07-14 23:00:00.015090 | 2024-07-14 23:00:00.022071 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996426 | send-pulse | NULL  | 2024-07-14 22:00:00.015273 | 2024-07-14 22:00:00.024249 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996235 | send-pulse | NULL  | 2024-07-14 21:00:00.013862 | 2024-07-14 21:00:00.021841 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996228 | send-pulse | NULL  | 2024-07-14 20:00:00.019124 | 2024-07-14 20:00:00.027072 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996085 | send-pulse | NULL  | 2024-07-14 19:00:00.015302 | 2024-07-14 19:00:00.023280 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4996084 | send-pulse | NULL  | 2024-07-14 18:00:00.016250 | 2024-07-14 18:00:00.026232 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995896 | send-pulse | NULL  | 2024-07-14 17:00:00.741565 | 2024-07-14 17:00:01.073783 | 332      | {""pulse-id"":5,""channel-ids"":[5]}   | success |\r\n| 4995895 | send-pulse | NULL  | 2024-07-14 17:00:00.370032 | 2024-07-14 17:00:00.700129 | 331      | {""pulse-id"":5,""channel-ids"":[5]}   | success |\r\n| 4995891 | send-pulse | NULL  | 2024-07-14 17:00:00.065745 | 2024-07-14 17:00:00.074721 | 9        | {""pulse-id"":4,""channel-ids"":[4]}   | success |\r\n| 4995890 | send-pulse | NULL  | 2024-07-14 17:00:00.049788 | 2024-07-14 17:00:00.055772 | 5        | {""pulse-id"":3,""channel-ids"":[3]}   | success |\r\n| 4995889 | send-pulse | NULL  | 2024-07-14 17:00:00.033832 | 2024-07-14 17:00:00.040813 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995888 | send-pulse | NULL  | 2024-07-14 17:00:00.011927 | 2024-07-14 17:00:00.331139 | 319      | {""pulse-id"":5,""channel-ids"":[5]}   | success |\r\n| 4995884 | send-pulse | NULL  | 2024-07-14 16:00:00.017200 | 2024-07-14 16:00:00.026169 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995696 | send-pulse | NULL  | 2024-07-14 15:00:00.018011 | 2024-07-14 15:00:00.026986 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995692 | send-pulse | NULL  | 2024-07-14 14:00:00.010510 | 2024-07-14 14:00:00.022478 | 12       | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995495 | send-pulse | NULL  | 2024-07-14 13:00:00.013901 | 2024-07-14 13:00:00.021879 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995493 | send-pulse | NULL  | 2024-07-14 12:00:00.016218 | 2024-07-14 12:00:00.027190 | 10       | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995302 | send-pulse | NULL  | 2024-07-14 11:00:00.014267 | 2024-07-14 11:00:00.022244 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995301 | send-pulse | NULL  | 2024-07-14 10:00:00.017632 | 2024-07-14 10:00:00.026604 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995106 | send-pulse | NULL  | 2024-07-14 09:00:00.993143 | 2024-07-14 09:00:01.419613 | 426      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4995105 | send-pulse | NULL  | 2024-07-14 09:00:00.743196 | 2024-07-14 09:00:01.108803 | 366      | {""pulse-id"":15,""channel-ids"":[15]} | success |\r\n| 4995102 | send-pulse | NULL  | 2024-07-14 09:00:00.518810 | 2024-07-14 09:00:00.946248 | 427      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4995098 | send-pulse | NULL  | 2024-07-14 09:00:00.076854 | 2024-07-14 09:00:00.082838 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n| 4995097 | send-pulse | NULL  | 2024-07-14 09:00:00.061894 | 2024-07-14 09:00:01.010073 | 948      | {""pulse-id"":16,""channel-ids"":[16]} | success |\r\n| 4995096 | send-pulse | NULL  | 2024-07-14 09:00:00.043968 | 2024-07-14 09:00:00.701311 | 657      | {""pulse-id"":15,""channel-ids"":[15]} | success |\r\n| 4995095 | send-pulse | NULL  | 2024-07-14 09:00:00.013057 | 2024-07-14 09:00:00.462963 | 449      | {""pulse-id"":14,""channel-ids"":[14]} | success |\r\n| 4995094 | send-pulse | NULL  | 2024-07-14 08:00:00.015156 | 2024-07-14 08:00:00.023134 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |\r\n\r\nHere is output for qrtz_cron_triggers:\r\n|     SCHED_NAME    |                    TRIGGER_NAME                   | TRIGGER_GROUP | CRON_EXPRESSION | TIME_ZONE_ID |   |   |   |\r\n|:-----------------:|:-------------------------------------------------:|:-------------:|:---------------:|:------------:|---|---|---|\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.21.0_0_6_*_*_?_* | DEFAULT       | 0 0 6 * * ? *   | Europe/Paris |   |   |   |\r\n\r\nDashboard look like this (contains sensitive employee data)\r\n![image](https://github.com/user-attachments/assets/39366b10-d3ae-4a48-bdfe-2cd35d79be6f)\r\n\r\nAnd the question is based on DB view, so in visual editor I just set order of DATUM_NASTUPU to be descending', 'created_at': datetime.datetime(2024, 7, 16, 6, 53, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232321543, 'issue_id': 2410294082, 'author': 'qnkhuat', 'body': ""It has multiple task histories, so I suspect this is a Quartz issue where it's being triggered multiple times.\r\n\r\nCan you do another query, you don't have to format it as a table in markdown every time. I'm okay with whatever format\r\n\r\n```sql\r\nselect * from qrtz_triggers where job_name = 'metabase.task.send-pulses.send-pulse.job';\r\n```"", 'created_at': datetime.datetime(2024, 7, 17, 3, 54, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232555508, 'issue_id': 2410294082, 'author': 'CZvacko', 'body': 'Here is it \r\n|     SCHED_NAME    |                    TRIGGER_NAME                   | TRIGGER_GROUP |                 JOB_NAME                 | JOB_GROUP | DESCRIPTION | NEXT_FIRE_TIME | PREV_FIRE_TIME | PRIORITY | TRIGGER_STATE | TRIGGER_TYPE |   START_TIME  | END_TIME | CALENDAR_NAME | MISFIRE_INSTR |   JOB_DATA  |\r\n|:-----------------:|:-------------------------------------------------:|:-------------:|:----------------------------------------:|:---------:|:-----------:|:--------------:|:--------------:|:--------:|:-------------:|:------------:|:-------------:|:--------:|:-------------:|:-------------:|:-----------:|\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.12.0_0_5_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721271600000  | -1             | 3596     | WAITING       | CRON         | 1721185203000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.13.0_0_5_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721271600000  | -1             | 3596     | WAITING       | CRON         | 1721185203000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.14.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.15.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.16.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.17.0_0_*_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | 1721196000000  | 6        | WAITING       | CRON         | 1718976821000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.2.0_0_7_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721624400000  | -1             | 3572     | WAITING       | CRON         | 1721019627000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.21.0_0_6_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721275200000  | -1             | 3599     | WAITING       | CRON         | 1721188801000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.3.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | 1721142000000  | 6        | WAITING       | CRON         | 1718976821000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.4.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | 1721142000000  | 6        | WAITING       | CRON         | 1718976822000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.5.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | -1             | 3594     | WAITING       | CRON         | 1721142005000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.7.0_0_1_?_*_6_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721343600000  | -1             | 3597     | WAITING       | CRON         | 1720738802000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.8.0_0_8_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721628000000  | -1             | 3574     | WAITING       | CRON         | 1721023225000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n| MetabaseScheduler | metabase.task.send-pulse.trigger.9.0_0_8_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721628000000  | -1             | 3582     | WAITING       | CRON         | 1721023217000 | 0        | NULL          | 1             | 1 070 bajtů |\r\n\r\n(I used markdown table generator, not many efforts for me...)', 'created_at': datetime.datetime(2024, 7, 17, 6, 49, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232683005, 'issue_id': 2410294082, 'author': 'qnkhuat', 'body': 'I can reproduce and will have a fix soon', 'created_at': datetime.datetime(2024, 7, 17, 8, 2, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2355192463, 'issue_id': 2410294082, 'author': 'Praesklepios', 'body': ""So for me this issue still persists even after updating to v0.50.19.4. Three reports are send out every time a subscription is triggered. I newly set up every subscription by now. When testing a subscription manually (send email now Button) this problem doesn't occur."", 'created_at': datetime.datetime(2024, 9, 17, 10, 14, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2355757770, 'issue_id': 2410294082, 'author': 'paoliniluis', 'body': ""@Praesklepios please check the latest issue I created, I think that there's something that's causing failures now and Metabase retries, but we can't find the root causee"", 'created_at': datetime.datetime(2024, 9, 17, 13, 15, 39, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-07-16 06:23:28 UTC): Hey, Thanks for reporting.

It'd help if you could give us the task history of send-pulse tasks by executing this query

```sql
select * from task_history where task = 'send-pulse' order by started_at desc limit 100;
```

And the trigger info

```sql
select * from qrtz_cron_triggers where trigger_name like 'metabase.task.send-pulse.trigger.[YOUR_REPEATED_PULSE_ID].%';
```

Also, what does the query of the question look like?

CZvacko (Issue Creator) on (2024-07-16 06:53:16 UTC): Here is output for task_history
Note: since dashboard have Date filter = Today, not every day have results, like once per week. 
2024-07-15 with results, 2024-07-16 without results.
|    id   |    task    | db_id |         started_at         |          ended_at          | duration |            task_details            |  status |
|:-------:|:----------:|:-----:|:--------------------------:|:--------------------------:|:--------:|:----------------------------------:|:-------:|
| 4998826 | send-pulse | NULL  | 2024-07-16 08:00:00.006530 | 2024-07-16 08:00:00.022154 | 11       | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998683 | send-pulse | NULL  | 2024-07-16 07:00:00.015459 | 2024-07-16 07:00:00.023437 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998682 | send-pulse | NULL  | 2024-07-16 06:00:01.033857 | 2024-07-16 06:00:01.162477 | 128      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998681 | send-pulse | NULL  | 2024-07-16 06:00:00.860705 | 2024-07-16 06:00:00.988953 | 128      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998680 | send-pulse | NULL  | 2024-07-16 06:00:00.687150 | 2024-07-16 06:00:00.812807 | 126      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998679 | send-pulse | NULL  | 2024-07-16 06:00:00.499662 | 2024-07-16 06:00:00.638284 | 137      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998678 | send-pulse | NULL  | 2024-07-16 06:00:00.340931 | 2024-07-16 06:00:00.455642 | 115      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998677 | send-pulse | NULL  | 2024-07-16 06:00:00.198348 | 2024-07-16 06:00:00.302037 | 104      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998676 | send-pulse | NULL  | 2024-07-16 06:00:00.032137 | 2024-07-16 06:00:00.037123 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998675 | send-pulse | NULL  | 2024-07-16 06:00:00.013217 | 2024-07-16 06:00:00.158429 | 145      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4998622 | send-pulse | NULL  | 2024-07-16 05:00:00.956293 | 2024-07-16 05:00:01.222637 | 265      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4998621 | send-pulse | NULL  | 2024-07-16 05:00:00.859557 | 2024-07-16 05:00:01.082495 | 223      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4998620 | send-pulse | NULL  | 2024-07-16 05:00:00.646060 | 2024-07-16 05:00:00.908423 | 262      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4998619 | send-pulse | NULL  | 2024-07-16 05:00:00.588218 | 2024-07-16 05:00:00.816674 | 228      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4998618 | send-pulse | NULL  | 2024-07-16 05:00:00.338898 | 2024-07-16 05:00:00.590213 | 251      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4998617 | send-pulse | NULL  | 2024-07-16 05:00:00.314964 | 2024-07-16 05:00:00.533368 | 218      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4998616 | send-pulse | NULL  | 2024-07-16 05:00:00.054989 | 2024-07-16 05:00:00.060972 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998615 | send-pulse | NULL  | 2024-07-16 05:00:00.038035 | 2024-07-16 05:00:00.302997 | 264      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4998614 | send-pulse | NULL  | 2024-07-16 05:00:00.015097 | 2024-07-16 05:00:00.279061 | 263      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4998610 | send-pulse | NULL  | 2024-07-16 04:00:00.012128 | 2024-07-16 04:00:00.020107 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998470 | send-pulse | NULL  | 2024-07-16 03:00:00.014831 | 2024-07-16 03:00:00.031078 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998463 | send-pulse | NULL  | 2024-07-16 02:00:00.017905 | 2024-07-16 02:00:00.033528 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998320 | send-pulse | NULL  | 2024-07-16 01:00:00.014477 | 2024-07-16 01:00:00.022455 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998317 | send-pulse | NULL  | 2024-07-16 00:00:00.015001 | 2024-07-16 00:00:00.024973 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998129 | send-pulse | NULL  | 2024-07-15 23:00:00.016239 | 2024-07-15 23:00:00.025214 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4998128 | send-pulse | NULL  | 2024-07-15 22:00:00.013978 | 2024-07-15 22:00:00.021956 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997937 | send-pulse | NULL  | 2024-07-15 21:00:00.015767 | 2024-07-15 21:00:00.026765 | 10       | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997930 | send-pulse | NULL  | 2024-07-15 20:00:00.015819 | 2024-07-15 20:00:00.024794 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997787 | send-pulse | NULL  | 2024-07-15 19:00:00.019305 | 2024-07-15 19:00:00.027284 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997786 | send-pulse | NULL  | 2024-07-15 18:00:00.014263 | 2024-07-15 18:00:00.022241 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997643 | send-pulse | NULL  | 2024-07-15 17:00:00.065778 | 2024-07-15 17:00:00.070765 | 5        | {""pulse-id"":4,""channel-ids"":[4]}   | success |
| 4997642 | send-pulse | NULL  | 2024-07-15 17:00:00.049822 | 2024-07-15 17:00:00.055806 | 6        | {""pulse-id"":3,""channel-ids"":[3]}   | success |
| 4997641 | send-pulse | NULL  | 2024-07-15 17:00:00.032869 | 2024-07-15 17:00:00.042842 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997640 | send-pulse | NULL  | 2024-07-15 17:00:00.014216 | 2024-07-15 17:00:05.104086 | 5089     | {""pulse-id"":5,""channel-ids"":[5]}   | success |
| 4997636 | send-pulse | NULL  | 2024-07-15 16:00:00.016321 | 2024-07-15 16:00:00.025297 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997496 | send-pulse | NULL  | 2024-07-15 15:00:00.016826 | 2024-07-15 15:00:00.025802 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997492 | send-pulse | NULL  | 2024-07-15 14:00:00.010987 | 2024-07-15 14:00:00.018965 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997343 | send-pulse | NULL  | 2024-07-15 13:00:00.012903 | 2024-07-15 13:00:00.020881 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997341 | send-pulse | NULL  | 2024-07-15 12:00:00.015462 | 2024-07-15 12:00:00.022444 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997198 | send-pulse | NULL  | 2024-07-15 11:00:00.018298 | 2024-07-15 11:00:00.026245 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997197 | send-pulse | NULL  | 2024-07-15 10:00:00.011858 | 2024-07-15 10:00:00.017842 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997050 | send-pulse | NULL  | 2024-07-15 09:00:00.978657 | 2024-07-15 09:00:01.433477 | 446      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4997049 | send-pulse | NULL  | 2024-07-15 09:00:00.916149 | 2024-07-15 09:00:01.292862 | 373      | {""pulse-id"":15,""channel-ids"":[15]} | success |
| 4997048 | send-pulse | NULL  | 2024-07-15 09:00:00.806836 | 2024-07-15 09:00:01.511577 | 702      | {""pulse-id"":16,""channel-ids"":[16]} | success |
| 4997045 | send-pulse | NULL  | 2024-07-15 09:00:00.509446 | 2024-07-15 09:00:00.947417 | 437      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4997044 | send-pulse | NULL  | 2024-07-15 09:00:00.493826 | 2024-07-15 09:00:00.869316 | 384      | {""pulse-id"":15,""channel-ids"":[15]} | success |
| 4997040 | send-pulse | NULL  | 2024-07-15 09:00:00.061615 | 2024-07-15 09:00:00.077288 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997039 | send-pulse | NULL  | 2024-07-15 09:00:00.061615 | 2024-07-15 09:00:00.775604 | 713      | {""pulse-id"":16,""channel-ids"":[16]} | success |
| 4997038 | send-pulse | NULL  | 2024-07-15 09:00:00.045995 | 2024-07-15 09:00:00.431372 | 393      | {""pulse-id"":15,""channel-ids"":[15]} | success |
| 4997037 | send-pulse | NULL  | 2024-07-15 09:00:00.014751 | 2024-07-15 09:00:00.462613 | 446      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4997036 | send-pulse | NULL  | 2024-07-15 08:00:00.053785 | 2024-07-15 08:00:00.053785 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4997035 | send-pulse | NULL  | 2024-07-15 08:00:00.038166 | 2024-07-15 08:00:25.408963 | 25371    | {""pulse-id"":8,""channel-ids"":[8]}   | success |
| 4997034 | send-pulse | NULL  | 2024-07-15 08:00:00.006891 | 2024-07-15 08:00:17.545975 | 17535    | {""pulse-id"":9,""channel-ids"":[9]}   | success |
| 4996978 | send-pulse | NULL  | 2024-07-15 07:00:00.033598 | 2024-07-15 07:00:00.039554 | 5        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996977 | send-pulse | NULL  | 2024-07-15 07:00:00.014622 | 2024-07-15 07:00:27.330058 | 27316    | {""pulse-id"":2,""channel-ids"":[2]}   | success |
| 4996976 | send-pulse | NULL  | 2024-07-15 06:00:00.966295 | 2024-07-15 06:00:01.224529 | 258      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4996975 | send-pulse | NULL  | 2024-07-15 06:00:00.674277 | 2024-07-15 06:00:00.921418 | 246      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4996974 | send-pulse | NULL  | 2024-07-15 06:00:00.379082 | 2024-07-15 06:00:00.630425 | 252      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4996973 | send-pulse | NULL  | 2024-07-15 06:00:00.035829 | 2024-07-15 06:00:00.042810 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996972 | send-pulse | NULL  | 2024-07-15 06:00:00.015883 | 2024-07-15 06:00:00.333238 | 317      | {""pulse-id"":21,""channel-ids"":[21]} | success |
| 4996919 | send-pulse | NULL  | 2024-07-15 05:00:00.983342 | 2024-07-15 05:00:01.225686 | 241      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4996918 | send-pulse | NULL  | 2024-07-15 05:00:00.728963 | 2024-07-15 05:00:01.019244 | 290      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4996917 | send-pulse | NULL  | 2024-07-15 05:00:00.657157 | 2024-07-15 05:00:00.936928 | 279      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4996916 | send-pulse | NULL  | 2024-07-15 05:00:00.380906 | 2024-07-15 05:00:00.662144 | 281      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4996915 | send-pulse | NULL  | 2024-07-15 05:00:00.338422 | 2024-07-15 05:00:00.603303 | 264      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4996914 | send-pulse | NULL  | 2024-07-15 05:00:00.051197 | 2024-07-15 05:00:00.057181 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996913 | send-pulse | NULL  | 2024-07-15 05:00:00.032249 | 2024-07-15 05:00:00.343408 | 310      | {""pulse-id"":13,""channel-ids"":[13]} | success |
| 4996912 | send-pulse | NULL  | 2024-07-15 05:00:00.013328 | 2024-07-15 05:00:00.299527 | 286      | {""pulse-id"":12,""channel-ids"":[12]} | success |
| 4996908 | send-pulse | NULL  | 2024-07-15 04:00:00.018233 | 2024-07-15 04:00:00.027209 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996768 | send-pulse | NULL  | 2024-07-15 03:00:00.016852 | 2024-07-15 03:00:00.027928 | 11       | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996761 | send-pulse | NULL  | 2024-07-15 02:00:00.017766 | 2024-07-15 02:00:00.024740 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996618 | send-pulse | NULL  | 2024-07-15 01:00:00.016358 | 2024-07-15 01:00:00.025305 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996615 | send-pulse | NULL  | 2024-07-15 00:00:00.019257 | 2024-07-15 00:00:00.027235 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996427 | send-pulse | NULL  | 2024-07-14 23:00:00.015090 | 2024-07-14 23:00:00.022071 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996426 | send-pulse | NULL  | 2024-07-14 22:00:00.015273 | 2024-07-14 22:00:00.024249 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996235 | send-pulse | NULL  | 2024-07-14 21:00:00.013862 | 2024-07-14 21:00:00.021841 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996228 | send-pulse | NULL  | 2024-07-14 20:00:00.019124 | 2024-07-14 20:00:00.027072 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996085 | send-pulse | NULL  | 2024-07-14 19:00:00.015302 | 2024-07-14 19:00:00.023280 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4996084 | send-pulse | NULL  | 2024-07-14 18:00:00.016250 | 2024-07-14 18:00:00.026232 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995896 | send-pulse | NULL  | 2024-07-14 17:00:00.741565 | 2024-07-14 17:00:01.073783 | 332      | {""pulse-id"":5,""channel-ids"":[5]}   | success |
| 4995895 | send-pulse | NULL  | 2024-07-14 17:00:00.370032 | 2024-07-14 17:00:00.700129 | 331      | {""pulse-id"":5,""channel-ids"":[5]}   | success |
| 4995891 | send-pulse | NULL  | 2024-07-14 17:00:00.065745 | 2024-07-14 17:00:00.074721 | 9        | {""pulse-id"":4,""channel-ids"":[4]}   | success |
| 4995890 | send-pulse | NULL  | 2024-07-14 17:00:00.049788 | 2024-07-14 17:00:00.055772 | 5        | {""pulse-id"":3,""channel-ids"":[3]}   | success |
| 4995889 | send-pulse | NULL  | 2024-07-14 17:00:00.033832 | 2024-07-14 17:00:00.040813 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995888 | send-pulse | NULL  | 2024-07-14 17:00:00.011927 | 2024-07-14 17:00:00.331139 | 319      | {""pulse-id"":5,""channel-ids"":[5]}   | success |
| 4995884 | send-pulse | NULL  | 2024-07-14 16:00:00.017200 | 2024-07-14 16:00:00.026169 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995696 | send-pulse | NULL  | 2024-07-14 15:00:00.018011 | 2024-07-14 15:00:00.026986 | 9        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995692 | send-pulse | NULL  | 2024-07-14 14:00:00.010510 | 2024-07-14 14:00:00.022478 | 12       | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995495 | send-pulse | NULL  | 2024-07-14 13:00:00.013901 | 2024-07-14 13:00:00.021879 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995493 | send-pulse | NULL  | 2024-07-14 12:00:00.016218 | 2024-07-14 12:00:00.027190 | 10       | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995302 | send-pulse | NULL  | 2024-07-14 11:00:00.014267 | 2024-07-14 11:00:00.022244 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995301 | send-pulse | NULL  | 2024-07-14 10:00:00.017632 | 2024-07-14 10:00:00.026604 | 8        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995106 | send-pulse | NULL  | 2024-07-14 09:00:00.993143 | 2024-07-14 09:00:01.419613 | 426      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4995105 | send-pulse | NULL  | 2024-07-14 09:00:00.743196 | 2024-07-14 09:00:01.108803 | 366      | {""pulse-id"":15,""channel-ids"":[15]} | success |
| 4995102 | send-pulse | NULL  | 2024-07-14 09:00:00.518810 | 2024-07-14 09:00:00.946248 | 427      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4995098 | send-pulse | NULL  | 2024-07-14 09:00:00.076854 | 2024-07-14 09:00:00.082838 | 6        | {""pulse-id"":17,""channel-ids"":[17]} | success |
| 4995097 | send-pulse | NULL  | 2024-07-14 09:00:00.061894 | 2024-07-14 09:00:01.010073 | 948      | {""pulse-id"":16,""channel-ids"":[16]} | success |
| 4995096 | send-pulse | NULL  | 2024-07-14 09:00:00.043968 | 2024-07-14 09:00:00.701311 | 657      | {""pulse-id"":15,""channel-ids"":[15]} | success |
| 4995095 | send-pulse | NULL  | 2024-07-14 09:00:00.013057 | 2024-07-14 09:00:00.462963 | 449      | {""pulse-id"":14,""channel-ids"":[14]} | success |
| 4995094 | send-pulse | NULL  | 2024-07-14 08:00:00.015156 | 2024-07-14 08:00:00.023134 | 7        | {""pulse-id"":17,""channel-ids"":[17]} | success |

Here is output for qrtz_cron_triggers:
|     SCHED_NAME    |                    TRIGGER_NAME                   | TRIGGER_GROUP | CRON_EXPRESSION | TIME_ZONE_ID |   |   |   |
|:-----------------:|:-------------------------------------------------:|:-------------:|:---------------:|:------------:|---|---|---|
| MetabaseScheduler | metabase.task.send-pulse.trigger.21.0_0_6_*_*_?_* | DEFAULT       | 0 0 6 * * ? *   | Europe/Paris |   |   |   |

Dashboard look like this (contains sensitive employee data)
![image](https://github.com/user-attachments/assets/39366b10-d3ae-4a48-bdfe-2cd35d79be6f)

And the question is based on DB view, so in visual editor I just set order of DATUM_NASTUPU to be descending

qnkhuat (Assginee) on (2024-07-17 03:54:02 UTC): It has multiple task histories, so I suspect this is a Quartz issue where it's being triggered multiple times.

Can you do another query, you don't have to format it as a table in markdown every time. I'm okay with whatever format

```sql
select * from qrtz_triggers where job_name = 'metabase.task.send-pulses.send-pulse.job';
```

CZvacko (Issue Creator) on (2024-07-17 06:49:03 UTC): Here is it 
|     SCHED_NAME    |                    TRIGGER_NAME                   | TRIGGER_GROUP |                 JOB_NAME                 | JOB_GROUP | DESCRIPTION | NEXT_FIRE_TIME | PREV_FIRE_TIME | PRIORITY | TRIGGER_STATE | TRIGGER_TYPE |   START_TIME  | END_TIME | CALENDAR_NAME | MISFIRE_INSTR |   JOB_DATA  |
|:-----------------:|:-------------------------------------------------:|:-------------:|:----------------------------------------:|:---------:|:-----------:|:--------------:|:--------------:|:--------:|:-------------:|:------------:|:-------------:|:--------:|:-------------:|:-------------:|:-----------:|
| MetabaseScheduler | metabase.task.send-pulse.trigger.12.0_0_5_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721271600000  | -1             | 3596     | WAITING       | CRON         | 1721185203000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.13.0_0_5_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721271600000  | -1             | 3596     | WAITING       | CRON         | 1721185203000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.14.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.15.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.16.0_0_9_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | -1             | 3599     | WAITING       | CRON         | 1721113201000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.17.0_0_*_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721199600000  | 1721196000000  | 6        | WAITING       | CRON         | 1718976821000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.2.0_0_7_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721624400000  | -1             | 3572     | WAITING       | CRON         | 1721019627000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.21.0_0_6_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721275200000  | -1             | 3599     | WAITING       | CRON         | 1721188801000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.3.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | 1721142000000  | 6        | WAITING       | CRON         | 1718976821000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.4.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | 1721142000000  | 6        | WAITING       | CRON         | 1718976822000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.5.0_0_17_*_*_?_* | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721228400000  | -1             | 3594     | WAITING       | CRON         | 1721142005000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.7.0_0_1_?_*_6_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721343600000  | -1             | 3597     | WAITING       | CRON         | 1720738802000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.8.0_0_8_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721628000000  | -1             | 3574     | WAITING       | CRON         | 1721023225000 | 0        | NULL          | 1             | 1 070 bajtů |
| MetabaseScheduler | metabase.task.send-pulse.trigger.9.0_0_8_?_*_2_*  | DEFAULT       | metabase.task.send-pulses.send-pulse.job | DEFAULT   | NULL        | 1721628000000  | -1             | 3582     | WAITING       | CRON         | 1721023217000 | 0        | NULL          | 1             | 1 070 bajtů |

(I used markdown table generator, not many efforts for me...)

qnkhuat (Assginee) on (2024-07-17 08:02:17 UTC): I can reproduce and will have a fix soon

Praesklepios on (2024-09-17 10:14:56 UTC): So for me this issue still persists even after updating to v0.50.19.4. Three reports are send out every time a subscription is triggered. I newly set up every subscription by now. When testing a subscription manually (send email now Button) this problem doesn't occur.

paoliniluis on (2024-09-17 13:15:39 UTC): @Praesklepios please check the latest issue I created, I think that there's something that's causing failures now and Metabase retries, but we can't find the root causee

"
2409930772,issue,open,,Adding filter type timestamp (or date) to Druid JBDC fails,"### Describe the bug

Hello,

When running a simple query in Metabase, an error occurs despite the same query working fine in the Druid SQL API (web console).


`select count(1) from table where __time >= {{dbtime}}`

When previewing the query:
 
`select count(1) from table where __time >= date '2024-07-14'`

This runs fine in Druid SQL API (web console) but fails in Metabase with the following error:

`An SQLException was provoked by the following failure: java.lang.UnsupportedOperationException: Cannot convert from java.time.LocalDate to long`


### To Reproduce

- Go to Metabase.
- Create a new question using the SQL editor.
- Input the query:
- ```sql
    select count(1) from table where __time >= {{dbtime}}
     ```
- Set {{dbtime}} to a specific date (e.g., 2024-07-14), mark as required to make things easier
- Click on ""Preview"".
- Click on ""Run"" or Ctrl-Enter 


### Expected behavior

The query should run without errors in Metabase, similar to how it runs successfully in the Druid SQL API (web console). Specifically, Metabase should properly handle the date conversion and execute the query, returning the correct count.
This is important as many filters of dashboards rely on date fields


### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.0-12-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""druid-jdbc"",
      ""druid""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-06-12"",
      ""tag"": ""v0.50.2"",
      ""hash"": ""1a2c2da""
    },
    ""settings"": {
      ""report-timezone"": ""America/Sao_Paulo""
    }
  }
}
```


### Severity

medium

### Additional context

_No response_",renatocron,2024-07-16 00:54:48+00:00,[],2025-02-04 20:28:34+00:00,,https://github.com/metabase/metabase/issues/45616,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Druid', None), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2409684830,issue,open,,Defendpoint Args Destructuring/aliasing Can lead to passing unvalidated Inputs,"Our `defendpoint` macro has a potentially confusing design related to map destructuring in the args.

Take this endpoint for example:

```clojure
(api/defendpoint PUT ""/:id""
  ""Update a Dashboard, and optionally the `dashcards` and `tabs` of a Dashboard. The request body should be a JSON object with the same
  structure as the response from `GET /api/dashboard/:id`.""
  [id :as {{:keys [description name parameters caveats points_of_interest show_in_getting_started enable_embedding
                   embedding_params position width archived collection_id collection_position cache_ttl dashcards tabs]
            :as   dash-updates} :body}]
  {id                      ms/PositiveInt
   name                    [:maybe ms/NonBlankString]
   description             [:maybe :string]
   caveats                 [:maybe :string]
   points_of_interest      [:maybe :string]
   show_in_getting_started [:maybe :boolean]
   enable_embedding        [:maybe :boolean]
   embedding_params        [:maybe ms/EmbeddingParams]
   parameters              [:maybe [:sequential ms/Parameter]]
   position                [:maybe ms/PositiveInt]
   width                   [:maybe [:enum ""fixed"" ""full""]]
   archived                [:maybe :boolean]
   collection_id           [:maybe ms/PositiveInt]
   collection_position     [:maybe ms/PositiveInt]
   cache_ttl               [:maybe ms/PositiveInt]
   dashcards               [:maybe (ms/maps-with-unique-key [:sequential UpdatedDashboardCard] :id)]
   tabs                    [:maybe (ms/maps-with-unique-key [:sequential UpdatedDashboardTab] :id)]}
  (update-dashboard id dash-updates))
```

All of these keys are decoded and validated correctly with the defendpoint macro, but the body of this endpoint calls `update-dashboard` with `id` and `dash-updates`. Here, `id` is correctly decoded/validated, and we pass an integer as expected. However, dash-updates is the shape of the data as it would appear after just running through our server middleware. That is, we pass an un-decoded, un-validated version of the data along. 

This happens because we validate the values in each key, via the symbols defined in the destructuring. However, using `:as dash-updates` doesn't rebuild the map with the coerced values.

This caught me while working on this: https://github.com/metabase/metabase/pull/44454 
And it took me a while to realize that defendpoint was validating things just fine, but later on, things failed to pass the same schema check because it was receiving the undecoded version of the data.

I think I'd like a version of defendpoint that could reconstruct a map with their coerced values, but I suspect that's a bit tricky.
It might make more sense to disallow `:as sym` in the defendpoint args, or perhaps create a linter that warns about the fact that it won't have the coerced values.",adam-james-v,2024-07-15 21:34:34+00:00,[],2024-08-01 13:59:51+00:00,,https://github.com/metabase/metabase/issues/45609,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Misc/API', ''), ('Type:New Feature', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2409438082,issue,open,,Remove hover color from pinned visualizations,"&gt; Perhaps all the hover colors should be removed so that the click targets inside the visualization don’t look interactable?
Yeah I think we should remove hover color, that would be clearer

[Slack Message](https://metaboat.slack.com/archives/C01LQQ2UW03/p1721069532870469?thread_ts=1721065710.900269&cid=C01LQQ2UW03)",rafpaf,2024-07-15 19:13:17+00:00,[],2024-07-15 19:14:14+00:00,,https://github.com/metabase/metabase/issues/45598,"[('Priority:P2', 'Average run of the mill bug')]",[],
2409373344,issue,closed,completed,Sandboxed users that in 49 were able to save questions are not able to do it in 50,"### Describe the bug

A user that could create and save queries in 49 can't do it in 50.11. The error ""You cannot save this Question because you do not have permissions to run its query"" pops up in the saving modal even though permissions are OK to run queries and save into his personal collection

### To Reproduce

1. Spin up 49.20
2. Create a test user and test group. Give an attribute UserID = 1 to the test user and add it to the test group
3. Block data access for All Users group of the Sample Database.  I also gave No Access perms to Our Analytics collection to all users and the test group to match a customer's setup, but I don't think this is relevant to this bug
4. Give Sandboxing permissions to the Orders table for the Test Group, and set the sandboxing to match the UserID
5. See that the user can easily create a question from that data and save it in his personal collection.
6. Upgrade to 50.x (i did it with 50.11)
7. Log in as the test user. Try to save a question from the Orders table into your personal collection. You will see: ""You cannot save this Question because you do not have permissions to run its query"" error. This is not expected


### Expected behavior

User should be able to save the question, as it previously could

### Logs

[de93ec6d-a244-43a0-83b2-e7e2e89c289b] 2024-07-15T15:23:13-03:00 WARN metabase.server.middleware.log POST /api/card 403 41.1 ms (10 DB calls) {:metabase-user-id 2} 
{:via
 [{:type clojure.lang.ExceptionInfo,
   :message ""You cannot save this Question because you do not have permissions to run its query."",
   :data
   {:status-code 403,
    :query
    {:database 1,
     :type ""query"",
     :query
     {:source-table 5,
      :aggregation [[""count""]],
      :breakout
      [[""field"" 35 {:base-type ""type/Float"", :binning {:strategy ""default""}}]
       [""field"" 34 {:base-type ""type/BigInteger""}]]}},
    :required-perms {:perms/create-queries {5 :query-builder}, :perms/view-data :unrestricted},
    :actual-perms
    #{""/collection/namespace/snippets/root/"" ""/collection/root/read/"" ""/collection/4/"" ""/application/subscription/""}},
   :at [metabase.api.card$check_data_permissions_for_query invokeStatic ""card.clj"" 417]}],
 :trace
 [[metabase.api.card$check_data_permissions_for_query invokeStatic ""card.clj"" 417]
  [metabase.api.card$check_data_permissions_for_query invoke ""card.clj"" 407]
  [metabase.api.card$fn__99374 invokeStatic ""card.clj"" 449]
  [metabase.api.card$fn__99374 invoke ""card.clj"" 432]
  [compojure.core$wrap_response$fn__52910 invoke ""core.clj"" 160]
  [compojure.core$wrap_route_middleware$fn__52894 invoke ""core.clj"" 132]
  [compojure.core$wrap_route_info$fn__52899 invoke ""core.clj"" 139]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 151]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 152]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [metabase.server.middleware.auth$enforce_authentication$fn__98244 invoke ""auth.clj"" 18]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52950 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 300]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 153]
  [clojure.lang.Var invoke ""Var.java"" 393]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [metabase.api.routes$fn__104704$fn__104705 invoke ""routes.clj"" 70]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.lang.AFunction$1 doInvoke ""AFunction.java"" 31]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [clojure.lang.AFn applyToHelper ""AFn.java"" 160]
  [clojure.lang.AFn applyTo ""AFn.java"" 144]
  [clojure.core$apply invokeStatic ""core.clj"" 667]
  [clojure.core$apply invoke ""core.clj"" 662]
  [metabase.server.routes$fn__104984$fn__104985 doInvoke ""routes.clj"" 73]
  [clojure.lang.RestFn invoke ""RestFn.java"" 436]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52950 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$wrap_route_matches$fn__52903 invoke ""core.clj"" 153]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 199]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$make_context$handler__52950 invoke ""core.clj"" 290]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 300]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922$f__52923$respond_SINGLEQUOTE___52924 invoke ""core.clj"" 197]
  [compojure.core$make_context$fn__52954 invoke ""core.clj"" 301]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [compojure.core$routes$fn__52922$f__52923 invoke ""core.clj"" 198]
  [compojure.core$routes$fn__52922 invoke ""core.clj"" 200]
  [metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__101123 invoke ""exceptions.clj"" 107]
  [metabase.server.middleware.exceptions$catch_api_exceptions$fn__101120 invoke ""exceptions.clj"" 96]
  [metabase.server.middleware.log$log_api_call$fn__107323$fn__107324$fn__107325 invoke ""log.clj"" 236]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invokeStatic ""diagnostic.clj"" 18]
  [metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info invoke ""diagnostic.clj"" 12]
  [metabase.server.middleware.log$log_api_call$fn__107323$fn__107324 invoke ""log.clj"" 227]
  [toucan2.execute$do_with_call_counts invokeStatic ""execute.clj"" 112]
  [toucan2.execute$do_with_call_counts invoke ""execute.clj"" 103]
  [metabase.server.middleware.log$log_api_call$fn__107323 invoke ""log.clj"" 226]
  [metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__113447 invoke ""browser_cookie.clj"" 40]
  [metabase.server.middleware.security$add_security_headers$fn__101079 invoke ""security.clj"" 238]
  [ring.middleware.json$wrap_json_body$fn__113706 invoke ""json.clj"" 64]
  [metabase.server.middleware.offset_paging$handle_paging$fn__87551 invoke ""offset_paging.clj"" 43]
  [metabase.server.middleware.json$wrap_streamed_json_response$fn__54365 invoke ""json.clj"" 83]
  [ring.middleware.keyword_params$wrap_keyword_params$fn__113795 invoke ""keyword_params.clj"" 55]
  [ring.middleware.params$wrap_params$fn__113814 invoke ""params.clj"" 77]
  [metabase.server.middleware.misc$maybe_set_site_url$fn__70006 invoke ""misc.clj"" 60]
  [metabase.server.middleware.session$reset_session_timeout$fn__77190 invoke ""session.clj"" 552]
  [metabase.server.middleware.session$bind_current_user$fn__77156$fn__77157 invoke ""session.clj"" 446]
  [metabase.server.middleware.session$do_with_current_user invokeStatic ""session.clj"" 425]
  [metabase.server.middleware.session$do_with_current_user invoke ""session.clj"" 408]
  [metabase.server.middleware.session$bind_current_user$fn__77156 invoke ""session.clj"" 445]
  [metabase.server.middleware.session$wrap_current_user_info$fn__77137 invoke ""session.clj"" 383]
  [metabase.server.middleware.session$wrap_session_id$fn__77109 invoke ""session.clj"" 259]
  [metabase.server.middleware.auth$wrap_static_api_key$fn__98252 invoke ""auth.clj"" 32]
  [ring.middleware.cookies$wrap_cookies$fn__113634 invoke ""cookies.clj"" 200]
  [metabase.server.middleware.misc$add_content_type$fn__69988 invoke ""misc.clj"" 28]
  [metabase.server.middleware.misc$disable_streaming_buffering$fn__70014 invoke ""misc.clj"" 77]
  [ring.middleware.gzip$wrap_gzip$fn__113676 invoke ""gzip.clj"" 86]
  [metabase.server.middleware.misc$bind_request$fn__70017 invoke ""misc.clj"" 94]
  [metabase.server.middleware.ssl$redirect_to_https_middleware$fn__113463 invoke ""ssl.clj"" 41]
  [metabase.server$async_proxy_handler$fn__70352 invoke ""server.clj"" 77]
  [metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a handle nil -1]
  [org.eclipse.jetty.server.handler.StatisticsHandler handle ""StatisticsHandler.java"" 173]
  [org.eclipse.jetty.server.handler.HandlerWrapper handle ""HandlerWrapper.java"" 122]
  [org.eclipse.jetty.server.Server handle ""Server.java"" 563]
  [org.eclipse.jetty.server.HttpChannel$RequestDispatchable dispatch ""HttpChannel.java"" 1598]
  [org.eclipse.jetty.server.HttpChannel dispatch ""HttpChannel.java"" 753]
  [org.eclipse.jetty.server.HttpChannel handle ""HttpChannel.java"" 501]
  [org.eclipse.jetty.server.HttpConnection onFillable ""HttpConnection.java"" 287]
  [org.eclipse.jetty.io.AbstractConnection$ReadCallback succeeded ""AbstractConnection.java"" 314]
  [org.eclipse.jetty.io.FillInterest fillable ""FillInterest.java"" 100]
  [org.eclipse.jetty.io.SelectableChannelEndPoint$1 run ""SelectableChannelEndPoint.java"" 53]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy runTask ""AdaptiveExecutionStrategy.java"" 421]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy consumeTask ""AdaptiveExecutionStrategy.java"" 390]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy tryProduce ""AdaptiveExecutionStrategy.java"" 277]
  [org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy run ""AdaptiveExecutionStrategy.java"" 199]
  [org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread run ""ReservedThreadExecutor.java"" 411]
  [org.eclipse.jetty.util.thread.QueuedThreadPool runJob ""QueuedThreadPool.java"" 969]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner doRunJob ""QueuedThreadPool.java"" 1194]
  [org.eclipse.jetty.util.thread.QueuedThreadPool$Runner run ""QueuedThreadPool.java"" 1149]
  [java.lang.Thread run ""Thread.java"" 833]],
 :cause ""You cannot save this Question because you do not have permissions to run its query."",
 :data
 {:status-code 403,
  :query
  {:database 1,
   :type ""query"",
   :query
   {:source-table 5,
    :aggregation [[""count""]],
    :breakout
    [[""field"" 35 {:base-type ""type/Float"", :binning {:strategy ""default""}}]
     [""field"" 34 {:base-type ""type/BigInteger""}]]}},
  :required-perms {:perms/create-queries {5 :query-builder}, :perms/view-data :unrestricted},
  :actual-perms
  #{""/collection/namespace/snippets/root/"" ""/collection/root/read/"" ""/collection/4/"" ""/application/subscription/""}},
 :message ""You cannot save this Question because you do not have permissions to run its query."",
 :query
 {:database 1,
  :type ""query"",
  :query
  {:source-table 5,
   :aggregation [[""count""]],
   :breakout
   [[""field"" 35 {:base-type ""type/Float"", :binning {:strategy ""default""}}]
    [""field"" 34 {:base-type ""type/BigInteger""}]]}},
 :required-perms {:perms/create-queries {5 :query-builder}, :perms/view-data :unrestricted},
 :actual-perms
 #{""/collection/namespace/snippets/root/"" ""/collection/root/read/"" ""/collection/4/"" ""/application/subscription/""}}

### Information about your Metabase installation

```JSON
- 50.11
```


### Severity

P1

### Additional context

Maybe caused by: https://github.com/metabase/metabase/pull/45000 ?",ignacio-mb,2024-07-15 18:36:25+00:00,['johnswanson'],2024-08-02 17:16:24+00:00,2024-07-16 22:36:49+00:00,https://github.com/metabase/metabase/issues/45595,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Permissions', 'Collection or Data permissions'), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2229157583, 'issue_id': 2409373344, 'author': 'ignacio-mb', 'body': 'Was able to reproduce in 50.10 as well.', 'created_at': datetime.datetime(2024, 7, 15, 18, 45, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265825482, 'issue_id': 2409373344, 'author': 'github-actions[bot]', 'body': '🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)', 'created_at': datetime.datetime(2024, 8, 2, 17, 16, 22, tzinfo=datetime.timezone.utc)}]","ignacio-mb (Issue Creator) on (2024-07-15 18:45:47 UTC): Was able to reproduce in 50.10 as well.

github-actions[bot] on (2024-08-02 17:16:22 UTC): 🚀 This should also be released by [v0.50.19](https://github.com/metabase/metabase/milestone/260)

"
2409348879,issue,closed,completed,Datamodel segment history title references a table name instead of the actual segment name,"### Describe the bug

Datamodel segment history title references a table name instead of the actual segment name.
It has been like that since forever.

### To Reproduce

Have a segment based on Orders table, and give it a name (in my case it was ""Orders < 100""

1. Go to `/admin/datamodel/segment/:id/revisions` 
2. Notice that the title references the table (Orders) instead of a segment
![image](https://github.com/user-attachments/assets/5b812813-5c8a-47c2-98c4-50b0e16d7b04)


### Expected behavior

The title should reference a segment name.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master`, 9c02ca6, H2, Sample Database
```


### Severity

P3

### Additional context

_No response_",nemanjaglumac,2024-07-15 18:21:53+00:00,['nemanjaglumac'],2024-10-08 17:02:14+00:00,2024-07-16 07:39:48+00:00,https://github.com/metabase/metabase/issues/45594,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Correctness', ''), ('Administration/Metrics & Segments', ''), ('.Team/Querying', '')]",[],
2409337114,issue,open,,Mobile Styling For EntityPicker,We have[ great designs for mobile](https://www.figma.com/design/ff1z9vhHNtgu1LAPhaa5eF/Entity-Picker-Component?node-id=122-11864&t=lXVEHMCTfptjKajS-0)! let's implement them!,iethree,2024-07-15 18:15:36+00:00,[],2024-07-15 18:17:02+00:00,,https://github.com/metabase/metabase/issues/45592,"[('Organization/', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2409327697,issue,closed,completed,Ability to pass parameters to interactive SQL questions in embedding sdk,Expose the `parameterValues` property to pass parameters to interactive SQL questions.,heypoom,2024-07-15 18:10:03+00:00,['heypoom'],2024-07-17 20:11:23+00:00,2024-07-17 20:11:22+00:00,https://github.com/metabase/metabase/issues/45591,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2234174214, 'issue_id': 2409327697, 'author': 'heypoom', 'body': ""We don't support drill-downs for SQL questions so it's not useful to add parameterValues support. [See the thread here.](https://metaboat.slack.com/archives/C063Q3F1HPF/p1721234527748689)"", 'created_at': datetime.datetime(2024, 7, 17, 20, 11, 22, tzinfo=datetime.timezone.utc)}]","heypoom (Issue Creator) on (2024-07-17 20:11:22 UTC): We don't support drill-downs for SQL questions so it's not useful to add parameterValues support. [See the thread here.](https://metaboat.slack.com/archives/C063Q3F1HPF/p1721234527748689)

"
2409319159,issue,open,,Converge query builder reducer logic with embedding sdk's interactive questions by extracting shared functions,"Tis is a technical task that follows up the changes from supporting multiple instances of interactive questions. We've decoupled the SDK from the QB reducers, as the query builder reducer only supports one query at a time. The upside is that we can support as many instances as needed.

The downside is that there are now 2 duplicate sets of functions/logic for the QB and the reducer. We can address this by extracting the logic into a set of shared functions, so when the QC team make changes to the query builder, the changes are also reflected in the SDK. This still allows room for SDK-specific customizations, but most of the logic can be shared",heypoom,2024-07-15 18:04:53+00:00,[],2025-02-04 20:29:51+00:00,,https://github.com/metabase/metabase/issues/45590,"[('Type:Tech Debt', 'or Refactoring'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2409318499,issue,closed,completed,Fix bigquery driver to pass tests,"Following tests fail for bigquery with `:foreign-keys` removed from codebase:

- `metabase.query-processor-test.explicit-joins-test/joining-nested-queries-with-same-aggregation-test`
- `metabase.query-processor-test.implicit-joins-test/join-multiple-tables-test`
- `metabase.query-processor-test.offset-test/offset-expression-inside-other-expression-test`
- `metabase.query-processor-test.offset-test/offset-expression-test-order-by-parameterized-expression`
- `metabase.query-processor-test.remapping-test/remappings-with-implicit-joins-test`

",lbrdnk,2024-07-15 18:04:29+00:00,['lbrdnk'],2024-10-08 16:20:20+00:00,2024-07-19 11:55:12+00:00,https://github.com/metabase/metabase/issues/45589,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2409314163,issue,closed,completed,Rename theme option for trend and number charts in embedding sdk,Rename theme options from `theme.scalar` to `theme.number` to match the name we use in our main app. This will result in a breaking change. We should also use `theme.trend` for trend chart once those theme options are available.,heypoom,2024-07-15 18:02:06+00:00,['heypoom'],2024-10-08 17:02:10+00:00,2024-07-16 11:55:17+00:00,https://github.com/metabase/metabase/issues/45588,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2409312827,issue,closed,completed,Ability to customize the popover's z-index in embedding sdk,"The popover for click actions gets shown behind the user’s modal. This only happens when the user puts an interactive question in a modal component of their choice.

![Image](https://github.com/user-attachments/assets/20da0c36-a106-40ce-b47e-1368e9f0b5a6)

",heypoom,2024-07-15 18:01:15+00:00,['heypoom'],2024-10-08 16:20:27+00:00,2024-07-18 06:55:21+00:00,https://github.com/metabase/metabase/issues/45587,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2409311743,issue,open,,Handle search API errors in EntityPickerSearch,"- If the entityPicker gets a non-json response from the search api, it crashes
- if the entityPicker gets a non-200 response from search, it loads forever",iethree,2024-07-15 18:00:34+00:00,[],2025-02-05 20:42:54+00:00,,https://github.com/metabase/metabase/issues/45586,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/Search', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2409305211,issue,closed,completed,Expose a React hook to get the authentication state of the embedding sdk,"Expose a React hook to check if we've successfully authenticated via the MetabaseProvider, to support rendering the component conditionally. When the user is not logged in, we see the default error messages added with `withPublicComponentWrapper`. We want to provide the ability to skip rendering the component when the MetabaseProvider authentication fails for any reason.

```tsx
const status = useMetabaseAuthState()
```",heypoom,2024-07-15 17:57:06+00:00,['heypoom'],2024-10-08 17:02:11+00:00,2024-07-16 11:00:33+00:00,https://github.com/metabase/metabase/issues/45585,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2409302363,issue,closed,completed,Fetch request token function does not get updated after first render in the embedding sdk,"The `config.fetchRequestToken` function in the embedding sdk does not synchronize to the Redux context, therefore it always use the function captured from the first render.",heypoom,2024-07-15 17:55:16+00:00,['heypoom'],2024-10-08 17:02:12+00:00,2024-07-16 10:51:48+00:00,https://github.com/metabase/metabase/issues/45583,"[('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]",[],
2409282335,issue,closed,completed,Ensure full testing matrix is covered,"Per the [tech doc](https://www.notion.so/metabase/Query-Validator-d481e94b9f8c49deb1d8c83b0a6de9d6)'s testing plan, we should have tests for the cartesian product of

- Entities:
    - Structured Question
    - Native Question
        - with field filter
        - with variable
        - with snippet
        - with embedded model
- Entity Types:
    - Without Join
    - With Join
    - With saved question as source
    - With invalid field filter
- Errors to catch (where applicable)
    - Bad Field Reference in columns
    - Bad Field Reference in Filter
    - Bad Table Reference
    - Bad source question reference
    - Bad Snippet reference ?",tsmacdonald,2024-07-15 17:43:02+00:00,['tsmacdonald'],2024-11-21 14:20:19+00:00,2024-11-21 14:20:19+00:00,https://github.com/metabase/metabase/issues/45582,"[('.Team/Workflows', 'aka BEC')]",[],
2409179578,issue,closed,not_planned,"In the dashboard picker, when creating a dashboard, the wrong dashboard is chosen when you press enter","When you go to add a question to a dashboard, and you try to create a dashboard through the modal, if you press the enter key rather than clicking select, the wrong dashboard is chosen (the enter key presses the main button on the modal that is behind the modal you're looking at).

https://www.loom.com/share/85925cd6f9f04cfba99a5e401990ca87?sid=aa7ed458-19b0-49f4-a55c-1f586ed038e5",rafpaf,2024-07-15 16:43:34+00:00,[],2024-07-15 17:11:03+00:00,2024-07-15 17:11:03+00:00,https://github.com/metabase/metabase/issues/45579,"[('Priority:P2', 'Average run of the mill bug')]","[{'comment_id': 2228998568, 'issue_id': 2409179578, 'author': 'paoliniluis', 'body': 'dupe of https://github.com/metabase/metabase/issues/43157', 'created_at': datetime.datetime(2024, 7, 15, 17, 11, 3, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-15 17:11:03 UTC): dupe of https://github.com/metabase/metabase/issues/43157

"
2409167661,issue,closed,completed,Segments revision history is broken,"### Describe the bug

Segments revision history is broken.
The loading spinner keeps spinning ad infinitum, and the request fails.

### To Reproduce

1. Go to `admin/datamodel/segments`
2. Create a segment if you don't already have one
3. Click on `...` next to the segment and select ""Revision history""
![image](https://github.com/user-attachments/assets/9cbf84bd-dfe5-49d1-b9d0-b7fe2da2db06)
4. The page is stuck on a loader
![image](https://github.com/user-attachments/assets/47257fcf-a5a7-4451-b15d-22c27881a6b9)

The console has a failed request because the `:entity` parameter is `undefined`
`GET http://localhost:3000/api//1/revisions` returns `400`

The correct URL should be `http://localhost:3000/api/segment/1/revisions`
https://www.metabase.com/docs/latest/api/segment#get-apisegmentidrevisions


### Expected behavior

Segments should load the revision history.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, master, 51c1d83, H2, Sample database
```


### Severity

P1

### Additional context

This is a regression in `master` only. It works correctly in x.50.13.",nemanjaglumac,2024-07-15 16:37:49+00:00,['nemanjaglumac'],2024-10-08 17:02:20+00:00,2024-07-15 19:43:10+00:00,https://github.com/metabase/metabase/issues/45577,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metrics & Segments', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/Querying', '')]",[],
2409156446,issue,open,,Include dashboard tab name information into Metabase Analytics collection,"**Is your feature request related to a problem? Please describe.**
Add dashboard tab information such as the dashboard tab names within Metabase Analytics collection.
As of now, the only place that’s viewable is within the **_“dashboard_tab”_** table in the application database.


**Describe alternatives you've considered**
Add the application database into Metabase, or a view of the necessary tables and bring that into Metabase.


",FilmonK,2024-07-15 16:31:56+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/45576,"[('Type:New Feature', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit')]",[],
2409117112,issue,closed,completed,[FE] Create the new admin page for setup channels (x days),,dpsutton,2024-07-15 16:11:38+00:00,['npfitz'],2024-08-30 04:23:28+00:00,2024-08-30 04:23:02+00:00,https://github.com/metabase/metabase/issues/45574,[],"[{'comment_id': 2319999329, 'issue_id': 2409117112, 'author': 'qnkhuat', 'body': 'PR https://github.com/metabase/metabase/pull/47022', 'created_at': datetime.datetime(2024, 8, 30, 4, 23, 27, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-08-30 04:23:27 UTC): PR https://github.com/metabase/metabase/pull/47022

"
2408955931,issue,closed,completed,Ensure endpoints are admin-only,"The Query Validator tool is only accessible to admins, so the endpoint should be as well. This also neatly sidesteps other perms issues related to card access since admins can see everything anyway.",tsmacdonald,2024-07-15 14:58:19+00:00,['tsmacdonald'],2024-07-16 12:46:49+00:00,2024-07-15 17:52:14+00:00,https://github.com/metabase/metabase/issues/45572,"[('.Team/Workflows', 'aka BEC')]",[],
2408951572,issue,closed,completed,We don't cancel queries when the user closes the tab,"### Describe the bug

While investigating https://github.com/metabase/metabase/issues/15817, I found that we don't cancel the running queries in v50.13 when we close the tab

### To Reproduce

1) spin up v50 with Oracle
2) create a dashboard with sql questions
TIP: USE
```
DECLARE
  v_start TIMESTAMP;
  v_result NUMBER;
BEGIN
  v_start := SYSTIMESTAMP;
  LOOP
    IF SYSTIMESTAMP >= v_start + INTERVAL '60' SECOND THEN
      v_result := 1;
      EXIT;
    END IF;
  END LOOP;
  
  -- 1
  DBMS_OUTPUT.PUT_LINE('Result: ' || v_result);
END;
```
to create queries that take 60 seconds
3) run it
4) close the tab in 30 seconds, on a new tab run the dashboard again

you'll see that there's no cancellation of queries in the logs and also the second dashboard will take more than the first one, since Metabase is still holding the connections

### Expected behavior

We always closed the connections when the tab is closed

### Logs

NA

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

NOTE: I started testing this with Oracle but the same thing happens on postgres and most probably many other databases",paoliniluis,2024-07-15 14:56:25+00:00,[],2024-09-15 13:06:49+00:00,2024-09-15 13:06:49+00:00,https://github.com/metabase/metabase/issues/45571,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]","[{'comment_id': 2233230816, 'issue_id': 2408951572, 'author': 'bshepherdson', 'body': ""Are we sure this used to work at the dashboard level, and not just at the question level?\r\n\r\nNot all drivers (eg. BigQuery) support cancelling the initial query before the first row/page of results is returned; that may apply here. But for every driver we should support cancellation as promptly as possible, and have tests accordingly.\r\n\r\nI suppose this is powered by the browser closing the sockets. We should test that feedback mechanism for each driver, if we don't already."", 'created_at': datetime.datetime(2024, 7, 17, 12, 42, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233272122, 'issue_id': 2408951572, 'author': 'paoliniluis', 'body': ""This worked everywhere according to my memory. It's a P1 as this can end up with lots of questions in a queue"", 'created_at': datetime.datetime(2024, 7, 17, 13, 2, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326463038, 'issue_id': 2408951572, 'author': 'sabyasachinandy', 'body': '@bshepherdson When we used 0.39.6 this used to work for  us with the default presto-jdbc driver for both dashboard and questions. Any help on how we can verify if this is not a driver specific issue? We are using trino starburst driver on 0.50.0', 'created_at': datetime.datetime(2024, 9, 3, 12, 59, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331008708, 'issue_id': 2408951572, 'author': 'lbrdnk', 'body': 'FWIW, it could be worth looking a the traces using `jconsole` to see where those threads are clogged (are they, right?) as described in [this comment](https://github.com/metabase/metabase/issues/45910#issuecomment-2283538552). And also observing the behavior in/after the moment when the limits those variables represent are reached.', 'created_at': datetime.datetime(2024, 9, 5, 9, 11, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2351585666, 'issue_id': 2408951572, 'author': 'paoliniluis', 'body': 'now we do after https://github.com/metabase/metabase/pull/47740', 'created_at': datetime.datetime(2024, 9, 15, 13, 6, 49, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-17 12:42:02 UTC): Are we sure this used to work at the dashboard level, and not just at the question level?

Not all drivers (eg. BigQuery) support cancelling the initial query before the first row/page of results is returned; that may apply here. But for every driver we should support cancellation as promptly as possible, and have tests accordingly.

I suppose this is powered by the browser closing the sockets. We should test that feedback mechanism for each driver, if we don't already.

paoliniluis (Issue Creator) on (2024-07-17 13:02:54 UTC): This worked everywhere according to my memory. It's a P1 as this can end up with lots of questions in a queue

sabyasachinandy on (2024-09-03 12:59:10 UTC): @bshepherdson When we used 0.39.6 this used to work for  us with the default presto-jdbc driver for both dashboard and questions. Any help on how we can verify if this is not a driver specific issue? We are using trino starburst driver on 0.50.0

lbrdnk on (2024-09-05 09:11:48 UTC): FWIW, it could be worth looking a the traces using `jconsole` to see where those threads are clogged (are they, right?) as described in [this comment](https://github.com/metabase/metabase/issues/45910#issuecomment-2283538552). And also observing the behavior in/after the moment when the limits those variables represent are reached.

paoliniluis (Issue Creator) on (2024-09-15 13:06:49 UTC): now we do after https://github.com/metabase/metabase/pull/47740

"
2408896846,issue,open,,"Export feature to export all dashboard cards to png, csv and json","**Is your feature request related to a problem? Please describe.**
A user would want to export all dashboard cards, and if there are many, doesn't want to go card by card exporting each one.

**Describe the solution you'd like**
A feature that lets you export all dashboard cards to png, csv and json at the same time

**Describe alternatives you've considered**
Can be done by API, but there's no direct way either

**How important is this feature to you?**
Requested by a customer, internal ticket: [28709](https://metabase.zendesk.com/agent/tickets/28709) 

**Additional context**
n/a",ignacio-mb,2024-07-15 14:32:02+00:00,[],2024-07-15 14:32:03+00:00,,https://github.com/metabase/metabase/issues/45569,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Reporting/Export', '')]",[],
2408888004,issue,open,,"A model encounters an error during persistence, with logs indicating ""Persistence already present...""","### Describe the bug

I am attempting to persist a model. The query executes quickly (in less than 20 seconds). However, the tools return a timeout error (ERREUR: annulation de la requête à cause du délai écoulé pour l'exécution de l'instruction). The logs do not reflect this timeout error but instead indicate that 'Persistence already present for model xxx.'

### To Reproduce

1. Persist a model

### Expected behavior

The model should be persisted with updated data and should not produce an error.

### Logs

```
[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-15T16:19:39+02:00 INFO metabase.task.persist-refresh Scheduling refresh for model: 252
[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-15T16:19:39+02:00 INFO metabase.task.persist-refresh Persistence already present for model 252 metabase.task.PersistenceRefresh.individual.trigger.150
[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-15T16:19:39+02:00 DEBUG metabase.server.middleware.log POST /api/card/252/refresh 204 10,0 ms (3 DB calls) App DB connections: 0/15 Jetty threads: 4/50 (4 idle, 0 queued) (108 total active threads) Queries in flight: 0 (0 queued) {:metabase-user-id 1}
```

### Information about your Metabase installation

```JSON
Metabase is installed on Windows Server 2016 and is configured for production mode with a MySQL 8 server. It is running version v0.50.12. The database that the model points to is PostgreSQL.

{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""fr"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.36""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-12"",
      ""tag"": ""v0.50.12"",
      ""hash"": ""86d4671""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

 This is important as I'm unable to run my report using these models.

### Additional context

_No response_",vipera7,2024-07-15 14:28:41+00:00,['metamben'],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/45567,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2229433966, 'issue_id': 2408888004, 'author': 'bshepherdson', 'body': 'Need to determine if this is a widespread issue with model persistence. Feel free to lower the priority if the scope is more limited than it appears at first glance.', 'created_at': datetime.datetime(2024, 7, 15, 21, 5, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231920015, 'issue_id': 2408888004, 'author': 'metamben', 'body': '@vipera7, can you please provide more details that could help reproduce the issue? Do you have this problem with just one specific model? Have you experienced any problems querying the model with this issue?', 'created_at': datetime.datetime(2024, 7, 16, 22, 23, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232736981, 'issue_id': 2408888004, 'author': 'vipera7', 'body': 'Of my 7 models, any one might fail at random. I have to refresh multiple times to successfully update them.', 'created_at': datetime.datetime(2024, 7, 17, 8, 29, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2235832981, 'issue_id': 2408888004, 'author': 'vipera7', 'body': 'I wonder if the name of the last model is related to this issue: \r\n\r\n![Sans titre](https://github.com/user-attachments/assets/97a5b6de-2b6e-4bfe-bc0b-cce042808045)', 'created_at': datetime.datetime(2024, 7, 18, 7, 38, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2240107738, 'issue_id': 2408888004, 'author': 'metamben', 'body': ""I created seven models with names in the picture from @vipera7 using MySQL both as app DB and as DW. I used both mbql and native models. I couldn't reproduce the issue."", 'created_at': datetime.datetime(2024, 7, 19, 21, 11, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241142919, 'issue_id': 2408888004, 'author': 'perivamsi', 'body': 'Lowering this to P2 based on the difficulty to repro. Not a widespread issue.\n\n@vipera7 what tools are you referring to when you say ""However, the tools return a timeout error""? Also, what do you see when you go to the url `/admin/tools/model-caching` for these models?', 'created_at': datetime.datetime(2024, 7, 20, 12, 49, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242283432, 'issue_id': 2408888004, 'author': 'vipera7', 'body': ""When I'm referecing to tools, I'm mean on this page : `/admin/tools/model-caching`"", 'created_at': datetime.datetime(2024, 7, 22, 7, 33, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2242582904, 'issue_id': 2408888004, 'author': 'perivamsi', 'body': 'Can you send a screenshot of the error?', 'created_at': datetime.datetime(2024, 7, 22, 10, 7, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243075917, 'issue_id': 2408888004, 'author': 'vipera7', 'body': ""Hello [perivamsi](https://github.com/perivamsi),\r\n\r\nHere is the screenshot \r\n![Capture](https://github.com/user-attachments/assets/219bae0b-282e-430e-a38d-fd13fb627020)\r\n\r\nLog from this refresh: \r\n\r\n```\r\n[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-22T16:14:11+02:00 INFO metabase.task.persist-refresh Error refreshing persisting model with card-id 273,org.postgresql.util.PSQLException: ERREUR: annulation de la requête à cause du délai écoulé pour l'exécution de l'instruction,\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725),\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412),\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371),\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502),\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419),\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194),\tat org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:155),\tat com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502),\tat clojure.java.jdbc$db_do_execute_prepared_statement$fn__42034.invoke(jdbc.clj:1049),\tat clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:860),\tat clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),\tat clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),\tat clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),\tat clojure.java.jdbc$db_do_execute_prepared_statement.invokeStatic(jdbc.clj:1048),\tat clojure.java.jdbc$db_do_execute_prepared_statement.invoke(jdbc.clj:1042),\tat clojure.java.jdbc$db_do_prepared.invokeStatic(jdbc.clj:1080),\tat clojure.java.jdbc$db_do_prepared.invoke(jdbc.clj:1060),\tat clojure.java.jdbc$execute_BANG_$execute_helper__42108.invoke(jdbc.clj:1464),\tat clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1466),\tat clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),\tat clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1456),\tat clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),\tat metabase.driver.sql.ddl$execute_BANG_.invokeStatic(ddl.clj:27),\tat metabase.driver.sql.ddl$execute_BANG_.invoke(ddl.clj:24),\tat metabase.driver.postgres.ddl$fn__85887$fn__85889$fn__85890.invoke(ddl.clj:49),\tat clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:807),\tat clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),\tat clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),\tat clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),\tat metabase.driver.postgres.ddl$fn__85887$fn__85889.invoke(ddl.clj:46),\tat metabase.driver.sql_jdbc.execute$fn__81542$fn__81543.invoke(execute.clj:397),\tat metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337),\tat metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320),\tat metabase.driver.sql_jdbc.execute$fn__81542.invokeStatic(execute.clj:391),\tat metabase.driver.sql_jdbc.execute$fn__81542.invoke(execute.clj:389),\tat clojure.lang.MultiFn.invoke(MultiFn.java:244),\tat metabase.driver.postgres.ddl$fn__85887.invokeStatic(ddl.clj:41),\tat metabase.driver.postgres.ddl$fn__85887.invoke(ddl.clj:38),\tat clojure.lang.MultiFn.invoke(MultiFn.java:244),\tat metabase.task.persist_refresh$reify__86844.refresh_BANG_(persist_refresh.clj:53),\tat metabase.task.persist_refresh$refresh_with_stats_BANG_$fn__86847.invoke(persist_refresh.clj:73),\tat metabase.task.persist_refresh$refresh_with_stats_BANG_.invokeStatic(persist_refresh.clj:72),\tat metabase.task.persist_refresh$refresh_with_stats_BANG_.invoke(persist_refresh.clj:57),\tat clojure.lang.AFn.applyToHelper(AFn.java:165),\tat clojure.lang.AFn.applyTo(AFn.java:144),\tat clojure.core$apply.invokeStatic(core.clj:673),\tat clojure.core$partial$fn__5914.doInvoke(core.clj:2660),\tat clojure.lang.RestFn.invoke(RestFn.java:397),\tat metabase.task.persist_refresh$save_task_history_BANG_$fn__86865.invoke(persist_refresh.clj:123),\tat metabase.models.task_history$do_with_task_history.invokeStatic(task_history.clj:116),\tat metabase.models.task_history$do_with_task_history.invoke(task_history.clj:105),\tat metabase.task.persist_refresh$save_task_history_BANG_.invokeStatic(persist_refresh.clj:115),\tat metabase.task.persist_refresh$save_task_history_BANG_.invoke(persist_refresh.clj:111),\tat metabase.task.persist_refresh$refresh_individual_BANG_.invokeStatic(persist_refresh.clj:219),\tat metabase.task.persist_refresh$refresh_individual_BANG_.invoke(persist_refresh.clj:211),\tat metabase.task.persist_refresh$refresh_job_fn_BANG_.invokeStatic(persist_refresh.clj:235),\tat metabase.task.persist_refresh$refresh_job_fn_BANG_.invoke(persist_refresh.clj:229),\tat metabase.task.persist_refresh.PersistenceRefresh.execute(persist_refresh.clj:245),\tat org.quartz.core.JobRunShell.run(JobRunShell.java:202),\tat org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)\r\n[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-22T16:14:11+02:00 INFO metabase.task.persist-refresh Finished updated model-id 273 from persisted-info 161.\r\n\r\n```"", 'created_at': datetime.datetime(2024, 7, 22, 14, 16, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243085675, 'issue_id': 2408888004, 'author': 'perivamsi', 'body': 'Thank you @vipera7 this is helpful.\r\n\r\nAre you able to run the question based on this model or no? What happens when you try and query the results of the model?', 'created_at': datetime.datetime(2024, 7, 22, 14, 20, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243094803, 'issue_id': 2408888004, 'author': 'vipera7', 'body': 'I can run the query in pgAdmin 4 client, and it takes approximately 17 minutes to complete', 'created_at': datetime.datetime(2024, 7, 22, 14, 24, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243252640, 'issue_id': 2408888004, 'author': 'metamben', 'body': '@vipera7, queries get terminated after 10 minutes during model synchronization and there is no option to increase this timeout. This is done to protect the Metabase instance from unexpectedly large/long running queries.', 'created_at': datetime.datetime(2024, 7, 22, 15, 34, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243277513, 'issue_id': 2408888004, 'author': 'vipera7', 'body': 'Is there any solution ? I have plenty of reports using this model.', 'created_at': datetime.datetime(2024, 7, 22, 15, 46, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2243321250, 'issue_id': 2408888004, 'author': 'metamben', 'body': 'Can the query be optimized? I understand some time ago it was faster than 10 minutes. Did the underlying tables grow that much?\r\n\r\nIf you are willing to fork Metabase, you can of course raise the timeout in `metabase.driver.postgres.ddl/set-statement-timeout!`, but that might de-stabilize Metabase.', 'created_at': datetime.datetime(2024, 7, 22, 16, 7, 42, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-15 21:05:09 UTC): Need to determine if this is a widespread issue with model persistence. Feel free to lower the priority if the scope is more limited than it appears at first glance.

metamben (Assginee) on (2024-07-16 22:23:25 UTC): @vipera7, can you please provide more details that could help reproduce the issue? Do you have this problem with just one specific model? Have you experienced any problems querying the model with this issue?

vipera7 (Issue Creator) on (2024-07-17 08:29:53 UTC): Of my 7 models, any one might fail at random. I have to refresh multiple times to successfully update them.

vipera7 (Issue Creator) on (2024-07-18 07:38:06 UTC): I wonder if the name of the last model is related to this issue: 

![Sans titre](https://github.com/user-attachments/assets/97a5b6de-2b6e-4bfe-bc0b-cce042808045)

metamben (Assginee) on (2024-07-19 21:11:52 UTC): I created seven models with names in the picture from @vipera7 using MySQL both as app DB and as DW. I used both mbql and native models. I couldn't reproduce the issue.

perivamsi on (2024-07-20 12:49:39 UTC): Lowering this to P2 based on the difficulty to repro. Not a widespread issue.

@vipera7 what tools are you referring to when you say ""However, the tools return a timeout error""? Also, what do you see when you go to the url `/admin/tools/model-caching` for these models?

vipera7 (Issue Creator) on (2024-07-22 07:33:51 UTC): When I'm referecing to tools, I'm mean on this page : `/admin/tools/model-caching`

perivamsi on (2024-07-22 10:07:24 UTC): Can you send a screenshot of the error?

vipera7 (Issue Creator) on (2024-07-22 14:16:18 UTC): Hello [perivamsi](https://github.com/perivamsi),

Here is the screenshot 
![Capture](https://github.com/user-attachments/assets/219bae0b-282e-430e-a38d-fd13fb627020)

Log from this refresh: 

```
[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-22T16:14:11+02:00 INFO metabase.task.persist-refresh Error refreshing persisting model with card-id 273,org.postgresql.util.PSQLException: ERREUR: annulation de la requête à cause du délai écoulé pour l'exécution de l'instruction,	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2725),	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2412),	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:371),	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:502),	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:419),	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:194),	at org.postgresql.jdbc.PgPreparedStatement.executeUpdate(PgPreparedStatement.java:155),	at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeUpdate(NewProxyPreparedStatement.java:1502),	at clojure.java.jdbc$db_do_execute_prepared_statement$fn__42034.invoke(jdbc.clj:1049),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:860),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_do_execute_prepared_statement.invokeStatic(jdbc.clj:1048),	at clojure.java.jdbc$db_do_execute_prepared_statement.invoke(jdbc.clj:1042),	at clojure.java.jdbc$db_do_prepared.invokeStatic(jdbc.clj:1080),	at clojure.java.jdbc$db_do_prepared.invoke(jdbc.clj:1060),	at clojure.java.jdbc$execute_BANG_$execute_helper__42108.invoke(jdbc.clj:1464),	at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1466),	at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),	at clojure.java.jdbc$execute_BANG_.invokeStatic(jdbc.clj:1456),	at clojure.java.jdbc$execute_BANG_.invoke(jdbc.clj:1435),	at metabase.driver.sql.ddl$execute_BANG_.invokeStatic(ddl.clj:27),	at metabase.driver.sql.ddl$execute_BANG_.invoke(ddl.clj:24),	at metabase.driver.postgres.ddl$fn__85887$fn__85889$fn__85890.invoke(ddl.clj:49),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:807),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at clojure.java.jdbc$db_transaction_STAR_.invokeStatic(jdbc.clj:789),	at clojure.java.jdbc$db_transaction_STAR_.invoke(jdbc.clj:776),	at metabase.driver.postgres.ddl$fn__85887$fn__85889.invoke(ddl.clj:46),	at metabase.driver.sql_jdbc.execute$fn__81542$fn__81543.invoke(execute.clj:397),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:337),	at metabase.driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:320),	at metabase.driver.sql_jdbc.execute$fn__81542.invokeStatic(execute.clj:391),	at metabase.driver.sql_jdbc.execute$fn__81542.invoke(execute.clj:389),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.driver.postgres.ddl$fn__85887.invokeStatic(ddl.clj:41),	at metabase.driver.postgres.ddl$fn__85887.invoke(ddl.clj:38),	at clojure.lang.MultiFn.invoke(MultiFn.java:244),	at metabase.task.persist_refresh$reify__86844.refresh_BANG_(persist_refresh.clj:53),	at metabase.task.persist_refresh$refresh_with_stats_BANG_$fn__86847.invoke(persist_refresh.clj:73),	at metabase.task.persist_refresh$refresh_with_stats_BANG_.invokeStatic(persist_refresh.clj:72),	at metabase.task.persist_refresh$refresh_with_stats_BANG_.invoke(persist_refresh.clj:57),	at clojure.lang.AFn.applyToHelper(AFn.java:165),	at clojure.lang.AFn.applyTo(AFn.java:144),	at clojure.core$apply.invokeStatic(core.clj:673),	at clojure.core$partial$fn__5914.doInvoke(core.clj:2660),	at clojure.lang.RestFn.invoke(RestFn.java:397),	at metabase.task.persist_refresh$save_task_history_BANG_$fn__86865.invoke(persist_refresh.clj:123),	at metabase.models.task_history$do_with_task_history.invokeStatic(task_history.clj:116),	at metabase.models.task_history$do_with_task_history.invoke(task_history.clj:105),	at metabase.task.persist_refresh$save_task_history_BANG_.invokeStatic(persist_refresh.clj:115),	at metabase.task.persist_refresh$save_task_history_BANG_.invoke(persist_refresh.clj:111),	at metabase.task.persist_refresh$refresh_individual_BANG_.invokeStatic(persist_refresh.clj:219),	at metabase.task.persist_refresh$refresh_individual_BANG_.invoke(persist_refresh.clj:211),	at metabase.task.persist_refresh$refresh_job_fn_BANG_.invokeStatic(persist_refresh.clj:235),	at metabase.task.persist_refresh$refresh_job_fn_BANG_.invoke(persist_refresh.clj:229),	at metabase.task.persist_refresh.PersistenceRefresh.execute(persist_refresh.clj:245),	at org.quartz.core.JobRunShell.run(JobRunShell.java:202),	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
[41fdb96a-1e84-4a49-840f-3e75ae668ac4] 2024-07-22T16:14:11+02:00 INFO metabase.task.persist-refresh Finished updated model-id 273 from persisted-info 161.

```

perivamsi on (2024-07-22 14:20:49 UTC): Thank you @vipera7 this is helpful.

Are you able to run the question based on this model or no? What happens when you try and query the results of the model?

vipera7 (Issue Creator) on (2024-07-22 14:24:52 UTC): I can run the query in pgAdmin 4 client, and it takes approximately 17 minutes to complete

metamben (Assginee) on (2024-07-22 15:34:27 UTC): @vipera7, queries get terminated after 10 minutes during model synchronization and there is no option to increase this timeout. This is done to protect the Metabase instance from unexpectedly large/long running queries.

vipera7 (Issue Creator) on (2024-07-22 15:46:24 UTC): Is there any solution ? I have plenty of reports using this model.

metamben (Assginee) on (2024-07-22 16:07:42 UTC): Can the query be optimized? I understand some time ago it was faster than 10 minutes. Did the underlying tables grow that much?

If you are willing to fork Metabase, you can of course raise the timeout in `metabase.driver.postgres.ddl/set-statement-timeout!`, but that might de-stabilize Metabase.

"
2408878677,issue,closed,completed,Add more tests,"```[tasklist]
### Tasks
- [x] Add question visual tests
- [x] Add analytics test (`background`)
```
",WiNloSt,2024-07-15 14:24:32+00:00,['WiNloSt'],2024-07-16 11:22:12+00:00,2024-07-16 11:22:12+00:00,https://github.com/metabase/metabase/issues/45565,[],[],
2408703746,issue,closed,not_planned,There's a difference between what the logs say and what chrome says in api response time,"### Describe the bug

While trying to see if https://github.com/metabase/metabase/issues/36771 was still a thing, I saw a difference in the time between what the browser and the logs say in response time
![image](https://github.com/user-attachments/assets/7985d645-4a8b-475f-9918-e4aa53a69e74)

When checking the difference, I believe that it's due to the fact that we're returning the results as soon as they come back from the DW, and then we do some other tasks, while the logs report the full response time (time it takes from the DW + some additional tasks), but the browser just takes the time that results come back
![image](https://github.com/user-attachments/assets/b1363048-3db3-406a-9bbe-7605177e133e)

### To Reproduce

1) start 50.13
2) do an x-ray
3) compare logs with browser response

### Expected behavior

we should align on having the same on both ends

### Logs

```
2024-07-15 12:55:19,009 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 1.2 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 11 (0 queued); redshift DB 6 connections: 6/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,079 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 1.2 s (20 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 10 (0 queued); redshift DB 6 connections: 10/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,093 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.2 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 9 (0 queued); redshift DB 6 connections: 11/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,278 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.5 s (19 DB calls) App DB connections: 0/28 Jetty threads: 4/50 (19 idle, 0 queued) (145 total active threads) Queries in flight: 8 (0 queued); redshift DB 6 connections: 0/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,329 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.5 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 7 (0 queued); redshift DB 6 connections: 2/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,341 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.5 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 6 (0 queued); redshift DB 6 connections: 5/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,373 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 1.6 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 5 (0 queued); redshift DB 6 connections: 3/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,455 INFO middleware.exceptions :: Request canceled before finishing.
2024-07-15 12:55:19,457 INFO middleware.exceptions :: Request canceled before finishing.
2024-07-15 12:55:19,409 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: completed] 1.6 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 3 (0 queued); redshift DB 6 connections: 1/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,405 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.5 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 4 (0 queued); redshift DB 6 connections: 9/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,438 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.6 s (20 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 0 (0 queued); redshift DB 6 connections: 7/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,438 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.6 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 0 (0 queued); redshift DB 6 connections: 8/13 (0 threads blocked) {:metabase-user-id 1}
2024-07-15 12:55:19,438 DEBUG middleware.log :: POST /api/dataset 202 [ASYNC: canceled] 1.6 s (19 DB calls) App DB connections: 0/28 Jetty threads: 3/50 (20 idle, 0 queued) (145 total active threads) Queries in flight: 0 (0 queued); redshift DB 6 connections: 4/13 (0 threads blocked) {:metabase-user-id 1}
```

### Information about your Metabase installation

```JSON
v50.13
```


### Severity

P2

### Additional context

NA",paoliniluis,2024-07-15 13:07:14+00:00,[],2025-01-22 14:16:50+00:00,2025-01-22 14:16:50+00:00,https://github.com/metabase/metabase/issues/45554,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Misc/API', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2228523883, 'issue_id': 2408703746, 'author': 'bshepherdson', 'body': ""Theoretically, these times don't line up since there's a network in between. We can't do much about exactly what Chrome measures (especially in the summary in the table; the Timing time for a single request has more details) but we can make sure that our logs are recording the time we want to pay attention to.\r\n\r\nPerhaps we can log both the response time and post-processing time."", 'created_at': datetime.datetime(2024, 7, 15, 13, 35, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228657413, 'issue_id': 2408703746, 'author': 'paoliniluis', 'body': ""considering that this is a local docker stack, this should be almost exactly the same (let's say up to the nanosecond level not to get picky)"", 'created_at': datetime.datetime(2024, 7, 15, 14, 35, 25, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-15 13:35:41 UTC): Theoretically, these times don't line up since there's a network in between. We can't do much about exactly what Chrome measures (especially in the summary in the table; the Timing time for a single request has more details) but we can make sure that our logs are recording the time we want to pay attention to.

Perhaps we can log both the response time and post-processing time.

paoliniluis (Issue Creator) on (2024-07-15 14:35:25 UTC): considering that this is a local docker stack, this should be almost exactly the same (let's say up to the nanosecond level not to get picky)

"
2408650187,issue,closed,not_planned,Allow sorting by error type,Discussion here: https://www.notion.so/Query-Validator-d481e94b9f8c49deb1d8c83b0a6de9d6?d=58b964609ee542a3a8fc8dbbdbf2322f&pvs=4#139106dd91a74104b520bb671345b14a,tsmacdonald,2024-07-15 12:42:10+00:00,[],2024-08-12 12:24:10+00:00,2024-08-12 12:24:10+00:00,https://github.com/metabase/metabase/issues/45552,"[('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2264798195, 'issue_id': 2408650187, 'author': 'crisptrutski', 'body': 'Since we currently group by card, and each card can have multiple error types, it\'s unclear how this ordering would work. While it makes sense as a secondary ordering, that doesn\'t seem that useful. We could ""ungroup"" by card when sorting this way, but that seems a bit surprising and complex.\r\n\r\nAdditional notes related to the  linked thread:\r\n\r\n- We would either need to sort in-memory (I don\'t think this is OK), or rework our two-phase (get cards, get errors) approach. The latter means widening the interface between the webapp and BEC modules, and making it more complex.\r\n- The backend uses error codes rather than messages, which the frontend renders into text. We may want to sort by the rendered messages, so we\'d need to move that mapping to the backend and ideally push it down into the database query.', 'created_at': datetime.datetime(2024, 8, 2, 7, 57, 31, tzinfo=datetime.timezone.utc)}]","crisptrutski on (2024-08-02 07:57:31 UTC): Since we currently group by card, and each card can have multiple error types, it's unclear how this ordering would work. While it makes sense as a secondary ordering, that doesn't seem that useful. We could ""ungroup"" by card when sorting this way, but that seems a bit surprising and complex.

Additional notes related to the  linked thread:

- We would either need to sort in-memory (I don't think this is OK), or rework our two-phase (get cards, get errors) approach. The latter means widening the interface between the webapp and BEC modules, and making it more complex.
- The backend uses error codes rather than messages, which the frontend renders into text. We may want to sort by the rendered messages, so we'd need to move that mapping to the backend and ideally push it down into the database query.

"
2408515164,issue,closed,completed,Query Validator page in Admin App,"```[tasklist]
### Tasks
- [x] EE Accesible page
- [x] Table with results
- [ ] Tests
```
",npfitz,2024-07-15 11:36:40+00:00,['npfitz'],2024-10-08 16:16:00+00:00,2024-08-29 19:20:56+00:00,https://github.com/metabase/metabase/issues/45546,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2407953406,issue,closed,completed,Summarized metric - Custom Expression - Case - Aggregate in 1st param gives an error,"### Describe the bug

In the ""Summarize"" part of a question, if I build a custom expression with a `case` statement that includes an aggregate function in the first parameter, like this: `case(Sum([column1]) = x ...` I get this error : `Expecting expression but found function Sum returning aggregation`

This used to work before. I'm not sure in which release this broke (possibly 0.50).
I have metrics defined this way, used in reports, so these reports are not working anymore.

### To Reproduce

1. Create a new question.
2. In Summarize create a custom expression `case(Sum([column1] = x) ...`
3. See error


### Expected behavior

`case(Sum([column1]) = x ...` should work in custom expressions of a summarized metric.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1053-gke"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.3 (Debian 16.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.3""
      }
    },
    ""run-mode"": ""prod"",
    ""plan-alias"": """",
    ""version"": {
      ""date"": ""2024-07-12"",
      ""tag"": ""v0.50.12"",
      ""hash"": ""86d4671""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking some reports

### Additional context

_No response_",SylvainGravejat,2024-07-15 06:24:55+00:00,['uladzimirdev'],2025-01-24 11:24:48+00:00,2025-01-24 11:24:47+00:00,https://github.com/metabase/metabase/issues/45538,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Hard', ''), ('.Frontend', ''), ('Querying/Notebook/Custom Column', ''), ('.Team/Querying', '')]","[{'comment_id': 2228788638, 'issue_id': 2407953406, 'author': 'annebelleo', 'body': 'I have this as well for v1.49.18 using Filter instead of Summarize. I try to create a custom filter using a case statement and the error states that a boolean is expected. \r\n<img width=""509"" alt=""Screenshot 2024-07-15 at 17 31 04"" src=""https://github.com/user-attachments/assets/55939cd3-e24c-4528-9b58-482f6bd42846"">', 'created_at': datetime.datetime(2024, 7, 15, 15, 32, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228965319, 'issue_id': 2407953406, 'author': 'lbrdnk', 'body': ""@SylvainGravejat, the syntax is `case(condition, value...)`. See [the docs](https://www.metabase.com/docs/latest/questions/query-builder/expressions/case#aggregating-data-based-on-conditions-from-multiple-columns) on how to use case with aggregations.\r\n\r\nWhat you are seeing is a correct behavior. I'm unaware of any recent changes to that.\r\n\r\nI've tried to create a question as you described in query builder in 50.7, with same error. As you wrote that questions as mentioned work on 50.7 for you, could you provide more detailed steps how can I create one? (On the version where it works according to your description.)\r\n\r\n---\r\n\r\n@annebelleo, filter is supposed to work on boolean expressions. The case expression you posted returns string for every row. What you are seeing is correct behavior. That said, I'd advise ask on [discourse](https://discourse.metabase.com/) if you need further clarification."", 'created_at': datetime.datetime(2024, 7, 15, 16, 54, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228996926, 'issue_id': 2407953406, 'author': 'SylvainGravejat', 'body': '@lbrdnk I meant a condition that includes an aggregate. For example `case(sum([column1]) < sum([column2]), ""yes"", ""no"" )` - this should work (as a summarized metric). (I edited the initial description to clarify a bit)', 'created_at': datetime.datetime(2024, 7, 15, 17, 10, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229000985, 'issue_id': 2407953406, 'author': 'lbrdnk', 'body': ""Thanks for updating the description. I'll look into that!"", 'created_at': datetime.datetime(2024, 7, 15, 17, 12, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229062552, 'issue_id': 2407953406, 'author': 'lbrdnk', 'body': 'Can you post full aggregation expression that works on 50.7 and not on 50.12?', 'created_at': datetime.datetime(2024, 7, 15, 17, 49, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229161628, 'issue_id': 2407953406, 'author': 'SylvainGravejat', 'body': ""I only realized there was this bug recently after upgrading from 0.50.7 to 0.50.12, but actually it's possible this broke in an earlier release. (I edited my initial description)\r\n\r\nThe metric formula I have is to cap an aggregate metric at 100% : `case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) < 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]), 1)`\r\n\r\nAnother example, using the metabase database, say I want the number of `report_card` views per creator, but cap it at 1000 views max. If I write this summarize measure formula I get the error : `case(Sum([View Count]) > 1000, 1000, Sum([View Count]))`\r\n![image](https://github.com/user-attachments/assets/29ad7532-33c0-4ba9-b474-e14ccbf32826)"", 'created_at': datetime.datetime(2024, 7, 15, 18, 48, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230324663, 'issue_id': 2407953406, 'author': 'AnabelLeo', 'body': ""Hi All,\r\n\r\n\r\n\r\nI think you made a mistake with the email address. And you should cc'd this\r\nmail:  annebelleo.github.io\r\n<https://github.com/annebelleo/annebelleo.github.io>\r\n\r\n\r\n\r\nI am not sure what is this all about.\r\n\r\n\r\n\r\n\r\n\r\nBest regards,\r\n\r\n*Anabel*\r\nProjects Manager\r\n360Compliance\r\nREGULATORY TESTING\r\nFROM START TO CERTIFICATE\r\n***@***.***\r\n\r\n\r\n\r\n*From:* lbrdnk ***@***.***>\r\n*Sent:* Monday, July 15, 2024 8:50 PM\r\n*To:* metabase/metabase ***@***.***>\r\n*Cc:* AnabelLeo ***@***.***>; Mention <\r\n***@***.***>\r\n*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -\r\nCase - Aggregate in 1st param gives an error (Issue #45538)\r\n\r\n\r\n\r\nCan you post full aggregation expression that that works on 50.7 and not on\r\n50.12?\r\n\r\n—\r\nReply to this email directly, view it on GitHub\r\n<https://github.com/metabase/metabase/issues/45538#issuecomment-2229062552>,\r\nor unsubscribe\r\n<https://github.com/notifications/unsubscribe-auth/BBPHHOTVR5I43BAKRK25QG3ZMQDTBAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRZGA3DENJVGI>\r\n.\r\nYou are receiving this because you were mentioned.Message ID: <\r\n***@***.***>"", 'created_at': datetime.datetime(2024, 7, 16, 8, 31, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230576550, 'issue_id': 2407953406, 'author': 'lbrdnk', 'body': ""Thanks for further input.\r\n\r\nI've attempted reproduction on _sample database, venues_ using expressions as follow:\r\n\r\n1. `case(Sum([Latitude]) > 10, 10, Sum([Latitude]))`\r\n2. `case(Sum([Latitude]) / Sum([Longitude]) > 10, 10, Sum([Latitude]) / Sum([Longitude]))`\r\n\r\nExpression 1 does not work. Expression 2 seems to work correctly.\r\n\r\nSearching for the error in the codebase leads to [metabase-lib/v1/expressions/resolver.js](https://github.com/metabase/metabase/blob/1e5bef2a0c17bfb90aaf68c608c395b4111417cb/frontend/src/metabase-lib/v1/expressions/resolver.js). I suspect the first case is mishandled in `resolve` function.\r\n\r\nHence routing the issue to QC."", 'created_at': datetime.datetime(2024, 7, 16, 10, 39, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230701069, 'issue_id': 2407953406, 'author': 'kamilmielnik', 'body': '> `case(Sum([Latitude]) > 10, 10, Sum([Latitude]))`\r\n\r\nThis never worked (I checked v50, v49, v48, v47, v46, v45, v44).\r\n\r\n----\r\n\r\n> The metric formula I have is to cap an aggregate metric at 100% : `case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) < 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]), 1)`\r\n\r\nFor now this can be worked around by creating a custom column (with `case`) after the aggregations, and then hiding the original aggregation column(s) in the visualization:\r\n\r\nhttps://github.com/user-attachments/assets/3b495e05-7a98-4cff-bd3c-b8ab1a826448', 'created_at': datetime.datetime(2024, 7, 16, 11, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230704467, 'issue_id': 2407953406, 'author': 'SylvainGravejat', 'body': ""Thank you @lbrdnk, I confirm your findings. The formula for my metric was :\r\n\r\n`case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) <= 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]), 1)`\r\n\r\nThat didn't work (but used to work).\r\nAfter switching it around to the below formula, it works:\r\n\r\n`case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) > 1, 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]))`"", 'created_at': datetime.datetime(2024, 7, 16, 11, 54, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230705919, 'issue_id': 2407953406, 'author': 'AnabelLeo', 'body': ""Hi Everyone\r\n\r\n\r\n\r\nCould you please remove me from the emails ?\r\n\r\n\r\n\r\nI don’t have an idea what all this emails about and I think you got the\r\nemail address wrong.\r\n\r\n\r\n\r\n\r\n\r\nBest regards,\r\n\r\n*Anabel*\r\nProjects Manager\r\n360Compliance\r\nREGULATORY TESTING\r\nFROM START TO CERTIFICATE\r\n***@***.***\r\n\r\n\r\n\r\n*From:* Kamil Mielnik ***@***.***>\r\n*Sent:* Tuesday, July 16, 2024 2:53 PM\r\n*To:* metabase/metabase ***@***.***>\r\n*Cc:* AnabelLeo ***@***.***>; Mention <\r\n***@***.***>\r\n*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -\r\nCase - Aggregate in 1st param gives an error (Issue #45538)\r\n\r\n\r\n\r\nThis never worked (I checked v50, v49, v48, v47, v46, v45, v44).\r\nI don't think we ever meant to support aggregations in case, so this looks\r\nlike a feature request.\r\n------------------------------\r\n\r\nThe metric formula I have is to cap an aggregate metric at 100% :\r\ncase(Sum([Actual\r\nContainers Created]) / Sum([Contract Daily Committed Containers]) < 1,\r\nSum([Actual Containers Created]) / Sum([Contract Daily Committed\r\nContainers]), 1)\r\n\r\nFor now this can be worked around by creating a custom column (with case)\r\nafter the aggregations, and then hiding the original aggregation column(s)\r\nin the visualization:\r\n\r\nhttps://github.com/user-attachments/assets/3b495e05-7a98-4cff-bd3c-b8ab1a826448\r\n\r\n—\r\nReply to this email directly, view it on GitHub\r\n<https://github.com/metabase/metabase/issues/45538#issuecomment-2230701069>,\r\nor unsubscribe\r\n<https://github.com/notifications/unsubscribe-auth/BBPHHOSWTAR3PFZ44MYBWU3ZMUCTFAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZQG4YDCMBWHE>\r\n.\r\nYou are receiving this because you were mentioned.Message ID: <\r\n***@***.***>"", 'created_at': datetime.datetime(2024, 7, 16, 11, 55, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230707768, 'issue_id': 2407953406, 'author': 'lbrdnk', 'body': '[AnabelLeo](https://github.com/AnabelLeo), unfortunately no. Please hit unsubscribe at the bottom of the email. Sorry for inconvenience.', 'created_at': datetime.datetime(2024, 7, 16, 11, 56, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230729152, 'issue_id': 2407953406, 'author': 'AnabelLeo', 'body': '@Mention ***@***.***> I cant do unsubscribe because I don’t\r\neven have an account in the github.. im not sure how you got to my email\r\n\r\n\r\n\r\n\r\n\r\nBest regards,\r\n\r\n*Anabel*\r\nProjects Manager\r\n360Compliance\r\nREGULATORY TESTING\r\nFROM START TO CERTIFICATE\r\n***@***.***\r\n\r\n\r\n\r\n*From:* lbrdnk ***@***.***>\r\n*Sent:* Tuesday, July 16, 2024 2:57 PM\r\n*To:* metabase/metabase ***@***.***>\r\n*Cc:* AnabelLeo ***@***.***>; Mention <\r\n***@***.***>\r\n*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -\r\nCase - Aggregate in 1st param gives an error (Issue #45538)\r\n\r\n\r\n\r\nAnabelLeo <https://github.com/AnabelLeo>, unfortunately no. Please hit\r\nunsubscribe at the bottom of the email. Sorry for inconvenience.\r\n\r\n—\r\nReply to this email directly, view it on GitHub\r\n<https://github.com/metabase/metabase/issues/45538#issuecomment-2230707768>,\r\nor unsubscribe\r\n<https://github.com/notifications/unsubscribe-auth/BBPHHOXWA64SJN6VPSWFW6DZMUDBXAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZQG4YDONZWHA>\r\n.\r\nYou are receiving this because you were mentioned.Message ID: <\r\n***@***.***>', 'created_at': datetime.datetime(2024, 7, 16, 12, 8, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2230885677, 'issue_id': 2407953406, 'author': 'kamilmielnik', 'body': 'Changed to P2 based on [Slack conversation](https://metaboat.slack.com/archives/C07BWMG9C8M/p1721135470917849?thread_ts=1721126443.379079&cid=C07BWMG9C8M)', 'created_at': datetime.datetime(2024, 7, 16, 13, 24, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612292046, 'issue_id': 2407953406, 'author': 'uladzimirdev', 'body': 'Both FE and BE changes were merged to master, so I expect this issue to be fully resolved in the next release (52.8).', 'created_at': datetime.datetime(2025, 1, 24, 11, 24, 47, tzinfo=datetime.timezone.utc)}]","annebelleo on (2024-07-15 15:32:46 UTC): I have this as well for v1.49.18 using Filter instead of Summarize. I try to create a custom filter using a case statement and the error states that a boolean is expected. 
<img width=""509"" alt=""Screenshot 2024-07-15 at 17 31 04"" src=""https://github.com/user-attachments/assets/55939cd3-e24c-4528-9b58-482f6bd42846"">

lbrdnk on (2024-07-15 16:54:11 UTC): @SylvainGravejat, the syntax is `case(condition, value...)`. See [the docs](https://www.metabase.com/docs/latest/questions/query-builder/expressions/case#aggregating-data-based-on-conditions-from-multiple-columns) on how to use case with aggregations.

What you are seeing is a correct behavior. I'm unaware of any recent changes to that.

I've tried to create a question as you described in query builder in 50.7, with same error. As you wrote that questions as mentioned work on 50.7 for you, could you provide more detailed steps how can I create one? (On the version where it works according to your description.)

---

@annebelleo, filter is supposed to work on boolean expressions. The case expression you posted returns string for every row. What you are seeing is correct behavior. That said, I'd advise ask on [discourse](https://discourse.metabase.com/) if you need further clarification.

SylvainGravejat (Issue Creator) on (2024-07-15 17:10:05 UTC): @lbrdnk I meant a condition that includes an aggregate. For example `case(sum([column1]) < sum([column2]), ""yes"", ""no"" )` - this should work (as a summarized metric). (I edited the initial description to clarify a bit)

lbrdnk on (2024-07-15 17:12:32 UTC): Thanks for updating the description. I'll look into that!

lbrdnk on (2024-07-15 17:49:15 UTC): Can you post full aggregation expression that works on 50.7 and not on 50.12?

SylvainGravejat (Issue Creator) on (2024-07-15 18:48:06 UTC): I only realized there was this bug recently after upgrading from 0.50.7 to 0.50.12, but actually it's possible this broke in an earlier release. (I edited my initial description)

The metric formula I have is to cap an aggregate metric at 100% : `case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) < 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]), 1)`

Another example, using the metabase database, say I want the number of `report_card` views per creator, but cap it at 1000 views max. If I write this summarize measure formula I get the error : `case(Sum([View Count]) > 1000, 1000, Sum([View Count]))`
![image](https://github.com/user-attachments/assets/29ad7532-33c0-4ba9-b474-e14ccbf32826)

AnabelLeo on (2024-07-16 08:31:26 UTC): Hi All,



I think you made a mistake with the email address. And you should cc'd this
mail:  annebelleo.github.io
<https://github.com/annebelleo/annebelleo.github.io>



I am not sure what is this all about.





Best regards,

*Anabel*
Projects Manager
360Compliance
REGULATORY TESTING
FROM START TO CERTIFICATE
***@***.***



*From:* lbrdnk ***@***.***>
*Sent:* Monday, July 15, 2024 8:50 PM
*To:* metabase/metabase ***@***.***>
*Cc:* AnabelLeo ***@***.***>; Mention <
***@***.***>
*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -
Case - Aggregate in 1st param gives an error (Issue #45538)



Can you post full aggregation expression that that works on 50.7 and not on
50.12?

—
Reply to this email directly, view it on GitHub
<https://github.com/metabase/metabase/issues/45538#issuecomment-2229062552>,
or unsubscribe
<https://github.com/notifications/unsubscribe-auth/BBPHHOTVR5I43BAKRK25QG3ZMQDTBAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMRZGA3DENJVGI>
.
You are receiving this because you were mentioned.Message ID: <
***@***.***>

lbrdnk on (2024-07-16 10:39:17 UTC): Thanks for further input.

I've attempted reproduction on _sample database, venues_ using expressions as follow:

1. `case(Sum([Latitude]) > 10, 10, Sum([Latitude]))`
2. `case(Sum([Latitude]) / Sum([Longitude]) > 10, 10, Sum([Latitude]) / Sum([Longitude]))`

Expression 1 does not work. Expression 2 seems to work correctly.

Searching for the error in the codebase leads to [metabase-lib/v1/expressions/resolver.js](https://github.com/metabase/metabase/blob/1e5bef2a0c17bfb90aaf68c608c395b4111417cb/frontend/src/metabase-lib/v1/expressions/resolver.js). I suspect the first case is mishandled in `resolve` function.

Hence routing the issue to QC.

kamilmielnik on (2024-07-16 11:53:00 UTC): This never worked (I checked v50, v49, v48, v47, v46, v45, v44).

----


For now this can be worked around by creating a custom column (with `case`) after the aggregations, and then hiding the original aggregation column(s) in the visualization:

https://github.com/user-attachments/assets/3b495e05-7a98-4cff-bd3c-b8ab1a826448

SylvainGravejat (Issue Creator) on (2024-07-16 11:54:56 UTC): Thank you @lbrdnk, I confirm your findings. The formula for my metric was :

`case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) <= 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]), 1)`

That didn't work (but used to work).
After switching it around to the below formula, it works:

`case(Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]) > 1, 1, Sum([Actual Containers Created]) / Sum([Contract Daily Committed Containers]))`

AnabelLeo on (2024-07-16 11:55:49 UTC): Hi Everyone



Could you please remove me from the emails ?



I don’t have an idea what all this emails about and I think you got the
email address wrong.





Best regards,

*Anabel*
Projects Manager
360Compliance
REGULATORY TESTING
FROM START TO CERTIFICATE
***@***.***



*From:* Kamil Mielnik ***@***.***>
*Sent:* Tuesday, July 16, 2024 2:53 PM
*To:* metabase/metabase ***@***.***>
*Cc:* AnabelLeo ***@***.***>; Mention <
***@***.***>
*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -
Case - Aggregate in 1st param gives an error (Issue #45538)



This never worked (I checked v50, v49, v48, v47, v46, v45, v44).
I don't think we ever meant to support aggregations in case, so this looks
like a feature request.
------------------------------

The metric formula I have is to cap an aggregate metric at 100% :
case(Sum([Actual
Containers Created]) / Sum([Contract Daily Committed Containers]) < 1,
Sum([Actual Containers Created]) / Sum([Contract Daily Committed
Containers]), 1)

For now this can be worked around by creating a custom column (with case)
after the aggregations, and then hiding the original aggregation column(s)
in the visualization:

https://github.com/user-attachments/assets/3b495e05-7a98-4cff-bd3c-b8ab1a826448

—
Reply to this email directly, view it on GitHub
<https://github.com/metabase/metabase/issues/45538#issuecomment-2230701069>,
or unsubscribe
<https://github.com/notifications/unsubscribe-auth/BBPHHOSWTAR3PFZ44MYBWU3ZMUCTFAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZQG4YDCMBWHE>
.
You are receiving this because you were mentioned.Message ID: <
***@***.***>

lbrdnk on (2024-07-16 11:56:52 UTC): [AnabelLeo](https://github.com/AnabelLeo), unfortunately no. Please hit unsubscribe at the bottom of the email. Sorry for inconvenience.

AnabelLeo on (2024-07-16 12:08:39 UTC): @Mention ***@***.***> I cant do unsubscribe because I don’t
even have an account in the github.. im not sure how you got to my email





Best regards,

*Anabel*
Projects Manager
360Compliance
REGULATORY TESTING
FROM START TO CERTIFICATE
***@***.***



*From:* lbrdnk ***@***.***>
*Sent:* Tuesday, July 16, 2024 2:57 PM
*To:* metabase/metabase ***@***.***>
*Cc:* AnabelLeo ***@***.***>; Mention <
***@***.***>
*Subject:* Re: [metabase/metabase] Summarized metric - Custom Expression -
Case - Aggregate in 1st param gives an error (Issue #45538)



AnabelLeo <https://github.com/AnabelLeo>, unfortunately no. Please hit
unsubscribe at the bottom of the email. Sorry for inconvenience.

—
Reply to this email directly, view it on GitHub
<https://github.com/metabase/metabase/issues/45538#issuecomment-2230707768>,
or unsubscribe
<https://github.com/notifications/unsubscribe-auth/BBPHHOXWA64SJN6VPSWFW6DZMUDBXAVCNFSM6AAAAABK34WVV6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDEMZQG4YDONZWHA>
.
You are receiving this because you were mentioned.Message ID: <
***@***.***>

kamilmielnik on (2024-07-16 13:24:55 UTC): Changed to P2 based on [Slack conversation](https://metaboat.slack.com/archives/C07BWMG9C8M/p1721135470917849?thread_ts=1721126443.379079&cid=C07BWMG9C8M)

uladzimirdev (Assginee) on (2025-01-24 11:24:47 UTC): Both FE and BE changes were merged to master, so I expect this issue to be fully resolved in the next release (52.8).

"
2407933723,issue,closed,completed,Add back field usage tracking,"Temporarily disabled in https://github.com/metabase/metabase/pull/45536. We need to add it back with proper performance.

As diagnosed in this [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1720897344735799), a large portion of the processing time is in `field-usage/pmbql->field-usages` call, we need to find a way to optimize this.

Epic where we added field usage: https://github.com/metabase/metabase/issues/38229",qnkhuat,2024-07-15 06:09:53+00:00,['qnkhuat'],2024-09-09 12:06:18+00:00,2024-08-29 04:20:53+00:00,https://github.com/metabase/metabase/issues/45537,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2227762055, 'issue_id': 2407933723, 'author': 'qnkhuat', 'body': '@bshepherdson said he had a few ideas for optimization', 'created_at': datetime.datetime(2024, 7, 15, 6, 10, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228500487, 'issue_id': 2407933723, 'author': 'bshepherdson', 'body': 'The most immediate things we can do are:\r\n- Make this processing (not just the DB call) async, and running after the `/query` response is complete.\r\n    - That\'s imperfect, since during a burst of queries like a dashboard load the CPU will be tied up doing this postprocessing for earlier queries and slowing the response for future queries.\r\n- We only need the underlying field ID, so we don\'t need to call `aggregation-column` etc. in cases where the field ref already has the numeric ID (common, but not universal).\r\n- We might be able to instrument the query processor itself somehow to record every field it touches into an `(atom #{})`? That\'s probably more fragile than it\'s worth.\r\n\r\nZooming out a bit, the set of used field refs is nearly fixed, but sandboxing and parameters (and more?) can add new filters. Presumably those count as field usages that we want to capture, so they prevent us from just recording `used_fields` on each saved question and model, effectively caching most of this work. We would still need to run this analysis to find the ""extras"", and there\'s no way to tell a sandboxing filter apart from an original part of the query by its `:field` ref.\r\n\r\nZooming out even further, this is suffering from a big weakness of the design of MBQL lib. That is, that field refs are merely symbolic, not pointers to the columns in memory. That fact has many consequences, but the ones relevant here are that in order to understand eg. a `:field` ref in a filter:\r\n    - we must (expensively) compute the `visible-columns` for the stage (which can easily be 100 columns!)\r\n    - run `lib.equality/find-matching-column` to compare the filter\'s ref against each such column.\r\n\r\nThat last is the Real Fix, in my opinion, but that\'s a long road. For the near term like v51, I think the `grouper` change to make this a background batch job instead of linking it to the query processing is sufficient to make this acceptably fast.', 'created_at': datetime.datetime(2024, 7, 15, 13, 24, 52, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-07-15 06:10:16 UTC): @bshepherdson said he had a few ideas for optimization

bshepherdson on (2024-07-15 13:24:52 UTC): The most immediate things we can do are:
- Make this processing (not just the DB call) async, and running after the `/query` response is complete.
    - That's imperfect, since during a burst of queries like a dashboard load the CPU will be tied up doing this postprocessing for earlier queries and slowing the response for future queries.
- We only need the underlying field ID, so we don't need to call `aggregation-column` etc. in cases where the field ref already has the numeric ID (common, but not universal).
- We might be able to instrument the query processor itself somehow to record every field it touches into an `(atom #{})`? That's probably more fragile than it's worth.

Zooming out a bit, the set of used field refs is nearly fixed, but sandboxing and parameters (and more?) can add new filters. Presumably those count as field usages that we want to capture, so they prevent us from just recording `used_fields` on each saved question and model, effectively caching most of this work. We would still need to run this analysis to find the ""extras"", and there's no way to tell a sandboxing filter apart from an original part of the query by its `:field` ref.

Zooming out even further, this is suffering from a big weakness of the design of MBQL lib. That is, that field refs are merely symbolic, not pointers to the columns in memory. That fact has many consequences, but the ones relevant here are that in order to understand eg. a `:field` ref in a filter:
    - we must (expensively) compute the `visible-columns` for the stage (which can easily be 100 columns!)
    - run `lib.equality/find-matching-column` to compare the filter's ref against each such column.

That last is the Real Fix, in my opinion, but that's a long road. For the near term like v51, I think the `grouper` change to make this a background batch job instead of linking it to the query processing is sufficient to make this acceptably fast.

"
2407537375,issue,open,,Keep alive the request for long running queries (websockets on /query and /dataset),"For long running questions/dashboard queries, have a mechanism so that the infra/cloud provider/firewall network timeout does not kick in and abort the query.

More context in this previous ticket https://github.com/metabase/metabase/issues/12423",perivamsi,2024-07-14 18:03:51+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/45531,"[('Database/', ''), ('Type:New Feature', ''), ('Operation/', '')]","[{'comment_id': 2227461320, 'issue_id': 2407537375, 'author': 'j-ro', 'body': ""Plus one for this. Noting, per my comment in the previous ticket, I'm not quite sure keepalive is exactly the method that will work here. The cloud provider in question (Cloudflare) has a hard timeout on long running request of 90 seconds or so. I think what's needed is more of a mechanism where the metabase backend can run the query against various data sources, and the frontend polls for updates with short requests, and displays results when the request finishes, or something like that. That way one request that waits until data is available is not needed, at least from the frontend's perspective."", 'created_at': datetime.datetime(2024, 7, 14, 19, 35, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228896265, 'issue_id': 2407537375, 'author': 'paoliniluis', 'body': ""@j-ro why are you using cloudflare? why can't your queries finish in less than 90s?"", 'created_at': datetime.datetime(2024, 7, 15, 16, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228899416, 'issue_id': 2407537375, 'author': 'j-ro', 'body': '@paoliniluis we use Cloudflare to put Metabase behind Cloudflare Access/Zero Trust, so only internal staff, properly authenticated, can access it. We run arbitrary queries on a large cloud data warehouse (Redshift) with a lot of data (hundreds of billions of rows in some cases). Sometimes 90 seconds is not enough.', 'created_at': datetime.datetime(2024, 7, 15, 16, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2583123913, 'issue_id': 2407537375, 'author': 'troyharvey', 'body': '@j-ro is spot on.\n\nCould we get an update on support for async queries described in this issue? We have a complex http network stack in our Metabase deployment. Extending http timeout settings across all layers is challenging and not ideal.', 'created_at': datetime.datetime(2025, 1, 10, 16, 14, 45, tzinfo=datetime.timezone.utc)}]","j-ro on (2024-07-14 19:35:05 UTC): Plus one for this. Noting, per my comment in the previous ticket, I'm not quite sure keepalive is exactly the method that will work here. The cloud provider in question (Cloudflare) has a hard timeout on long running request of 90 seconds or so. I think what's needed is more of a mechanism where the metabase backend can run the query against various data sources, and the frontend polls for updates with short requests, and displays results when the request finishes, or something like that. That way one request that waits until data is available is not needed, at least from the frontend's perspective.

paoliniluis on (2024-07-15 16:19:17 UTC): @j-ro why are you using cloudflare? why can't your queries finish in less than 90s?

j-ro on (2024-07-15 16:21:00 UTC): @paoliniluis we use Cloudflare to put Metabase behind Cloudflare Access/Zero Trust, so only internal staff, properly authenticated, can access it. We run arbitrary queries on a large cloud data warehouse (Redshift) with a lot of data (hundreds of billions of rows in some cases). Sometimes 90 seconds is not enough.

troyharvey on (2025-01-10 16:14:45 UTC): @j-ro is spot on.

Could we get an update on support for async queries described in this issue? We have a complex http network stack in our Metabase deployment. Extending http timeout settings across all layers is challenging and not ideal.

"
2407516708,issue,closed,not_planned,Metabase v0.50.12 broken migration,"### Describe the bug

When updating to the latest version of Metabase, v0.50.12 one migration fails to execute due to sql error.

Tried going back to version v0.50.11 but got stuck in the same migration somehow.

Finally went back to v0.50.10 then it booted up no problems.

### To Reproduce

1. Have the version v0.50.10 installed
2. Restart Pod and get the latest image or update to the latest version v0.50.12
3. Se error then booting up the server

### Expected behavior

The migrations should run as expected and the server would run without problems.

### Logs

[service.log](https://github.com/user-attachments/files/16228145/service.log)


### Information about your Metabase installation

```JSON
- GCP K8s with metabase/metabase:latest image
```


### Severity

Blocking usage

### Additional context

_No response_",truckpad-dev,2024-07-14 17:02:17+00:00,[],2024-07-15 03:19:45+00:00,2024-07-15 03:19:45+00:00,https://github.com/metabase/metabase/issues/45530,"[('Type:Bug', 'Product defects'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2227633264, 'issue_id': 2407516708, 'author': 'qnkhuat', 'body': ""Please update your Postgres version to 12+ and try again. 11.22 has gone out of support 8 months ago https://endoflife.date/postgresql\r\n\r\nParticularly we need the generated column feature that's introduced on PG 12"", 'created_at': datetime.datetime(2024, 7, 15, 3, 11, 41, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-07-15 03:11:41 UTC): Please update your Postgres version to 12+ and try again. 11.22 has gone out of support 8 months ago https://endoflife.date/postgresql

Particularly we need the generated column feature that's introduced on PG 12

"
2407350808,issue,open,,Problem connecting to MongoDB with selfsigned certificate,"### Describe the bug

Hey there, I've tried to add a database to metabase to connect using Selfsigned certificate but when I paste SSL certificate chain , I get following error : signed overrun, bytes = 1820
FYI : I've pasted certificate in the following format and my certificate is RSA 4096 : 
-----BEGIN RSA PRIVATE KEY-----
xxxx
-----END RSA PRIVATE KEY-----
-----BEGIN CERTIFICATE-----
xxx
-----END CERTIFICATE-----

this exact format is working on mongo compass and other tools fine

### To Reproduce

just try connection mongo to metabase using SSL pem files


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version : 0.47.10
```


### Severity

annoying

### Additional context

_No response_",hosseinabaiyani,2024-07-14 09:38:19+00:00,[],2025-02-04 20:25:12+00:00,,https://github.com/metabase/metabase/issues/45529,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2407281746,issue,closed,completed,Add hungarian translation,"**Context**

Hi All,

I have managed to fix the Hungarian translation.  Can you please add it in the next minor ? 

see https://poeditor.com/projects/po_edit?id_language=65&id=200535

",istvano,2024-07-14 06:00:37+00:00,[],2024-08-30 08:59:56+00:00,2024-08-30 08:59:56+00:00,https://github.com/metabase/metabase/issues/45528,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2407078608,issue,closed,not_planned,Duplicate Dashboard with Action,"### Describe the bug

Guys, I went to duplicate a dashboard that has actions and it gave the image error, if I fill in some parameters like description or archived via the api, is it possible to duplicate a dashboard with action?

![bug metabase dashboard duplicate](https://github.com/user-attachments/assets/116c295d-984a-4063-913d-d1def74b3ab7)


### To Reproduce

1. Go to your Dashboard that has Action
2. Click on Duplicate Dashboard
3. See this error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase version: v0.49.20
```


### Severity

Low Severity

### Additional context

_No response_",MateusRamos10,2024-07-13 17:57:17+00:00,[],2024-07-23 15:45:08+00:00,2024-07-23 15:45:08+00:00,https://github.com/metabase/metabase/issues/45525,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', ''), ('.Backend', ''), ('Querying/Actions', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2229418601, 'issue_id': 2407078608, 'author': 'bshepherdson', 'body': 'Needs investigation to see whether this is a FE or BE issue.', 'created_at': datetime.datetime(2024, 7, 15, 20, 56, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233761039, 'issue_id': 2407078608, 'author': 'kulyk', 'body': 'Possibly a duplicate of #38224', 'created_at': datetime.datetime(2024, 7, 17, 16, 52, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2245604801, 'issue_id': 2407078608, 'author': 'kulyk', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/38224', 'created_at': datetime.datetime(2024, 7, 23, 15, 45, 8, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-07-15 20:56:35 UTC): Needs investigation to see whether this is a FE or BE issue.

kulyk on (2024-07-17 16:52:35 UTC): Possibly a duplicate of #38224

kulyk on (2024-07-23 15:45:08 UTC): Duplicate of https://github.com/metabase/metabase/issues/38224

"
2406924362,issue,open,,Incorrect sorting of NULL values in pivot tables: nulls are sorted as literal string 'NULL',"### Describe the bug

When sorting a pivot table on a column that contains sql null values, these rows end up in the middle of the results. It seems Metabase sorts sql null values as literal ""NULL"" strings.

![image](https://github.com/user-attachments/assets/b4dd74d4-952b-4acf-9858-751da26d11af)


### To Reproduce

1. Create a question with an aggregate and a group by on a string column that contains a null value
2. Select Pivot table as visualization
3. Sort by the string column that has null values
4. The row with null is sorted between rows with M and O.


### Expected behavior

When sorted, nulls should be consistently at top or at bottom of results.

### Logs

- Browser: nothing
- Server: nothing

### Information about your Metabase installation

```JSON
- Firefox 127.0.2
- Windows 11
- Postgres 14
- Metabase 0.50.12
- Metabase internal database: Postgres 14
```


### Severity

Worse than annoying because null values can get overlooked.

### Additional context

_No response_",janfrederik,2024-07-13 13:24:16+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/45524,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2406566525,issue,closed,completed,Float value in the TTL will break migration,"### Describe the bug

If you set a fractional value in the min TTL or ttl ratio you won't be able to migrate to v50

### To Reproduce

1) spin up v49
2) set min ttl or ttl ratio to 0.5
3) move to v50

### Expected behavior

_No response_

### Logs

```
metabase-mysql1       | 2024-07-13 01:01:07,648 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:09::piranha encountered an exception.
metabase-mysql1       | liquibase.exception.DatabaseException: (conn=8) Truncated incorrect INTEGER value: '0.5' [Failed SQL: (1292) UPDATE cache_config
metabase-mysql1       |    SET config = json_object(
metabase-mysql1       |            'multiplier', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-ttl-ratio'), 10),
metabase-mysql1       |            'min_duration_ms', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-min-ttl'), 60000)
metabase-mysql1       |          )
metabase-mysql1       |  WHERE model = 'root' AND
metabase-mysql1       |        model_id = 0 AND
metabase-mysql1       |        strategy = 'ttl' AND
metabase-mysql1       |        (json_extract(config, '$.multiplier') = 0 OR
metabase-mysql1       |         json_extract(config, '$.min_duration_ms') = 0)]
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
metabase-mysql1       | 	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
metabase-mysql1       | 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
metabase-mysql1       | 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
metabase-mysql1       | 	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
metabase-mysql1       | 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:252)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:256)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
metabase-mysql1       | 	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
metabase-mysql1       | 	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
metabase-mysql1       | 	at liquibase.command.CommandScope.execute(CommandScope.java:217)
metabase-mysql1       | 	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:234)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:212)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:194)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44522.invoke(liquibase.clj:360)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked$reify__44518.run(liquibase.clj:325)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_$fn__53458.invoke(setup.clj:84)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44459.invoke(liquibase.clj:140)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:425)
metabase-mysql1       | 	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
metabase-mysql1       | 	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_$fn__53486$fn__53487.invoke(setup.clj:167)
metabase-mysql1       | 	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
metabase-mysql1       | 	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_$fn__53486.invoke(setup.clj:161)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_$fn__53511.invoke(db.clj:86)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:421)
metabase-mysql1       | 	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
metabase-mysql1       | 	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
metabase-mysql1       | 	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
metabase-mysql1       | 	at metabase.core$init_BANG_.invoke(core.clj:165)
metabase-mysql1       | 	at metabase.core$start_normally.invokeStatic(core.clj:182)
metabase-mysql1       | 	at metabase.core$start_normally.invoke(core.clj:176)
metabase-mysql1       | 	at metabase.core$entrypoint.invokeStatic(core.clj:215)
metabase-mysql1       | 	at metabase.core$entrypoint.doInvoke(core.clj:209)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:397)
metabase-mysql1       | 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
metabase-mysql1       | 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
metabase-mysql1       | 	at clojure.lang.Var.applyTo(Var.java:705)
metabase-mysql1       | 	at clojure.core$apply.invokeStatic(core.clj:667)
metabase-mysql1       | 	at clojure.core$apply.invoke(core.clj:662)
metabase-mysql1       | 	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
metabase-mysql1       | 	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:397)
metabase-mysql1       | 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
metabase-mysql1       | 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
metabase-mysql1       | 	at metabase.bootstrap.main(Unknown Source)
metabase-mysql1       | Caused by: java.sql.SQLSyntaxErrorException: (conn=8) Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
metabase-mysql1       | 	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
metabase-mysql1       | 	... 86 more
metabase-mysql1       | Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
metabase-mysql1       | 	... 89 more
metabase-mysql1       | Caused by: java.sql.SQLException: Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
metabase-mysql1       | 	... 90 more
metabase-mysql1       | 
metabase-mysql1       | UPDATE SUMMARY
metabase-mysql1       | Run:                         80
metabase-mysql1       | Previously run:             315
metabase-mysql1       | Filtered out:                 5
metabase-mysql1       | -------------------------------
metabase-mysql1       | Total change sets:          400
metabase-mysql1       | 
metabase-mysql1       | 
metabase-mysql1       | FILTERED CHANGE SETS SUMMARY
metabase-mysql1       | DBMS mismatch:                5
metabase-mysql1       | 
metabase-mysql1       | 2024-07-13 01:01:07,687 ERROR metabase.core :: Metabase Initialization FAILED
metabase-mysql1       | liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:09::piranha:
metabase-mysql1       |      Reason: liquibase.exception.DatabaseException: (conn=8) Truncated incorrect INTEGER value: '0.5' [Failed SQL: (1292) UPDATE cache_config
metabase-mysql1       |    SET config = json_object(
metabase-mysql1       |            'multiplier', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-ttl-ratio'), 10),
metabase-mysql1       |            'min_duration_ms', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-min-ttl'), 60000)
metabase-mysql1       |          )
metabase-mysql1       |  WHERE model = 'root' AND
metabase-mysql1       |        model_id = 0 AND
metabase-mysql1       |        strategy = 'ttl' AND
metabase-mysql1       |        (json_extract(config, '$.multiplier') = 0 OR
metabase-mysql1       |         json_extract(config, '$.min_duration_ms') = 0)]
metabase-mysql1       | 	at liquibase.command.CommandScope.execute(CommandScope.java:253)
metabase-mysql1       | 	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.Liquibase.runInScope(Liquibase.java:1419)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:234)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:212)
metabase-mysql1       | 	at liquibase.Liquibase.update(Liquibase.java:194)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_$fn__44522.invoke(liquibase.clj:360)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked$reify__44518.run(liquibase.clj:325)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked.invokeStatic(liquibase.clj:318)
metabase-mysql1       | 	at metabase.db.liquibase$run_in_scope_locked.invoke(liquibase.clj:301)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:349)
metabase-mysql1       | 	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:342)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_$fn__53458.invoke(setup.clj:84)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase$f_STAR___44459.invoke(liquibase.clj:140)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:143)
metabase-mysql1       | 	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:131)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:73)
metabase-mysql1       | 	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:55)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:425)
metabase-mysql1       | 	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:149)
metabase-mysql1       | 	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:144)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_$fn__53486$fn__53487.invoke(setup.clj:167)
metabase-mysql1       | 	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
metabase-mysql1       | 	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_$fn__53486.invoke(setup.clj:161)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:160)
metabase-mysql1       | 	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_$fn__53511.invoke(db.clj:86)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:81)
metabase-mysql1       | 	at metabase.db$setup_db_BANG_.doInvoke(db.clj:68)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:421)
metabase-mysql1       | 	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:117)
metabase-mysql1       | 	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)
metabase-mysql1       | 	at metabase.core$init_BANG_.invokeStatic(core.clj:170)
metabase-mysql1       | 	at metabase.core$init_BANG_.invoke(core.clj:165)
metabase-mysql1       | 	at metabase.core$start_normally.invokeStatic(core.clj:182)
metabase-mysql1       | 	at metabase.core$start_normally.invoke(core.clj:176)
metabase-mysql1       | 	at metabase.core$entrypoint.invokeStatic(core.clj:215)
metabase-mysql1       | 	at metabase.core$entrypoint.doInvoke(core.clj:209)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:397)
metabase-mysql1       | 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
metabase-mysql1       | 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
metabase-mysql1       | 	at clojure.lang.Var.applyTo(Var.java:705)
metabase-mysql1       | 	at clojure.core$apply.invokeStatic(core.clj:667)
metabase-mysql1       | 	at clojure.core$apply.invoke(core.clj:662)
metabase-mysql1       | 	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
metabase-mysql1       | 	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
metabase-mysql1       | 	at clojure.lang.RestFn.invoke(RestFn.java:397)
metabase-mysql1       | 	at clojure.lang.AFn.applyToHelper(AFn.java:152)
metabase-mysql1       | 	at clojure.lang.RestFn.applyTo(RestFn.java:132)
metabase-mysql1       | 	at metabase.bootstrap.main(Unknown Source)
metabase-mysql1       | Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:09::piranha:
metabase-mysql1       |      Reason: liquibase.exception.DatabaseException: (conn=8) Truncated incorrect INTEGER value: '0.5' [Failed SQL: (1292) UPDATE cache_config
metabase-mysql1       |    SET config = json_object(
metabase-mysql1       |            'multiplier', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-ttl-ratio'), 10),
metabase-mysql1       |            'min_duration_ms', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-min-ttl'), 60000)
metabase-mysql1       |          )
metabase-mysql1       |  WHERE model = 'root' AND
metabase-mysql1       |        model_id = 0 AND
metabase-mysql1       |        strategy = 'ttl' AND
metabase-mysql1       |        (json_extract(config, '$.multiplier') = 0 OR
metabase-mysql1       |         json_extract(config, '$.min_duration_ms') = 0)]
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
metabase-mysql1       | 	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
metabase-mysql1       | 	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
metabase-mysql1       | 	at liquibase.command.CommandScope.execute(CommandScope.java:217)
metabase-mysql1       | 	... 58 more
metabase-mysql1       | Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v50.2024-06-12T12:33:09::piranha:
metabase-mysql1       |      Reason: liquibase.exception.DatabaseException: (conn=8) Truncated incorrect INTEGER value: '0.5' [Failed SQL: (1292) UPDATE cache_config
metabase-mysql1       |    SET config = json_object(
metabase-mysql1       |            'multiplier', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-ttl-ratio'), 10),
metabase-mysql1       |            'min_duration_ms', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-min-ttl'), 60000)
metabase-mysql1       |          )
metabase-mysql1       |  WHERE model = 'root' AND
metabase-mysql1       |        model_id = 0 AND
metabase-mysql1       |        strategy = 'ttl' AND
metabase-mysql1       |        (json_extract(config, '$.multiplier') = 0 OR
metabase-mysql1       |         json_extract(config, '$.min_duration_ms') = 0)]
metabase-mysql1       | 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
metabase-mysql1       | 	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
metabase-mysql1       | 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
metabase-mysql1       | 	at liquibase.Scope.lambda$child$0(Scope.java:186)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:195)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:185)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:164)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:252)
metabase-mysql1       | 	at liquibase.Scope.child(Scope.java:256)
metabase-mysql1       | 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
metabase-mysql1       | 	... 66 more
metabase-mysql1       | Caused by: liquibase.exception.DatabaseException: (conn=8) Truncated incorrect INTEGER value: '0.5' [Failed SQL: (1292) UPDATE cache_config
metabase-mysql1       |    SET config = json_object(
metabase-mysql1       |            'multiplier', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-ttl-ratio'), 10),
metabase-mysql1       |            'min_duration_ms', coalesce((select cast(`value` as unsigned) from setting where `key` = 'query-caching-min-ttl'), 60000)
metabase-mysql1       |          )
metabase-mysql1       |  WHERE model = 'root' AND
metabase-mysql1       |        model_id = 0 AND
metabase-mysql1       |        strategy = 'ttl' AND
metabase-mysql1       |        (json_extract(config, '$.multiplier') = 0 OR
metabase-mysql1       |         json_extract(config, '$.min_duration_ms') = 0)]
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:470)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:77)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor.execute(JdbcExecutor.java:179)
metabase-mysql1       | 	at liquibase.executor.AbstractExecutor.execute(AbstractExecutor.java:141)
metabase-mysql1       | 	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1285)
metabase-mysql1       | 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
metabase-mysql1       | 	... 81 more
metabase-mysql1       | Caused by: java.sql.SQLSyntaxErrorException: (conn=8) Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
metabase-mysql1       | 	at com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)
metabase-mysql1       | 	at liquibase.executor.jvm.JdbcExecutor$ExecuteStatementCallback.doInStatement(JdbcExecutor.java:464)
metabase-mysql1       | 	... 86 more
metabase-mysql1       | Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
metabase-mysql1       | 	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
metabase-mysql1       | 	... 89 more
metabase-mysql1       | Caused by: java.sql.SQLException: Truncated incorrect INTEGER value: '0.5'
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
metabase-mysql1       | 	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
metabase-mysql1       | 	... 90 more
metabase-mysql1       | 2024-07-13 01:01:07,692 INFO metabase.core :: Metabase Shutting Down ...
metabase-mysql1       | 2024-07-13 01:01:07,695 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
metabase-mysql1       | 2024-07-13 01:01:07,708 WARN db.liquibase :: ()
metabase-mysql1       | 2024-07-13 01:01:07,713 INFO metabase.core :: Metabase Shutdown COMPLETE

```

### Information about your Metabase installation

```JSON
v50
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-07-13 01:06:25+00:00,['qnkhuat'],2024-07-16 02:21:20+00:00,2024-07-15 13:32:38+00:00,https://github.com/metabase/metabase/issues/45520,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/MySQL', None), ('Querying/Cache', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2227816114, 'issue_id': 2406566525, 'author': 'qnkhuat', 'body': 'This only affects mysql instances', 'created_at': datetime.datetime(2024, 7, 15, 6, 58, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2227843562, 'issue_id': 2406566525, 'author': 'darksciencebase', 'body': ""(here's this bug's FE friend btw https://github.com/metabase/metabase/issues/45519)"", 'created_at': datetime.datetime(2024, 7, 15, 7, 18, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228469171, 'issue_id': 2406566525, 'author': 'crisptrutski', 'body': '> This only affects mysql instances\r\n\r\nAnd H2 right?', 'created_at': datetime.datetime(2024, 7, 15, 13, 9, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228485915, 'issue_id': 2406566525, 'author': 'qnkhuat', 'body': ""yea, you're right :)"", 'created_at': datetime.datetime(2024, 7, 15, 13, 17, 54, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-07-15 06:58:30 UTC): This only affects mysql instances

darksciencebase on (2024-07-15 07:18:57 UTC): (here's this bug's FE friend btw https://github.com/metabase/metabase/issues/45519)

crisptrutski on (2024-07-15 13:09:21 UTC): And H2 right?

qnkhuat (Assginee) on (2024-07-15 13:17:54 UTC): yea, you're right :)

"
2406542506,issue,closed,completed,Float value in TTL returns an error in the FE,"### Describe the bug

If you set a float in the TTL you will get a BE error in the FE
![image](https://github.com/user-attachments/assets/4eabee7b-ba56-42ea-90c7-4bf452f0f79f)

### To Reproduce

1) just go to 49 and enter a float in the TTL box

### Expected behavior

We should not allow users to enter floats

### Logs

```
{
    ""via"": [
        {
            ""type"": ""java.lang.AssertionError"",
            ""message"": ""Assert failed: (or (integer? new-value) (and (string? new-value) (re-matches #\""^-?\\d+$\"" new-value)))"",
            ""at"": [
                ""metabase.models.setting$fn__47024"",
                ""invokeStatic"",
                ""setting.clj"",
                808
            ]
        }
    ],
    ""trace"": [
        [
            ""metabase.models.setting$fn__47024"",
            ""invokeStatic"",
            ""setting.clj"",
            808
        ],
        [
            ""metabase.models.setting$fn__47024"",
            ""invoke"",
            ""setting.clj"",
            803
        ],
        [
            ""clojure.lang.MultiFn"",
            ""invoke"",
            ""MultiFn.java"",
            239
        ],
        [
            ""clojure.core$partial$fn__5908"",
            ""invoke"",
            ""core.clj"",
            2642
        ],
        [
            ""clojure.core$partial$fn__5908"",
            ""invoke"",
            ""core.clj"",
            2641
        ],
        [
            ""metabase.models.setting$set_with_audit_logging_BANG_"",
            ""invokeStatic"",
            ""setting.clj"",
            896
        ],
        [
            ""metabase.models.setting$set_with_audit_logging_BANG_"",
            ""invoke"",
            ""setting.clj"",
            884
        ],
        [
            ""metabase.models.setting$set_BANG_"",
            ""invokeStatic"",
            ""setting.clj"",
            924
        ],
        [
            ""metabase.models.setting$set_BANG_"",
            ""doInvoke"",
            ""setting.clj"",
            900
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            425
        ],
        [
            ""metabase.api.setting$fn__99789$fn__99792"",
            ""invoke"",
            ""setting.clj"",
            59
        ],
        [
            ""metabase.api.setting$do_with_setting_access_control"",
            ""invokeStatic"",
            ""setting.clj"",
            14
        ],
        [
            ""metabase.api.setting$do_with_setting_access_control"",
            ""invoke"",
            ""setting.clj"",
            10
        ],
        [
            ""metabase.api.setting$fn__99789"",
            ""invokeStatic"",
            ""setting.clj"",
            58
        ],
        [
            ""metabase.api.setting$fn__99789"",
            ""invoke"",
            ""setting.clj"",
            53
        ],
        [
            ""compojure.core$wrap_response$fn__45015"",
            ""invoke"",
            ""core.clj"",
            160
        ],
        [
            ""compojure.core$wrap_route_middleware$fn__44999"",
            ""invoke"",
            ""core.clj"",
            132
        ],
        [
            ""compojure.core$wrap_route_info$fn__45004"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""compojure.core$wrap_route_matches$fn__45008"",
            ""invoke"",
            ""core.clj"",
            151
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.auth$enforce_authentication$fn__95154"",
            ""invoke"",
            ""auth.clj"",
            17
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__45055"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.api.routes$fn__103220$fn__103221"",
            ""invoke"",
            ""routes.clj"",
            65
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            667
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""metabase.server.routes$fn__103385$fn__103386"",
            ""doInvoke"",
            ""routes.clj"",
            72
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__45055"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__45008"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__45008"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__45008"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__45055"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028$respond_SINGLEQUOTE___45029"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__45059"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__45027$f__45028"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__45027"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99898"",
            ""invoke"",
            ""exceptions.clj"",
            108
        ],
        [
            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__99895"",
            ""invoke"",
            ""exceptions.clj"",
            96
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__105711$fn__105712$fn__105713"",
            ""invoke"",
            ""log.clj"",
            230
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invokeStatic"",
            ""diagnostic.clj"",
            18
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invoke"",
            ""diagnostic.clj"",
            12
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__105711$fn__105712"",
            ""invoke"",
            ""log.clj"",
            222
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invokeStatic"",
            ""execute.clj"",
            112
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invoke"",
            ""execute.clj"",
            103
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__105711"",
            ""invoke"",
            ""log.clj"",
            221
        ],
        [
            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__110549"",
            ""invoke"",
            ""browser_cookie.clj"",
            40
        ],
        [
            ""metabase.server.middleware.security$add_security_headers$fn__99854"",
            ""invoke"",
            ""security.clj"",
            182
        ],
        [
            ""metabase.server.middleware.json$wrap_json_body$fn__46372"",
            ""invoke"",
            ""json.clj"",
            67
        ],
        [
            ""metabase.server.middleware.offset_paging$handle_paging$fn__86052"",
            ""invoke"",
            ""offset_paging.clj"",
            43
        ],
        [
            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__46390"",
            ""invoke"",
            ""json.clj"",
            103
        ],
        [
            ""ring.middleware.keyword_params$wrap_keyword_params$fn__110816"",
            ""invoke"",
            ""keyword_params.clj"",
            55
        ],
        [
            ""ring.middleware.params$wrap_params$fn__110835"",
            ""invoke"",
            ""params.clj"",
            77
        ],
        [
            ""metabase.server.middleware.misc$maybe_set_site_url$fn__67651"",
            ""invoke"",
            ""misc.clj"",
            61
        ],
        [
            ""metabase.server.middleware.session$reset_session_timeout$fn__73084"",
            ""invoke"",
            ""session.clj"",
            546
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__73050$fn__73051"",
            ""invoke"",
            ""session.clj"",
            440
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invokeStatic"",
            ""session.clj"",
            419
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invoke"",
            ""session.clj"",
            403
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__73050"",
            ""invoke"",
            ""session.clj"",
            439
        ],
        [
            ""metabase.server.middleware.session$wrap_current_user_info$fn__73033"",
            ""invoke"",
            ""session.clj"",
            378
        ],
        [
            ""metabase.server.middleware.session$wrap_session_id$fn__73005"",
            ""invoke"",
            ""session.clj"",
            257
        ],
        [
            ""metabase.server.middleware.auth$wrap_static_api_key$fn__95162"",
            ""invoke"",
            ""auth.clj"",
            30
        ],
        [
            ""ring.middleware.cookies$wrap_cookies$fn__110736"",
            ""invoke"",
            ""cookies.clj"",
            194
        ],
        [
            ""metabase.server.middleware.misc$add_content_type$fn__67633"",
            ""invoke"",
            ""misc.clj"",
            29
        ],
        [
            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__67659"",
            ""invoke"",
            ""misc.clj"",
            78
        ],
        [
            ""ring.middleware.gzip$wrap_gzip$fn__110778"",
            ""invoke"",
            ""gzip.clj"",
            86
        ],
        [
            ""metabase.server.middleware.misc$bind_request$fn__67662"",
            ""invoke"",
            ""misc.clj"",
            95
        ],
        [
            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__110565"",
            ""invoke"",
            ""ssl.clj"",
            51
        ],
        [
            ""metabase.server$async_proxy_handler$fn__68073"",
            ""invoke"",
            ""server.clj"",
            78
        ],
        [
            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
            ""handle"",
            null,
            -1
        ],
        [
            ""org.eclipse.jetty.server.handler.StatisticsHandler"",
            ""handle"",
            ""StatisticsHandler.java"",
            173
        ],
        [
            ""org.eclipse.jetty.server.handler.HandlerWrapper"",
            ""handle"",
            ""HandlerWrapper.java"",
            122
        ],
        [
            ""org.eclipse.jetty.server.Server"",
            ""handle"",
            ""Server.java"",
            563
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
            ""dispatch"",
            ""HttpChannel.java"",
            1598
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""dispatch"",
            ""HttpChannel.java"",
            753
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""handle"",
            ""HttpChannel.java"",
            501
        ],
        [
            ""org.eclipse.jetty.server.HttpConnection"",
            ""onFillable"",
            ""HttpConnection.java"",
            287
        ],
        [
            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
            ""succeeded"",
            ""AbstractConnection.java"",
            314
        ],
        [
            ""org.eclipse.jetty.io.FillInterest"",
            ""fillable"",
            ""FillInterest.java"",
            100
        ],
        [
            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
            ""run"",
            ""SelectableChannelEndPoint.java"",
            53
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""runTask"",
            ""AdaptiveExecutionStrategy.java"",
            421
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""consumeTask"",
            ""AdaptiveExecutionStrategy.java"",
            390
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""tryProduce"",
            ""AdaptiveExecutionStrategy.java"",
            277
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""run"",
            ""AdaptiveExecutionStrategy.java"",
            199
        ],
        [
            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
            ""run"",
            ""ReservedThreadExecutor.java"",
            411
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
            ""runJob"",
            ""QueuedThreadPool.java"",
            969
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""doRunJob"",
            ""QueuedThreadPool.java"",
            1194
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""run"",
            ""QueuedThreadPool.java"",
            1149
        ],
        [
            ""java.lang.Thread"",
            ""run"",
            ""Thread.java"",
            829
        ]
    ],
    ""cause"": ""Assert failed: (or (integer? new-value) (and (string? new-value) (re-matches #\""^-?\\d+$\"" new-value)))"",
    ""message"": ""Assert failed: (or (integer? new-value) (and (string? new-value) (re-matches #\""^-?\\d+$\"" new-value)))""
}
```

### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-07-13 00:49:54+00:00,[],2025-01-22 14:17:47+00:00,2025-01-22 14:17:32+00:00,https://github.com/metabase/metabase/issues/45519,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2607370273, 'issue_id': 2406542506, 'author': 'luizarakaki', 'body': 'This was fixed with the cache new UI', 'created_at': datetime.datetime(2025, 1, 22, 14, 17, 46, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2025-01-22 14:17:46 UTC): This was fixed with the cache new UI

"
2406104236,issue,open,,Improve Release Code Testing/etc in CI,"- [x] move release unit tests to a separate job so they can run in isolation from the whole frontend test suite
- [x] add a check to make sure that the release bundle builds properly in CI
- [x] run type checks in CI for release dir
- [ ] enable linting and prettier in release directory
",iethree,2024-07-12 18:05:14+00:00,[],2025-01-17 20:29:46+00:00,,https://github.com/metabase/metabase/issues/45501,[],[],
2406019654,issue,open,,Title fonts are cut off when exporting a card as png from a dashboard,"### Describe the bug

When exporting a card as png from a dashboard, the font is cut off, as seen here
<img width=""468"" alt=""image"" src=""https://github.com/user-attachments/assets/051efcf9-a914-40b5-8cb1-3b80beb68432"">


### To Reproduce

See examples here https://metaboat.slack.com/archives/C01LQQ2UW03/p1720803141264079

I was able to reproduce this in a combo chart, row chart with a single series, and line chart with multiple series 

### Expected behavior

It should look fine and not cut off

### Logs

_No response_

### Information about your Metabase installation

```JSON
Hash: e1e8e0c
```


### Severity

P3

### Additional context

_No response_",cbalusek,2024-07-12 17:15:39+00:00,[],2025-02-04 20:31:50+00:00,,https://github.com/metabase/metabase/issues/45499,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Limitation', ''), ('Reporting/Export', ''), ('.Frontend', ''), ('Visualization/Static', 'Subscriptions/pulse generated image'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2405838800,issue,open,,Logging: Standardize the order of factors in log lines,"**Is your feature request related to a problem? Please describe.**
Our logs are pretty standard, but the log lines are different if we pull an entity from the application database or if we make a query to the DW, which makes a lot of sense, but it makes logs parsing a pain

**Describe the solution you'd like**
Standardize the log lines. All lines should have the async thing and dbs they hit with the connections in the end of the log line (possibly as a map or a json), so for the ones that hit the app db send how many connections we used and how many are blocked, so both operations have the same amount of concepts in the log lines:

e.g.
2024-07-11 16:54:15,276 DEBUG middleware.log :: GET /api/public/dashboard/xxxxxxxxxxxxx/dashcard/104/card/141 202 [ASYNC: completed] 541.9 ms (22 DB calls) App DB connections: 1/15 Jetty threads: 3/50 (17 idle, 0 queued) (144 total active threads) Queries in flight: 18 (0 queued); mysql DB 3 connections: 2/3 (0 threads blocked)

should be transformed to
2024-07-11 16:54:15,276 DEBUG middleware.log :: GET /api/public/dashboard/xxxxxxxxxxxxx/dashcard/104/card/141 202 [ASYNC: completed] 541.9 ms (22 DB calls) Jetty threads: 3/50 (17 idle, 0 queued) (144 total active threads) Queries in flight: 18 (0 queued); {mysql DB 3 connections: 2/3 (0 threads blocked), App DB connections: 1/15 (0 threads blocked)}

or
2024-07-11 16:54:14,134 DEBUG middleware.log :: GET /api/public/dashboard/xxxxxxxxxxxxx 200 59.3 ms (10 DB calls) App DB connections: 1/15 Jetty threads: 4/50 (3 idle, 0 queued) (112 total active threads) Queries in flight: 0 (0 queued)

should be transformed to
2024-07-11 16:54:14,134 DEBUG middleware.log :: GET /api/public/dashboard/xxxxxxxxxxxxx 200 [ASYNC: completed] 59.3 ms (10 DB calls) Jetty threads: 4/50 (3 idle, 0 queued) (112 total active threads) Queries in flight: 0 (0 queued); {App DB connections: 1/15 (0 threads blocked)}

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Ease the process of parsing log lines",paoliniluis,2024-07-12 15:14:44+00:00,[],2025-02-04 20:30:31+00:00,,https://github.com/metabase/metabase/issues/45494,"[('Type:New Feature', ''), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]",[],
2405817106,issue,open,,Logging: Standardize separators (eg ;),"**Is your feature request related to a problem? Please describe.**
The current logs don't have standard separators, so I end up having to do some crazy stuff to parse it decently. We should have a standard separator in the logs, e.g, a semi colon

**Describe the solution you'd like**
Log lines should have separators between each concept

**Describe alternatives you've considered**
NA

**How important is this feature to you?**
Ease the log parsing process

**Additional context**
NA
",paoliniluis,2024-07-12 15:03:20+00:00,[],2025-02-04 20:30:11+00:00,,https://github.com/metabase/metabase/issues/45491,"[('Type:New Feature', ''), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]",[],
2405811860,issue,open,,Logging: Standardize time to milliseconds,"**Is your feature request related to a problem? Please describe.**
When I do log parsing, api response time can be milliseconds, picoseconds or seconds so I need to start converting stuff. We should always log in milliseconds

**Describe the solution you'd like**
Always log times in milliseconds

**Describe alternatives you've considered**
I need to do conversions and it's a mess

**How important is this feature to you?**
I want to make log parsing easy

**Additional context**
NA
",paoliniluis,2024-07-12 15:00:28+00:00,[],2025-02-04 20:30:44+00:00,,https://github.com/metabase/metabase/issues/45490,"[('Type:New Feature', ''), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]",[],
2405810814,issue,closed,not_planned,Error al descargar archivo .xlsx,"Tengo un error al desczrgar el archivo no se descarga bien y ademas sale el siguiente mensaje en mi excel

![image](https://github.com/user-attachments/assets/99fe6a8b-1c1e-40bc-bc2b-991720d2297c)

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?
Note: the more honest and specific you are here the more we will take you seriously.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""es-ES"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""1.8.0_292-b10"",
    ""java.vendor"": ""Red Hat, Inc."",
    ""java.vendor.url"": ""https://www.redhat.com/"",
    ""java.version"": ""1.8.0_292"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""25.292-b10"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.18.0-240.22.1.el8_3.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.28-MariaDB""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.6.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""tag"": ""v0.41.0"",
      ""date"": ""2021-10-06"",
      ""branch"": ""release-x.41.x"",
      ""hash"": ""c529fe2""
    },
    ""settings"": {
      ""report-timezone"": ""America/Bogota""
    }
  }
}
```",Camilazhs,2024-07-12 14:59:56+00:00,[],2024-07-12 16:30:21+00:00,2024-07-12 16:30:20+00:00,https://github.com/metabase/metabase/issues/45489,[],"[{'comment_id': 2225929648, 'issue_id': 2405810814, 'author': 'paoliniluis', 'body': 'actualiza a v49.18', 'created_at': datetime.datetime(2024, 7, 12, 16, 30, 20, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-07-12 16:30:20 UTC): actualiza a v49.18

"
2405799654,issue,closed,completed,Popover crashes parameters in interactive dashboard,"### Describe the bug

When using the Embedding SDK, clients are running into some errors with dashboard filters, causing the screen to go black and forcing the user to refresh the browser. 

It looks like users are running into this with a Vite build, and maybe our original Popover isn't playing well together.

https://files.slack.com/files-tmb/T078VCLCR-F07CB0GTPB2-0141d75997/image_720.png

### To Reproduce

Try to use the dashboard filters in the `InteractiveDashboard`, which causes the browser to crash with the error of 

```
Tether Error: Both element and target must be defined
```

### Expected behavior

Using filters/parameters shouldn't crash the browser and should work normally.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{}
```


### Severity

P2

### Additional context

_No response_",oisincoveney,2024-07-12 14:53:47+00:00,['oisincoveney'],2024-07-24 13:20:14+00:00,2024-07-24 13:20:13+00:00,https://github.com/metabase/metabase/issues/45488,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Embedding', ''), ('Embedding/SDK', 'Embedding SDK for React')]","[{'comment_id': 2247920161, 'issue_id': 2405799654, 'author': 'oisincoveney', 'body': 'Closed as it should be fixed with #45671', 'created_at': datetime.datetime(2024, 7, 24, 13, 20, 13, tzinfo=datetime.timezone.utc)}]","oisincoveney (Issue Creator) on (2024-07-24 13:20:13 UTC): Closed as it should be fixed with #45671

"
